Do you remember this paper, less than two weeks old?
It made waves by concluding that open source models
can mimic the style, but not the factuality of chat QPT.
Overall, we can conclude, they say,
that model imitation is a false promise.
Well, 48 hours ago, we have this,
a 51 page report on Orca,
based on a small 13 billion parameter model.
I don't often comment on open source models
because they're simply not competitive
with open AI's models.
But Orca is not just competitive with GPT 3.5.
It beats it in quite a few well-established benchmarks
and even matches GPT-4 in a couple of tests of reasoning.
As always, I've read both papers in full
and can also bring in just-released comments
from Sam Altman and Ilya Sutskova
on competition from open source models.
But let's start with Orca, named presumably
because Orcas or killer whales
are frequent visitors to South American coastlines.
And South America is, of course,
the land of llamas and vicunas.
But all the research was done by Microsoft,
which I find interesting
and I'll come back to that at the end.
But why did they make Orca
and why does it perform better than models
like llama, alpaca and vicuna?
Well, they say here in the abstract
that those other models lack rigorous evaluation,
resulting in overestimating the small model's capability
as they tend to learn to imitate the style
but not the reasoning of LFMs, large foundation models.
To address these challenges,
we developed Orca, a 13 billion parameter model
that learns to imitate the reasoning process
of the larger models.
Orca learned by looking at GPT-4's
step-by-step thought processes
and is guided by teacher assistance from chat GPT,
which is GPT 3.5.
And to give you a taste of what's to come,
Orca surpasses conventional state-of-the-art models,
such as vicuna, by more than 100%
in complex zero-shot reasoning benchmarks,
like the big bench hard, which I'll talk about,
and by 42% on AGI eval.
It goes on, Orca reaches parity with chat GPT
on the big bench hard
and shows competitive performance
in professional and academic examinations
by the SAT, LSAT, GRE and GMAT.
And I know many of you will be interested in this footnote.
We are working with our legal team
to publicly release a diff of the model weights
in accordance with Lama's release policy.
So if this is anything like Lama,
it's gonna be leaked across the internet imminently.
I'm gonna show you so many tests
and benchmarks in a moment.
But just to give you a sample,
here is Orca outperforming chat GPT
in the vicuna evaluation set
and matching text DaVinci 3 in the SAT, LSAT, GRE and GMAT.
And as I'll touch on later,
this was zero shot without chain of thought
or any advanced methods.
You can watch pretty much any of my other videos
to see how advanced prompt engineering
would probably boost those results still further.
For those who didn't know, 13 billion parameters
is about 7% the size of GPT-3,
which is 175 billion parameters,
and possibly around one or 2% of GPT-4's size.
That gives you an indication of the difference in size
between Orca and these models that it's competing with.
And if that doesn't make any sense,
a smaller size means it can be run on much smaller devices,
like a desktop or even possibly a laptop.
The authors start off by giving a little slap
to the other paper.
You know that one that said model imitation
is a false promise.
And they continue that contrary to this assertion,
it is possible to reduce the gap with proprietary LLMs
on multiple zero shot benchmarks
that require sophisticated reasoning.
As we'll see, models like Vakuna claim to have 90%
of chat GPT's quality,
but when it came to reasoning tasks
or more technical tasks, it basically flopped.
Here's a chart I'll come back to
outlining some of the more technical challenges
you can give a language model.
We should remember that Vakuna is a fine-tuned version
of the LLama model,
and it's competitive or even better than Palm II.
But give it some of the harder challenges
for a language model,
and it really struggles, as you can see in this column.
Take logical deduction, where it only scored 1.2%.
Well, this Orca model was 2,900% better than that,
scoring 36% competitive with chat GPT.
I'm gonna come back to the big bench benchmark,
but look for a second at causal judgment,
where Orca, a 13 billion parameter model, matches GPT4,
which is about 100 times the size.
But back to how they actually did it.
Models like Alpaca and Vakuna
were given lots of query and responses
from chat GPT or GPT4.
But what they did is they leveraged system instructions,
asking models like GPT4 and chat GPT
to think step by step.
This gave Orca access to detailed responses from the model
that explained the reasoning process of the teacher
as it generates a response.
It allowed these parent models of GPT3.5 and GPT4
to be much better tutors for this young Orca.
Also, they let the teachers of chat GPT,
which is 3.5 and GPT4,
give far more examples to their student.
Five million and one million examples respectively.
That compares to the other models you may have heard of,
like Alpaca, Wizard, Vakuna, et cetera,
which had tens of thousands
or the low hundreds of thousands of examples.
But again, the key difference is the explanations,
the step by step thinking
that the smaller Orca could then imitate.
They give a quick demo here
of how the other open source models
learn from their GPT parents
with a simplistic question and answer format.
In contrast, the authors leveraged system messages
to get chat GPT and GPT4 to think step by step,
leading to much richer explanations,
as you can see in this diagram.
It wasn't just let's think step by step, by the way,
also things like explain like I'm five.
They also wanted the task to be as complex
and diverse as possible.
So they used the Flan collection.
This was released by Google in February
and focused on balancing the kind of prompts and tasks
that you fine tune the language models on.
You can see here the 16 system messages
that they give to chat GPT and GPT4.
And you can see here the kind of difference that that makes.
Imagine a language model trying to learn from this human.
The human is asked, pick which sentence is not logical.
Sentence A, people in the desert often look forward to flood
or sentence B, people in the desert often look forward
to rain.
The human responds, there is no reason
to look forward to a flood because floods cause damage.
The answer is sentence A.
Now, yes, a language model can learn from that,
but by leveraging those system assistant messages,
look at the kind of response that GPT4 gives.
Now, Orca can learn a lot more from that explanation.
And that's one of the main reasons it's better
than all the other open source models.
Because remember, Vikuna is the best
of the open source models.
In this leaderboard, it has an elo of 1054,
better even than Palm II bison.
All the models higher than it are proprietary.
But there is another reason why Orca performs so much better.
You might have wondered,
why didn't they just use only GPT4?
Well, yes, there were cost and time considerations,
but there was another factor that they found.
They were able to use chat GPT or GPT3.5
as an intermediate teacher.
That teacher, chat GPT, was able to reduce the gap
in capabilities so Orca got smarter
and better able to learn.
A bit like progressive learning where you first learn
from easier examples, then followed by harder ones.
After that, they gave it outputs from GPT4.
Notice, by the way, what happens
if you skip the chat GPT teaching assistant
and only train on those one million examples from GPT4.
What happens is a bit like a student struggling
in a class that's too advanced for them.
Orca actually performs worse in those circumstances,
averaging 37%.
But with that intermediate teacher beforehand,
it gets 41.7%.
Speaking of time, it only took about 200 hours
to train Orca on 20 A100 GPUs.
They did take a few weeks to collect the data
from chat GPT and GPT4,
but presumably if they're planning to open source this,
which they say they are,
then that step could be skipped by the wider community.
Let's now look at some more of the results.
First, for open-ended generation, not multiple choice.
Orca is 95% of chat GPT quality
and 85% of GPT4's quality as assessed by GPT4.
But they wanted to quickly move on
to some more definitive tasks,
because there is a problem of using GPT4 as an assessor.
For example, they observed that there is a positive bias
in GPT4 evaluation toward the response
of the first model in the comparison set.
This reminded me of the unfaithful reasoning paper
that I talked about in one of my recent videos.
You can't always trust GPT4 to give its true reasoning.
But here it is in more objective multiple choice questions.
And notice how much harder many of these tests are
for even these advanced language models.
I am fortunate and proud to have attained a perfect score
in some of the tests in this chart, like the GRE and GMAT.
They were part of the aqua-rat tests
that they gave the models.
So I can say that they really are quite challenging,
hence why GPT4 only gets a 40%.
You can see that throughout,
Orca outperforms Vakuna by quite a margin
and is very competitive with Textavinci 3.
Of course, overall, it does lag behind GPT4,
but this is all zero shot.
A bit later on, I'll come back to the range of methods
that we could use to further improve on Orca.
The percentages, by the way, are the improvements on Vakuna.
Again, the second best open source model.
So far, we've looked at human centric benchmarks
like the GMAT and GRE.
These are grouped with the lovely name AGI EVAL.
As we've seen, even the top models lag behind
the top human performers.
But what about a benchmark specifically for language models?
It's called Big Bench Hard.
The original Big Bench had 207 tasks,
but language models got so good
that they had to narrow down the benchmark
to just the 23 challenging tasks
where human raters still did better than language models.
Now, it turns out when you add chain of thought prompting
to the models, they do even better
and there are even fewer tasks that humans are better at.
Anyway, all you have to remember is that these are 23
of the hardest tasks for language models.
And I'll just let you compare the results for yourself.
But the trend is really quite clear.
Orca massively outperforming
the previous best open source model, Vakuna,
beating even chat GPT on average,
but still, of course, lagging behind GPT-4,
except for a few tasks.
Look at Web of Lies where Orca outperforms GPT-4.
That would be a question like this.
Alexis says, Shonda tells the truth.
Jim lies.
Antoine says, Jim tells the truth.
Shonda says, Antoine lies.
Does Alexis tell the truth?
Or what about temporal sequences
where Orca absolutely crushes Vakuna
and doubles chat GPT's performance?
That would be a situation like this.
Now, I'm not gonna read it all out,
but essentially you have to figure out
when the timings match up.
Basically keeping track of time
and Orca does really well
and chat GPT flops getting it wrong.
Interestingly, they also tested all four models
on that common sense reasoning question
that I demonstrated for smart GPT
about hanging the clothes to dry.
As you might remember,
you can use prompt engineering to nudge the models
to almost always get it right,
which is partly why I view these results
more as a baseline rather than a cap.
And the authors admit this too.
Orca has been trained on data
that simulate zero shot setting with standard prompts.
The models performance in other contexts
such as multi-turn conversations
like the DERA paper I talked about on the channel,
in-context learning and few shot learning
or advanced prompting techniques
that smart GPT or Tree of Thoughts, for example,
and they say like chain of thought prompting
remains untested.
These results are a baseline, not a cap.
They mention other ways that Orca could be improved,
for example, through tool augmentation.
And that's not just calculators, calendars,
Bing or auto GPT.
I was gonna do a separate video on this paper,
but I'll just mention it here.
This paper from last week demonstrated
that larger models can create tools
that smaller models can then use more efficiently.
Once the best language model, say GPT-4,
has created a generic Python function, which is the tool,
and then written some unit tests,
it can then wrap and hand over those tools
to smaller models like GPT-3.5, or in this case, Orca,
and check out the toolmaking row
to see the improvement for chat GPT, or in our case, Orca,
when they're given these tools created by GPT-4
or better language models.
Their performance across a range of tasks
goes dramatically up.
And we haven't even talked about using
a process-based reward model,
like in the Let's Verify step-by-step paper.
That, of course, could further improve Orca's performance.
Of course, when this model becomes publicly available,
I will test all of this out.
But it hasn't been open-sourced yet,
and they do say this model is solely designed
for research settings.
That does seem a little bit naive to me.
I mean, that's what Metta said when they released Lama,
but then everyone and their grandma
just use the language model for whatever.
I do wonder what it means when they say,
we are working with our legal team.
And it is particularly interesting to me
that this was all done by Microsoft.
I'm gonna go into a little bit of speculation here
about why I think they conducted this research.
You might remember that leaked memo from Google,
we have no motes, and they even mentioned Vicuna,
and talked about how it circumvented restrictions
on the OpenAI API by using shared GPT.
And my theory is that the Microsoft researchers
were testing this point from the memo.
The point was that training giant models from scratch
not only throws away the pre-training,
but also any iterative open-source improvements
that have been made on top.
It doesn't take long for those improvements to dominate,
making the full retrain extremely costly.
Maybe Microsoft is hesitating about future investments
in GPT-5 or GPT-6, and they really wanna test out
if it's easy to imitate those large models on the cheap.
If it is, then why would Microsoft invest billions
in a new giant model?
That's my own theory as to why Microsoft is working on this,
but let me know in the comments what your theory is.
In the conclusion, the authors state that Orca suggests
that learning from step-by-step explanations
could significantly improve the quality of models
regardless of their size,
and that they hope these insights will inform the design
of more robust evaluation methods,
compared to those used for Vecuna, for example,
and the advancement of alignment and post-training techniques,
and the more effective use of powerful models
like GPT-4 as teachers.
And maybe they should have said,
and also with chat GPT as an intermediate teacher.
I'm gonna end with the thoughts of the leaders of OpenAI,
Ilya Sutskova and Sam Altman on open-source models.
And I think there is a bit of a contrast
between the two answers.
Ilya Sutskova thinks that the gap is growing ever wider.
To the open-source versus non-open-source models question,
you don't wanna think about it in binary black and white terms
where there is a secret source
that will never be rediscovered.
What I will say, or whether GPT-4 will ever be reproduced
by open-source models, perhaps one day it will be.
But when it will be,
there will be a much more powerful model in the companies.
So there will always be a gap between the open-source models
and the private models.
And this gap may even be increasing this time.
The amount of effort and engineering and research
that it takes to produce one such neural net keeps increasing.
And so even if there are open-source models,
there will never be, there will be less and less
produced by small groups of dedicated researchers
and engineers, and it will only be the providence
of a company, a big company.
While Sam Altman seems to say
that even if open-source models do catch up,
OpenAI will always have a different kind of moat.
What are your thoughts about the we have no moat document
that was released lately, the leak document?
The thing that is special about OpenAI,
and I think the thing that is so misunderstood
by that document, aside from the fact
that we have a gigantic number of users and people
that have formed some sort of relationship
with us and our products,
is what OpenAI is special about
is figuring out what comes next.
It is the ability, it is easy to copy something
once you know it can be done, and in that sense, sure.
It is very hard to go figure out what to do next,
and the ideas, the big ideas, the medium size ideas,
the small ideas, and the careful execution on them
that it takes to get from here to superintelligence,
that's what our moat is.
Anyway, this video could have been
at least three times longer.
There was so much I had to edit out for brevity.
If you're interested in me talking more
about open-source models, do let me know in the comments.
I've got much more to say.
As always, thank you so much for watching to the end
and have a wonderful day.
