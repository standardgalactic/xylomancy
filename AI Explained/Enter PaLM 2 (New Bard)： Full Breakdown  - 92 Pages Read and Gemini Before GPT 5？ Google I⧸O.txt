Less than 24 hours ago, Google released the Palm 2 technical report. I have read all 92 pages,
watched the Palm 2 presentation, read the release notes and have already tested the model in a dozen
ways. But before getting into it all, my four main takeaways are these. First, Palm 2 is competitive
with GPT-4 and while it is probably less smart overall, it's better in certain ways and that
Second, Google is saying very little about the data it used to train the model, or about parameters,
or about compute, although we can make educated guesses on each.
Third, Gemini was announced to be in training and will likely rival GPT-5 while arriving earlier
than GPT-5. As you probably know, Sam Orman said that GPT-5 isn't in training and won't be for
Fourth, while dedicating 20 pages to bias, toxicity and misgendering, there wasn't a single
page on AI impacts more broadly. Google boasted of giving Gemini planning abilities in a move that,
surprise as I am to say it, makes open AI look like paragons of responsibility.
So a lot to get to, but let's look at the first reason that Palm 2 is different from GPT-4.
On page 3, they say we designed a more multilingual and diverse pre-training mixture,
extending across hundreds of languages and domains like programming, mathematics, etc.
So because of the text that they train Palm 2 on is different to the text that open AI
train GPT-4 on, it means that those models have different abilities and I would say Palm 2 is
better at translation and linguistics and in certain other areas which I'll get to shortly.
If that's data, what about parameter count? Well, Google never actually say,
they only use words like it's significantly smaller than the largest Palm model, which was
540 billion parameters. They sometimes say significantly, other times dramatically.
Despite this, it significantly outperforms Palm on a variety of tasks. To all the references you
may have seen to imminent 100 trillion parameter models were bogus. Skipping ahead to page 91
out of 92, in the model summary, they say further details of model size and architecture are with
held from external publication. But earlier on, they did seem to want to give hints about the
parameter count inside Palm 2, which open AI never did. Here they present the optimal number of
parameters given a certain amount of compute flops. Scaling this up to the estimated number of flops
used to train Palm 2, that would give an optimal parameter count of between 100 and 200 billion.
That is a comparable parameter count to GPT-3, while getting competitive performance with GPT-4.
Bard is apparently now powered by Palm 2 and the inference speed is about 10 times faster than GPT-4
for the exact same prompt. And I know there are other factors that influence inference speed,
but that would broadly fit with an order of magnitude fewer parameters. This has other
implications, of course, and they say that Palm 2 is dramatically smaller, cheaper, and faster to
serve. Not only that, Palm 2 itself comes in different sizes. As Sundar Pichai said,
Palm 2 models deliver excellent foundational capabilities across a wide range of sizes.
We have affectionately named them Gecko, Otter, Bison, and Unicorn. Gecko is so lightweight that
it can work on mobile devices fast enough for great interactive applications on device, even when offline.
I would expect Gecko to soon be inside the Google Pixel phones. Going back to data,
Google cryptically said that their pre-training corpus is composed of a diverse set of sources,
documents, books, code, mathematics, and conversational data. I've done a whole video on the data issues
that these companies face, but suffice to say they're not saying anything about where the data comes
from. Next, they don't go into detail, but they do say that Palm 2 was trained to increase the
context length of a model significantly beyond that of Palm. As of today, you can input around 10,000
characters into BARD, but they end this paragraph with something a bit more interesting. They say,
without demonstrating, our results show that it is possible to increase the context length of the
model without hurting its performance on generic benchmarks. The bit about not hurting performance
is interesting because in this experiment published a few weeks ago, about extending the input size
in tokens up to around 2 million tokens, the performance did drop off. If Google had found
a way to increase the input size in tokens and not affect performance, that would be a breakthrough.
On multilingual benchmarks, notice how the performance of Palm 2 in English is not dramatically
better than in other languages. In fact, in many other languages, it does better than in English.
This is very different to GPT-4, which was noticeably better in English than in all other languages.
As Google hinted earlier, this is likely due to the multilingual text data that Google trained
Palm 2 with. In fact, on page 17, Google admit that the performance of Palm 2 exceeds Google
translate for certain languages and they show on page four that it can pass the mastery exams
across a range of languages like Chinese, Japanese, Italian, French, Spanish, German, etc.
Look at the difference between Palm 2 and Palm in red. Now, before you rush off and try BARD in
all of those languages, I tried that and apparently you can only use BARD at the moment in the following
languages, English, US English, what a pity, and Japanese and Korean. But I was able to test BARD
in Korean on a question translated via Google translate from the MMLU dataset. It got the
question right in each of its drafts. In contrast, GPT-4 not only got the question wrong in Korean,
when I originally tested it for my smart GPT video, it got the question wrong in English.
In case any of my regular viewers are wondering, I am working very hard on smart GPT to understand
what it's capable of and getting it benchmarked officially. And thank you so much for all the
kind offers of help in that regard. I must admit it was very interesting to see on page 14 a direct
comparison between Palm 2 and GPT-4 and Google do admit for the Palm 2 results, they use chain of
thought prompting and self-consistency. Reading the self-consistency paper did remind me quite
a lot actually of smart GPT, where it picks the most consistent answer of multiple outputs.
So I do wonder if this comparison is totally fair if Palm 2 use this method and GPT-4 didn't.
I'll have to talk about these benchmarks more in another video, otherwise this one would be too
long. But a quick hint is that Wynogrand is about identifying what the pronoun in a sentence refers
to. Google also weighed into the emerging abilities debate, saying that Palm 2 does indeed demonstrate
new emerging abilities. They say it does so in things like multi-step arithmetic problems,
temporal sequences, and hierarchical reasoning. Of course, I'm going to test all of those and
have begun to do so already. And in my early experiments, I'm getting quite an interesting
result. Palm 2 gets a lot of questions wrong that GPT-4 gets right, but it can also get questions
right that GPT-4 gets wrong. And I must admit it's really weird to see Palm 2 getting really
advanced college level math questions right that GPT-4 gets wrong. And yet also, when I ask it a
basic question about prime numbers, it gets it kind of hilariously wrong. Honestly, I'm not certain
what's going on there, but I do have my suspicions. Remember though that recent papers have claimed
that emergent abilities are a mirage, so Google begs to differ. When Google put Palm 2 up against
GPT-4 in high school mathematics problems, it did outperform GPT-4. But again, it was using an
advanced prompting strategy, not 100% different from smart GPT. So I wonder if the comparison
is quite fair. What about coding? Well, again, it's really hard to find a direct comparison
that's fair between the two models. Overall, I would guess that the specialized coding model of
Palm, what they call Palm 2S, is worse than GPT-4. It says its pass at one accuracy, as in
past first time, is 37.6%. Remember the Sparks of AGI paper? Well, that gave GPT-4 as having an 82%
zero shot pass at one accuracy level. However, as I talked about in the Sparks of AGI video,
the paper admits that it could be that GPT-4 has seen and memorized some or all of human eval.
There is one thing I will give Google credit on, which is that their code now sometimes references
where it came from. Here is a brief extract from the Google keynote presentation.
How would I use Python to generate the Scholar's Mate move in chess? Okay, here Bard created a
script to recreate this chess move in Python. And notice how it also formatted the code nicely,
making it easy to read. We've also heard great feedback from developers about how Bard provides
code citations. And starting next week, you'll notice something right here. We're making code
citations even more precise. If Bard brings in a block of code, just click this annotation,
and Bard will underline the block and link to the source. As always, it seems the appendix
contained more interesting information sometimes than the main body of the technical report. For
example, we get a direct and fair comparison between GPT-4 and Palm II, or I should say
Flan Palm II. That is the instruction fine-tuned version of Palm II. Essentially, that's the
version where it's been fine-tuned to get better at following a question-and-answer format. But
anyway, the original Palm II scored 78.3% and Flan Palm II scored 81.2%. That's below the 86.4%
of GPT-4. And that's why my broad conclusion is that GPT-4 is a bit smarter than Palm II.
But as I'll be showing over the coming days and weeks, there are genuinely quite a few areas
in which Palm II is better than GPT-4. What about the big bench, which was designed to be
particularly tough for language models? I talked a lot about this in my earliest videos.
Well, the graph is going to look pretty weird because Palm II has improved upon palm while
reducing the number of parameters. So the graph kind of doubles back on itself, back up here,
up to around 69% according to the technical report. I would say this is quite a major
moment in human history. There is now virtually no language task that the average human can do
better than Palm II. Of course, expert humans can do better in individual domains, but the
average human is now worse in virtually every domain of language. Here you can see that confirmation
of the big bench hard results for Flan Palm II, 69.1%. Interestingly, in the original chart,
Palm II is even claimed to have higher performance than that at 78.1%.
If you remember, the reason we can't compare that to GPT-4 is that in the technical report for GPT-4,
they admit that during their contamination check, we discovered that portions of big bench were
inadvertently mixed into the training set and we excluded it from our reported results.
Before we get to Gemini, Google show off in the latter half of the technical report with examples
of linguistic ability, like writing paragraphs in Tejiki and then translating them into Persian.
They go on to show examples in Tamil and they are really making a big point of showing off
its multilingual capabilities. At this point, and I'm going to admit this is my personal opinion,
Google then strays into dozens of pages on bias, toxicity and gender. Interestingly,
some of the people paid to assess these risks were paid only 1.5 cents per judgment. These things
do need to be addressed, of course, but it was somewhat shocking to me to see 20 pages of that
and not a single page on the broader AI impacts. As many of you may know, I have criticized OpenAI
plenty of times on this channel, but compare their technical report, which goes into far more
detail about what we need to monitor. The closest Google got was showing how their universal translator
could be used for deep fakes. Universal Translator is an experimental AI video dubbing service
that helps experts translate a speaker's voice while also matching their lip movements.
Let me show you how it works with an online college course created in partnership with Arizona State
University. What many college students don't realize is that knowing when to ask for help
and then following through on using helpful resources is actually a hallmark of becoming
a productive adult. Muchos universitarios no comprenden que saber cuando pedir ayuda y
usar recursos útiles es en realidad una clave para convertirse en un adulto productivo.
It just seems a massive black hole when one of their recent former employees Jeffrey Hinton
had this to say this week on CNN. You've spoken out saying that AI could manipulate
or possibly figure out a way to kill humans? How could it kill humans? If it gets to be much
smarter than us, it'll be very good at manipulation because it will have learned that from us.
And there are very few examples of a more intelligent thing being controlled by a less
intelligent thing. And it knows how to program. So it'll figure out ways of getting around
restrictions we put on it. It'll figure out ways of manipulating people to do what it wants.
It's not clear to me that we can solve this problem. I believe we should put a big effort
into thinking about ways to solve the problem. I don't have a solution at present. I just want
people to be aware that this is a really serious problem and we need to be thinking about it very
hard. This all seems particularly relevant when Google made this announcement about Gemini,
their rival to GPT-5. All this helps set the stage for the inflection point we are at today.
We recently brought these two teams together into a single unit Google DeepMind. Using the
computational resources of Google, they are focused on building more capable systems safely and
responsibly. This includes our next generation foundation model, Gemini, which is still in
training. Gemini was created from the ground up to be multi-modal, highly efficient at tool and
API integrations, and built to enable future innovations like memory and planning. That
ability to plan may ring a bell from the GPT-4 technical report, which said this, novel capabilities
often emerge in more powerful models. Some that are particularly concerning are the ability to
create and act on long-term plans. Remember, Google didn't identify planning as a risk,
but as a selling point for Gemini. Next, Google talked about accelerating their progress, which
was again directly mentioned in the GPT-4 technical report. It said, one concern of particular
importance to open AI is the risk of racing dynamics leading to a decline in safety standards,
the diffusion of bad norms, and accelerated AI timelines, each of which heightens societal
risks associated with AI. We refer to these here as acceleration risk, and make no mistake,
Gemini will be very accelerated from Palm II. It looks set to use the TPU-V5 chip, which was
announced back in January of last year, and on page 91 of the Palm II technical report,
they say that that model used TPU-V4. Now, it should be said that Palm II is leading to some
impressive medical applications, as I actually first reported on seven weeks ago without quite
realizing it. Here's Med Palm II. We believe large language models have the potential to revolutionize
healthcare and benefit society. Med Palm is a large language model that we've taken and tuned
for the medical domain. Medical question answering has been a research grand challenge for several
decades, but till date the progress has been kind of slow. But then over the course of the last
three to four months, first with Med Palm and Med Palm II, we have kind of like broken through
that barrier. Unlike previous versions, Med Palm II was able to score 85% on the USMLA medical
licensing exam. Yeah, this is immensely exciting because people have been working on medical
question answering for over three decades. And finally, we are at a stage where we can
see that confidence that AI systems can now at least answer USMLA questions as good as experts.
Now, as many of you may know, the CEO of Google as well as the CEO of Microsoft and Sam Altman
and the CEO of Anthropic all went to the White House to discuss AI risk and opportunity. But
given that the main outcome from that seems to be 140 million to establish seven new AI research
institutes, that feels a little slow given all the acceleration that's occurring. Because as Google
somewhat soberly conclude their report, we believe that further scaling of both model parameters
and data set size and quality, as well as improvements in the architecture and objective,
will continue to yield gains in language understanding and generation. They are not
slowing down and the world hasn't yet caught up. Thank you so much for watching to the end and have
a wonderful day.
