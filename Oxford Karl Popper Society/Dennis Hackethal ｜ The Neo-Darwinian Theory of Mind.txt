So everyone can hear me then. Good afternoon. I'm very pleased to announce their speaker
today is Dennis Hackenthal, who is a software engineer, artificial intelligence researcher
and author of the book, A Window on Intelligence. And today we'll speak about the role of replicators
in creativity, a topic in which Dennis has written for Conjection Magazine in an article
called The Neodorinian Theory of Mind, which we've linked to on Twitter and which we'll
link to in the video as well. And I should also say that I think Conjection Magazine is open to
pictures from writers, for those of you who are interested in possibly contributing an article
to the website. And in general, I also really recommend checking out Conjection Magazine,
I think is a great initiative. And yeah, with that introduction, I give the floor to Dennis.
Dennis, thanks so much for joining us. And I look forward to your talk.
Hi, I'm glad to be here. It was very nice of you to invite me. And I should also mention
Logan Chipkin, who I think is behind this. So shout out to him as well.
Yeah, shout out to Logan.
Yeah, so I'm here to talk about what I call the Neodorinian Theory of the Mind.
Before I start, I should say that to give credit where credit is due, I'm indebted to Karl Popper
and David Deutsch, because without their epistemological work, I could never have thought
of what I'm about to tell you. And also Richard Dawkins, who's influenced my thinking on evolution
quite a bit. And it occurred to me recently that maybe the Neodorinian Theory of the Mind is much
too grand a term. I think maybe it should be called the Neodorinian aspect of the mind or
the Neodorinian approach to the mind or something like that. I think that'd be a better name because
I think theories of the mind are a dime a dozen and none of them work. And otherwise,
we could already build AGI, artificial general intelligence. And so it might be better to choose
a smaller name than that. But also there's some construction going on outside, so apologies if
you hear anything if there's any noise. But yeah. So the meat of the theory of the approach or whatever
you want to call it is very simple. But it does take just a moment to kind of sneak up on it.
And so in the Papyrian fashion, what I'd like to do is I'd like to start with some problems.
Some problems that I'd like to think that the theory or the approach solves are, for example,
one, how does the mind create new conjectures? Two, how does memory work?
Which includes things like why do we forget things? Why are memories so unreliable?
Why do some memories last longer than others? Those kinds of things.
How did people evolve? And then lastly, I want to give, by no means any theories, just some
small pointers for why I think we are conscious of some things and not of others.
It's interesting to note that originally I only set out to solve the problem of how people
evolved. And then I later found that this approach also allows me to solve these other problems.
So I only have a few slides. This is the last slide. I'll leave this open.
I want to give, I actually want to start in biology. And then I'll tie this back in with a
mind later on. I promise they're related. And I'd like to talk about the origin of life
for a moment. And many have said that what happened there was so unlikely and credible.
It's almost too good to be true that that happened. And as far as I understand it,
there are still some mysteries around it, what exactly happened there. But there are some
good explanations that I think give us a pretty good idea of what may have happened.
And the theory that I subscribe to is called the RNA world hypothesis.
And the idea is basically that a long, long time ago when the Earth had just formed,
the oceans, they were still highly chemically active. And there were molecules forming
spontaneously in those oceans and disintegrating. And it was a big mess. It was a big chaos in this
so-called primordial soup. And what some of those molecules were is they were enzymes,
they were chemical catalysts. And what that means is that they were able to,
they were, they were able to cause a change in other molecules, for example,
while retaining the ability to cause those changes again at a later time. They didn't
undergo any changes themselves. And what happened then, so to say, that some of these molecules
happened to cause chemical reactions that produced some of their own components.
So that in this primordial soup, over time, you would get more and more of the building blocks
of which these molecules themselves were made. This is what I'm kind of sneaking up on,
is the role of replication in biological evolution. And because once these molecules,
once these enzymes get targeted enough, it makes sense to call them replicators.
Because that is what they end up doing. They create a copy of themselves.
So the idea is that this way, gradually, we get replication happening in the primordial soup.
But this alone isn't enough for evolution to occur. You also need variation in selection.
But I think once you have replication, variation is bound to happen sooner or later,
because replication is not going to be perfect forever. And sooner or later,
the replicators are going to make a mistake during replication. And this is what introduces variants.
And what you get then is you have, if the variant is even fit enough still to keep replicating,
what you get then is you have a slightly different kind of replicator. And if that
is still able to replicate now, what you're getting is you're getting two different pockets
of this population. One pocket of the population is still the old replicator, the copies of that
replicator. And the new pocket of the population is this new kind of replicator. And so then
the question is, well, which one is better at replicating than the other? And these differences
in the rate of replication is what we call selection. I think Richard Dawkins in his book,
The Selfish Gene, I think he uses the technical term as the non-random differential reproduction
rate or something. And usually, because a replicator is already adapted to replicating,
that means that any variant, if a mutation is going to occur, more often than not,
it's going to be worse at replicating. So usually you could expect that if the
replicator mutates, the mutant variant is going to have a harder time replicating.
Because by definition, this is how William Paley, I think, defined adaptation,
something is adapted to something, for example, replication, that by definition means that if
you make any slight change to it, it's going to get worse. It's very difficult to get it to make it
better. But every now and then, a mutation can lead to a benefit. And by benefit, I don't mean
that there's some well-meaning force in the biosphere. It just means that it helps the variant
spread through the population of replicators at the expense of its rivals. And I think it's
important to keep things simple when it comes to the theory of evolution. Really, all that the
replicator wants to do, I say in scare quotes, it's not a conscious being, but all the replicator wants
to do is spread through the population of replicators. It's all it cares about. And sometimes,
in service of that goal, complex adaptations can arise. Now, what is... So I'm going to start tying
this back in with the mind now. Carl Popper said that the information that is stored in such
replicators is adapted. And so therefore, it's knowledge. Adapted information is knowledge,
or maybe that particular phrasing originated with David Deutsch. And Popper's conjecture is
that people also create human knowledge by evolution. So evolution in that sense
is not limited to the biosphere, excuse me, although there are important differences between
biological evolution and the evolution that occurs in our minds, there are strong parallels
between them. And so Popper offered this analogy of a new conjecture that people come up with,
being analogous to the mutation of a gene, and criticism being analogous to the selection of
a gene. And the old theories that we derive knowledge from the census, for example, which is
empiricism, or that we create them by extrapolating repeated observations, which is inductivism,
although they're completely false, as Popper explained. And instead, he argued that we create
knowledge by starting with problems, not with observations, which are conflicts between ideas,
as David Deutsch defines them. And then we guess solutions to these problems, and we criticize
them until we, hopefully, come up with a solution that we deem good enough to adopt tentatively.
And this is not only scientific knowledge that grows that way, all human knowledge grows that way.
And an example I like to give is that of losing your keys. If you're not sure what your keys are,
and let's say you need them now because you want to leave, really all you can do is guess
where they might be. So maybe you left them on the kitchen counter. So that is a tentative
solution to the problem. And then you can go look for them there. And if you don't find there,
then you know that your theory was false. And so you have to guess another solution, maybe they're
in your pocket or something. And if you find them there, that's great, then you've made progress.
So knowledge, even in the most mundane, you know, scenarios like that, knowledge grows that way.
And I do think that Popper was right about all of this. And I even like to think of them as the
foremost artificial general intelligence researcher of this time, although I don't think
he would have called himself that. But as should be expected, if we're papyrus and fallible lists,
there are open problems with hispistemology. And these are some of the open problems,
the open problems I mentioned at the beginning are some of those. So just to reiterate them,
those were how does the mind create new conjectures? How does memory work? How do people evolve?
And then the big one is consciousness.
And to solve them, what I would like to suggest is the following, that if we can think of
the biosphere as an arena of self replicating genes, that analogously, we can think of the mind
as an arena of self replicating ideas. Now, having said that, there are still many
important differences between the mind and the biosphere. So I don't by no means do I want to
equivocate those two. But I do think there are strong parallels that may help us explain some
things. I should also mention once I say replicating ideas, we may jump to memes, which are Richard
Dawkins idea of the cultural unit of a replicator. Those are not what I mean, just to just to clarify.
Memes are ideas that replicate across minds. Memes are not just funny pictures on the internet.
It's basically any idea that manages to jump from one mind to another, or at least enough minds
that it becomes meaningful to call it a meme. So a joke is a meme, but also catchy song could be a meme.
And with the example of the joke, I think this is an example David gives in his book,
you know, if the joke is good enough, then it causes the holder, the person who knows the
joke to tell it to somebody else. And so now the joke is in two minds, not just one. And that's
why it's meaningful to call it a replicator. But again, I'm not talking about memes here,
I'm only talking about ideas that replicate strictly within a single mind. So it can help,
I think, to just think of a mind that's just cut off completely from the outside world to make
things easier. So you can just imagine the brain in a vat, if you like, doesn't have any access
to the outside world. And still, I think there would be self replicating ideas in the mind.
It's also a nice way to make sure that we can't accidentally adopt any empiricist or
inductive notions, if we just completely disregard sense data. And so I think with this simple premise
that the mind is an arena of self replicating ideas, we can we can now start solving the problems
that I mentioned. And I think when it comes to the question of how people evolved,
I would say that the evolution of the mind and the evolution of people
is analogous to the origin of life in the biosphere. Because I'd like to suggest that the
evolution of self replicating ideas in a mind happened analogously to the evolution of self
replicating molecules in the primordial soup. And I think what happened is, well,
so this is popper again, so all organisms contain knowledge in the objective sense.
Meaning, for example, wolves know how to hunt in packs and dogs know how to fetch balls,
beavers know how to build dams and so forth. This all takes knowledge.
All of these activities have the appearance of design. So we know that there must be
knowledge behind them. And that knowledge is stored in their genes. And so we could just call
the knowledge that results in these behaviors, we could call those ideas in the objective sense.
And the set of all ideas that an organism has, I call its idea pool.
And some of these ideas, I think, act just like the enzymes, those molecular catalysts
from the primordial soup. They're able to make a change in other ideas within the same organism
without undergoing any net change themselves. And in one of our ancestors, because of a genetic
mutation, there was one such idea, one such catalyst that happened to promote the production
of ideas of which it itself was made. But more technically speaking, you could say that it happened
to promote the production of source code of which it itself was made. And then the same thing
happened that happened in the primordial soup. Whenever that catalyst happened to become a little
more targeted, it produced more of its components more faithfully, until you know, at some point,
you could say that it was targeted enough to meaningfully call it a replicator.
Except this time, it's not a molecule that self replicates. It's not a material, a physical thing.
It's an abstract thing. It's an idea. And this thing now replicates over and over
during that single organism's lifetime. So in addition to biological evolution that we have
happening, we now have what we could call mental evolution happening during that single organism
lifetime. I also call that runtime, the runtime of that software. And like I said, just like in
the primordial soup, once you have replication, or replication is not perfect forever, the even
the best replicator makes mistakes every now and then. So sooner or later, variation and selection
will kick in. And that's how you get evolution in the mind. And so that's how you get a dynamically
changing idea pool, much like you have a dynamically changing gene pool in nature.
And this is how this organism can now create new knowledge, knowledge that was not genetically given.
And that's something people do all the time. Everyone in this column is doing it right now.
And I believe that this, what I've laid out is the underlying logic that allows them to do so.
So we've solved now the, I mean, hopefully, we've solved the problem of how people evolved.
And the second problem also, which is where do conjectures come from? I think they're just the
result of a long string of ideas replicating perfectly, accidentally morphing into an idea.
And we can also explain now how memory works. Memory, as with so many things of the mind that are
unfortunately explained on the level of the brain, memory is often explained on the level of neurons.
And so I'm going to butcher it probably, but one idea that I've heard many times is that
one set of neurons is said to encode one idea. And then if that set is wired to another bundle of
neurons, then whenever one thinks of one, one also thinks of the other. So this is how associative
memory is explained. And also, they say that the more you think of those ideas, the stronger the
physical connection that these neurons get. I think that's completely false. I think it's
reductionist. And it also sounds a bit like there might just be a tinge of Lamarck's use
and disuse theory sprinkled in there. But I think the reason that can't be true
is that we know from computational universality, here I'm influenced by David Deutsche again that
we know from computational universality that we could simulate a mind on a computer,
including that mind's memory, even if that computer hardware doesn't have any neurons.
So you don't need neurons. We need to explain memory on the appropriate level of emergence.
And that is software, not hardware. And I think with this approach, the new Darwinian approach,
with the replicator approach, we can answer the question of how memory works.
In the biosphere, some species survive for much longer than others, although it's really the
genes that we're concerned with, not with the animals themselves. And I think the same is true
in a mind. Some self replicating ideas just manage to stick around longer in that mind's idea pool.
And those replicators that are longer lived than others and happen to encode events from
the past, those are the ones that we call memories. But there's nothing else that's
special or different about them that separates them from other ideas. I think memories are usually
thought of as a special class of idea. I certainly used to think of them that way, but I think that's
wrong. And then when a certain population of ideas and coding memory dies out, let's say because they
can't compete with rival ideas in that idea pool, then that's just what it means to forget something.
And we can also explain why memories are so unreliable. It's because replication
isn't perfect and mutations happen eventually. So memory is just an emergent phenomenon
of that underlying pool of self replicating ideas. And memory being unreliable
is just a special case of knowledge being unreliable.
And now just some small pointers for when it comes to consciousness. Why are we conscious of
some things and not others? Popper conjectured that consciousness has to do with disappointed
expectations. I think this was in this book, Objective Knowledge. If I recall correctly, he
gave this example of walking up a flight of stairs. And if you get to the top and you think that
there's one more step, but there isn't, we've all been there, it feels very weird. And you,
not only are you surprised at that sensation, but you also realize that you had an expectation that
there was another step. And you wouldn't have realized that if there had been another step.
So this is what why Popper argues that consciousness may have to do with disappointed
expectations. Something I'd like to add to that is that when we, for example, when we're
children and we learn how to ride a bike, initially this process is a very conscious
effortful process. We're very aware of everything we're doing. We're aware of the peddling. We're
aware of keeping our balance. We're aware of steering and everything because all of this
requires error correcting. But as you get better at riding your bicycle,
excuse me, as you get better at riding your bicycle, you become less aware of those things.
Until now, you know, now when I ride my bike, I don't really know how I do it anymore. I just,
I just do it, but I couldn't tell you how I keep my balance, for example. And that allows
me to free up my attention and focus it on the road, for example, so that I can avoid potholes
or avoid accidents. So it seems to me that consciousness has to do with error correction
generally. And I'd also like to add this observation that I think what's curious is that
despite the mutations of ideas that we know must be happening in our minds because mutations are
inevitable, we never seem to be aware of any junk ideas. But if mutations are usually detrimental
and only rarely beneficial, that must mean that at any given moment, there are probably
many of these junk ideas in our minds. But we're never aware of them. I think that's curious. So
I conjecture that maybe a necessary condition for something to enter our consciousness
is that it be sufficiently adapted by some yet to be defined criteria. Now, to be clear,
none of this explains consciousness by any means. And it's not meant to. But these are just some
pointers. Something else that I think this approach allows us to do is we can start thinking, taking
maybe what Richard Dawkins would have called the genes I view, and we can, we can take the
ideas view, ideas I view, I guess it would be called, and think about what it would be like for an
idea to live in that self replicating pools of idea, a pool of ideas. And we can think about
different replication strategies that these ideas may have, and what effect this could have on the
mind. So now I do want to take it back to the level of means for a moment. Dave, do I just conjecture
that there are two different replication strategies for means, static and dynamic.
And I quote from the beginning of infinity, a dynamic meme is quote an idea that relies on the
recipient's critical faculties to cause itself to be replicated. End quote. So these are ideas that,
broadly speaking, help progress and they help their holder make progress. They can at least.
And opposed to that are static means or anti-rational means. And those are quote,
an anti-rational means quote an idea that relies on disabling the recipient's critical faculties
to cause itself to be replicated. End quote. So these are ideas that prevent criticism of themselves
and thereby prevent their holder from making much progress. And so
the David Deutsch calls the societies that are dominated by either kind of those memes, static
versus dynamic societies. And so static societies, he says, are the kinds of societies which rarely
ever change on timescales that the people living in those societies could notice. Whereas the
dynamic societies change rapidly and they can make rapid progress because they're dominated by dynamic
means. So those are the memes. But what I wonder is if we could introduce the same replication
strategies inside of minds. So instead of the level of society, we're now looking at the level of the
mind with ideas being the individual actors, not people. Or ideas or I should say the self-replicating
ideas in a mind being the actors, not memes being the actors. And so that could then lead us to
identify, say, certain minds as static and certain minds as dynamic or more or less of one or the
other. And then we could think about how static minds differ from dynamic minds and maybe what
that would mean for mental ailments and their alleviation. Given the damage that static memes
can do to static societies, I wouldn't or societies, I would not be surprised if static ideas inside
a mind can also do great damage to that mind. And I would expect a static mind to have a much
harder time making progress than a dynamic mind. And perhaps, just like a static society, a mind
that's dominated by static ideas would be overly concerned with, you know, faithfully enacting
some lifestyle and focusing too much on prevention strategies, which isn't sustainable. I'm borrowing
here from Dave Deutsche again, which isn't sustainable because the mind would eventually
encounter a problem that overwhelms completely. So those are, that's just an idea to play with,
you know, maybe we can find something interesting there when it comes to replication strategies
inside minds. And then one last thing that I'd like to mention is the, when it comes to the
approach itself is another reason that, or another explanation for why you cannot download an idea
from one mind to another, which is a direct conclusion from Popper's critique of what he
called instruction from without. It's not like we need another explanation, but I think this
may be illustrated a little more. So as a thought experiment, let's say that we have the technology
to read people's minds or read their ideas somehow. It doesn't matter how it works, but
let's say you somehow connect their brain to a computer interface and then the program in that
interface parses all the ideas in that brain and presents their source code to you. So you could
read them technically. And let's just say that's a given. And let's say that you could then, via
the same interface, you could connect to another person's brain and you could just copy paste the
idea from one brain to another. So technically, you know, couldn't we say that that would constitute
a successful download of an idea from one mind to another? And maybe we could, but even if so,
I think it still wouldn't refute what Popper meant when he said that instruction from without
it's impossible. And I think the reason is that the transferred idea, once you copy and paste
that idea, it most likely will not make it in the new mind. It's a bit like taking a penguin from
an arctic on placing it in the African jungle, that penguin is not going to survive. Because I
think our minds are all extremely different, just like extremely different ecosystems. So placing an
idea from one another is it's not going to make it, we shouldn't expect it to survive in the other
mind. The idea, if we want to get the second mind to have that idea, much better approach, I think is
to get that mind to evolve the idea itself, in other words, through persuasion.
So this is the new downloading approach, more or less in a nutshell. What I'd like to do
is respond to some criticism that the approach has received. And I'll start with
Ella Hepner, who most notably has offered several different criticisms of the theory.
One such criticism says that replication is wasteful. It's computationally wasteful.
And so there wouldn't have been enough memory in our early ancestors' brains for ideas to replicate.
And now I mean memory in the sense of storage space, not in the sense of remembering things.
So my response to that is I'm not sure that that is true. Many complex animals already seem to have
enough spare memory to store additional information during their lifetimes. And in particular, our
ancestors must have had enough memory, at least memory that was free at the time of birth,
for them to copy and store relatively complex memes, at least complex compared to other animals'
memes. Now to be clear, they didn't replicate those memes creatively because this is pre
the evolution of minds. But as David Deutsch points out in the beginning of infinity, meme
evolution already drove the evolution of our ancestors. So there was already selection pressure
favoring the development of ever more free memory in our ancestors' brains so that they could copy
ever more complex memes. And that would have been space that our ancestors' self-replicating ideas
could have used. On the note of memory, I would think that biological evolution, even long before
the evolution of people, would have discovered basic memory management solutions,
such as garbage collection, for example. Garbage collection, I don't have a computer
science degree or anything, but my basic understanding is that garbage collection is
a way to monitor a program's memory usage and monitor its memory pressure. And if you only
have so much memory available on your computer and your program is using, say, 95% of it,
then the garbage collector will go in and look for any stale references to data that you're not
using anymore, that the program isn't using anymore. And then it just deletes those references,
though I may be butchering now, but I think that's the gist of it. And I would expect that
evolution would have stumbled upon something like that much earlier, because it seems to mean that
any organism that can store additional information during its lifetime would eventually run into
memory pressure issues. And so evolution must have evolved. There must have been a solution
to this problem. Also, these increases in memory that I think are needed for those self-replicating
ideas, they would have happened very gradually. So I'm not suggesting that once self-replicating
ideas came on the scene within minds that suddenly brains had plenty of extra storage,
certainly possible that initially there wasn't all that much extra memory to go around,
and but maybe just enough to help that adaptation spread. And then there was selection pressure,
biological selection pressure to increase memory in humans brains if that adaptation was helpful
enough. And by some accounts, there was a large and relatively sudden increase
in memory in our evolutionary history. And I've heard theories that attribute that to a change
in diet or upright posture or opposable thumbs and all that stuff, but it could also be possible
that that increase in memory in our brains was caused by the selection pressure I've just described.
And lastly, for this particular point, the claim that replication is wasteful or redundant
in the sense of being unnecessary. Although this criticism is not meant as a creationist
standpoint, but it reminds me a bit of what a creationist might say about replication and
biological evolution. A creationist might think that genes carrying the same knowledge millions
of times over in each organism is unnecessary. To them, it might seem much more parsimonious
and efficient to simply say that a single entity, God, for example, contains a single copy of all
the knowledge that's required to create each organism. And then each organism is just the
result of him doing that. Okay, then another criticism that Ella has offered is the self
replicating ideas. They sound dangerous. They could have led to all sorts of dangerous behavior in
our ancestors. And so biological evolution would have selected against them. I don't think this
is true either. I think animals around us are evidence that they contain sophisticated knowledge
with enough reach to use a German term to guard against unwanted behavior. For example, being
stuck in an endless loop or something, I've tried this, even a well behaved dog won't repeat a trick
forever when instructed to it'll only do it so many times, it just stops at some point. So
there seem to be built in criteria that can override erroneous behavior. So it seems to me
that biological evolution has already has built in safeguards. So self replicating ideas wouldn't
automatically have led to ever repeating behaviors or something that would, you know,
certainly cause death for the organism. I think actually the opposite is the case.
Self replicating ideas were then and are beneficial and they help the gene spread that code for them.
Excuse me. Because whenever there was a detrimental genetic mutation present in an organism
that led to a bad mutation in one of those organisms ideas, it was thanks to those self
replicating ideas that there was an opportunity that broken functionality with working functionality.
And because detrimental mutations are much more numerous than beneficial ones,
that actually means that the existence of self replicating ideas was favored by biological
evolution up to a rate at which detrimental mutations occur. So I think there would have been
strong selective pressure and favor of self replicating ideas in mind because it would have
helped the gene spread. And then Ella has offered another approach that one could
implement the same algorithms say the same self replicating idea pool without replication.
And the idea is basically just have a single instance of each idea and a score or weight
that you attribute to each and then increasing and decreasing the weight as you go. And David
George recently independently suggested this criticism as well. Now it seems to me that
denotationally that sounds similar to my theory. And I think Ella in particular is has in mind,
although she's here, she should correct me on this, but I think Ella in particular has in mind
what's his name, Donald Campbell's work on evolution that you don't really need replication
so the argument goes, you just need variation and selection. Imperfect replication can be the
source of variation, but it need not be. Now, I've said in the past and I'm still
the opinion that I'm agnostic as to the question of necessity. But if we were to make this change,
I think it would come at some costs. The one thing that I think the
New Darwinian approach that the approach that does adopt replication
brings to the table is that we can explain how people evolved. I'm not sure how we would do that
because it allows us to explain with a very simple accidental small mutation. I'm not sure
this algorithm that would store and decrease weights, we would have to explain how that one
came about that seems to require a different explanation that I'm not aware I'm not familiar
with. And then the question is when does it decide to mutate an idea and why and how
and at which location in the idea source code. It also seems to me that such an algorithm would
make plant mutations, but in real evolution mutations are not planned. So what I like about the,
what I like about my approach is that none of these questions need to be answered in explicit
programming. These are all just things that automatically fall out of having self-replicating
ideas. So in a way actually structurally speaking, maybe it's the pool of self-replicating ideas
that's more parsimonious because you don't need to explicitly program any of these other things.
And if the goal of that approach is to, if the goal of that approach is to get rid of replication
because it might be wasteful or redundant or whatever, then the thing is like let's say you'd
have one instance of an idea and you'd have a weight associated to it. And let's say at some
point this master algorithm decides to make a copy of it and mutated. And so at that point you would
store a second entry and over time you would get more and more entries and some registry of ideas
or whatever. And I think then you would still get source code that is shared among many of these
entries. And so it's a little bit similar to what Dawkins has pointed out with in regard to
the cisterns and the DNA versus the genes which he defines separately. The cisterns or maybe
butchering the term but I think that's what is called the cisterns are like the actual section
in the genome that code for eye color say. Whereas the gene he defines as the longest possible stretch
of the genome that gets replicated over and over without changes. You'd get a very similar
phenomenon in this registry of ideas where you'd have sections of those ideas that stay the same.
Across those those entries and then that would be the replicator. So although the idea set out to
get rid of replication I'm not sure it actually does. And I think what's nice about adopting
replication is that it gives us consistency with other evolutionary phenomena that we know exist
and we know our power by replication that's biological evolution and meme evolution.
And I think that consistency is valuable because it means that we can share knowledge between these
different disciplines. So I like to think that this need our approach has a unifying character
and I think that's worth keeping. And we couldn't excuse me we couldn't investigate
the static and dynamic replication strategies in the mind anymore without replication.
Those really are replication strategies and they don't work without replication.
And then the last criticism that I'm familiar with that Ella has offered is that
it's unclear how the mind creates and discovers problems and contradictions.
And that's the driving force of creativity. So that's a really important thing to answer. And I
agree with that. So I want to clarify my current idea is that when there are populations of ideas
that are competing in a mind especially when they compete fiercely over resources memory for example
then that leads to cognitive dissonance that the cognitive dissonance that we experience when we
experience a problem. And depending on the nature or the fierceness of the competition that we may
a problem may seem interesting or annoying or downright depressing like I said depending on
the nature of the competition. And then when we solve such a conflict it could mean for example
that there's a third population of ideas that has evolved and operates as a sort of mediator
enabling the two conflicting populations to coexist peacefully or it could fight and win
against both populations and largely replace them. I think that's what might be happening when
you have one theory that supersedes and explains two conflicting ones which then live on in the
new theory as approximations. Or it could just enable one of the two to win over the other.
And then recently David Deutsch suggested that we need not mimic how biological evolution
created creativity the same way that we need that planes don't need to mimic birds to fly.
And I agree with that. I just I don't know of any other way yet.
And yeah and I forget if I mentioned it but he also just like just like Ella Hepner suggested
that replication would be inefficient that it wouldn't be necessarily the approach that a programmer
would take. So all these criticisms would be very helpful and have motivated me to think more about
this idea. But what strikes me is that I think none of these are conclusive criticisms and this
brings me to something that that many of them have in common. I think they're along the lines of
they say something like self replicating ideas are not necessary to explain the mind.
And like I said I agree with that. In fact I'm pretty certain that my that my approach is wrong.
What I'd like to find out is why. And I think the a an avenue that I would find more more productive
is what what is an explanation for why self replicating ideas cannot be part of the mind.
Not why they need not. And like a real refutation of the idea would be extremely helpful.
That also brings me to what could change my mind about this this approach. That is one of them just
just an explanation of why it cannot involve self replicating ideas. And then also an internal
contradiction or something like that I'm unable to fix. At least that would that would definitely
constitute a big problem that I would need to solve. I should point out that the idea that
self replication for example would have hurt the genes encoding that
it would have hurt genes in biological evolution. I think that was a candidate for why creativity
cannot involve several self replicating ideas. So I think something like that would be promising.
And then lastly some outstanding problems. There are still big unknowns left.
Like I said consciousness is the big one. Something that I've been thinking about recently is that
when you the the approach kind of goes along the lines of well as long as you have self replicating
ideas you kind of get variation automatically eventually because the mind is messy and therefore
you also get selection automatically because different variants spread with different at
different rates. But if you actually write a self replicating computer program they're also called
a quine. They don't ever mutate. You can run them a billion times in a row. They don't mutate and
unless you force them to but then mutations are planned. So that tells me that the self
replicating programs that people have written are too good at replication for evolution to occur.
And then there's the problem with evolutionary algorithms generally that David Dorch has written
about in the beginning infinity which is that as a programmer you can't really tell if the
knowledge that you find in the program after running it is knowledge that the program created
itself or if that is knowledge that you as a programmer just happen to put into it without
realizing it. You leak that knowledge into the program and so you can't really judge whether
the program is creative. You'd need to know to make that call. So we need to find a solution for
that before even trying to implement this theory. And yeah so that is the approach and I'd be ready
to take questions if there are any. Great thanks so much for the talk. Yeah so we have about 45
minutes of questions and I think what we'll do is Dennis if you could first close the presentation
because I think it's nice to go back to and then I will open with a question and then anyone who
wants to ask a question can do so afterwards either by raising your hand as I see David has done
or by typing in the chat. Yeah so the first question I had was I really like the idea set out
and I like especially explanation of memory and this idea that memories are replicators and the
memories that you retain other ones that have replicated best. But memory in my computer is
just accessible like the files in my computer don't replicate. If I require an old file I get an
exact copy of that file and I just retrieve it as it was when I first stored it. Why do you think
that mines store memories differently? Why do you think that they will have to replicate?
Yes I think it's sort of a quirk maybe of the English language that we use the term memory to
refer to both of these phenomena even though I think they describe different things.
Memory in the second sense in the sense that your computer uses
actually our brains have too because they need to store data in that sense and that
is just the plain old memory storage that you've described and nothing changes like if I
start very rarely because our hard drives are very reliable. So yeah if you store a file on
your computer it just stays there and it doesn't replicate. So this is I think that is like a lower
level kind of memory phenomenon like the direct interaction with the hardware for how to store
information. The kind of memory in the sense of remembering things
I think it's just a different phenomenon so and that that is the phenomenon that involves
the self-replicating ideas so I would just distinguish between the two. Very nice.
Okay thanks for your answer then I see that David has a raised hand Dave go ahead and ask
your question. Hi well I too found that very persuasive and I also liked the way that it kind
of explains features of the would otherwise perhaps seem accidental features of the human mind and
memory as well. I just I can't quite see the overall picture though so in RNA world there were
as it were genes but no organisms and in the brain in your picture I think there's also
genes but no organisms is that right first of all? Yes that is right I've wondered if maybe
sometimes ideas as they get more complex as they replicate in the mind if they stumble upon
a replication strategy something like the genes stumbled upon when they invented organisms.
Well yeah well so the thing is that if you imagine a huge soup of RNA then it doesn't
have an outside world that is the only outside world it interacts with is other RNA molecules.
Things started happening in RNA world to make to make more sophisticated replicators
when RNA started manipulating things that aren't RNA
and started for example making enzymes making proteins and so on so like I would guess that
there's only so far you can get by twisting RNA into different shapes and trying to get them
to produce more of those but at some point they invented enzymes and then you know from then on
there's phenotypes there's organisms I'm not asking how you explain the origin of species
you know why a bunch of DNA just moves along through the world together it's not that it's
it's the it's it's the when it gets to encounter the non RNA world and I think most selection
in the biosphere and most selection in the brain I'm guessing is caused by problems to do with the
non to do with the outside world it's the outside world that causes things in the inner world to
come into conflict right okay so you know I'm just kind of asking or asking for comment or whatever
I mean I don't have any objection to the idea I think it's a great idea and you know please pursue it
great um no you know I think that is a really helpful pointer that is I don't have an answer
off the bat for you for that um I think that's something I'd very much like to explore so I'll
I'll keep thinking about it okay can't ask for more
oh um then Timothy do you have a raise hand
yeah hi Dennis thanks for the talk I really enjoyed it hi I think um I think one term that I'm
sort of stumbling over in this framework is accidental how do you think about our sort of
effectiveness at problem solving or the kind of deliberateness of it in terms of this accidental
idea creation um do I understand correctly that you're trying to to square the the purposeful
thinking or the at least the purposeful the feeling that we get that we're purposefully
solving a problem say with the notion that ideas mutate accidentally am I understanding that right
yeah I mean not just the feeling the fact that we actually approach problems and solve them
right um yeah um
I do I I've thought about this too and I think it's a really interesting thing to explore the
um I think those things can be squared um and it I think the way we introspect and look at
the way we solve problems is often deceptive and this has led to ideas such as induction for
example where people even though they could not have induced from experience that's what they
thought they did um so people can be mistaken about what they what they're doing when they solve
problems um and the thing that ideas happen to morph into a new conjecture that that solves a
problem say um I think isn't really at odds with purposeful problem solving um we we purpose we
want to solve problems that means we have ideas that we would like when there's a conflict we
would like to solve it and that idea exists even before we encounter a solution to a problem but
the the solution to the problem itself we can't really move toward an targeted fashion because
we don't know it what it might be it's unknowable in advance we only know it once we've evolved it
and at that point we just kind of happen to know it um I think that's just true of evolution
generally is whether it's the the gene or the self-replicating idea in a mind um there's only I
think popper called them happy accidents there's only happy accidents or sometimes not so happy ones
uh that's I think all we have we we can't think of a solution before we
before that idea mutates it mutates into one does that make sense I'm not sure that I that
I really put my finger on your on your question
I am not hearing the participants sorry sorry that that that does make sense um I'm not yeah I'm
not sure if it it quite um feels the gap for me but um yeah I'm not sure of a better way of framing
it but thanks for the thanks for your response okay sure okay uh then I see you have two more raised
hands uh I don't know who was first I think I'll go with uh Parik I I think I'm just pronouncing
you name it so so go ahead that's all yeah that's uh Parik uh thanks a million uh really enjoyed the
talk Dennis thanks a lot for it and so yeah my question was uh sort of related to the last
question a little bit uh but you remarked I think about halfway through to talk about there may be
because ideas will self-replicate there will be these junk ideas which are analogous in some ways
to to junk DNA so I guess my question is about the self-replication um
so it would in this model is the replication a matter of degree so that the the idea which
isn't the junk idea which presumably is the one that we're we're then conscious of um
you know you know because you you're mentioning that uh we we there's a lot that we're we're
unconscious of and those would be the uh the sort of the ridiculous answer is let's say to a problem
or the ones that we that don't get uh promoted into our awareness um but the ones we are aware of
would those be more active replicators in in in this way or or they're um
so yeah I guess it's sort of a two-part question one is like is the replication a matter of degree
and secondly uh are the the ones we become conscious of the sort of better at causing their
their copying yeah I'll I'll try to answer the second one first um they I think being better
at copying oneself is one way to just retain the the faithfulness and the the coherence of an idea
for sure so that if if that idea wants and scare quotes to be to be thought of again
one a good way to do that is to make sure that one retains one's faithfulness
I could see that um now with regard to whether that makes it a more active replicator I don't
know I could certainly imagine that there are ideas with different replication rates
um one might replicate twice as often as the other um and if it can make up for for you know
the mutations that might be introduced during the the double replication then it's fine um
so I guess it just depends on how reliable the replicator it is or it is not very reliable but
thanks to those mutations it creates a new idea and then that new idea is coherent enough that
you become aware of it so that could also be the case so um I'm not sure that we could tie it to
the activity of a replicator per se um with regard to your your first question I'm not
sure what you mean by degree of replication uh yeah I guess just to clarify it a little bit so
you know some um so to to bring it back to the analogy that within genes there will be
like the junk DNA is a replicator of sorts although it's it's not usually referred to
as a replicator because it's it's not uh you know it would contribute within its environment it
contributes to its copying more than you know a whole lot of other physical objects and both
it's you know it's it's for some it's maybe not worth calling a replicator because it does so
far less well than than the ones we call replicators so I was just wondering if that's the same sort
of implication that was being drawn between the analogy of junk ideas and the junk DNA that they
are sort of they're still self replicating but they're they're less uh let's go ahead I got you
yeah no I think I think absolutely that could happen yeah you get you could through an through
mutation you could get a junk idea that's it's junk in the sense that it doesn't result in a
coherent idea anymore but it's still kind of manages to get itself replicated every now and then
that could happen or sometimes the mutation might be so detrimental that it's just it dies
immediately yeah thanks uh then I see Danny has a raised hands Danny go ahead
hi Dennis um I really enjoyed the talk as well um and one of the things that I really like about
this theory which is something that I've wondered about myself in the past is the fact that
poppers notion where we conjecture ideas I've always wondered why the ideas that appear in
our conscious mind seem to be non-random you know so they you know to take your example about the
keys you know some silly idea about your keys being somewhere that you've never been before that idea
doesn't appear in your mind so I suppose my question would be do you have any conjectures around
what is happening in the mind in that moment when an idea when that first idea appears in your
conscious mind do you like so what is happening when your mind quote unquote like selects one idea
to present to you consciously have you have you thought about that at all yeah I have and
one idea that I've just played with um is that maybe what's happening is that
in the pocket of the population of ideas that's relevant to this problem
um maybe the idea that you've left your keys on a kitchen counter
is just very good at spreading through this pocket and it outnumbers rivals and that's why it gains
a foothold in that niche and maybe that is why you become aware of it this is just a
you know purely conjectural I'm making stuff up kind of thing but um that's an idea I've played with
so it's so more broadly than it's you think it might be possible that um the distinction between
you know the ideas in the conscious mind and the ideas in the unconscious mind
has something to do with we'll say the number of of replicas of an idea or or am I maybe stretching
stretching what you just said as well well I think it may have to do with that and um it
it may have to do with one idea outnumbering or overwhelming um or one population of that idea
like one set of replicas of that idea outnumbering another competing set and that's why you don't
think of the other set I think that is one one thing and then as I've mentioned there's the
thing about ideas competing fiercely and that constituting a problem that is also something
that become aware I would imagine that there are ideas competing all the time countless ideas
competing all the time in our minds but the competition is so small and you know the conflict
is so small that you don't you don't realize it but because the the key in the key example of the
missing key it must mean that just by virtue of you thinking and recognizing it as a problem
it could mean that there were two populations of ideas encoding conflicting preferences say one
I want to leave um that is my preference conflicting with the idea that I can't find my
key so I can't leave and this this conflict is both on both sides the ideas are numerous enough
that the conflict conflict is noticeable that you I mean it's a bit circular because I'm trying to
explain what we notice in terms of what is noticeable but I'm suggesting that that is what
makes it noticeable uh if that makes I hope that makes sense yeah yeah I know it does thank you thank
you okay I don't see other raised hands so I will ask another question and it has to do with
uh these higher level concepts so we we also like you you draw this picture of single ideas
evolving in a mind and and partly you say that for example we experience suffering as a as a
consequence of competition between ideas and I think what I'm wondering is like where does the
sense of self come in and where does uh this is kind of related to the question of where does
conscious problem solving come in and uh just truly I mean I can imagine there would be such
an explanation of consciousness or maybe that's asking too much but where where do these seemingly
higher level uh entities come in the sense of self a sense of direction sense of purpose
um and yeah it's kind of a vague question that is pointing at something I hope it's enough
no no it's a great question um yeah I'm afraid it really is the big one I don't have any any
good answers for you I mean I have thought that there that there is a sort of meta algorithm in
the mind that that we've inherited from from our ancestors that used to just be responsible for
interrupting you know bad loops or stuff like that but um and maybe that is because it looks over
the pool of replicating ideas that maybe that is why we have this we at least that's how we feel
that we have this bird's eye view of our ideas but I don't know I would really like to know
yeah same but it's yeah as I said it's maybe too big of a question
um I see there's more race hands now uh and I think Antonio was first so Antonio if you
want to ask a question go ahead that's right thank you um so I don't want to get into a
play of definitions but what do you mean when you say an idea and do you differentiate between the
explicit content or the inexplicit content do you think it matters at all how they are
instantiated in the brain what would be like the goal of an idea why wouldn't it want to exist
in your brain in the first place because yeah unless you actually define what you mean by idea
having self-replicating ideas doesn't say much about what's going on so the the what's
throughout to me is when you said that why would an idea want to be in a in a mind I don't think it
does um this the same way that there's no gene that wants to be in the biosphere it just kind of
finds itself there and because it's a replicator it makes ever more of itself um there there's
nothing um you know the on the level of the replicator there's there is no consciousness or
purposeful purposefulness so um now when it comes to what like how what do these ideas actually
look like how are they implemented um I have given this some thought now at the risk of
getting too technical I think of ideas the way they're stored in the brain when it comes to source
code as functions in the sense of the lambda calculus and I do think there are important
parallels between or not just parallels I actually think they're the same between the
functions in the sense of the lambda calculus and explanations and so I use the term idea just for
those functions um before just those functions I should say um so that would be my technical
answer to how our ideas implemented in the mind um if that helps okay if you imagine a brain
a human brain okay human baby raised without language okay in 2021 now you can raise a human
being without say speaking to it to him or her whatever um do you think that it will contain
knowledge will it only contain like inexplicit knowledge but it will be able to move around
to hand to eat to feed to interact with other human beings purely on an inexplicit level
yeah um I think so I think I mean our ancestors at some point were in that stage right before the
invention of language presumably they had the same brain the same genes yeah um no I do think
that language comes after um you have creativity and that's what allows you to learn language it's
not the other way around um so yeah I think there's plenty of things that that people can learn
even without language and and the inexplicit ideas will do and with the mechanism of how they
learn all these inexplicit ideas be different to how they learn explicit ideas um I don't think so
I think the the method and scare quotes of conjecture and criticism is universal um
I mean yeah I think it worked the same for for explicit ideas as for an explicit ideas
and wouldn't it be more easy if the mechanism is the same to try to explain
how we learn inexplicit ideas before jumping to the explicit ones and having all these extra
dimensions of language of science all these meta levels um I would agree yeah okay I'll
pause here maybe we can thank you bye yeah go ahead Dan okay hi hi Dennis I missed the beginning
of your talk but I think this is a really important line of inquiry and um I applaud you for exploring
us um I I feel like the area which needs to be fleshed out more is the selection mechanism and
I wanted to mention that there is an existing theory called neural Darwinism but seems to be
that theory is more in the to explain perception rather than the formation of ideas um and in
neural Darwinism the idea is you have you have basically a bunch of when and when in a newborn
brain it's known like you have tons of random connections and then there's sort of a pruning
process and the idea of neural Darwinism is the different groups of neurons are selected by how
faithfully they replicate the the incoming sensory data streams um with your with your theory
you you were talking about more of an internal process right so I was thinking
wouldn't you wouldn't you need some kind of like world simulator to to to test different ideas
to see if it makes sense and like have you thought about how there might be like a world simulator
and then um basically so for example with the missing keys example which is which is really
interesting one example um different parts of your brain would would be simulating different
scenarios and and sort of seeing if they uh if if if the idea if if the simulation
maps onto the idea like like you'd have different ideas
like you'd have an idea of the keys or location x and then you'd run a simulation based on the
all the information you know and you see if it uh confirms that idea have you thought about anything
like that um well just to give a general answer um the as I as I said earlier I like to just
leave sense data out of it completely I mean I do think that um sense data is important
to to test your theories um but uh so to make progress sense data is important in that sense
but I don't think sense data is required for for creativity to work or for any of the evolution
that occurs in the mind to work um and I mean you could you could simply ask you know if somebody
is born and I don't want to put words in his mind I think David does this in the beginning of
infinity and if somebody is born blind they're not any less creative I mean they might they're
still people they're fully qualified people right so um they might have a harder time correcting
some errors because they don't have access to sense data from the eyes but then they might
creatively find other ways to to correct those errors um but what I like I said what I like to
do is just leave sense data out of it completely just to avoid any empiricist pitfalls um and I
also like to leave the brain out of it completely I like to think only in terms of the mind um
just to avoid any any accidental reductionist mistakes um so I so I you know the thing about
neuronal structure is self replicating I don't know uh I would right I was more just mentioning
that for the audiences say uh benefit not not I'm not saying that you should go in that direction
I actually think the direction you're going which is more at the higher higher level um extracting
away from the uh from the um the neural circuitry is is is very it's very interesting um
um as I guess my my question was really about the selection mechanism I could could you elaborate
more because so far on the selection mechanism because so far you I mean at least for the part
I heard you just mentioned uh you know some will be better at replicating than others but
um what is the selection how is how does selection occur is it context dependent
or is there some how is that how does that work yeah so again barring Dawkins um definition of
selection that is it's the non-random differential reproduction of a replicator in a pool of replicators
um that is how I would describe the selection effect or the selection mechanism in the pool
of self replicating ideas in the mind as well it's just the fact that once a mutation arises
if the mutation either helps or harms the the new copies ability to spread now you have differences
in the rate of replication and that itself constitutes selection in addition to that um
the this meta algorithm which by the way it caught myself not crediting the uh this the idea of the
meta algorithm originated with a temple in a different context but the the meta algorithm could
also um have you know act as a sort of arbiter of ideas or select or arbiter is new normal but
impose additional selection pressures on the idea pool um now how in detail that would work I think
is depends on what happens at runtime um because it might it might um look at some ideas for what
to do and what selection pressures to enact on the idea pool itself so there's some kind of
feedback loop there but the details of it the kinks I think need to be worked out there
okay then we have two questions in the chat by Taha the first one is in the case of genes
RNA DNA we know what the replication unit is made of a sequence of nucleotides
what constitutes the replication unit of an idea yes this is a great question um
I would uh I would follow Dawkins here who who says well you know on the one hand we have the
the physical instance of the replicator um which is the molecular structure itself um
but um so actually the terminology I use is that that I would call an instance of a replicator
a physical instance of that replicator and oh maybe I'm jumbling biological terms but I would
consider even that um physical instance of that string of molecules itself part of that
replicator's phenotype which may sound a bit confusing until you realize that the replicator
itself is actually an abstraction um the replicator is not physical it has physical
instant physical instantiations but the replicator is an abstraction because as Dawkins explains
the replicator is that part of this the string of DNA that manages to stay the same over many
many generations first you know for as long as possible and so this is just a chain of instances
and that of course that chain physically exists but it also exists over time and so
some of the older chains some of the older part of the chain would already be gone
at that point and still we would consider all that part of the same replicator so
it's abstract those are independent of the the physical instantiation um but
so the the unit of rep the unit of replication in that sense we could ask the same question
also when it comes to memes um in the mind I think are are again these the uh again at the
risk of sounding too technical the the functions in the sense of the lambda calculus these little
programs just think of them as programs really um those are the ones that replicate and of course
they're going to have a physical instantiation in the physical memory now again in the sense of
storing stuff not in the sense of remembering stuff in the brain um I think Dawkins even went
so far as to say one time that you know he proposed this conjecture that maybe we if if you have a
joke in your mind and I have a joke in my or in your brain I have a joke in my brain that maybe
that means that the neuronal structures in coding that joke are the same so maybe meme replication
implies uh replication of neuronal structures across brains or something um actually I think
I'm getting ahead of myself here um so the replication unit of an idea is the function
in the sense of the lambda calculus hope that helps yes I think that makes sense just
get a clear picture for myself do you mean that uh there is there is something that
you and I have in common when we have the same idea in in our minds so that we have a similarity
when we have the same joke then whatever is encoding that joke in our uh in our brains
has to be uh it's fundamentally the same thing like it is it is encoding the same abstraction
as you would say and it might do so differently it might use a different encoding but it is
they're both encoding the same abstractions in that sense yeah provided that enough error
correction has gone into it the the I agree the abstraction that that encodes the idea in your
mind should be roughly at least similar to to the encoding in my mind yes right okay and then
there's a second question uh also from Taha uh which goes knowing that the sequence of a gene
allows us to target it with a strip of DNA how can we do the same and target this is a specific idea
yeah um that's also a really great question uh well if you maybe we can go back to the the
thought experiment I suggested earlier with the with the brain interface that allows you to connect
to someone's brain and you know read the source code I don't know how exactly you would do that
but if you somehow manage to and I think that process itself would involve
conjecture and refutation so the brain interface may need to be a person but
if somehow you manage to do that and you you can turn the zeros and ones in the brain somehow back
into functions you know represent the mass functions in the sense of the lambda calculus
then what you could do is you at any point in that source code you could make modifications or
split it or put something new in there um all that stuff would be available to you
seems to be a challenge to to make that happen that that interface great um then yeah we were
almost through the 45 minutes and I don't see any further questions uh unless someone has them
now in which case please please go ahead and ask uh uh oh yeah go ahead yeah if you don't mind
me asking a second one that's okay so I was just wondering about like uh so do you think uh a
conflict or problems are a necessary precondition for a conjecture or uh because I was thinking about
like in order for us to um identify a problem would we first need to conjecture that a problem
exists so in other words there's like let's take a simplistic probably unrealistically
simplistic case there's two conflicting ideas and and uh we're we're conjecturing solutions
to that problem do we need to conjecture that there is a problem and then like just as a related
idea uh in order to conjecture anything in order for any new variation of an idea to to come about
does that kind of conflict need to need to exist if that makes sense um I think the answer is no
for because new ideas will just evolve by virtue of replication being imperfect over time
um but when there is a conflict between ideas um that certainly helps and I would imagine
that at least that is the main thing like I said that we're consciously aware of when we do
come up with a new conjecture is it is because it is in response to a problem so I still think
that problems are the raw material of creativity so far um but strictly speaking no conjectures
could arise just by virtue of a been perfect replication okay okay thanks okay uh any other
questions uh Antonio go ahead thank you um do you think there's a difference between
the perception of a problem so this conflict between ideas and sensory perception in general
um could you elaborate a little more yeah do you think there is I mean when you realize
that there is a conflict between two ideas isn't this something you perceive via your senses
is there is it a different physical structure say from vision or from looking at the screen or
recognizing a bicycle when you recognize there is a problem between two ideas do you think it's a
different object in a way than recognizing a physical object around you um I think those are
different things um when we experience a problem experience yeah right when we experience a problem
I mean maybe I use the term experience differently but this the sensation we have
sensations also tricky term because it has sense but the the sensation we have when we experience
a problem with cognitive dissonance need not result from sense data it certainly can happen
that you're you know with an optical illusion for example you think you're looking at one thing
but it's actually another and you can change if you change your perspective if you see and then
you experience that problem that's a problem you want to solve but the experience of the problem
itself as all experience I think is entirely within that is not something that is induced
somehow by by sensory data and again if I agree I agree but they're both inside both when you
perceive a bicycle on the road and when you perceive a problem in your mind both of them
are inside you that's what I'm saying is there a difference um yes I think there's still a
difference when you just look at a bicycle and say you have you know I imagine that children
learn this when they're very young they they creatively conjecture um recognition algorithms
like shape recognition algorithms so that later they can recognize bicycles that stuff just
happens automatically once you see it once you've created that algorithm you just recognize bicycles
unless you're horribly deformed or something um whereas when you have a problem there's something
unknown there there's something mysterious there so I I still think those are qualitatively
different experiences if that if maybe if that's where you're getting at it I don't know if I'm
answering the question okay well I don't think there is a difference but uh yeah can you elaborate
what what is it you think that is the same about it I mean at some point to a child
seeing a bicycle was a mystery in the same way that when you think about supernovae or whatever
it's a mystery for you right and there is no automatic thing going on I mean if at some point
uh because if you're never exposed to bicycle then you can be as old as you want but at some point
you will be mystified by this new object so I see yeah no I think you're right that went for the
for the first time you see a bicycle that is a mystery you know what is that thing how does it
work and how would I recognize it again at like that first time you're confronted with a problem
and you want to solve that problem and in response to it you learn about the bicycle and you come up
with a shape recognition algorithm for the bicycle and so forth but once you have that
now it's automatic now you can just recognize bicycles again if I look at the window and I
see a bicycle that doesn't constitute a problem so I would I would still consider those two different
things well fair enough yeah I think aren't they just the same thing only one is subjected to
empirical criticism and the other is just an internal idea I'm maybe well yeah I mean your
internal ideas aren't they criticism how do you experience how do you think don't you visualize
your objections to something why do we need to distinguish between these two worlds
it's the same distinction as between science and philosophy I think and it's not really a distinction
it's just a matter of where the criticisms come from and useful in some cases but this is not a
fundamental distinction I think I'm not sure if Dennis agrees with that but this is how I
would understand that I do although I still have the the feeling that I can't quite put my
finger on on uh what's your name Antonio's question so I feel that I haven't really answered it
satisfactorily um yeah well maybe uh topic for future discussion I'm afraid we've we've run out
of time though and uh yeah I just want to thank Dennis for his great talk I will I'll do so as
usual with uh appalling in the mochi mochi there you go and that was a lot of fun uh it was great
to be here yeah yeah thanks so much for coming and and again um I encourage everyone to check out
your article on the conjecture magazine websites which we'll link to in the description of the video
and uh and yeah so thank you for Logan for uh helping Rangers thank you and good luck yeah
thank you okay goodbye thank you everybody
you
