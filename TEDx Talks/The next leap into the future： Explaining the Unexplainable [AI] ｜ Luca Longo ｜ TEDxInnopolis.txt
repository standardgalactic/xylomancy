Artificial intelligence, how many times have we heard this?
We wake up in the morning, we drink our coffee, we read newspaper, and there is something
about it.
We watch the television and we hear something talking about the latest technological progress.
We drive in the car, we listen to the radio, and there is someone talking about artificial
intelligence.
How many times have we heard their robot will take over?
How can we trust a robot?
A robot will take our job.
You think I'm going to do another class on artificial intelligence today.
Forget about it.
Today we're going to talk about self-serve coffee machine.
How many of you have taken one of this coffee?
Everybody.
Well, me too.
How many of you can build a self-serve coffee machine from scratch?
Nobody.
Me neither.
But we consume the coffee.
We trust that machine.
How we trust this machine?
For sure we are not going to open the machine or read the electrical scheme of the machine.
We are not going to read the software code of the machine.
We trust the machine because of the coffee we take, we consume, we drink our coffee,
and we like it.
We trust the machine.
You might wonder why I'm here in Annapolis listening to Luca talking about self-serve
coffee machine.
Because artificial intelligence today is exactly like this self-serve machine.
We use all the time.
We trust what it does for us.
But we use all the time.
We go in the airport.
We put our passport on the screen reader.
The gate opens.
We go through.
We play Rizzico.
We play Monopoly with our friends while we have dinner.
Alexa, play Bohemia Rhapsody of Queen.
And it's our play.
We have a job interview.
We don't know where to go.
We put Google Maps.
Google Maps tell take this street, left, right.
We arrive at destination.
We use every day artificial intelligence.
We don't know how it works, but we trust what it does for us.
But it's not always good as it seems.
A few years ago, I had a friend.
He wanted to buy a nice car.
He was saving every month some money.
But he realized it would have taken many years to save the money to buy the car.
He was a nerd.
He was an engineer.
He was always the first of the class.
He was a high skilled individual.
So he started building a software.
He started building a predictive model.
And he started investing in his own favorite cryptocurrencies, Bitcoin.
So he built this model.
He started using this model.
This model was telling him, A, tomorrow open a position.
Bitcoin is going up.
For close disposition, Bitcoin is going down.
For a few months, he started making money.
He trust his own model.
Everything was working perfectly.
But all of a sudden, on a rainy day, things start changing.
And he started losing money.
Bitcoin was dropping.
And he was not able to understand why.
He built something.
He was a very skilled engineer.
And he was not even able to understand his own artificial intelligence.
Imagine you are the owner of a bookstore.
And you have thousands of books on display.
You are the owner.
And you want to maximize revenue.
So you hire a consultant.
This consultant is an expert in machine learning, in computer vision specifically.
And he installed a lot of cameras on your shop.
Every camera pointing to a specific area of the bookstore.
And basically, he created a model that employs computer vision and performs facial recognition
of expression.
So you recognize if a customer is happy, is engaged, is sad, is disengaged.
So the model can say, A, in this area of the shop, all the people are engaged.
In this area of the shop, all the people are disengaged.
So the owner can have a suggestion on where to put books.
But for a few months, again, he started making money.
He started selling books.
Everything was going okay.
But all of a sudden, the revenue started dropping.
He called the consultant, the consultant answered, A, I have some problem here.
I keep taking the decision according to the model.
But my revenue is going down.
And the consultant says, A, listen, I don't know.
Is the model that is telling me what to do, is everything is automatic?
I don't know.
So imagine the frustration of the owner.
He's so frustrated that he say, I don't want to play with artificial intelligence anymore.
I fire you.
A few years ago, I had a friend.
One night, he started shaking.
And he lost control of half of his body.
He thought he had an ictus.
He was sleeping with the wife.
And he started losing vision from one eyes.
He couldn't see anymore from one eyes.
He was very reactive.
And he called the wife and said, Please, bring me to the hospital.
Everything is going on.
So they go straight to the hospital.
The doctor understood something was wrong.
And he performed a scan of the brain.
And there was something as big as a grain, mice grain, that he was in his brain.
And the doctor said, A, I'm sorry.
But you have a tumor.
You have a malignant tumor.
You have just a few months of life.
What you can imagine, my friend, he was destroyed psychologically.
He didn't know what to do.
He didn't know how to react.
He was destroyed.
So the doctors start giving him cortisone.
And he was performing over time these brain scans to see if something is happening.
And strangely, every day, something good was happening.
He started seeing again from the left eyes, he started getting control of his half part
of the body.
Well, he was getting happy.
But the doctor didn't know what's going on.
He was trusting the machine who took those pictures.
He was interpreting.
There is a tumor.
And he still didn't know what to do, what to say.
So the doctor couldn't trust the machine, couldn't trust artificial intelligence anymore.
So what is the moral of this?
Should we really trust artificial intelligence?
We cannot stop technological progress.
It doesn't make sense.
We cannot stop to build intelligence machines.
It doesn't make sense.
But we can challenge the prediction, the assessment, the inference of these black box machines.
And above all, we have the right to understand how they work.
And we have the right to get explanation on the recommendation of the machine.
So what is the solution of these black box artificial intelligence?
Nowadays, in artificial intelligence, there is a sub-discipline that is called explainable
artificial intelligence.
And this is getting at the forefront of artificial intelligence in our society, everywhere in
the world.
So remember my friends who wanted to get some money for his car?
Now let's assume that this black box model is saying, A, there's going to be an increment
in price of 5%.
But it doesn't know.
Why?
Imagine now that the artificial intelligence that tells, A, there is a 5% increase, add
something more.
For example, he had a statement like this.
The number of buying orders has significantly increased at current prices.
Therefore, investors are willing to enter the market now.
Or in the last month, Bitcoin has dropped by 20%.
Every time it happens, it's strongly rebounded.
Therefore, we have high chances of a positive price increase.
Again, with current trading volumes, there are high chances of a big price move.
As you can see now, we have a prediction from the machine, which is plus 5%, but we have
a set of explanation.
This is in artificial intelligence are called propositional rules.
And you can understand that with this type of information, we can actually inform our
decision making.
Now let's go back to the bookstore.
You were losing money, but the model was saying, A, all the people in the shop are
happy.
But still, you are making money.
You are losing money.
Sorry.
Imagine you have something like this now.
You have a dashboard of visual analytics.
So now you know the number of people that enter your shop during the day.
So we have in the morning, lunchtime, evening.
As you can see, most of the day, people were happy.
But during lunchtime, there were so many people in your bookstore that even if you put the
books in the right order and organize the book properly, there are so many people that
their experience is negative.
And now with this visual analytics, we have a better understanding of why and what's going
on.
And again, with this type of information, we can better inform our decision making.
Now let's go back to my friend.
He was diagnosed a tumor.
I don't know if I would have survived just with this information.
Now imagine the doctor beside this prediction, which is evidently wrongly, as some more
information.
We have two premises.
White pixel in the picture, in tissue, brain tissue, suggests abnormal cells that are present.
And while we have abnormal cells and we know that they are actually growing after multiple
scans over time, therefore, we have high evidence of a tumor grade 3, 4, which is a malignant
tumor.
This is another argument.
The patient reported recurrent headaches in the morning, followed by nausea.
And his vision was diminishing over time.
Therefore, there is further evidence that abnormal cells are actually tumor.
But then we have something different now.
We have a third argument.
Neurological specialists demonstrate a very rare condition called multiple cavernomas.
Multiple cavernomas causes cluster of abnormal blood vessels to form in the brain, causing
headache and seizure.
Four of our previous arguments, one and two, are no longer applicable.
So now you can imagine that if the doctor would have had such information, he would
think twice to say you have a tumor.
In artificial intelligence, this is called the feasible argumentation.
We can express information as arguments, premises, and conclusion, and all of you understand
what's going on.
But also we can add other arguments, and with this, we can retract the previous conclusion.
As you can see, with this type of information, we can actually inform our decision-making.
So we need to focus on building an artificial intelligence system, not only focus on what,
but also focus on why.
We should build an intelligent machine, focus on what, and on why.
Intelligence machine that can actually empower human, that can actually empower our decision-making,
can inform our decision-making.
And we should have the right to understand what's going on and interpret this machine
and interpret their inference.
Alan Turing, who's already 50 years ago, 60 years ago, is considered the father of artificial
intelligence, is, when everything started, and yet, a very simple question.
Can machine think?
Some of you know how things have evolved.
And artificial intelligence now is spanning across sector in our life, in our society.
But we have built a very powerful, very accurate, very robust system, but they are looked like
black boxes.
We don't understand what's going on inside.
We get the input, we take the input, and we get the output.
Stephen Hawkins says, success in creating artificial intelligence will be the biggest
event in human history.
Unfortunately, it might also be the last, unless we learn how to avoid the risks.
So it is time to take action.
It is time to build an intelligence machine that can actually inform our decision-making.
We need to take control of this system, intelligence system that we build.
And we need to use this system, artificial intelligence, to empower human intelligence.
We need to do a revolution, a revolution that democratize artificial intelligence.
It is time to open black boxes.
Thank you.
