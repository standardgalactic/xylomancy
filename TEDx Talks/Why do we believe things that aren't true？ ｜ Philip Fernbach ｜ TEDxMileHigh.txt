A few months ago, the Internet exploded when a rapper named Bobby Ray Simmons, aka B.O.B.,
started tweeting out reasons why he thought the world was flat.
Now the story really took off when Neil deGrasse Tyson, the astrophysicist, started tweeting
back at him, explaining the apparent discrepancies.
But guess what, B.O.B. held his ground.
He didn't give in.
Now it turns out that B.O.B. is not the only one.
Believe it or not, there's actually a flat earth society.
With roots going all the way back to the 1800s, their motto is amazing.
We man the guns against oppression of thought and the globularist lies of a new age.
When I first read this, I thought it said, globalist lies.
But it's actually globularist, i.e. those nutty folks who think the earth is a sphere.
Starting with reason, we offer a home to those wayward thinkers who march bravely on
with reason and truth in recognizing the true shape of the earth.
Flat!
This is not some elaborate hoax.
B.O.B. and the flat earthers really believe that the earth is flat, despite all evidence
of the contrary.
So why am I showing you this?
Because your natural reaction to this story is wrong.
Your first instinct is to laugh at the flat earthers and assume they must be incredibly
dense or crazy.
But actually, they're not all that different than you and I.
As human beings, false belief is our birthright.
It stems from fundamental principles that govern the way our minds work and the way
we store knowledge.
Consider how common it is for groups of people to believe things that just aren't true.
Right now, in this moment, it feels like we're in the midst of an epidemic.
The explosion of fake news shows how easy it is to do people on the left and the right,
and science denial has gone mainstream.
Significant proportions of the population maintain beliefs counter to the scientific
consensus on critical issues like vaccination, global warming, and the safety of genetically
modified foods.
Public attitudes about these issues literally determine whether we can feed ourselves, whether
we can raise healthy children, and whether we can forestall a climate disaster.
The stakes could not be higher.
Which is why it's just not good enough to chalk all this up to lunacy or stupidity.
Simplistic explanations like that aren't getting us anywhere.
If we really want to improve the way we grapple with these challenges, we have to go deeper.
We have to understand what it is about the way we think that makes us so susceptible to
believing things that aren't true.
And that explanation actually begins with a kind of shocking observation.
As individuals, we do not know enough to justify almost anything we believe.
Now, I know that might sound crazy to you, but let's think about a couple really obvious
facts.
We all believe that the earth revolves around the sun.
Of course we do.
It's the most basic fact in the world.
But on what basis?
Can you explain the astronomical observations that support that belief?
I know I can.
What about smoking?
We all know it's terrible for us, right?
But what's actually in cigarette smoke that's bad?
And what does it do to our bodies and ourselves?
What's cancer really?
How does it even form?
These are not isolated examples.
Most of what we believe is not based on what's in our heads.
And there's a good reason for that.
There's not much in our heads.
As human beings, we are just not made to store a lot of detailed information.
In the 1980s, a psychologist named Thomas Landauer set out to estimate the size of an
individual's knowledge base in bytes, the same scale that's used to measure computer
memories.
One approach he took was to analyze the result of memory experiments where people are asked
to study some pictures or words or bits of music and then later tested to see if they
recognize them.
Using the data, he was able to estimate the rate at which we can acquire knowledge and
also the rate at which we forget what we learned.
And then he extrapolated to a 70-year lifespan.
So how much do you know?
Landauer's estimate?
One gigabyte.
I think this is an amazing result, mind-blowing, really.
One gigabyte is a tiny amount.
By comparison, you can buy a thumb drive on Amazon.com for less than 18 bucks that holds
64 gigabytes.
Now at this point, some of you guys might be freaking out a little bit, feeling a little
bit concerned.
After all, we all think it's the most important thing in the world to know a lot and have
great memories.
But really, this is a misconception.
We do not have to know a lot because we're not made to think on our own.
It's natural to think about thinking as what happens between your ears.
But that's not where the magic really happens.
This video comes from a psychologist by the name of Michael Tomasello and his colleagues.
They study human children's cognitive abilities in comparison to other animals like chimpanzees.
The goal is to understand what really makes us special, what abilities do we excel at
that other animals just cannot master.
You see how easily this young child reads the mind of the experimenter and then figures
out how to coordinate his behavior to achieve the goal.
He even makes eye contact at the end as if to say, I've got your back, man.
This is so natural to us that it seems like nothing, but it's actually incredibly difficult
to design a cognitive system that's capable of collaboration.
This is really the secret to our success.
It's what separates us from all other thinking creatures.
Chimpanzees routinely fail at tasks that require sharing knowledge and working together to
pursue goals, tasks that young children master with ease.
Now for me, this realization was a major wake-up call.
It really changed my perspective on the nature of the mind.
I'm a cognitive scientist.
I'm used to studying how individuals make decisions or solve problems in isolation.
But thinking is a social process.
Rather than happening inside your head, it emerges from your interactions with those
around you.
People are a little more like bees than we often realize.
In a beehive, you have an incredibly complex cluster of behaviors that is achieved despite
no individual being responsible for it all.
Food is collected and stored.
The hive is protected from intruders.
Genetic diversity is introduced.
The key is specialization.
Each individual does its own little part, and the complexity emerges.
The same is true of people.
On our own, none of us knows all that much.
We don't have to.
We each have our own little slice of expertise, and our minds are built to collaborate and
to share knowledge, which allows us to pursue incredibly complex goals when none of us has
anything approaching the knowledge to understand it all.
This is the Milan Cathedral.
It's one of humanity's great works.
Construction began in 1386, and the facade was completed, get this, under Napoleon in
the 1800s.
It turns out that cathedrals have a punch list like a home renovation.
The punch list was completed when they consecrated the final gate in the 1960s.
Six hundred years.
In that time, there were 75 chief engineers responsible for the project, and thousands
upon thousands of people involved.
None of those people had anything remotely approaching the knowledge to understand it
all, not even close.
Everything great we do as human beings depends on this ability to share knowledge and to
collaborate.
So that's the positive side of the knowledge sharing story.
When we put our minds together, we can do incredible things.
But there's also a dark side.
Because we are built to so seamlessly draw on knowledge outside of our heads, we often
fail to realize the limits of our own understanding.
Let me tell you about a study that my colleague Stephen Sloman recently ran.
He told his study participants about some new scientific discoveries that he completely
made up.
For instance, a kind of glowing rock.
He told one group of people that scientists had not yet explained why the rocks glow.
And then he asked them, how well do you understand?
Unsurprisingly, they said they had no clue.
This makes perfect sense.
They knew nothing about the rocks.
The more surprising result is what happened when he told a different group of people about
the same discovery, but this time he told them that scientists had explained exactly
how the rocks worked.
Now the participants claim to understand the rocks a little bit better themselves, which
is kind of weird because just like the other group, they knew nothing about the rocks.
It was as if the scientist's knowledge had been directly transmitted to them, even though
it was never described.
And it turns out that a similar thing happens when you surf the internet.
Just having access to all of that information makes you feel like you know a lot more than
you do.
The sense of understanding is contagious.
And when contagious understanding is paired with individual ignorance, it can be a toxic
recipe.
The danger is that I may express a strong belief because I feel like I understand.
But my sense of understanding is false.
It comes from those around me expressing strong beliefs because they feel like they understand.
But their sense of understanding comes from those around them and so on.
And yet, because we feel like we're on firm ground, we don't do enough to verify.
And that is how entire groups of people can come to believe things that aren't true.
We can build cathedrals, but we can also build houses of cards.
Now the real tragedy occurs in how we relate to people who have different beliefs than
us.
We live in the illusion that we have arrived at our own positions via a serious analysis
and that we can support and justify what we believe based on what we know.
Therefore, when someone doesn't believe what we believe, it's obvious what the problem
is.
They're too stupid to see the truth.
And there's actually a sense in which you're right when you think that.
It's true.
They did not arrive at their position via a rational process of evidence evaluation.
And they don't understand the issue in depth.
But neither do you.
Think about how we talk about a complex issue like healthcare.
If you're a liberal, the Affordable Care Act is the bee's knees.
If you're a conservative, it's destroying America.
But most of the time, arguments about the policy's merits amount to little more than
repetition of sound bites that we heard from someone else.
As non-experts, we can't possibly do justice to the complexity of an issue like that.
When we express our beliefs, we are all just channeling our communities of knowledge.
That's what we do.
Knowledge is not in my head, and it's not in your head.
Knowledge is shared, and therefore, the things that you really care about, those things are
shared too.
Now the point is decidedly not that people are stupid.
It's true.
We are all ignorant, but that's not something we should hide from.
The world is far too complex for any one of us to understand much of it.
What makes us special is the ability to thrive amidst that complexity by sharing knowledge.
From our individual ignorance can arise collective genius.
Ignorance is a feature of the human mind, not a bug.
But we don't have to be so darn sure about things we don't understand.
Of course, we have to take positions on issues without knowing everything about them.
And if we have good sources of expertise in our communities and a culture that values
truth, we'll get things right more often than not.
But when we go through life feeling like we individually have it all figured out, it can
lead to a warped and simplistic view of the world.
My way is perfect.
Yours is crazy or evil.
In reality, most issues are complicated and most people have good intentions.
Okay, now the bad news.
We can't eradicate false belief.
It's too basic to the way that we think.
What we can do is practice a little more intellectual humility to open our minds to the possibility
that some of those things, some of those false beliefs probably reside in our own communities.
We have a tremendous opportunity, an opportunity to improve the quality of our discourse by
recognizing the limits of our understanding and by appreciating just how much of what
we believe depends on those around us.
Thank you.
Thank you.
Thank you.
