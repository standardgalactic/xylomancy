I found out like yesterday afternoon that I had to do this talk, so I was preparing so I didn't get a chance to see the keynote
I look forward to watching the video of it. Hi, my name is Richard Campbell. I am an old geek
I've been doing this stuff for a long time. I'm from British Columbia
This is a picture of my house on the left and my neighbor's house on the right. We call this the animal highway
I didn't realize until I put this camera in that we get bears every week
It's this is about six in the morning in the summertime
On a Wednesday because Wednesday in my neighborhood is garbage day
So he's just coming to see if I put out my garbage early or not
And there are consequences if I do so and actually we get fine if we put out the garbage early
It's quite against the rules, but it that's what it's like living British Columbia. It's just forest behind me
It's like a big old buffet for bears and they come through and check on it
He sees actually at the at the top of the driveway right now
Surveying his domain anybody got the garbage out before he moves on I
Make a lot of podcasts than he done at rocks listeners
Awesome Carl's not here. I won't be recording it out in a rocks this week
I'm gonna be doing some run as Carl started down at rocks back in 2002 which predates the word podcast by a couple of years
I came on board with show 100 in 2005 where it 18 will do 18 30 this week
It's already in the can and this
And yeah, a lot of the stuff that I do is based on down to rocks
This talk definitely is coming from all these interviews we get to do
We get to talk to really smart people and so you get to a side of synthesize the sort of vision of what's going on
I do an IT show as well
called run as radio and I think a episode 863 went up today and for a brief period between
2011 and 2014 we made a show called the tablet show
Back when we didn't know what to do about tablets and now we know tablet development is just development. It's not a big deal
All right, so we're gonna do a little future prediction
So let's refer to Niels Bohr's prediction is very difficult, especially about the future although. I don't know what else you would predict
So let's go through the obvious things that are happening today that are gonna shape the way we build software for the next few years
I wrote the first version is talking 2019 thinking one of the 2020 is gonna be like and now it's 2023
And it's not exactly what I thought but
Did anybody plan up for a pandemic in 2019? I don't think so
But obviously the cloud has come to dominate in the past few years. It was true
It was less true in 2018 2019
But today if you don't have a cloud plan you kind of don't have a plan your your employer is probably gonna ask you
Well, how does the cloud fit into this equation and
Same for mobile devices mobile devices are now the most common computing device in the world
They are the majority of compute the reason iPhone and Android dominates just because there's so many of them
We figure this four billion smartphones operating in the world which pretty much is one for every adult human and
We've transformed society for that
Fundamentally, we are all cyborgs
Right, we have digital extensions to ourselves now
We tend to because of science fiction think about cyborgs as the digital stuff is inside you but a yuck
And B impairs upgrades
But if we don't think of our phone as an extension of ourselves try losing it for a day
Like we're pretty agitated when we don't have that device around it's our communication device
We would just take it for granted that we can talk to anybody anywhere if they'll answer which they won't
Or we at least message them and whatever messaging constraint you currently have the Venn diagram of messaging systems is continued to be messy
But that's because it's so all-encompassing and so we can't talk about
Future of compute and and the kind of work we're going to be doing if we don't include these devices and how they're going to evolve as well
We know how to make an awful lot of data
That's just a byproduct of having a lot of devices feeding into common reservoirs, right?
The you know, ultimately a lot of what's made the modern machine land
Machine learning models exist is because of this is tremendous feed of data that we're generating on the behalf of others
And all of these are obvious trends more compute more cloud more devices
More data nothing surprising here. It's all expected. What are the unexpected things?
We're we're we're going to hit limits in the next ten years
For me the big one is we are finally going to run Moore's law to the ground
So Gordon Moore is a person. He was one of the founders of Intel
They were one of the first companies to make micro processors. Well, actually they first made Ram
That was their original product when when Intel started up Ram was still largely core Ram little ferris coils wound with copper to store
Bits sounds as reliable as you think it would be
And so the idea of building
Silicon substrate Ram was a big deal and that was an Intel's original product and it was while they're making Ram
That Gordon Moore observed that for roughly the same amount of cost
Every 18 to 24 months. We could double the number of circuits on the piece of silicon
Now they only were able to do that by working very hard at it
Later that would be called Moore's law. It's not a law
Right a law is something that happens whether you work hard at it or not
Like gravity you don't have to do much gravity is going to apply
But for Moore's law to be a law companies work extremely diligently to increase the density of electronics and it's worked if you'd
So pull this data from Wikipedia. This is a sort of chart of the processor
The density of transistors in processors from the original
4004 in 1970 up till around now and you see how clean that line is and that's because we have an
Exponential number on the left of the number of transistors if I didn't use an exponent on the left and go up orders of magnitude
We get the hockey stick the dumb graph where nothing is meaningful and then it shoots up at the end
It's a bad way to explain this honestly, I mean and we're technical people
Getting our heads around an exponential function is hard when I'm explaining it simpler. I talk about things like this
What is that warp drive for the enterprise? No, that's this
This is a cray
XMP supercomputer circa 1985
They've only they only made a couple of hundred of these that in 1985. This was the most powerful computer
You could buy they were millions of dollars
They ran on on 200 kilowatts of power. So you kind of need to bring your own generator
They're cooled with mineral oil because they're running so hot without mineral oil pumping through it all time that it will melt
You notice it's kind of curved
They're trying their best to keep the wires as short as possible
So the speed of light doesn't impair the performance of the computer
This is leading edge technology in 1985 and it's knocking out about 1.9
Gigaflops
per second, so just about two billion floating point operations per second in 1985
They modeled nuclear explosions on this the Voyager missions were computed on computers like this doing the orbital calculations
fast forward a few years say
2011 the iPad 2 by 800 bucks
Don't put it in any liquids. That's a mistake
It runs, you know on its built-in battery for about 20 hours and it's got about
1.9 gigaflops of processing power
So 26 years later the most powerful computer in the world is now a device you give to children and
They play candy crush on it
That's the advancement of society and
This face it that's not fast
That's a 20 that 2011 device and a consumer device at that
Today if you're a consumer you want a high-performance compute device you buy a very expensive video card, right?
An RTX 4090 these days if you can find one, they're a couple of grand
You know, they're not cheap
but
16,000 cores in it
currently pulls down about 82 teraflops at full bore so
It's 40,000 times faster than the iPad 2
So 11 years later, you know, and that's this is also 450 watts
So, you know, you can heat the room with it if you like like I hope you bought a big power supply because you're gonna need it
And if you want you can run too. I don't know why you would
Nobody's mining Bitcoin anymore. That's done
And it's still a consumer device today
There's a today the fastest computer in the world the supercomputers of the world
There's a race going on between the Chinese the Americans and the Japanese and the current leader like literally this past fall
Was the frontier supercomputer in Oak Ridge labs? So that's in Tennessee in the US. That's based on the HP architecture
so this is a massive multiprocessor machine and
1100 petaflops or 1.1 exa flops
For about 600 million dollars
Needs about 20 megawatts of power so bring your own nuclear reactor
and takes up about
700 square meters so clear out the basement
13,000 times faster than the 4090 or
600 million times faster than the iPad to or the cray XMP
Moore's law
Right, and that's what we're talking about is our ability to continue to extend compute
And I like that comparison where the cray compute power became our consumer device
Like are we going to have an exa flop device in our hands? It's possible. I don't know what you'd do with it
But then we didn't know we needed to play candy crush in the first place right it just emerged that way
And Moore's law is ending this graph cannot continue. Why why are we running into the limit?
Well, we're getting better and better at packing transistors into a smaller and smaller space
And you'll hear these terms like the 10 nanometer process and the 7 nanometer process and the 5 nanometer process
Scientists have built a 1 nanometer transistor, but only one of them
Those are all rough measurements. They're not realistic in the actual circuits are more complicated that we have good
Sensors now. This is an electron tunneling image of the IBM 5 nanometer process
So this is doped silicon layered together
It's hard to measure what we talk about nano things all the time is compute people the billionth of something a billionth of a meter
Is really really small people can't understand a billion right same problem is that exponential function?
And I always describe this as if I want to wait get you to wait for a million seconds a million seconds about 11 days
But a billion seconds is 33 years
So the idea that a nanometer is to a meter as a second is the 33 years
And we're making stuff at that scale today. That's how dense we're getting this is kind of this is
Stanley scanning tunneling microscopy of a of a silicon substrate the yellow dots are
Silicon atoms the blue holes are phosphorus atoms
We talk about doping silicon when we make integrated circuits so they change their voltage behavior
So you can apply voltage and pass it through a semiconductor. This is literally the structure of it. It is a crystal
and when you get down into those
nanometer scales, we're running out of atoms a
Silicon atom is a hundred and eleven pico meters across like point one nanometers
So when you start talking about a transistor layered together, that's only a couple of dozen nanometers across it's only
hundreds not even hundreds of atoms
Strictly right quantum effects start to apply like we're just getting as dense as we physically
Can get and that's going to be the limit and not only that we can make these things at all that that we can make
Billions of transistors on a given die
for about a thousand dollars
Right keep the prices stayed consistent the manufacturing process has to keep improving without really raising the price
So that we'll continue to buy them
Again we get debate like how fast did you need to go and how dense they need to be
But we've built our entire industry of on the fact that we're going to have more compute in about two years
for the same amount of money and
That ends in the next decade
Now there's a bunch of things that we're doing or
Haven't been doing because of Moore's law one is we have not really improved
architectures for the most part especially if you're talking about Intel
They've more or less sold the same core chip design
for 40 years
Because every time they try to change it we got very angry because it wasn't compatible with what we've done before and we like
Compatibility more and so at this point that perpetually evolving x64 and x86 architecture has gotten fairly convoluted
the amount of steps involved in a given work cycle even if it's going at multiple gigahertz is
Complex now we do have simpler architectures the arm architecture came along quite a few years ago and
It was built for more power efficiency more compute efficiency
And it just didn't have the legacy that the other systems have but arms pretty mature today
And it's one of the reasons you're seeing more and more interest in arm in general for compute because the amount of energy necessary
For a given unit of work is lower in those architectures
You can expect as we lose the ability to get more compute
For free by buying the next generation processor that optimizations in architecture become much more important
Now for us as programmers for the large part we're insulated from that our modern programming environment
Almost completely abstracts us from the actual underlying hardware if you're living in a dot in dot net land
It's Microsoft's responsibility to make sure that the common language runtime
Compiles and optimizes to the processor you have they do that all of the time. We don't even think that it happens
It's kind of magic. It just works in that brief period where they thought arm was a really good idea now
They're coming back to that idea again. You could compile dot net to arm
It went away. It'll be back because it's nothing that we have to do
It's their responsibility to do implementations against the hardware. That's the power of abstraction for us
I would argue that today the M1 and the M2 made by Apple are the most advanced
processors out there architecturally
They're arm based, but they've also added they've condensed a lot of things. Most of the memory is here
They have tensor compute units or basically units optimized to do neural neural net calculations
They have the GPU integrated in putting all those things in a single die
Putting 40 billion transistors together all working and playing happily has some benefits
And so, you know, those are some of the nicest computers we can buy today
And it sort of speaks to what the future looks like and I'm I'm an advocate of William Gibson
The guy who coined the term cyberspace while typing it on a Wedgewood typewriter
But his quote is the future is here. It's just not evenly distributed
So if you want to understand the future one of the easy ways to go is go look at where the concentrations of real rare innovation are and
What's happening in Cupertino with processors like this is pretty profound
It speaks to what phones should look like in the future and what our other compute devices can be deeply integrated circuits the modern
manufacturing foundry
Allows us to build very customized circuits that are as close together as possible to run as fast as possible with the least amount of heat
And the least amount of battery waste
All right
Let's stop talking about the underlying hardware the net real constraint these days is the network
5g was wonderful. It was heavily advertised a few years ago now. It's here and nobody can tell works perfect
mean the
It's a good question
in theory these
Standards for wireless are about increasing
Frequency to intensify more data so more people can communicate simultaneously the downside is as you move up in spectrum
You decrease the penetration
So our old 2g phones which were living down in the 900 megahertz range worked beautifully in basements
When we got up to 3g and 4g phones and we moved up to the 2 gigahertz band range
We had trouble communicating into in closed areas, right? Some buildings were some not so much
It was easy to get into a fair day cage rear phone would work
5g bumps this up into the 20 gigahertz range
Big increase in data density, but the penetration goes down a fair bit. It's blocked by things like
trees
Bodies, you know, I've stood in front of a 5g tower doing a speed test with my phone and going wow that's smoking fast
And then I turned around
And 20 gigahertz apparently doesn't go through me
So there's challenges for these higher frequencies. There was the 6g specification underway
But there's no simple solutions here network is going to be our constraining resource as
Developers we have to think hard about how we move data between points of compute
That's always going to be a limitation. There are no workarounds largely for
For the laws of physics the speed of light, that's a law
This the modern is a the the satellite networks that are going up now are very interesting
For certain applications what we've really reached is a point where much of the parts of the globe that don't have good cellular coverage
Can have sufficient
satellite coverage
So more and more we're reinforcing Esther Dyson's belief that it was easy
It was easier to put networking everywhere than it was to build a good disconnected client
So you just keep presuming we're going to have bandwidth everywhere
I got I got on the early Starlink beta because I have a place sort of up in the wilderness in BC where the bears are even more common and
It's an insuppressive like that's just a pizza box size antenna. You need a clear shot of the sky
That's the hard part and if you've got a clear shot of the sky
You've got about 400 megabits down and 100 up at 20 now at 20 milliseconds
You can game from there. It's not as fast as your your your synchronous fiber, but it's faster than you would get in most isolated areas
So that ubiquitous connectivity and huge amounts of compute available in very small devices
You know the other side of Moore's law is the old hardware gets very cheap
And so we're seeing in things like automobiles where they won't spend money on compute. They still have it
They're still they're now starting to put 3g
Cell services into all cars so that all cars have telemetry back to the factory whether you want it or not
Because it's more important for the factory to know about what how you're using the car
So this model of the ubiquitous computing is emerging more and more where every device has an IP address and
Can connect to the network and and is communicating perhaps not for your benefit before the vendors benefit
But it's always communicating and we have options there. We're going to be responsible for a lot of it
I'd be remiss in just setting the stage for all this to not talk a little bit about the pandemic
Well, again, when I wrote the original version, it wasn't the thing, but we've continued to deal with this
That's obviously in the later stages
Our friend Satya Nadella said was famously quoted by May of 2020 saying two years of cloud migration happened in two months
As we as everyone discovered yes
You can work at home and we tore apart our perimeter networks and shoved and expanded our VPNs and
Quickly shuffled whatever we could into the cloud. We changed the landscape of work. We changed the landscape of compute
I mean for most of us in our industry working from was just not a big deal. We've been doing it anyway
I do hope one day to make either a video series or a talk just on how video conferencing evolved over those two years
Remember that period where everybody thought all of those
Inlaid graphics with the hats and in the horns and things was a good idea
It lasted like three months for three months. Everybody had fun with that
They're like, okay, that's really dumb and they turn that off. But that's the evolution of etiquette and perception
And today it's really interesting to see how everybody comes on with a face initially says hi
Then when somebody actually starts to talk most cameras go off to not distract like that
We're developing an etiquette for that model. We were rushed to do it
But we're also seeing the other side of the pandemic we're starting to see the economic impacts
We the side effect of mass layoffs was a loss of expertise that in general all
Workchains are less efficient today as we tried to gear them back up and you have a 20 or 30 or 40 percent
Inexperienced worker role in across those chains of work
You have a lot more mistakes and they cascade on top of each other
We had the supply chain deeply disrupted ports that were had too many empty containers and not and not enough full ones
Not enough space to move things around and literally going to take years to straighten it out
And then the byproduct of all of that friction in supply was an increase in demand for certain goods
Which then got interpreted as inflation and here we are it's 2023. I hope you're having fun
Now, what does this mean for us in our industry specifically because for the most part
We've had 20 years as developers
Just in a growth mindset
2008 2009 not withstanding the sort of great recession because I think for the most part technical industry was insulated from that
We were not as impacted as much as many others
So I've talked to folks that have been working since after the dot-com bust 2100 2002 and it's just been build what you want
Go faster build more, you know, explore great ideas. Now. I'm older than that
I started writing code in the 80s when economics are a lot tougher and we focused really hard on this contact of return on investment
The problem is that when we're software developers, we rarely are directly responsible making money for the company
Typically the things that we make are tools that allow those that make money for the company to work more efficiently
If the things we're making don't do that they're really not that important
You know, this capitalist model has always functioned on the idea of
Rapid relatively inefficient growth followed by a period of sort of cleanup
Shaking out the the weak stuff a bit of a recessionary period for a year or so
We cut the sort of fat off and then we'll grow again
Except that we've gotten good enough with our economic models to avoid that whole cleanup phase for 20 years
and now that we're looking at one in a very serious way and
Folks are seeing that, you know, what it's like to have a five or six percent interest rate and
That, you know, new costs of things the pressure on energy and so forth
Companies are being more reflective. They're sort of looking back and going are we doing the right things?
Are we focused on the important stuff and it's in our best interests with our skills and domain knowledge and the companies that we're working in
Make sure you know how your company makes money
Make sure the things you're building
Help that because we are productivity amplifiers
We're incredibly good at building tools that allow the rest to work faster to do more
We can help companies survive in difficult times. We work on the right things
All right, we wanted to talk about technology. We've kind of set the stage. Here is the landscape we live in today
So now that we know we're living in a cloud and living in a cloud world mostly smartphones
We're not going to count on you compute going much faster and in general our employers and our customers are really tighter with their cash
What should we do?
Start with the browser market because the browser market is
Kind of stable now
If you really want to use up a lot of memory in your computer, there's chrome
If you want to be frustrated with how well your websites work you've safari
If you want to use a browser, nobody else cares about there's edge and if you want to be an angry
Anarchist there's Firefox like you have choices, right?
There's no perfect solution to any of these there. Nobody's utterly dominating the market
I mean chrome is still a big player, especially for your typical employer
That's likely the browser using you tend to build to that and we're clearly seeing the rough edges
We're not all the same things work together, but we have the tooling sets and
You know in on Donna rocks we made fun of the rapid rates like hey
We've got an hour-long show here. There'll be at least two more framers before this is done
That I feel like that pace is eased off a little. I think people want a certain level of stability
you know angular is not the new sexy anymore, but it's
It's utilization level inside of larger companies is massive and those top three across the board seem to be
That you know majority of web development and we're still doing mostly browser development
Especially for companies because it's also deployment issue and they're always running latest version
And that's things we want from that even if we have to constrain the feature set someone and getting and all of these libraries
Have some degree advantages for working in the in the
Heterogeneous client world that we have that people are expected to be able to use those pages on a phone and on a tablet
Not a PC and have a reasonable experience on all of them. It's still not easy
Development for us has all the easiest time of development was when the device you were writing the code on was the device
It would normally run on that just hasn't been true for 20 years
Whether we acknowledge it or not now we typically are writing on a test stop PC or a robust laptop
But we're running it on smaller form factor devices and that's a way more difficult thing to develop for it
More complicated model. It's a longer cycle, but if you're not respecting that cycle you struggle with what you're making
The progressive web app movement has helped us at the minimum to give us an icon
For regular users to be able to get to that web page because goodness knows they couldn't figure bookmarks out
Right, so now we have an icon. It starts up a frameless browser
We're that's good enough. There's a bunch of other great stuff in PWA and the three guys to use it think it's great
And then there's our friend Steve Sanderson who brought us web assembly in the form of what would eventually be known as blazer
now
He didn't invent it. You know, he wasn't first
But he definitely brought it for us in the dot-net community back in 2016 at the NDC conference in Oslo
He showed it off for the first time with a very bizarro version of C sharp
That allowed us to run C sharp on the browser and really what web assembly is evolved into is a kind of container strategy
Where the inside service of the container is this browser environment a sandbox
That's relatively safe to operate within and you can introduce almost any kind of code
Microsoft took their time
Committing to blazer Microsoft doesn't like being first. It seems these days
They kind of sat on that project as an experimental project until go lang for web
W a shipped as soon as that happened well then blazer came out
But it was like when nobody wants to attack Javascript, but we do want to program in the languages
We want to program the devices we want to program in and w a gives us this ability to program in the languages of choice
Down on the client device still in the browser. So I still have my deployment issue solved
I still have continuous update models or every time you click on it
You get the latest version like all of the benefits of working in web development, but now I get the language that I want to use
And if you've listened to the show, you know, we've been talking about other places that this container could run
I mean blazer made it absolutely obvious to us that we can run it on the server
We can run it on the client, but now it's you should be start thinking about different points of compute. I
Don't want this code to necessarily run on the client device, but I wanted to run close to the client
so could I define a
Set of parameters for where this X block of code could execute that it could run in a CDN an edge point of some kind
You know, and this is all
Experimental, but I'm hearing it more and more often that the web assembly is a another kind of container
And what the potential of that offers to us long term
So if you haven't explored this world and started poking around what's possible there
Just understand this is an area of growth
Extremely smart people are looking at where they can take web assembly to
Now if you want dumber areas we could talk about web 3
It's easy to make fun of mostly because it's pretty silly I
See it coming down to three central ideas
Decentralized web is I think the most reasonable aspect of web 3
We
If you think about web 1 late 90s early aughts the whole dot-com boom
Not dot-com from Microsoft perspective for the idea of the internet becoming a popular thing
That was very decentralized people ran web servers on machines under their desks
Connected to the internet. It wasn't a good idea, but it's something we did and
It was powerful and flexible except it wasn't reliable right sometimes that machine sometimes you trip over the power cord
Sometimes the cat barfs into the CD drive right like stuff happens and that machine was actually on the internet
Web 2 was far more centralized right we gave up our ownership of those
Devices in on the internet for a service provider. It's just that we chose folks like Facebook
But you can still put geocities in that can as well if you want
But we now we're getting into more interesting compute models with distributed execution
and the problem of course is that those products turned into other kinds of exploitation of us and
Us not controlling the value we're actually making and now everyone's a little bit sick of it
And so decentralized web is becoming hip again. Just trying to do it in a better way
Meaning running on the cloud you could still be largely decentralized because it's all about ownership of data
So can you run your own services through a provider who's not really running competing services directly?
But rather having other people compete in that space. I look more to stuff like the Shopify model
Where there's no reason for you to employ your own e-commerce engine anymore when you can go to a Shopify and run their engine
For a set fee with many thousands of other people running their the same engine for their products
The one person not running an e-commerce engine is Shopify themselves. They're not a competitor in your own space
That's fairly decentralized. I can live with that
This only parts when we get into web 3 I mean blockchain is not inherently stupid. It's just wildly
Misapplied right the idea of a distributed data engine is pretty compelling
It's just that people don't think about it. Well, you know when I have a customer asking me about well
We got to use blockchain. It's like why because he saw it in a magazine
Like what do you want from it?
What what's the difference and often with most companies they still want to be central point of control
It's like so you don't want blockchain the idea that other entities can introduce transactions on into this data
independent of you is
The basic step important like if you're not going to do that then what are you talking about?
Why do you need this? But blockchain's got the problem that BitTorrent has
BitTorrent's problem was that it came out of Napster about a stealing music. It was a good protocol
used for where its initial use was a nefarious use that was ultimately illegal and
Blockchain has the same problem. It's bound to crypto and as we're seeing pretty clearly these days
Crypto is pretty much a Ponzi scheme and so
Are we gonna get something from it eventually? Maybe our most people just gonna lose their money here seems like it
It's easier to see that now than it then we saw before but that's the part that's really
Contaminating web3 is these fairly good ideas bound up with an idea that was very easy to exploit to fairly destructive purposes
And so I think most of us these days who are a little more serious about stuff are going
You know, I think I'm just gonna stay back from that
Rodeo and let it wind down and then we'll see what pieces are left in the end
Web 2 didn't happen overnight either this exploration of new ways to use the internet. It is an exploration
It takes time. There's no other way to do it
And so it's a question of are you gonna jump in and be part of that exploration?
Or are you gonna witness it and then make your move later on?
If you think like an engineer you're pretty conservative and you're not the first you're big on the IT mantra of change is good
You go first
Not a bad way to look at crypto these days
Dot net's in a good place
It just knows I'm glad about that I make a podcast called dot net rocks and back in 2011
We thought maybe dot net doesn't rock and things were pretty hard by 11 years on 12 years on dot net's rocking pretty hard
They've done a remarkable thing. They've rewritten the entire thing to be a cloud-centric
heterogeneous client platform with some limitations without having to replace all the tooling in the process. I
Mean if you learned how to develop against dot net in
2010 with studio 2010 I can drop you on to studio
2022 and dot net core and you won't be confused
You'll more or less get it there's a bunch of new stuff and there's some edges to things and we focus on some other elements
but
Really we've had a complete
overhaul of this 20 year old stack over the past six seven years and
Yet we don't have to relearn we don't have to start over we get to move most of our code on
On to it and the new things you write we use familiar skills
If anything the biggest problem Microsoft has right now with this is that it's so calm
It's so similar. We still have our old practices. We're not using the new language features
We're not taking advantage of the new stuff that's been brought to it and the only way they're gonna fix that is tooling
Because compatibility is so important
They're not going to take stuff away if you're using C sharp to constructs. They're going to keep working
But you probably want to use a new one
So I think you're gonna start having more clippy events where pops it goes. Wow, you're coding like it's
2007 can I help you?
Because you need help and
The big new tool in this space is Maui
So this is the culmination of a tremendous effort inside of Microsoft to consolidate a client development solution
That's deals with the heterogeneous client and multiple platforms. It's still pretty raw
Again the conservative engineering a type of look at that you go
You know, I'll let you guys iterate on that a couple of times
You guys you kind of get it right at the third version
You're kind of like an aversion a half right now
So we'll give you a little more time, but the goal is challenging the idea of this magical
Unified client development model works for all the devices something we want our customers couldn't care less about
The customer only cares that it runs on their device. They don't care if it runs on anybody else's device
We're the ones who want to write one code base that runs on all of those devices because otherwise
We can't keep them in sync or we're leaving somebody out and they're angry with us and that's never fun
So this is Microsoft's client side attempt on this and I mean, I'm I'm excited for them
That said the seven version is substantially better. I think this will be almost sexy by November of this year with dotnet eight
It just takes time for them to get this many features and this many teams
Co-operating across the stacks and if you're sticking with web development
I don't blame you because it does it solves this problem with its own set of limitations
I've yet to see a Maui implementation of a cross prop platform client solution where I said wow you couldn't do that with web
We're not there yet
We might be I don't know the answer to that
We've talked about this a few times on the show and it doesn't seem to be going away the power platform
So here's the other reality is that we kind of know what the client space landscape looks like
We know there's phones and tablets and PCs an
awful lot of our data over forms problem space and in work is all dependent on
The cloud tenant that our employer has anyway
And so the fact that we can essentially run this set of tools that builds a bulk of that for us
is pretty compelling
But even more importantly
These tools are are straightforward enough that a domain expert can take a pretty good shot at an 80% solution
For a workflow for a company
And then it needs to be cleaned up by some of the bit more experience
But a lot of ux development can be done by the person who's going to use it
Now this has happened before this is access and visual basic in the middle 90s
Where most people who grab those tools were domain experts not developers
They became developers later, and I think we're seeing another wave of this
But the parts that we find the least pleasant as professional developers that ui multi-platform ui problem
This thing kind of knocks out
And then it has a set of hooks back to back end services with some limitations. They're all customizable
We as professional developers can build additional endpoints for the power platform
And if you're good at the ux side, you can build custom components on the ux side for these domain experts to use too
But i'm looking at our to-do list
And we're not getting to the bottom of it
So if there's a group of people out there that want to move things along by taking on some of that work
Do it
The way microsoft's licensed the thing it's for internal apps only
You pretty much cannot put a power app into public. It has to be
authenticated members of the tenant
So it's for
internal apps
They weren't fun to build in the first place
So anything we can do to get more of those off the table and modernize them, right?
You're looking at that web forms app that the cio wants to run on their ipad
And suddenly the fact that a power platform could get you a prototype of that in pretty short order. It's pretty compelling
I've mentioned web w a in the context of containerization containerization is an ongoing evolving thing
It's only getting bigger. I got a recent show up where we're talking about azure application identities
and
That ties into giving a security context to an application
It's going to run in the cloud in a lot of ways containers do that too, right?
We're demanding a manifest saying this is what the app this is the resources the app needs
This is the operating contents it needs to operate in here are the rights that it needs the access points that it needs
And more importantly if it tries to do anything isn't in that kill it
Containers are just the evolution of that
Um in the next few years, I think we're seeing containerization of software in general on desktop machines
because of the security problems
That when a given piece of software gets exploited and it tries to do anything outside of its normal set of behaviors
The operating system recognizes that it's exceeding its container limits and stops it
Now that was always a good idea and microsoft's tried to implement this in a few different ways for a long time
But I think the security context is going to win
I look at what's happened in cyber insurance in the past couple of years
Today if you want to get cyber insurance not only is it more expensive
But even multi they they and they require multifactor authentication
But more and more i'm seeing things like you're required to do a privileged access audit
I wouldn't surprise me at all if the insurers at some point say if the apps if your apps aren't running containers, you're not insured
Because they see them as ways to avoid the exploits that the black hats are using
So that might be what pushes this technology over the top is it becomes a
consistent industry-wide way
To resist the ransomware and other security attacks
And if you're feeling a little overwhelmed with all the stuff i'm rattling through because I get to just tell stories for a living
I don't have to implement any of it, which is why it's all easy for me
That's okay
There are a bunch of ways to have a great development career
Staying on the leading edge is really fun if it's fun for you
You know the upside the downside to the leading edge is also the bleeding edge and sometimes you bleed
You can also have a great career and many people do by becoming an expert in a stack that your company values and staying that expert
It may not be the newest technology anymore, but it's the one the company relies on
And they need those experts and they need you to continue to grow and to be good at that technology
And to keep it functional for the organization to keep you into things it needs to
Don't jump because the thing is new you jump because it can no longer solve the business problems that it needs to solve
I've talked to folks that started doing web forms develop in 2005
And their company still uses a ton of it there and it works
It's reliable. It's known set of problem spaces
They have a you know, they're 15 years into this or plus and do I really need to to jump to a new stack?
It's like no those apps aren't going away
And in fact even when they are they're going to technologies that are orthogonal to web forms. Anyway, that's why blazer got so hip
If you're a web forms developer and you look at blazer, you're just not that surprised
This looks like something you've done. It's not that hard to jump onto the new stack
So
The question is what did you want to do?
Do you want to be part of the group of folks that are always learning and pushing on the new thing?
Or you're going to be the expert in a given set you find a space that you like and you stay in that space
And you get really good at that space and now you're an expert in a diminishing pool
Like you're pace still going to be good
But you need to maintain your expertise
You need to keep figuring out where the limits are and what's possible like it doesn't mean you ever stop learning
We don't get to do that in this industry
But it's a question of what you focus on
Do you really want to learn the new bits where we're all just trying to figure it out?
Or you continue to expand on the space that you're in there's not one way to do a great career
Let's talk about artificial intelligence
And I use this image for the simple reason that it's it is the reason that we think about AI the way we think about it
It's a terrible term
It was coined in the 1950s by a guy named Marvin Minsky when he's trying to sell stuff to the US military
The first time regular humans heard the phrase artificial intelligence
It was in the movie 2001 a space odyssey and how and then he tried to kill everybody
And set up our relationship with artificial intelligence going forward
It's an umbrella term the one thing I know for sure about artificial intelligence is as long as somebody's calling something artificial intelligence
It's because it doesn't work
As soon as it does work it gets a new name
Right it becomes deep learning a predictive analytics or you know speech tech systems as long as it doesn't work
It's AI
And so when folks talk to me about hey, you know, I'm working on this AI problem
It's like what are you really working on? Like is it a machine learning model? That's the new
thing right like really what really came out of
Jeff Hinton's papers in 2011 that led to stuff like siri and all the voice recognition and ultimately these vision
Interpretation models is all
Deep learning models based on machine learning right and this particular graphic I like because the short lines
Are the oldest technologies those planning schedule and optimization. Those are back in the 50s
Expert systems and robotics from the 1970s original speech recognition systems go back to the 80s
And then in the 2010s we get this current crop of image recognition
vision systems language interpretation
And we can incorporate that into our software today. There are good libraries. You don't have to invent stuff
It isn't research anymore. You want an image recognition module? It's a module you load it into your software
You have an image to be recognized and it can recognize it
This is a real thing the software was doing what you told it to do
Said oh no no three dogs
Uh, and you've run into the chatbots right they're out there
You they are first line tech support for almost everything today
You're going to get a chatbot for us and sometimes they're speech bots
And they're they are getting better. There's mean they're good
We all learned to say agent very early on if we want to get out of that loop
These are again tooling sets that we can work with
The area that I I'm really fascinated by right now that microsoft's working on are these form recognizers
So the idea that I can I can use an image recognition system look at a form and it recognizes
What is form and what is data and then associates the two together into
value pairs
That's pretty cool right that we had a different strategy to digitizing a form rather than building it by hand
In in code that now the tool would actually recognize before you generate for you
I I this was really about using initially paper because they called it a form recognizer
Like can I parse a page and have it pull the data out of it?
But I immediately thought hey aim that in a at a web forms page
and re reimparse it for me
And make it into power platform stuff
Like can you could I just have a tool thumb through all of the different views in an application and regenerate it in the new language?
Why not we have machine learning models that are capable of parsing the data
The final area in the machine learning space is that it's gotten powerful
Actually has been powerful a while and when people are asking about hey my kids getting into technology
Like where's the big career opportunity? It's analyzing data
We have more data than ever before we're analyzing it
Less and less effectively because we're just outnumbered there's so much data and only so much time
The good news is the cloud is making things simpler for us in the 90s
We had most of these predictive analytic models
It's just that each one of them represented a huge amount of compute
And so you'd do a bunch of pre-work to figure out what the most likely
Analytic model would be effective on this given data and then you'd build out a system and run it once
And it would take weeks
Today, this is a couple of hours in azure
Load the date you'll spend more time loading the data out
Then you'll run all of the predicted analytic models and then you'll run model analysis against the models to figure out the one that fits
the data set best
for $20 worth of compute
So we have better tools than ever for doing advanced analytics and as we go and when we talk about advanced analytics, you know the predictive model
Is really what's the next number that's going to come from this?
What's the trend on these is going up as it's going down, right?
We have plenty of tools in those sorts of forms as we start adding in machine learning. We do it in bulk
We're able to do more of them faster and compare them so that we can select models more efficiently
It's less time of your space and more just hammer it with compute, but you can go to a more advanced stage
Given you take a predictive model and it says this is the most likely outcome
Now you can actually run a scenario beyond that you're getting into prescriptive analytics
So you're cycling the predictive model with actions
You've been experienced. This is where you know it or not. Have you lately?
thrown a bunch of stuff in a shopping cart and abandoned it and then you get an email from someone saying hey
You put this stuff in your cart
Like can I give you a 10 off so you'll go buy it?
You're seeing a prescriptive model saying how often do I tickle this person now that they've shown some interest to increase the likelihood of completing a sale
There's no humans involved. It's all software
But they're now running these prescriptive explorers to say how often should I hit them?
Given a thousand people did that and I emailed them this way. What was the response rate?
Whatever email in this way. What's the response rate? That's automated now. That is prescriptive analytic models
Now obviously in the e-commerce sale there's one side
But you're also seeing the same models used for things like when should you evacuate a town for a forest fire?
If I wait till it's obvious that the fire is going to hit the town
Now I risk people's health
In the crisis of trying to get them out or is it better at a low stress level to say let's move them early
It'll cost us less the chance of them being injured killed is lower
And then if the fire goes the other way it's not that big of a deal, right?
We're still building prescriptive models to explore the psychological effects of emergencies
And being able to act more effectively to protect people
We can also make video games
So this is one of the open ai models
In the early days where you would describe a game
This is someone making a bad version of asteroids and it would spit out code for you
This is not that exciting anymore. Most people have played hopefully with co-pilot now
A whole other way to pull up code. You don't understand you used to have to use stack overflow for this
But now you can do a machine learning model. So there's fewer people saying that's a dumb question
Uh
I'm concerned with the training set
We've done a couple of great shows around this with folks like michelle manning where we
You know, it's maybe generating code that works, but isn't secure
Or isn't you know reliable
They've trained it against all of the open libraries on github and that doesn't mean that means it's only as good as the code
That we put into github some of the code I put into github. I'm not proud of
Uh, so it is interesting to say how can they improve this to say hey, I only want highly secure code
That's thoughtful of all of those kinds of things. Uh, they're now starting to stick language onto this
So now you're going to talk about what code you want to write
And the vp of the power platform charles lamanna announced they've made a version of co-pilot for power platform
So, oh you had a no code solution where you're draggy dropping the form too much work. Just say make me a form
All right now use the image recognizer show them a copy of the paper version of the form and it comes up
So those are machine learning models for programming. There are tools for us to use
The whole we will all be replaced by this is silly. It always was silly. It's only getting sillier
The longer we use these things, but if you don't use them in your routine work
You kind of miss it out. It's an accelerant
There's no excuse for not understanding the code you're putting your system
So the idea that this is an you're already you were using google
Sometimes you're using stack overflow. Why wouldn't you use co-pilot to pull up code and then evaluate that code?
It's easier than a blank screen. It's at all anything we can do to get ourselves moving on a given problem space
But it's still our discrimination
The tool does not know that this code is right. All it knows it is it fit the criteria you described to it at the time
That's as much as know with some percentage of probability. Hopefully in the high 90s, but not always
And chat gpt about the same thing right there. I call it a dunning kruger accelerator
If you know nothing about a topic chat gpt is awesome
As soon as you know something about a topic and ask chat gpt bim, it's not that awesome
Not actually concerned with facts
What replaces the smartphone
I mean the smartphone is dominated. It's not the primary computer device, but it's kind of mature
you know
The phones get bigger they get smaller they have one camera two cameras three cameras way too many cameras
But they're kind of the same they're a slab of black glass
We're kind of ripe for disintermediation. The obvious device is some kind of ar headset
Right is some pair of glasses that we can put on that puts the data directly to our eyes
It does everything the phone does without having to pull it out
All right, and actually gives us a bunch of other capabilities because now we have instrumentation on our head
So it can observe the world around us because we're not paying attention
And that offers a bunch of possibilities that being said 2023 not a good year for ar
Apple's just announced. This is a mock-up of what we thought apple was going to make
It's all a lie and currently apple says they're not making anything they backed off
So whatever prototypes they were working on internally, they're not happy with them right now
There are commercial products that are glasses with devices on it. This is a qualcomm device called the xr1
You can buy this today. It's about thousand bucks. It's tethered to an android phone
And it's just a usb headset that has microphones and speakers and cameras and and
And screens integrated into it and you're seeing these used in certain commercial applications
If you want to look more like google glass, you can do this with the toshiba devices
This is the dinah edge. So I want one eye a little more industrial looking
Okay, this hardware exists
There is hololens, but hololens is not in a good place if I was this is the tremble version of hololens 2
This is the one they wanted to put on all construction workers because construction workers are good with equipment
um
At 3 000 bucks a piece plus about a thousand dollars a month in operating costs
When I when we started doing some case studies on implied hololens products
I was stunned at how much azure eats to operate it properly like
Now for certain markets that makes perfect sense construction site not so much
But if you've been paying attention to the recent round of layoffs, you know, they've pretty much laid off the entire hololens team
The leader of the hololens team a guy named alice kipman left microsoft back in july
So they've been a little bit leaderless for the past few years then the army announced they shut down there
They were going to shut down a project. They want to do more research on it
And then these round of layoffs came so it looks like the hololens is an orphan for the moment
I mean the opportunity in certain verticals is really interesting the you know industrial applications where
Basically equipment becomes transparent checklists are live
You're making continuous video record of the maintenance that you're doing. These are all interesting applied cases
I looked at this very much as the
That the ar glasses were in the same place that the blackberry phone was in like the 1990s
In the 90s if you want an email on your phone. I know crazy
You had to buy these a thousand dollar phones in the 90s
From from rim called the blackberry and had a little keyboard on it and you had to run a custom version of exchange server
Inside of your organization to make it work
So you need a couple of guys in lab coats
And a whole ton of licenses and you too could have email on your phone
And it was so popular in the 90s. They called them crack berries
But it needed to be the right vertical it needed that cost had to be worthwhile that continuous access that person was important enough
Right, you saw it on like the west wing
Right the politicians and bureaucrats needed this sort of thing
And of course today email has been completely commercialized. It's in every device. It's not a big deal
But I look at hololens and the ar devices that way for the right vertical where you can afford that
Expend is trivial to its value totally makes sense consumer device. No not there yet
And we don't know when we will be it's an insanely complex device now the hololens two is six years old
We never saw the hololens three
So the tick tock of moors law still applying we should be able to get dramatically better headset
We're just struggling for the applications for
I'll make fun of meta very briefly. It's not hard to do anymore. It was funnier a couple of years ago
I we would have said hey zuckerberg created the largest loss of value in all time
He burned through 10 billion dollars in a year
but then
I mean facebook was a trillion dollar company now it's a 300 billion dollar company well done
But then you know, let's look at twitter or tesla
My billionaire is messing up their companies seems to be a style. I presume it will pass
Uh, these headsets are compelling. This was really john karmack the guy behind oculus that got acquired by facebook
Who has now put down his his laptop and go okay? I've had enough people and he's left now too
So any sense
That facebook's along between Cheryl sandberg leaving and azure and and and karmack leaving
Zucks by himself
And I think fairly far off the rails microsoft seem to be playing ball
They they wanted the team's version of this with the new the quest pro the 1500 dollar headset in the horizon workspace
They've now backed away from this
So this is kind of a dark time in general
We're kind of for ar and vr if you are interested in developing in this space
The obvious tool is unity like the bulk of development being done in this space is done in unity. It's c-sharp centric
It's its own custom build essentially if you've never played with this it's an experience
And I recommend the tool often to kids who think they want to make games
Because you can do a few watch a few videos use the free version of unity and you can do a lot
You can make a pretty straight forward side scroll and have an experience and then start to think more profoundly about the challenges of writing games
But a lot they but unity has going forward is a really good set of 3d libraries
For making it easy to do all of that three-dimensional work
Okay, one last topic and then we'll wrap up
Um quantum computing because people love it
So quantum computing is a kind of super computing. It's not likely to be
A regular general purpose computer. It's for super compute problems
So the same way that we build these titanic supercomputers for modeling weather and things
These are the kinds of problem spaces the quantum computers good at
There are a number of companies that are building a variety of different styles
Of quantum computers this to me likens very much to the late 40s early 50s
in general computing before the development
Of the of silicon so every computer is kind of bespoke. This is the sycamore computer built by google
It has 54 cubits. It was the first to achieve quantum supremacy where it worked on a particular problem
That was considered thousands of years of compute in traditional computing
That's questionable. My favorite part of that story was it's a 54 bit
Quantum computer except one of the bits was broken on performance day. So it was a 53 cubit cubit run
This particular design of quantum computers
Is what they call
Transmon quantum processing. So this is kind of this is a way of doing quantum entanglement with ultra cooled
material they cool in the liquid helium
Which is dangerous
The chinese have a photonic quantum computer. They had up and running in about 2020 with 113 entangled cubits
They did a boson sampling compute in 200
Seconds that would have been multi billion years of traditional compute
It was a known problem. It's kind of a proof point. But again, these are
Getting there and then ibm's eagle and osprey and condor architectures
in the 100 to
120 or so cubits that one was in benchmarking in 20 late 2021 2022. We haven't seen the results from it yet
They were promising by last year to have a 400 cubit
Processor that hasn't materialized yet and this was supposed to be the year they produced a thousand cubits. That hasn't happened either
But the real question is what the hell are you going to do with this thing?
Like the only thing you ever hear on the news is the end of security that we're going to be able to break
Our say encryption, which is true
Kinda in the end encryption strategies that use prime number these very large prime numbers are susceptible
To the compute strengths of quantum computer if you have four or five thousand entangled cubits
You should be able to crush through 128 digit primes
in a matter of seconds
We don't have to use prime based encryption
There are other kinds of encryption in fact and the nsa is currently recommending that we switch to lattice based encryption
It's just not as efficient
To encrypt with other kinds of encryption strategies. It turns out the computers are good at prime numbers
It's a cost effective ways to do encryption as well as decryption
So
Forget the encryption problem solvable not interesting
The most interesting problems in the quantum computing space are actually chemistry problems and the classic one for me is in agriculture
So in the pre technological era if you wanted to grow crops routinely if you were planting wheat
If you kept growing wheat in the same chunk of land year over year
You got less and less wheat because you depleted the soil you had to rejuvenate the soil now today in an industrial world
We have the Hayrabash process where we make industrial fertilizers and after you have a season of growing wheat
You then fertilize the stod out of that land and repopulate that replenish the soil to grow wheat again
But before we had that we rotated crops
And there are bean plants typically that has a rhizome on it
That lives on the roots and inside of that is an enzyme called nitrogenase and nitrogenase
Naturally affixes nitrogen
It takes water and nitrogen from the air and in a catalytic reaction turns it into ammonia
So in the normal crop rotation you would grow a crop of beans you would harvest the beans
You plow the plants under and then you let the land go fallow for a year
You let those roots rot and they were to release fertilizers back into the soil
And then the third year you can plant wheat again. That's the
Traditional non-technical way to do it chemical fertilizers avoided that but chemical fertilizers have their own cost
All right, they're about 1 of the energy consumption of this planet is based on making distributing fertilizers
So if we could utilize this thing that a bean plant could do
We could have a significant impact on agriculture
The problem is that the catalytic reaction that goes on inside of that enzyme
involves atoms of molybdenum and iron
And it's a 2 to the 170th complex problem to understand the electron interaction
Which is like more atoms that are on the than that are on the earth
A mid-sized quantum computer something in the 400 qubit range should be able to solve this
Should give us an example of the correct catalytic reaction
That doesn't mean we'll immediately be able to implement it
But once you know what the reaction looks like you have a chance of now engineering an implementation of it
So that we could be making fertilizer directly from air
at low power plant power
And be able to grow food more routinely it's an interesting quantum problem
There are other quantum chemistry problems like that battery design is largely based on experimentation
Not on our actual understanding of the interactions of the compounds
What we have done in battery development today has gotten really good at iterating on trying different combinations
Not actually understanding the optimal combination. It's a quantum computing problem
Modern superconductors the Rebco superconductors, which are made from rare earth materials and baryon cupric oxide are ceramics
That are superconductive at liquid nitrogen temperatures as opposed to niobium Tim, which is superconducting at helium temperatures
Which is way harder to deal with we've had these superconductors for about 40 years
Which just don't really understand how they work
And so it's hard to make better ones and again quantum computer quantum chemistry problem
These are all deterministic problems. So the real question is how many quantum computers do we need?
Because once you've solved it you kind of need to solve it again, right?
It's not a non deterministic problem where you need to do it every time like a weather problem
It's just a deterministic problem and it reminds me of of uh
Of thomas watson's statement when they were first building mechanical mainframes for the original version of IBM
Where he told his board
I think there's only a market for like five of these and then they went out selling and they sold like 25
And it was a revelation, but that was because back then the computer looked like this
Right, this is before
Intel this is before
The silicon transistor you've your computer looks like this
You can't envision a smartphone like you can't see it from there
It's it's too hard
The first transistor ever made may in bell labs the geranium transistor looked like this
It's pretty hard to look at that and make m1 chip
All right, it's a big jump
So going back to that mainframe
What made traditional computing useful was the integrated circuit. We suddenly had a stable reliable way to make bits
We made ram and then we made processes for them. They were consistent and we could scale them and Moore's law took over
We got more and more potential compute
I described to you three different kinds of quantum computer today
They were all radically different because there's not a good qubit yet. Everybody's trying to make the right qubit
They're exploring their quantum computers are very much like these bespoke general computers from the 40s and 50s
And maybe that's what it's going to take the my favorite story of this whole thing is the guy one of the guys who made this transistor
guy named william schochli
He was also the guy who who then created a company called fair child simmer conductor and he tried to make and he made the first integrated circuits
And when he was trying to figure out the chem the chemistry was going to need to dope it properly and what the ratio should be and so forth
He used an old style mechanical mainframe to do the computation
And that gave him the models to be able to build the first integrated circuits that made far more reliable general purpose computers
I wonder if these flaky goofy
Unreliable quantum computers are building today or the compute devices will need to find the reliable qubit
I don't know the answer to that, but I like how the history rhymes. I do know this
When we're trying to predict the future the best way to do it is to make it and that's us we do this
We're going to go out and do some work
We're these next couple of days
We're going to do a bunch of learning and we're going to create the future and I can't wait to see what we make
Thank you for your time
