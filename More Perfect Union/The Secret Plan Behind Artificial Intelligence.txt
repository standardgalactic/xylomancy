I'm about to say something that you would never expect to hear from more perfect union.
Elon Musk is right about something.
Elon Musk is suing the maker of chat, GPT.
Suing open AI.
Suing open AI.
For breach of contract.
By putting profit ahead of benefiting humanity.
Elon's lawsuit against open AI, the most recognizable developer of artificial intelligence, was big news.
But when I heard it, I was a bit confused.
When has Elon ever been against profit?
So I dug it.
I read and I watched far too much of these guys talking about AI.
I think that AI will be a technological revolution on the scale of the agricultural, the industrial, the computer revolution.
AI is about to revolutionize digital biology and genomics and transportation and retail.
Artificial intelligence, this is, it is a renaissance.
This is a world-changing set of advances.
By the time these lawsuits are decided, we'll have digital god.
So digital god.
I noticed three things.
That the rise of AI is inevitable.
That it will change everything about our lives.
And that there's a war brewing between a handful of billionaires to seize control of it.
NVIDIA became one of the most valuable stocks of all time producing chips for AI.
Microsoft reached an over three trillion dollar valuation based on its AI work.
And open AI tripled in value in just ten months.
But where do we, you, and I, and everyone other than the dozen or so billionaires duking it out for control fit in?
We're already seeing plans to replace human nurses with AI.
Media magnates killing jobs to focus on cost cutting with AI.
AI written drivel filling the internet.
And AI that does karaoke for you.
But let's look at the possible AI future.
Through the rise of Sam Alman, CEO of OpenAI.
And just one contender from the billionaire battle for the future.
Sam Alman is the ruler of Silicon Valley startups.
And that's not me saying that.
He thinks that.
I think the president of YC is sort of the unofficial leader of the startup movement.
YC is Y Combinator, a significant venture capital firm and tech incubator that Alman ran from 2014 to 2019.
He'd originally connected with YC in 2008.
When the firm funded his app, Loopt, when he was 19 years old and wore two popped collars.
Loopt was a common Silicon Valley story.
They raised a ton of money, gathered a bunch of data and got in trouble for texting everyone in your phone when you downloaded the app.
Alman sold the company and it all but disappeared.
Alman landed at Y Combinator where he rose to president in two years.
Under Alman's leadership, Y Combinator invested in massive companies most people have heard of.
Like Reddit, Airbnb, Coinbase, Dropbox, Stripe, Twitch, DoorDash and Instacart.
In a lecture to Stanford computer science students on startups, Alman quoted Peter Thiel's advice.
As Peter Thiel's going to discuss in the fifth class, you want an idea that turns into a monopoly.
But you can't get a monopoly in a big market right away.
You have to find a small market in which you can get a monopoly and then quickly expand.
Quick expansion is an inherent part of the way venture capital funded tech runs today.
This is Tim O'Reilly. He's been in tech forever.
And if you know phrases like open source or WEM 2.0, it's because he popularized them.
One of the big problems with today's Silicon Valley is that it no longer really supports remarket competition.
Early days of VCD, you are really talking about funding insurgent companies that had an experimental idea.
Most companies didn't actually raise massive amounts of capital.
But at some point that changed.
But then you fast forward to 2010 in the wake of the look super low interest rates.
There's all this cheap capital and companies are just buying market share.
And I call this the Uber problem.
We didn't see real competition with different business models, different pricing.
We saw two heavily capitalized companies driving everybody else out of business.
By growing rapidly with a bunch of capital, Uber created an ecosystem where if you want a cab, you need to use Uber.
The old system of car services was pretty much pushed out of existence.
Uber is not an Altman company, but DoorDash, Airbnb and other companies that used similar strategies totally are.
In 2015, we get our first hint of open AI.
I actually just agreed to fund a company that is not even really a company, sort of a semi-company, semi-non-profit doing AI safety research.
Open AI is announced as not a company, but a non-profit focused on AI safety.
Funded and supported by Y Combinator, Elon Musk, Reid Hoffman, the LinkedIn guy, Peter Thiel, Amazon and Infosys.
Basically a who's who of the people who built the broken tech infrastructure of today.
The stated goal of open AI was to advance digital intelligence in the way that is most likely to benefit humanity as a whole, with no shareholders to be beholden to.
We wanted to build this with humanity's best interest at heart.
That doesn't sound too bad, right?
A groundbreaking new technology?
It's power available to all without any responsibility to shareholders?
But let's dig a little deeper.
They say they want to make the world better and do it safely, but where does that mean to them?
Most of what Altman talks about in regards to what open AI's products can do seems to center on productivity, efficiency and margin boosting.
Our ability to have amazing ideas for our children to like teach themselves more than ever before for people to be more productive.
How does that make life better for the rest of us?
Well, Altman claims to have the answer.
In his essay, Moore's Law for Everything, he explains it would require simply changing the entire economic system.
Altman claims AI would drive down labor costs so everything would get cheaper.
And the lost jobs would be offset by a universal basic income coming from corporate and property tax rates, with no other taxes.
Which sounds great, maybe.
But how true is that?
Would corporations see falling labor costs and reduced prices or just keep the profits for themselves?
Would a flat tax and UBI mean more money for working people?
Or more tax cheating by the rich and social service cuts for everyone else?
And there's a running theme through all of what Altman says, the inevitability and the danger of artificial intelligence.
Listen to this clip.
You know, I think AI will probably like most likely sort of lead to the end of the world.
From the narrative that AI is this big scary thing, even as they're the ones trying to build and profit from it.
Here's Tim O'Reilly again.
To accelerate it so they can get a monopoly.
It's a lot like the famous line from The Wizard of Oz.
Pay no attention to the man behind the curtain.
And a lot of what I spent my time in talking about AI regulation is this.
There is a man behind the curtain or a series of men who are making decisions for their business advantage.
And those are the things that we need to be regulating.
Why are they moving fast to break things?
I mean, in the Altman except from before where he says the world ending thing, he literally says this right after.
You know, I think AI will probably like most likely sort of lead to the end of the world.
But in the meantime, there will be great companies created with serious machine learning.
Companies? See, it's right back to profit.
But hold on, isn't open AI a non-profit?
Not anymore.
Just three years after the founding of open AI, they transitioned to something they're calling mixed profit.
To do what we needed to go do, we had tried and failed enough to raise the money as a non-profit.
We didn't see a path forward there.
So we needed some of the benefits of capitalism, but not too much.
And the new board of open AI is rife with the profiteers who've been extracting value from working people for decades.
They're also not open.
None of this stuff is just simply available.
Sure, an old version of chat DBT is free and kind of fun sometimes.
But open AI's real product is enterprise software doing partnerships with other giant tech companies
and loads of stuff we don't even know about.
Defense contracts included.
Open AI has a product to sell, a product they see as having inevitable near universal proliferation.
Which is a pretty damn good business plan, but it's dangerous for the rest of us.
Here's what Tim O'Reilly said about the Uber problem.
Here's how it applies to AI.
All of the smaller AI firms are already starting to fold because there are a couple in the form of open AI and Anthropic
that are incredibly heavily funded that have tens of billions of dollars of capital.
And we don't know that they're the best companies.
We just know that they're the ones that big investors picked up early.
And so we have a defective kind of market where if you really believe in the wisdom of millions of people
making independent decisions based on optimal information to kind of work this re-magic market,
we don't have that.
We have a central committee of deep-pocketed investors.
It alluminates Elon's lawsuit against open AI when he and Altman had once been such good friends.
I'm looking for a new video game play. Can you give me a recommendation?
Overwatch. After Overwatch.
Yeah, that's great.
I named it Open AI after Open Source.
It is, in fact, closed source.
It should be renamed Super Closed Source for Maximum Profit AI.
But he has his own for sale, for profit AI that he wants to be predominant.
He made it Open Source in a seemingly empty gesture,
but meanwhile Nvidia, Microsoft, and Google all want to take control of the tech
that will change our future and destroy our jobs.
It doesn't matter that these guys say they're doing it for good.
It matters what they are actually doing.
Look at the dom of the internet itself.
Or Web 2.0. That's social media and user-generated content.
All of that seemed great.
And yeah, the modern internet has obviously had a lot of clear benefits,
but it was also pretty quickly ruined by giant corporations and profit motive.
We're already starting to see effects of the AI power grab.
Nvidia, the main producer of the chips used for AI,
is partnering with a company that wants to replace nurses with an AI that costs $9 an hour.
Look at anything from the history of the American medicine industry.
Will a new low-cost tool actually help patients or just pad investor pockets?
Companies are using AI to do job interviews, and it's shutting out applicants unfairly.
And on a simply annoying level, they're spitting out content
that's making the internet even more unusable than it already was.
AI generated LinkedIn comments?
Why don't you just not post anything if you don't have anything to say?
So what are we going to do about this?
Well, let's turn to Sam Altman for advice.
He has what he calls the more good guys than bad guys approach.
He wrote in that Moore's Law essay,
There are bad humans, but all humans are within a magnitude are as powerful as one another.
And the good humans band together to stop the bad humans.
It's been that way through all of history so far.
What if the bad humans are actually the people building the system?
One built entirely on fast profits and monopoly, advancing as quickly as possible.
Then we need more good guys, and we've got them.
They're like 12 people.
What if we all stand up and say no?
When electricity was first becoming widespread,
it was still dangerous for the low-paid workers who were setting up the systems.
But those workers stood together and formed the International Brotherhood of Electrical Workers,
that's the Electricians Union, to demand safer jobs and better wages.
It worked, and it didn't hamper progress.
We clearly have electricity today, right?
That same concept applies to AI too.
Remember the writer's strike?
The screenwriter's guild stood up and said no to AI taking their jobs.
Senator Bernie Sanders just introduced legislation for a shorter work week.
Do we continue the trend that technology only benefits the people on top?
Or do we demand that these transformational changes benefit working people?
And one of the benefits must be a lower work week.
If AI is going to make workers more productive and labor cheaper,
workers should be able to take advantage of it.
AI cannot exist without being trained on all that humanity has done before.
That's literally how chat GPT, the way most people interact with AI, was built.
By reading a bunch of stuff online and then synthesizing it so it can talk.
If all of this is built on the labor of all of humanity,
then it should be all of humanity that benefits.
Thank you so much for watching.
To support more human-written, human-edited, human-shot videos like this,
please don't forget to like and subscribe.
