All right, hello everyone.
Welcome to AME HQ.
For those who I haven't met, my name is Cam Linky.
I'm the CEO here at AME.
And we're pleased to welcome everybody today,
both to our office here and to our friends
who've tuned in online on the live stream.
Many of you probably know about AME,
but for those who don't, AME is one of Canada's three
National Standards of Artificial Intelligence.
We're tasked with advancing Canada's AI potential
and we're proud to collaborate
with the University of Alberta
on driving AME's AI research excellence forward.
We're really, really excited to have everyone here today
for this special announcement
from our Chief Scientific Advisor, Rich Sutton.
Before we get started,
we'd like to respectfully acknowledge
that we're on Treaty Six territory,
a traditional gathering place
for the diverse indigenous peoples,
including the Cree, Blackfoot, MÃ©tis,
Nakoda Sioux, Hadnashone, Dene, Ojibwe, Sotu,
Anishinaabe, Inuit, and many other peoples
whose histories, languages, and cultures
continue to influence our vibrant community.
And it's in the spirit of that exchange of knowledge
and of that gathering that we're excited
to welcome everyone here today.
At AME, we're really excited to support our friend
and mentor, Rich Sutton.
There's so much that could be said about Rich
and the pioneering work that he's done
in reinforcement learning and AI.
The span of Rich's impact is almost hard to enumerate
from his dedication to fundamental research
and the advancement of the science of AI
to his efforts to train the next generation of AI researchers.
His book, Reinforcement Learning and Introduction,
has both educated and inspired scores
of graduate students and beyond,
and is one of the most approachable people in the field,
always having time for researchers,
for curious observers, and for everyone in between
to sit down, have a discussion, discuss reinforcement learning,
discuss our official intelligence.
He's one of the people that, while many people
have already left either the party or the conference,
Rich will be in the corner somewhere
having a conversation with someone
about reinforcement learning,
about some nuance of the field.
And one of the things we talk about here a lot at AME
is approachability, and that approachability
is something that we've really been inspired by Rich from.
And speaking of pioneers, the guest I'd like to invite up
with Rich has trailblazed multiple fields.
Among his list of pioneering accomplishments
are co-founding id software, and his leading work there
in computer graphics and computer gaming
created an entire genre of gaming.
Since then, John's also known for his work in rocketry
and ushering in a modern era of virtual reality
with Oculus Rift.
So we're so excited to have them both here at AME HQ,
and everyone, please join me in welcoming John Carmack
and Rich Sutton to the stage.
Thank you so much, Cam.
It's a delight to speak to you all this afternoon.
Today, I am pleased to announce the formation of a partnership
between John Carmack and myself
to work directly towards the challenge of understanding
and creating an artificial general intelligence
based on reinforcement learning and neural networks.
The partnership will be embodied within Keen Technologies,
which is a startup that John created about a year ago.
And as of today, I am an employee of that company.
Of course, I will continue as professor
at the University of Alberta,
and as the chief scientific advisor at AME,
the Alberta Machine Intelligence Institute
that you're all here at.
So I'm very excited to be partnering with John.
John is the world's preeminent developer
of complex high-performance real-time systems.
His skill and brilliance was first demonstrated
in technical innovations in 2D and 3D graphics
and in computer games, such as Doom and Quake.
His engineering skills were honed on rockets
at Armadillo Aerospace and by his work
on immersive virtual reality at Oculus.
Roughly five years ago, John turned to the challenge
of artificial general intelligence
and that eventually led to Keen.
Now, when I first learned about John and Keen earlier this year,
I was struck by how aligned we were, I was with him,
despite having done this all my life
and John just turning to it a few years ago.
There are many aspects to the way we are so strongly aligned,
but let me identify just four of them.
We both strongly felt that the field
of artificial general intelligence
was dominated by too narrow a set of ideas.
This was groupthink and this groupthink was to be avoided.
We both strongly felt that trying to make money too soon
was like an off-ramp on the road to AGI
and we needed to keep our eyes on the long-term prize
of full AGI, eyes on the prize.
And number three, artificial general intelligence
is not too complex for one person
to understand the principles of it
or even to write the code for it.
That's an important part of our alignment.
And finally, 2030 is a good target.
To have a success, to have a prototype AGI,
to show signs of life, we're a toddler,
as John likes to say.
So John and I are really well-aligned
and but there's a sort of an elephant in the room
and it's become clear.
Keen is a small team, the entire technical team
of Keen Technologies is here today
and it's John and me and Gloria and Lucas,
if you could stand up.
And also Joseph, who's we expect to join us
by the end of the year.
And now all these Keen people are now part of our community.
And could you all give him a good Alberta applause?
Whew.
Thank you for that.
So the elephant in the room is that this is a small team
and other companies have thousands of technical staff
and they're spending billions of dollars on AGI.
It's truly audacious of us
to think that we can make a contribution, but there are actually, it's audacious of
us to think we can compete with them, and we think we can or at least we can make a contribution.
There's much to say about why that might be reasonable to think, and I'm going to refrain
from trying to explain it, but I will only remind you of what Margaret Mead said.
She said, never doubt that a small group of thoughtful, committed people can change the
world.
Indeed, it is the only thing that ever has.
Now I'd like to turn the floor over to John to say a few words.
The legendary John Carmichael.
So a couple months ago, I got an email from Richard Sutton.
Well, this is cool.
So I am relatively new to the artificial intelligence field, and when I started kind of my larval
phase as I like to call it, where I just inhale all of the relevant information in kind of
the first year, one of the very important references for me was Richard's book on reinforcement
learning.
And in fact, I later went through the first half of it again with my son doing exercises
just a couple years ago.
And of course, I referenced the bitter lesson all the time as one of the deep fundamental
insights to the kind of broader effort of everything that goes on here.
So I'm Richard was trying to figure out I'm kind of like how he should be pursuing his
efforts towards research across different options in commercial, academic and nonprofit.
And I wanted to be super helpful.
I hooked him up with a few other people and I tried to kind of give him whatever help
that I could.
But I did very tentatively kind of broach the subject that, all right, you're the Godfather
of reinforcement learning.
You can write your own ticket anywhere you want to go work.
But there are some downsides to especially larger established organizations, and you
may get access to lots of resources and still have the freedom to do whatever you want.
But there are problems with culture and direction, kind of strategic direction in other areas.
That's why as fired as I was when OpenAI tried to recruit me, I respect all that they do,
but they've got their plan, they've got their directions, it's not really what I'm doing.
And there began a little process of kind of feeling out, well, exactly how do you feel
about certain of these directions?
Like what are the odds of technologies going this way?
How important is this?
How important is that?
And it turned out that we really did have a remarkable amount of overlap in what we
think is possible, what we think the remaining challenges are.
And to be clear, nobody has line of sight on the solution to this today.
But we feel, and a number of other people, that it's not that much left.
There are things we don't know, we don't know how to get there, but they all feel like the
same scope of things that mattered in this last decade.
They're relatively simple things in the way that you set up your architectures, the way
you do your training, the way you query it in different ways.
And I certainly think that in 30 years, when the textbook of artificial general intelligence
is written, it's going to get digested down to a chapter that people are going to be able
to understand.
We just need to figure out what those sort of core ideas are.
So it was really still to my great surprise, but immense pleasure that we have decided
to go ahead and work on this together.
So Richard is working at Keen Technologies now.
He's in our workplace, and we spent all day today basically talking about the plan of
research, how we want to start figuring out what we're going to be doing.
So this is incredibly exciting for me, and would you like the same thing else, Richard?
Thank you, John.
I think now we'd like to take questions from the media, and we'll use a mic.
Good.
Okay.
So we're going to open up the floor for any media questions.
For the media in the room, if you have a question, please come over here.
And for media on the line.
So operator, please open up the line for the first question.
Oh, there's no media on the phone.
Any media questions from the room?
Oh.
Hi, I'm Renali Unchin with CBC Edmonton.
So following this partnership, I'm wondering if you could talk about some of the tangible
steps that are going to be taken to kind of develop AGI more.
So one of the big points that we do have alignment on is that there's not a near-term
offer answer, where there's not going to be a chat GPT-like deliverable that goes out
and mows the world, where there are fundamental research questions that need to be answered.
And this is me learning how to be a researcher, and hopefully I'm learning from Richard a
lot about that process.
But we have internal projects and angles of attack on things, but they probably will not
have a lot of publicly visible effects for likely years, and we are fairly aligned on
this sort of, we are seven-ish, six, seven, eight years out from something really big
and important being publicly visible.
That's perfect.
Next question.
Yeah, I have a follow-up.
So for the average person, obviously there was a lot of terminology thrown around.
Why should the average person care about this, if you can describe in the most simple terms?
I would say the average person probably shouldn't care a whole lot about this.
This is something, this is inside baseball work for people that are in the field.
A lot of people are going to be geeking out about this, where Rich is a big name, big
percentage, and I'm a big name in a very different field, and we're kind of coming
together, and I do think there's synergistic benefits for that, and it's kind of exciting
just as a two-great-taste-taste-great-together sort of mix things up between the different
backgrounds.
But no, I mean, I don't want us to try to make this out to be something that the man
in the street should actually care about.
It may yet lead to one of the most important things in the world or in history, but there's
very little guarantees about any of that, and that's the benefit of the way we're financed
and the way we're structured right now.
We don't have to have a rush to a product.
We don't have to have a rush to make sure that there's an investor return in a very
short amount of time.
We can concentrate on just trying to answer these critical important questions.
Okay.
Cool.
Great.
Any other questions?
Fantastic.
That concludes the Q&A portion of the program.
Oh, yes, Rich.
If we're done, I have a few things I want to say.
Please.
Before we close, I want to thank Amy and the University of Alberta for their help today,
particularly Stephanie Enders and Laura Carter and Cam and Linda Vang, and express my appreciation
for the entire Edmonton and Alberta community for all they do in creating the rich intellectual
environment in which I and this part of Keen can thrive.
The community has supported fundamental research in AI for 30 years before I came here, and
this is bearing fruit now in Amy and in industry and startup companies and more fundamental
research results.
Please join me in a huge round of applause for Amy and for yourselves, the entire AI
community.
And with that, I want to turn the floor over to someone else.
Cam, there you are.
All right.
Well, thanks everyone.
I have a big round of applause for Rich and John again.
So thank you, everyone, for joining us today.
That concludes the program for the announcement.
We're going to reset the room for the fireside chat.
So if everyone can do us a favor, I know this is a pain, but we need you to all leave the
room, continue the conversation.
Everybody can have their favorite conversation about what took place here today.
Head over to the co-working space in the cafe.
We have food and drinks and caffeine to really amp you up for this next portion.
If you've RSVP'd for the fireside chat, we'll re-admit you shortly.
So please do us a favor, move over there to our beautiful space, and we'll see you back
here shortly.
Thanks.
All right.
Okay.
We're going, welcome to the second half of the show.
If you can do us a favor, if you're on the edge of the role, please squeeze into the
middle.
Help as stragglers come in, not doing this, excuse me, pardon me, excuse me, pardon me,
and distracting the speakers, or just me.
So do me a favor, squeeze into the middle, help us out.
Thank you very much.
Get close.
Get to know your neighbor.
Welcome back.
For those who missed the earlier part of this, I'm Cam Linky, I'm the CEO here at Amy.
We're excited to welcome back to the second part of our doubleheader with a special fireside
chat.
The host for the night is well known for his hate of, love of games, love of games, yes,
loves games.
An Amy fellow, Canada CIFAR AI chair and full professor at the University of Alberta, Mike
is best known for his work in poker, most notably solving the game of heads up, no limit
Texas hold them.
In 2015, and for DeepStack in 2016, the first AI to beat human professionals at heads up,
no limit Texas hold them.
I think I made an error in there that Mike's going to correct.
He's glaring at me.
We're so excited for Mike to be our host and to host our special guests tonight.
And so I don't make any more errors.
Please welcome Mike Bowling to the stage.
Thank you very much, Cam.
I'm sorry.
I do have to correct you.
So we, we did essentially solve heads up limit.
And we beat the first profession, first to be professional players of heads up, no limit.
Okay.
But you're not here for that.
I get to have the great honor of, of introducing John Carmack.
Many people have already said wonderful words about him, but maybe you weren't here for
that.
I'll, I'll just say that he's, he's a pretty big deal, maybe a BFD, if you will.
But I'll just say my first connection to John was probably my first memory of seeing something
really innovative was thanks to John.
Because if you're really young, you, you can't see innovation.
Everything is new.
You didn't know what came before.
So you don't know this change things.
And when I was 17, I went to a gaming convention and they're sitting was a rows of computers.
This wasn't even a video game convention.
It was board games and, and real playing games.
And they're sitting was a rows of computers with Wolfenstein 3D running on them in the
summer of 1992.
And my mind was blown.
So thank you, John Carmack.
And welcome to stage.
Welcome John.
Thank you.
It doesn't seem to be on.
Can we do something?
Oh, I'm supposed to push the button.
Okay.
Yeah, when, when I was asked to do this, I was trying to think through.
I felt like I had a lot of pressure on me to ask you really insightful questions for
the audience, but I decided I'm going to kind of almost ignore the audience.
I'm just going to ask you the questions.
I feel like I want to ask you totally selfishly.
And I'm going to hope because I have a love of games, you know, I have a love of innovation
and I have a love for AI that maybe these are the questions that the audience wants
to hear too.
But so I want to walk you back to the, the, the beginnings of, of Id and Wolfenstein 3D.
And maybe you could say some words about how, how did you even end up at that place?
And then I want to turn around and talk a bit more about innovation from there.
Yeah.
So it did, I, games were super important for me in my childhood, you know, I loved the
arcade games.
I loved the early eight bit video games and the tabletop games, all of that.
And so it did seem obvious to me that this level of computers that I had that the best
way to express it was through games.
Now it is important to kind of differentiate a little bit there where there are a lot of
people that go into gaming and they learn about computers so they can make games.
And it was a little more fortuitous for me because I had this intrinsic love of computers
as well.
And I probably could have been happy and found interest in doing more mundane things, but
the games were there.
They were the obvious place and it turned out to work, you know, really well for me.
And so I had been, you know, for the first time I could do anything on a computer.
I was trying to write games.
I was trying to, you know, at first mimic some of the other games that I would see.
The first, the early text adventure games, writing my dungeon crawlers, you know, kind
of inspired by wizardry and Ultima and the early things like that.
But as I got to be a teenager and I built the assembly language skills and started figuring
out how to do the sort of the real world things and I had a talent for it.
I got good at it and I had decided that I wanted to actually try to make a living making
games and there was, you know, there was a lean year there of barely scraping by doing
contract programming work before I accepted the position to come down and work at soft
disc publishing where I met the other founders of id software and we started out making our
initial side-scroller games, which was Commander Keen, which I have kind of harkened back to
with the name of my latest company with Keen Technologies.
But then we, you know, we really broke out and kind of made our name with the 3D games.
And I always did kind of look at that as it wasn't, the games were the same things that
you could do in 2D, but the change in perspective of going to 3D, it made a qualitative difference.
Even if sort of symbolically it was the same game, but it made a great difference in the
impact it had on people.
Tell me more about that jump to 3D.
Was that intentional where you, like I could think of so many ways this could have gone
where you could have just been like, that seems like a hard challenging computers problem.
And so I'm going to solve that versus feeling like this is the future of games.
So we need to innovate in that front versus not even realizing maybe that you were being
innovative.
Like how did that work?
Now I knew I was heading for that from the early 80s.
I am, you know, as a, you know, even as a young teenager, you would see the representations
of 3D graphics or in the movie and you think about, you see Tron or you see 3D animated
logos.
I can remember making a little wireframe MTV logo spin around on my Apple too, kind of
figuring out these basics and looking back, like I didn't know how to do clipping at the
time so nothing can get close to the edge of the screen.
It just has to stay in the center and rotate around.
But that idea of wanting to be inside the video game.
I mean, everybody that's a gamer kind of got that sense of you want, you look at the game,
you play the game, you appreciate it, but how amazing would it be to put yourself inside
it and then, you know, see the enemies coming at you rather than looking down at it as that
16 by 16 block of pixels.
And that was magical and you could take exactly the same game and put the user inside it.
And that really followed on even more with virtual reality later on where getting the
sense of presence where you kind of believe that you're in this other environment.
So that was always a big issue for me.
But I do, you know, it is important to say that that's kind of the obvious visible thing
that stands out that there was a time period where there was nothing else like that.
But there are a thousand good decisions that go into making a game and it was never about
just the technology.
It was about doing those thousand things right, all the subtleties about how you feel, how
you move, how the guns react, what the sound effect is.
There's 10 things you layer on top of every action that happens in a game to wind up giving
it this really good feel.
And most of them will be things that people don't even notice.
I mean, everybody points to, oh my God, this 3D black magic that was going on that left
people, you know, just wondering how they could compete with something like that until,
you know, engine technologies got out there.
But there were plenty of other now forgotten games that wound up having flashy 3D graphics,
but people don't remember them because they didn't do all the other things, right?
I mean, I definitely remember the just smoothness of the original it games were just, I think
just blew people away.
Like it felt like you could play them as opposed to being pulled out of the immersion from
the clunkiness.
But that's also innovative technology, too, right?
That's some of the things that were actually subtle that were really important to me and
nobody actually called these out.
But in terms of the graphics, the way they were rendered, there were a lot of 3D games
that had this kind of non-solid feel to it where there are these subtle things that happen
to do with pixel centers and avoiding cracks between polygons.
And you can still make great games for that, like the entire PlayStation 1, you know, set
of titles was all done with this integer-snapped, affine-interpolated rendering technology.
You can do good things with that, but I always took pride in the solidity, the kind of sense
that everything was really rock solid there where some games felt fragile, like, you know,
you bumped the wrong way and you're going to slide through the wall, get caught and see
a flickering mess of stuff.
And for the most part, we took great pains to make that not happen in ours.
That's awesome.
Is there anything else that, like, you think, like, this was the innovative part, but in
the, you know, decades later, no one remembers that being the innovation?
Well, what was great is we had this period of, like, this five-year period during the
development, going from Wolfenstein 3D to Doom to Quake, and there were so many things
that wound up setting the tone for gaming for the following 30-something years and things
like the multiplayer gaming, the modding.
These were not the flashy 3D graphics technology, but they, you know, they were things that
were super valuable and it was happy to see people, you know, follow up on it, even little
things like having a console, you know, having the, you know, the override ability for the
different data sets.
There were a lot of decisions like that, you know, that worked out pretty well.
And I could imagine a world where 3D graphics was inevitable, it was being done on higher-end
systems, offline rendering, but it is possible to imagine a contingent set of history where
you didn't wind up with this action-oriented things because the dominant vision was you
do sims.
You do flight sims, driving sims, tank sims, you know, destroyer sims, and this idea of
this run-and-gun, really fast-paced action, twitch reaction, you know, whipping around
the mouse directly at inhuman speeds and all these things, that might not have happened
without idSoftware in the early days.
I wonder just, like, how much that affected the development, even get to where we are
today in terms of would, you know, we've seen gaming drive technology a lot, right?
So would we have GPUs today?
Would we be sitting on top of AI, on top of Dean Learning, sitting on top of GPUs today
if we didn't have those initial games saying we could have action-oriented, broader, open
games?
Do you think that's a possibility?
Yeah, so the GPU side of it is flattering you, but it's...
Yeah.
I mean, I do...
You know, it's one of those things where I smile and I'll talk about it a little bit.
I do take some satisfaction in the fact that the GPUs were largely built to play the Quake
series of games at the beginning, and then you had this great insight from, like, Jensen
at NVIDIA saying it's like, well, all these pixel processing things that we're doing,
we can do other things with them, and they had a lot of foresight to do the long game
investment in CUDA and give us the kind of generalized processing, because people were
doing general processing before that in this horrible way.
You'd encode your values into pixels, you'd draw a giant triangle that covers the screen
to do an array processing action on there, and it was, you know, it was effective a little
bit, but it was awful.
But the evolution of GPUs to where they are today as this quite general purpose device
that does underpin all of the modern era of artificial intelligence, it's nice to...
Even if I wound up not working in artificial intelligence, it would be something that I'm
proud of that I at least contributed at some point to that evolution.
I have one more question of curiosity from this time that relates to Wolfenstein itself.
So I played the original Wolfenstein games and Beyond Wolfenstein and loved them.
How did this...
Did you have that IP in mind, and then we're designing a game for it?
Did you have the game first?
What was the order of events and how did that come about?
So all of us that did, John, Tom, Jay, and I, we were all Apple II background people,
so we all had this background with the original Escape from Castle Wolfenstein, and it was
a game that had these, it was more what you today would think of as a stealth game.
You would sneak around, you'd wear guards' uniforms, you'd drag the bodies out of the
way, but it still did have that sense of shooting Nazis, and we had originally thought we were
going to do some alien-based game, calling it It's Green and Pist, just kind of a generic
alien shooter.
This was following up off of our kind of fantasy-themed Catacombs 3D, but when the idea came up that
it's like, well, what if we did Wolfenstein 3D?
All the good memories for us, it was playing the nostalgia card even for us at that time,
some 15 years after that was initially released, and back at that time, I look back and kind
of cringe at our business practices at the time.
We did not sort this out very well, we kind of just charged ahead and looked around a
little bit thinking, well, maybe the rights are clear, these companies seem bankrupt.
We eventually ran into Silas Warner, the original author at an Apple II convention, and he was
delighted to see Wolfenstein something.
Of course, he didn't own the rights, his blessing didn't actually mean anything from
a legal term, but to us, it felt good to have the original creator kind of bless our effort
in what we were doing there, and in the end, we got out of it unscathed, but that was luck
involved, I think.
Awesome.
Also, in the early times, I feel like it formed another aspect of your career, which
is your proponent for open source software, both in distribution models of how software
is distributed, we're pretty original in those early games, I'm wondering what's your trajectory
through that?
What's your thoughts about open source, say, then and now, and what connections are between
them?
Probably the most formative book of my teenage years was Stephen Levy's book Hackers, Heroes
of the Computer Revolution, and I read it dog-eared, and it had these major themes about
the hacker ethic and the kind of sharing of information and communal use of code in different
ways, and this was before open source became what it is today, or even before the Free
Software Foundation kind of had their mission and coined the term, so that was pretty deeply
in me early on, and it was fortunate that John Romero, my kind of co-programmer, had
similar feelings about it, that this idea that it's just amazingly cool to be able to
share the program to make it possible, where we had these memories of hacking the games,
like you'd get Ultima, you'd get your Sector Editor out, you'd find out, oh, that's my
goal, I want 9999 in there, and I always, I mean, I remember fervently wishing that
I could look at the source code for these things, to be able to go these games that
I adored that I spent a lot of time on, I wanted to see exactly how they were made,
and to get into a position as a small private company, where we owned all of our own IP,
the ability to kind of make that earlier childhood wish that I had had come true for a whole
new generation of programmers was, you know, it was very motivating for me, and it was a
drawn out process inside the company, because there's a huge divide generally between the
technical and the creative people here, where, I mean, it's not a judgmental side of things,
but just the technical people tend to get this sharing more than most of the artists
and designers do, where there's a lot more worry about chain of credit, and, you know,
where the work builds upon other people's work, so it was not fully understood by everyone
in the company, but, you know, a little bit of it was, I was able to throw a little bit
of my weight around in my position, and I know there was a little bit of hard feelings
for a while that I did something that there was thinking was bad for the business.
Is this related to the leak of the Quake source code, or are you talking about different?
No, just the open source in general, where there was this point early on where we had
released the tools for Doom, and the ability to do all of this, and a product came out
called D-Zone, which was a CD-ROM just full of hundreds and hundreds of maps, and the people
that did that actually made more money than we made on Doom 2, because we did not have
a great royalty deal at the time, and, you know, they shoveled that out, and there was
some genuine bitterness that that was possible, and that to some point, to some point, I had
enabled that by sharing the tools, but I did feel very good that a decade or more goes
on, a couple decades now, and the people, like Kevin Cloud, who is one of the artists
on there, had later told me that, no, that really was all for the best, looking back
on it, and we are in this almost unique position where Doom will never die.
As long as there are processors, Doom will run on them.
Right.
Do you think there's lessons to take now, and then, like, I feel like the open source
community has played a role in the last 10-year development of AI?
Do you see the lessons that we should learn in thinking about how that connects to the
current innovation?
Yeah, I'm still surprised that it doesn't play more of a role in the game industry,
where I wouldn't, I'm genuinely, I'm surprised that there is not more, like, full open source
development.
You see bits of it in, like, the Minecraft mod scene where you have projects up on GitHub,
but people that are generally making games, they still feel very protective of their source,
and then you had the commercial companies with Unity coming in and making a very powerful
product that gets the job done that was better than open source alternatives in many cases.
I think Epic does a really grand thing by, they have strict licensing terms, but the
fact that the source code is all available, that's half the battle.
I am pragmatic.
I'm not a purist.
I'm not going to, like, you know, license snipe somebody about what they're using.
Just having the source code available for view is a large chunk of the value.
So there's good stuff there, but in the AI space, it's much more open, and I think in
the broader sense of where academia has gone, where comparing, I go back and I do read a
lot of papers from the 90s and stuff, and it's papers without code, without data, unreproducible.
There's a whole lot of things that are just probably are not right, and the path to having
the norm, it's still not fully established, and there's still pushback about it, but the
world is a far, far better place now for the openness that we do have on the pace of artificial
intelligence and most other science that I don't even have windows into, the fact that
code available on GitHub, ideally data there, we still have too many cases of data available
upon request, and there's still norms that need to be pushed there, because you do still
have sensitive people.
It's like, oh, if I release this, people will find mistakes, they'll critique my code, they'll
have all of this, and that's still a problem being worked through, but I have no complaints
about the state that we're at now and the trajectory that we're on.
I think it really is one of the great things for the world today.
Cool.
I wanted to have an AI, but before that, let me take your detour through VR for a minute.
Tell me what would, did that just feel like a natural extension for you, for games, or
were you thinking something bigger?
What was motivating you to move into space?
I had actually tried some VR stuff back in the 90s.
We had one of the really old headsets that cost $10,000 and was like 320 by 240 resolution
screens and pixels the size of small footballs in your peripheral vision, and it was clearly
not the right time for something there, and it was interesting where I went and I said,
I'm just going to go look at the state of VR, because it's been two decades, surely
it's all fixed by now, and I was really surprised to find that even though technically we had
good screens, good accelerometers, we had all the things that seemed to be necessary
to make this work, but there were still just this handful of government contractors making
headsets.
There were $50,000 headsets in some cases, and they still weren't even all that great.
That was one of those points where you can say that opportunity is the difference between
what's possible and what people are actually doing, and it did seem there, it's like from
a technical level, these things were now possible, and the early experiments that I did there
showed that it can also be really quite compelling.
Now there's the obvious play there about, well, you make games, it's more immersive.
There's the step from looking at a 2D game to looking at a 3D game to being inside a
3D game, and that is absolutely true, but I do think there's the even more powerful
case about once you have a virtual interface, everything that you do on screens can at least
in theory be done better in a more flexible way with a virtual reality headset.
I do think there is that many billion dollar value there.
I spent eight years involved with it, and there's things that I'm very proud of.
The Quest 2, the Quest 3 being announced officially and coming out real soon now are great pieces
of hardware, and there's an interview that I did 10 years ago in 2012 or 2013 where I'm
saying this is the way I want things to go.
I want this self-contained device that has inside out position tracking, not cabled anything,
no external tracking aids that can run lightweight applications internally all by itself and
can connect wirelessly to PCs to go ahead and have higher performance things, and that
turned out just the way I wanted, but there's a lot of things that I had friction at meta
with trying to get the rest of the way.
Right, I was going to ask you, I was sort of thinking about the transition into AI.
I don't know how much of that was somewhat being disillusioned by the impact that you
wanted to see in VR?
No, it really wasn't.
I was still fighting the good fight as much as I could from my position in VR, but it
is funny how my origin story for the AI really does go back to Sam Altman and OpenAI trying
to recruit me when I knew nothing about the state of AI.
I was very flattered by that, that they just thought that my skill set in background could
play a useful part in the company that they were building and putting together.
Now we were talking about that just before we got on stage, but had you already started
looking at AI at that point that raised your profile?
No, they were just like, they went after you as purely, you are a brilliant engineer.
You will help get us the rest of the way there.
I had some vague relationship to it for like there were hand tracking models and eye tracking
and face tracking.
Neural nets were used a little bit in the VR side of things, but I hadn't barely touched
it.
I had done my neural nets in C. I just spent a week writing that by myself, but that was
about it.
Yeah, so they reached out to you and that made you think I should look into this AI stuff
then.
Yeah, exactly.
And then I looked into it and I was very happy.
They helped me get my feet under me and here is roughly what you need to learn.
And when I started looking into it, I carefully thought about it and I reached this conclusion
that this is probably the highest leverage time for someone like me, an individual engineer
in the history of ever, that there are so many important things that require huge teams
of people, that require lots of management, but the gap between where we are now standing
on the shoulders of all those giants and this really transformative thing with general intelligences
applying to almost everything that we do intellectually in the world, that feels like this small,
modest number of things.
And when I look back at what mattered in the last decade, they all feel like things that
I would come up with.
So it was exciting.
Yeah, so I think it's kind of funny that if you look at what Edmonton's innovative scenes
are, there's one on the side of games and there's one on the side of AI.
Do you think that that's, you're traveling a similar set of spaces.
Do you think that that's coincidence or do you think that they're related?
It's interesting because, of course, famously, like Dennis Asabas at Deep Mind was also a
gaming background person.
Yeah, it's hard to say there are certainly some aspects of being all about virtual worlds
and simulations that plays a little bit into it, but it's a little bit of a stretch.
I think it might be more fundamental that the people that are overjoyed at the technology
of games, it's this general sort of optimism about what you can do with technology and
you've gone through the feedback cycle of getting this huge reward and joy from solving
a wonderful technical problem and it causes you to delve deeper into it and push harder
on it.
And it does, in some degree, give you confidence or maybe even hubris to think that you can
make a difference in some of the other areas.
Cool.
So this partnership with Rich, I'm kind of curious, all disclosures.
I was also a co-author on the paper of the Alberta Plan with Rich and Patrick, but I
want to ask you, have you read the Alberta Plan?
So I hadn't before I started talking with Rich, so I was familiar with, I had gone through
his textbook twice, actually, and I loved his Bitter Lesson paper and I had caught
like a couple of his presentations, but I was several years behind on sort of the research
work that he was doing.
And I had my mental model of Richard Sutton had a few things that I had some concerns
about from my view of reinforcement learning from several years back, and when I started
talking with him and started going on all of his more recent work, I got most of my concerns
there were pretty much elated and it was kind of surprising how aligned we were on a lot
of things.
Okay.
If you could pick one thing that you think the Alberta Plan gets right and one thing that
you think the Alberta Plan gets totally wrong.
So yeah, I'm setting you guys up for success.
So I have concerns that the monolithic nature of the models that are talked about there
may not capture some important aspects of the way human brains work as a much more distributed
semi-consensus finding system.
I mean, we draw these neat boxes about here's state, here's policy and implemented with
monolithic models, you know, these are, we have Turing equivalents on a lot of these
things.
I won't say anything can't get across the finish line, but I do like to at least gesture
in the direction of our one existence proof of general intelligence with biology and say
that there is much less of a central driving force behind these things that I believe they
operate more at these somewhat lower levels and I don't have this resolved, but that's
always a concern for me when something, I mean, we've all stepped back away from anything
smelling of symbolism, but there's still monolithic tendencies that I think may yet prove to be
a little bit of a retarded for it.
But the important things about what an AI does is digest its experience into a state
representing its view of the world and how it predicts things going forward and how it
needs to have motivations both internally and externally imposed.
These are core that are completely unaddressed by the current sensation with the large language
models.
These take a very, very wide context and they throw something at it and you get an answer
out the end and there's enormous value.
I don't want to take anything away from everything that's being done with that, but that's not
how our brains are working.
And I think that there are important things that it doesn't encompass and yet every lab
in the world is throwing so much of the dominant share of their resources at that.
So being a little bit contrarian, both of us, I think is a positive thing.
Yeah, I'm glad you used that word.
That seems like a word when I first thought of you and Rich, I was like, well, those two
things I know you're aligned on being contrarian, but I don't know if you can be aligned on
being contrarian.
I'm going to ask you one more question, but I'll say that I'm going to open this up to
the audience for questions after this last question and the microphone, I believe, is
over here.
So if you want to rush to get in line to ask a question, I'll let you do that while I
ask my last question to John, which is, what's your future?
You talked a little bit about 2030 as being a goal of we might see some AGI, but maybe
you could describe when you say there's a 60, 50 to 60 percent chance that it happens
by 2030, paint me a picture of what happens, looks like.
So it does appear that I'm a person of decade-long efforts where there's a spectrum of useful
there.
There's a lot of people that have 18-month kind of passions and cycle through and you
get more breadth with that, but I've been a fairly in-depth person, overlapping with
gaming and rocketry and virtual reality and now AI, and I fully expect this to consume
a decade of my life or more, so I certainly wouldn't give up in less than a decade, and
if things are going well, it'll carry on longer than that.
I do intend us to stay intentionally away from anything, smacking a commercial product.
I think that it is important.
So this is one of the things I do struggle with a lot, though.
I mean, there are all of these things, I'm far from having this surety of direction or
anything.
One of the problems that I had a lot at META was a lot of the research I thought was actually
not particularly valuable, that it was building for things, and I wanted everyone to concentrate
just on product.
You have product, there's a million things you can do, just do those million things.
Don't look too far ahead, and yet here I am doing exactly the opposite, and I have the
arguments with myself, do I have a legitimate reason why this is different, or should I
just be doing some data generation startup, the 10 companies that want me to help them
do game generation with generative AI, there's tens of millions of dollars just to be had
at the drop of a hat to go do something like that, and I can't say with surety that that's
not true, that you don't learn as much along the way building those skills there, but my
hunch, my bet that I'm making with this company and putting my effort into it is that there
are a number of things that are very important that are not immediately commercially valuable
that contribute to the big brass ring of the big deal there.
We have, just today we spent most of the day at white rooms, at conference rooms, kind
of talking about finding out what areas we're aligned on, what areas we think need to be
explored, hashing out a little bit of differences in understanding on some of the questions,
but I have a series of things that I'm building up that I hope will demonstrate to me that
we're at least on the right track, but in the end you want to get something that winds
up being sort of a virtual being that you can delegate tasks to that's not just a chat
bot, it's not just a tool that you use, but it starts winding up being options in remote
employees for companies where you have the option of like, oh, I liked working with AI
Tom before I'll take five more of him, put them on the different tasks here, and at the
end result, so many of the things that humans do now are mediated by computer interactions
and the pandemic really did put quite a point on that where more things than people would
have thought possible five years ago really are capable of being done just through the
computer intermediation, and I think that that is the opportunity to have this golden
age of creative power and ability with magnifying all of that.
Awesome, thanks. I didn't see anyone walk over to the microphone, which I told you there's
no hand raising just to be clear. There's no hand raising, you have to walk to the microphone.
Taking away. Hello. Thank you so much. So I have a question about kind of this path towards
artificial general intelligence, and I'll kind of frame it in terms of Quake. So in Quake
you have fast inverse square root, which was a method that no one would have thought of
to do this process much more efficiently. So I'm wondering when you think towards the
path of artificial general intelligence, how much of it do you think is these ideas
that no one was thinking of that are just a little bit more efficient than before, and
how much of it is kind of a combination of ideas that we already have and that are floating
around our circles? Yeah, so there's some interesting aspects to the question of efficiency
where I have to guard my time to not spend too much time on optimization because I love
that work. It's like a vacation for me to have something so clear, just make this number
go down. That's like fun for me, but it's not the most important thing because in so
many ways making something two times faster, four times faster, even ten times faster,
if it's not on the critical path, that's probably not the right thing to do now. Now where it
does matter, you get into factors of a hundred and a thousand, and there are architectural
choices that you make that have these three plus orders of magnitude importance, and those
are important that you not mess those up, that you not do something, and there are architectures
that you could make that are just going to be like involve pointer chasing or something
that are just not going to be good enough because three orders of magnitude matters,
you can't run your experiments in time, you can't deploy it and all that, but on the other
hand there are some architectures that may be important that just because they're not
easily expressed as tensors in pie torch or jacks or whatever that people shy away from
because you do, you only build the things that the tools you're familiar with are capable
of building, and I do think there is potentially some value there for architectures that as
a low level programmer that's comfortable writing just raw CUDA and managing my own network
communications for things, there are things that I may do that others wouldn't consider,
and like one of the aspects is the boundaries that we put on the things that we're going
to do, one of my boundaries is it has to be able to run in real time, maybe not from my
very first experiment, but if I can't manage a 30 hertz, you know, 33 millisecond sort
of training update for a continuous online learned algorithm, then I probably won't consider
it because I do consider that necessary for even while you might grow in a simulated world,
at some point people aren't going to really buy it until they're having a zoom call with
the AI and poking it in various ways and having conversations, so that ability to run in real
time goes against the current grain because things are moving up to you use a warehouse
full of computers, but your step time might be a second and a half or something, there
are alternate ways of structuring your systems such that you use a warehouse full of computers
and you get a 30 millisecond time, but you can't do that with the tools that most people
are using today, so I hope that it does have some benefit, but that's one of those speculative
things, my background may let me do something that might be important, but I can't say with
any confidence that it actually is critical.
That's awesome, thank you very much.
All right, next question.
Hey there John, so I'm a huge fanboy, I just wanted to say thank you for everything and
you've done for this industry and specifically thank you for building Quake, Quake was a
very important game for me for both my social and professional life, thank you, but my question
is about who in this world has the ability to build the next great thing?
In my mind throughout history of computers there's always been like a sole person or
a small team and not some giant corporation that's really pushed things forward.
Every programming language was created by like one or two people, there's Linux, Google
was famously started by two dudes in a garage, your former employer Facebook was created
by one guy or one set of twins depending on who you ask, and I basically believe you created
a lot of these technologies on your own, but when we look towards AI and VR there seems
to be like these huge requirements for enormous amounts of data, big training sets, multi-million
dollar compute time.
So I ask like can a small team still build the next great thing?
So there are I would say most projects in the world of importance actually do need larger
teams and resources, building commercial infrastructure, building highways, these take large teams
and even in the software side of things building Chrome takes a large team, building Android
takes a large team and these are super important things that the world runs on to some degree.
So the default state is it probably needs a lot of people for these big things, but
my point about AI or AGI right now being this potentially unique point of high leverage
comes from my belief that I have this whole set of spiel about how the data is not that
large, the compute is probably not that large in the larger scheme of things, like a point
I make a year of life is a billion frames at 30 frames per second and that fits on a
thumb drive and you can tell that a one-year-old is a conscious intelligent being, so it does
not require all the data on the internet to demonstrate artificial general intelligence
if your algorithm is correct.
The arguments about how much compute you may need are I don't have as ironclad positions
about that, but I have plenty of reason to believe based on the capabilities of what
the networks are doing today and the size of the brain and the parts that we think we
understand what's going on that it is not a warehouse full of computers, I mean I don't
think it's one node or even one rack, but in that scale over the course of the coming
decade we will factor that by it will be another order of magnitude less and I do think it's
inevitable, but there is this period where well-healed individuals right now can potentially
take a crack at this, if none of us make it then eventually it's going to get to the point where
every grad student has the resources to take a stab at these problems and the problem will
fall shortly after that point if it hasn't fallen before that, but I think we're in this
magical time right now where it is a golden opportunity and I'm honestly surprised that
there aren't more people, I mean there are hundreds of people like me that were technical
people that succeeded, sold companies, have the resources to go and apply this and I'm kind of
surprised that there aren't more of them taking small stabs at it because even if you think
you've got one tenth of one percent chance of kind of making it and getting all the way
it's kind of a Pascal's wager sort of thing where the expected value from that if you have no
fear of ruin is still quite significant. Great answer, thank you so much.
Hello John, so I understand that the AGI Gold might seem a little bit abstract,
so my question goes towards if you're taking steps towards this goal, how are you making sure
you're, how are you measuring your progress, are you decomposing it into sub-problems like
what are the proofs for the steps, or maybe abstractly how are you sure you're gonna,
you are gonna be making progress towards this 2030 goal? Yeah, so I'm not at all sure about it and
it is, it is almost one of the key questions, you know, how do you gauge whether your child
is growing properly, you know, do you have things that are crude like I, you know, the basic
responsiveness tests about things, you track pupil movement, but how do you tell at the earliest
level before a billion steps have gone by what level of cognitive processing is going on there,
and I have like my angles on this involve, you know, like moving foveas and centers of attention
and there's low-level things that I can look at and say I believe in intelligence should be
following these patterns and I have these indirect measures that I can make of it,
but I dearly wish that I had better objective measures because it's, it's undervalued how
critical benchmarks were to the pace of this last decade of terrific AI progress, where
turning things from a discussion section into numeric values, and yes there's downsides and
people talk about grad student descent of the problems with leader boards and different things
like that, but overall it's been enormously valuable, and I, you know, I do worry a little
bit even with the LLMs that I don't really buy a lot of the measures of how they're benchmarked
against each other, and it's an even harder problem for AGI, so I wish I had a better answer to that
because I think it's important, but I think that there's at least directions that we can be following
that we feel pretty good about, but it's entirely possible, years could go by and it turns out it
was the wrong direction, but it's still worth the try. Okay, thank you.
Yeah, I had a question about the kind of AGI you visualize building at Keen, so when I think
about AGI I think there's an embodiment, there's an actual robot functioning in the real world,
so are you thinking about something which is animal-like or human-like or is it come
completely virtual? All right, so I'm not a fan of robots which puts me at odds with Joseph here,
and, you know, it comes from, of course, I'm the virtual reality guy, so I believe in simulation
and the general ability to, you know, to do valuable things in simulation. While robotics puts
much of the value of working with robots is this discipline of saying you're going to be real time,
you're working with reality, you can't just get slower and slower and make your model better by,
you know, by scaling it in a way contrary to time, so I think that that discipline can still be
maintained in a virtual environment, and I think that's the primary benefit, and there's a lot of
downsides to robots where I did spend over a decade building rocket ships, and that drives home sort
of the, you know, the cussedness of physical things, and the less you can be forced to work
with physical objects, the better in most cases, so I think in general I don't expect us to be doing
anything robot-based. Now the question of exactly what simulated environment you have, there's a
broad range there where, like, right now I'm working with sort of this 2D infinite movie wall of,
like, moving around looking at different things, and there's a degree of agency there, and you
could learn about 3D environments and you can put 3D games inside there, but to me, like, it's an
open question, should it be a virtual reality environment of instead of a virtual 2D wall,
should it be a physical space where they have to, like, walk around essentially to look at
different things, and I don't know, I'm leaning towards the simpler possibilities right now,
but if it turns out that I wind up making a full-fledged, you know, game engine rendered virtual
world, I wouldn't be at all surprised if that's where we wind up in, you know, in a year or two.
Thanks, John. So it's very special to have you joining our community here in Edmonton,
and when Rich emailed you, you must have thought to yourself whether you wanted to start this
partnership, and obviously you did, so I was wondering about what were the behaviors that you
saw in this community that wanted to make you join our community, and more broadly, like, what
should we hold on to, because we might have taken it for granted, because we've been fostering for
so long. Yeah, so the, you know, initially I did not get my hopes up, I was just like, hey, it's cool
to be having a communication with Richard Sutton, and I was going to try to be my helpful self as
much as I could be, and the fact that we did wind up hitting it off well enough, that it's
almost remarkable how many areas of overlap that we've got in terms of the way we look at this,
and, you know, in some ways, both me and Dallas and Rich up here in Alberta, it is, this is not
the center of gravity of artificial intelligence research, you know, we are in our own way in the
wilderness, and I think there's some commonality that came from that, where there is, you know,
there is this kind of fashion in research, and especially in the commercial side of it, and
the current looking at things, like the reinforcement learning, and the real-time
online continuous learning, these are not the current fashion for things. I, you know, great
strides are being made with large language models, large batch training, slow steps, inference only,
and, you know, and that's all great, but everybody should be aware that this is not the be all,
end all, it doesn't solve all of the problems, so somebody's still got to be looking for the
remaining answers, you know, we don't have them all, so being willing to go against the grain,
and to step a little bit outside, and have a lot of people say, why are you working on that,
you know, that's not the, you know, the mainstream, that's not where you can go,
impress the VCs or whatever, but at some point somebody has to solve some of these problems,
and, you know, the willingness to go ahead and do that, because you think that it's the right
long-term solution, it's, you know, I do tip my hat to the kind of the academic virtues of
you are trying to find truth, you're trying to find, you know, the knowledge and the way to solve
these problems in the hopes that then they will be applied into the world to produce, you know,
great value across the different areas, but yeah, the biggest thing right now is we're both
outside the mainstream, but we both have conviction, and we have, you know, reason to believe that
it's a profitable direction to be pursuing, and this is far from the only direction, again,
I'm surprised that there aren't more efforts like this going on, rather than having the 10th company
training their own large language model to compete with something, there are other interesting
problems that may wind up being even more important, and being excited about the general
technology while kind of picking a path that's not just following somebody else's trail in the
specifics, I think, is important, you know, the world needs more people like that.
Thanks.
Hello, I'm very excited to hear about this partnership that you have here, and so one of
the things that I like about it is that there's a lot of blue sky research that you sort of have
in mind, right, that for the next seven, 10 years, whatever, there's going to be a lot of focus on
these fundamental things, some maybe online, real-time algorithms to do certain things,
but you also emphasize that there is no need for a tangible product in, let's say,
in this time frame, right, so all this sounds very much like an academic lab,
and while this is certainly not one, right, and perhaps, so my question is out of curiosity that
is this something you're specifically guarding against, because like DeepMind and companies
like this also started with a similar, perhaps, intention, right, that lots of blue sky research,
solve intelligence, use that to solve everything else, but now maybe it's not exactly the same
anymore, right, so are you specifically guarding against that or is that something you don't really
think about? So I am unashamedly a capitalist, you know, I do, I think that this could make
me a trillionaire if everything goes well, it's worth, you know, it's worth kind of aiming for
some things that I, you know, producing value, I think it's good for the world, I mean, I deeply
believe that building commercial enterprises is most of what has made the world what it is today
in a very positive sense, so, you know, and I don't have the academic background, I am,
you know, I respect, I recognize I'm standing on the shoulders of all of the academic work that's
been done before, and it was funny because I talked to, you know, ahead of a university one time,
and I was kind of mentioning how I feel a little guilty being a commercial company that is built
on lots of this research, and he said, you know, your tax dollars have paid for a whole lot of
this research, don't feel bad at all, you know, this is the point of all of this is to let people
try to build on it, so, yeah, it's, it is a commercial effort, and part of that was a focusing
tool for myself, where I spent kind of the prior few years in what I call Victorian gentleman
scientist mode, I was kind of styled like Darwin or Babbage, where I'm a rich guy that can buy all
the scientific tools that he needs, and can kind of have my backyard laboratory for things, and,
you know, and I learned a whole lot, I spent the time kind of going through this extended larval
stage about finding out what everybody is up to, and getting myself up to the modern standards
there, but it always gave me an out, you know, just at that level, I could think of it, it's like,
well, it's almost a hobby, I could just quit at any time, I can divert my time any way that I want,
and I had had several, several different organizations pestering me about form a company,
take our investment money, and I didn't need it for the money, but I looked at it as a focusing
tool, where I have in many ways an overactive sense of responsibility to, you know, to investors,
you know, it, it killed me at, at Metta, just seeing that all that money going out, I went,
I'm like, no, turn it into profitable businesses earlier, so that is an aspect of it, and then
hiring employees means it's like, okay, now I've got people's paychecks that I am responsible for,
so it makes me focus better on the, you know, on the tasks at hand, as well as actually bringing
the resources to bear. So, yeah, in some ways, it's a pure research play, and, but at some point,
it turns into, if it works, products that really, literally reshape the world. Thank you.
Yeah, so I think you touched on this a bit earlier, but I'm sure many people have tried to hire Dr.
Sutton before and failed, and so, yeah, like, could you talk a bit more about, like, why you
succeeded where no one else could, and was it, like, fully attributed to being aligned, or?
Yeah, so I still, you know, I still wind up being happily surprised that I'm here today with this,
because I, you know, a couple times, I just said, I know you can write your own ticket
anywhere, you can go to any of these companies, and everybody would be happy to have the father of
modern reinforcement learning just in their collection, and for some big companies, it is
almost like a Pokemon collection, you know, collect your favorite researchers, and I, you know,
make sure they're on your team and your deck, but I, you know, I think, you know, part of it is that
we want to actually do these things, it's not about prestige and being out there and,
kind of, staking a claim, we want it to exist, we want to build it, I am, and I think that there is
a sense that a smaller team, there's, I mean, there's all sorts of drags and friction that you
get in big teams, it is wonderful to have a 10,000 GPU cluster that you can go ahead and just kind of
get time on whenever you feel like it, but I am, again, I've got enough options for, you know,
for doing things like that, I, that I don't think that's going to hold us back, and the ability to
have a purity of focus, I think is important, but I'm, yeah, I'm, I'm still, you know, really
very happy that it all worked out this way. Thank you. Hello, thank you so much for the talk,
John, it was fantastic. So my question goes back to the discussion about game development and,
and open source, and I would like just to hear your opinion about what is, what do you see
as the future of open source software in the video game industry, especially since it's a
world full of, full of IPs and proprietary platforms. So there is, you know, right now,
is an interesting inflection point because Unity had their whole change their terms of services,
and this is making a lot of people reevaluate what they're doing. And it's been a long time
since I was really close to the work being done on the open source engines. But, you know, I believe
it's fair to say that Unity, with all their employees, they do a lot to make it a comfortable,
cozy development experience. They do provide a lot of value, and you do get a lot of open
source crusaders that just don't acknowledge the value that the commercial companies bring to the
table when they build their software, because there are a lot of blind spots that the open
source teams, it's, it's weird how the DNA of the people that are willing to work on open source
wind up with certain important blind spots in the kind of applicability of their software and
usability. You make super powerful tools, but you know, they're not very comfortable and it winds
up making them not the right call for a lot of people. But like I said, I very much respect
EPEX in between position where even if you don't pay them a cent, you can read every line of code
and learn from it and understand how things work. You can pay reasonable license fees. Having
competition there is great, you know, letting people choose. And I always thought that the trade-offs
between Unity and Unreal was a nice market balance to have. And like in virtual reality, 95% of the
developers wound up with Unity because of just the crowd that was attracted, but it was always
expected that if you need serious control, you'd then go with Unreal and you could write things
at a lower level. So there's an opportunity now, I think there will inevitably be some larger move
after Unity stumble here to open source projects. I don't expect it to be a tsunami that like accelerates
and takes over everything because there are just so many of these grubby business things
that are just not fun to do on the open source projects that I, you know, I could imagine a
scenario where somebody like, you know, Meta gets behind open source things and winds up
helping do some of the unpopular, unfun things for their own kind of self-interested reasons
that could be positive. But I think I'm resigned to a slow pace of migration towards more open
source tools. Again, at this point, 30 years back, I'm disappointed that we aren't further along there
relative to like compiler tool chains and things where the world is a better place for having
those be almost universally open source. And we probably could have been there on some game engine
type things, but I don't think the fundamental reasons why we're not have changed. So I think
it's going to be modest changes going forward still. Thank you so much. I'm being told we're
almost out of time and we have a line of six people. So I'm going to go in a lightning round mode
and you get 10 seconds to ask your question. I can actually hang around a little bit after
then, you know, after the actual official end. Okay, well, so I worked with Mike and Rich at
DeepMind and actually some friends and I left DeepMind to create a startup here in town.
Using AI to make AI in video games. So first of all, thank you for not shooting to make a
commercial product in the next couple years in the game space. But my question is more like,
I know Rich has a really strong commitment to open research. And it sounds like you embrace
that as well with the hacker mentality. So what are the plans for keen to like share your insights,
your breakthroughs, maybe even your code? So this was, you know, one of the significant
conversations that we had. And I, you know, Rich does understand the importance of commercial
businesses and that there's, you know, there's reasons why these are fundamentally important
and the incentives matter. And there's a talk about like, yes, I, you know, I did champion
a lot of releases of different things and I would, there's certain technologies that I'm happy to
have us publish. There's other things more like around experiment design and architectures that
I probably don't want us talking about. And it's going to be in a situation like if, if somebody
wants to write a paper about something, we'll have a conversation about it. And if it's, you know,
if it's something at the very tactical level, like, Hey, this is an interesting way to do an
optimizer. This is, you know, another way to calculate your, your TD assignments, whatever,
that's, that's probably fine. But here is the architecture of what our proto AI, AGI looks
like that's probably not going to be talked about. Because all of these are going to be things that
we see it today where all of the major laboratories, they can reproduce anybody else's work with a
couple sentences of direction and a couple weeks of time. And I think that's going to be the case
for AGI as well. When, you know, when it does all get solved, the textbook from the future is going
to have a relatively thin chapter about this is actually all that's really required built on
the baseline to make it happen. So yeah, there's some sense of secrecy. And then there's real
concerns about any real company is going to have employee turnover, they're going to walk out the
door, you know, NDA or not, they're going to know what the things are. So there is a large part of
this gamble on even if all of this value gets developed, much of it may dissipate into the
broader world, which is great for the world, not so great for my investors, but we're all
still collectively willing to take that risk. Thank you. Okay, it looked like lightning round
didn't work. So I'm going to call it here because we're out of time, but John has very generously
offered to answer some questions. If you have some, we'll make sure we start with this line first.
Yeah. But let's first thank John for telling us so much insight about his past, present and future.
All right, thanks. Do I have to vacate the stage? Yeah, I don't know what we do next. Thank you. Bye.
