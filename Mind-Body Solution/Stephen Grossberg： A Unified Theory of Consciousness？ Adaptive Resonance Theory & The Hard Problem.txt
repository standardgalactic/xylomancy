The main focus, I'll put links to the 2017 paper on the hard problem of consciousness,
but for the most part, I would be nice. Yeah. Yeah. I'm going to put a direct link to that
in the paper because I mean, in the video, because I think people should read this. It's
very long, very, very in-depth. And I like that. I mean, that's when someone has a lot
to say about something so complicated. I think you can't really summarize it. It's
something that does require that level of detail. So to all those who are going to read
this paper, just bear that in mind. You've got to, it probably takes repeat readings
for most people to really understand and grasp most of the concepts, but you do a great job
at putting the imagery. And I mean, it's a wonderful paper overall.
Well, thank you. Two things come to mind. One is that it's a long paper, but it compresses
a huge amount of knowledge. So if you can get through that, you've saved an enormous
amount of time. And that's one thing that my students always came to realize. It was
a way that they could get an entree into so much psychological neurobiological knowledge
and start organizing for themselves. Whereas if all you did was you gave them 200 articles,
which may be explained or explanation offered in this one article of mine, they wouldn't
know where to begin. And they wouldn't, they would have to build up a model in their mind.
And that's what I'm giving them, not to say it's the final model, but it's been validated
each of the models in multiple ways. And, and it gives them a way to start organizing
all this information. Because ultimately, the model as a thing in itself isn't what
we're interested in. We're interested in understanding what the hell is going on. And if models help
us to create stories about what's going on, and those stories make sense and help us to
clarify what we're learning, well, that's what they're for. So I was going to say something
else that split my mind. I should write notes.
Now anyway, the huge chunk of this conversation will be about the heart problem of consciousness
in your paper on that topic. And I think the best place for us to start, I've got a list
of questions from from the general fans, audience listeners and viewers. And I'll just go through
those later on in the conversation. But the beginning, I think let's start with, what is the
heart problem to you? And if you could tell me your philosophical history of the heart
problem and your perception of it, what would that story be?
Well, I don't have my 2017 paper in front of me, but it was David Chalmers, who described what he
considered the heart problem. And my comment about it was the following.
How to put it. Let's go back to the orbits of the planets. If we can predict the orbits of the
planets with great precision, we don't have to necessarily visit them. We don't have to touch
easily them. It's a description that's predictively effective. And so my comment at the beginning
of my magnum opus, and I think I made a very similar comment in my 2017 paper is, let's say you
have a neural network model, which describes identified brain cells and identified regions of
the brain interacting in a way that's validated by neurobiological data, anatomical and physiological,
in some cases, biochemical. And let's say the emergent properties map quantitatively onto lots of
behaviors that interest you, including parametric properties of conscious experiences like seeing,
hearing, feeling, knowing things. That's all equations can do for you. And if you expect an
equation to see color, or to hear musical tone, that will never happen. And it doesn't happen in
mind brain science, but it doesn't happen in physics or chemistry. And people have come to
understand that if you get predictive insight based on harmonious laws that make things seem
clear, that's enough. You know, it's to think you would get more, which is implicit in the
definition of the hard problem is asking for something that equations can never give you in
any science, and only look to sciences that are better developed to realize, you don't really
need it to feel quite satisfied that you've understood something. So that's my response. It's
it's sufficient. Of course, it is a mystery. You know, and as I point out, let's say, right down
to the photons. And, you know, for example, Gail Carpenter and I, among other colleagues, did
very detailed models of the transduction of color signals in vertebrate cones. And we were able
to quantitatively simulate very hard data using designs that you could see had been using many
other parts of our brains. But the model doesn't see color. It just describes how we see color.
And there is that explanatory gap. And I, for one, don't see how equations can ever bridge the
gap. But we don't need equations to do it, because we have our conscious minds. So one of your
I don't know what one of your quotes in the in the paper was, as in quantum theory, there are
measurement limitations in understanding our brains, we can no more personally ride an electron
than we can enter a neuron that is participating in a conscious experience. That's pretty much
among the lines of what you're trying to say.
Yeah, it is what I'm trying to say. And of course, there are superb neurophysiologists now who do enter
neurons. In fact, a colleague or a miller at MIT might put an array of 100 or more electrodes in three
different parts of the brain and do experiments with the way behaving monkeys to try to correlate what
the monkeys are seeing and doing with the recordings. And it's very insightful. And if you have a strong
enough theory to explain what these patterns mean for emergent properties to link brain to mind, to
link brain to the perception of the action, but that is extremely useful. But in itself without a
theory, it's not satisfying enough, you need more. You know, where's the spice? Yeah, so
what are your thoughts on Thomas Nagels? What is it like that that that specific component of
consciousness that what is it like? And the fact that we'll never really be able to say what it's
like to be a bit slow to the extent to which what it's like is that having having an equation that
in that is the quality, you can't do that. That's what I just said. But there are cases already in
many cases where we've developed models, principled models that you can understand are using
principles that are parsimoniously used in many processes. That can tell you a lot about different
percepts and where the end like what's the difference between vision and auditions say? Well, even
though the circuits, even though the equations, I mean, the local neuronal processes and the modules,
as I talked about last time, a certain number of conserved microcircuits that are used for many
things may be shared in vision and auditions. If you look at how they're specialized, in order to be
sensitive to environmental invariance of those signals in the world, photons and phonons and how
they're organized by sound sources, then you can begin to understand, wow, this is really fascinating,
because here is a universal computational substrate that can be specialized to resonate with the
invariance of different environmental experiences. And that is the power of how evolution has crafted
our brains in order to be able to do that. And we know that, you know, there are a variety of
species that are resonating on things that we can't do, like consider honeybees or consider the
vision of birds. You know, certain birds from hundreds of feet in the air can detect the movement of
a fish under the water and dive straight down to it. But we can't do that. But that doesn't mean that
their neurons, their fundamental components are, you know, something totally unfamiliar. That's not
true. And that's why for quite a while, people studied invertebrate circuitries like crayfish,
swimmer rats, etc, etc. And one of my colleagues many years ago, Al Silverstein out in California,
I hope he's still alive, a wonderful scientist, you know, he had, I guess, studied the stomatogastric
ganglion of, I think it was the lobster. And he had characterized on multiple levels of physiology
and anatomy, all the parts. And when it was all in said done, he still didn't know how it worked.
And he said that, and that was because it's an emergent property of all those parts,
interacting in a highly nonlinear feedback manner. And I'll acknowledge that he did
what you could do with brilliant experiments. And then you need
a level of description, notably a sufficiently powerful model that can show how those components
interact to generate the emergent properties that are the adaptive behavior of the stomatogastric
ganglion or whatever else we're considering. So it's that speculative leap we talked about a
little last time. You know, how you discover that it's not, we don't have an algorithm for it.
In fact, my colleague Rudy Kalman, I don't know if you studied the Kalman filter, which is used in
many problems in prediction and engineering. And he was trying to characterize,
in a very rigorous way, linear controllers. But at least at the time, he said, when he got the
multi-linear controllers, he couldn't even do that. You know, the methods he had just weren't
powerful enough. So the miracle is that somehow the methods that I've been lucky enough to discover
have not hit that brick wall yet. And lots of other people use them in one form or another,
including in technology. And as I may have mentioned last time, one of the reasons why
Gil Carpenter and I and a number of our PhD students and post-docs were eager to
specialize our model discoveries into applications in engineering technology and AI
was to show they work in the real world. And, you know, one way you can show they work in a way
that people who don't really care at all about mind and brain is by doing a technological
application that they do care about and frankly can make a lot of money for them.
Yeah. Steve, the approach that the science of the brain and the approach of philosophy of
mind are very different. As a scientist fundamentally involved in this interface of mind and body,
what are your thoughts on philosophy as a whole regarding their approach to this topic or philosophy's
engagement in this field? Because definitions play a big role and there's often arguments.
I mean, within philosophy, even merely starting with the brain as the source of consciousness
seems to be problematic for many philosophers. You have philosophers who claim that consciousness
is fundamental to reality. You have others that claim that consciousness is a fundamental feature
of reality, so panpsychism, which integrated information theory is pretty much a form of that.
Are you able as a scientist to even have a conversation with those people with such
different views from your own? Well,
I always ask, what can you explain with your concepts? And by explain, I mean facts, data.
If you can't explain anything, then you're not in the ballpark yet.
Now, one of the things that's fascinated me personally
is, I don't know if you looked at a later chapter in my book, it's about
really simple evolutionary precursors of brains. I talk about a universal developmental code
and show how mathematical laws and primitive circuits that are controlling the development
of non-neural single cell or multicellular organisms have many of the features that the
laws have that I might use to explain mammalian and human data. I talked about hydra's heads and
slime old aggregation and stuff like that. And to me, it wasn't an accident that I published
an article in 1978 called communication memory and development, where I described these things
theoretically. And in the same year, I published an early magnum opus called the theory of human
memory, colon, and then more stuff about what was in it. In fact, together they were book length,
and I originally planned to publish it as a book, but I was young and foolish. I didn't know what I
was doing. And so, Robert Rosen, Bob Rosen, who was a very sweet and significant mathematical
biologist, also was an editor of a book series called progress in theoretical biology, and he
was eager to publish the two articles as articles, but by putting it in something called progress
in theoretical biology, it buried it from the viewpoint of marketing. So that was one of many
naive things I've done in my life that I could kick myself for, but I'm just a naive guy, basically,
and I welcome it because having a naive approach to stuff really helps you to be creative.
You don't come in with, you know, too many preconceived ideas, so there's a cost for it,
and so far the cost has been worth it. But I should have published a major book in 1978
on mind and brain. As it is, I wised up a little, and by 82, I published a book that brought
together my articles, but, you know, and that I think a lot of people were influenced by,
it was called studies of mind and brain. I think it's still in print in some form, anyway.
So you have people like Edelman and Tanoni. I order information theories and integrated
information theory. At some point, this is quite a lengthy quote, so bear with me. This is your
words. I mean, they used the word information as a critical component of their hypothesis,
but what is information? The scientific concept of information in the mathematical
sense of information theory by Shannon requires that a set of states exist whose information
can be computed, and that fixed probabilities exist for transitions between these states.
In contrast, the brain is a self-organizing system that continually creates new states
through development and learning, and whose probability structure is continually changing
along with them. Without a theory that explains how these states arise and how their transition
probabilities may change through time in response to changing environmental statistics and internal
representations thereof, the classical concept of information is useless. You want to unpack that
a bit for us? Well, I think you just did. I mean, I'm not sure what else. I mean,
yeah, well, Jerry Edelman was a very brilliant man and a Nobel laureate.
There are a lot of Jerry Edelman stories I won't go into, but he was a faculty member at the
Rockefeller University when I was a graduate student there, and one of the more favorable
descriptions of Jerry was the Black Knight. I won't go beyond that in this public forum,
but he made very many useful contributions, and then as many Nobel laureates decided, hey,
you know, the next great frontier is brain, I'm going to get my next Nobel laureate in brain,
but the problem was Jerry didn't know any data, you know, and I was lucky to grow up
daved in data, which is where I comfortably live, and you can't go very far if you don't know the
data. And to know me initially, although I haven't kept track of his work, he's a clever person,
try to give a scalar to discuss, you know, whether I don't remember the details in such a long time,
whether the system was complex enough to, you know,
I think, do consciousness or something. My remark was, hey, you can't do anything with a scalar,
you know, I mean, we have a brain after all for a reason, but to the extent to which
everyone's contribution is useful,
hey, do it. I only view problems if work is useful, and it's not just hype,
of which we know today there's a huge amount of hype, and if it's done in a solipsistic environment,
I always taught my students, and it was a policy about apartment, whenever we were studying models
to do it in a comparative setting, what are all the models out there? What are their strengths and
weaknesses? If we have models we favor, do they have weaknesses that other models have overcome?
And if they have, how can our models be refined and further developed to also do that? So that's
a certain attitude, and if everyone's making their proposal in the context of a comparative
analysis, then hey, go for it, it's good. But if it's solipsistic and if it's aimed at selling
any idea in a, I'll push it to the limit here, a cult-like setting, we know that's
bad news. And to me, the worst part of it is, students go into
courses with famous professors or any professor who they like as a teacher,
and they're going to try to absorb everything the teacher says
at the time of life when you can learn better than at any other time in your life,
it's only to get a good grade. And it's really not proper, I would almost go so far to say,
it's not ethical to give kids a misleading view of the world that they're about to
have to live in. If you know better, if you don't know something's out there, hey,
you do the best you can, that's all any of us can do. But if you know something's out there and you
try to shield your kids from it because, hey, your work isn't as good and you want your kids to
do what you do so you can publish more papers or whatever, that's unethical in my mind. That's
the strongest I put it. Usually, I'd say it's just in a weak character, opportunism, marketing,
those words are dead enough. So the last time we went very in-depth on
an adaptive residence theory in most of your work, obviously, it's just scratching the surface
of what is very complex. And as a scientist, I mean, huge respect for your work and everybody
seems to have a consensus regarding that. So I tried to frame this conversation slightly more
philosophically so that people can get a deeper understanding of the science behind the work
and what its implications on the heart problem as a whole are. And with that in mind, the understanding
of other theories of consciousness are important because with yours, you can highlight flaws within
theirs, just the same way you did with the information aspect of this one. Along those lines of
Nobel laureates doing that, then you've got others like Francis Crick, Penrose, very different types
of theories of consciousness. You've got someone who was approaching it from a pan-psychist perspective
who's claiming that consciousness is that fundamental feature. And then you've got someone like Penrose
who claims that consciousness is almost quantum in a sense and beyond what classical physics
can interpret. And therefore the data in this case would not be as easily applicable. What do you
think about that? Sorry, that was a very long question. Well, I don't want to sound like a
broken record, but it's always, you know, what theories have the broadest and most principled
explanatory range and how many of their predictions have been supported by subsequent data. And
in terms of quantum brain, you know, there's an obvious sense in which our brains are quantum.
Hey, well, matter comes out of quantum mechanics or some kind of quantum reality, even if quantum
mechanics is not yet a complete theory as some people think, and you know, string theory and all
that. So obviously, you know, the structure of matter would embody ourselves in a world
that has a quantum substrate. But I take the kind of work I've done as an existence proof. And
there have been many times in my life when I've been dying to use some kind of concepts
to explain the kinds of phenomena that I'm really yearning to understand. And the existence proof
here is that if you look at all the things that I, my colleagues have explained, which I think
has the broadest and deepest, interdisciplinary explanatory range, linking brain to mind of
any existing theory, I've never needed quantum theory, except, except, for example,
at the sensory level. So for example, I mentioned briefly Gil Carpenter and I did some work on
photoreceptor transduction and vertebrate cones. And what that means is photons come in,
photons to the quantum constituents of light, you know, the whole thing with Einstein and
Wake particle dualism and all those profound things. But photons come in. And the question is,
how does, how does a photo detector, which is at the front end of registering that there's
something going on in the visual world, how does it generate a signal through the retina
to the optic nerve? And one of the things we realized is that the brain, our brains in many
species, I think we were doing turtle, I think with turtle photoreceptors because, oh gosh,
you know, it's been so long ago. Some really wonderful experimentalists had worked up
turtle phototransduction. And it was a parametric database, really challenging. And
there were some really bizarre, at the first lush properties of the data curves. And what we
showed is that if you had a temporal averaging of the photons, just so you're computing a photon
density, and you know, it wouldn't rise and then it would fall when a little event occurred,
we showed with simple ideas like that, you'd be quantitatively explaining all those data. So we
faced the problem that you have to transduce from individual photons, which is on the quantum level,
into a classical description of neuronal dynamics. We needed some stuff you don't
use everywhere. And that is a simple version that goes way back in phylogeny. And I've talked about
with some of my graduate students, we looked at multiple species that have these precursors,
what ultimately, a discovery I may call spectral timing, which is
both in space and in time. Our brains face the problem of going from, you know, you could respond
to a single photon, but that's too short to register any microscopic event. Or in space,
you could have a cell that's selective to just a very little region, but that's not going to
influence your navigational behavior. So one of the things I talked about in my book, I like to
sort of say it in a cute way, how do little nerve cells generate spatial and temporal representations
that can influence adaptive behaviors. And a key ingredient in that turns out
are called grid cells and time cells. And one of the things I loved about this modeling,
much of which I did with Praveen Tilley, a brilliant PhD student of mine who then
worked with me in much more senior positions before he got, I think. I think he's got quite an
important job at Intel now. They obeyed basically the same laws. And they're in two parallel streams
in the entorhinal to hippocampal cortex. And because of this
homology between the spatial and temporal laws, I love to say, you know, give me a break here,
space and time are one. And I called it neural relativity, because space and time are one.
But the parsimony of it was breathtaking. Now, you know, the evolutionary precursors of that,
someone else is going to have to look at, but I'm condensed. They'll love the answer.
And it'll be well worth their time. But to be able to say space and time are one and to show,
you know, and we're talking about entorhinal cortex, I didn't know from entorhinal cortex
when I was young, it's an acquired taste. You get forced into it by conceptual
questions that you then get stuck on, you get hung up on until you've got to get an answer,
not the final answer, there's no final answer, but a computationally effective and experimentally
remarkably successful pair of models, they, Praveen and I didn't mainly the space part of it,
but we were able to simulate quantitatively very challenging parametric data about grid cell dynamics.
And then the time stuff I did were the series of other THD students, Nestesh Mayak and
John Merrill, among others. So I had called it spectral timing because there's a spectrum of cells.
If you want to go from little nerve cells to temporal delays, you could bridge. So let's say,
to give a simple example, let's say I'm a human or a pigeon or a rat, or let's say that I have to
wait two or three seconds after a stimulus to make a response in order to get my reward,
and if I prematurely make the response, I might get punished.
Not so different like a student in a classroom, you have to know when it's okay to raise your hand.
And so spectral timing, you have lots of nerve cells, each with its own local
firing delay, because they all have different rates of firing. So one cell might fire,
bump, another cell might fire, bump, another cell might fire, bump, bump, bump. And if the stimulus
activates the whole spectrum, it turns out that each of those cells has an adaptive weight assigned
to it. And the correlation between the stimulus and when the action is trained to occur,
is going to strengthen some cells in the spectral spectrum better than others.
So for example, you could train, I'm not sure if I can show you this.
So one sec.
Steve, do you mind bringing more to your left?
I'm going to jiggle, I didn't do it.
Bringing more to your left, Steve, the other way. Yes.
Can you see?
Oh there, there they are, they're the curves. So you know, time is plotted against activity,
and for example, you can get spectral cells to fire selectively at two distinct times.
And if you notice the bump at the earlier time is narrower than the bump at the later time,
that is a signature of spectral timing. And you find it in the cerebellum, you find it in the
basal ganglia. I'm blocking the several other parts of the brain, you find it and I can't
pull it all up fast enough. It is a conserved mechanism. And you also find evolutionary
precursors of it in very primitive organisms where it isn't even neural. It is a way of doing a kind
of blocks law, a trade-off between time and energy. That's what's behind it.
But that kind of spectral timing that I just showed you, you can record from in cerebellar
parallel fiber, piquantia cell, synapses.
So Steve, I'm sorry, you finished that first? No, no, I just want, I was forgetting why I was
telling you this, what triggered this reply. It's fine, maybe if I ask the next question,
it'll come back to you. On that note, you're talking about the fact that it's also not just in
neural cells. There's work being done by people like Michael Levin. He's at Tufts University
where they started to show this blurry nature of what intelligence seems to be. Now, fair enough,
some people might argue that defining the word intelligence here plays a big role. But
in a nutshell, what he's trying to say is there's bio-electrical communication occurring
between cells that goes beyond what our hard-wired DNA is producing to communicate between cells.
Because of that, they're able to actually do some incredible work at this lab. It's called Levin
Lab. I don't know if you want to check this out afterwards, but they're able to create... Well,
I've interacted with Michael Levin in Tufts in the past, but you're not giving me a good
focus in a prime need to remember what we were interacting about. Because there was something
he was doing that I thought some of my work clarified, but I'm just talking about intelligence.
In essence, he's work starting to almost confirm panpsychism as an area of consciousness in the
sense that there is... What does that mean? Panpsychism basically means that consciousness
is a fundamental feature of reality, not in the sense that consciousness is just everywhere,
because a lot of people, technically, that is what they mean. But for the most part... Okay,
well, let me interrupt you there, just because that reminded me of why I was telling you a lot of
the stuff. The reason why I was telling you about some of these primitive and not even
neural mechanisms is because, for example, there are very primitive processes which have
properties of resonance, in fact, adaptive resonance. And one of the ones that I talked
about in my communication memory and development paper way back in 78, and then I review it in
whether Chapter 15 or 16, I forget, in my 17. And my magnum opus has to do with the process whereby
a blastula, during when you have a single cell, a very early embryo, becomes a gastrula.
You start with a spherically symmetric set of cells after the first few stages of mitosis,
and then some of the cells get selectively active, and they start sending pseudopodia
to the other side of the blastula. And on the other side, certain cells develop adhesiveness.
And when some of those pseudopodia hit the adhesive cells, they stick. And then this accumulates until
enough of these, it's an autocatalytic interaction, until enough of these pseudopodes connect. Now,
why is that going to do something? It's because the pseudopodes have contractal properties.
If they go up and they don't hit, they might come down and go up. If enough of them stick,
it becomes like a primitive muscle. And they contract, and then they pull the cells on the
two sides together, and that starts to create a gastrula. It's gastrulation. It's the next step
in cellular development. And in my communication memory and development paper, way, way back,
I began to realize that these morphogenetic processes already embodied primitive versions
of things like adaptive resonance because when the connections occur, the prediction is they
get more and more tuned, which strengthens the sensation. And as I recall, there was some later
data that were at least partially consistent, but very hard experiment to do directly. But my
prediction would be it's a simple form of adaptive resonance in an early stage of morphogenesis,
in multiple species. And there are a number of examples of these. Remember, I talked about
complementary computing, the kind of yin-yang fitting together. And that goes in multiple
parts of biology too. And although I'm going to make a statement now that,
it's the rankest form of speculation that doesn't give you any
predictive ability beyond what wonderful scientists have already done, I think an
example of that complementary computing is the double helix, DNA and RNA. Double helix is
a way of bringing complementary stuff together into a more complete representation,
the information you need to do stuff. Barbara McClintock did wonderful work on
her dancing genes. I don't think that was quite it, but trying to get at the dynamics of how
the double helix, which usually you see in a static form and some wonderful
chemical architecture, but it's very dynamic. It's always doing stuff.
So, I think there's resonance and complementarity everywhere. And remember, last time I talked
about the fact that in many parts of my work, there are principles of complementarity,
uncertainty and resonance. And we know, coming back to quantum theory, those are principles
at the core of quantum theory. That doesn't mean that we are operating on the quantum level.
It just means these are kind of universal principles of nature. And we, through evolutionary
adaptation over the eons, have been built embodying them in a form that could support
animal intelligence. So, if you ask about hand psychism and stuff, well, you're never going to
get into that system, just like you're not going to write an electron. But hey, they're built on
very similar principles as we are. And I feel I've understood more by commenting about these
three general principles that are conserved over phylogeny and evolutionary time than just saying
the word PEN psychism, which I want to know exactly what are you talking about, because
it's a lovely phrase and it's important to have a lovely phrase. But I need to know,
where's the beef here? Where is the beef? Where is it? What's the beef?
So, just to define it a little bit, Mike once wrote a paper with Daniel Dennett. I think this
would be a nice way to reel it in. It's called cognition all the way down. And the reason why
I bring that paper up is because at some point I was going to mention Dennett, you do mention him
in your paper. And Dennett doesn't have a panpsychist view. So panpsychism is pretty much the,
it pretty much means consciousness is everywhere, not always in the very mystical sense that a lot
of people seem to think of it. They're pretty much trying to come across by saying that
cognition or proto-cognition or even proto-consciousness can be found
within smaller layers of reality in terms of a human. So you can go down into like let's say
tissues and cells and within those biological processes, you can find forms of proto-consciousness.
Well, I don't necessarily agree with it. Wait, wait, let me, let me,
you really have to be clear about what you mean by consciousness.
Yes, I agree with that completely.
I've already given you examples with guest relation and with
talking about complementarity and resonance and uncertainty going all through the natural world
that these things go all the way down. Now, the question is what's the definition of cognition
that you're using here and what's the definition of consciousness? There are these shared processes.
As I remarked in our last discussion, I'm happy to believe that every species that solves the
stability plus disability dilemma has some form of consciousness because, you know,
my own work, I showed that to do that at least in everything I've seen in experiments and
models, you need a combination of learning expectation, attention, resonance, and synchrony.
And when you have all those things, if you're exposed to an external world that has
stable enough events for you to actually learn something with spatial and temporal stability,
then the process will also give you a form of consciousness, either of recognition or of
perception. But that was a big if too. You know, what is the stable world that
resonant events are interacting with and is it what we would call consciousness or cognition?
So I think that until I hear their definitions and how they've used to explain something
interesting, I would be more comfortable just saying stuff like I said, giving examples of
shared mechanisms like adaptive resonance and
gastrulation and his complementarity all over the place.
But cognition all the way down, it's cute.
In your paper, you mentioned.
But as I pointed out in my book, Dan, who is a very bright leading philosopher of mind,
also wrote things about neon color spreading that are just wrong. And then he became sarcastic
about all the fools who actually believe it's a phenomenon. And it really sarcasm in sciences
had hominem and gratuitous. And he was especially embarrassing when he was wrong.
And at a meeting where I invited him to speak because I don't only invite people who agree with
he said to the audience that he was wrong. But I'm not sure if after he left the meeting,
he still said he would just surrounded by good psychosis and neuroscientists and modelers.
And what exactly did he say?
And what exactly he well, I think part of my talk was, I think, you know, so long ago explaining
a lot of data about how we consciously see, you know, brightness, perception, form,
the end color spreading, you know, general surface filling in the complementarity of
perceptual boundaries and surfaces. And he was one of two philosophies of mind I invited.
Anyway, he just got up and started his talk with that retraction.
Because what, you know, if he had claimed it again, people would say, but
but Steve just explained data about it. It exists. You can see it, you know, with your own mind.
So I don't know where he stands on it. Now he's very bright and very creative.
But he went too far there and he was wrong. And what made what annoyed me was it's my
current understanding that he first heard about neon color spreading. When he came kindly,
I don't take it to granted, people come to my lecture, he came to a talk I gave on vision and
which one of the kinds of data I was explaining was neon color spreading data. And, you know,
as part of a more integrated view of a lot of visual processes, like neon color spreading is,
you know, the reason it got popular. Well, one reason it got popular is because we
pulled it out of anonymity, because I could see that it gave really good visible evidence
of our predicted laws of how boundaries and surfaces interact, because there were colors
where there shouldn't have been colors. And I actually
emphasized it. And then Ken Akiyama and Mike Paradiso and other people picked up on it
and started doing more experimental work on it. But it was, it was lying unnoticed until
the theory clarified how remarkable the interactions were and gave compelling evidence
of surface filling in, which is precisely what Dan was saying doesn't exist.
Yes, that is something you have. And it's not the only one, you know, Mike,
my very gifted colleague, Ben Jo Pinner, has what he calls a watercolor effect, which is all
about surface filling in. And, you know, you could say this is due to the first competitive
stage doing that. I mean, we can explain it, and you can see it.
Are there any, are there any philosophers of mind who that whose work you're familiar with,
who you feel does represent your form of emergentism in a great way, or your view on
consciousness in a similar way? Well, people don't have to do what I do in any way. I'm
blocking on his name. The other philosopher of mind, who I invited to that meeting long ago,
is a Canadian guy, and I forget his name. It's, I shouldn't forget it, but I, you know, I'd have
to pry my stuff, my mind's elsewhere now. And he gave a lovely talk. I really thought it was a useful,
interesting talk. Was it Paul Churchland? No, it's not Paul. No, Paul also did serious work.
I'm not sure. Anyway, but, but my advice to anyone who wants to talk scientifically about
mind and brain is read the data, and then read the state of the modeling community,
because you don't want to make a fool of yourself.
No, okay, so with that in mind, so we've discussed the people who have,
let me, let me make a remark about that, you know,
I forget who said it, but a very distinguished guy who I very much admired, and, and he gave a
keynote lecture. And, and he said, you know, everybody thinks they can have a theory about
how our minds were quits, we have a mind. But by extension, we also have electrons and
photons and atomic nuclei. Do we feel we're immediately physicists, you know? Yeah. I mean,
it's people think introspective evidence will explain their mind, but remember the main point of
cognitive and penetrability is that you and I can see each other, hear each other have feelings
about each other, learn from each other. Because we have no cognitive penetrability, we don't
know what's up here. We don't know that even the brain is the seed of intelligence from our
daily experience. And as you know, anyone who studied the history of neuroscience knows people
originally thought that other organs were the seed of intelligence, the heart or the
pancreas, you know, so, yeah. So, so to you, I mean, fundamentally, the that phenomenological
first person, subjective qualia, that qualitative field is explainable via scientific theory.
I'm just obviously I'm just playing devil's advocate. I know what your view pretty much is,
but I want people to understand this as much as possible, that intentionality that people
that intentionality, the aboutness of reality. For you, that's nothing so
and special about this. Well, again, you have to be very clear about how you use the word intentionality.
I mean, for example, an adaptive resonance theory, there are top down expectations,
which were a form of intentionality. There are predictions of what's going to happen next,
which are a form of intentionality. I'd have to know an example that would be different from that
to realize that someone's talking about something else. So, using the nice word, you know, some
words are better as chapter headings. And then you write what you mean by the word in and of
themselves. They don't tell you, do you know what, what meaning of intentionality is being
expressed here? Can you articulate it better? Did I say something irrelevant? What would be,
I think, maybe the best way for me to do that, let me define it from the
Stanford X-cycle video philosophy is to make it easier. In philosophy, intentionality
is the power of minds and mental states to be about, to represent or to stand for things,
properties and states of affairs. Now, I know in your theory, obviously, you address these,
but to a philosopher of mind, this is considered almost a very special property, a qualitative,
it's difficult for me to actually explain it, to be honest.
That's what all my work is about. That's what the work does. But when you're talking about
what it's about, there are multi-dimensional aspects of that knowing, including the perceptual,
the cognitive, the recollective, the emotional, the action, the appetitive. It's too vague.
The issue is explanatory power. As people have written about time and again,
you know, in physics, people were doing natural philosophy until they could explain stuff and
then it was called physics. I think that's true of philosophy of mind, too. I mean, I took philosophy
courses in college and what they were good at was imposing questions, articulating questions.
But if you wanted the answers, you have to turn to science.
But also, what I found is by getting to a deep principled understanding of something,
it helps me to articulate new questions that I couldn't have done just based on intuition alone.
Intuition is limited. I mean, it is so important that because we can't consciously see, because
we can't consciously feel and so on, that helps us to know at least, well, what are we trying to
explain? I want to explain how I see, you know, how I see color and brightness and texture and
shading and objects and, you know, motion and, you know, all this stuff. So it gives us a whole
series of chapter headings. But to actually explain it, you have to think in a totally
different way. And finding that way I have found requires an immersion into large databases that
probe the different aspects of the properties that you're trying to explain. You can't just, hey,
hey, I bet it's like this and be right. The chances are as close to zero as you can imagine.
Hunches are good. Don't get me wrong. I mean, hunches help theorists think about, oh, I should
have been thinking about that. But the hunch you'll have after you know a lot will be very
different from the hunch you have when you know very little. Steve, you mentioned you know Paul
Churchland and he was a very problem. No, I don't. I don't know Paul. Okay, but you know off. I just
knew. Yeah, I knew that he did some good work, but I haven't looked at it for many years. Okay,
so there was Paul and Patricia Churchland and they were the theory known as Eliminative Materialism.
And what that was was it was it's a very radical claim basically ordinary common sense terms.
So common sense understandings of the mind, they claim to be deeply incorrect. They felt that
folk psychological terms that we use. So even saying things like learning or thought, etc.
Don't technically work in the physical world because when you take materialism to be true,
you have to realize that reality is just neurons fired. It's actually got there is no secondary
reality in psychology where we could say things like, okay, that's thought, that's memory,
that's conscious experiences. Because in reality, that's just neurons firing. That's just blood
circulating, etc. etc. So yeah, well, what are you all all that? Well,
first words like learning and thought are more chapter headings. You know, they're not theories,
they're not principles that chapter heading, then you've got if you're going to continue using those
words at all, you've got to say what you mean. So for example, I invented the phrase adaptive
resonance in order to describe a brain process for which there was a great deal of evidence
that I could explain. The word wasn't there before and I've done that. We've talked about
spectral timing. I invented the word spectral timing. We talked about neural relativity.
I invented the word neural relativity. You know, I mean, all these words come out of an analysis
of lots of data. But you know, again, we're just getting back to the problem of emergent properties.
It's not just neurons. It's neuronal interactions that generate emergent properties
that often cause actions that lead to feedback that create a cycle of perception, cognition,
emotion, action over and over and over as you evolve in the world. And through that cycle, if
there are statistically repeatable enough or stable enough properties of that interaction,
you will learn about them as appropriate to the circuits that are resonating with those
particular invariants. And as I mentioned last time, you know, we talked briefly about cognitive
emotional interactions. To me, it was very satisfying that cognitive and emotional circuits
share many properties. But one thing they don't share is their inputs and their outputs,
like with emotion, you have a lot of interceptive inputs of hunger, satiety,
pain, you know, whatever, belief, happiness. And with cognition, usually there's a
perceptual front end, envision, audition, you know, tactile that drive those. And then there's
an interface that resonates. So a lot of the circuitry can be shared but specialized in order to
be able to resonate with particular invariants of the environments that they are trying to
understand. That's a bad word, it's a loaded word, to the environments for which they have adapted.
Yes, so emergent properties, emergent properties, emergent properties, which you cannot understand
without a sufficiently powerful and principled computational, mathematically rigorous theory.
And there is that explanatory gap without theory.
In your work, I mean, you refer to this as establishing a linking hypothesis.
Between brain and mind, yeah. Well, it's a familiar phrase, linking hypothesis.
Yeah, and I don't want us to go in circles, but if you don't have a way to generate the
emergent properties linking to behavior, then you really can't mechanistically explain behavior.
Okay, no, so I've got a lot of questions from fans and audience members in general, but
tell that some of them are going to take us in circles. Well, that's okay. You know, I don't
think it's bad to say the same thing more than once. I think I might have mentioned I would
sometimes give the same keynote at two different conferences, assuming that because they were in
different continents or whatever, a lot of the people hadn't heard it. And then I see in the
audience, some of the same people and they said, you know, it's good to hear more than once. Oh,
by the way, I forgot to mention, you know, there are, when it comes to my 2017 paper on the hard
problem, I do have keynote lectures about that on my webpage. My webpage, your relegation is
sites, s-i-t-e-s dot b-u for Boston University, dot e-d-u for education slash Steve G. That's
s-t-e-v-e-g, sites dot b-u dot d-d-u slash Steve G. So for people who want to hear
that lecture given, I might have given that one in more than one form, I forget,
and sometimes I will have both of them put on my webpage. But there are a number of
keynotes that I try to make self-contained for interdisciplinary audiences. But, you know,
as we were joking before, self-contained depends on where you're coming from.
No, exactly. But they keep inviting me back. So I assume I couldn't have been that bad. I keep
getting invited back. So. Well, yeah, as well, we'll help to solidify some of these concepts for
people because I think it does require repeat reading, repeat watching, and repeat listening
just to get all of these, well, in your world, to see, feel, and experience this a lot more,
resonate with it a bit. Well, I would recommend, you know, a discussion such as ours, I think,
for me, is successful if it motivates someone to want to learn more. And then I would recommend
someone go to one of the videos on my webpage or YouTube or wherever
and listen to the lecture. Yes. And maybe listen more than once and stop it and repeat if you,
what is he talking about? And after you've done that, until you feel I know a little better,
then go to some of the articles. And some of the articles are heuristic,
like my 2017 paper is in a way, even though it breaks new ground in a way, it's a review paper,
because a lot of the foundational mathematical work is earlier, or I wouldn't have had the nerve to
write that paper, because I knew everything I was writing is supported by mathematical models and
computer simulations of challenging data. So, you know, there were levels
from an art chat to videos of self-contained lectures to reading,
hopefully non-technical review papers to technical ones. But really, the best resource I can recommend
is my magnum opus, conscious mind, resonant brain, colon, how each brain makes mind.
Because there I work really hard to write a self-contained and non-technical synthesis and
overview of my work in many different areas as well as to bring together and try to clarify the
meaning of the work of really hundreds of other scientists. So, but as we might have mentioned
last time, you know, we are talking about this, and this is one of the hard things to understand
in the world. So, nothing that I would write about it, I hope would be trivial, but I hope it's,
you could see, oh, he's writing clearly. I just have to stop and think about what he just wrote.
And one reason I have over 600 color figures is to help people to visualize
the concepts that the words are trying to express. Because until you can get a picture in your mind,
it's often hard to know what the hell someone's talking about, and it's not only me, it's anything.
So, yeah.
Steve, talk to me about one of the one of the other very leading theories of consciousness,
which is global neuronal workspace. What are your views on that theory of consciousness?
Well, I'm not going to give a professional review like you would for a journal article.
I'm blocking on who's, I know the very nice fellow who promotes it. What is his name?
Bernard Bos.
Yeah, I know Bernie Bos. He's a very nice guy, and he's very dedicated and sincere.
Just check what his predictive and explanatory range is, that's all I could say.
I mean, it's not for me to try to give a review of Bernie's work. You should ask Bernie to review
his work. I think it's always intriguing to see where, I mean, you guys either align or disagree.
It's fascinating, particularly for the audience, to kind of get a grasp of where you guys diverge
or intersect. Well, I could discuss it. Bernie had an explanation of a certain fact,
and I thought it was correct. I'd say, yeah, I agree. But if I thought it was incorrect, I'd say,
well, I would explain it as well as that I can do. But to give some holistic way and waving
evaluation of Bernie's hard work, no, I won't play that game. I don't think it's constructive.
If people find value in reading Bernie's work, they should read it. If there are still questions,
they'd like answered, and they can find some of those questions given more complete answers in
my work, they should read my book. There is a section within the book where you do discuss it,
and the fact that that theory sort of does provide a little bit more information when
you compare it to the other ones that we briefly discussed. Oh, yeah, Bernie is more serious, I
think. Okay. Okay, let's let you know. I'd like to leave it at that. Was that one of the
questions someone wanted to comment on? I haven't gotten to those. Well, you better get to that,
because it's an hour and a half in, and I can go up the two hours or so. Let's go. So one of my
friends actually asked this question. This question, this first question, one of my friends asked this,
he wants to remain unnamed, but he wants to know at what, so let me just read this.
At what point would, sorry, I just missed, okay, at what point would Professor Grossberg
delineate between zero conscious experience and conscious experience? Are all conscious experiences
considered to be resonant states in that regard? Well, you know, later in my book, I talk about
quite a few mental disorders. And for example, without talking about parametric properties of
behavioral symptoms, and the mechanisms that cause them, and what has gone wrong there
in altering consciousness, you know, if you don't have a sufficiently sustained and energetic
adaptive resonance that is resonating with either external stimuli or internal memory
representations, it won't get to consciousness. You know, what I'm blocking on his name now,
oh, he did very nice work. You know, I talk about it a little in my book where, you know,
usually the stimulation our senses get by the time we're consciously aware of it
can be 150 to 300 milliseconds later. And that's partly because in addition to the
all the preprocessing stages, you then have to activate resonating circuits that have to
resonate for a sufficiently sustained and energetic interval before it becomes conscious.
So anything that prevents that will not become conscious. And there are many ways that can be
prevented. In your work, you also you address the fact that not all resonance states are
conscious states, but conscious states are always resonance states.
Yes, not all resonance states are conscious. And I give example to that. For example, I mentioned
grid cells and play cells will enter Rhino hippocampal resonances which
support the stable learning stable and coordinated learning of grid and play cell
receptor fields are not conscious. They are not linked to internal or external sources of
of sensory experience. Not directly, you know, for example, grid cells are sensitive to
linear motions and rotational motions. But those sensors aren't designed to support qualia.
And so, you know, there's just no nothing like a conscious awareness there. There are
inputs, but the inputs are very low level. Now it's another matter entirely if you try to link
the spatial representations that are learning grid and play cells with information like optic flow,
visual cues that are being synthesized when you navigate. So you use combinations of visual
and motor information to know where you are. And then if you suddenly in the dark,
you use path integration information. That's what the information about the linear and
angular movement is all about path integration or integrating how far these sensors think you've
gone. That's your ground truth. And my PhD student, Bill Gnatt and I developed a rather
comprehensive animat model of how, for example, how an animat would under visual guidance learn
to efficiently acquire a food reward, say that's in a maze, you know, how you would, first, you
would just be randomly exploring the maze, you know, that would be endogenous exploratory behavior.
And then how that, as you explore it, how that is transformed into an efficient, goal oriented
series of actions to efficiently acquire the goal in some distal part of the maze.
And there we do combine the visual and the path integration information to help
learn how to solve that problem. I forget what we call the model. It was, oh, the sovereign model,
sovereign for self organizing, visual expectation, you know, let me wait sovereign, maybe I can
sovereign. And I think that Bill thought of this when I thought, hey, that's not that
self organizing vision expectation, resonance, and on and on, I can't even remember what the other
letters stand for, but it is an acronym that captures the essence of what the architecture's
doing. And I say architecture, because not just a model, it's a very, you know,
you know, sparse version of a full animat, it doesn't have higher cognition, but it has working
memory, you know, it can learn sequential actions, et cetera, et cetera.
And there, you know, the design of working memory, I don't think we talk much about that, but,
you know, you can derive all working memories from a couple of simple postulates,
without having to do with stable learning. It's not surprisingly, but this is stable
learning of sequences. So even though in a working memory, it would be like,
you know, to have remember the following series of letters, five to eight, eight, nine, five, three.
And, you know, you can repeat it back to me, five to eight, eight, nine, five, three.
But if I distract you and say, hey, repeat it back to me, you can't, because it's in a short-term
temporary working memory buffer, you know, in computer science algorithms,
sometimes call it a blackboard, but this is more than a blackboard, this is a sub-organizing
blackboard. And one of the key issues here is how do you know which
subsequence of all the sequences you've just experienced is predicted in a given context.
And, you know, the theory gives a solution to that problem.
You want me to-
And, what?
Oh, sorry, you were, you, sorry, continue.
Well, well, and, you know, you can see immediately there are, there are issues. Let's say
I have already learned the word my, and I've learned the word self, and in particular I've
learned recognition categories of my and self. But now for the first time in working memory,
I represent myself, the new word with a new meaning. First problem, why doesn't adding self after my
undermine the previously learned inputs to the my and self category? But the second problem is,
how do you learn a new category for myself, given you have two perfectly good categories,
my and self, that already learned? How do you overcome the salience of the known to self-organize
a larger grouping that's unknown? And of course, if you couldn't do this, you couldn't learn language
or dance or navigational sequential skills, because we're talking here about short words,
my and self. The same problem arises with individual phonemes grouped into words.
And so, you know, my theory of working memories off is a computational solution
to that, you know, based on very simple principle. Remarkably, that also was first published in
my human memory paper in 78, when communication memory and development came out. It was a good
year. And, and one of the reasons I got into it was because it often fails.
You know, you might not know, but there was a, let me give you a simpler example of it. I was
interested more in verbal learning from when I was a boy. But, but did you over here, George Miller
is the magical number seven plus or minus two? Well, George Miller was the person who introduced
the notion of a chunk. And he basically showed that most people, if you tell them a series of
numbers or letters or whatever, they can't repeat it right back to you without learning,
or without actively trying to learn if the sequence is more than five to maybe nine,
depending on the person units. But then what he showed about chunks is that,
you know, you could do that for much higher level chunks.
You know, like, let's say you're controlling the movements of a dance, and you know, each movement,
you're a, you know, professional ballet dancer, and you can do all of the individual movements. And
now, you know, George Bell and Shane is teaching a new dance. Well, you have to be able to put that
sequence of movements into working memory, where each of the items in working memory is a chunk of
a familiar dance gesture. And so that he realized you could have, you know, sequences of chunks
creating another chunk. And you could get higher and higher. And that's how we learned so many of
the higher order things, because we chunked all the lower order stuff and automated it.
So we don't have to pay focal attention to things that are already chunked, they more or less
can be done under very much less oversight. Anyway, so that's what this theory is about.
How you get this chunking,
really, by solving the myself problem, by, in a stable way, it's sort of like the stability,
plasticity, dilemma, solve to sequence learning. But that was too far field, maybe. But it did get
a new, it got a new information. Yes, at least. And it wasn't, oh, I was talking about sovereign,
I was talking about sovereign, you need that to learn sequences of terms in sovereign.
Yeah. Okay, so the next question is from YouTube. It's by ecstasy.
Different functional modalities have been proposed to explain the emergence of qualia
from physical properties. Under the given art framework, how would residents even in principle
explain the perception of a qualitative state?
I'm not sure what qualitative state is. I don't mean to be perverse. I mean, the first thing that
comes to my mind, of course, is that we have to ask ourselves what flavor of what we're talking about,
you know, the category learning stuff, as I had briefly reviewed last time, it's about
feature category resonances. But if you're talking about experiences from the external world,
let's say a visual experience, what you're often conscious of is a surface route resonance,
which is a conscious seeing. And if you synchronize surface route and feature category
resonances, you know, and see about the object or event, and then the surface route resonance
via posterior parietal cortex can can control actions, which we've learned in response to
that combination of events. But now I didn't understand the last two words that I don't
know what they mean. Yeah, the last two words. I think this is basically referring to qualia,
that qualia like state. Well, I just commented on that. Yeah, you have you have surface route
resonance, you have stream shroud resonances, they're not the same as basic category learning.
And they, and when I hear and see, and know things about you, you're a coordinated synchronization
of surface route, stream shroud,
feature category, and to the extent of which your processing sequences, you know,
their item list resonances responding all this, because that's where you get understanding of
speech and language. So there are all these resonances that are being coordinated quite
wonderfully. And, you know, you have resonance and reset resonance and reset. So as, as our visual
representations of a momentary visual experience is reset by your movement to what have you,
and I have another frame. And so I have a sequence of these, you know, likewise, we're
updating all our working memories, because the sequential information that's forming the context
of them is changing. One of my articles, you know, I try to bring together a lot of,
a lot of these ways of thinking in an article that I think that I published it in 20,
19, 20, 20. It's an article that starts, well, I think it's one of the latest, maybe
it's one of the latest chapters in my book. Let me,
um, do you have the chapter names in front of you by chance?
Let me, let me try to search for it. It's important that I make this comment. Okay,
I'll go to my, uh, okay. Let me see, um, oh, I have to turn off airplane mode.
That was to stop me from getting bothered airplane mode. Okay. I'll be there in a minute. I have no
fear. It's fine. I'm just going to answer the questions.
Okay. I think this is it as a list of the chapter titles on the Oxford listing.
Oops. I hit the wrong thing. Okay.
Okay. Let me see. Okay. Okay. Yeah. Yeah. Yeah.
Yeah, it was chapter 14, how prefrontal cortex works,
colon cognitive working memory planning in emotion can jointly achieve valued goals.
Yeah. Sorry, Steve, my, my copy of the book isn't in this office.
No, it's fine. I'm looking at it, but, but, um, yeah, and I'm, it's not, I have the abstract and
the keywords here. Um, but it's, let me get the book one second. I'll get it. I have a copy in the
next room. Anyway, for people who haven't seen the cover, this is the cover and the background around
the brain is neon color spreading. If you look carefully at it, you'll see the red or the blue
spreading out of their crosses. Because I thought of that, you know, as such an important example of
the complementarity of boundaries and surfaces. And let me go here. Okay.
I want to do that.
What, what, except for that aspect,
what is that the artwork? Well, what, how did you come up with that? That is the idea for the artwork.
Oh, well,
um, I wanted a cover that, um,
um, so I said what the book is about. So, you know, the title is on a brain. And, um,
uh, the brain is into Hemifield and I fiddled with trying to indicate the complementarity of
the Hemifields cause the water and wet streams and stuff like that. Other parts of the brain
complemented, made it too complicated. But so that said, it's just brain, but neon color spreading,
the spreading is an emergent property that happens in our mind. It's a property of our conscious
visual awareness. And I thought it would be nice to emphasize on the cover. It's about emergent
properties. Um, and, um, uh, I'm trying, I thought I, oh yes. Yeah, yeah. Um,
I, Betsy Murray stimulated me to write, to make some of these discoveries cause
Betsy told me that they had all this wonderful data in prefrontal cortex that no one could explain.
And so she sent me the paper and I realized that not only could I explain it, but I predicted
some of it. And, you know, and they have, you know, words like desirability and availability
stuff like that, which are good words for the phenomenon that they were talking about. But,
you know, a macro circuit in complete one of, of the predicted adaptive resonance theory I needed
for this. I don't know if you can see that, but I couldn't put in the basal ganglia or a number
of other things. And those different colors, the red, green, what have you, are systems.
And so it just showed that like for prefrontal cortex, I needed and, and explained data from
seven interacting parts of the prefrontal cortex. It's not a unitary thing. It's a complex organ.
And then I also, in red, I had some of the main reinforcement learning kind of things that,
and then just in black and white, I had some of the main vision and spatial kind of things. Anyway,
I, I, Roy, you want me to move? I think the point I would, the point was I was trying to
clarify that, you know, the prefrontal cortical work really is a synthesis of a lot of work.
Yes, and I think, I think that
things really came together in a nice way.
You know, with a number of points in my book, I point out, you shouldn't take for granted that
the next step could be taken. And this happened to me over and over again, how the previous work
sort of thrust me into a new area where I knew they were interacting with. And the same things
with the prefrontal cortical work, so many parts of the brain are interacting there to explain
really challenging quantitative data, physiological data mostly. But, you know, it's all an accumulation
of evidence. And if you're a really good theorist, you can weigh the amount of evidence for this
part or that part or the other part. You know where the weaknesses are, where, where you might
have variations on a theme that don't undermine any of the principles as you would expect
for species specific variations of the design. And you also know what you can't explain.
And, and that keeps you up night until you can. So this is not, this is not finished, but I think
if someone wanted to get into an overview of some of my work after this discussion and maybe looking
at a lecture of mine on my web, you might look at my magnum opens and I want to emphasize one thing.
It's a long book. After you read the preface and introductory chapter one, I wrote it so that you
could jump directly to any chapter that's topic interested. You don't have to read it all. I don't
expect even interested people have the time or interest to read it all. The chapters are written
independently of each other. And so, you know, if you wanted to read more about art in the
sense of future category resonance, jump to chapter five. But if you wanted to read about
prefrontal cortex, you'd go to chapter 13. If you wanted to know about spatial navigation,
I think it was chapter 16. If you wanted to know about visual perception,
go to the first few chapters, and so on. Yeah, I really enjoyed that aspect. I said this the
last time. It's that easily accessible nature of the book, the way you can just jump from chapter
to chapter without having a preconceived idea of the previous chapter makes it very accessible.
Steve, one last question, and this one's from Facebook. This is a funny one,
Brancina. Who resonates most in the Grossberg-Karperter household?
Whoa, now this is getting very personal. Who resonates most with why?
I have no idea. That's just the question. That's where the question ends.
Well, all I could say is that Gail Carpenter is the love of my life. We've been together for a
half century. She has strict instructions that she can't pre-decease me, because she's younger
than I am. We already spoke on the phone earlier today. I'm in Truro on Cape Cod, and she's back
in Newton, where we have our main residence. I'll be talking to at least two, three more times today.
She's a brilliant neural network modeler. She's done foundational work,
as well as really doing some of the best work on large-scale applications, like she did really
important work on remote sensing, on medical database prediction. One of the things she
did that I think should be studied more, and I think she'd agree,
is in a remote sensing context, where you can have multiple observers.
They're each looking at different pieces of a remotely sensed terrain, maybe with different
combinations of sensors. They will create their own personal labels for what they're trying to
describe. One person might say water, one person might say pond, another person might say lake,
for the very same object. They only do this for a subset, usually a pretty small subset, of the
remotely sensed terrain, because it's expensive to get ground through. Someone has to be running
around down there. How do you input this kind of information, which may be incomplete, probabilistic,
sometimes self-contradictory, and out of it, automatically learn a cognitive hierarchy of
rules, including the confidence you have of the links in the hierarchy. Whereas you get higher
and higher in the higher and higher in the rules, they get more and more abstract. I think that
is a foundational contribution, a really quite a wonderful one. That needs a lot more work.
Gail and I are both no longer teaching, we're both emeritus, and that doesn't mean we're
brain dead. I just published my last paper, I think a few weeks ago, and I'm writing another book,
but Gail's not going to work on that project again, and that project could really be very
interesting, especially if you're in some kind of a technology AI lab. That's a kind of project
that Google could really sink its teeth into, because you could do it for the whole world.
And part of it, we got into it because many years ago, I gave a lecture at the Optical Society
meeting about some of the vision modeling work, and there were several program managers from
MIT, Lincoln lab there, which is one of the great sensor houses in the world. They have laid
our multi-spectral IOS and tetic aperture radar and so on, and very much pixelated data with very
intense pixels and dropout pixels and a lot of noise, and they realized that the kind of work,
even then, that we were doing in vision modeling could help them process their sensor data. And
in fact, there was a very active project at Lincoln lab for a while doing that. They also
designed a robot based on some of our ideas and sensory motor control course, some of the models
I developed with my students and platform independent, they work with wheels or legs or what have
you. Yeah, so what more should I say about my wife? My best friend, the love of my life,
the mother of a wonderful daughter, and we have wonderful grandchildren. We feel super lucky,
super lucky. I love the way your face lights up when you talk about us, Steve. Sorry for the
personal question, but I thought it's quite cool that you bought such great pioneers in this field,
and I thought it would be a nice question to ask from, well, it wasn't mine, but I chose it.
To sum it up, we've been a real mom and pop show where I have many projects without Gail,
she, many without me, and we've done, I think, at least 20 projects together, and you know,
they're sort of like our scientific children. Well, I think it's absolutely beautiful,
and keep up, keep up the great work. Steve, thank you again for joining me. So I really appreciate
your round two, and you've also written a paper on illusions enough that I find very fascinating,
and I hope at some point we can also dissect one of those. And with that one, it will be far less
philosophical and a lot more scientific. So I think you'll enjoy it a lot more as well.
Yeah, well, I love studying, especially visual illusions, of course.
You know, it's sort of like how very young people can get
excited by mathematics, some of the hardest problems in number theory you can say to any child,
and then it takes third math to solve it. But visual illusions, it's right there,
it's in your face, and immediacy raises questions of how do you see anything?
What's next step to having me on? And so this would be part, this would be part two of this
series. Yes, definitely. That's so much. I enjoyed this. Thank you so much, Steve. I appreciate it.
