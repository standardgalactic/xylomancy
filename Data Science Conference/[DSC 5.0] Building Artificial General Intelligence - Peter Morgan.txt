So, hi everybody, as a guy gentleman just said, I'm the CEO of a consulting company
in London called Deep Learning Partnership and I'm going to talk to you today about
something I don't really do on my day-to-day job that doesn't pay my rent, but it affords
me nice trips to exotic places. So, who here has heard of artificial general intelligence?
Yeah, so quite a few. And so what we label today is AI, isn't really AI, it's matrix
multiplication. So I'm going to talk to you today about how we might actually get to AGI
and it's more of a neuroscience based approach. It's how the brain works, it's how biology does it.
So it's okay, everything that we've heard the speakers talk about so far,
which has been labeled AI is really deep learning or artificial neural networks
and the early creators of that said this is nothing to do with how the brain works, right?
It's just it kind of works to classify cats and dogs and that's about it. Okay, we do a lot more
than that. So how do we get there? Is it even possible to build an artificial brain basically
how biology does it? And I'm here to tell you yes it is, I'll just give it away, you can go now,
but if you're interested, I'll walk you through how that might look and how that might be done.
Okay, so here's a little book I wrote for Riley, it's a booklet. There's my company website,
there's my Twitter handle, you can follow me, I tweet a little bit about AGI and sometimes
quantum computing my other hobby or interest. So this is what we're going to outline just briefly,
we're going to look at physical systems, how biology does intelligence and you know where
we are with the non-biological, I've kind of just explained that in a broad sense, but we'll look at
some of the, well we'll go through the slides, deep learning recap and then we'll look at how we
might build AGI and some of the theories and in particular one called active inference that
I find particularly compelling to how the brain might work. Okay, so at that point,
it's sort of theoretical neuroscience, so I hope I don't lose you. I try to keep this kind of high
level and not too much code or anything, although there is code and math for this stuff. And then
we'll wrap it up by saying is it possible, how long might it take? Okay, so why do we even want to
build AGI? Why don't we just stop here with the cats and dogs and TensorFlow? Well if we do,
like DeepMind says, if we can solve intelligence and we can use it to solve everything else,
I mean we're quite good at stuff, we've got here today, we've had Einstein's theory of relativity,
we've had quantum physics, we've had classical physics, Newton, all the big names, why do we
need any help? Well clearly if we do manage to figure this out and build an artificially
general intelligent system, then we can accelerate progress, which is probably, we can all agree,
is a good thing. Although some people like Elon Musk say that, let's not build it because it will
straight away kill us all, right? Well, we don't know, but I don't think it will. Okay, so I'm
the anti-Elon Musk, okay, I'm the opposite. Okay, so I'm an optimist, he's a pessimist.
So he's a good entrepreneur anyway. So what about all of these things here? AlphaGo,
this is DeepMind in London, I'm sure we all saw on TV, AlphaGo beating the best go player in the
world, was that AI, was that AGI? AlphaStar, it's a new project to beat the world's best video game
players, a little bit more general one might argue than just playing a board game. DeepBlue,
IBM's DeepBlue and Chess, Landmark, and IBM Watson, that's actually natural language processing,
so that's quite clever, that's quite getting a little closer to AGI maybe, because it's having
to understand language, but was it just doing it statistically? Was it just a massive computer
hardware system that could crunch numbers really well and just do everything statistically? Is
it how we learn language and understand language? I would argue no. So actually,
all of those are just narrow AI, they're just statistical mathematical analysis of big data
sets, okay, so it's not really how the brain does anything. If it were, I mean, we do all of that
in the little three pound thing above our sitting above our shoulders, right? We don't need huge
data centers, so clearly biology is doing it in a slightly different way, okay, so how is it
doing it and how is it different? So, well, first of all, you know, to build something, we have to
understand what we're building, what is intelligence, general intelligence? Well, it's all these things,
right? So, you know, we don't just classify things, we do all of that. I won't read them out,
because I've only got 30 minutes and sometimes, you know, I give this talk it's an hour,
but there's basically nine types of intelligence here, maybe even 10, and this guy at Harvard,
Howard Gardner, just mapped it all out, see, you know, existential thinking language,
you know, we can do math using ANNs, but the rest of it is pretty much music, creating art,
you know, spatial navigation, yeah, that's all, we can do all of that in three pound, we don't
need a huge data center, hardware cluster of GPUs, so what's different, what are we missing, okay?
Well, first of all, how far have we come? Like I said, you know, the mathematical
part, we're like 50%, we're pretty good, we're not bad, we're about halfway there,
linguistic, but it's only statistical analysis. Spatial navigation, self-driving cars, robots
who can navigate through systems, I'd say we're about something called SLAM, I'd say we're about
50% there, that's the algorithm, simultaneous mapping, and I forgot what the LAM stands for,
but don't worry, we're about 50% there, you've probably seen simultaneous localization of mapping,
you've probably seen the Atlas, you know, robot that do flips and run around outside and do good
stuff, busts and dynamics, so that's why I'm giving it a generous 50%, we do a lot more than that,
we can do gymnastics, we can run around, we learn stuff very quickly, we don't need millions of
datasets to train, but as we go through that list of nine types of intelligence, it gets really,
it just gets worse, right? Robots understanding each other, or even algorithms running on a
computer virtual sort of intelligence, interpersonal understanding themselves and existential,
you know, show me an algorithm or robot that kind of questions why it's there, or even
understands that it exists, it's kind of zero, okay, so we haven't figured that intelligence out
at all, so the brain is pretty special, right? Biology is kind of special, you know, we could
argue chimpanzees, self-aware, well yes, right, dogs, cats, probably, and as you go, you know,
snails, maybe not, you know, bacteria, no, so there's clearly a continuum in what makes us
a little different is our neocortex, that sort of outer layer of the brain, so we kind of have to
figure out how that works basically, but we've got all this other stuff in the brain like your
megalith or emotional intelligence, you know, the reptilian brain, and there's sort of layers,
you can trace it, in fact, you know, as babies are born and embryos develop over the nine months,
you know, maybe you could see, you know, evolution, it starts off, you know, with the,
you know, reptilian brain, and it goes out monkey and then, you know, humans as we develop in the
womb, so, you know, it's all, all of that evolution is still captured, all that information is actually
captured by biology, it's just that last layer, the neocortex that makes us be able to come up with,
you know, science, special theory of relativity, whatever, you know, that, that, so what are we
missing, why can't we do that yet in TensorFlow, okay, why can't Google or DeepMind do that yet,
so how will we get there, well, it takes a village to create a child, and I'm going to argue it takes,
it's going to take a big community to create AGI, we're going to need computer scientists,
physicists to understand the physics of the brain, neuroscientists, clearly,
and also psychologists, so what I'm seeing really at the moment, where these teams trying to build
AGI or AI, just computer scientists, you know, just computer scientists, you know,
you clever people, they have PhDs and computer science, which involves a lot of math and
understanding hardware and algorithm, algorithmic complexity, but it's not really
understanding how much about biology at all, okay, so we're going to need a whole bunch of people,
and so I'll speed up a little bit now, I've kind of laid the foundations for what we might need,
so this is basically what we've got in hardware, so this is how biology does it in hardware,
so, you know, like I mentioned, we have a continuum from bacteria, that's a simple,
C. elegans is the simplest biological system with a central nervous system, it has,
I think, about 300 neurons, then the bumble bee, the humble bumble bee with about a million,
a few million neurons, and then us with about 80 billion or 100 billion neurons, okay,
so what, you know, that basically, maybe if we start the simple, the C. elegans,
and then build a bumble bee, then maybe one day, you know, we'll get to us, that's one sort of thought.
The other observation, really, is that nature is very hierarchical, you know, we're built
neurons, they're not magic, you know, they're built of atoms, molecules, and then if we just go up
the different layers, we have synapses, neurons, then collection of neurons is a connectome,
so these 80 billion neurons are organized into some kind of structure, maybe, you know, we should
start there, so the question here is, you know, what level do we start at, do we have to start at
molecules, or can we start at neurons, or should we start a little more holistically at the connectome,
you know, and on and on up until the central nervous system, us, which is about a meter in
dimension, so we're going from 10 to the minus 10 up to a meter, so it's a hard problem, it's kind of
no wonder we haven't solved it yet, there's a lot of physics in there,
and so that's what it looks like, this is how nature has done it, it's complicated, isn't it,
you know, I mean, do we need all that little tiny microstructure, probably not, I might argue,
so you know, this is how, you know, what do we, four and a half billion years of evolution on the
earth, maybe a billion since the first sort of organisms, bacteria, whatever, the first, you
know, primitive life, so over that billion year, this is what nature has ended up with, right,
this is what makes us intelligent, these things, right, you couldn't guess that, you start with a
blank piece of paper, but this is just the universe we live in, the laws of physics, this is how we
work, okay, so there's no magic, but there's certainly a lot of complication, it's this
complicated looking thing, that's a neuron, okay, and so the next level of the hierarchy,
we see that these neurons are kind of organized into some kind of structure called cortical columns,
which each have about two million neurons, so maybe this is a good level to start, maybe we
don't have to go right down to all that complicated structure, maybe here, so that's kind of an
interesting thing that we know, and then up onto the connectome, and then the central nervous
system, that if we want to build a robot, we edit those flips, we'll probably need all of that
connected to the brain at the top, okay, so, and then we have societies, we're organized into
societies, bees are, you know, and there's swarms and humans in their villages, towns, cities,
countries, and then the global national community, so there's all these layers of hierarchy,
which are intelligent, right, so, you know, we have this kind of macro,
meta-intelligence built into communities and systems of communities, which has enabled us to,
you know, survive, reproduce into the next generation, so, okay, so that's biology,
that's how it works, that's how it does it, that's what we know, plus a whole lot of other details,
which I haven't really covered, so what have we done, how far are we along the line with hardware,
so, basically, the talks that we'll see here, you know, talking about CPUs, HCO, GPUs, that's
what they use, sparkling water all runs on these things, there's a new sort of endeavour to build
ASICs, which are specialized for deep learning, but again, it's just narrow AI, it's matrix
multiplication, but is it GROC and Cerebrus, Graphcore, Intel, Nirvana, they're all coming
out with these amazing things that can do, you know, petaflops operations, which is more than
a brain does, it's actually more than biology does, but all they're doing is multiplying matrices,
right, they're incredible feats of micro engineering, incredible, these fabs cost,
you know, billions of dollars to build, they've all raised, you know, Graphcore just raised 200
million dollars, and they're impressive things, right, and that's what they look like, that CPU,
GPU, there's a Google TPU, which is an ASIC, and runs in their data centres, you can hire them,
run them in the cloud, and then there's the Graphcore IPU, and they all look the same, but,
you know, the micro architecture is a little different, so that, you know, this is all digital,
classical, if you do computer science, you'd understand, you know, the details of how bits
move around in there, how much energy it takes, how the memory in the processor,
you know, interact together, but they're not intelligent, right, they're just very good
mathematical processes, okay, that's what a hundred petaflops looks like, and you can,
you know, log in today to these things, in the Google data centre, this is the most powerful,
you know, three exaflops, for goodness sake, that's 1,000 million, almost a million times
more powerful than the brain, but it's as dumb as a brick, it's incredibly impressive engineering,
it takes up a football field, it's a data centre size, but you know, you can't do much except for
model plane numbers together, it's not intelligent, okay, so clearly we're heading into a dead end,
if we just follow that, computer science, classical, digital hardware route, see the brain
does all of that, and all the other types of intelligence in that little three pound mass,
so clearly it's not just about speed of compute, right, it's not just about horsepower,
so what is it about, okay, so recently, some of you, who's heard of neuromorphic computing,
who's heard of that, yeah, maybe a few, right, a couple, so there's a project called Spinnaker
in the UK, there's IBM True North, Intel, there's, you know, a few different projects
that are trying to do mimic how biology in hardware, you know, does computation,
okay, it's called neuromorphic computing, so it's based on the brain, and so there's Steve Furber,
he's one of the guys who come up, invented, founded the ARM processor company, and so he,
20 years ago, left ARM and started on this neuromorphic journey, and he's based at University of
Manchester, and recently the human brain project has folded, it's called Spinnaker, into itself,
because it's biopausable hardware, so they have lots of nice funding now, again, as IBM True North
and Intel, I mean, these companies have a lot of money too, so that's what it looks like,
so there's five racks there, that is about as powerful as the brain of a mouse,
so it's not human level yet, but it can do things, it can go through a maze, it can solve Sudoku,
and stuff like that, just like we do, so it's kind of getting there, and I would argue, you know,
to build intelligence, rather than just simulating it on classical digital hardware, this is a
more intelligent route to take, okay, so, and there's a little bit of detail, so this is an
important, you know, technology, and a new path that not many have heard of here, you know, which
is very interesting, it's probably like we were in the 50s with digital computing, you know,
there's just a few main frames in the world right now, a few of these devices, but they actually
exist, and you can actually log into Spinnaker, it's part of the human brain project, you can
create an account and log in and watch it do stuff in real time, so they're not these magical,
mystical things in a lab, they're kind of getting in real, and let's see, so that's okay, that's
another initiative from Heidelberg, the brain scales project, which is also part of the human
brain project, so the one on the left, I would argue, will get us to general intelligence, the
one on the right, no matter how impressive that looks, won't, okay, so, and then there's quantum
computing, how about it, is the brain quantum? No, it's warm, it's squidgy, nothing to do with
quantum at all, okay, although birds navigate and plants photosynthesize using quantum processes,
but it's not really generally how we do it, okay, but the pictures look really nice, I decide to
include a couple, and there it is, what a quantum circuit looks like, I also quite like quantum
computing, because I have a physics background, but it's probably, we don't need to worry about that,
if we're building AGI, it might help some of the computations initially, but ultimately we're not a
quantum computer up here, it's a neuromorphic computer, okay, so that's the sort of four
different types of hardware, and I'd argue the one on the top right, neuromorphic will get us there,
and that's how they look in a little bit more detail, and so, you know, it's not magic, it's
just really hard engineering, which is why we haven't built it yet, it's just hard, okay, it's
small, it's, you know, and to understand it, it's difficult. Do we have a mathematical theory of
the brain? Well, I would argue sort of, before I go there, so the data center of the future right
now is just full of those very clever chips we saw, the Graphcore, the, you know, TPU, GPU, CPUs,
very, you know, amazing engineering, but soon we'll see them being filled up with neuromorphic
quantum as well, so Google announced quantum supremacy last week, a couple of weeks ago,
which means that quantum computer, it can do something faster than the biggest classical
computer, so the data center of the future will look like this, okay, so we're entering a very
interesting time in human history, I think, in terms of computation, because we haven't just
got classical computing, we have neuromorphic and quantum as well, coming online, it's been 80
years, right, since we first started doing computation, so at a very interesting time,
I think, in the history of computation with these other two major types of computation coming online.
So deep learning, I've argued that won't get us anywhere near intelligence, it will classify
stuff really well and do a little bit of statistical language processing, but it doesn't
do the nine types of intelligence, okay, and so the most popular framework by far is TensorFlow,
PyTorch is kind of also increasing in the last little while, but general intelligence,
how biology does it, it doesn't do matrix multiplication, so deep learning is not AGI,
so we won't talk about that, but we will talk about more neuroscience stuff, okay,
sorry to be so harsh, but it's reality, all that clever stuff isn't actually AGI,
but it's good at certain things. Okay, so what do we do? I mean, where do we even start, right,
with the general theory of intelligence? Well, you know, the brain is a physical system,
right, it's just three pounds of physics, just, okay, so what do we know about physics? Well,
we've pretty much discovered all of the laws of physics, I think, dark matter is kind of a new one,
it's a bit of a bold statement, I'm a physicist, I'm allowed to say that,
okay, so what out, I mean, what out of there do we use, okay, you know, probably thermodynamics
and electromagnetism in a complex system, right, so it's nothing magic, now the underlying theory
of all of that can be described in something called the principle of least action, which is that,
and it's just been a book published last year, surprisingly it wasn't one before, that sort of
says, okay, all of physics, that's, you know, classical, quantum, everything can be, you know,
derived starting with this principle of least action. Now, if anyone's who's got a PhD in physics
here, yeah, a few people, and so we've all, this is what you get at grad school in physics, right,
we do Lagrangians and Hamiltonians and principles of least action, so everything we learn F equals
MA in undergrad, we're told, yeah, that's very nice and quaint, but really, this is the powerful
machinery that's been developed, but we don't, you know, that we sort of, we get there, but
I think we're not really taught that, you know, it's a very unifying principle, okay, so I'm saying,
okay, well, probably that's a nice place to start if we want to try to come up with a general theory
of intelligence, okay, it's a big statement, a bold statement, but, you know, the brain's not
doing anything that physical systems can't do, even though it feels kind of, it is different,
right, because we have consciousness and, you know, that subjective experience and
self-awareness and that kind of stuff, but I'm going to argue it's all just physics,
there are people in the room and elsewhere who will say, no, there's something beyond physics,
metaphysics, I'm not one of those people, okay, so I'm just going to keep it really simple,
so, you know, what can we do? Well, we can explain and understand what we see, we can imagine things,
you know, imagination, imagine that, problem solving, planning actions to make these things
real, we can do all of that, that's what intelligence is really, and we can build new models as we
learn about the world, so probably, okay, we've got five minutes, so these are the sort of major,
some of the major theories of general intelligence, mathematical theory, these are all smart people
who have spent their whole lives dedicating to this, you can look them up later,
there's a guy called Carl Friston at UCL in London, and so his theory of active inference is the one
that I think is particularly compelling, and I won't spend any time going through the details,
because it's pretty hard math actually, but he uses something called a free energy principle,
it's based on physics and information theory, it's nothing kind of new and crazy, it's just
applying it to the brain, and he is a theoretical neuroscientist, and so here he is,
and we don't have time to play it, but so the slides will be made available, I think,
so you can listen to him, and he's on YouTube if you want to Google, and so that's how he sets it up,
there's internal, there's us agents acting in an environment, that's the same if we're bacteria,
monkeys, birds, human beings, it's a system, right, a physical system, we act in our environment,
the environment acts back on us, so there it is, bacteria to brains, and the math gets really ugly
because it is statistical, probabilistic, and physical all at the same time, it's complex
information theory essentially, but the ultimate question is can we build general intelligence,
so I would argue yes, because we have theories, we have very compelling theories, all of those are,
hundreds and hundreds and hundreds, literally thousands of papers written, deep mathematical
theory which keeps hundreds of graduate students in PhDs, so yes we have the theory, we have
candidate theories, we have the algorithms and software, we have the hardware, NeuroMorphic in
particular, and we have datasets nowadays, so yes, and I think we're kind of on our way with these
projects like Spinnaker and IBM True North, so we're starting to build the hardware, it's just a
sort of, it's always just an engineering problem, right, yeah, so you know, what else,
so should we, that's an ethics question, we won't go into that because we could spend
the rest of our lives arguing should we do it or not, we're going to do it anyway, so
there are some projects, DeepMind is trying to, although you know all the go and stuff isn't
general, it's just specific, but there's a whole bunch of AGI projects and all super
interesting, so I definitely encourage you to look and explore if you're interested in this
subject at all on the internet, and in conclusion, so it's obvious that deep learning is just
statistical, it's not based on physics at all, like zero physics in there, so it's definitely
not going to get us anywhere towards general intelligence, but research groups are, many
are looking into bi-plausible models, that's both on the theoretical and the hardware side,
we're sort of getting the glimpse of the very first systems, we have the rat brain there
with Spinnaker, so we're sort of at the very beginning of a steep exponential, so maybe we'll,
you know, that will improve in 10 years, we'll have a human-level brain which will be conscious
and self-aware and subjective experience, which is kind of spooky and creepy, right, but you know,
there's nothing, I'm trying to argue there's nothing that mysterious about the brain, it's
just a complex system, and so what do we do then? Well, you know, we'll figure it out as we go along,
as we have done everything, and so the future of AI, Jeff Hinton, he's the godfather of AI, he's
in Canada and he, I'll let him have the final word, except there's no volume, okay, so he's
just basically saying that the brain is super, everything he's done in his whole life is,
he's just clearly admits he wasn't working on general intelligence and to do, to figure out
how it works, we're going to have to look at neuroscience, that's pretty much his message,
and it's pretty much my message, and so I hope you've enjoyed my talk, it's been a little bit
different from everyone else's, but thanks. Yeah, and we have questions, of course.
Okay, one interesting question is, could AGI be achieved without emulating human brain,
but building a completely different model? No. That was a short one, you kind of answered this
one, but maybe you can elaborate a little bit more, when do you think AGI will arrive,
and I can follow with another one, as you said you're at 50% of achieving AGI, what are the
main challenges you are facing to get to 100% what technology breakthroughs are needed? Yeah,
so it's basically a hardware engineering problem, so I did show the Spinnaker, and you know,
there are other hardware projects around the world doing this, like IBM and Intel, and so
that's the mouse brain right there, so basically it's a scaling problem now, I mean we started at
two transistors, one transistor at one point with classical computing, and then companies like Intel
were formed, and AMD, and NVIDIA, and the rest is history, right, it'll go on its own Moore's Law,
so right now we're at the kind of like 10 transistor stage that we were with classical, so we'll
just see that scale, I'm going to say something really bold, it's just a scaling problem at this
point in time, so watch this space, yeah. So what will you say? Well it'll go mouse, and then it will
go you know bumblebee, and then well no bumblebee, then mouse, and then monkey, and then human,
so we're on a curve, so human in 10 years, that's my prediction. They're too optimistic, I mean
in 1969 when people flew to moon, they thought that they will be living on the moon by now.
Okay, I'm an optimist, I'm saying 10, yeah, that's okay, but I appreciate that. The last one,
a comment about the Soul Machines Baby X project and the potential to get closer to general AI.
What's that, say that again? Yeah. I haven't heard about the Soul Machines Baby X project.
Oh yeah, I have, yeah. Okay well certainly. What was the question, the Baby X? I mean
your comment about it and the potential to get closer to general AI. Yeah, I didn't actually
mention Baby X, but that's a nice project in New Zealand, and it's another AGI project,
but basically it's going to come back to neuroscience, you know, we saw the math,
we saw some of the mathematics involved, it's going to be people working at that level from
a theoretical point of view, and other people like Steve Furber and the Human Brain Project,
you know, brilliant engineers basically working on the hardware level, and these people talking
to each other, and I know Carl Friston and Steve Furber do talk to each other in building this
very complex system. Okay Peter, thank you. Thank you. I will present you with a certificate.
We got to fill you with a certificate.
