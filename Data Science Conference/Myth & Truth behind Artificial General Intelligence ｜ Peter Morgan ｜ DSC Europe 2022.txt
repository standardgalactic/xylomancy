Okay, good morning from Serbia.
Our first speaker of the day is Peter Morgan, a longtime friend of the conference, and he'll
be talking about artificial general intelligence.
Artificial general intelligence is a primary research goal and focus of many AI researchers
and is a common topic in science fiction and future studies.
Peter Morgan is the publisher of O'Reilly Otter and will lead us through the vast meet
that he will talk about what AGI is and what might be the myth and what does it really
mean and how far are we from achieving something like artificial general intelligence.
Hey, I'm Peter Morgan.
I'm going to talk to you today about the myth and truth behind artificial general
intelligence.
I am the CEO and founder of Deep Learning Partnership.
We are an AI consulting company based in London.
So here is an outline of the talk.
So what is intelligence, general and versus narrow, biological versus non-biological systems?
And then we'll look at artificial general intelligence or AGI and we'll look at what
it would take to build such a system and then we will conclude the talk.
So basically it's a talk about AGI.
So why do we want to build AGI at all?
Well, we want to solve general intelligence and then we want to use that to solve everything
else, right?
So that's medicine, cancer, brain disease like Alzheimer's, Parkinson's.
We want to live forever, longevity.
We want to solve physics, math, biology, chemistry problems, material science and social problems
we want to solve.
Basically we want to build a system that will help us to solve all these problems that we're
busy solving anyway and sometimes creating.
But basically if we could build a system that's as generally intelligent as us and
even more so, even more intelligence, ultimately superintelligent systems, then we could accelerate
basically the progress that we're making in all of these areas.
Okay, so what is not general intelligence?
We've seen a lot of very impressive displays of what we call narrow AI.
We think about AlphaGo, AlphaStar, the company DeepMind here in London and DeepBlue IBM being
chess and again IBM Watson winning at Jeopardy.
So these are all super impressive examples, aren't they, of intelligence because they're
sort of super human levels at these very narrow tasks like playing a board game like
chess or Go, winning at a video game which is a hundred billion dollar plus industry
these days and solving linguistic problems.
And so these are all, these all are examples of narrow AI but they're not general AI systems.
So these again are examples of narrow AI.
So what is general intelligence?
You know, how is it different from those systems?
What are we missing?
Well, Howard Gardner at Harvard in the 80s came up with this really good way of classifying
the different types of intelligence and he came up with about nine, possibly ten different
categories.
We've got mathematical IQ which is the ones we looked at there, language but then we've
also got these other things that are really unique to humans like interpersonal intelligence,
how we communicate with each other, how we know what each other's thinking, theories
of mind, that type of thing.
And then we've got intrapersonal where we sort of introspect, you know, we can sort of examine
our own thought processes, computers cannot do that today as far as we know.
So these are uniquely human kind of intelligence levels.
So we're certainly knowing they're getting towards that, those types of intelligence.
Yeah, so there's other ones there, maybe spiritual intelligence, we've got, you know, athletic.
So building robots, you know, intelligence systems that can navigate around in space,
that's another type of intelligence.
A little clunky right now but we are making progress with that type of intelligence.
So how far have we come?
Can we put numbers on these things?
Well, I've sort of come up, you know, put my finger in the air a little bit, come up
some numbers, I think, you know, the logical mathematical intelligence, maybe we've come
50% of the way.
Like we saw, we can beat these narrow AI tasks quite comprehensively now, but they cannot
do other things.
We haven't completely solved language, for example, I put 50% on that musical.
They can actually create music, you know, these generative AI systems.
So we have made a lot of progress actually in the last, especially in the last decade,
I think, with these artificial neural networks, but we still have a long, long way to go.
For the rest of the types of intelligence, robotics, interpersonal, interpersonal understanding
of nature, our surroundings, what's good, what's bad, sort of moral intelligence, ethics.
Yeah, so subjective intelligence, conceptual intelligence, we have a way to go there and
existential, our place in the universe, I don't think computers can think like that just yet.
Basically, their statistical system.
So how will we build AGI?
Well, it takes a village to create a child, and I think it will take a village to, or
at least a team of scientists from different backgrounds to create an AGI.
So that will include computer scientists, physicists, neuroscientists, psychologists.
The usual suspect, I think, if you think about the human brain and what we do humans do, we're going
to need all of that expertise from all of those areas.
OK, so let's have a quick look at the difference between biological and non-biological intelligence.
We'll drill down a little bit there.
And so with biological, we've got plants, bacteria, insects, and mammals, including us.
So we've got a range of intelligence systems.
Plants have their own intelligence.
They're able to survive in their environment.
They can't do some of the things that we can do, but they still manage to survive.
That's a type of intelligence.
Moving on up to bacteria, which can move around and do a little more than plants.
Insects, of course, like, say, the bumblebee.
Quite intelligence, you know, they can communicate with each other when they find
something, some pollen somewhere, and they know how to navigate all of that.
And then we've got mammalian brains, say, for example, monkeys, very clever.
They have their communities.
They live in community.
But they can't sort of conceptualize to understand the universe.
They can't do math.
They do have language.
Most animals have language, in fact, birds, birdsong, etc.
Even insects communicate with language, a very primitive type of language.
But we are the only mammal that can actually conceptualize our environment.
We have a sophisticated language.
We can do mathematics and physics and all that good stuff.
And, you know, I guess our consciousness is at a slightly higher level, perhaps,
and all the other mammals as well.
And consciousness, of course, is a part of general intelligence.
And then we have the non-biological.
This is how we're going to try to make AGI.
It's artificial general intelligence.
So that includes digital processors, CPU, GPU, FPGAs and ASICs, neuromorphic,
which is a more analog based, bio-inspired based on how the brain works.
And then type of hardware.
And then finally, sort of question mark.
Do you think, do we think quantum computing is needed?
Or will it give a different type of intelligence?
Well, very briefly, look at all of these things.
OK, so, yeah, there's some of the examples in biology that we've talked about.
Biological systems are hierarchical.
They go from sort of atomic molecular level right up to the body, the system.
So, you know, we have atoms, cells, neurons, systems of neurons,
and then our whole central nervous system.
And then if we look at these neurons, they are very complicated systems, in fact.
So, you know, intelligence is very unique.
And I think we do appreciate, you know, we don't sort of understand consciousness
or how it would even arise, for example.
So we do understand, you know, there's something a little bit unique
about especially human intelligence and consciousness.
So maybe it's no surprise that these individual elements
is about 100 billion in the human brain called neurons,
slightly complex systems in themselves.
And then you can see when we put, you know, tens or hundreds of thousands of them
together and then millions and then billions, then we're going to get a very
complex system out of which could emerge and does, in fact, emerge intelligence
and consciousness, subjective experience and all of those good things.
So how on earth are we going to try to build something that complex?
And then this is the brain.
This is the sort of level where general intelligence does occur.
It doesn't occur at the neuronal level.
I don't think individual neurons are intelligent, but they're part of the system
where you put 100 billion together of different varieties of neurons,
of course, and connect them all up in the connectome, you know,
whether that's humans or primates or even insects.
The sort of intelligence occurs at the the full system level.
And then, you know, the last bit of the hierarchy is the central nervous system
in all animals and insects.
So, you know, the brain is attached to the body, right down to our toes,
you know, six, some of the neurons are six feet long, et cetera, very long
systems here are very complex.
Biology has had, you know, 12 billion years to evolve in its
this is where we are today, very complex systems,
quite, quite amazing and unique systems, in fact.
And then if you wanted to go one level higher, then you could say start
thinking about communities.
We do act in communities, cities, countries and internationally.
OK, so let's have that sort of biological that that's biological intelligence.
Let's look at non-biological hardware and how we might build intelligence from that.
OK, so, yeah, so, you know, we've got different types of processes.
The CPU, GPUs, ASICs, I put an IPU on the end there.
It's an intelligent processing unit from Graphcore.
It's basically an ASIC designed specifically to optimize artificial neural networks.
The GPUs are very good at it, but they have their limitations.
CPUs can do it, but they're the least efficient system of all to run an A&N on
or deep learning artificial neural network, whereas GPUs are slightly more
efficient and then the ASICs, of which the IPU is just one type.
There are many, many companies these days, dozens of them, set up
primarily in the last 10 years to build systems optimized for artificial neural networks.
So interesting time, in fact, in this whole process of a humanity trying
to build an artificially general intelligence system.
OK, so those are all silicon based systems and digital.
And so these are the neural network, artificial neural network I spoke about
that will be running on these things, different architectures for different purposes.
So your computer vision language, the slightly different architectures.
And so just kind of looking back at our history and seeing, you know, where we came
from in the 50s, you know, in the 30s, we had valves and then we went on to
transistors in the 50s and so integrated circuits.
And I mean, this is 1970s.
We had to create one at 160 megaflops, pretty impressive at the time.
But then, you know, today, right up to date, 2020, 2022.
Yeah, we've got the CPU there.
We've got a GPU and video Intel CPU and video GPU in the upper right hand
corner there. And then we've got a couple of ASICs.
We've got the Google TPU and we've got the Graphcore IPU.
So this is kind of state of the art today, as opposed to the crate that we saw
in the previous slide.
OK, so there's a whole rack of Google TPUs, basically.
And that's over 10 exaflops.
And so that means that it's about 100 billion crates that we saw earlier,
100 billion fold increase in hardware since 1976, roughly 50 years or so.
Very, very impressive.
We are reaching the limit of physics in terms of Moore's Law's ending,
the exponential doubling or the doubling in a number of processes
where you can fit on a chip, sorry, transistors on a chip every two years doubling.
So we're kind of running out where we're down the laws of physics
after you get down to about two nanometers, you get quantum tunneling
and the transistors break, basically.
So we're kind of the Moore's Law is kind of flattening out a little bit,
but we've made so much progress.
Question is, though, will will I be able to create
or will we be able to create intelligence, general intelligence from a rack with 10 exaflops?
It's a very good question.
So keep that in mind as we go through.
Here's another system.
That's the IBM Summit.
They've built even more powerful systems since then and other countries as well,
for example, China.
And so these things, again, are, you know, multiples of exaflops, huge memories.
So again, the question we need to ask, do you think general intelligence
will sort of come out of this digital hardware?
It's a very, very good question to ask.
OK, so I guess now's the time to answer it.
The answer is no.
So what are we missing?
The brain, right?
It weighs about 1.5 kilograms, about 30 watt of energy.
Those systems we saw use like a million or 10 million watts.
Huge difference, right?
We're talking, you know, orders of magnitude, 10 to the 6, 6 orders of magnitude.
OK, so the biology is clearly optimized for intelligence over the billions of years
that we have not been able to do without digital technology,
no matter how impressive it is, you know, pushing, pushing the laws of physics here.
But yeah, it's a different type of structure and architecture.
I think that's needed to build AGI.
OK, so clearly, you know, share digital horsepower
is not going to get us to generally intelligent systems or we'd have them by now.
So we've got 10 exaflux, right?
And so we know that the brain biology uses a different architecture.
Memory and compute are actually combined.
So a neuron is not only a processor, but a memory as well.
We call that memristors, memory plus transistors, both taking place
at the same location in space.
So perhaps we should be looking at the brain for inspiration
if you want to really build an AGI system.
It seems obvious now, right?
But so why why why haven't we sort of been doing this?
We'll hopefully answer that question by the end of the talk.
So here we'll introduce neuromorphic computing.
It's biologically inspired, first proposed, proposed,
or most famously proposed, maybe by Carver Mead at Caltech in the 80s,
but other people were working around similar ideas around the same time
as normally happens and they use analog signals.
So spiking neural networks, not digital, just so definitely bio inspired.
We we understood how the brain worked by then.
We had been dissecting and in looking through
microstopes and had a pretty good idea what a neuron was
and how the electrical current moved through as analog waveforms
integrate and then fire when when a threshold is crossed of information.
Then one neuron would basically fire across to the next neuron
via the synapse connection.
And so we kind of had a general idea how biology, biological brains
worked with a mouse or mammalian primate or even human,
because we'd kept them open.
So how on earth are we going to build that in artificial materials?
OK, so that's all we have to do, right?
We know kind of how intelligence works because we work.
So but how are we going to build us basically in using processes?
That's the question. OK.
So right now we we have built systems,
the spinnaker and the human brain project and brain scales
in the human brain project.
IBM have True North and Intel have a processor called Lowihe.
And so and there are also many, many startups actually these days.
There's a couple there, but there's many.
If you just Google Neuromorphic Processor Startup Companies,
you'll find some more.
And so we have up to a million cores,
maybe a billion neurons, which is about the size of a mouse brain.
OK, it's a hundred times smaller than the human brain.
They can do mouse like tasks.
They can navigate through space, for example.
But mice can't do much in terms of conceptualising.
Certainly don't do math or anything.
They have a very basic language, but so we've kind of built mouse
intelligence in a way.
So not quite the same, though.
Not not conscious like a mouse would be conscious
and have subjective experience, feel pain, for example.
Processes don't, as far as we know, feel pain.
And so you basically need to scale that up a hundred times,
plus add a little bit more.
So this is sort of where we are.
We're at very, we're probably at one percent of the journey.
But often these things can be exponential, like the human genome project,
for example, is in the normal sort of conditional processor.
These are all on exponential curves.
So, you know, doubling every couple of years may not take us, you know,
200 years to get there.
It may take us 20 with the exponential on our side.
OK, so and they do use a lot less power than digital.
So instead of a million watts, you know, we can we can do about
around a thousand watts, for example.
And so Spinnaker has been available on the cloud for five years.
You can log in today, set up an account if you wanted to.
OK, so there is an example of Spinnaker, the Neuromorphic computer.
They're slightly bigger now.
I think they're on the Mark II version, probably twice as the size.
And it's housed up in Manchester, where the Professor Ferber,
who is leading the project, is based.
He was one of the co-founders of ARM, by the way.
OK, so very, very exciting stuff.
There is an example of an analog Neuromorphic computer on the left,
the brain scales, and the Spinnaker was actually a digital Neuromorphic.
So there's slightly different architectures there.
The brain, again, I said the spiking neural network.
So it's kind of a combination of digital and analog.
The signals are analog, but the fact that they sort of have to reach
a threshold before they cross the synapse to the next neuron
is a kind of a digital thing.
So there's no like it's purely analog or purely digital.
It's sort of a combination of both, the brain, the biology.
So these things are sort of a slight mix of analog and digital.
So we've got brain scales on the left analog,
and we've got the definitely digital Google TPU-A6 on the right,
just for comparison's sake, roughly the same size.
But one will give us a sort of general intelligence task.
But in the other, we'll be able to do super good at math,
but they're not going to do other stuff that the biological brain can do
or the Neuromorphic hardware can do, even though they're roughly the same size.
By the way, the one on the left uses about a thousand times less energy
than the one on the right as well.
OK, what about quantum?
Very quickly with quantum,
so basically the brain is warm, it's wet.
So we don't, most people think probably there won't be quantum effects
involved in a AGI, but, you know, obviously, as scientists,
people are open to get the very small scales,
perhaps just something quantum going on.
So we probably won't be looking for
the quantum computer, we're probably focusing mostly on Neuromorphic hardware,
but I sort of threw this in for fun, really, a little bit of fun.
OK, just to say that, you know, we're building quantum computers,
but personally, I don't think we're going to need them for intelligence,
general intelligence. OK, so, yeah, just to summarise everything we've spoken about,
we have the four different types of processor,
digital, Neuromorphic, quantum and biology.
And there they are, and looking at the processes that we've,
the quantum, Neuromorphic and digital processes we've built,
very, you know, very, very clever progress has been made to the point
where we can build these things, and then we've got the biological system there in the middle.
OK, so we've got, you know, three stacks, three non-biological stacks,
digital, Neuromorphic and quantum.
And the data centre of the future will no doubt have all three.
Types of compute, hardware, digital, analogue and quantum.
But we're focusing on AGI, so let's just see in the last few slides
what that's going to look like in terms of building it.
All right, so what do we need?
What are the difference approaches and how are we going to build
artificially general intelligence systems?
OK, so the thing is, the brain is a physical system,
so we're basically going to need all of the physics that we've,
as a species, developed so far and then apply it to the brain.
So neuroscience basically, plus computer science, plus physics,
you know, plus psychology, as we saw at the beginning.
So there are the basically all of that we've understood about the universe
and that's all the physical laws there.
So we've done pretty well with understanding the physical laws.
Possibly, I don't think there's anything missing really for the brain.
It's another physical system.
So if we apply those laws to intelligence,
then we may, with a lot of hard work,
build a artificially general intelligence system.
So intelligence is conceptual, objective and subjective.
This is why we'll need the neuromorphic.
I mean, right now, the digital processes are purely objective.
But what we as humans can do, what biology can do,
is conceptual intelligence and subjective intelligence and experience,
as well as objective.
We can do the math and everything like that and science.
That's all objective, very nice.
But we can come up with concepts of the universe, of each other.
We can come up with theories of mind and we feel stuff, you know,
we feel pain, physical pain, we feel mental pain.
We have all of these types of emotions.
So digital hardwares certainly won't won't do that.
But analog and neuromorphic probably can.
OK.
So can we build general intelligence?
Well, we have candidate theories.
We have good theoretical models of the brain.
We can buy huge textbooks and read thousands of papers
with millions of equations, all describing how the brain works.
So yes, we have theories.
We have candidate theories of how the brain works.
We have hardware.
We have the neuromorphic in particular.
We have algorithms and software.
We've written frameworks for these neuromorphic processes.
And we have a lot of good data sets these days as well to feed it data,
whether that's written papers or data from the environment.
We've got a lot of good data.
So we need to build a complete software framework with libraries,
software that will run on neuromorphic processes.
We have to build a hardware, scale it up.
We know, you know, to 100 billion neurons.
We're not quite there yet, maybe in 10, 20 years, we will be.
It's like an Apollo project.
If we really, you know, put the manpower in, we have the human brain project.
But if we put the manpower in to developing these processes,
then then it will happen quicker.
And, you know, we are actually putting billions of dollars.
Here's some huge projects here, the human brain project,
billion dollars at least funding, the brain project in US,
human brain projects in the EU, Google research, DeepMind, China.
All of these are billion plus projects.
So, you know, there's a lot of effort, time, effort, resource being put in,
money being put into building an AGI system.
Although it's not really doesn't make the news so much,
but there is a lot of work in universities as well as big companies.
Government projects, OK, should we build it?
Well, there's safety and ethics to worry about.
And we have the singularity where these things get as intelligent as us or more.
Maybe a runaway intelligence, we have to think quite carefully about all of that.
That's probably another discussion. OK, so here's some AGI projects.
I'll let you look at that in your own time, running out of time a little bit.
Just to know there's many projects in many countries.
Startups and big organizations.
OK, so how are we going to coexist with AGI?
Well, there's lots of books and movies, Terminator being one of the more famous
tons of sci-fi books.
People love writing about it, making movies, especially scary ones.
So, you know, we've thought about this a lot, fiction and nonfiction.
There's several takes on this.
They will never be super intelligent, but that's unlikely.
I don't think there's anything in the laws of physics that will stop that.
We're intelligent.
So why not if you can build it bigger and faster?
I don't see why we shouldn't be able to build super intelligent systems.
There will be benevolent.
Well, I hope so. Fingers crossed.
We will merge with them.
That's what Ray Kurzweil thinks.
That will avoid this sort of problem of running away from us.
We will be a part of us.
We will go to the next phase of evolution.
It's all kind of sci-fi, but these are good things to think about.
In advance, they will destroy us.
We don't really know, to be honest.
I can't reassure you.
I'm not. It's my job.
It's not. I'm not here to reassure or scare or do anything to anyone
that's up to each of us as individuals to make our own minds up.
And take action that we want to either get involved, building them
or help join an ethics society or committee or, you know, just get involved.
But I think everybody at the conference, we're mostly from a computing background,
so we're sort of involved anyway as it becomes more mainstream.
I'm sure we'll start programming these things or working on them in some some some way.
There's some nice reading that wrote to General Intelligence.
I think that's out just this year.
Singularity is near Ray Kurzweil and our final invention, James Barrett.
All good reading.
OK, so conclusions.
So it's obviously that obvious to most that deep learning or artificial neural networks
running on digital hardware won't get us to AGI.
It's based on statistics, not physics or biology, but how the brain really works.
So it's an approximation.
So we need we do need a complete theory of general intelligence.
We need credible research turning to biology.
Biopausable models are appearing.
The hardware is appearing, the software to run on it.
And so will we have real AGI systems in 20 years?
I wouldn't doubt it.
You know, sort of human level, maybe not super intelligence,
but you know, getting to that point, 2040s, something like that.
And we still have to wait for the hardware to mature and scale exponentially.
But they're on the Moore's Law.
These neuromorphic processes will be the ones that get us there.
Final takeaway.
Using basic physical principles, AGI systems will be built over the coming 20 years.
Thank you for your attention.
