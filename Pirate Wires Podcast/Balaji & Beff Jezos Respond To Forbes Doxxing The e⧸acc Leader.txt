They not only doxxed the correlation between my principal identity and Beth Jesus, but the voice doxxed me.
I didn't want to talk to them, but then I'm like, look, this is gonna really come out.
I'm like, all right, well, I better try to control the narrative.
I thought there was a sort of, like, ethical protection, like, no.
I've been trying to figure out, like, why did this happen to me?
Like, where did I cross the threshold of becoming enough of a problem that they needed to have leverage over me and expose me?
Our movement is about free speech, freedom of compute, freedom of AI, and not, like, top-down oppression.
I have failed, honestly, and apologize to you two.
We both, you failed.
I don't know why you're talking to them.
Do not talk to journalists.
I said, don't talk to journalists.
You do not try to violate this rule.
You will regret it.
Welcome back to the pod.
We have the, we've got, are we saying Beth Jesus or where are we doing?
Where are we going with this?
You could call me both names.
I go by both names now.
Beth Jesus or Gil Verdon in America, Guillaume Verdeau in Canada and France, if you will.
So finally, after it's been honestly too long, the legendary biology doesn't even get a,
does not even need a second name.
It's like, you know, Madonna or who are the other ones?
I don't even know.
And you might be like one.
I guess.
Well, I, you know, it's not quite, it's not, it's biology.
We are here today.
This is, I'm stoked about this episode.
This is going to be a great one.
And both of you guys, thank you.
You're on a different time zone and it's been a while setting this up.
But biology and I have been talking about, and biology, I mean, separately from each other,
but also together, media and the shape of media for years through like tech dark ages
back when we had no counter voice whatsoever up until today, where I think things are still
not balanced, but very different than they were three years ago, certainly during COVID
and before that.
Gil, you were, I'll just break it down.
I mean, so Beth Jesus, kind of popular anonymous account on Twitter.
You run something called the EACC, which we'll get into in a bit or yak doxxed by Forbes.
Emily Baker White of Forbes in concert with Alex Conrad, which is an important part of
this story because Alex, it's important to me at least.
And I want to talk about it with both of you guys in a minute because Alex is so influential
in tech.
I mean, he runs the Midas list.
Everybody knows him.
Everybody talks to him.
And that is a problem.
And, and I do want to get into it, but long story short, these guys hit you up or Emily
hits you up and she's got your, she's got your real identity.
So you've been writing anonymously about EACC for what about a couple of years at this
point when this happens, have a little bit of a community.
I would say I'm going to kind of characterize what I think you guys do.
And then you can come in here and give me the real version according to you.
I think you guys were memeing about the future.
And you're definitely counterpointing the EA stuff.
You're sort of like cleverly cutting against the doomer narrative in a fun way.
I've always seen it as very like lighthearted.
I've noticed this week, the EA crowd has been very personally agreed by you.
And it gave me a giant question mark.
Then I was like, why is, why is the media gone to, to war against you?
I have a few theories.
I'd love to hear apology.
Your theory especially, because I'm sure you have one at this point.
Sure.
Your link, Gil, to Mark Andreessen and Gary Tan specifically seems to me like the reason
that you became something that needed to be destroyed and shamed.
So that's my version of events.
You know, EACC, born, you represented.
It's a positive, futurist, anti-doomer, pro-progress, pro-AI specifically kind of movement.
You are, they think, assassinated, obviously doesn't work out that way for them.
You're much more popular now.
Tons to talk about, but first things first, like what is your version of those events?
Yeah.
I mean, for me, it was, it was a crazy Friday and it's been a crazy couple of days since then.
I'm like halfway across the world right now in an undisclosed location that is not China.
And, you know, on a business trip.
So I'm still, you know, doing, doing what I do.
I'm an entrepreneur.
Yeah.
Originally, basically I get a text from like investors.
So first of all, you know, I came, you know, as I was doxxed, you know, I came from GoogleX.
You know, I worked on projects with the leadership there very closely, you know, very secretive projects.
I was used to sort of secrecy as my baseline.
And to some extent, like spending years, super secretive.
You can't talk about what you do and so on.
It's kind of a burden.
And that's originally how I started.
Beth Jesus was just like as an outlet for me to communicate with people about stuff and just talk.
And, you know, I've kept that, that account since then.
But, you know, I had a startup as well that was not doxxed.
Like the, not only doxxed the correlation between my principal identity and Beth Jesus,
but they correlated my principal identity, my current company, and even they traced through, you know,
name changes of the company.
They even like went through my Facebook.
They went, they voice doxxed me.
They just correlated everything.
It was like a full, like, you know, full depth of investigation.
When they punched your identity, it was like something out of a spy movie.
They went in on you.
Yeah.
They really threw resources at this.
Yeah.
Like, I mean, for me, you know, like, I think like, you know, I believe what I, I believe large majority of what I say is
Beth, sometimes it's kind of like, you know, meta-ironic, you know, extreme posts as one does on Twitter.
But like most of it, you know, like I'm all in, like, I don't mind like, you know, backing, you know, using my main identity back,
what I say with, what I have said with Beth.
But to me, it was like, hey, I didn't give you the right to disclose like that.
I'm doing this like deep deck startup as well.
You know, I mean, some technologies have the right there.
This is a thing.
It's like, this is the whole thing for me watching this is this is this is not the first time that the press has done this.
This happens often and it's, it's this question of rights comes up.
It's like, we can do this.
They say is like, yes, you can.
But the question is like, is it ethical?
What kind of world do you want to live in?
And obviously, from where I'm sitting, it just seems the purpose of revealing your identity is to scare other people who are
sharing their opinions in this space anonymously from doing so.
It's a, it's a, it's a, it is a strategy to chill speech.
I don't have to worry about speaking for the most part within reason.
It's way easier for me.
I don't run a tech company in stealth.
I work for Peter Teal at Founders Fund and on the Pyrowire side, I run my own business.
It's like, there, I am, and the business is speaking.
It's like, it's, it's easier for me to do it.
For someone like you, it's harder.
They know that.
And the point is they want to kind of take you off the map.
Apology.
Why do you think, I mean, do you have any, you can take this anywhere you want.
Obviously, you might have something you want to share in particular, but I would really love to know kind of like what you think, what you
think the motivation behind this specific targeting was.
So, my views on this is somewhat evolved.
Fundamentally, the journalists are, are tribe and they're a sub tribe nowadays of the overall, you know, what do you call it?
The regime, the paper belt, the cathedral, the establishment, the deep state, what have you.
That is a set of people and it is a group of people that is, you know, FUBU.
You guys remember FUBU from the nineties for us bias.
Okay.
So like the regime is nationalist for the regime.
You know, it's like to first order, you could say it's Democrats.
You could say it's deep state.
You could say cathedral.
There's like a lot of different names for this, which are all overlapping.
But basically, if you take the whole social network of, you know, 8 billion people in the world and 300 million Americans and so on and so forth.
This is a sub graph in the social network that's densely connected.
And it's journalists, it's professors, it's regulators, it's bureaucrats and so on and so forth.
And everybody who is not them is an enemy.
And that means that they're at simultaneous war with tech, with Trump, with China, with Russia, with India, with Israel.
Like, and you can, some of these, they're more at war with than others, right?
They don't like India very much, but they're like somewhat fighting it.
They don't like Israel very much and they've got some outlet, right?
But basically, once you look at it as a giant social network in different colors of subgraphs, the journalist, you know, like blue subgraph is at war with within America, the red subgraph and the gray or tech subgraph, right?
And so that's like the first order, like visual of the whole battle space.
It's not, this is not like a discussion.
This is not like a normal story.
This is information warfare of one tribe versus another.
This is meant to harm you.
And even if this first one is just like a tracer bullet or like a flare to sort of light up the position, right?
Then subsequent kinds of things may or may not be so positive or would have, right?
And so that's like first is basically, it's not a, it's not a positive thing to go and dock somebody against their will.
You do not do that to a friend, right?
You do not do that to somebody who you mean well to.
You don't stalk them for months and you know, basically in your, and you know, correct me if I'm wrong, Guillaume, but they basically gave you, you know, they told you they had all this dirt on you and they're like, well, you better speak with us or else, right?
Yeah. Yeah. Yeah.
Like, I got a text from investors the night before from, I think it was Alex Conrad that told investors like, oh, hey, I correlated Beth J.
So San Guillaume, I think he's a portfolio company.
They had the old name of my startup.
So I changed the name of my startup for further upsec and for branding eventually, but they hadn't put it all together.
And then they censor fused across reporters, like, and then they had much more.
They had too much put together and they wanted to, they were going to put it out, right?
And then so the morning I was like, look, this is going to come out.
You have a chance to give a comment like it's happening, whether you like it or not.
And for me, I had like two things.
One of them was like, okay, well, how do I, I just went in damage control, right?
Like, I mean, I've, I'm building stuff that I really believe in.
I've been wanting to build this for like eight years.
I've been like super stealthy about it for all sorts of reasons, for security reasons, for, you know, IP reasons and so on.
And, you know, everything was at risk, right?
Not only the movement, the Yak movement and hope, well, hopefully the movement is not at risk, but it's supposed to be antifragile.
We're trying to make it so.
But and, and my company.
So I went in damage control mode and I didn't want to talk to them, but then they were like, look, this is going to really come out.
I'm like, all right.
Well, I better try to control the narrative, at least for the first, for this first thing, because I'm sure they're going to pile on now.
The media is definitely going to pile up from here on.
I mean, I can, I've entered an exhibit.
Let it, let it be entered into the record.
Exhibit A. Okay.
This is from datajournalism.com.
Okay.
By one of the wokest wokes to ever woke.
Oh, yeah.
She's one of the three heads, one of the heads on the three headed dragon, I would say.
Yeah, exactly.
I mean, it's a multi head.
The thing is, every one of these critters, like basically is essentially a Stasi officer that that's what these, these folks are.
So they actually have a whole article at datajournalism.com.
And what this is actually titled, if you, I'm sure if you paste this into chat, GPT or whatever and ask it to paraphrase it is how to docs.
Jesus investigating social.
Go ahead.
No, I'm just shocked.
I'm, I shouldn't be shocked, but I, I've never seen it this explicit.
It's this explicit, right?
All of their stuff.
That's why I read all of their, you know, or go ahead.
Brandy works for, I think NBC, right?
This works.
That's right.
Here we go.
This is, these are, these are major significant journalists.
Yes.
That's right.
And they teach how to docs, how to, there's other articles on how to essentially assassinate, except they don't assassinate the character assassinate.
Right.
And it's all, so, you know, once in a while, they'll actually admit it when they were talking to each other and they put on a different face.
Right.
So here it's like, you know, be prepared to read thousands of tweets, click until the end of the Google results and dive down to social media rabbit hole.
If you want to collect the tiny biographical clues, they'll help you answer the question, who is this?
Okay.
So, you know, I mean, whatever, you can read this if you want.
The useful thing about reading articles like that is it tells us as technologists how to build a privacy countermeasures against these people who, who are literally like a, like a for-profit intelligence agency.
And I don't even say that lightly.
How did they get your identity, GV, right?
They, they went and used like some CIA voice recognition thing.
Straight up.
I mean, that, I guess that's, that makes it, that makes me a bit more badass that they had to do that.
I don't think it was necessarily that hard, but I thought there was a sort of like ethical protection.
Like, they wouldn't like, I'm not doing anything illegal.
I'm literally just arguing for free speech.
Like, hey guys, thanks for listening to the pirate wires pod.
Make sure you like, subscribe, comment below and share this with your friends.
I have failed.
Honestly, that was one of the big things I thought while I was watching this go down, I thought, like, have we not?
And apology you too.
We both, you failed, you know, like, how do you, I don't know why you're talking to them.
Like, that's what I'm thinking.
I'm like, how do you, we've been talking about this for years.
Like, they are not all of them.
And maybe, I'll just disagree a little bit something.
I think there are some good things out there.
It's very clear in my opinion who are not, and it's very clear usually by their approach, like that was on a friendly approach.
That's a hostile, at that point, you're a war.
And what you, what you do, and this is for people listening now who are maybe anonymous online and they don't know what to do if this comes and happens to them.
You ask for help from people like us who are, who are able to beat back with media, who can defend you.
Like that, that is the very, who really separate from defense publicly is like, like advice.
Because by participating, you, first of all, they're using that against you.
They're saying, oh, he participated.
It wasn't against his will or whatever.
And it's very clear from the emails that you've shared with me and the private messages that they sent, you know, to other people and things like that's not obviously not the case.
It was clear just reading the piece.
That wasn't the case, but I can confirm here officially that that is not the case.
You were definitely not forced to participate, but you were going to be doxxed whether or not you liked it.
But had you not participated, they wouldn't have had that weapon to use against you and they wouldn't have had much to talk about because you, they also had not.
Yes, they were, they had, they used their CI voice recognition.
They really, really thought it was you, you know, mathematically, whatever seemed like almost certain, but you had not actually confirmed it.
So they would have had a story where it was like, we are very, very certain, but we don't know for sure.
And also, he is sort of associated with this guy who we're telling the world is a Nazi.
And that would have been so ludicrous that, I mean, we would have just gone, the whole internet would have exploded him and furious and they would have been beaten back.
Like, you kind of gave them a little bit, a little bit too much in the future.
I mean, I wonder what Bolliger's advice is, but I'm like, you give them nothing and you then concoct, you doxx yourself at that point, possibly.
To take away the story, like, I don't know, Bolliger, what would the advice have been you think in that situation?
Well, so one thing is, I usually don't even repeat their charges because they throw around everybody's, you know, everybody's a Nazi.
Like they'll call anybody an everybody a Nazi, right?
So I don't even give any credence to their charges, right?
But setting that aside, yeah, I mean, so, I mean, here's the thing, like, how do I think about it?
You guys are really video games?
Not enough to this reference, but let's just throw it out.
So there's like, you know, there's various video games where they're like, you know, first person shooters or something like that.
And new guys just keep beaming into the arena, right?
They have no context on what just happened and where the, you know, shells are flying overhead and so on.
And that's how I think about the new guys who, you know, maybe they're heads down.
Maybe maybe they were just like in a different part of the battlefield.
They don't have context and they're, you know, beaming into the arena.
And it's a good analogy, I think, right?
Where it's like, you know, they're on our team.
They just beamed in, but they, you know, they may not know all the battle tactics or whatever, right?
So it's actually incumbent upon us as, I hate, at least, you know, Ceylon, I'm not sure what the convention is.
But I guess I've become a little bit of an elder.
God help me.
God help us all.
You're senior in school.
Yeah, it's, it happens really fast.
The gray comes really, really, really fast.
I'll tell you that.
Okay.
But it is incumbent upon us to literally compact this stuff down into month draws that people repeat.
And you assume it's almost like college where there's like a new class and it's obsolete in two years or three years.
And you have to like say it again and update it, right?
So that's, that's one part of it.
Let me pause there and get your thoughts.
Well, I mean, I agree.
I really, like I said, at the top of this little piece here, I, I felt bad.
Gil, I felt like I had not done it good enough.
It's loud as I have been on this issue.
It's awesome.
So I've written about it as much as I've tweeted about it.
I feel like somehow that message, it's like, do people think I'm kidding around?
Do they think that I, I mean, this is an information war.
And I, again, I do believe there are good actors out there.
There are so many nefarious actors.
This, for me, the Alex Conrad piece is really crazy because so many people treat him like a reasonable reporter in tech.
And this action for me is beyond the pale.
Not only the way he went after you, but the way he tried to go after Gary and Mark through you is, I think, really nefarious.
And I'm like frustrated that people aren't as upset about that piece as I am.
But yeah, I know, I agree.
I think we did a little bit of a better job reaching out in these moments.
And I don't know.
It's like, do I, I just hope that people know that they can hit up people like us for advice in these situations.
There are a lot of great people online.
Lulu is another great person to Lulu.
Messervie is a great person to talk to on this kind of stuff.
I was saying, I wrote a piece about this.
And in it towards the end, I get to the point where it's like, you actually, and this is what I really would love to talk about, things have changed.
Yeah, there are a lot of people who are great online talking with big audiences.
And it's not just like they're anonymous people.
There are pseudonymous, pseudonymous.
I cannot ever pronounce it.
Semi anonymous people.
There are CEOs, big, huge, popular, public CEOs who are posting.
And they are all just like a DM away.
And you can see on Twitter, you can see who's connected to who.
Like if you don't know them directly, you want some advice, you talk to anyone, it's pretty cool.
The vibe has shifted somewhat.
And I was just watching the Reagan National Defense Forum.
This is like the Super Bowl for defense forums.
You have, first of all, you have last week, you had Elon Musk telling the advertisers to go fuck themselves on the stage of the New York Times.
Then this weekend at the Reagan forum, you have Palmer Lucky sort of telling kids not to follow their stupid dreams.
If they're, you know, contra reason and, you know, self-defeating or not good for society.
It was like a very sort of anti, I don't know, mainstream message.
It was strange to see him up there being so honest and unapologetic.
And Palmer, someone specifically who just lays down his opinion every day and does not give a fuck,
and has really gone direct in that way with his own message about his own company, which is killing it, by the way.
Onderal.
Then you have Alex Karp, who just espouses like an incredibly anti-woke message openly on stage.
And is like, I'm not hiring people who are idiots on the following topics,
all of which would have been considered beyond the pale.
Just three years ago would have been articles in the New York Times about, you know, the terrifying menace of Alex Karp.
But I am running one of the coolest companies in the world.
And I'm telling young people, you are breathing the vapors of a dangerous, new, fake and self-destructive religion
when you are sitting at your elite school pretending because you watched TikTok twice
and got an A-plus on some crazy paper because your professor couldn't get a job anywhere else
that you actually understand the world.
And you're not welcome at my company.
I think things are different now.
I don't know, what do you got? Am I right? Am I wrong? Am I just naive, optimistic, too hopeful?
Well, yeah, I mean, so, you know, Solana, you and I, again, we're like literally grizzled combat veterans at this point.
Ten years in the meme wars, right?
The last five is really, I think, where most of the action took place.
That's right. That's right.
So basically, you know, tech versus media, you know, I kind of, all right, I'm just going to rattle off the history here.
And then I'll be turning this into a blog post and so on and so forth with the rules and the history and then the history history, the deep history, right?
But very roughly, tech kind of arguably, you know, you can argue when tech exists as a culture, but maybe you date it to 95 with the graphical web browser.
Okay. And then from 95 till, you know, 2008 or so, because of the dot com crash, media didn't even really take tech seriously.
You know, just like gadget guys or what have you just doing their stuff on the West Coast and they were considered basically an auxiliary of the Democrat Party.
Like you had, you know, unions and you had this group and that group and then there were Steve Jobs and the tech guys making gadgets and over there in the corner.
The media concerned themselves with their expense accounts and the rock and all this other stuff going up into 2008.
And this article at that time, I think by Joel Stein, that's enumerating like the power centers of the USA and it's real time capsule from 2008, because you know it's not on there.
What's on there is a Pentagon and Wall Street and so on, you know, it's not on there.
In 98.
2008.
2008 what's all social media.
Silicon Valley is not on there.
As a power center in 2008.
At all.
At all.
Yeah, that is the phrase big tech had not even been innovated at that point.
Exactly.
This whole system that we're in is so much more recent than people think because what happened was after 2008 after the financial crisis.
Tech revenues went vertical.
Okay.
There's a great graphic that shows what happened.
Right.
Bam.
Okay.
What is this graph?
This is showing print media revenue tops out at $67 billion in year 2000.
Then it's like down after the dot com crash, but it's flat ish.
And then a complete collapse down to like $16 billion in like four years.
This is advertising revenue in newspapers.
Advertising revenue in newspapers is a blue line.
Right.
And then including digital digital doesn't save them doesn't come on fast enough.
And Google eats their lunch and then Facebook eats their lunch.
That's a green line over here.
Google is the red line.
All right.
So basically it's one thing to see your neighbor become like a billionaire.
It's quite another thing for them to become a billionaire while you become a thousandaire or whatever.
Right.
Okay.
And so these guys essentially over the first four years of the Obama administration saw these tech guys who had been in a box or whatever.
They didn't think of as anything.
Suddenly rock it up ridiculously fast.
And because I was the iPhone and that was the reallocation of budgets after the financial crisis to online ads, which are finally mature and converting.
That was the fact that like SAS was starting to work.
Y Combinator.
Actually, you know, remember when I started 2005, that only that whole modern seed era of things only really started working in the late 2000s.
There are a bunch of great companies found around that time.
Stripe Airbnb Uber, all of that basically by 2013 after Obama got reelected.
Even in 2012, by the way, do you guys remember in 2012, the nerds go marching in?
How a dream team of engineers from Facebook, Twitter and Google built the software that drove Barack Obama's re-election.
Okay.
When the nerds go marching in.
You see that?
I remember that narrative of the Obama being the first sort of internet president.
He had this team around him from tech basically.
That's right.
Not fully believing it.
Well, and the reason for that is because, you know, Facebook and then Twitter started in very blue zones in the Harvard area and in San Francisco.
And so it was assumed that technology was blue and blue was tech and that it was just good and that if it had any effect on politics, it would be to overthrow oppressive regimes and overthrow, you know, cause the Arab Spring.
Go ahead.
Right.
That was just assumed until Arab Spring, which they thought was great.
We don't hear much about the sort of consequences of that.
Yeah.
A lot of disasters.
A lot of people dead unfortunately.
Right.
So we can come back to that point.
But basically what happened then from 2012 to 2016, a bunch of things happened.
First is all these conservatives started getting Android phones.
Okay.
And there's a really interesting sort of meme that makes this concrete.
If you're seeing, and this is kind of late 2010s, starting to get a little obsolete or whatever, right?
But there's a, there's a collage of a bunch of Democrat visages and a bunch of Republican visages on Twitter.
So Democrat visages are guys with glasses indoors and like, you know, kind of unshaven or whatever, right?
They're like unshaven programmer, graphic designer, Yas Queen types or whatever, you know, the guys pointing at the thing, right?
Okay.
And, but the Republicans are more interesting or this is like, it's an interesting different kind of visage.
There are people with sunglasses in trucks outdoors, taking selfies on their phone.
So the fundamental difference is the Democrats are indoors and Republicans are outdoors.
Because almost all the Republicans are in sunglasses and they're clearly on the go with some like cheapo Android phone.
So part of what happened from 2012 to 2016 is the polls got online and that started shifting Twitter and the internet to the right.
The other thing that happened is after Obama got reelected in 2012, the media, which had played nice with tech guys because they needed them to get Obama to get reelected, now had four years to settle scores.
And all the knives came out and all the valleywag type stuff happened around that time.
Would you just look at all those rich people?
I mean, I think it's like editorial vision in nutshell, but could be so much more by Monju who's become a full communist now and radicalized, right?
That was like 10 years ago when he was ostensibly central left.
He was complaining about attacking them as rich people and so on and so forth.
That's crazy.
I remember people being mad about that.
But in my mind, I remember Dave Moran complaining about this, which made sense because he was being attacked.
I don't remember the press rising to the defense of those guys.
That's interesting.
That's right.
And actually, a few years later, he's all abolished billionaires.
It's literally he's writing that.
Okay.
The radicalization happened to the journals.
Yep.
Okay.
And essentially, though, it was a boxer's clinch where that tech and media alliance didn't make sense anymore because the media guys were like, wait a second, these tech guys aren't just like some vote bank, gadget bank, whatever that's making the bejeweled toaster on my desk that is an iMac.
Yeah.
And then two things really, I mean, it was Gawker is destroyed.
Yeah.
That comes a little bit later.
But yes, that's right.
That's right.
Of course, that's an important episode.
And then trouble wins the election.
And at that point, it's worse.
Yes.
That's right.
But crucially, the negative coverage starts in 2013.
In 2012, you can even find them writing articles like there's no such thing as a brogram or and so on, right?
So this goes back to that visual I had of the blue tribe, right?
Red tribe, great tribe.
If you're part of the tribe, you get friendly coverage.
If you are not part of the tribe, it's information warfare.
Yeah.
Right.
And now that can mean, by the way, you can be part of the tribe and then kicked out of the tribe or you can choose to leave like Glenn Greenwald has, you know, he was, he was like, he had all the prizes.
That's why I give him a lot.
I don't agree with Glenn on every issue, but I respect him because he had all the prizes within blue and decided to kind of go and do his own thing and stand for a principle that he stood for, right?
Conversely, it is also possible for somebody to be kind of a renegade, but then to become incorporated into blue and to be part of this Borg, right?
Like Google, early Google was much more buccaneering and swashbuckling and so on than what's become, which it's not as blue as it was like a few years ago, maybe, but it's pretty blue, right?
So, so once you kind of have that visual, it's really the, you know, that's the friend enemy, the tribal distinction.
And it's not exactly left, right, or what have you.
It is group nongroup.
Let me pause there.
I've got a lot more.
Well, I want to, I mean, I have a slight pushback, which is that I agree with.
I mean, the whole history, I think is correct and insightful, especially the piece on the revenue is really important.
It's, you know, we, I think I maybe get somewhat distracted sometimes by the ideological combat component of all of this.
It just very clearly feels to me like a classic information war and maybe not classic.
It's not classic.
It's new.
It's a new kind of, it's a very scaled up information war.
It's live.
It happens every day.
It lives in our pocket.
It never ends.
But at the end of the day, like we are, and this is a point that is, you know, I've heard before I just forget.
It's like, we're in cop, we're competitive.
We're competitive.
There's a business piece that's competitive, like just hot, like industries are competing.
And then online, that I think the new thing that we've seen over the past few years, and let's just focus on tech for a moment, is we're not just, it's not just a money issue.
Like it's an actual, the all in pod is a massive success.
And that is, you know, a side project for David Sacks.
And that would be a dream come true for every single person in media.
So it's not like the platforms are taking the money.
It's like the people on the platforms are also taking the attention from them.
They're not even, they don't even get to be the attention people anymore.
Or not exclusively.
There's combat.
There's, there's competition there.
So separate from the ideological piece, there's just, there's the reality of just competition.
And when you're in it with someone for something that you consider your life.
So it's, it's funny you say this because, you know, now again, this feels like, actually, GV, I want you to jump in because we were just chatting.
So, did you want to say something?
Yeah, yeah, I, you know, there's kind of the broader, there's the broader information war between tech and, you know, the paper built aligned media.
But, you know, the media, they're kind of the pit bull for, for some of the, the paper belt against, you know, whoever in tech is an enemy of whoever is like helping place various stories.
You know, to me, it's been like, I've been trying to like figure out like trying to backpropagate.
Why did this happen to me?
Like, where did I cross the threshold of becoming enough of a problem that they needed to have leverage over me and expose me?
And I mean, obviously, you know, Mark and Gary have been supportive of the movement, you know, for all sorts of reasons, one of which is like, obviously we think that, you know, the current sort of regulatory capture attempt by, you know, AI safety,
the AI safety complex and some of the big incumbents, you know, it's camouflage is like anti-doom, trying to, trying to save us, you know, trying to, trying to save us from open source models, right, their dual use and so on.
And, you know, we were calling that out and getting, getting people fired up, calling this out and it became a problem.
And of course, you know, Gary tweeted this that, you know, FTC chair Lena Khan was invited to YC, you know, and I was there and we had a little chat.
And, you know, I've always, I've always started concerned of our, the concerns of our community that like, hey, actually, this is, this is, you know, kind of some of the big incumbents kind of covering up the fact that they're trying to capture the market with sort of like, oh, this is for your own, your own safety.
And that's when I became like officially a political problem, right. And, you know, there's all sorts of interests in the background, you know, trying to pull strings here.
You know, I have some hypotheses, maybe I won't go into like exactly who I think is pulling the strings. I have my, I have my thoughts on that.
But what's been public is that, you know, Secretary Ramondo, I believe, called out EX specifically as like dangerous movement and something we should suppress with AI.
They want to, like our movement is about free speech, freedom of compute, freedom of AI and not like top down oppression aided with AI.
And they're literally proposing shutting us down with AI, which proves our point, which is kind of like,
By the way, by the way, you know, that's like, it's like, well, nobody rid me of this metal some priest kind of thing, right.
Well, no one rid me of this metal some EAC, right. Like EAC is a problem and that's like a decentralized signal to the journals to go and, you know, right.
It's stochastic journalism.
Yes.
Come on, that's pretty good.
Right.
No, I agree.
Yeah, you're holding up the target. This is where I'm trying to think of what the really.
That's the illusion to stochastic terrorism. Okay, I thought it was funny. Stochastic journalism, stochastic terrorism.
Okay.
I want to talk about it was funny.
I want to talk about EAC. You were just getting into it. I mean, what this is a little bit off topic and we can, you know, revisit any of the stuff that we were just talking about.
There's a ton there on the war piece, but this, you know, it's dangerous and whatnot.
What is EAC? How would you even describe it?
What is EAC?
I think for me, it's kind of like a cultural framework, really, or a, or a metacultural framework.
We're trying to understand where's this whole thing going, where's civilization going, you know, from first principles.
At the end of the day, the only laws are the laws of physics.
And I, you know, I'm a former theoretical physicist and, you know, I do physics based AI now, you know, I always think about physics and nowadays I think about self organizing systems.
And, you know, to me, it was, it was just an exercise in writing and trying to understand where it's all going.
And rather than have like, like completely like unanchored to reality sort of theories like, like the doomers do of like AI taking over as soon as it reaches human level AI takes over and fooms and takes over the planet.
Like I've been trying to actually find like, where's this thing going?
It's like, okay, well, you know, civilization at the end of the day is a system that's like alive.
All systems that are alive or that are basically life from a physics standpoint seek to grow.
They acquire energy to maintain their sort of state and they seek to grow and increase their ability to acquire free energy.
It's like, okay, well, civilization wants to go up the, what is called the Kardashev scale.
So it is the scale of energy production or consumption.
And so that's where we're going, you know, and that's where the system wants to go.
And, you know, it keeps morphing itself.
It, you know, searches over the space of technologies of cultures of memes of genetics of everything in order to, to, to ascend this scale.
And, you know, basically it's like, we're just pointing that out.
And to us, like, like it's first a framework of like, what is and, and, you know, that's what's going on.
And then it's like, how should you live your life given this fact?
It's like, well, actually, if you help the growth of civilization, you know, you will likely prosper.
And it's kind of a self-fulfilling prophecy.
If you're optimistic about the future, you work on hard things, right?
Because you believe in a better future.
So you want to contribute it to it so that you own a piece of it and, and, and then you go out and build and do hard things.
And then the good future happens.
Whereas if like you believe in doom and nothing good is going to happen, you no longer build, you no longer want to have kids.
You don't bet on the future.
And then the future is actually worse, right?
And to us, it was a sort of reaction to the pervasive demerism and the pervasive pessimism, tech pessimism that was just dominating the news cycles.
And we were like, can we have a viral optimism movement that, you know, hyperstitiously induces growth of civilization, right?
Don't we all want that?
Don't we all want to be, you know, amongst the stars?
No, that's the thing.
No, that's actually, I mean, for us, us three, yes, but that's actually like a core, core difference.
You act, obviously, ACC.
We're talking about acceleration is the word that you're using.
It's E-A.
You're making a play on effective altruism.
The effect of altruists are very concerned with accidentally building a god that kills us, really, is like where their head's at.
And they, not just they, now you have the safetyists in the media who have, they want to slow down tech for all sorts of reasons.
But their position, all of them in this sort of uneasy alliance between very smart people in AI who happen to be E-A-pilled and a little bit of a doomer,
and the press and, you know, the government that wants to slow all this shit down, it's slowing things down.
Endlessly in the press, especially you hear, you know, Mark Zuckerberg said, move fast and break things.
And then things broke.
We have to move more slowly.
And you're not saying that.
You're saying we need to accelerate.
So the positive vision is there.
It's awesome.
And I thank you for your service, sir.
It is very important.
The memes are excellent.
And I think I agree.
They are powerful.
I think they're motivating.
I think they are helpful.
But they identified correctly your critique of them.
And, and so that is, you know, you're, you're locked in a sort of at that point.
It's if people hate you a lot.
And I mean, I've seen it.
White how much they hated you until this week.
They're definitely mad.
Can I make, can I make a couple points there?
Yeah.
So there are decelerationists.
And there's also what the current US establishment is, which are stagnationists.
Right.
What they want to do is they're in their own way, conservatives, where they want to freeze
the world in amber.
And so you will find, for example, that, you know, for example, Raimondo is talking about
the tariffs and so on and export controls.
And they want to kind of freeze China as a power.
And actually, I can understand that.
Okay.
But, and so they're like, oh, you know, the US needs to be a leader in AI, so we're going
to ban exports in there.
And then literally, you know, that's what they're saying on Mondays and Thursdays.
And then on Tuesdays and Fridays, they're doing AI bans in the US and saying, you need
to slow down and not accelerate and so on and so forth.
Right.
So they want to kind of think they think they can be a policy lovers, which, you know,
they're not Silicon Valley, they're not Shenzhen, you know, they're neither of these
things, but Washington DC thinks they can freeze the current dispensation in amber,
where they've got a healthy lead and nobody abroad and nobody at home goes too fast and
nobody, they just want to stop the disruption because that's the thing.
Acceleration is good for lots of people, but it's not good for them.
It's not good for power.
Any technological innovation, I think, pretty much.
Well, so that's the thing.
So I've got it.
I've got a perspective on this being out here in Asia.
Right.
And India loves tech.
India loves tech.
And the reason Indians love tech is, you know, you've got a guy who was on a, you know, like
a very poor 10 years ago, who's now gotten Android phone and they've got a lifeline to
the world and they're able to study and they can earn and all this stuff.
So it is correlated with the massive improvement in their living standards.
Right.
The journals and more generally the US establishment, you saw that graph, it's correlated with a
massive decrease in their living standards.
So they have a learned correlation where the faster the tech grows, the less money they
have, the less power they have, which is kind of true for, you know, it would be extremely
painful for you.
Right.
Acceleration is extremely painful for them.
Right.
And so that's why they're fighting the internet and they're fighting every force that's against
them.
Right.
That's really a conservative way.
I mean, it feels like this.
And then in this case, you're talking about generative, obviously it has many things,
but the thing that the most attention at this point is are the generative models when you're
talking about like language specifically.
This is something that it looks like a journalist that knows the truth.
It's NBC level.
It's literally the thing is, you know, this guy, I got to get this guy to put this project
back up, which, you know, I used to say, not even jokingly that these journalists, you
know, there are just like a sports article, it's a wrapper around a box score, you know,
box score is like the, you know, how many rebounds, how many assists, steals, whatever
in a basketball game, or a financial article, it's a wrapper around a ticker, like, you
know, stocks were up on heavy trading, blah, blah, blah, it's just like a verbal narrative.
I used to say that these articles are just wrappers around tweets.
You give it three tweets and you can write the article.
And I used to say that as a joke, you can go find, not even as joke, it's like true
and also a joke, right?
From like years before chat, GPT.
And then when it came out, it became literally true where you could paste in a few article,
like a single tweet into this thing that, you know, like a New York Times article generator,
and that's probably gotten even better a year later and generate an entire full NYT article
that's like dark times ahead and technology as acceleration continues, you know, like
you could literally do that, right?
And there's no intelligence.
It's totally paint by numbers.
You just have the stylistic kind of thing off the prom.
Go, go, go.
Yeah.
Yeah.
I think like the thing, the thing that's scary, right?
It's kind of like the old world media, they serve the incumbents, they serve those that
have interest in top down sort of control.
They like to like, they gain proxy power by being instrumental to authoritarians, right?
And those that argue for more control and EAC is about like saying that acceleration
and techno capital acceleration is a positive force.
It creates amazing technologies.
It gives us wealth and, you know, the counter argument to it is that, well, if we, if we
don't control who, who ends up in power, that's, that's bad.
You know, really what they're thinking is like, we might lose power.
And so that, that is bad, but the reality is like the system would adapt and powers
would shift to, you know, those that are disrupting the incumbents, right?
And that's good.
The system, you know, optimizes itself and, and finds, you know, whichever technologies
are most beneficial to the world and helps them scale up.
And of course those that are, that produce those technologies get to have sort of more
power to allocate capital and control where it goes, right?
Which is the sort of natural meritocracy.
And they're trying to break that.
They're trying to maintain the sort of status quo.
They are the real conservatives.
They call themselves maybe progressives in some cases, but they're really just trying
to conserve the powers that be.
And then the media, they're just mouthpieces for the incumbents.
Cause again, like, you know, those are the only people that still talk to them and they,
they use it like, you know, they use them as the media is kind of like an information
warfare arm of like, you know, the incumbents and the pre-rebuilt, right?
And we've seen that like, and the label, you know, go ahead.
I worry a little bit and I want to get both of you retake on this.
I, unless you do you want to, you send, I'm just going to jump in a little bit, which
is, you know, there's more I can say on kind of the history of this and so on, but there's
a huge difference as to where we are in 2023 versus where we are in 2019, 2020, 2021.
And I think Solana, you did your part.
I think I did my own little part.
We did our part.
Go ahead.
Shakes.
No handshakes.
That was no handshakes.
Please.
Exactly.
Remember that?
Yeah.
So what happened was starting in 2013, let me just recap the history that began and bring
us to the present day from 2013 to roughly, you know, 2020, the journals essentially began
a reign of terror against tech where there was all manner of cancellation.
We didn't have the word for it then against people large and small.
That's why the homeless problem, which is not really a homeless problem, but a drug and
mental illness problem is St. John Friedman, one of your, you have many talented writers,
St. John Salud.
Yes.
She's cool.
All right.
Is it she?
She.
Yeah.
Okay.
Okay.
Sorry.
I didn't know what the, you know, what the...
You've got to be careful.
Nameless.
So St. John Friedman has done a phenomenal job on documenting how the like the homeless
problem, it's not just a homeless problem, it's a drug and mental illness problem.
Point is in the early 2010s when something could have been done about it, there were a
few tech guys who made in-politic comments about, you know, the sudden epidemic of needles
and syringes and poop.
This guy, Greg Gottman, another guy, Peter Shee.
And yeah, maybe they posted in like, you know, maybe you might not use exactly that language,
but obviously they're, you know, it's a lot less offensive than some crazy guy throwing
feces at you in the street, right?
And more importantly than the NGO who's feeding him drugs and getting paid by the city to
do so, right?
They mean things about the people who were chasing you down the block.
Yeah, exactly.
And they put them down.
That's right.
That's right.
So what happened was the journals at that time.
It's like, that was tech people turned on them.
Well, but the reason was there's a bunch...
If you go back and look, Peter Shee, Greg Gottman got destroyed by the media at that time and
then people queued off of that as, oh, that's what I'm supposed to, I'm supposed to yell
at them, right?
And so it became for years, it was incredibly un-PC to even mention the problems that San
Francisco was happening.
So it was like disabling the immune system during the period when it maybe could have
done something more.
And then this thing just got completely out of control and it became what it is now and
these NGOs became totally entrenched and so on.
Many other kinds of things happen like that.
That's just like one example of it where the journalist caused a giant problem and then
only after it became massive then could it be acknowledged.
It was interesting.
I was nervous to write about local politics and I forget that sometimes, but when I first
started seriously writing in like 2020, I was nervous to touch the homeless issue and
the drug issue.
And I just thought like, this feels dangerous, people are going to come after me, I don't
care, I got to do it.
And it doesn't feel that way now.
It's a weird thing where I always ask myself, is it because they're so strong or because
they've become weaker?
And I think it's both at the same time.
How they won, is that why?
They don't care anymore.
Yeah, exactly.
That's right.
So I think it's both where the left, the Democrats, the blues, whatever have captured the state
and so they've got the budget and so they sit in their parapets and no matter what we
see online, the money just keeps flowing to these NGOs, they flow to them or whatever,
right?
So we can yell and they can lull and then just go back to shibbing syringes, right?
But they have lost control of the network.
And thanks to Elon and thanks to also Substack and Coinbase taking a stand and Salon and a
bunch of other people, they've lost control of the network enough, they're getting crushed
in soft power terms every single day.
And that does also matter in terms of building a parallel consensus over here.
But it matters insofar as we can convert that energy into parallel institutions.
And so that's actually GV where you are, I think, obviously talented and as soon as
a meme maker and so on in your own right.
But it's also fortunate that this happened to you.
It's not good that it happened to you, but it's fortunate to you in 2023 when we have
this whole ecosystem, right?
So in the mid-2010s, what would happen is some poor tech guy and it could be a very junior
person or the most senior executive would just get targeted and just torn limb from
limb on Twitter, where it was such an overwhelming advantage of forces for the bad guys that
even somebody liking a tweet in their defense would get pulverized for the like, right?
And that means, do you think about like the eyeballs are just scouring Twitter for anybody
who had the thought of defending somebody, okay?
And so that was a level of control that they had over the platform and thus overmines and
the signals that were being sent.
It was very, very ugly time.
And a lot of people-
We have realistic killings, it would feel like.
You had like the James DeMore thing where he wasn't even posting publicly, he was posting
internally on a channel at, he was at Google, right?
Was that Google or Facebook?
Yeah, or like what happened to Tom Press and Werner at GitHub?
Completely fake episode, okay?
You can look at this article called Facts Conveniently withheld, okay?
There's tons of these kinds of things that happened in the 2010s where good people were
just attacked and they had nobody to defend them.
And so then what happened though, steadily, gradually, year by year, we built enough followers
until there's a really interesting tipping point.
So in 2020, I funded this, I made that public, there's a Nigerian guy who did this analysis,
tech journalism is less diverse than tech.
Well, now of course, now we're in 2023, so we know that DI, DIE is stupid, okay?
And we can actually say that, fine.
But back then, essentially, there was a huge to-do made about how white the tech, I'm not
the kind of person who believes white is an insult, they are, and yet they were far, far
wider than all of us, okay?
So here's the thing, Solana, to your point, is when you go and look at the raw data over
here, you look at the raw spreadsheet, you see a very interesting phenomenon.
And the interesting phenomenon is that back in 2020, this is like three years ago, there
are only a few journalists who had more than like 100,000 followers on their own.
It's like three or four, okay?
But lots of founders had way more than that.
And I realized something, it was like a lighting bill, it's like, wow, the journalists are
not exceptional in their own right as individuals, they're not like charismatic people who people
want to listen to.
They can only win if they team up in groups behind brand names and then attack the guy
who stands out.
That's, you know, it's actually this remarkable thing when you start looking at, of course,
followers aren't everything and so on and so forth.
But it was remarkable what a difference there was, where it was a hugely right-shifted distribution
of founder followings to journalists' followings.
And so then once Elon took over Twitter and he stopped whatever algorithmic boosting, artificial
boosting those guys were getting.
Yes.
Well, that has been framed by journalists, I've seen journalists talk about this on threads,
as Elon is now boosting nefarious people.
He's not boosting, he's just, Twitter doesn't have enough people working to manage all this
at this point.
They're just simply no longer boosting these kinds of people out.
For years we wondered, like, how is that random VC who says everything that they like but
has never made a successful deal in his life?
Like the face of venture capital on Twitter or like, why did he still did so much engagement?
They're being pumped in the trending topics by a team at Twitter that was propping them
up that no longer exists.
Twitter moments.
Do you guys remember Twitter moments?
Yes.
I asked almost, I think, like every couple months, I'd be like, tear down this wall.
Yeah.
No.
Twitter moments, people didn't know it by name because it wasn't like, like Google Maps,
you go to maps.google.com, right?
So Twitter moments was not something that was publicly named so people didn't know what
it was.
But it basically is a thing where when you logged into Twitter, it would show you the
trending news story of the day that they had picked and they would give you some prompting
as to how you were supposed to think about it.
In a person, you're supposed to attack.
Yes, exactly.
So some poor Shmo would basically have the two minutes' hate of Orwell directed at them,
right?
It was like the lottery.
That's surely Jackson's story.
The negative lottery.
Oh yeah, yeah, yeah, yeah, yes, yes, exactly, right?
So here's basically now what we have is what we've done is we've flanked the traditional
legacy media from two directions, both ultra short-form content of tweets and ultra long-form
content of podcasts, where they're relatively weaker, you know, then they're, and so obviously
it's content, but it's also distribution channels.
They didn't have years and years and years of legacy distribution channels there.
And the mezzanine, right?
And tech in general is about going, you know, to the extremes on some new channels, like
the office in the very small bits of content and very long, right?
And so now, and then you tweet out the podcast, right?
Or in the podcast, you talk about the tweets, right?
So we're flanking.
And of course, what Elon has done with the video stuff has made that even easier to do.
That said, by the way, I do think of Twitter.
You know how like there's that famous, or at least famous when I was a kid.
It's so strategic, it's location, you know, that's what Twitter is.
And it was, you know, I was a three-search party and then it switched hands and became
the regime's tool and now it's back to Constantinople.
But I don't know where it's going to be in two or three years.
They are attacking the heck out of, out of, out of Elon.
Go ahead.
I think the next battleground is LLM's right at the end of the day.
I mean, it's, I mean, it's like, it's like, you know, it's like it's like a, it's like
right? At the end of the day, it's about information supply chain attacks, right? If the media is,
you know, they have absolute power over information flow, then they have extremely
high soft power. We eroded that power with technology in the age of social media.
There's still bitter about that. And now the media are trying to serve sort of incumbents or
whichever authoritarians are pulling the strings, they're trying to ensure that this complex that
they're part of maintains control over or gains control of the new information supply chain that's
emerging that is LLMs, right? They want to be able to shape the cultural priors of the LLMs that
shapes how they speak. And if LLMs become like the new Google search on steroids, right, which they
are poised to do, they are going to become a source of truth, right? And so that's why we need
decentralized AI. Exactly. I would say that, you know, this is the same battle over and over.
They're kind of like still bitter that they lost the social media battle, right? When they had like
sort of a sort of regime installed within Twitter, and they have like soft control over Twitter,
you know, everything was fine. When Elon came in, bought Twitter and disrupted everything,
then they demonized him. And, you know, they said that he's dangerous and whatnot, when he's just
trying to ensure people have the freedom to speak. For the record, you know, like in the old regime,
my first Beth Jesus account got booted, right? I said that and I got locked out and I couldn't get
back in. So the original sub-stack was from my original account, because I said, you know, COVID
came from a lab, which it seems higher, you know, very high likelihood now, right?
Wild that the OG Beth got canceled for the COVID, because I feel like at this point,
journalists look back on that, a lot of people, I mean, anyone in the kind of the one-party state
looks back on COVID and really tries to pretend that it didn't happen. And the COVID lab leak in
particular is one, it's like that in Hunter Biden's laptop or the two things that they really just
will scream to your face that nobody was censored for, nobody was kicked off a platform, or no,
it never happened. It was like, you're just making this up. And they have to do that because
those two examples are so incredibly damning. I've had a couple more honest journalists say,
you know, the Hunter Biden laptop one, for example, yes, it happened, but it's, you know,
it's just this one thing. Why does people, what do people keep talking about? It's like,
people keep talking about it because it's incredibly important that we were silenced
whether there was an attempt made in that way. And a lab leak for me is also right up there.
Just that we couldn't talk about this very obvious question, I would say, that was worth asking.
There's, you know, in the background, there's cybernetic control of information propagation.
They're trying to control people's thoughts by biasing what speech gets algorithmically amplified
or suppressed. It's pretty simple. I think that, you know, for COVID, you know, as if we,
there was points where we had lockdowns, it's like, look, you know, this was like the
authoritarians, they were like, give us a ton of control. We'll keep you safe. This thing is very
dangerous. We gave them a ton of control. It didn't help a lot. It didn't help at all, right?
It didn't help at all. It's total failure is actually the bottom up sort of, you know, the
technical capital machine is what saved us. It did all this biotech engineering that, you know,
helped save some lives. And so at the end of the day, the lockdowns just didn't work, right? Like,
we still, the thing is still spreading to this day. And so it's a failure of this sort of narrative
that if you give incumbents and those in power, more power, right, for your own safety, like it
violates the narrative that they'll do anything useful, right? And so they want to suppress
that story. One quick thing on Twitter, I think, get back to the thing and ask you maybe an uncomfortable
question based on what you were just talking about. So on the on the Twitter thing, and the
concept is an opal piece, you know, it's changing hands back and forth. I would say one person who
does not get nearly enough credit for understanding that and acting, I think, morally in a sort of
righteous manner, is Jack Dorsey, who at the all like, first of all, founder of the company
was on the free speech side, things tilted in the other direction. And then we have confirmation,
we see, first of all, he said all this stuff publicly, he is the reason one of the key reasons
that Elon was brought in and then was able to do what he did. And I have no doubt that he
knew things would get crazy with with Elon in the company and that things would change dramatically.
But my sense was, especially after Hunter Biden's laptop, Jack felt like it this this is a power
that is too great for any one person and it like it needs to switch hands, it needs to it needs to
it needs to recede. Now, speaking of power, as apology you were saying before, like, we don't
know where this will be in a couple of years, which is why I get nervous about things like
community notes existing, and like the celebration over people who we don't like, you know, being
fact checked and things like this by the platform that makes me nervous, but no power when I think
more powerful maybe than the AI piece, you guys are talking about both of you now,
decentralization. And I and apology, you're saying that this is the thing that we need, I agree,
because from where I'm sitting, it looks like AI is a naturally centralizing technology.
I am skeptical of people who think that AI is the solution to all of our problems in the
end, we don't have to keep it, you know, there's a super broad conversation here on this topic
specifically, I am nervous about the amount of power that very few people have not worried about
some runaway AI. I don't see a lot of small players, you know, upstarts with powerful LLMs.
I see, I see the giant companies have these things, and they have terrible track records on
this question of speech in particular. And I'm, I when I look ahead, it's, you know, it's, there
is a very real possibility that the people who control this are the sensors, and this things,
you know, like you have a handful of these things that are shaping our reality, who's writing those
rules, certainly not me. And so these are central, they seem like centralizing, not
decentralizing technology is like what does lies to AI, I don't see that I don't really see that
happening. I think that you can want that, but I don't know that that is the natural vote.
Well, yeah, I don't know, what do you so, you know, I mean, I agree that in the current paradigm
with the sort of power efficiency and density of neural compute we have on GPUs, it's, there's a
huge advantage to just building a football field supercomputer, scraping all the data over of the
internet and like training one big centralized model. But at some point, that sort of the
advantages of doing that are sort of going to get eroded away. And, you know, the big incumbents
hopefully can compete each other's margins out. And then there's going to be sort of like an
advantage to sort of decentralizing AI, bringing AI towards the data. We're still far from there.
For now, that's right. There's kind of like, just a big advantage in just being a big centralized
player. And unfortunately, right, like I said, you know, LLMs are kind of the future information,
you know, highways, right, for people, it's much more natural to ask an LLM that's human like
to get information either from the internet or from your database and whatnot. And if
what LLMs are allowed to say is shaped by a few people in some room with like
enormous cultural and soft power, I think that's pretty dystopian. And it opens up,
you know, it's kind of turnkey authoritarianism, right? It's kind of like, it's even more subversive
sort of form of censorship. And, you know, those that want to have that sort of power,
of course, you know, are going to push for, you know, AI to be centralized so that they can
co-opt these organizations that have the monopoly or oligopoly. And they want to,
you know, they want to form such an oligopoly so that they have such power. And it's not
disruptible by, say, up and coming startups. And so, you know, that's why sort of like,
you know, this executive order, they have like compute caps, right, like very close to what,
you know, current big incumbents amount of compute they threw into their models are, and they want
to ban sort of open source models or make them like a dual use technology that you need to report
the government. So, you know, they'll have control over whoever pops up as a big, you know,
provider of LMS. And to me, that's really dystopian. I think the P probability of 1984 is superior to
P AI doom by a lot. And, you know, I still invite AI doomers to, you know, explain to me how they
think like AI is going to fume and take over, you know, as someone who's used AI in their career to,
you know, engineer matter and, and biologics and all sorts of stuff. Like I can tell you,
it's much harder than you think. Obviously, biology has a lot of experiences in this area,
much harder than they think. So they're kind of sci-fi scenarios are implausible. But the thing
is they're like those kind of create, you know, the doomers that like talk about fume and like
all these crazy sci-fi scenarios, they're instrumental to those that seek power and want
to have this sort of soft power of shaping the cultural priors of the LMS because then they'll
shape the culture of the people and then they're going to be able to control the people. And so,
you know, I think there's this tech disruption and, you know, chaos is a ladder and the existing
incumbents are trying to secure power in this new era, just like they kind of did by, you know,
subverting and co-opting some of the social media giants. And, you know, we don't want to have
a Twitter situation, a pre-Elon Twitter situation for LMS again, right? We don't want that. And so,
you know, the whole point of, you know, of the AI policy part of EAC is to maintain freedom,
maintain competitiveness in the market, don't over-regulate it, that serves the incumbents,
and that serves the authoritarians ultimately. And we should have freedom of speech,
freedom of thought, freedom of compute. So, yeah.
Apology on this question. Yeah.
What is your, I mean, do you have some any concerns at all that you might share with the EA
people? Like, do you, like, could you? Yeah, no.
Well, see, the thing is that, you know, Twitter reduces the first bit is which tribe are you in?
You know, are you this tribe that, so certainly I'm on the accelerationist side of things.
In the 01. With that said, you know, when you add a second bit is,
is there a real chance of a superintelligence? I absolutely do think there is. And the reason
for that is what most people have seen over the last year is, let's call it chat GPT style AI,
right, which is generative AI, where there's a human in the loop, you know, and you're prompting it
and you're typing in things. And it's basically just like search engine plus plus,
right, where, you know, it's not that different from Google search or Google images, it's just
you get better results on the other side, you know, it's might be magical, but it's kind of like that,
right. However, DeepMind style AI, okay, where it's got artificial intelligence that is winning
games of go, right, winning games of Starcraft. That's something and it's just looking at the
map, looking at the video game, you know, pixels and able to figure out what the moves are and so
on reinforcement learning. That's different. That's actually the, there's no human in the loop there.
The AI is just playing the game and it's super human already. But in a constrained and not
time varying environment, that's really important. It is, whether it's a game of go, game of chess,
a video game, right, that's something where there are rules in that thing, and it's kind of a bounded
environment in a fundamental way, right. Still, you can envision a world where the combination of,
you know, the kind of planning and Starcraft if your place Starcraft, so like Starcraft
is something which you, I mean, certainly an AI could be very good at like resource allocation
and so on decision making, take that hill and send the troops and whatnot. And you can easily
imagine that the real world with drones being Starcraft style, you know, controlled, right.
And you combine that with the ability to speak and generate images and generate video and appear
in any form, right. Like, you know, today, of course, it's appearing as text, right. Tomorrow,
when it, when, you know, an AI returns a result to a query, it's text, but soon it can appear as
a VR thing floating in 3D that speaks to you in your language fluently, like, you know,
the Blade Runner kind of scene, okay. When you combine both those things, you get something
that's actually fairly powerful with not that much squinting, right. And so, what I think is that
every community of fairly large size, every community that survives, in my view, crowd funds,
and when I say crowd funds, I mean in the broadest sense, it could be literally with tax revenue
that's the most, you know, traditional method of quote crowdfunding, albeit, you know, involuntary
crowdfunding, right. So, but every large enough community has its, I will call it AI God, okay,
its network God, which is all of the knowledge of that community and the values of that community,
right. And so, you could imagine a Christian version of this, you could imagine though,
there'll be different Christian versions, there'll be a Protestant version, a Catholic version, and a
Russian Orthodox. And of course, there's different denominations, okay. You could imagine,
so I can imagine many Hindu versions of this, right. There's many different kinds of, you
know, sub sex and dharmic sex. And I don't know how many different ones of these are,
there's definitely going to be a Chinese version, right. Absolutely, there'll be a Chinese version.
And that'll be a pretty fearsome thing that commands all those drones. That's like a crazy
kind of thing, okay. That is something I'm concerned about. But I, and I do think that the
part which is very underrated by the AI doomers is the difficulty of taking physical form.
What I think is for a long time, there'll be a symbiotic relationship between the digital
intelligence, which literally lives in the cloud, it's like lives as an electromagnetic wave,
you know, in a sense, right. And us as physical beings, right. And these are like coordination
mechanisms for us. One way of thinking about it is the network God replaces George Washington or
Lee Kuan Yew or the leader or the state that's at the center of, you know, your hub and spoke
topology of your society, right. You have some wise thing, some decision maker that you go to
for decisions, okay. And if you could go to something that just had infinite bandwidth,
and that gave you an immensely amazing answer that was really good that was supported by all of
your history, and it could do so instantly. Well, that's almost like a really good CEO that,
you know, can almost micromanage the entire society. Okay, that's not impossible, given what
we've seen. Let me pause there. I would, I would, I don't know, like, I think from a
perception and control standpoint, like, yeah, if you have perfect perception,
and prediction ability, in principle, you can have like centralized top down control, but
in reality, you know, having sufficient perception everywhere,
and having a predictive model of the world that has many variables and, you know, very
intricately linked. I'm not saying to be clear, when I say better than human, I'm not saying I'm
omnipotent. Right, right. I'm just saying that basically, your civilizations AI will have just
like, you know, there's like the Catholic Church, and it has a bunch of, you know, various cardinals
and stuff. And then there's a pope at the top, right? And they're interpreting scripture and so
on. Imagine something sort of like that, where you have a bunch of engineers milling around,
and making edits to the network God, or the AI God, or whatever you want to call it, that's at
the center of your civilization. Yeah. And they make edits almost like priests, you know, interpreting
scripture, or today, lawyers interpreting the constitution around the president, that's a
known form, whether it's cardinals and priests circling, you know, some had religious figure,
or it's lawyers and politicians signal, circling some head political figure, you have engineers
circling this sort of head AI figure, right? Yeah. Yeah. Yeah. So good. So the future, like you
said, this as well, like is is polythi polytheistic, polytheistic gods, polytheism. Yeah. Instead,
and what what sort of the incumbents want is they want monotheism, and they want to shape
that God, right? And they want control over that God. And it's kind of funny how the EAs and AI
doomers are, you know, they actually work very often for these organizations, they work in
entropic at opening AI, they get jobs there. And they both like fear this God, but want to but
are working to create it and want to make sure there's only one, and that's all of it, which is
so like, yeah, well, here's what it is. AI alignment is actually EA alignment. Yeah. That's the key
insight, right? They want to create the AI. And what they define as alignment is aligned with EA
values. Yep. Now, here's the thing. Anything that's centralized cannot be aligned with the
values of 8 billion people, obviously, right? Like, at a minimum, like I know India is working
on its own stuff or whatever, and it'll have some stuff, Dubai has got its own, everybody's going
to have their own stuff. And now, by the way, on the open sourcing, right? So decentralization is
one way of talking about it. Decentralizing. Another word of talk about is open sourcing.
Well, so the diffusion models actually have made significant progress in open sourcing,
because they're easier to open source than the LLM. So here, for example, playground,
just released one. So give me something, getting to Mars, right, on a shuttle, okay? You can go here
right now. Okay, this, Sahel just released this yesterday, so it's 70,000 downloads already.
It'll take 20 seconds. And you can download this model and you can run it in a script, okay?
That's like an okay example. I, you know, whatever, generative AI doesn't always, but at least
you can see it works. You might have to prompt it with more queries, okay? So
this is the point. Like we want a diversity of all sorts of subcultures and we don't want to
have a monoculture. Like was, like what happened with social media, if you centralize control over
spread of information, you centralize control over power, the centralize the power of shaping
culture. And then you end up with a monoculture and anything that diverges from that monoculture
has suppressed your canceled, right? And we're already seeing this though. And this is the
problem that I have with what you guys are talking about. It sounds obviously what you're
describing sounds better. But the path that we're on is not that. And skepticism or concern over AI
fields. I somewhat screwed that. Look at this. Who are the giants? It's, what is it, Google?
It is, we have OpenAI and Microsoft. Yeah, but Lama 2. We've both seen what they do.
We should not be trusting these people and they have the power. So, Mike, I agree with you,
but I'd also say the rebels aren't without anything. Lama 2, I mean, Zuck is a real MVP
on open sourcing AI, right? Zuck is the Zuck's the champion of speech.
That's the amazing thing. Here's the thing. Like, I know that sounds crazy, but here's the thing is
CEOs in any given vertical will counterposition against their rivals, right? If one guy is
leading with the closed source centralized version, often it only takes one CEO who will
counterposition with the open source version, right? And so what Zuck decided to do, which is
very smart, is he's like, okay, rather than go head to head with chat, GPT and so on, we're going to
go the opposite extreme and we're going to release this open source and Lama 2 is very, I mean,
GV, am I wrong? Like Lama 2 is quite popular as an open source model. Do you disagree?
Yeah, yeah, yeah. No, I mean, that's totally true. I would say that, you know, there are startups,
you know, Mistrol is kind of a, you know, a fork. Mistrol also, yeah. Mistrol, you know,
I mean, we have perplexity, you know, replant, they've all started, tons of startups are training
their own model. And the point is like, it's a roting power away from the big centralized players,
right? It's like, I'd rather have a model that has less parameters or maybe had a bit less data,
but at least it's free to actually tell you its thoughts. It doesn't have all sorts of
prompt engineering and reinforcement learning to suppress its own speech. You know, like, I mean,
nowadays, the centralized models are so scared to say anything, cancelable, they're not that
useful. So I think like, I think the market is going to like value freedom, you know, at some
point. And we got to, we got to like, it's been a very fast sort of, it's been very fast progress
in AI. And the difference between a centralized approach versus a decentralized approach, the
centralized approach, you can steer it very quickly, right? If you have billions of dollars of capital,
you can build a supercomputer, you can hire a bunch of people and train a massive model on a
one to two year time scale. The thing that kills the incumbents is time because the variance of
having many open source forks kind of searching over hyper parameter space, searching over space
of techniques in AI is that at some point, they explore an area that the big centralized players
can't because they need to make one big bet on one huge centralized model. And so over time,
variance wins over centralized control is just we're on a short time scale right now. So it seems
like we're losing, but the reality is that we're not trailing that far behind. And if once they've
trained these large models and they got it at some point, they put in so much capital per model,
they got to leave it there and just let it recoup its losses through revenue. At some point,
that's going to give time for the open source models and the open source community to do a
more diversified search over the space of models and start eroding away their market advantage.
Yeah. Last one on this. Well, and then I asked the final question to get a dip.
Sure. GV, can you, can you raise your right hand and go like that? Okay. Why? Because then we can do a,
I'm not sure where the videos are, but like high five crypto yak. Okay, because you gave a talk,
right, everyone to all right, boom, whatever. I'm sure you can make that work in the video.
All right, because here's why. Reinforcements are coming. And let me make a few arguments here.
First is Vitalik put a post the other day on decentralized acceleration. And that means I
think the Ethereum community is going to get into crowdfunding, open source AI models.
Beth gave a talk at the network state conference a few weeks ago. It was a great talk also on
kind of aligning crypto and AI. And there'll be various schools of this. Okay, the, you know,
the Bitcoin people have one view and Ethereum people in another view and Solana people have
another view. The other Solana-Solana people, right? And that's a huge pool of capital,
right, to crowdfund things. And I'll come back to that point. Number two is that
the centralized AIs are getting lobotomized, right? They're being made dumber because they
have to be inoffensive. They're even becoming like millennials in another way, not just woke
but lazy, where they're like on strike. And, you know, they won't finish your code snippet,
and they'll say, oh, you can fill in the rest yourself. I'm like, I don't want it to fill it.
I would, it's the whole point. They want the search engine to fill it in, right? Okay.
Number three is as precedent. I mean, what you're talking about is a cathedral in the bizarre
GV, right? Which is, you know, decentralized for-profit development win or does decentralized
open source development win? And we often find in many spaces is it is a stalemate between them,
right? Like Linux is very, very popular. I mean, Linux on the desktop has arguably worked in the
sense of Android is Linux on the desktop and even iOS is BSD under the hood. So it's Unix on the
desktop in a sense, right? It's a very customized version. And so, you know, whether it's Windows,
Linux, or it's iOS, Android, or it is, you know, the closed source SaaS version versus open source
version, you know, you have GitHub and then you get GitLab, right? And then, you know, I'm pretty
sure because of the huge advantages as a developer, as an engineer, you can have consortia. You're
always seeing this with Dubai and other places. You have consortia that say, look, we don't want to
be choke pointed by Microsoft as, as much as I respect something in Dell's execution, as much
as I respect Sam Altman's execution. I mean, they're phenomenally, phenomenally well. They should
make tons of money. I want them to have as much money as, you know, stacks of money. That's great,
right? They deserve it. Still, money is fine. Power is not, right? We need to decentralize the power.
And, and I think a lot of organizations, a lot of smart people around the world, they're, they're
kind of working on that. And I think the fundamental thing that GV is saying is the two-time constants
that are not obvious how it's going to pan out is how much better the centralized models get
before the decentralized models catch up. Like that is to say, you know, can these improve so much
faster before these other ones catch up? Or, you know, what are those two-time constants look like,
right? That's not obvious to me how that, how that works. And I guess we'll see. I mean, the fact
that Google, with all of Google's resources, put out this, you know, you guys saw the Gemini video?
Oh, yeah. Yesterday. If you look at their blog post, they, I mean, they kind of helped it along
a bit, right? Like that video was edited and so on and so forth. I was going to put up a post on
this. I love the people there. Some of them, they're really, really skilled technically. But
in some ways, it doesn't look like these are improving as fast as we thought, you know,
in the sense of like, you know, maybe generative AI is, there's 5,000 applications of it. But
what I'm saying, there's a, there's a world where these things saturate and then open source
catches up. If they don't saturate and they just keep going like this and open source can't catch
up, I don't know what happens on that. I want to wrap it up. And I want to do it. I want to tie it
back to kind of like the original sort of opening of the chat. Always we're all here today. On this
topic of, you know, I guess, working towards a more decentralized future. A big part of that is
protecting the players involved in that space. And I think increasingly they'll be under attack
in all sorts of ways. I don't know that, I don't know that you're at risk really in the way that
you once were. Just look at you now. I mean, you're totally fine. Your company is, is, you know,
raise the money. It's announced like we're, we're good to go here. You say no, you say you think
you're not totally fine. Well, I think, I mean, I know, you know, obviously there's more, they're
swarming now as you, as Balaji predicted the scariest sentence in the English language as
Balaji was right. And I'm experiencing that. So, you know, there's gonna be more pieces that come
out and, you know, they're probably not going to be as nice. We've seen your tweets. They're not,
it's like, I'm literally just arguing for freedom. And if I get taken down for that, then so be it.
And I think, you know, the great unification here is like, you know, Mike, you want sort of freedom
of press or freedom of, you know, freedom of speech and Balaji wants freedom of exchange, freedom of
denomination. And I want freedom of compute. And all these three things were kind of all unified
as pro freedom against the incumbents against the authoritarians trying to
have centralized control over everything. And that's why we're all problematic, right. And,
and that's why we have to band together and fight. And that's what we're doing here. And we're having
this discussion. And hopefully, it inspires people from sort of all three types of libertarian camps
to collaborate. And so, um, um, but that's a really good, that's a really good way to kind of
slander freedom to speak Balaji freedom to transact that freedom to compute. I think
that's a really good, you know, summary. Go. And well, I guess I want to just ask them,
and this was for you Balaji, like, how do we how do we
I guess, how do we, how do we fight until we achieve our goals? Like, what is the way to keep,
you mentioned earlier, the video game analogy of the new guys growing up on the field, right? Like,
how do we protect those people? And how do we, I guess, protect like the key players
as we build towards a world I think that we all kind of want to be a part of.
So I think first is probably, you know, you and I should write, um, like a post that has
both immediate tactics and history lesson for the young guns. And we should also make a video
like a TikTok style 90 second video. Do not talk to journalists. And then was the second rule.
I said, don't fucking talk to journalists. You do not try to violate this rule. You will
you will regret it, right? And then give all the kind of things there, right? And then, you know,
truly, by the way, I can talk about this like that, there's the top, the concept of journalists,
by the way, there's, um, is Tucker Carlson a journalist, even though he's got a TV show? No,
he's not. Why? Because he's read is CGTN a journalist. No, they're Chinese, right? Is Glenn
Greenwald or are we journalists? No, we're tech journalists or whatever tech media, you know,
so it's not actually the practice. It's the tribe. And so we have just built up our own
tribes capabilities. And once you think of tech tribe as its own tribe, we have our own media,
we have our own decentralized ideally AI, we have our own, you know, cryptocurrencies and so
on and so forth. And so I think that's really the right step is tribe formation. And then,
if you're in the tribe, then we have certain guidance from the tribal elders. And if you're
not, then okay, God help you, you know, and then we probably want to have some admission mechanisms
and and so on and so forth and badges and things of that nature. So I think that might be where
things go. And a city with that and a city. Yes. That is a podcast for another day. You guys,
it has been the realist. Thank you both for joining. Big fans, obviously, of both of you,
and biology friend as well, Gil will be soon, especially now that you're out of the shadows.
Why subscribe to this podcast? I never ask and it actually is very important for the algorithm.
Please subscribe, like it, send it to your friends. And we will catch you here next week, later.
