Imagine if your phone could see for you. This could be really useful in low visibility situations,
but more than anything, it should be useful for people who are blind. This should be possible
because smartphones and tablets have some pretty incredible sensors in them. They know where they
are in space and what's around them. If you could somehow communicate what the phone is seeing
with an interface that doesn't require a screen, something you can touch or hear,
it could actually be a pretty good replacement set of eyes. I've been thinking if I could do that,
it might actually be useful invention in contrast to a lot of the stuff I make.
It took me a few tries, but I did eventually get a system working. This iPad is running an app that
I wrote, which is talking to a kind of unusual case for it. And what it does is it's communicating
what it sees into my hand through a tactile interface right here. This allows me to walk
around blindfolded and not hit things. I think if I refined it a little bit more, it could be
a Braille display. It doesn't have enough resolution to do that right now, but there's no reason it
couldn't, I don't think. So inside of this, there's a pretty cool mechanism, which I'll show you.
I also spent way too much engineering time trying to prank my wife. She's kind of on
red alert now, so I had to come up with a complicated scheme to get her rate where I wanted her.
So as usual, this project was a lot harder than I was thinking that it was going to be.
Yeah, because you did it the hard way. If you just would have used a bunch of motors,
like I said, it would have been a whole lot easier that way. No, what we should have done
is made an entirely new actuator from scratch. I'm telling you, night and all is the future.
All right, all right. So I did have a lot of internal debate on the best way to build this thing.
There's actually several different, all good ways to build this. I went with this approach
because I thought it was the most interesting. There's a really cool mechanism inside of here.
I also want to thank San Juan Steve for nerd sniping me with this idea and the comments
from my last video. Also, thank you for having a name that is WorkSafe San Juan Steve. This totally
distracted me from the project I was working on, which is making myself better at playing this violin
with the help of some robotics. It may still be on hold because I have a couple of other really
interesting projects that are competing for my attention. So I've been thinking a lot about
guided missiles and if there might be any kind of constructive uses for them. And I finally think
I have it. So imagine building the Iron Man gauntlet that flies like a rocket onto Tony Stark's hand.
I've been thinking about this problem. It definitely is dangerous, but I think it might be borderline
possible. That would be really cool. I'm also really interested in the idea of a baseball bat
that doubles or triples the power of my swing with the assistance of a very modest explosive
charge. I think I have a legal and interesting way to do that as well. If any of those things sound
cool, you should subscribe. I give you my word that I will build some all or none of those things.
I promise. Oh yeah. And I did finally set up a Patreon. If you want to help support me making
more awesome things and videos, this is a great way to do that. These videos do typically take
more than 100 hours each and also quite a bit of money and material and tooling and other things.
In exchange, I'll be giving you more behind the scenes info and in-depth project stuff. So if
that's interesting, there's a link in the description. All right, back to the project. I calculate
that this thing gives me roughly 20-1200 vision. Not the best, but it's better than nothing.
What 20-1200 vision means is that if I look at something with this, that's 20 feet away, it
will look as clear as it would look to someone if I took that thing and moved it 1200 feet away.
Going into this project, I really wasn't sure how I was going to do the sensing.
I was looking at using sonar sensors and off-the-shelf LiDAR unit. I was strongly
considering using the Kinect, but seriously, where are you going to put this thing? Are you
going to ask someone to just wear this on their head? You look like a complete idiot. Think about
how people would treat you if you walked down the street with this on your head. The goal of this
project is maybe something that could help humanity not hurt it. And I then remembered
that the new iPad has a LiDAR in it, which is awesome. The only problem is that it's only the
latest iPad that has the LiDAR in it and I don't have one. And if you really think about it, I
don't have a choice here. I have to get this. It's to help humanity. Really? Humanity? It's
going to help blind people. Let's think about it. Fine. LiDAR is one of those things that if it didn't
exist and you proposed it to me as an engineer, I would lap you out of the room. It just does not
seem like it should exist. It's kind of like ball screws where if you look at how they work,
it still seems like magic. LiDAR is crazy because it measures the time that it takes light to travel
from the iPad to an object, reflect off it, and then come back. And this is crazy because light is
mind-bogglingly fast. It's going around 670 million miles per hour. Unless it's light in the EU or
Canada, in which case it's going about a billion kilometers per hour. So the time that it takes
to go from the iPad to a wall is on the order of 5 nanoseconds. And to actually measure distance,
you have to measure much more precisely than this. The LiDAR is actually sending out beams of light
in all directions. It gives you a bunch of measurements on the surface of everything
that it sees and how far away it is from the iPad. So this is an incredibly powerful technique for
perceiving the world. It's how most self-driving cars actually figure out what's around them.
The other big architectural question I had to figure out is how do I communicate what the
thing is seeing using touch? The proposal in the comments was to use some kind of vest, but my
limited experience with nerves and humans is that your torso isn't actually very good at sensing.
So we're going to do a two-point discrimination test. Tell me if you feel one or two touches.
One. It's so funny. I'm like jabbing you with two screwdrivers. I know it's just how your body
works, but it's really kind of funny. All right, now turn around so I can test the front.
That's probably not such a good idea, is it? Your back isn't so great for tactile input,
but your hands are incredible. Not only do they have good resolutions, they can distinguish lots
of touches. They also are extremely sensitive. If this device could be a phone case, I think
that's legitimately more useful. A vest, you have to wear it and have all these sensors, whereas
your phone, you just have your phone, and it helps you see. So let's imagine that the iPad is seeing
this. It's a room with a door and a chair. What I do is I convert this into the simplest
representation possible for navigating the space. Right here, there's something that you don't want
to hit. That's very close. That's the chair. I have some stuff that's further. That's the walls,
and then everywhere else is clear. I can actually communicate this in your hand because
there's not so much information. If something is really close, I push really hard on your fingers
at those corresponding locations. If something is there but not as close, I can push not as hard.
Where it's clear, I don't push at all. This gives me basically a course map of what's going on in
the world on my hand. So I also made a couple different views. So if you want to zoom in and get
more detail, I have the ability to zoom. I also have an experimental top-down view. So this is the
chair, this is the wall, looking down from above. I can say that this is no go. This is open,
and these areas are unknown because I can't see through the walls with the lidar. Remember,
I'm looking from this perspective, so I can only see what I can see through the doorway. I can
communicate this to the hand the same way I do the other view. It's just a different view of the room.
This view is kind of like the little mini-map in a first-person shooter in the bottom of the screen,
if you know what I'm talking about. I think this could be a pretty nice view with more improvement,
but this problem of things blocking other things happens a lot in practice, and so it can be really
difficult to interpret what you're looking at. To make this work, I had to find a way to poke all
of my fingers simultaneously with a controllable amount of poke, and that's hard because I would
like this to be an iPhone case, and that means I really, this is about as big as I can go, kind
of a grip shape. So if I just try to do the simple thing and cram a bunch of servo motors in here,
attach to each pin, there's just no way that's going to fit, especially if I try to scale it up
so that it can be a Braille display, which I think is important and very useful. So the big
challenge for this project was finding a way to move all those pins with a compact and ideally
simple system. So what I wanted to do is make something that had a little metal pin that I
could push into every joint of every finger, and the way that I did this, imagine that I have one
of the pins that I want to move pressed against a cylinder that I can rotate. If I attach a little
wedge to this cylinder when it goes underneath this pin, it's going to force it up. Then if I make an
even bigger wedge and I move my cylinder over, I can spin the cylinder and then push this pin
up even higher. All that I have to be able to do is rotate the cylinder and shift it left and right
to control how high up this pin goes. And then because it's a cylinder, I can pack lots of ramps
and lots of pins into it very compactly. Here's what some well used ramps look like, IRL. That big
bump next to them is used to trigger the pin locking and unlocking mechanism. It's basically
another ramp and this keeps the pins in place when they're not under a ramp. And then you can see that
I can control where the cylinder goes with two opposing motors. By driving them together,
it rotates and by driving only one of them, I can move it left and right. Planning the
motor moves for this system is a lot harder than I expected, mostly because I wanted to move one
motor at a continuous speed and then have the other one keeping pace. It was a lot of quadratic
equations. And now the pain and joy of making this in 60 seconds or less.
Ah, why?
This is the electronics and the only thing that really mattered for proving the system is that
they work. So I made zero attempts at miniaturizing them and they're very simple. They're just a
microcontroller Bluetooth communication module and then two big fat stepper motor drivers.
If I was trying to make this a real product, I'd be trying to fit it onto a little circuit board,
which there's no reason it couldn't. This is just what I had on hand. I should also point out that
these motors are massively overkill for the application. It doesn't take much power to raise
a little pin. I went with these partially because they're what I had on hand and also because
it's convenient to have a lot of extra power when you're prototyping, now we don't worry about
stalling and other stuff. It's been almost a decade since I last wrote an iPad app and it's
gotten a lot easier. And this is the app. It's really quite simple. I have all the controls on
the side for the different views and for zooming and these are all accessible when you're holding
the grip on the side. There's a little preview of the depth data and this just helps me see what's
going on. Ideally this would be running on a phone but the lidar is only in the iPad. If Apple puts
the lidar on the iPhone, you could imagine it could just be a phone with a little case on it,
which would be really cool. That's pretty much all there is to this app. Apple makes it really
easy to work with the lidar data. I spent a lot more time on the embedded system trying to get
the motor profiles working and it was kind of wasted time but I spent probably more time trying to
get wife mode working than anything else in this app. I really wanted to see my wife walk into something
so I set it up to initially tell her correct data then after a bit start giving her bad data.
So it was clear. Probably just a bug. It's a complicated system. This thing is really weird
to use. It's a lot less intuitive than I was thinking it would be. You can feel all the pokes
but I think about every finger and what it's feeling to try to create a mental image of
what's in front of me. Although I do think that if you used it a lot it it might become second
nature. I remember learning the type was pretty similar to this. It also lets you see things like
overhead obstructions so you can get under them although it's since it's only giving two levels
of depth it was hard for me to figure out where the obstruction actually was so and you can see
me pointing the iPad up to see if there's anything above me. I would really like to see more touch
points and more control of those touch points because you really can feel the difference between
these different pin pressures. I think you could get a much nicer picture of what's around you if
they could push with more granularity. If I was doing another revision or trying to make this
as a product I would be trying to find some little tiny actuator that I could buy that would allow
me to directly control every pin. I think it's a cool proof of concept and hopefully you like it as
well. So a lot of people have pointed out that I have a lot of tools and that I may in fact even
have a problem which is probably true but I would have an even bigger problem if all my tools got
stolen. Though I do spend a lot less time worrying thanks to this video sponsor SimplySafe. I spent
most of my adult life and my adult dollars building out this shop and the idea of someone
busting in and stealing my tools makes me want to curl up and die. Although let's be real if someone
manages to steal this they can have it. I'm only joking that it's not a challenge please
don't rob me. Although if you do try to rob me you're busted because SimplySafe detects basically
every possible intrusion and calls the police immediately. You're gonna kick down my door
you just triggered my entrance sensor. You're gonna break my window you just triggered my
glass break sensor. You're gonna cut a hole through my wall say hello to my motion sensor.
Then wave to me and the police dispatch on my HD security camera. You're gonna try to break in
when the system's disarmed boom got a panic button. SimplySafe protects against outsiders but it also
protects against me and honestly with all the stuff I get up to I'm probably the biggest danger
here. I've got a fire alarm in fact so I leave a smoldering heap in the basement that catches fire
once I'm gone I'm gonna get notified. I've got a carbon monoxide sensor. If I leave my jet engine
running and it makes a bunch of carbon monoxide it's gonna let me know before it kills me. The
number one thing for me though is the automatic deadbolt. The number of times I've come back to
see if the shop is actually locked is way too high. You get notified if you forget to lock the door
you can lock it remotely you can check it super handy. So if I was gonna rob your house the first
thing I'd do is I'd cut your power and your telephone. Although if you had SimplySafe I'd be
a fool because it has a battery backup and uses cell service. It's super reliable. So you just
order it online or over the phone and they ship it straight to your house. You stick the sensors
wherever you want them and hit a few buttons and that's about it. It doesn't even take an hour.
And it's only 50 cents a day with no contract. That's cheaper than my previous security system
which had a contract. So have a lot more peace of mind with SimplySafe knowing that you're protected
around the clock from basically anything you can think of. Visit simplysafe.com slash stuff
made here to learn more or click the link in the description.
