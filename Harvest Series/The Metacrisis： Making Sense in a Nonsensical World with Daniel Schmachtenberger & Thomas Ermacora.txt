I just want to say thank you for this welcome again from the team at Harvest.
It's great for me to have been able to suggest Daniel as a speaker here, very fond of him
as a human, as a fellow futurist and as a thinker for our time.
I think it probably needs a little introduction. Why is Daniel here?
Daniel is not a prophet of doom, absolutely not.
He's trying to equip us with the understanding that will help us navigate some of the crises that are ahead of us
and something that some people call the metacrisis and he's one of the main people in the world now who can explain it very clearly.
I'll try and break it up a little bit so that we can go over some of the points again.
It's difficult to sort of say what Consilience Project is in a few words because it has evolved over time
to sort of confront the reality of what the world is ready to accept.
However, it's certainly one of, in my opinion, the best attempts and very tangible attempts to help people navigate what's right now in front of us.
And the news cycle is certainly not helping us understand.
It's sort of distracting our minds from the real things that are going on.
And so Daniel is one of these people out there who's working really to formalize the way that we can anticipate, connect, collaborate
and work more effectively to solve problems that we are facing.
So Daniel, I think there's something that we should know about your past and I'm going to be provocative.
You didn't actually start out with the same objective.
You sort of thought that maybe we were doomed and that we had to accelerate doom in order to get somewhere.
I'm going to be very provocative so that you can explain your journey from a young man to where you are now.
I was homeschooled and when I was nine, I was at a gas station and a factory farming cattle truck pulled up.
And so I went and looked inside the holes. The cow nearest to me was missing its eye and bleeding.
All the cows were in terrible condition.
And I grew up loving animals, eating meat from factory farms, not putting the two together.
And I was just kind of shocked and horrified by that.
I asked my parents about it. They said that's where animals come from.
So I asked to go to a factory farm.
And I became a vegetarian that day, started working with PETA and Greenpeace and studying animal rights work.
That took me from the issue of factory farming to the issue of species extinction, whaling, overfishing the oceans,
which took me into the issues of the environment.
And that took me into global poverty and just kind of the whole set of issues as a young person.
I was fortunate being homeschooled that I got to just have that be my curriculum.
I was actually an educational experiment my parents ran. I didn't have any fixed curriculum.
I just got a study that I was interested in.
So this became the context of most of my life study.
And the next really important part happened.
I was 13. I was working on a project that Greenpeace and World Wildlife Federation were leading to protect elephant poaching
in a particular elephant preserve in Kenya where the poachers had come in over the preserve and hunted a bunch of elephants.
I saw the videos of the elephant slaughter and was moved in the same way as the factory farms.
And the thing I observed though was over the two years of the people on the ground working extremely hard to protect the elephants there,
the strategy was get bigger fences around the preserve so the poachers couldn't get in
and do legislation to get harsher sentencing for poachers in the area.
All the activists had their life threatened but they finally succeeded.
It was a huge win. Those elephants didn't get hunted.
But they didn't address the poverty of the people that were doing the poaching.
They didn't address a macro economy that creates poverty at scale.
They didn't address the views towards animals or identity regarding them or black markets on animal parts.
So the same poaching groups moved to hunt other things which happened to be the white rhino and the mountain gorilla,
both of which were more endangered than the elephant.
And I was working with enough groups that I got to see those other issues get worse as a direct result of the success of that project.
And then that was like the second existential hit.
The first existential hit with the factory farms was, I'm saying this to relate,
that was the first time I had like a suicidal ideation around not feeling okay being complicit with my species.
That my species was somehow fundamentally fucked up.
But as a kid, it wasn't that hard to realize if I kill myself all those cows are still in the factory farms.
They didn't help them. That's unethical.
But then I'm like, if I stay alive to try to help it, can my life be a success
while sentient beings are experiencing that much suffering?
What does it say about me that I can be totally stoked that my life is a success
when other beings are in that kind of suffering?
And I'm like, there's no answer for me that doesn't address that.
So I remember thinking to myself then, I'm like, all right, well, if I die and factory farms still exist,
I failed like there is no definition of success for me that isn't a sociopath's definition of success.
It has to empathetically separate too intensely.
But at least the hope came that like activism might work.
And so then when this thing happened where I saw that the activism for one thing made other things worse,
that was the next kind of devastation.
And that led to me starting to look at how many other places where we were doing activism,
where the world was doing activism, did that kind of issue.
And I saw that there were projects to solve global poverty by creating hydroelectric dams
to bring electricity to areas and hydroelectric dams.
Of course, drowned whole ecosystems and extinct species and on and on.
And kind of like it seemed like the world was caught in these trade-offs
where when they would focus on solving one problem, it was too narrowly defined.
The result of solving that problem would have externalities that related with larger systems.
I started to do kind of historical analysis on that.
And that became kind of a defining trend of all of the issues.
We created the automobile to solve a transportation issue,
which was that horses were a very limited means of transportation.
Horses in the cities caused a lot of horseshit in places like London.
Literally the excessive horseshit in the cities of London
was one of the kind of like significant impetuses to make a horseless carriage.
And in solving that problem and creating transportation that increased mobility
and comfort for the whole world, climate change,
like the venusification of the entire planet and oil spills
and wars over oil and the US petrodollar,
like all of that were the side effects of solving a transportation issue,
you know, a couple hundred years later.
And I got to see that there was this underlying deep issue
that statecraft that is thinking about the well-being of its own citizens,
the rest of the world, so it's not just exporting its harm somewhere else and of the planet.
And there's a lot of countries where they're genie coefficient,
meaning their measure of wealth inequality is pretty good within their country,
but they import a bunch of stuff to make their country function
from countries that have the worst genie coefficient.
So you can't actually do genie coefficients at the level of a country.
It ends up just being a way to kind of whitewash the reality of global supply chains.
Oh, so the conscious statecraft thing.
So how do you do what is good for your own country,
what's good for other countries, and what's good for the planet
when there are fundamental trade-offs between them and you're stuck in those trade-offs?
That becomes really the deep challenging question.
If we look at climate change today, we can see that for the planet
and for all of us in the future, we should not just decarbonize but degrowth.
We can also see that any nation that tries to lead that will do worse GDP-wise in the near term,
which means worse geopolitically and actually so much worse,
particularly for the leading countries like U.S. and China,
change the control systems of the world.
So many of the people in the U.S. that are anti-climate change
aren't actually anti-climate change because they did a good analysis of the IPCC science.
It's that the solution of increasing the price of carbon for us,
which will decrease our GDP relative to China's GDP in a great power game,
which will increase planetary autocracy, seems like such a bad solution
that they don't want the climate change assessment because they don't want the solution that goes with it.
So a part of the thing that I focus on is how do we understand
the interconnectivity and the generators of all the issues deeply enough
that we can come up with solutions that don't cause other problems?
But one point was a little while after this I had come to...
I started doing forecasting on how many people have read Limits of Growth,
the MIT Club of Rome book.
So I read that as a teenager and then started looking at a lot of other analyses
on species extinction and biodiversity loss and dead zones and oceans and all those things.
And then I looked at the Stephen Pinker kind of stuff of everything's getting better.
A lot of people might have that question of like,
you hear Stephen Pinker, Hans Rosling Gates and like everything's getting better
and then you hear all the environmental statistics and like everything's getting worse.
They're both true. You can cherry pick your stats, but they're not equally true.
The things that are getting worse are leading to the unviability of human habitation ongoingly
in a way that the things that are getting better don't converge on solving automatically.
So there's a real... And the things that we're making better are causing the things
that are getting worse towards self-extinction points, right?
Like grow global GDP where we all have like nice stuff because of that
in a way that breaks the biosphere's capacity to continue to make life possible.
So we have to do something deeper than saying it's getting better and worse so we just choose.
It's like the way that we make things get better is a major part of what's making them get worse
towards tipping points that are unique now to any point in previous civilization.
So when I was at 15, I came to the assessment that there was no chance
that humanity would actually make it in time and that if we had radically less population
we might have a chance and I started studying viruses and depopulation strategies
which is a thing that an angsty but earnest caring teenager might do.
I had a spiritual experience that took me off that path while I was working on it
but I was seriously studying vector delivery of novel pathogens
and the spiritual experience was something Bucky Fuller used to say
and I had heard it a lot but it hadn't hit me in the same way
that the chicken developing inside of a shell is totally unsustainable, right?
It's eating the unrenewable resource, the egg white.
It's creating metabolic pollution in its environment.
It doesn't even know that it's inside of a shell but it's in a developmental phase
and of course it doesn't have the beak or the gastrointestinal tract to eat seeds yet.
The whites are exactly what it developmentally needs to go through that embryonic phase
and right as it runs out of whites, as soon as it's GI tract and beak
and all the things are developed to be able to crack through the shell
and emerge into a world where now it's part of a new phase
and I started thinking about humanity as being unrenewable
because of being in a developmental phase where a discrete phase shift
that isn't the result of just a continuity of the previous lines
and I thought about all the examples of caterpillar to chrysalis to butterfly
and that in the chrysalis there's a fundamental dissolution of all the organs
and a restructuring with a different genetic code
that if a fetus went more than 40 weeks in the mother's uterus
it would kill itself and kill the mom but it has to go through that developmental period
and then the birth is a discrete kind of difficult process
and then the umbilical cords cut and now there's a new developmental time
and so I had this kind of profound experience that developmental phases
whether inside of an egg or in a chrysalis or in a womb are always unsustainable
there is some discrete nonlinear phase shift that is different
than the curve in the developmental phase and will be different afterwards
and I started thinking about if humanity as a species was in a developmental phase
and there was a discrete phase shift that was different than the curves
what that might look like but that got me off of the track that Thomas was bringing up
but what's really interesting is a lot of my work now involves the way that exponential technology
equals exponential decentralized catastrophe weapons for everyone
whenever we talk about the positives of exponential tech
AI, biotechnology, nanotechnology, cyber technology
we talk about in positive terms usually like the democratization of this great technological power of creation
but the democratization of catastrophe weapons is actually not a great idea
like keeping nukes to the G8 you can do because it's really hard to make nukes
and you can see who's making nukes and there's not that many places that have uranium
and enriching uranium is hard and you can see it from outer space
but it's pretty easy to make drone weapons
and it's increasingly becoming easy and the ability to use those for infrastructure targets
and specifically it's becoming pretty easy to make pathogens
in the advancing of synthetic biology we're only a few years away from the ability to synthesize novel pathogens on a desktop for a thousand dollars anywhere
and so when I was a kid that was not true it was actually like a hard thing to do
it's becoming an increasingly easy thing to do while increasingly more people are feeling kind of concerned and disenfranchised
so as the group of people that would be motivated to change this world system in harmful ways
and the group of people that are capable is converging and increasing
there's a lot of risk associated with that, how do we deal with that?
that's an interesting part of the topic
I'm really excited that you didn't turn out to become a terrorist
it wasn't motivated by not liking people
it was motivated by seeing self-induced human extinction as inevitable
and as being the only way out
and that's actually like most terrorists are well motivated
they're motivated in service of something they care about that they feel is being harmed and they don't know other solutions
we could agree but I'll pause on that one
I think what a lot of people here are probably expecting if you have heard anything about Daniel
is you present a little bit about the meta crisis
there's a framework of thinking around how we can put dots in between a lot of the crises that we're facing collectively
and instead of addressing one and creating externalities in another problem set
perhaps understanding the total problem set at the same time
and before you act actually you have a more enlightened perspective
gives you more edge
so that's an assumption and a hopeful one
and some people might argue that we need to act very fast on certain issues
so they don't really like this sort of temporisation of it
but I'm of the belief like you that basically having better tools to understand the world we live in
is essential for us to make critical decisions
and I would love for you to spend a moment unfolding what you call or what we call the meta crisis
and why it's unique to this moment in history
and why humanity has to put some effort towards solving that concretely
or we will probably end up in a pretty bad place very quickly
so it could easily seem like the stuff that I'm talking about is just the collection of all the worst news in one place
I would bother sharing it because I think it is true
the risks that we're talking about are true
it's not determined that we definitely fail at them or that we definitely succeeded them
so what we do actually matters in determining it
and there's no chance that we can solve it if we don't more competently understand it
so more people competently understanding
and seriously working to apply themselves to the unique needs of this particular time in the world
is something that I'm hopeful for
and I guess that's why I'm speaking here and said yes to Thomas inviting me here
so the meta crisis frame might actually help deal with some catastrophe fatigue
because rather than see the issue of drones and autonomous weapons
and the issue of exponential tech empowered terrorism
and this planetary boundary issue and this pollinator issue
and this forever chemical issue is separate issues
I look at them all as expressions of an interconnected set of generative dynamics
that we call the meta crisis
where what it takes to solve any of them is the same actually
and if you try to solve them without factoring these deep underlying generative dynamics
you will at bet, you probably won't solve it
and if you do you'll displace problems somewhere else and actually kind of mess the whole thing up
so when you understand that all those problems are connected at first
it makes it seem more overwhelming because you're like fuck to think about climate change
I also have to think about geopolitics and fundamental changes to finance
and all these other issues and that seems like a lot of complexity
but it actually takes it from too many problems to tractably manage
all of which have solutions that end up externalizing harm elsewhere
which means impossible to hard but tractable
so hopefully in terms of being able to see it all as one interconnected set of issues
you're like alright there's a lot more learning that I need to do
to be able to competently engage but there is actually a way through
there's actually kind of a tractable analysis
so that's what I hope to share
so if you can move towards what people call the third attractor
or that you like to call the third attractor
so that we sort of gravitate towards a landscape of defining
what is the solution environment that we want to find ourselves in
because obviously there are a lot of people who are very competent
who are deploying intelligence and capital
and being very innovative about what they do
but they sometimes miss the fact that they are creating
really negative externalities in other let's say problem sets
so the third attractor to me seems like a very easy thing to understand for people
even though if we don't have the answer to what the third attractor is
but it's at least theoretically a framework for understanding
why the metacrisis may find a solution set through a third attractor
Yeah, let me give an example though of how we solve problems
and make worse problems that are current and really relevant
we're working to try to change currently US federal government program
and have had some really good success with it for pandemic prevention
for preventing whatever the next pandemic from animal sources do not expel over would be
and the federal government and it's not only the US
lots of countries employ this approach the US has been leading the way
in what seems like great science and technology and innovation
towards preemptive problem solving which all seems like the right thing
but the approach to preventing zoonotic spillover involves viral hunting
so going out and finding tens of thousands of new viruses in back caves
that have mammalian viruses that have never been exposed to humans before
bringing them back to labs doing gain of function research on them
to figure out how they might mutate into things that are more virulent or transmissible
and then publishing all those genome sequences to an open source database
so everyone who wants to work on vaccines has access to the knowledge
it seems like a decentralizing information democratizing multi-state coordination
science anticipatory good thing and it's maybe one of the worst things happening in the world
and so we're lucky that we've been able to shift it
if you open source publish all of the pandemic grade viral gene sequences
in an age where gene synthesis is becoming extremely cheap
that we're about three years out from tabletop gene drives and CRISPR and like that
the bioterrorism potential of that is just unimaginable
and even just the accidental kind of lab leak dynamics
that when you have enough labs working with enough things
the probability that none of them happens drops towards zero over enough period of time
there was a lab doing gain of function research that figured out how to make
an extremely virulent version of H1N1 like an R0 of 18
H1N1 is like a 60% fatality rate and it did that in a biosecurity level 2 lab
so lab leaks happen right like this is an example of trying to do the right thing
but not understanding the problem space well enough
and doing something totally that's the wrong thing
and what I remember the first time I was engaged in the UN network
it was a project with World Food Program and I was 20
the solution to world hunger involved bringing conventional NPK based agriculture
to the developing world so we didn't have to send food over there
and the answer was way more nitrogen and phosphorus affluent into the rivers
it would cause faster dead zones in the ocean
and so I talked to the guy about it and I said
you realize you'll speed up the rate of dead zones in the ocean catastrophically
if you do this and he said I hadn't thought of that
but those aren't the metrics I'm tasked with
and those aren't the metrics I'm tasked with
so I'm gonna for a few years decrease hunger
while working to extinct the planet
because that's what my accountability is like
it just became very clear that that problem-solving approach was ubiquitous
and so another great example is you look at the advancement of something like gene editing, CRISPR
it's being advanced for purposes we all want like immuno-oncology
how do you change 15,000 genes at once to be able to cure and prevent cancers
that were genetically predisposed to
but all technologies are dual purpose or multi-purpose
meaning every technology that you can make for some positive purpose
has a military or otherwise weaponizer kind of externalizing application
so the research that's being done on how to do that type of gene editing
is making it then really cheap and easy
once we figured out how to do it
it takes major universities that have ethical review boards to do it for that purpose
to develop the technologies that then drop the price by orders of magnitude
to do it for any purpose and it's open publishing
so to give a little bit of history
because some people might think
well people have been predicting rapture since the 1600s
there's always some kind of like Mayan 2012 whatever
and this is just new catastrophism
I would really like people to think more deeply about what is discontinuous
and novel in this time relative to other times
so I want to argue that real quick
the first technology we had that was powerful enough for humans
to actually make the planet meaningfully uninhabitable
was the nuclear bomb in World War II
that was the first truly existential technology
it was not an exponential technology
meaning nukes don't automatically make better nukes
in the ways that computers automatically make better computers
computation allows us to design better computer chips recursively
you get Moore's law
but it was the first existential technology
and that was really a break from the history of the entire world of tech
up until that point
because up until that point every new military tech that we had
there was an absolute arms race to deploy it as quickly as we could
and to win more battles and territory based on deploying it
this was the first one where we actually had to make an entire world system
to ensure we would never deploy it
because nobody would win mutually assured destruction
and all of a sudden you're like whoa we're so big
that we can't actually deploy our tech without destroying everything
we can't actually do the us versus them effectively anymore at that level
and so post World War II
and we haven't had another World War that is kinetic between superpowers yet
and we're at the brink of it right now
post World War II because of that tech
we rebuilt the entire global world system
to deal with
preventing kinetic World War III
and that kind of Bretton Woods
world system, IGO world system has been effective at preventing World War III
but that world system is almost totally broken down now
and it drove all of the catastrophic risks we're facing currently
so specifically one part of the post World War II system was
a international monetary system
that created, that had exponential growth of GDP
why is exponential growth of GDP important
is because the wars are based on everybody wanting more stuff
if you don't have exponential growth of GDP
the best way to get more stuff is to take somebody else's stuff
if you have exponential growth of stuff
everybody can have more stuff without taking other stuff roughly
or at least the major nations don't have to take each other stuff
they can do it through colonialism or vassal nations
but exponential growth of GDP is comprehensively bad for the environment
like all of that growth of GDP equaled
there's an important thing called the Garrett relation
that shows a one for one correlation between energy used
and global GDP
global energy use and global GDP
it's a 99% correlation actually
meaning that the increases in efficiency of energy generation
only give you about 1% change of more dollars per joule per year
but for the most part
exponential growth of GDP equals exponential energy demand
so climate change and exponential GDP are exactly correlated
and all of that money gets used in a materials economy
a supply chain
it's a linear materials economy that through mining, logging, fishing, etc
is unrenewably taking stuff from the earth on one side
turning it into shit we use for a little while
and making it into trash and pollution on the other side
you cannot run
this is like so obvious
but you cannot run an exponential financial system
on a linear materials economy
that has to be coupled to it on a finite planet forever
so you start to hit planetary boundaries, right?
so what decreased us having likelihood for war
moved us towards planetary boundaries on all the planetary boundaries
we said we can all have more stuff without taking each other's stuff
by taking all the shit from nature as quickly as we can
so this was obviously not that smart for our own long term
and now we're there where we're actually bypassing
some of the planetary boundaries critical tipping points already
there was a paper published a couple months ago
in the American chemical society journal
that said the planetary tipping point
on certain environmental pollutants
particularly floral surfactants had already been passed
meaning rainwater all around the world
and very remote areas contain these PFOS forever chemicals
beyond EPA safe levels
that means that if you're gathering rainwater
in the middle of nowhere for your off-grid sustainable thing
it has beyond EPA levels of carcinogen, neurotoxin,
endocrine, disrupting chemicals everywhere
no matter where you are on the planet
because we've put that many of them into the environment already
and an exponential financial system
means an exponential amount of pollution, mining, etc
and so the metacrisis
what happened for me was like alright
well if we have to address factory farms
but then shit we also have to address overfishing
we have to address what is the problem set
what is the actual problem set that we have to face
how do we make sure that when we're addressing it
we don't cause other worst problems
so how do we understand the interconnectedness
I was always asking if we were to actually try to rebuild
the world from scratch with 21st century problems
and technologies and capacities
that actually worked with the biosphere and human nature
how would we do it and then what does enactment look like
to get there given all the vested interests
and issues in the current world system
so you were mentioning third attractor
third attractor roughly is
there are two futures that we want to avoid
well mention the first and the second first
so that people can understand the sort of negative image of it
but maybe just before you go there
just maybe explain what you really think
if there's a takeaway
what's absolutely different about this moment in history
for mankind
you've kind of said it in a roundabout way
which is explaining the sort of crumbling of the Bretton word
Bretton word's world system
and you know that a lot of the solutions
that we're trying to put forward
actually generate bigger problems
than we can possibly face
and in many instances
and you can talk about in the situation of the arms race
between China and the US with AI
or biotech for example
without even talk about road actors that are in garages
but I think if you can sort of
map this a little bit
I think that it's helpful for people to see
their place in history
okay so I was saying that the first existential tech
was the bomb
we built a world system to deal with that
so one of the answers to that world system
was the global financial system
which has driven us to
all of the planetary boundaries that we currently face
planetary boundary is a good way to put all the environmental issues in one place
so when we're talking about dead zones and oceans
overfishing, species extinction, loss of pollinators
climate change, ozone
all of those are basically places where the human
social sphere, techno sphere complex
is incompatible with the biosphere
but that means we're debasing the substrate that we depend upon
that means it's a system that's self-terminating
you cannot debase your own substrate forever
one of the other parts of the post-World War II system
was globalization
and these radically interconnected
six continent global supply chains
that are necessary to make this microphone
for all of the others or anything
one of the downsides of that we've seen during COVID
is the radically interconnected supply chain
the benefit was you're less likely to bomb somebody who you depend upon
for fundamental supply chain purposes
this is one of the big benefits of globalism
so the localism movement
if you were really successful at localism
there's actually less investedness in the other guy over there
when I don't actually depend upon them
so these are some of the tensions we have to factor of
okay, do I want to make everything local
or do we want to actually have interdependence on them
but if we have it all global then we get these cascading fragilities
of where you can have an issue in Wuhan
and get supply chain shutting down all around the world
which then means you don't get the movement of pesticides
and fertilizers for the agricultural system
in Iran and Northern Africa that probably put more people into
radical food insecurity than we're totally at risk from COVID
and it's like, so you can see how the
those post-World War II situations
gave us this world of high interconnectedness
but very high fragility
and then high planetary fragility
and then also the exponential financial system
meant the growth of exponential technology
you know, speeding up commerce
and the key thing to understand about that
is that we don't have
one technological weapon of mass destruction
now we have many
and in the World War II system
the mutually assured destruction system
had one catastrophe weapon
and two actors that had it
so you could create a system of mutually assured destruction
where neither one could utilize it
we currently have a world
where you have dozens of catastrophe weapons
if we include all of the types of
not only weapons of mass destruction
but the ability to take out critical infrastructure
and in a highly connected supply chain system
we have dozens of catastrophe weapons
with not just many state actors
but non-state actors having access to them
so you can't put some mutually assured destruction system on it
so it's like how do we make it through
this much distributed technological power
with the current incentive systems
so if you want to look at what is unique to this period of time
humans have been here for roughly 200,000 years
biologically identical
2 million years of hominids with tools
we didn't reach the first billion people until 1815
we were less than a half a billion people
for that entire history
and then with the industrial revolution
and liquid nitrogen fertilizer
we went from half a billion people
to 8 billion people almost overnight
we simultaneously increased our energy consumption per person
and our total resource consumption
per person exponentially
so we exponentially increased the number of people
and the consumption of resource per person
and this does bring us
so for the whole history of the world
we did not have the technological power
to quickly destroy everything
like nukes or even to pose a threat to the biosphere as a whole
that is only the result of post-industrial
and now particularly post-late industrial technological capacity
really important thing to understand is
you know as a species
we because of tool creating
were able to move from early environments to other environments
in a way no other animal could
and become the apex predator in every environment
so when we over-hunted an environment
a lion can't increase its predatory capacity radically faster than the gazelles can
because predatory capacity only comes through genetic evolution
which is very slow over time and there's co-selective pressures
with tool making we were able to increase our predatory capacity
through a different process that wasn't genetic evolution
radically faster than anything else could increase its resilience
to our predatory capacity
so we could over-hunt an environment
then rather than have our population fall back
move to a new environment
and so we've actually been on the beginning of a self-terminating path
for a very long time
it's just an exponential curve that looks like this
and the first major bump was agriculture
and then the next major bump was the industrial revolution
and then it's been verticalizing
and so regarding earlier civilizations though
we didn't have the technological capacity
even in aggregate to mess up the biosphere
but we did have the technological capacity
to mess up our own local environments
and that's one of the main reasons early civilizations died
we read the collapse of complex societies by Joseph Tainter
where you read Jared Diamond's book on it
many early civilizations actually died
because they created topsoil erosion from bad agricultural practices
cut down too many trees and stopped being able to feed their people
so civilizational collapse from overuse of the environment
is actually a multi-thousand year reality
and if you think about early civilizations
the first insights you'll have
whether we're thinking about the Ottoman Empire
the Egyptian Empire
the Roman Empire is that none of them still exist
so it's actually the precedent of civilizations
to have a life cycle and to fall
but most of them fall from internal self-terminating causes
either environmental ones
or even if they lose a war to someone else
very often they lose a war to a smaller foe
than they had defeated during their peak
because internal decay and infighting happens
from generational institutional decay
so self-induced purposes make civilizations break down
so civilizational collapse is actually the norm
that's the first thing that's important to understand
it's just it was always a local phenomena
this is the first time that we really have a global civilization
in terms of the supply chains that we depend upon
to meet our fundamental needs
and so we're in the process of a breakdown of this civilization
but what that portends in scale
and what it portends to be having the biosphere
the ecological effects but at a biosphere level
is totally unprecedented
and what I would also say is that our solutions
to the previous problems
because there's this nice narrative
that there've always been problems
but we always come up with solutions
and necessities the mother of invention
and we'll figure our way out of this
and then we get to live to solve new problems
and that's kind of true
but it is also true that the problem-solving process
we have employed is actually drives larger problems
and you get to a place where those problems
are actually beyond the scale of what the biosphere
can handle in human capacity
and so you actually have to have a different problem-solving process
so if you think about making a technology to solve a problem
or a business or a law to solve a problem
you define the problem in a narrow way
like this viral issue
or like a transportation issue or whatever it is
you define it in a narrow way
there's one or some small number of metrics
you're trying to change
and you create a technology or a law or a business
or a non-profit to produce a first-order effect
meaning a direct effect to solve that problem
but it interacts with ecologies and societies
and psychologies which are complex
and it has second and third and fourth-order effects
on a whole bunch of metrics that aren't even identified
and that's where the harm ends up being externalized
so the metacrisis that we face currently
we can talk about very specifically
what the generator functions are
but if we look at all of the planetary boundaries
from species extinction to biodiversity loss writ large
to nitrogen and phosphorus cycles to climate change and ozone
all of those are the result of an exponential financial system
coupled to a linear materials economy
hitting planetary boundaries
so you have to fundamentally make the materials economy go closed loop
and the financial system has to stop being exponential
which means a post-growth financial system
that's a really, really huge lift to get from here to there
and then when we look at all of the issues associated
with externalization from exponential tech
how do we steward the power that exponential technology gives us safely
that does require a totally different level of consideration
of like yes I'm making this immuno
I'm doing this genetic modification science for cancer purposes
but as soon as I've done it it now becomes cheap and easy
for designer babies and every other kind of purpose
so how do we kind of mythopoetically say
if no other animal had the ability to extinct species at scale
or destroy ecosystems or genetically engineer new species
so this is not the power of apex predators
this is the power of nature
the power of gods
if we have the power of gods and not the love and wisdom of gods to steward it
we don't make it
so to make it through this technological kind of adolescence
what is the infrastructure that can make it
and what is the social structure and culture
that are required to be able to guide that are core interesting questions
so you've very eloquently defined how good we've been for a long time
at being self-terminating civilizations
and we've scaled it to the planet now
so I think to go back to my question around the first and second attractors
and then the third maybe browse very quickly on the first and the second
this is a whole theory around that
but there's a theory of change which you're proposing through the third attractor
and I think that's where there's hope
and not only hope
it's sort of a story of collective ingenuity that has to unfold
and unfortunately you have to go through a little bit of a difficult phase
to appreciate the complexity of the problem with a new set of eyes
before you can do so effectively
so that's how the lens of the metacrisis is useful
because you can't get to that third attractor before you've understood that
so could you maybe just go quickly over the two first attractors
and then the third one that will give us a little bit of a glimpse of hope
If we just think about
if you can build some gene synthesis in your basement cheaply with no exotic materials
if anybody can build gene synthesis in their basement
how does the world make it through that technology being a distributed capacity
if you think about it for a while
the answer almost everybody comes up with is it can't
so that can't become a distributed capacity
okay so we have to make it to where the companies that make the gene synthesizers are regulated
what about the DIY version that makes it on the internet
well now either we have to control information on the internet
so who does that that can radically control the information
or we have to know what people are doing in their basement
some kind of ubiquitous surveillance
this is some of the thinking behind the IOT and sesame credit system in China
is actually not stupid thinking
it's forward thinking to distributed exponential tech and how do we deal with that
so you can see that the solution to preventing a catastrophe
can be a control mechanism that can look like a dystopia
so the two attractors that I say we want to avoid are catastrophes on one hand
and solutions to catastrophes that involve being able to keep those from happening
which requires both optics of what's happening and the ability to prevent it
which sound like control mechanisms which become dystopic
and so right now one thing I'll say about the catastrophes is
you have to look at the cascades between all of them together to make good sense of it
if you look at exponential tech as one category
and environment as another and war as another and supply chain and electrical grid separately
you'll miss the way it actually happens
so when does climate change become a catastrophic risk
well you're talking about like the venusification of the planet
or the drowning of coastal cities or something like that
long time before that happens
extreme weather events that start to hit high population density areas
and cause human migration can cause escalation to World War III
right so you think about the extreme weather events in Australia
it was just very fortunate that that was low population density
low total population area
you look at the droughts in Syria that caused population movement and did cause a war
what if you look at the temperatures that Pakistan and Bangladesh
and northern India have been starting to hit during the summer
and just say some time in the next few summers
you get past a temperature where the crops fail
and they don't actually have stored crop
a lot of it was destroyed during Covid
they don't have ground water and when you're in a 50 Celsius heatwave
but you're talking about an area that has 100 million people now
as opposed to a very small number of people
what happens
does the resource war fall along Muslim Hindu lines
does that lead to an India-Pakistan war
so with climate change you're not looking at climate change
just as a problem itself
but it is a force amplifier of the other problems
and you have to look at all of them that way
so there's a lot of different entry ways to catastrophic collapse
and we're seeing some of them right now
and so one attractor is increasing catastrophes
the other meaning a likely path the world goes
another attractor is the world recognizing that and saying
shit we have to keep that from happening
so we have to actually deal with climate change
through pricing carbon properly and degrowth
but that is really bad for a lot of people
because as soon as you make carbon more expensive
you make all the commodities more expensive
which hurts the poor people the fastest
and on and on and everyone who doesn't want that
do you use violence against them
and so to prevent certain things ends up meaning control
if currently human behavior is doing that
and so how do you prevent increasing dystopias
which a lot of people think the Chinese state is in the direction of
so a desirable future is a future that doesn't self-terminate
and it doesn't have unchecked centralized power structures
the question one of the causes of the increase in nationalism
is the distrust in globalism
and one of the major reasons of the distrust of globalism
is the idea that unchecked power doesn't have a good history
and so the idea that we at least keep power-checked in a multilateral way
is preferable for a lot of people
but if you have many different nations
that are in economic competition with each other
nobody wants to price carbon properly
because if the US does it will be radically disadvantaged relative to China
as a result China's Belt and Road will geopolitically dominate the world
and crowd out democracy and those types of things
and so if you have nation states in competition with each other
they just can't deal with global issues well
if you have global governance who's creating a check on that power system
to where it can't be captured or corrupted
so I would say thinking in terms of the design criteria we need
has to be able to do global governance
it has to be able to deal with things like decentralized catastrophe weapons and basements
but it also simultaneously has to have checks and balances on every power system
or every control system that are there that are adjudicatable
it would take me a long time to describe what I think the best processes for how to do that are
I will say that there are world systems
there are technological systems that could be enacted that meet these criteria
that align with human nature so I am optimistic about that
the enactment to get there takes a lot of work
so just briefly mentioned the third attractor
I will move afterwards towards some hopeful scenarios that we might encounter
so that people don't leave this room with a sense of fear and catastrophe as being dominant
but in order for us to create a third attractor
we have to put some energy towards developing one
and that's not a simple thing to do
but first we have to understand what it is and how that could drive us away from those two attractors
decentralized catastrophic capability and centralized capacity to control
which is kind of dystopian
there is not a term
there is not like a term for a type of political economy or system that makes that third attractor
and we actually don't know
so specifically what I mean by the third attractor is literally something that is
can prevent all the catastrophic possibilities where the control mechanisms required to do so
have the types of checks and balances that they prevent centralized power issues
so we are actually defining in terms of what it isn't
it's not catastrophes and it's not that the solution of the catastrophes involves dystopias
exactly what that looks like
there's both how would we design it from scratch which is a nice question
but it ends up being kind of a nonsense question because we don't get to design it from scratch
there's this enactment issue of with all of the vested interests that the world currently has in play
how do we actually get there
so I can give you a few examples of things that give the sense of what can make a third attractor possible
so I'm just going to mention one which I think you'll probably refer to
we have a common friend in Will Marshall
were you going to mention Planet Labs
I wasn't but we can
okay well I mean so Planet Labs you know I'll let you talk about it
but effectively I think it's interesting to see also that some of those third attractors reside in the domain of intelligence plus
or human intelligence plus technology applied to a new level of what you've actually yourself called force transparency
and you know that probably is not it doesn't define exactly what the third attractor is
but it's a sort of you know hopeful way of looking at technology
that can constitute an underlying let's say conversation between different actors
whether they're state or civic actors or technology bodies
that can start to formulate more of those
so I think we both agree that there needs to be a proliferation of these examples
and force transparency is a really important tool because we've got very weak international governance and law
so maybe you can address the third attractor by giving some examples
yeah so market forces like incentive by itself doesn't solve all the problems
so you end up having to use both incentive and deterrent there
if we didn't have law protecting national forest we wouldn't have national forest
we wouldn't have market forces that continue to turn everything into commodities
but as far as international law it's tricky because law mostly exists where you have a monopoly of violence that can enact the law
a police state inside of a nation state so where we have global issues like the oceans or the atmosphere
this is where we have a really tricky time because
how do you if you're going to make a law it requires multinational agreement
and then the ability to see if it's being violated and then the ability to enforce some enactment
and the ability to enforce it where it's not more expensive to do so than the benefit you get right
so let's say that we have an agreement about oceans and China's violating it
and so we say okay we're going to sanction you for that like how but the sanction is on supply chains that we depend upon
and if you escalate they also have nukes so it's like there's a tricky thing with all that
but one of the places where a lot of environmental issues global environmental issues don't get legal support
is where we just don't even know what's happening it's hard to know what's happening in the middle of the Amazon
it's hard to know what's happening in the middle of the open oceans
so this particular example is where technology can be repurposed in a positive way
there's a satellite imagery of the earth is a pretty amazing technology
there's a friend of ours who runs a company called Planet Labs
and they image the entire surface of the earth every day 30 terabytes of compressed data
but they're increasing the spectral and temporal resolution of that
and spatial resolution sets that it'll be pretty much real-time human level video capture of the surface of the earth in about three years
which is amazing and one of the things it means is the ability to see where logging is happening
and where mining is happening and where dumping is happening and where legal fishing is happening
and even to be able to see in a dead zone in the ocean the effluent how much of it came from which source
how much came from which port and all those types of things
the ability to see all that use machine learning to process it
means that there's a whole bunch of international law that we've never even bothered to create
because there'd be no way to know if it was being violated or enforce it
now we'd have the ability to create international law that says no we actually
you don't have plausible deniability anymore we know exactly how much of the trash or the nitrogen effluent came from there
because we can see the whole thing
it also has the ability to do spectral analysis that can see an invasive species entering an area
or soil microbes in an area to be able to actually support the environment
when critical issues are starting to happen
but this is itself very concerning because you probably many of you
even as I'm describing this are like wow that's really hopeful for the environment
to be able to have that level of transparency that could create law so we could support the environment
but fuck who gets to have access to video level data of the entire surface of the earth all of the time
that sounds like pretty massive surveillance capability which it is
so that can prevent certain catastrophes but can totally create dystopias
depending upon how it's managed so how do we create the governance of that information
such that it doesn't get used for nefarious purposes
and that people get to know what it's being used for this is not trivial right
because it's easy to deploy the technology to solve those problems
it's actually quite hard to create the governance to ensure that it's used properly
well the official version that will give me is that it's 50 centimeter resolution
so you can't see a face it's easier to count trees and cars and tanks in Ukraine
when the Russians pretend that they're leaving a certain battle area
but let's agree that you know that power is something that needs to be at least checked
so what I guess I was trying to get at is there is some hope
in terms of how we can leverage technology in order for us to sort of monitor
and then have some checks and balances and also create the international agreements
and legal frameworks to enforce some form of limits if you want to call it that
I know something I'd like to say is there is a naive techno-optimism
that I think is super dangerous that just tech will solve all the problems
and the very worst version of it is we're only a few years from generalized AI
and then that'll be able to solve all the problems
if you study the alignment issue of how do we ensure that truly generalized AI is aligned with our interests
it's a really, really tricky problem
there's also a naive anti-tech, a kind of naive Luddite perspective
it's like man all these problems are because of excessive tech
quality of life is actually better at a lower level of technology
let's get back to the land and permaculture and that kind of thing
but if you study the history of the world any time there is an intersection
of a less technologically advanced society with a more technologically advanced society
it doesn't go well for the less technologically advanced
and so the China-Tibet type interaction always happened
and so whatever this group of people are saying we're going to do the less technologically advanced
will not actually influence the direction of the way the future goes
because the technology is power which does mean influence
so the future will be high tech but it has to be also high nature and high connectivity
or it will self-terminate so you have to say we don't get to put the Pandora's box of tech closed
but we have to actually become wise stewards of it
so what does a high tech, high nature, high connectivity future actually look like
and if we don't have the technological capacity for outsized influence over the current systems
the current systems will be what dominates
and so I am a techno-optimist but not a naive techno-optimist
meaning I know that all the existential risks we couldn't do without tech
Stone Age people cannot destroy the planet
so I'm acutely aware that all the catastrophic risks are results of human activity
extended through technological levers
but I'm also aware that the solutions to those things can't avoid technological elements
but the technology alone is not sufficient
so one way, think about this, there's an anthropologist named Marvin Harris
and he said you can think about civilizations as these triples of what he called the infrastructure
the social structure and the superstructure
the infrastructure is the tech stack
that the civilization depends upon and meets all of its needs with
the social structure is the collective agreement field
so economics, governance, law and the institutions
and the superstructure is basically the culture
the values, the identity, the definition of what the good life, what were motivated by are
he particularly argued that they are interconnected
but the tech changes in tech drive the other ones
and he gave a heap of examples from the plow to the wheel to on and on
where a change in tech meant that whoever used that tech
now they're behaving differently right
driving a plow is a different set of behaviors than hunting
but the no tech catches on if it doesn't provide adaptive advantage
if it does provide adaptive advantage it changes pattern of human behavior by using it
as a pattern of changing, by changing human behavior you also change human values
and then everybody else has to adopt it or they lose in war
to whoever has that increased adaptive advantage
so he basically said cultures and political systems change because tech changes
there are other deep anthropologists and sociologists who say no actually
and give a heap of examples of how cultural changes make us innovate in different ways
aligned with our values or have us bind our technology like the Sabbath
or things like that and say that cultural changes are the deepest
and then there are plenty of others who say no
ultimately the economy and law is the deepest thing
because ultimately whatever you incentivize financially is the technology that will be developed
if you change the subsidies and the taxes and the incentives
the tech stack would evolve differently
I would say that all three of these
the infrastructure, the social systems and the superstructure
or culture are equally fundamental and inner affecting
and you have to think about changes to all three simultaneously
so if you dismiss any of them out of hand
like our cultural changes don't matter that much
or technological changes or government doesn't
you're definitely not thinking comprehensively
but if you have a favorite one like we can just do culture change
and everything else will automatically happen
that's also not thinking comprehensively
they're all necessary and only thinking about them together
and the way they interact with each other is sufficient
so we could think about if we want a future that avoids all these catastrophes
what does the infrastructure have to look like?
pretty quickly we can say we can't keep using nature unrenewably
and turning it into pollution and waste unrenewably
so it has to look closed loop and it has to look post growth
and we can't grow it exponentially on a finite planet
so what types of technologies would mediate that
and what things should be global and what things should be local
has a lot to do with the social structure interaction
of there are things that you want to be global
and so long as you're wanting to bind the well-being of those people to each other
through supply chains and interdependence and that kind of thing
what would the social systems of the future look like
and what would the culture
there's been conversation today around in-group, out-group and identity systems
that's culture questions right?
I think there's a lot of probably focus on the well-being picture here at Harvest
and it's a virtual picture of planetary identity
and obviously the planetary identity has to be not just humans
but all life forms because you can't advance all humans
at the expense of the biosphere for a little while
but then it goes pretty badly for the humans
so when we think about third attractor
we have to think about what is the culture of it
what must it be
what must the coordination systems
and the distribution and allocation of resources
and you start to get into things like well, man
doesn't interest by itself
even if we don't think about central bank policy
or interest rates or fractional reserve banking or anything
doesn't interest itself
compounding interest force exponential growth of finance
yeah, it does
and then to not debase the currency
doesn't that mean you have to have an exponential growth of goods and services
yeah, it does
doesn't that mean you basically have an exponential materials economy on a finite planet
yeah, so interest has to go
well, that's really fundamental
we don't know how to make that world
and then as long as most access to resources
based on private property
doesn't that mean rival risk interest
where I can do better at the expense of the environment
and others based on private property
probably a lot of stuff has to be rethought around property law
and then even when you get to
I can appreciate the atmosphere
in fact my life depends upon it
but I don't have to pay for it
and so if I cut a tree down
I get immediate benefit from the timber
and the little tiny damage it causes to the atmosphere
I don't really notice
but when everybody thinks that way it does have that effect
but locally I have way more incentive to cut it down than to leave it up
because the extraction value
that I get from turning it into lumber
gives me game theoretic value
whereas if I
if I put my resources towards planting more trees
that I don't have economic interest in
I do less well in the economic system
which means that there is a fundamental rethinking of the value equation
because whoever ends up valuing extractable exchangeable wealth
ends up doing game theoretically much better than those who don't
which means they influence the world and culture more
those who pay more attention to common wealth
have less influence over the whole thing
so the changes that we're talking about at the level of economics
are things like interest, private property, fungible currency
even deeper than whether we have nation states or not
and the same in terms of thinking through what is the future of the tech stack look like
so we share a lot of views and thank you for laying it out
I hope everyone could follow with these
this way of presenting where we're at
a lot of people are quite naturally fearful
of where we're going in terms of the labor force because of AI, for example
so in one of your talks, I don't know if it was very recent
and we shared this view about this by the way
you talked about education or educators and nurses
I think it's a good way to present a hopeful opportunity for us to do something
where humans are uniquely designed to do something different than machines
and where efficiency is not what matters
it's more about qualitative than the quantitative
and our computational capability is not challenged by that
so I thought maybe I'd switch gears a little bit
but it's giving a little bit of hope again
in terms of how we can address concretely some of these challenges
that we're facing whether we're techno optimists or techno skepticists
so I worked with the G7 on a scheme to try and infuse
into national security in the G8 countries
a concept of benevolent AI
and we were just studying with 80 scientists from all over the world
how we could potentially put that into motion and start to educate government bodies and leaders
and the main failure point was purely geopolitical
so the arms race and AI just made it so that it made every single suggestion stalemate
so we have to address it on a population level
and also in terms of how, in terms of society
we adapt to the change that's coming towards us
we've adapted to bringing cars into our life, arguably imperfectly
we've adapted to many changes in our society in terms of health care and pandemics
and how we travel and etc etc
give us a little, I share this view with you by the way
how you think educators and nurses could become a little bit of a new orientation for mankind as AI steps in
so the topic of technological automation creating a jobs issue
there's a couple perspectives
one primary perspective is technological automation will obsolete certain jobs
but it'll create new jobs
it's always been the case we don't have elevator operators anymore
but there's plenty of new jobs
and then there's the other perspective
no actually advanced robotics and AI are different in kind
and some of the earlier industrial technologies
and they're different in speed that as new jobs are created
they will still be able to beat humans at doing it for market purposes
which I think is much more true
so if you take an AI like Google's AI
you take AlphaGo, you can train it on chess
you can train it on Go and how to beat everybody at Go
you can train it on StarCraft and how to beat everybody at StarCraft
it can gain the capacity very quickly to beat humans at any finitely definable game
and so AI is different in kind than other previous technologies
it's more like the difference between us and all the other animals
with our ability to innovate, you know, creating recursive technology on technology
that allowed us to become apex predators in every environment
and that the AI is kind of like that jump again
and so it does portend a break of capitalism and market structures
as we know it and that most of, not just labor
but most of the jobs that we currently have
and even the new jobs that emerge in the niches that it creates
it's better at than we are
that sounds pretty terrible if you keep the existing political economy
where people need the jobs
but one of the main reason we created a system where the people need the jobs
is because the jobs needed the people to do them
and to make a civilization run well
if you had to get the people to do the jobs
and a market seemed like a better answer than the state forcing the people to do it
so let's let the market force people to do it
and they can kind of self-organize
but as soon as the jobs don't need the people to do them anymore
you can also start thinking about economies where the people don't need the jobs
which is why now a lot of people are thinking about universal basic income
and like different ways of thinking about that
there's early naive thoughts on universal basic income
of course it's the beginning of thinking about it
but there's a really deep question which is
what is the role of humans in a world of advanced robotics and AI?
because the advanced robotics and AI will be better than us
at most of the things that we're used to being good at
so what is the role of humans in that world?
what are we still uniquely good at
and then what is also intrinsically fulfilling and meaningful?
and there becomes a steep question of
what does education become in a post-technological automation world
where you're not preparing people for the workforce in the same way
what is the role of education and human development
but obviously to answer that you have to say not just education
but and obviously there's the economics component
how do we do resource allocation and access in that world
but there's a really deep civilizational question of what is the role of human life
and if we for a moment avoid the topic of sentient AI
which is a whole theoretically difficult question
and we just talk about functional AI
meaning AI that we're not saying there's something that it is like to be it
we're simply saying it's very good at figuring out how to do stuff
then right away the key what is uniquely different about humans
and it is sentience
is the capacity to actually have there be something that it is like to be you at all
is subjective experience and then inner subjective connective capacity
and what's interesting is things related to sentience
are what is where our intrinsic motive
is not being behaviorally controlled by extrinsic motive
i.e. being paid to do a thing or external deterrence
and so mostly you have to pay people to do shit they don't want to do
and if the shit that people don't want to do is increasingly getting automated
can you then have a world where largely what humans are spending time doing
also more deeply coincides with what they have the deepest intrinsic motive to do
particularly if you then have a developmental system and developmental society
oriented to find out what the unique human motivations and capacities of each person
are and develop them in light of that
and so not only does AI portend something in terms of the obsolescence of humans
for lots of labor roles and repetitive things
one of the things Tomas was probably referencing was
the topic of AI in human tutoring is pretty amazing
it's also scary as fuck because again you have to get this thing right
if you have an AI that has so many orders of magnitude
more information processing in terms of being able to model your micro expressions
to see how you're learning it can also
have undue influence in a way that no cult leader has dreamed of
in terms of asymmetries of power of influence
so who controls that and how do they control that
these actually become the cultural questions
the theoretical philosophic questions that are so fundamental
if you can genetically engineer humans and have designer babies
don't we all want to be like tall and beautiful and thin
and is that actually the right idea
as soon as you have the ability to actually design intelligent machines
and design self-replicating machines and change biology
the philosophic questions of what is good and desirable
become so fundamental because so much becomes possible
but if you do it right
imagine everybody's heard about deepfakes
the ability to train an AI
you can make basically pictures that aren't real
faces that aren't real from AI images that look totally real
you can also make a video of me speaking
where it looks exactly like me, sounds like me
but it's totally AI generated, it's not real
that technology already exists, it's not that good
some people have made deepfakes of me that are audio that sound like me
but the deepfake videos are currently about three years away
from being Turing test passing
meaning you can watch a video of Obama or Bernie Sanders
or whoever say something and have no idea if it was real or not
and you won't have the human capacity to tell if it's real or fake
you can imagine what that does to our ability for collective sense making
but that same deepfake capacity can be positively purposed
because what that means is it's trained on the semantic patterns
and the vocal patterns enough to be able to generate novel answers
like a chatbop where you can't tell that it's not real
so now imagine an educational environment where you train that same AI
this is large language models as the type of AI
say you train it on all the writings of Thomas Jefferson
or all the writings of Socrates through Plato
or whatever in writings about them
such that I can go into a metaverse environment
and say I want to pull up Einstein and von Neumann and Kurt Girdel
and be able to have a talk with them about formal logic
and not only can it seem like I'm actually having a conversation with them
where they're sharing differing views based on their actual views, writing, etc.
but I could also just have an avatar that is like the voice of chemistry
that is the holistic knowledge of all chemistry that no human could be
and yet all of them are the AI's best attempt to model what that person would do
in terms of semantic coherency with what they did and said in the past
so now imagine a future where every kid has access to be able to study
with Einstein and Gandhi and Socrates and von Neumann and whatever directly
where those AI's can model our theory of mind
and titrate the learning directly to us associated with our learning dynamics
but then also because the jobs have largely been automated
what humans spend way more of their time with is things like being educators
and being nurses and being musicians
and the things that have kind of high connectivity value
because those are the things that the machines don't do as well
as the actual sense of shared interiority
so now imagine that we have way more teachers per capita that are way more well trained
so all the teachers are PhD level trained
there's one of them per 10 kids as opposed to one per 30
and now I get out of my AI environment where I was just studying physics with Einstein
and my tutor asks me a question like
what do you think was different about what the AI Einstein said
than what an actual Einstein alive today might have said
so then helping us to try to understand the difference between human intelligence
and artificial intelligence and what it means to be sentient
and what effect does consciousness have on intelligence
so not only are they getting that level of educational access
but the AI can do
but the differential of what is unique about human intelligence and artificial intelligence
so this is one of a million examples we can give
of how those technologies could do mind-bendingly amazing things
I'll say one quick thing about this is
there's a study done on super genius of the past
or polymaths, people who advanced many different fields
beyond what the specialists in those fields did
and was there anything that the great polymaths had in common
and the single thing that stood out the most
was that they were all the result of aristocratic tutoring
and this was actually a very taboo topic
because when we ended feudalism and tried to create democratic states
the idea, like if you think of meditations by Marcus Aurelius
Marcus Aurelius spins the entire first chapter
just thanking all of his tutors
but when you're being raised to be the emperor of Rome
the best mathematician, the best poet, the best grammarian, the best historian
literally in all of Rome are your private tutors
and you can't learn to think like a mathematical genius
from someone who wasn't a mathematical genius
so your average math teacher cannot teach you to think like that
because they don't think like that
and yet how do you make that accessible to everyone? You don't
so the aristocratic tutoring in the past was a nice patronage job
for the smartest people
but it was also so radically unequal
but it's what created the best minds
so could that possibly be made popular?
Well, we can see in a third attractor kind of world
the application of these technologies
where you could actually have better tutoring than Marcus Aurelius had
for everybody, you know, et cetera, et cetera
now for each of these wonderful scenarios
are like a million ways it goes wrong
and so how we steward that properly
is the key defining thing over the next while
Thank you, Daniel
Thank you
