Hello, my geeslings. It is Mother Goose, Robinson Earhart with the introduction to
Robinson's podcast number 43. This is a first as far as introductions go. I am wet because
it has been raining here for months in Palo Alto seemingly without end. And for that reason,
Pins for the first time is not on my lap for this introduction. But here she comes. Maybe
she will be joining me. Anyway, I also just had a pint of ice cream for breakfast and that
adds to my shivering coldness. But this episode is with Eric Schvitz-Gabel, Professor of Philosophy
at UC Riverside. And it was an extremely fun conversation to say the least. It was quite
bang, bang, bang. He's really lively and full of all sorts of interesting thoughts,
fun thoughts, fun topics. He writes about an incredibly, and I'd say unprecedented,
unprecedentedly wide variety of material as you'll hear. And in this conversation, we talk about
an upcoming book of his about the weirdness of the world and the philosophy of weirdness.
So we talk about why if you're a materialist, the US might be conscious. We talk about what
Kant and cyberpunk have in common. We talk about evidence for an external world,
whether ethicists are more ethical than other people, other philosophers, just anyone you see on
the street. One of the more fascinating and surprisingly thrilling things we get into is
snail sex. And I didn't know that this could be fascinating. I don't think that I
got up the morning that we had this conversation expecting to talk much about snail sex, but
I'm glad we did. I listened to the conversation again before preparing to do the edits. And
snail sex is quite enthralling. Let me just, I'll just leave it at that. So I think you are
really going to enjoy this podcast. Like I said, it's just, it is just so fun to talk to Eric.
And I'm already really looking forward to having him on again at some point so that we can get into
the more of the near endless content he writes because he's just a prolific author.
So without any further ado, from pins and, and I, or me, from pins and me, enjoy this episode.
So you write about a ridiculously wide variety of topics. And yeah, so because of this, I suspect
that our conversation is going to be uniquely disjointed compared to the others that I have.
But I think that's a good thing. It's new. But first off though, so did you get into philosophy
because it's a discipline uniquely suited to this that you can write about? You can dip your toes
into all the issues you want. You've got the tools for it. That is a large part of why I got into
philosophy. I thought for all X, you can basically do philosophy of X. So it's, it's very free in
terms of what you can pursue as long as you whatever question you want to pursue as long as
you pursue it in a certain kind of intellectual way that tries to get at the core fundamental issues.
In my view, you're doing philosophy.
So I stumbled across a manuscript you're working on. I think it's going to be coming out relatively
soon. The weirdness of the world. Yeah. And what does it mean to say or to argue as you do
that the world is fundamentally weird? And why is this a good thing?
Right. So I mean something in particular by weird. I mean, it's got you, it gets used in a lot of
ways, but I'm using a little bit as a technical term where something is weird if it defies a kind
of expectations of what's normal and readily understood and fits with common sense. So it defies
like a folk theory defies a folk theory and is also difficult to understand defies understanding
even beyond the folk theory. Right. So it has to defy the folk theories for sure. But it also has to
be in some way also epistemic elusive epistemic elusive. So I use a different term bizarre for
stuff that justifies folk theory, but isn't otherwise elusive. Right. So for example,
relativity theory, the twin paradox and relativity theory is this idea that time flows differently
depending on what relative speed you're traveling at. It's actually even a little more complex than
that. But we understand it quite well. Our satellites depend on it. It's very well confirmed. It's
completely bizarre from a folk point of view. But it's not weird in the further sense that we really
don't understand what's going on scientifically either except except that it doesn't quite fit
with quantum mechanics. And that's weird, actually. So then you get the weirdness when you try to fit
relativity theory and quantum mechanics together, then then you get something that both defies common
sense and just like we don't know what's going on. That leads me to wonder then, will all of the
current weirdness eventually just collapse into bizarreness. So the world is ultimately not
going to be weird to us forever. I don't think that's right. So there's this analogy that's often
attributed to Einstein. But in fact, I don't think he said it, which is that as the circle of light
grows bigger, the circle of darkness grows bigger around it. I think there are things that used to be
weird that became merely bizarre and now aren't even bizarre, like the fact that earth is not in
the center of the universe, right? The idea that the earth moved, you know, and when Copernicus
posed it, it was bizarrely contrary to common sense. It didn't really fit with our current
astronomical understandings. There wasn't a compelling astronomical evidence in favor of it,
right? Eventually it became bizarre in the sense that it still didn't fit with common sense. But,
you know, once Galileo and Kepler got their thing going, it was like, yeah, okay, scientific consensus
is a favor. And now people don't even find it all that strange, right? So particular issues can move
from being weird to being merely bizarre to being not even bizarre. But the idea that there won't
always be stuff beyond our understanding, that doesn't strike me as likely. I think, you know,
one of the things, one way of thinking about it is, you know, to think about the two-year-olds
annoying why questions, right? Two-year asks you something, why is the sky blue, right? And you
give your best attempt to scientific answer. And the two-year-old says why, right? And the two-year-old
says why. And this two-year-old can keep backing up with why questions. The deeper your understanding
goes, the more of those why questions you can answer. But eventually there will be,
you're not going to run to the ground why, where there's no further why to ask, I think.
There will always be something about the world and something about us that we're not going to be
able to back away far enough to understand. So I guess what I'm wondering then is this a time thing?
So we won't last long enough to explain all of the things or there are questions that are outside
the capacity of science to answer and thus move from the realm of weird to bizarre?
It's not a time thing as I'm seeing it. Now I should say that this particular thing that
we're talking about right now, I don't develop in detail as an argument in the book.
I just read it a little bit. But so I haven't fully developed my detailed answer on this. But
it's, well it's definitely, it's not in my view a time thing. And it's not even that there are
particular questions that I think necessarily elude science as it's almost more like a transcendental
thing in the sense that any knowledge you have, here's another way you can think about it in
terms of the classic Agrippin Trilemma, right? Any knowledge you have is-
I'm sorry, the classic what? Agrippin Trilemma? Do you know this?
No, I don't. I love to.
Even if you pretended that, even if you said you knew it, your listeners might not, right? So the
idea is anything that you say, anything that you claim, if you try to defend it, well you've
got basically three options. You can either just assert it, undefend it, or you can defend it by
appealing to something else. Or, but then you raise the same question again, okay, so why is that
thing, what do you do in support of that thing, right? You either give it undefended,
or you can pull up something else in support, or you can argue in a circle, right? So there's
a trilemma. All arguments ultimately will either be circular, ground out in something undefended,
or just regress infinitely. I like that, that's nice and clean. Right, so whatever scientific
knowledge or philosophical knowledge we come to, at some point, we're gonna have to say,
well we're just taking that as an assumption, I can't really explain it more. Or we're gonna
just get caught pursuing that regress and pursuing and pursuing and pursuing it, you know,
or we're gonna tie ourselves in a circle, and then the circle really ultimately is gonna be some
kind of ungrounded thing too. So the thought that I have here is that in some, we could call it
transcendental to make it sound fancy, right? In some transcendental sense, we're not ever going
to be able to understand the grounds and explanation of everything. There's gonna be the grounds of
the grounds of the grounds of the grounds, and eventually we're gonna poop out. It's not just
because we're gonna get tired or go extinct or something like that, there's just something about
the process that's inexhaustible. Okay, I like that answer. Now, just for my own edification,
it's the Gripen Trilemma? Agrippen, A-G-R-I-P-P-A-N after Agrippa. He was a medieval, I think,
you know, I tried to find his writings at one point to try to get back to the original source
of the Gripen Trilemma, and you know, I can't remember. This was a long time ago, but...
I found him. Agrippa was a Pyranist philosopher who probably lived toward the end of the first
century. Yeah, okay, so late antiquity, but we don't have his writings. We just, he's kind of,
as far as I remember, just basically famous for this trilemma. Yeah.
All right, well, great. We've started off very well. I've learned something quite fascinating.
So now, to talk more about some particular issues in your book.
Why, if materialism is true, is the United States probably conscious? My guess is that this has
something to do with functionalism, which I know a little bit about from Ned Block, but why don't
we start with maybe just briefly, I think materialism will be pretty easy for you to sum up and then
move from there, right? Well, materialism is actually not that easy to sum up. There have been
various attempts to define it, and it turns out to be actually pretty tricky to define, but
we can gesture toward it, right? Sure, sure. I mean, all things are material, but then there is
the question, I mean, what is, like, is a field material? Yeah, exactly, right? So the way that
I like to think of materialism is it's the view, if you think about quarks, protons, electrons,
photons, field, magnetic fields, stuff like that, right? Materialism is the view that the
universe is fundamentally composed of stuff like that, and the things that compose it or interact
with it in a way that is not fundamentally mental, right? So decades ago, we might have said, you know,
protons, electrons, neutrons, everything's composed of that, that's it, story's over, right now it's
going to be more complex than that, but some version of that is materialism. And then you
have to build into that, that these things are not fundamentally mental, or you get
some views that end up being technically materialism that we wouldn't want to call materialism,
right? So you've got this non-mental kind of little stuff, or either particles or fields or
strings or whatever that kind of is not fundamentally mental and interacts in some way,
and then every all of our mental lives arise from that. So that's materialism. Okay. And then the
kind of the central thought of that chapter is that if you look at what materialists say about
how conscious experience arises out of the interactions of these fundamental things,
the United States basically satisfies all the kinds of criteria that are normally appealed to.
So why is it that brains are conscious, right? So, well, they do a lot of complex information
processing. So does the United States. Well, in order to really understand this thesis,
we need to think a little carefully about what I mean by the United States. But the United States,
I don't mean the government. I don't mean some abstract thing. I mean, like the concrete entity
that is all the people of the United States as parts, kind of like the cells of your body
constitute you as parts, right? So imagine all the people in the United States as residents and
citizens, each of them are part of this spatially distributed large thing, like group entity,
right? That thing does a lot of information processing, a lot of exchange, it behaves in
all kinds of ways with this environment, it imports goods, it regulates its smoggy exhalations,
it announces its position on foreign affairs, it engages in wars. When it engages in wars,
it seems to deploy sensory capacities where the army doesn't crash into the mountain,
it goes around it, right? It speaks, it represents itself, it's got really complex
self representations. It is, I mean, if you think about what like, if we think rabbits are conscious,
as most people do, right? What does a rabbit brain have that the United States doesn't have?
There are a couple of things that immediately come to mind. Again, since it's a rabbit,
we're going to have to be a bit presumptuous, but a rabbit, I assume, has some sort of
narrative center, even if it's not linguistic the way ours is. But I imagine that the rabbit is sort
of, it sees itself or feels itself located in a kernel somewhere behind its eyes.
The United States is located on North America, I mean, it's a big thing, so it's not going to be
located in any narrow location, right? But it's located on North America. I can imagine though,
it's not so much, I didn't mean to draw a location into this point, because I can imagine a conscious,
artificially intelligent creature that is disembodied, but still has maybe a narrative
sense of self. It doesn't need to necessarily be instantiated in one point, but that's one
difference that I see between the rabbit and the United States. And then one other thing
is that all the other conscious creatures that we know of, I mean, chief among them,
ourselves, do have a very clean spatial delimitation to what the brain is and what we think is the
subject of consciousness, whereas the United States is this very discreet conglomeration of
things that, I mean, pretty much everything within the skull, I can really say, okay,
this is part of the, of Robinson's brain, but I can't necessarily point to everything within
the United States and even imagine how these things would play some role in consciousness, but.
Yeah, well, I mean, there's stuff in your brain that you might not think plays a role in consciousness.
I mean, to what extent? You're very right. The blood vessels, the linings of the blood vessels,
I mean, you know, they're important, but they're not the neurons, right? Well, so the roads in
the United States are important. They're not the people. I mean, from a broad point of view,
you can say, well, the neurons, the blood vessels are part of your brain and part of the system that
gives rise to consciousness, and you might take a similarly broad view of the roads in the United
States, right? Or you could go more narrow and say, well, look, it's really about the neurons of
the neural connections, or in the United States, you could say it's really about the people that
compose it. And so you can kind of go either way on that. On narrative, I'm not sure exactly how
rich you mean it, but, you know, do rabbits have a narrative sense of the self? Well, I don't know,
but maybe in a, maybe in a weak sense at most, but then I'm not sure the United States doesn't
also. I mean, the United States talks about its history, has plans for the future, it seems to.
Sure. When the United States scolds Iran for developing nuclear weapons or whatever, right?
That's fitting into a whole history of its interactions with other organisms of its type.
Maybe another word I might point to is there's some sort of phenomenology to being a rabbit,
but I'm not sure that there's a phenomenology to being a United States.
Well, that's exactly the question, right? So I use consciousness and phenomenology
interchangeably. They mean the same thing in my term, right? So I think, commonsensically,
we'd say, no, of course, the United States doesn't have phenomenology. But what I'm saying is,
okay, well, what's the basis for having phenomenology according to materialists? Well, it's
having stuff like lots of information exchange and intellectual and, you know, sorry, and intelligent
information exchange with this environment and, you know, maybe having some kind of narrative in a
weak sense, a weak enough sense that we could include a rabbit, right? That kind of stuff is what is
seems to be on most materialist accounts enough to have phenomenality, phenomenology, experience,
something it's like, consciousness. I use all these phrases equivalently. So why doesn't the
United States have the same thing? We find it absurd. People think it, I mean, you maybe,
they get absurd. It's obviously false, right? But I don't find it obviously false.
Okay. Yeah. That, no, that's, that's great. That's what I was going to ask next. I listened to
Kieran Satya's podcast, five questions. And he often asks his guests a question inspired by Iris
Murdoch. Murdoch, do you believe the papers that you write or the arguments that you make?
And I'm very curious, in this case, do you think that the United States is probably conscious?
Well, I'm not necessarily a materialist. Okay. So I, I am
kind of ambivalent among three possible reactions. And where I put the weight
among this ambivalence fluctuates, depending on kind of what's salient or something.
Um, but I bet, but all three of these reactions, I think, get a non trivial portion of my
greens. One is go for it. Sure. Materialism is probably our, it's our best guess. And
why not think that one surprising result of materialism is that you get group consciousness
and entity like the United States. I mean, boy, cosmology, physics, they're pretty some pretty
fundamentally surprising results there. The world is not necessarily like we common sensically assume
why couldn't that just be the case here? Right. If our best materialist theory say, here's what
you need for consciousness and lo and behold, the United States has it, you know, well,
maybe that's just kind of like the twin paradox or the weirdness of quantum mechanics or whatever.
Right. So that's one reaction at one mood that I'm in sometimes or another mood or another thing
that I'm kind of aspect of the ambivalence or tri-bivalence is to say, okay, well, look,
maybe materialism isn't right. I have some, it's my weekly, my favorite inclination or theory
with respect to consciousness, but I'm not committed to it. You know, and maybe this is
just one of the unfortunate consequences that you get from committing to this false theory.
And then the third thing that the one that the materialists are you generally happiest to think
of as the proper conclusion of this paper, which I think is definitely a reasonable thing that you
could think is, well, think of it as a challenge. Maybe the materialist, maybe what's happened is
materialist theories are not really well developed, right? Show me develop materialists a theory that
delivers the appealing conclusion that humans are conscious, rabbits are conscious, space aliens
of various plausible sorts are conscious. We didn't talk about that, but you know, if you want a
general theory, you're going to want a theory that applies to lots of hypothetical cases and
delivers what seem to be the right results for those cases, right, gets you consciousness and all
those right kinds of cases, but also doesn't get you US consciousness. I mean, maybe,
maybe the thing to do is develop that theory. Now, I don't know why we should take it as a fixed
point in developing our theory of consciousness that, okay, we know for sure the United States,
you know, it's not going to be conscious. If the theory implies that just check it out.
That would be a good fixed point to have if we had excellent epistemic reason for thinking
that group group consciousness was impossible. But as far as I can tell, our only real reason
for thinking it's impossible is it's unintuitive. It's contrary to common sense kind of doesn't seem
right. But that's not really compelling reason. The next subject that I was curious about is
involves Kant, who is who I don't I don't know nearly enough about. I mean, their philosophy,
as you're well aware, is a huge subject. And we inevitably even the 80 year old emeritus
professors who've been around for a long time have huge gaps. And Kant is definitely one of my
gaps. Now, I also know very little about cyberpunk, other than I have I have a vague idea of what the
aesthetic is. Right. So when when I saw that you were writing or thinking about the similarities
of Kant and cyberpunk, I was quite perplexed. Now, who or what maybe we should start here with
what cyberpunk is. Right. Well, the thing that your viewers will probably be most familiar with
from cyberpunk is the matrix. So lots of people. Oh, really? Oh, yeah, the matrix is a classic
cyberpunk movie. Really? Okay. Yeah, matrix is definitely I mean, top five movies. I absolutely
adore it. Yeah. So I mean, in the history of science fiction, it got I got started in the mid 80s.
Neuromancer by William Gibson is kind of like a very important central early piece of fiction that
was seen as cyberpunk. And yeah, there's this kind of aesthetic to it, which isn't really relevant
to the part of the picture that that I'm drawing philosophically. But what's one thing that's
central to a lot of cyberpunk, including Gibson, Gibson's Neuromancer and the matrix is that you
can plug in to a reality that is what we now call a virtual reality in which you can interact with
people. And that is super important. And that in some ways might be more important to ordinary people
than kind of what we think of as an ordinary reality, right? So you can jack in and you're
interacting and living in a totally different kind of world that's created by computers.
And you experience it directly, right? In the matrix, you know, that's the situation of ordinary
people, they don't even know that they're living in this kind of illusory world, right? In Neuromancer,
hackers intentionally kind of jack in to the matrix so they can manipulate computer programs and
hack in to security websites and stuff like that, right? So they know that they're in
they're in cyberspace. But that's the kind of idea. And then I can connect that up with Kant,
if you like, but that's the that's the please, please. Right. So, you know, Kant is open to so
many interpretations. So I don't I am not a Kant specialist by any stretch. But I think it's within
the realm of not unreasonable interpretations of Kant to think of it as having a certain kind of
kinship with this cyberpunk idea of plugging into a virtual reality or the matrix or cyberspace.
Right. And that is, you know, the critique of pure reason, the transcendental aesthetic
sees space and time and causation as not fundamental features of things as they are in
themselves, but rather as features that we bring to the world. So as a first pass version of the
analogy here, you could kind of think of it as if we are creating our own cyberspace or our own
matrix psychologically that we live in that doesn't really resemble fundamental reality as it is in
itself. Because the numina is just inaccessible to us in principle. Right. So the position that I
call transcendental idealism, and I think Kant is the most important advocate of it. But I think
he could be a transcendental idealist and without being a Kantian down the line. The position I call
transcendental idealism is committed to two things. One is that we don't know the fundamental nature
of things as they are in themselves. And two, spatiality is a feature that we bring to the world.
It depends on our minds. And if you accept those two things, then in my view,
you're a transcendental idealist. And that would be a that would be an alternative position to
materialism. In the materialist view, standardly, I think, right, spatiality is a feature of things
as they are in themselves. Now, this is where defining materialism gets a little complicated,
because, you know, there are some physicists who think that spatiality arises from the
informational features of things. And then how materialist is that really? What do we mean by
materialism exactly? But kind of your ordinary bread and butter materialist, you know,
protons, neutrons, fields, there are things that exist in space and have spatial property, spatial
location. So if you want to spend a little more time on it, I can give it one more, I can give
it another twist and kind of bring it together. All right, so please. So the the other twist is
to think about the theory of computation, right? So the theory of computation goes back to Alan
Turing in the 1930s. And there's nothing about computation that is inherently spatial, right?
In order, if you look closely at standard understandings of computation, you need states,
you need transitions among states, you need symbols, you need those kinds of things, but
you don't need entirely materially agnostic. It's agnostic about materialism, right? So you could
implement, and I in the book, I go through in detail how you do this, you could implement a
computer wholly in a non-spatial substance like a Cartesian soul, right? If you think of the Cart
traditionally thought that souls, immaterial souls existed in time, but not in space, right? Your
soul is not located in the center of your head or something like that. It's not a spatial thing.
It is a temporal thing, right? So you could have an immaterial soul that engages in computation.
Now, if you also hold that the mind
is a computer or could be implemented by a computer, as many people hold, but, you know,
not everybody holds, right? But a lot of people who like science fiction, you know, think, well,
robots could be conscious, right? That would be an example of a mind being implemented by a computer,
right? Now imagine it being implemented by a spatial computer, sorry, by a non-spatial computer.
What if all of reality is being implemented by a non-spatial computer, and we are just
software programs, basically, inside that non-spatial computer, right? So we're living
in a matrix or we're living in a simulation. The simulation, the matrix, is being implemented
by a computer that is not fundamentally spatial. It's informational. Maybe it's temporal,
but it's not fundamentally spatial, right? Then you've got a kind of a fundamental reality
that's just very different from how we ordinarily think, and to which we may not have any access,
really, at all, right? If you go down that path, that's not, you're not quite at
Kant yet, but you're getting closer. That's kind of the idea here, right? I'm not saying it's true,
but considering it as a possibility, I think, gets us interestingly close to Kant, using
modern science-fictional-type concepts that a very different type of
philosopher in person resonates with than normally resonates with, you know, 18th century philosophy.
So if you go down that path, then you can start to see how, oh, it might be the case that reality
is not fundamentally spatial. That spatiality is just how our minds make sense of some fundamentally
non-spatial thing that we don't really understand. I very much see how the matrix connects to this
idea of there being an inaccessible reality, but the part, the place where the matrix itself
no longer becomes the ideal example for this case is that you can become unplugged from the matrix
and leave the matrix and enter the aroused while inaccessible reality, right? But I saw that there
in your book, you indicate that there is experimental evidence for the existence of an
external world. And I had the sense, as I saw this chapter, that you were precisely referring to,
I mean, not necessarily just a brain in a vat-type case, but the idea that the world is a simulation.
And if that is the case, if I'm on the right track, what is the experimental evidence for the
existence of an external world? Why do you find this matrix picture convincing?
So, right, so to be clear about the aim in that chapter, the skeptical position that I'm aiming
to refute in that chapter is the view that the only thing that exists in the entire cosmos,
or at least the entire universe, is my own mind. So even if I'm in the matrix,
that would be, that's a strong form of solipsism. So even if I'm in the matrix,
solipsism would be wrong because something would exist other than my own mind, the computer.
So in that chapter, all I'm trying to do is move from
solipsism-compatible premises to an anti-solipsistic conclusion.
I haven't seen a philosopher who's really done that well and carefully. There have been attempts,
like Kant's refutation of idealism and Descartes' meditations, but I think those arguments really
don't quite work. Russell has done some stuff that I think is interesting, but also I think his
arguments are kind of undeveloped and problematic. You know, and there have been others, Fishta and
others, but what all I'm trying to do in that chapter is like, here I am with my stream of
experiences. Can I somehow break through that stream and say something besides this stream
of experience must exist? Maybe I don't know, have any idea what it is, but it's something
other than just me that exists. That is the aim of that chapter. And yeah.
Yeah, it seems kind of aimed at this Husserlian picture that all we really know is
our phenomenology, and everything else is really just a castle in a cloud or something like that.
But for the purpose of that chapter, I kind of take the Husserlian Cartesian starting point
as my own starting point, although in my earlier work, I don't agree with that at all. And in fact,
I don't agree with that at all. So this chapter is dialectically working in variance with some
of my other views. So, but you're right about taking that Husserlian starting point yet.
And how do you propose to break through that very, very thick wall?
So in that chapter, I do three experiments with the help of Alan Moore, who was one of my graduate
students at the time. Alan Moore? No, not the famous, not the famous Alan Moore.
I mean, you know, he should be famous. He should be the famous Alan Moore.
Are these three thought experiments? No, they're actual experiments. They're actual experiments
with actual data and, you know, statistical tests, right? I mean, I was at an APA meeting
with Alan. And we were like, wouldn't it be cool if you had like scientific p values that the
external world exists? And it wouldn't be fun to write a collaborative paper about solipsism?
So the, the, the, the idea of the paper, which eventually became the chapter with further revisions
was kind of this, this idea for a fun project of like collaboratively trying him trying to convince
me that the external world exists, including him, right? And could he do it? And could we do it with
like actual scientific experiments? So what we do is we try three scientific experiments. And
I won't describe all three. The second one in particular is really complicated to explain,
and I found that people have a lot of trouble understanding it. But the first and third are
a little easier. So in the first experiment, basically, what I do is I create what seems to be
a program in Microsoft Excel that will determine whether four digit numbers are prime or non-prime.
I generate a fresh set of four digit numbers. And then I guess,
is this one prime? Is this one prime? Is this one prime? I do that for 20 numbers.
And then I run this seeming Excel program. Now, I don't assume that Excel actually exists,
that there actually isn't a program or anything like that. I just do what seems to me
to be kind of the experience of doing this seeming thing in my head, of dragging down
the prime number function. And lo and behold, it lists the various numbers as prime or non-prime.
And then through laborious hand calculation, I figure out that it is almost entirely correct.
So it seems like there is something, there must be some explanation for how I experienced the word
prime and word non-prime next to these various numbers in a way that actually correlated with
their primeness or non-primeness. Even though at the moment, my best guess didn't align very well
with the non-prime. The best explanation I propose for that experience of seeing prime
next to all and only the prime numbers is that something in the world can calculate
prime numbers better than my, than I can do so in my own experience. And then I go through
various possible alternative explanations. This experiment isn't decisive on its own,
but I do think the easiest, most straightforward explanation of it, if we're open-minded about
solipsism rather than being committed solipsists or close-minded about it, is to say, well, look,
it seems like the best explanation is like maybe there is something out there that's like
better than I am at figuring out what prime numbers are. And then I do a couple other experiments.
The kind of the third and final experiment is I play speed chess with Alan and he basically
kicks my butt. And the best explanation for why it is that I'm having these experiences of like,
wow, that was a clever move that I wasn't expecting was, is that there's something in
the world besides that's better than me at chess that is set on defeating me. Even if this was
a dream, you know, I could imagine being drew, I could imagine a dream of being defeated by a
chess master. You know, but the thing about a dream is those chess moves won't,
they won't be real and clever in the same kind of way, right? I'll have a vague sense
that I'm being defeated, but I'm not going to be, I'm not capable of dreaming up a real
chess master's play, right? Any more than I capable of dreaming up the proof of Fermat's
last theorem, right? I could like dream that I wrote a bunch of lines and ah, I proved from
my last theorem, right? But it wouldn't like, you know, it wouldn't hold up, right? Whereas the
chess and similar thing for if I dreamed of being beaten by a chess master, right? So,
so these concrete specific moves that regularly surprise me despite my best efforts, right?
The best explanation for that appears to be that there's this thing in the world, Alan,
or maybe a computer program or maybe the matrix or something, but something out there is better
than the MHS, right? So that's the, so what, what we try to do in the chapter is just
do that rigorously, right? Really think about, okay, look, if we're being open-minded about
solipsism, what could the solipsists say? What kinds of possible scientific responses could the
solipsists give? How can we think through those responses, right? So try to give solipsism a
chance to, instead of just kind of casually say, as most people who favor inference to the best
explanation, style, style responses, solipsism, they just say, ah, solipsists couldn't explain
that. That's kind of what Russell does, just kind of casual, right? We try to give the solipsist
really a fair chance and then work through, okay, here's what the solipsists would have to say,
as a scientific explanation for this pattern of results, right? When you think about it,
doesn't seem very plausible, but you know, worth trying another experiment to, to see if we can,
you know, angle in on that a little better. That's the spirit of it. No, no, I really,
I really like that a lot. I mean, for, if you, if you wanted to maintain the solipsistic position
in the face of an argument like this, you would really have to provide a quite a drastic
re-understanding of, of what the mind is. I mean, compared to our, our contemporary scientific
understanding of it, to explain how there could be all of these regularities or maybe sensible
complexities, like a chess match out there that you, the, the Husserlian phenomenological subject
has no way of, of constructing yourself, right? I mean, one way to think about it too is think
about like a scientific theory when it's in trouble, right? It kind of, it predicts one thing
from the empirical evidence. The empirical evidence comes out a different way. It comes up with
excuses. It gets more complicated. It gets more implausible. And it's kind of like, comes up with
ad hoc explanations for why everything must be the case. And it's really complex, right? That's
the sign of a theory in trouble, right? And I think that's the position that Allen and I kind of
put solipsism in through this series of experiments and discussions of what could the solipsists say.
There's always something that solipsists could say, but it just gets so complicated.
Like by scientific standards, you're just like, okay, this just looks like a theory that's not
cutting it. Well, while, while we're on the topic about experimenting, you, you wrote a very well
known paper about the relationship between whether one is a moral philosopher and whether they
actually act more morally than, than the rest of the population at large.
Can we talk a bit about that and, and what the experiments or experiment that you
performed were? Right. I've done a bunch of experiments on that. I think,
overall, I've got something like 17 different main
measures and a bunch of measures. It's over a series of papers. Most of the papers are
collaborative with Joshua Rust, who's a former graduate student of mine, is a professor of
philosophy at Stetson University. Allen Moore is a professor at San Francisco State, by the way, now.
So, right. So, Josh and I were interested in the question of whether people who study ethics
behave any differently or more ethically than other people. And no one had ever studied that
systematically before. Right. People have opinions, you ask people, ethicists and non-ethicists,
other philosophers, other people in academia, everyone's got an opinion.
And it's an interesting question. I mean, I think most people, it's kind of interesting, right. And
a lot of people think it's obvious that they wouldn't or that they do or, you know, but,
but no one ever really looked at it systematically. So we decided to look at it systematically as we
could, right. Do people who study ethics, does it have any effect on their behavior that we can
measure, right. Do people who study ethics actually behave any ethically better than comparison
groups, right. And you got to choose the right comparison group. I think the right comparison
group two, there are two comparison groups that we normally use. One is other professors of
philosophy who don't specialize in ethics. Then the other comparison group we sometimes use is
professors in departments other than philosophy at the same universities, right. So by looking at
those comparison groups, you're looking at people who differ in their level of exposure to
philosophical ethics, but who are going to be similar in level of education, in income,
in social background, and lots of other stuff, right. So what we found over and over again with
a couple exceptions, which are worth going into if you're interested, is that ethicists don't
behave any differently than the comparison groups, not better, not worse, just kind of the same.
The kind of the most striking result for me about this concerned vegetarianism.
So what we found was on some issues, ethicists have more stringent moral views or more demanding
moral views, right. So ethicists were more likely than were other professors to say that it's morally
bad regularly to eat the meat of mammals. That was the way we phrased our vegetarianism question.
There are various ways you could phrase a question like that, no perfect way. So they were more
likely to say it's bad regularly to eat the meat of mammals. But when we asked them to self report,
did you eat the meat of a mammal at your previous evening meal, not including snacks,
they reported having eaten meat at about the same rate as did our comparison groups.
So we found a pretty big difference in opinion. 60% of the ethicists said it was bad versus 45%
of the non-ethicist philosophers and 19% of the non-philosophers, professors and departments
other than philosophy. So 60, 45, 19, pretty big difference. Did you eat the meat of a mammal at
your previous evening meal? I think 37% of ethicists said yes and 38% of respondents overall.
It was a little lower for the non-ethicist philosophers, maybe 30, low 30s, a little higher
for the professors and departments other than philosophy. Anyway, no big statistical difference.
So pretty big difference in opinion, not much difference in self-reported behavior.
So I think that's kind of interesting, right? So ethicists are more likely to say that's bad to
eat meat, but then they go ahead and eat meat anyway. I should say though, when I say this, so
there was a follow-up study done several years later in Germany that did find that
ethicists reported eating less meat at their previous evening meals as well as having more
stringent worldviews. So maybe they do a little bit, but maybe not as much as you would think,
given their difference in opinion. But anyway, overall what we found over and over again was
very little difference in behavior between ethicists and non-ethicists.
This I find very surprising, which I mean, well maybe you didn't, maybe you were one of those
people who didn't expect to find a difference. But just based on introspection, it surprises me
because I feel that the more that I think about moral issues, and again this is subjectively
measured, maybe other people who know me don't think that this is the outcome, but I at least
feel that I act much more morally. So I find this surprising. I find it surprising in a way also,
right? Because I think it is pretty compelling phenomenologically and anecdotally that sometimes
you think about ethical issues, you change your minds about things, and then you put them in
into, then you live according to it right now. And we chose vegetarianism in part because
that's one of the strongest cases for this, right? There are lots of people who say,
yeah, I read Peter Singer, I read James Rachel's, the arguments for not eating meat,
not eating factory-farmed meat are compelling, and so I stopped eating meat.
Lots of people say that, and I don't, it would be really strange if that was just systematically
wrong. So that was partly why we thought vegetarianism would be kind of the
best chance for finding a kind of a real effect. And we do have, actually there's another study
we did where there does seem to be kind of effects, so maybe sometimes it happens for
vegetarianism and talk about that. We found some effects with students, but
right, so lots of other stuff, like honesty, right? You know, oh, I read Kant, I decided I
shouldn't lie, you know, I should be more honest, right? That's kind of fuzzy, and you know, is that
really, do people like who study Kant's ethics, are they really less likely to lie? You know,
that I feel like, I don't know. But when someone says, look, I read Singer and I went from eating
meat to not eating meat, you know, I don't think they're lying. I mean, I think that probably
really did happen if that's what they said. So yeah, I find it somewhat surprising, especially
for the more concrete issues, especially vegetarianism and charitable giving, that we don't see
much or very consistent effect. And was there a philosophical, or did
you offer a philosophical explanation to what you found? Or was this purely to satisfy a curiosity?
And it was just something maybe you wrote a blog post to share results or
it started, how did you deal with the? Yeah, it started partly as just curiosity,
because it's an interesting issue. And it seemed like someone ought to study it very much, right?
Also part started partly out of my interest in classical Chinese philosophy.
I'm one of the things that I'm interested in classical.
Very nice background, by the way. Oh, thank you.
That might be Japanese. Yeah. One of the things I'm interested in classical Chinese philosophy
is the debate between Mungza and Shunza about whether human nature is good.
And Mungza says human nature is good. And what he means by that, in my interpretation,
is something like if you stop and reflect and really kind of authentically think about
moral issues and how to treat the people around you, you will find yourself drawn to do what's
morally good and revolted by what's what's evil. And what you need to do in order to develop morally
is kind of think, reflect, notice these reactions that you have of like,
yeah, it feels good to help somebody. Yeah, it feels yucky to like steal someone's umbrella or
something, you know, right? You notice that it feels yucky to be bad. It feels good to be nice,
right? And you cultivate that and right. So in this mention picture,
you think that what you said mentioned it, am I right that his we refer to him as Mencius?
Mencius or Mungza? Anglicization, right? There's two anglicizations for the same guy. Mencius is
the kind of older one and Mungza is the more contemporary one. What does that say about
how Confucius is in Chinese? Do you know? Do I know what about Confucius? Well, I'm guessing
that if Mencius is the anglicization of Mungza, Confucius is the anglicization of something else
and I never thought about that before. Kangza or Kung Fuza? Yeah. Oh, cool. Well, okay, I'm sorry for
cutting you off. Right. So, right. So, you know, I don't think it necessarily follows from Mungza's
view, but the part of me that's drawn to Mencius thinks, look,
and part of me that's drawn to ancient ethics in general, I think in the Western tradition
also is like, isn't an important part of ethics to like reflect and think about what's good and
like try to become better as a result and see what's good and what's right and do those things?
And could you really make intellectual progress in thinking about what's good and right and not
have any motivation to change or kind of become that way? Is there some kind of failure if you're
doing ethics in this completely abstract way that has no positive impact on your life?
You know, that kind of more ancient vision of ethics is attractive to me. So, I mean,
not that I, I mean, I think there's also room for weird abstract metaethics articles and stuff
like that. That's fine. Right. But like, most of us who teach ethics, it's not just all about
trolley problems and metaethics. I mean, you also teach students about racism and sexism and
charitable giving and vegetarianism and honesty and, you know, all those kinds of things that have
real that are, you know, relevant to your life decisions and shouldn't thinking about that have
some impact on what you do. And wouldn't it be weird if it did? So, yeah, so that's kind of the
frame of mind that I was coming at this from. And then I thought, you know, because that was my
background theoretical inclination, but then I saw people who are ethicists in my life, and they
seem like ordinary, right? They didn't seem especially good or especially bad. It seemed
like there's just kind of a mix of normal kind of nerdy intellectual people. Right. So, I thought
this is kind of, there's something incongruous there. What's really going on?
So, while we're talking about Mancha, you mentioned that you were interested about
in his debate with another person named, I think, Zhang Xue. And I don't think that's
Kong Xue, which is Confucius. Yeah, I know they're a little hard to pronounce.
Yeah. So, what did the second one, I won't pronounce his name, what did he have to say on
human nature? And how did how did his, yeah, how did he, how did his
dispute or disagreement or argument or debate with, with Mancha
Manifest itself?
Right. So, I think, I think when you're pronouncing foreign words that the thing that I like to do
is just get as close as you can with English phonemes, right? So, you don't need to try to
like get the tones right or whatever, right? But with English phonemes, with Mancha, it's like
think of it as like M-U-N-G-T-Z-U, Mung-Za, right? And Shun-Za, it's like S-H-U-N-T-Z-U,
Shun-Za, right? And Kong-Za, K-O-N-G-T-Z-U, right? Kong-Za, something like that, right? And that's
not how you, that's not how they're actually spelled, right? In the current aglomization,
but, but that's kind of think about it pronouncing them that way, right? So,
Mung-Za versus Shun-Za. So, Shun-Za thinks that he has a, he has a surprisingly secular
kind of modern view for some information China. It's really interesting. One of the things that I
think that you learn by looking at ancient Chinese philosophy, not in a super casual way,
just reading a few of the very most famous texts, but by like looking at it a little more deeply.
So there's a lot of diversity in it and there are a lot of different types of views represented and
you know this kind of picture that you see. Here's how Eastern people think, here's how
Western people think it's way too simple. The Shun-Za sees this as really interesting kind of
modern, almost modern in some ways, philosopher who thinks that morality is basically an artificial
social construction. He says, you know, ancient people figured out what kinds of social structures
led to an orderly society and morality is basically teaching the next generation those
social structures and people have no attraction to behaving in those ways. What people want naturally
is like, you know, pleasure and fun and good tasting food and sex and power and all that kind
of stuff, right? You kind of have to force them to abide by these social structures that we've
discovered make society run well and if you just let them follow their inclinations, it's going to
be chaos, right? So he's got this really kind of secular social structure view of morality.
Well, that was all very fascinating, very cool to listen to. It's always nice to
learn more about the philosophy and other cultures since we're very west-centric in our
philosophy departments. I just talked to Peter Adamson about Islamic philosophy at length and
that was really great. But returning to the question that all this emerged from, are you vegetarian?
No. I'm an example of the kind of ethicists that I'm talking about, right? I think at this
point I've done enough ethics that I think that in some sense, although it's not my main focus,
I kind of am an ethicist by the standards that I apply. And right, I kind of, my behavior is kind
of the modal normal thing, right? I think it is a little morally bad. I mean, I don't think it's
extremely bad. I think it is a little morally bad non-ideal to eat the meat of mammals or eat factory
farmed animals. And yet I do continue to do it.
Well, then now really returning full circle. We started off the cyberpunk discussion that
turned into all these other things and then ended up with vegetarianism. But we started off by
talking about The Matrix and I mentioned that it's one of my absolute favorite movies. And before we
move on, I'm just curious if there are other aspects of The Matrix that you find philosophically
compelling that we didn't touch on? No, it's really that main idea is the idea of this artificial
reality is the one that I find most interesting from The Matrix. I haven't even seen all of
The Matrix movies. I'm not a big Matrix nut, so I couldn't get into the exact details of how it all
works. My taste in cyberpunk is a little more Greg Higgin and William Gibson.
Then maybe I guess we'll return back to animals, but you have a chapter about
whether there's something it's like to be a garden snail. And you pressed me a little bit when I
talked about there being a narrative center of some sort to a rabbit. So I'm curious about how
you approached the garden snail in particular. Garden snails are really interesting for a couple
reasons. So I think they're a really interesting test case for thinking about animal consciousness
because people's intuitions diverge. We're talking about common sense as a starting point. So one
of the themes of weirdness in the world is that common sense is going to mess up. But still,
I think it's got to be a starting point for philosophy. For any area where you don't know
what you're doing, you start with common sense. That's the default position and then you see
what happens. You start from common sense. Everybody thinks you've got a cat in your lap.
Everybody thinks cats are conscious. I mean, there are a few nutty philosophers who have
some doubts, right? But basically, we all think cats have conscious experience, right? And most
people don't think that bacteria are conscious or trees, although there are some people who do
think that. But when we're talking about common sense, cats are in and bacteria are out. But garden
snails, people are mixed. I would say based on just kind of informal asking around in my social
circles and my subculture, maybe three quarters of people will say, oh yeah, garden snails,
I think they have experiences. I think they can feel pain or taste things. And about 25% are like,
no, they're basically just plants. They don't have any experience. They don't have a sense of self.
There's no phenomenological center going on there. So opinions are different. It's not a kind of
obvious commonsensical from a commonsensical point of view. It's not an obvious yes or no.
So that makes an interesting case in thinking about animal consciousness questions.
So they're interesting in that way. The other way they're interesting is they're weird.
So okay, they've got in our colloquial sense of weird or well kind of in both senses really.
So their central nervous system is only 60,000 neurons. That's tiny, like an ant.
A little more than a nematode, but very tiny. It's like an ants got a quarter million.
So it's like, oh, wow. It's a lot less than an ant. That is very surprising.
And furthermore, these neurons that they have in the central nervous system,
they're in kind of clumps of ganglia around their esophagus. They're not even all that interconnected.
Oh, quite bizarre. So I haven't found like the United States of animals.
Kind of, I don't know, right? Now they do have a lot of peripheral neurons. They've got like,
you know, maybe a quarter million one way peripheral neurons, especially from their
posterior tentacles that terminate, you know, so nerves here. Yeah, input nerves, right? We
don't usually think input nerves are where consciousness happens, right? Happens in the
central nervous system. Normally, right? So, you know, so there's that, like most of their nerves
are in their posterior tentacles instead of, well, they don't even really have brains where
they got clumps of nerves around their esophagus. At the same time, they engage in some pretty
sophisticated behavior for having such a, so few central nervous system neurons. Like,
they have home ranges that like have homes where they nest and they will wander around
through their home range and then come back to their nesting place. And if you, if you just place
them, you know, throw them, right? You know, you know, 10 meters away, they'll find their way back
and they're not just doing it by kind of, you know, if you think about like single cells,
single cell animal, single cell entities will, they'll tumble, you know, and they'll move toward
attractive things in a way from, but they don't have like systematic exploration, right? Whereas
snails have that. The other thing is like their sex is really complicated. They are simultaneously
like they, they're, they're sexual intersexual behavior. Yeah. They're sexual. Of course,
it's really complicated. They're, they're simultaneous hermaphrodites, right? So they
have both female and male genitalia. If you pick up a snail, you might be like, wait, where's the
penis? Yeah, it's like, there's this, basically, you might think of it as the side of the neck.
There's like this pouch in there that is normally inside the body. And then it kind of comes out,
right? And there's a penis and a vagina in this pouch, right? When they're sexually aroused,
convenient, right? So mating takes about on average, like seven hours. So what you get is
you get two snails and they'll, they'll kind of, they'll contact each other and then pull away,
and they'll kind of taste each other slime trails. And then like either continue the mating thing or
break away, right? They'll, they'll kind of touch or kiss their, their front tentacles. Sometimes
they'll take little bites out of each other. And then they'll shoot love darts. They'll shoot love
darts at each other, right? So these are centimeter long arrows made of calcium covered in mucus,
and they'll shoot them at each other. And like they hit about half the time or a third of the time,
right? When they hit, it's not hitting in the vagina or anywhere. It's just like going into the
skin, right? They shoot love darts at each other, sometimes hit, sometimes miss, right? The mating
kind of continues. They try over and over again to insert their penises into each other's vaginas,
you know, and mating culminates when they manage to do that simultaneously. And then they kind of
transfer each to the other a spermatophore, which is like sperms plus nutrients. The receiving
snail will then like basically digest almost all of the sperm.
Well, they're both receiving, right? They're both receiving, right? So they'll each digest,
like just eat basically most of the sperm that they received. And they'll do this then several
times, typically, right? And then after they've made it several times, they'll, they'll dig a shallow
hole in the soil with their heads and they'll ovulate down to the soil and deposit eggs from
their various mates. Now, mates whose, whose darts have hit, more of the eggs will have been fertilized
by mates whose darts have hit, right? So one of the theories is that the mucus on the darts
protects the sperm of the shooter from being digested at, at as high a rate as, as it would
have been at the dart mist. So then they, so then they ovulate down into the soil and this is the
hole that they dig and then they cover it up and then they leave, right? This is super complicated.
Yeah, I never thought 60,000 central nervous system neurons and they're doing this.
Mm hmm. I never thought I'd find soft core snail porn narration so enthralling. I think you should
really consider writing a romance novel. You should see some of my science fiction.
Slightly strange sex is, is not an uncommon theme in my science fiction.
Nice. I'm sure you waited until you had tenure.
Yes, I did. Actually, yeah, I did. Now, so what then?
So you've, you've, you've made a very good case for this being weird. And I'm curious
how you develop the philosophical discussion around this question of whether or not they're
conscious. So here's the kind of core argument prior to developing a theory about consciousness.
I don't think it's obvious or should be obvious whether garden snails are or are not conscious
based on the description I just gave.
You know, it's kind of attractive to think that they might be conscious, right? And, you know,
the more complicated the behavior, you start to relate to, relate to them. And, you know, like,
in my heart, I kind of like hope and think maybe they're conscious. That's where I would
bet if I really had to, but you don't want anybody to be missing out on that, right? But man, you
could also like concurrent computers can do pretty sophisticated things. And toy robots can do pretty
sophisticated things. And your enteric nervous system, your gut is lined with half a billion neurons,
way, way, way more than a garden snail. As many as a small mammal, right, just line your, your esophagus,
your stomach, your intestines and controlled digestion, right? And it can operate even when
it's severed from the central nervous system. We don't normally think that your enteric nervous
system is a source of consciousness, right? So there's like, you can have pretty complicated
behavior, you can have pretty big neural systems that, you know, at least most people would say
they're not conscious, right? So maybe the snails kind of like that, maybe it's kind of not conscious,
like we think a toy robot is not conscious, or it's not conscious, like we think a,
a computer is unconscious, or it's not conscious, like we think the enteric nervous system is
unconscious. I think that's a reasonable point of view. That's also a reasonable point of view
to think, well, maybe they are conscious, right? We could give an argument, we could kind of give
the intuitive argument for that if you want, but I don't want to get too much into that because,
you know, we don't have so much time. I think that's where people are a little bit more drawn
anyway. So I think you could come up either way, kind of on kind of armchair intuitive
grounds, right? So if we're going to settle the question of snail consciousness, we need a theory,
we need a good theory of consciousness to apply to the case. But then here's the problem.
To develop a theory of consciousness to apply to the case, you need to make some background
assumptions about approximately what kinds of things are conscious, right? Some theories of
consciousness that you see on the market by philosophers or neuroscientists or psychologists
or computer scientists are plainly liberal in the sense that they're going to let lots of things
count as conscious. Other theories are plainly conservative in this, in the sense that they're
going to require really sophisticated cognitive structures for something to be conscious.
So you have one of these liberal theories that says basically, well, as long as you've got a body
and, you know, you can kind of distinguish your own body from the environment and not eat yourself
and kind of have a sense of position, right? You know, then you're conscious, right? Something
like that, Merckers theory, maybe, you know, then plainly on that kind of theory garden snails are
going to be conscious, right? Or if you take a theory that requires some kind of sophisticated
self-representation like a high-roader thought theory, you know, garden snails are not going
to be engaged in high-roader thought, right? They don't have representations of their own minds,
probably, right? So what's going to happen is in order to develop a general theory of consciousness,
you're going to need to make some background assumptions about in broad strokes, at least,
what kinds of things in the universe are conscious and what kinds of things aren't.
And as soon as you do that, you beg the question one way or another about garden snails.
So we start in ignorance about the consciousness of garden snails and then we end up in ignorance
because we've got a bunch of theories and how attracted you are to the various theories is
going to partly depend, to a substantial extent, depend on your prior opinions about whether things
like garden snails are sophisticated enough to have consciousness. So it's going to just basically
kind of end up in a circle, kind of like Agrippa says, right? So I don't think that we have enough
common ground. I call this a common ground problem. I've got it. There's some other
complexities to this, right? But just one of the problems, I call it the common ground problem,
right? In a lot of areas in philosophy, there's a lot of common ground, right? So if you look at,
say, epistemology, there's a lot of common ground about like what counts as an instance of knowledge
or an instance of ignorance, what counts as a good justification, what counts as a bad justification.
There's, of course, disputes, right? But, you know, basically, there's a lot of agreement about
straightforward cases. And the disputes are, you know, where the interesting fights are,
right? But there's a lot of common ground. Or if you look at ethics, there's a lot of common
ground. Another thing I think you can learn by looking at ancient Chinese ethics is you read
Confucius, and it's like, this all fits common sense, right? It's not like reading some alien
document. This is as far as you can get from having, as far as you can get from contemporary
Western culture and have a large written body of ethical documents, right, is basically ancient
China, right? It's as far as you can get culturally from us, you read Confucius, and you're like,
yeah, I basically agree with almost all of this. It seems pretty common sensical, right?
So of course, there are lots of disputes and ethics, but there's so much common ground.
But that's what we don't have in common. So, so, so philosophers can resolve things because they
can appeal to the common ground, kind of figure out what's going on in the middle. In consciousness,
there just isn't that common ground, right? You go all the way from some people who are pan-psychists
who think consciousness is ubiquitous, consciousness is everywhere in the universe,
literally everything is conscious, right? This is an increasingly common view, right?
Two people like Peter Carruthers, Dan Dennett, who are like, humans are conscious,
apes, dogs, maybe, right? Oh, really? Yeah. I wouldn't have thought Daniel Dennett would say that,
but I'm not a dispute. He's a little, he's a little cagey about it. There are moments where
he seems to be saying that, and there are other moments where he's not. I'm not,
I find him a little bit confusing on that. And Carruthers also has shifted his
view over time on this a little bit. So, I think the best way to characterize both Dan and Carruthers
is like, not totally clear on whether dogs and apes are conscious, you know.
Definitely not going to go all the way to snails, for sure, right? If you got doubts even about
dogs and apes, right? So, that's huge, huge, huge difference in starting opinions about
consciousness. We're not going to find the common ground. If you, any theory of consciousness
you're going to be attracted to, you're going to be attracted to partly to a substantial extent,
because it fits your initial inclinations about broadly how widespread consciousness in the
universe. If you've got really liberal inclinations, you're not going to like, you know,
higher thought theories, and you're not going to like, you know, views where you need to have a
narrative self or something like that, right? Whereas, if you've got much more liberal views,
you're going to have no problem with snail consciousness.
Yeah, I think Dennett actually has a book called From Bacteria to Bach, and I think he,
he's going to say, Bach is conscious, bacteria, not, and as you mentioned, if somebody's not,
if somebody's not going to allow dogs or apes, they're certainly not, well, maybe not certainly,
but probably pretty certainly not going to allow a snail and definitely not a bacterium.
But you mentioned that at the beginning, I think at the outset, that even you're probably going to
write off the consciousness of a bacterium. So, if I'm putting words into your mouth.
Yeah, no, that's my inclination, right? I am on the skeptical side. So I don't totally rule out
panpsychism. One thing I think we, I wish people did more as philosophers, was just have a little
more sense of what we might think of as their credence space. Like, you can invest a little bit
of credence in positions that you think are not likely to be true. Well, here is where I was going
to go if you wanted to. So, so like panpsychism, I think it's probably not true. It's definitely
not where my bet is. But that doesn't mean that I just think it's absurd. And I don't think there's
any chance that it could be true. So I think, you know, it's healthy. And one of the things that I
hope for in my book on weirdness, actually, right, is to do what I call disjunctive metaphysics.
A disjunction is a series of statements connected by the word or this or that or that or that might
be true. Right. So, like, think about what possibilities there are that are worth a little
bit of like, okay, this could be true. Maybe it's not where my money is. But it could be true.
Maybe it's worth a 5% credence or a 10% credence. Right. So why not have panpsychism there,
say with, you know, 5% of your credence or something like that. That's how I think about it.
The reason that I stressed the bacteria and was going to talk more about that is I actually
recently just got Twitter, maybe a couple of weeks ago, and you were one of the first people I
followed. And I, according to Twitter, you recently gave a, I'm going to quote,
a defense of the intrinsic moral value of alien microbes in the solar system,
should any exist, even if they lack sentience. Yes. And I'm curious about
what that is and what that, why you're distinguishing moral value from our microbes.
Yeah. Right. This started when I was invited by NASA and the Library of Congress to go to
Washington DC to meet with NASA scientists to talk about the ethics of exploring the solar system.
And there are a lot of NASA scientists who think that it's not unlikely that we will find microbial
life. Icy moons are the hot thing now, not Mars. I mean, maybe Mars is too dry, right? But
under the surface of the ice of Europa, you know, and maybe the warm oceans
in Europa, right? Maybe. Or other icy moons, right? So there's a lot of scientists that
they know there's a decent chance. There's a pretty good chance. Some scientists think
it's quite likely in the next 10 years that we will find microbial life in the solar system.
There's also evidence, you know, there's also a whole series of approaches where you look for
evidence of life on distant stars, on planets around distant stars by looking for signs of gases
in planetary systems that were likely only to exist if there were a life on that planet, right?
So that's a whole other research strand, right? But there are people in NASA who think, you know,
there's a decent chance we're going to find evidence of microbial life. So one of the things
that we're talking about at this meeting was, okay, well, let's say we found microbes on Mars
or on Europa, like, what's our attitude toward that? And some people seem to have a very
exploitative attitude, like, you know, well, great, let's do some science, right? And, you know,
let's, you know, they'll be fascinating to study. We don't have any particular ethical
obligations not to disturb them, right? And there'll be, there were some other people who were like,
man, if you find life on another planet, let it be, don't touch it, right? If you know Star Trek,
right, kind of the prime directive, right, don't mess with life from another planet, right? Let it
be its thing. And I found myself with a moderate version of the latter view, right, thinking
if there are microbes on another planet, my inclination is to think we should not treat them
as casually as we treat the microbes in our own bodies, like when we take, take antibiotics,
right? I don't feel any guilt about taking antibiotics. But man, if we wiped out, if there's
one patch of life on Mars and our probe lands there and blasts it and wipes it out, now life
is extinguished on Mars, I'd be like, that's not, I wouldn't want that. That'd be way worse in my
mind, ethically, than taking antibiotics. So then, so why is that? It's not because I think microbes
are conscious. And it's not because more subtly, right? Some people said, well, they might not
be conscious now, but it could be that microbial life would eventually become conscious life,
and we've got to give it the chance to evolve, right? That, I mean, that's a reasonable thing to
think, right? But I guess I'm not thinking that as the only reason that we might care about microbial
life, right? My inclination is to think that there's something intrinsically valuable about life
on another planet that's worth respecting. And that is kind of just an intuition. I don't really
have an argument for it, other than to just kind of state it and invite you to agree, right? Not
everyone's gonna agree, but I think a lot of us, when we think about it, me at least, some of my
friends and maybe you, right? Think, you know, there's some pull in that. Here's one way to think
about it. Here's one way to kind of just massage the intuitions a little bit. I think of this as
the distant planet thought experiment. Imagine there's some planet far away from us on the other
side of the galactic core. We'll never interact with it. We'll never see it. No connection with it
whatsoever. What would you hope for from that planet? What would be a good for that planet?
Was it good if it's a sterile rock? Or would it be better in some way, would the universe
somehow be better if that planet had life on it? And I'm inclined to think, yeah, you know,
the universe would be better if that planet had life on it. Not anything to do with our interests
or the interests of any conscious organisms, right? Just the universe is richer, more wonderful,
more awesome, you know, in virtue of having life on its planets. Awesome. Well, on that note, then
I'll just ask one last question for my own curiosity. You are, we started off by talking
about what a prolific author are, author you are, and I think the conversation shows
what a diverse thinker you are. I'm curious, what are your writing and work habits like
that you're able to put out so much? I love to write. You know, a lot of people
do other stuff and procrastinate the writing. I like write and procrastinate the other stuff.
Like this week, I wrote a new science fiction story, I like, I was supposed to be doing all
this other stuff. Like, I'm kind of irresponsible with some other stuff, but I really like I wanted
to write this story. I think for me, it's like, I want to write, I just, it's my priority,
I carve out the time to do it and I work other things around it. So it's like, it drives me.
So it's not a particular habit or schedule or discipline or anything like that. It's kind of
the undisciplined, I'm just like, now I'm gonna do what I want to do. So is it, it's not painful
for you then? No, I love writing. To write. I love writing. Okay, that's amazing. That's great.
Okay, well, what a great way to end this. Thanks so much for joining me. This was,
this was really fascinating on all levels. Yeah, thanks for having me. It's been a fun chat.
