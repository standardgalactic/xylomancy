I will speak today about a measure theoretic approach to negative probabilities, it will be a complimentary talk to that of Acasio earlier today.
I'll first start setting the mathematical background and the intuitions or concepts that are behind these mathematics and then I will jump into some technicalities of the negative probability approach based on measure theory.
So suppose that you have a probabilistic system, it could be an atom to fix ideas, but it could be any other thing that you're observing.
And then you perform measurements. So this drawing here represents a particular type of measurement.
Each measurement will have or experiment at one performance will have outcomes. I wrote only three of them here but this is quite general it will be any number of different outcomes. So these are the outcomes of a particular experiment.
But when one considers the set of outcomes one conform an outcome set and from an outcome set one gets a Boolean algebra of events associated to that outcome set.
And a probability will be nothing but a measure satisfying Kolmogorov's options, as was explained in Jorge Hirsch's talk the other day.
So I will not go into the details because this was discussed several times in this conference, fortunately.
But if you don't get any of this you can of the maths of this, you can think about it as a dice or a coin so each empirical context so each each concrete experiment that you perform on a system on a probabilistic system will define a set of probabilities.
And mathematically, we describe this using the notion of a measurable space, which consists of an outcome set the Boolean algebra and a measure that behaves pretty much like in measure theory as if it were an area as in the best game.
So, Sigma is a sigma algebra but what is important for us is that it is a Boolean algebra.
So the distributive laws called a random variable is nothing but a measurable function. If you don't have the mathematical details of a measurable function at hand seem think simply about an observable in classical physics like the energy or the, or any other quantity.
But what it is important is that with this mathematical formalism, one has a well defined probability theory that allows to compute mean values and probabilities of any event in a rigorous way so this is called Mogorov theory.
So this experiment keeps place to a called Mogorovian probability theory.
But one can perform other experiments I represented this symbolically using another drawing.
And there are many different types of experiments that we can perform on a probabilistic system. Some of them can be performed together.
Some of them can be performed on this one and this one but some of them cannot. So, as it happens in quantum theory, we cannot measure a spin of the system in two different directions at the same time.
So, some experiments are jointly measurable and other experiments are not.
And ends up in a, in a sort of matrix like this. This means that on each row of the matrix, we have experiments that can be performed together. So this one, these two can be performed together, these two can be performed together, and so on.
But if one mixes elements from different columns, they cannot be performed together. This is the most general situation in any empirical probabilistic theory. Quantum mechanics is just a concrete example of this.
And what is important for us is that for for each pair or shortly measurable experiments that exists a classical probability model.
By that I mean a call Mogorovian probability that allows me to describe the combined experiment, but you don't have a global classical probability.
You can describe all possible experiments. If you try to do that, you very quickly reach into contradictions or things that might not happen in the world, like for example as happens in the belly inequalities.
So I put this here with mathematics right this was with withdrawing, but now I put the same with mathematics you have random variables on each row.
And the idea is that some experiments, for example, this one here, the arrow can be performed with this one.
But also with this one, but there, but the same experiment, the same empirical procedure appears in two different contexts.
That is one of the most important characteristics in quantum mechanics. There are experimental procedures that are the same, but in different contexts.
One can say that contexts or measurement contexts defined by rows.
So just the ones I am showing you here.
Context are intertwined. Why because they share things.
So, each experiment is described by a call Mogorovian probability space, but also each row of the matrix.
By that I mean a collection of compatible random variables that can whose experiments can be performed together will have also associated a measurable space for all the random variables that might be not that there might not exist.
This is the global classical probability distribution, but notice that these random variables F11 and F14 are essentially the same, because they have the same content and are defined by the same empirical procedure.
They might not be a priority identified because they belong to different contexts and this is very important in statistics because it might lead to two problems if one don't have, if you don't have that into account.
So one has some observables that belong to different contexts.
What is the status of the observables that have the same content but belong to different contexts. Well, in principle, one could try to identify them to put an equal sign between them.
This is very usual in physics. Why, because the marginals, even if they belong to different contexts, the marginal are the same, given that they are the same, you can identify them and not having too much trouble.
Notice that this is the no signal condition. The marginal probability for this will not depend on the context.
But some authors say that they are different because this is a natural assumption in a statistics because in general, in a general probabilistic theory, this might be seen.
So the marginals, the probabilities associated to this particular experiment could be different.
Fortunately, it doesn't happen in quantum theory.
With Acasio de Barros and Desio Krause, we propose to consider them as indistinguishable.
And we combine this notion with the mathematical formalism of quasi set theory.
Usually an identification takes place. So one, one, so one can see that contexts are intertwined. So C1 cannot be performed at the same time with C2.
If one chooses to perform experiment C1, one cannot perform experiment C2.
So a quantum state will give us a collection of classical probabilities, one for each context.
But we know that contexts are intertwined. So we have quantum observables, maximally compatible quantum observables define context.
So one has an injection here, a kind of embedding of Boolean algebras. This is a Boolean algebras and this guy here is a Boolean algebras too.
And for Boolean algebras, we have classical probabilities. For each observable, a classical probability, and for each context, a classical probability.
But the thing is that given that context are intertwined, this is not the end of the story.
So we know that there is a mathematical object that contains the information about all possible contexts.
This is the lattice of projection operators of the Hilbert space. So a quantum state is not a classical probability, but it is a measure on the non Boolean lattice of projection operators acting on the Hilbert space.
One, the glissons theorem makes this diagram commutative.
Why? In quantum mechanics, as I said, we have a global object.
That contains the information about all the contexts and correlations. It is very useful in practice.
If you would only stay in the classical description, it will be very difficult to deal with quantum phenomena.
The great step forward of quantum physics is to build a non commutative probability calculus that allows us to give a unified description for all possible measurement contexts.
The story will not end up there because we know that there is more. The projections are elements of a ring of operators and due to glissons theorem, all these diagram commutes.
There are at least two ways of describing global states. An object like this, this guy here is a measure, and this guy here is a density operator, but remember that they are the same because of glissons theorem.
The first alternative is the one just described, to paste Boolean algebras and end up in a non Boolean structure and define states as usual in quantum mechanics or in quantum logics.
One can speak about automotor lattices or partial Boolean algebras, but the second alternative, and it is very important in physics.
And so I will explain why I mean it is to keep using Boolean algebras and create here a Boolean algebra, but allowing this measure to be negative.
This is a move that is very important in quantum physics.
Why negative probabilities are so important in physics. Well, they have a long tradition in the history of physics.
And it knows the beginner quasi probability distribution and its applications.
And Iraq also studied them in the context of energy, for example, he says, negative energies and probabilities should not be considered as nonsense they are well defined concepts mathematically like a negative money.
So Feynman tried to dig into the mysteries of negative probability, he says trying to think of negative probabilities gave me a cool cultural shock at first, but when I finally go easy with the concept, I wrote myself a note so I wouldn't forget so.
The question says, well, there's a video of Peter shore explaining that he attended to a lecture by Feynman, and he was thinking that allowing negative probabilities would allow to understand the EPR paradox, and of course he was right to a great extent.
So, but the most important thing for us is that many relevant applications in quantum optics, quantum contextuality and quantum information theory, rely on dealing with negative probabilities.
So, even if you like it or not, if you're a practicing physicist is very likely that you find yourself working on negative probabilities or trying to read a paper that deals with negative probabilities because they are a very useful practical tool.
So, now I will turn into a joint work with Professor Acasio de Barrios from the San Francisco State University about negative probabilities.
Let me explain the motivations first. We started to work on contextuality and we were wondering what will be a general definition of negative probability.
Of course, there are many in the literature, but we wonder whether it was possible to give a definition which is based solely on measure theory, as in Kolmogorov's actions.
So we wanted the, the negative probability version of Kolmogorov theory, is that possible. And importantly, we wanted it to be independent of any Hilbert space structure.
So we don't want to rely in the quantum formalism. Another question was how to incorporate the notion of context from the very beginning. This is very important, the notion of contextuality.
And the other question was to study connections between indistinguishability and negative probabilities.
The details can be found here in this publication. It's from the last year. But now I'll give some some idea of the definition and its technical properties.
So the simple move will be instead of using Kolmogorov's actions to use just a sine measure, which is the same as Kolmogorov, but one allows this measure to take negative values.
Now we don't put the evaluation into the zero one interval, but we allow all possible real numbers. This is, so this triplet here will be called a sine measure space.
But of course, there's a problem here because in quantum mechanics, we need contexts.
Where are contexts in this definition. They are not included. So we need to find, we needed to find a definition that incorporates from the very beginning, the possibility of having measurement contexts.
So one way that we found was starting with a sine measure space, define the notion of an extended random variable, which is the same, pretty the same as a random variable, but now define over the sine space.
So now the pre image of every open interval or everybody said will be just a measurable set associated to this place, but the measure could be negative up to now.
This is very usual, but now it comes to the idea that I think that changes the setting because what we do is to consider a family, a collection of extended random variables defined on a family of sine probability models.
What we say is that the general context will be a subset of this family. So a context will be a collection of random variables.
Notice that there exists a sub sigma algebra of the algebra associated to this family of of of sine probability models in such a way that when the probabilities are restricted to the sub sigma algebra, they are classical.
So, for all F for all event in this sub sigma algebra this try and becomes a classical probability space and the random variables of that context are classical random variables with regard to that measurement context.
So, let me put now an example suppose that we have three random variables, and the three of them are not compatible so you cannot perform an experiment in which the three of them are measured together.
So, you can measure X and Y, Y and Z and X and Z, but not the three of them at the same time. So what you have is for each pair for example X and Y, you will have a classical probability space for Y and Z a classical probability space depicted here in red and for X and Z.
Another classical probability space depicted in green, but the whole thing is embedded in a Boolean algebra.
Sigma. So this Sigma one is a is a sub algebra of Sigma Sigma two and Sigma three they are sub algebras and Omega is the same. And this is done in such a way that when move the global measure when restricted to the black circle here is a classical probability
and coincides with P1 and the same move restricted to the red circle coincides with P3 and so on.
But move is not necessarily positive, it might take negative values. So this allows us to describe
negative probabilities and surprisingly it includes many physical examples of interest like the beginner transform can be described in this way.
But this way is not dependent on the Hilbert space formalism, of course, and also the very inequalities and many other examples. So with this definition, we think that we capture the notion of
the textuality of having contexts that are not necessarily compatible between them, but with the global shape that might take a negative values.
Assigned probability space, also called the negative probability will be assigned measure space and do it with a non empty set of context in the sense of the previous definition, the measure will be assigned probability or a negative probability.
This is for example, what happens, I showed you here for example, X and Y, how to build a Boolean algebra for the two of them.
So this is how the Boolean algebra looks like, and the probability assigned to them will be a measure defined here, as in measure theory.
And of course one can go on and add more variables, X, Y set and create a Boolean algebra. So our algorithm, what it does is to compute first a global Boolean algebra for all the random variables, even if they are not compatible.
But then, in that global Boolean algebra, we define a measure which might take negative values.
So how would that work for the three random variables? Well, one ends up in a family of equations, these are linear equations. The inputs are the mean values of the random variables.
One has for example, the mean values of single random variables, and here one must solve these equations for the piece, the piece are the probabilities associated to the elementary events.
One also can consider mean values of products of random variables and so on.
Depending on how much information one inputs into this system, one might have one solution, many or none, it depends.
But the thing is that one ends up in a linear system and using the input one can solve this linear system and find all possible negative probabilities that are compatible with the input statistics.
So this is how our general definition describes families of non-compatible random variables. But there's something important. In this definition,
we are using measure theory. So there is no restriction to finite models. I am explaining things using a finite model, but with the atomic random variables, but this is not restricted to finite sets.
So it is pretty much a single model of theory. So you have a very nice measure theory going on.
So I'm just about to end. So what are the advantages? Well, the advantages of this approach, it can be used to define contextuality measures.
So this is done by quantifying how negative is your state. And it includes previous examples of non-signal models as particular cases.
The probabilities never appear in experiments. Only concrete contexts represent what actually happens.
And it is possible also to define an entropic measure in the usual way.
So it is a usual way in quantum logic. You just take a sort of convex rooks on all possible measurement contexts.
How will that be in the in the very inequalities? Well, Jorge Hirsch was talking about this the other way. Not so explicit about negative probabilities, but he described how to build a hidden variable model for a bell type scenario.
So if one proceeds that way, one ends in a Boolean algebra, as in bell, and a classical probability. Well, of course, bell stops because he cannot go on.
He says, well, it doesn't exist. It leads to a contradiction. Of course, of course, because quantum mechanics cannot be described by the global classical probability measure.
But if you allow for negative probabilities, and this was a clear intuition of Feynman, so you can find a solution.
You will get a lot of equations. These are linear equations. They look bad, but it's very simple. And you find that actually a singlet state will be described by the negative probability.
So we have a general universal framework for dealing with negative probabilities that includes, as far as we know, most examples of interest.
And it is based on measure theory, a single model of theory, but it is an extension that allows to describe contextual theories. So it seems to us that to understand contextuality is deeply related to understand how contexts are intertwined.
And how global states and event algebras emerge. The identification of random variables among different contexts seem to play a key role in their genesis.
There seems to be an indistinguishably indistinguishability principle at play. Why?
Let me come back to this slide here. In order to build a global boonial algebra, I have to assume that this random variable x is the same when I consider it in context y, x, y, and it's the same when I consider it in context x set, and so on for y and set.
That is very important. So I have to identify random variables that have the same content but belong to different and incompatible contexts.
So we have discussed the general features of a measure theoretical approach for describing quantum states and our approach makes boonial algebras and allows for negative probabilities.
If you are interested in this approach, you can go to some of our previous papers, especially this one last year. And I thank you for your attention. That's all.
Okay, thank you, Federico for the talk.
If there are questions, you can express it in the chat and give you the word. It is a question from Alison Tessin.
Hi.
So, can you hear me?
Yes.
Okay, so thanks for the talk. And when you discuss quantum predictions from this perspective, do you take into account the spectrum of operators or you assume that outcomes, the value doesn't matter?
Let me see if I understand your question. I'm just when I speak about projection operators, I just speak about the usual thing that you do in quantum mechanics. Quantum mechanics observables are represented by self-adjoint operators.
In the finite dimensional case, they are Hermitian.
And of course, a particular sub-family of the Hermitian operators or self-adjoint in the infinite dimensional case are the projection operators.
So it turns out that these mathematical entities have a very precise structure with ease that they form a lattice.
So with projected operators, you mean the physical interpretation of what do you mean?
So, if I understood it correctly, you represent measurements as random variables, correct?
Yeah, I understand. Now I see your question. Now I see. Let me explain you something that might make it very clear.
Look, let us start the other way around because I went from the basics to the most complicated. But let's suppose that you assume quantum mechanics, standard quantum mechanics.
Okay, then you have a ring of operators. That's trivial, right? Okay, so now you have a density operator that gives probabilities for all observables here, right?
So, it turns out that if you restrict to elementary tests, like yes, no questions, like for example, is the photon inside this box or not?
You represent that by a projection operator.
But each context, each context, so each time you have a family, a maximal family of compatible observables.
If you look at the projection operators associated to that family, they form a Boolean algebra.
Do you agree? Okay. So that's elementary. So then these are the Boolean algebras here in this round.
But these Boolean algebras are sub algebras of an algebra which is non-Boolean.
So, each quantum state when restricted to one of these Boolean algebras defines a classical probability model.
This is why you can perform experiments. Otherwise, you wouldn't be able to do nothing in the laboratory.
You do experiment and you just consider a family of compatible observables, you will have a classical probability.
But the whole thing is not classical because there is no joint global probability distribution for all the possible contexts.
But notice the move that we do here. This is standard physics.
This is what every physicist do. But also physicists do this.
So what you can do is not to create the quantum logic. Don't do that. Don't go into the ring of operators, but go into the beginner transform.
For example, when you have the beginner function, you transform the observer and you have P and Q in the same space. You have a phase space and a negative probability in that space.
This is another way of representing quantum mechanics and quantum states, which turns out to be equivalent. That's very interesting.
So what we do here is to get independent.
We get independence of the Hilbert space formalism, and we give a general measure theoretic definition of probability that allows contexts, but allows also the probabilities to take negative values.
And when you restrict to the well-known examples, you will get, yes, the usual, the beginner distribution. That's the idea.
Okay. And can I ask you one more question?
I don't know. Ask Sebastian. I don't know if we have time. Sebastian.
There are two more questions.
Okay, I can wait.
You can surely send me an email, Alison. No problem. We can keep, yes.
We can keep discussing that one.
Yes, yes.
Thank you.
Thank you for the talk. I, every time I hear you again, I understand a little bit more of the kind of proposal that you have in mind.
Okay, so I was just curious if we can go back to the last part of your talk where you were making reference to Bell's theorem and the problem with how he assumed how the distributions worked.
So here's the thing.
You attribute the problem to the idea that he is somehow assuming classical probability, right?
It's one of the problems. There are many problems, right? One of them is that he assumes classical probability. Yes.
It's not a problem. It's an assumption. Yes, it's not a problem.
Perhaps that's the answer to my question. But my question was this.
It seems that what you're denying basically is the idea that you can have the same distribution over the lambdas, irrespectively of how you, how Bob and Alice measure.
Is that correct? You are basically denying the assumption of settings independence.
Well, no, because if you allow them to be negative, you can have the same.
You see what I mean? That's what I'm saying.
Okay.
I'm telling you that one of the key assumptions, and this was, this was, well, this was even, you can look it on YouTube, for example.
It's very nice how Peter Schor tells about it.
He says that he attended to lecture by Feynman, and Feynman said that.
One of the main problems is that you're assuming a classical probability, and there are many ways of assuming a classical probability.
I mean, there are many, sorry, there are many different ways of not having a classical probability. So Bell assumes a classical probability.
Correct.
So, one might say, well, what are the assumptions that are wrong? One possibility could be, well, the world is not local.
I think some people believe that there are hidden variables and that the world is not local.
It's a very good reasoning, it might be.
But it might be that using positive probabilities is not the best.
I mean, what should suffice?
That's a very deep discussion, not in quantum physics, in the foundations of probability theory, and it was never easy at all.
What are the right rules for probability?
So, it is presented sometimes as a mild assumption, but if you know about this, it is not.
I think it is not. I mean, you cannot present it as a mild assumption, that's what I think.
So, one way to play is to go into negative probabilities. Of course, some other people will say no, not go into negative, just use a non-commutative probability theory.
That could be also.
Okay, perhaps we can talk in another moment, but my suspicion is going to be that in the end, what is really happening, but it's really, really, really the cost of the problem is the idea that you are writing the distribution of lambda independently of the settings of A and B.
Of course, yes, but well, that's one of the things, right, in, yes, but you can, what I'm telling you is that you can do that, you can actually do that, and allow the probabilities to be negative, and then you will not derive inequalities.
But the thing is that you don't need to talk about the probabilities, you can stop with saying that the distribution of lambda depends on what is going to be measured by Alice and Bob, and you can stop the theorem.
The theorem doesn't go.
Yeah, I know. That's the usual way to deal with the problem, right? That would say, I mean, an orthodox quantum physics will say, well, it's not the classical probability calculus.
Stop assigning values to things that are not measured, stop mixing results from different contexts and assigning global probabilities, because this is what we know from the very beginning of quantum mechanics.
Which if you don't say anything else, that is a mystery, right, because it is another discussion.
We have some minutes for the last question from Benendix.
Thank you, Federico.
I found it very interesting, even exciting talk.
Thanks.
I'm still shocked by the negative probabilities.
So I can understand that you have a mathematical scheme here in which the negative values of the measure occur and that that makes it possible to combine all these different contexts.
I would, I myself would object to using the word probability for the negative measures, if you combine these contexts, because probabilities have to, I have to interpret main interpretations.
One is relative frequencies.
And the other is a measure of belief, the credence you can attach to a certain proposition, and neither of them applies to this negative probability.
So it, in my opinion, these negative probabilities do not qualify as probabilities, they are just mathematical quantities that are signed measures.
I agree with that.
But I feel and that links to the comments you made on one of the previous question.
I think there are very good reasons for the common core of axioms, and especially for the axiom that the probability should be between zero and one.
So, to cut things short, my question is why do you insist on, on calling these negative values probabilities.
If for me it's obvious they are not probabilities.
Now, okay, good question. Thanks. Thanks, Dennis.
Let me clarify things because there are, there are several problems here. One is the interpretation of negative probabilities, which have scored, of course, in is problematic.
In this case, it's not so problematic, because we don't claim that you will measure negative probabilities will we will never ever measure a negative probability that's nonsense, you will not.
What you will have is context, you have a very clear here in this definition, a very clear mathematical definition in the sense of called more of, of mathematical of measurement context.
This is independent of quantum theory that's what I why I like this.
So, on each measurement context, you will have classical probability and that's what you observe in the laboratory.
But, at the same time, it is reasonable to call, you can call it instead of negative probability or sign probability or, I don't know, you can call it the way you want the interesting point is that this is a natural
mathematically, it's a very natural extension of Kolmogorov theory that incorporates the notion of context from the very beginning as a mathematical concept.
That is very important for me. And let me tell you why.
You know that negative probabilities, even if you don't want to use them as a as a nice interpretation that are pretty useful in quantum optics, I mean you, you end up dealing either way or the other with negative probabilities in physics, especially in quantum
information, and especially if you want to study contextuality, because usually you want to look at the properties of quantum states.
And one way of studying contextuality is to look at the beginner distribution and see how negative it is with regard to a family of observables, for example, or for example, classicality.
If you want to study if your system reaches the classical limit or not, a very usual tool is to look at the, how, how negative is the, the, the beginner distribution.
So we think that with this definition, we can give the other definitions of contextuality that can be useful in practice to understand better for example why quantum computers have a speedup.
But now we are working with Elisa Monkietti, she's starting her master thesis and we try to apply these mathematical tools to study problems in quantum information.
That's the goal. And it is very difficult to escape from that because you cannot tell a guy from quantum optics, no, don't use, don't use quasi probabilities, don't use the beginner distribution.
No, people will will continue using it, even, I mean.
So, so with this work, we are not claiming that you should replace standard quantum probability by negative probability. No.
So, but we think that this approach will give us at the technical level clues to understand better a quantum contextual. That's what we think.
Thank you.
Thanks.
Okay, thank you for your talk, and thank you for the people who participate, making questions and comments.
