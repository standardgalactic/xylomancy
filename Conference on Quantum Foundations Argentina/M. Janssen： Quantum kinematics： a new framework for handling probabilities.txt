Okay. Okay, welcome to the second part of the conference of this day. The first talk of this
session is in charge of Michael Jensen from the University of Minnesota. The title of the talk
is quantum kinematics, a new framework for handling probabilities. Go on, Michael.
Okay. Thank you very much for the invitation. Everybody can see my screen. I hope you had
a chance to read my abstract. So what I'll be doing, for the most part, is to talk about
like the correlations you can get with the proverbial Alice and Bob performing measurements
on two spin half particles entangled in the singlet state. And I'll represent the class
of correlations that you can get in that kind of, like I should say, in a setup that was suggested
by David Merman where Alice and Bob both choose from the same three observables that they're going
to measure. And I'm going to be looking at the kind of correlations that are allowed in that setup
if you just restrict it to like anything that's non-signaling, anything that can be do quantum
mechanically and anything that can be done like with local hidden variable theories. And I'll show
you that there is a nice three-dimensional like a graphical representation of that. So the work
is based on a book that I wrote with Michael Janis and Michael Faro. So here is the three of us,
like in Minneapolis a few years ago. And since the names of the three of us are sort of variations
on Michael, like this has become known in certain circles already as the three mics manifesto,
the book will come out in January. It's in the series Boston Studies in the Philosophy and
History of Science and its official title is Understanding Quantum Raffles. Now the book
was inspired and this is the banana that you'll be seeing as my background image throughout the talk
by this book by Jeff Boop, Banana World, Quantum Mechanics for Primates. And here you see a picture
of me and Jeff at a conference in 2019, like in Santiago, like following actually write this
conference in Cordoba in 2019, where I also gave the talk and had a great time. So I should also
like put in a plug for like the sequel to Banana World, which is one of my favorite books. It's a
serious comic on entanglement by Jeff and his daughter Tanya, a graphic artist called like totally,
totally random. So here's the set up I want to talk about. And so instead of talking about
spin half particles, I'm going to be talking about like entangled bananas, like in honor of Jeff's
book. And so what we have, we start out with like a pair of entangled bananas, so they are described
by the usual, you know, singlet state. And then like Alison Bob, you know, the side like on one
of three ways to peel the banana. And so this is basically just window dressing for like, you know,
they have they have like a Dubois magnet with which they measured spin in a certain direction.
And now they're going to hold their banana in a particular direction, you know, while peeling it,
and then they take a bite out of the banana and determine whether the banana tastes yasty, tastes
yummy or nasty. Right. So and the results are we're going to, we're going to put like in a
correlation array, which is really the workhorse of Jeff's book, Banana World. And so here you see
like, you know, Alice can measure A, B and C, Bob can measure A, B and C, they can only find, you
know, plus or minus corresponding to a yummy and nasty. And what you see is that if they happen,
all the runs in which they happen to peel the same way, they find like a perfect impact correlation.
And in all the runs in which they peel different ways, they find like an imperfect like positive
correlation. Right. So look at A, B. So there is like, you know, like a three fourth chance of them
finding the same 75% chance of finding the same, and only a 25% chance of them finding opposite.
And the question is like, you know, like what's how to how to account for this.
Now, so this is like what you get in this Merman setup, if the angles between like the
peeling directions are like 120 degrees. Now you can consider like a more general
correlation array of this sort. And we're going to consider like, you know, any array
that would like this, that would be non signaling, right. And in order to guarantee non signaling,
if you have these anti correlations like on the on the diagonal, it has to be the case that you get
uniform marginals. And you do that by by making sure that in all the off diagonal cells, the sum
of both the two rows and the two columns is equal to a half. Right. And so since the probabilities
of course also have to be like numbers between zero and one, you get that you can parameterize
this by these guys that I have here, and these guys can run for all the way from minus one to
plus one. Right. And so I can characterize this correlation array by having three of these of
these parameters for for three of these cells. Right. This thing is also going to be symmetric.
It doesn't matter if you switch like a and B. So that's the that's the story here.
And you see that in the special case that is considered by Merman, that these guy values
are equal to minus a half. Right. So stick that in here. If you put in like minus a half like
this would be, you know, three halfs. So this would be three eighths. Right. And this would be,
you know, like, you know, one eighth, right. So you recover that you recover that Merman
correlation array. But again, like, you know, you, you, this is a more general form of it.
Now, what we're going to try and do is to see like how like what
subclass of those correlations, we can simulate, like with a raffle, right. And the raffle is
or our toy model for a local hidden variable theme. And so we have we imagine that you have a
basket with a bunch of tickets in it, and the tickets like half the outcomes for like all
possible measurements that Alice and Bob can do. Now look at the first ticket, like, you know,
we know that if they if they measure the same way that they find opposite results, right. So
like, you know, the results on two halves of the tickets have better be up has better be opposite.
The way it works is that you take a ticket, you rip the ticket in half, and then you randomly
decide like which one goes to Alice, and which one goes to Bob, right. So a ticket where you
just switch the left and the right side does not give you a this does not give you a new ticket.
So with that said, there is like four different tickets, right. So it doesn't have to be the
case that all the pluses are on one side, you could have a case where two of the pluses are on
one side. And like, you know, with one minus. And again, there is three ways of doing this,
right. So you have the minus here is for C here, the minus is for B, and here the minus is for A,
right. And again, keep in mind that it doesn't matter which side of the ticket you're looking at.
Now, we could easily see like if you had like single ticket raffles with just like a basket
with one one type, what these sky parameters would be, you know, for your correlation array,
because you can see that if you have this ticket, no matter whether you take like a a a b or a c,
you always have like a perfect anti correlation. And that means that these chi values have to be
like plus one, maybe I should go just like back here, right. So the moment that that chi is plus
one, right, then you see have an anti correlation, the moment that chi is minus one, you have like
a perfect correlation. So okay, so so that's easy. Now look at this ticket, there's a little more
complicated. So for a b, you see that there's still a perfect anti correlation. But if you now look
at a c or at b c, you see that there's a correlation. So you have minus one. And the same is true for
C and D, right. It's just that a different parameter will get like the the plus and the other two
parameters will be minus. And here then you immediately have like a bell inequality of the type
of the class of horns, your money holds variety. And you can see that, you know, like the the the
sum of these three parameters is three for ticket a, and it's going to be minus one for all other
tickets. So if you take like an arbitrary mix of tickets, right, you would always get like a value
somewhere between minus one and three. So and you see that Merman's example where chi where these
three kinds of minus a half. So that would be if you sum them would would be minus three halves
violates this inequality. Now, the nice thing about this is that you can come up with a very
nice geometrical representation of the situation. And that is essentially due to Jeff's long time
collaborator, now deceased, unfortunately, Itamar Petovsky. And so, so first of all,
we start out with like, you know, like representing these sky values, they can run from minus one
to one in like what is called like a non signaling cube. Remember, like, you know, this was like
the general form of a correlation array that is non signaling. And you see that these tickets,
like they're represented now by a vertices of that non signaling cube, right. So it's these four
points, right, A, B, C and D. And a mixed raffle would be represented on like points that are like
somewhere in between, right. And once you have so imagine like, you know, you have your your basket
with tickets. So if you take this and this and you put a certain mix, you can end up end up somewhere
over here. But then you take a mix of like, you know, D and C, you get up somewhere over here,
but you can also like, you know, now mix those right. So you get all of that. And you can also
like mix and match, mix and and get like on the inside of this thing. So this is like what is
known as the classical tetra tetrahedron. And this is like a very nice way of of geometrically
representing, you know, the what what the local hidden variables here we can do the bell in the
quality only corresponds like one facet of this of this of this tetrahedron, it just says that
you can't be behind that that plane like B, C, D, but you see that there's three other
forbidden regions that you would also have to spell out if you want to define fully, you know,
what is and what is not allowed. All right. So now in what is allowed by quantum mechanics, right.
And so in quantum mechanics, the the result that is predicted by quantum is that these
kais are just given by the cosine of the the peeling angle, right. In a way, this is like
very satisfying, right. So classically, you see that these kais with these tickets, they're always
going to be plus one or minus one. But wouldn't it be nice to have like a theory that just allows
like a like a continuity of values between minus one and plus one quantum mechanics gives you just
that. Right. And so it's the cosine of the of the angle. And that cosine, of course, is the inner
product of like unit vectors in these different peeling directions. All right. So if you think
about this correlation array, you see that the entire correlation array can be like characterized by
these parameters, right, these sky parameters. And we can also introduce them for the for the
for the diagonal cells, where they're just one. Okay. So and so we'll I'll I'll define this more
carefully later on. But these kais are like, you know, what what can be called like anti-correlation
coefficients. As for now, it's just hinges on three values, right. If chi is one, we saw you have a
perfect anti-correlation. If it's minus one, you have a perfect correlation, right. So it makes sense
that the anti-correlation coefficient is then minus one. If chi is zero, you have no correlation at
all. Now look at introduce now like a matrix, an anti-correlation matrix of just these chi values.
And you can write that again, like in in terms of these inner products of these unit vectors.
Now, this is a grand matrix, right. And it's a well known property of the of the grand matrix,
it doesn't take too much to verify this, but in the interest of time, I'll skip that.
We know that the determinant of that of that matrix is going to be it's going to have to be
greater or equal than zero. And if you just calculate the determinant of this here, you now get this
condition. Okay. So quantum mechanics like imposes the condition that that you know that this inequality
has to be satisfied. Right. So put differently, right. So quantum mechanics, once you have the
idea that these chi values are the cosine of the of the peeling angles. So you can you can specify
like the correlation array by just giving me three angles. But basic geometry tells me that once I
pick two of these three angles, it puts constraints on the third. And this one, this is the constraint
that it's that it imposes. And if you now like plot this, you see that what this picks out is an
elliptope, or you know what it's been called sort of a fat tetrahedron, you puff it up a bit, the
lines here are contained in it. But like, you know, in the middle, like it's it's it's blown up a bit.
And we call this like the elliptope inequality. And this then is sort of the quantum analog
of the of, you know, what the CS, the CHSH inequality in the case of the Merman setup,
right. And remember, for the full specification, we don't need just one, but we need four of those
inequalities here, we only need one nonlinear inequality. And this inequality is satisfied
by Merman's example, right. I mean, if you just look at it, you see that this, if you put in a half,
you get like exactly that this is going to be equal to zero.
So this is actually a neat result, I think, because like it gives a concrete example of
like a cartoon that you often see about how the convex set for, you know, non signaling quantum
and local hidden variable theories are related. Right. So so here is the here's a cross section
of our drawing, right, with the non signaling cube, the elliptope and the tetrahedron, right.
And now compare that to like the cartoon that is in Banana World, right, where you see like
the non signaling cube with like, you know, like the maximal variation, like a Perpeco-Rohlich box,
right, was a super quantum correlation that still is non signaling and doesn't violate special
relativity. Then you have the quantum convex set, and then in the middle you have the local
polytope. And the beauty is, is that in this particular example of the Merman setup,
you reproduce like now exactly, you know, what you just have as a cartoon in general.
And you can play the same game for bananas now entangled bananas of higher spin. And so in our
book we do this, right. So here's what the correlation array looks like, just one cell for a spin one
banana. The anti-correlation coefficient, it turns out, you know, which is defined like this.
I'll get to that in a moment, like stays the same is still the cosine. If you go for two,
three halves still the same cosines. So all these correlations are all like constrained by the exact
same elliptope inequality. That's not the case if you now try to simulate them with these raffles.
So we saw that, you know, like if you do this for spin half, you get like the tetrahedron,
right, so you get something with like four facets like this. If you now go up to higher spin, you
see that you get a little more structure on these facets. So this is what it looks like
for spin one. And notice that this point here is going to touch the elliptope.
For spin three halves, it's not going to touch the elliptope again, but for all integer spin,
it will, right. You see this gets more and more faceted, more and more vertices. And like you
can, it's very suggestive that if you go up to higher and higher spin, it gets more and more
close to the elliptope, but never quite gets there, right. Now the, so so far it may seem
that this elliptope somehow captures like something special about quantum mechanics,
in particular, like we used, you know, sort of as hidden like in what I showed you,
what we use like, you know, the Bourne rule, the Hilbert space formalism. But in fact,
this inequality is not new to quantum mechanics at all. It has been known to statisticians since
the 1890s. And it's basically a general constraint on the correlations between any three random
variables, right, which also like, you know, makes it understandable that even if you go to
higher spin particles in quantum mechanics, you'll never get out of the, get out of the elliptope.
So this work is due to Carl Pearson, and mostly to Utney Yule. So Pearson, of course, these days
is mostly remembers for his dubious role in the eugenics movement. But he's also like, you know,
like a very important character in statistics. So let me run to this quickly, right. So now
we're talking about sort of arbitrary random variables with sets of possible outcomes that
I'm going to keep discreet. And in fact, I'm only interested in a case where you have a,
you have a random variable with only two outcomes, like, you know, yummy and nasty.
And so I'm going to restrict my attention to what we call balanced random variables.
And that just means that if x i, x sub i is a possible value, minus x i is two, and that the
probability of x i and the probability of minus x i is the same. And that simplifies matters because
that means that in that case, the expectation value is going to be zero. And that simplifies
like some other variables that some other quantities that we're interested in. So we're
looking at the variance, right? So the expectation value of x minus the expected value of x squared.
If the expected value of x is zero, then the variation of x is just the expectation value
of x squared. The standard deviation is the, is the square root of that. And then the covariance,
again, like, you know, in general would be like the expectation value of x minus the expectation
value of x times y minus the expectation value of y. If these two expectation values are zero,
then that is just going to be equal to the expectation value of x times y.
And I now introduce like what is called the Pearson correlation coefficient,
which is just the covariance of, so the Pearson correlation coefficients of x and y
is the covariance of x and y divided by the corresponding standard deviation sigma x and
sigma y. And so if x and y are balanced, this is just the expectation value of x and y divided by
these, by these standard deviations. And you can immediately see two properties like, you know,
the Pearson correlation coefficient of a variable with itself is just one. And it doesn't matter
if you look at the correlation coefficient x, y or y, x. And we'll now, I'll now prove for you that
such, such, any triplet of such variables is going to have to satisfy this elliptop inequality.
And this was shown by Yule in the late 1890s. So here's where, here's one way to do it, like,
you know, consider, you know, for any triplet v1, v2, v3, like this quantity over here. So I'm looking
at the expectation value of some expression squared. So I know this is going to be greater
or equal to zero. And now I'm going to work this out. Okay. So I take, like, you know, like,
this term times the rest that gives me this here, right. And so notes that I now get, like, you
know, v1, and then I have, like, x times x, right, expectation value x squared divided by
sigma x squared. And then we have the x times the y, the x times z. And then you have similar
terms for, like, if you now do the v2y over sigma y and v3z over sigma c. And you see that in here,
like, you have, like, all these Pearson correlation coefficients, it just looks like that. Right.
And I can write this, like, a little more concisely and compactly as just this matrix
with these Pearson correlation coefficients sandwiched between, like, you know, the column vector,
v1, v2, v3, and the row vector, v1, v2, v3. And remember that this thing has to be greater or
equal than zero for any, for any value of v1, v2, v3, which means that that matrix row is
positive semi-definite, which means that the determinant of row has to be greater or equal
than zero. And it follows that, you know, that that's just elliptope inequality. Right. So there we
have it again. Okay. So now look at the special case that x, y, and z are the taste of Alice's
banana, right, in this experiment in the, in the Merman setup. Right. So x is the, the taste of
Alice's banana when she peels in the A direction, y is the taste of Alice's banana when she peels
in the B direction, and z is the taste when Alice's banana when she peels in the C direction.
All right. So now the obvious problem is, is that as Papescu points out in the, in the preface or the
forward of banana world, a banana can only be eaten once, right, once it's peeled, it's peeled,
once it's tasted, it's tasted. But there's, we'll see there's ways around this, this, this problem.
So first I note that these variables are balanced, right. So we have to now give them some numerical
value rather than just yummy or nasty, but you know, inspired by spin, you know, like instead of
having like a half h bar, we now have like a half, like a B bar, you know, which I call the banana
split, which is just boops constant B divided by two pi, and we're going to pick units such that
B bar is equal to one. And so then, you know, these, we see that these, that these variables are
perfectly balanced. The expectation value is zero, the variance, right. So it's like, you know,
half, half the time, like, you know, it's the product is, it's, it's, it's one half squared,
the other half, it's like, you know, minus a half squared, and that adds up to one fourth,
the standard deviation, take the square roots, that is like a half. Now the covariance here,
it's a little trickier. And what we're going to do, and like, you know, if you, if you're
squeamish about this, like we did find a way to avoid like this counterfactual reasoning.
But I think it's perfectly innocuous. We're going to use the opposite. If we want to
find the covariance of the variables, Alice, Alice's taste of the banana when peeling a,
and the taste of Alice's banana when peeling b. So half Alice, appeal a, and then have her use
minus what Bob finds when he peels b as a proxy for what she would have found had she peeled b instead.
And so basically, like, you know, that, so we, we use, we calculate this thing here,
and we can use our correlation array to figure this out. Right. So we have like, if the, if the,
if the tastes are, are the, are the same, we get, we get, we get like one fourth. What is the probability
of that happening? Well, you need to add these two things, right. So that's a half one minus
chi a b. And then, you know, like, if the opposite is minus one fourth, and the probability of that
happening is this, if you work this out, you see that this is one fourth times chi a b. And if you
now like calculate the Pearson correlation coefficient, you see that that is exactly equal to chi a b.
Right. I already took an advance on that result calling this chi a b like an anti correlation
coefficient, right. And the anti is because of this minus. All right. So the elliptope inequality,
you know, I can just now write for this, for these particular variables, right. So in terms of these
rows down internally, rather than these guys. And so this is just exactly the same.
But there is a few problems, right. So the first problem we already dealt with, like,
how do we determine the taste of these two of a Alice feeling a and Alice feeling b in one run.
Well, you know, have her use Bob's result as a proxy for one of those. Right. Now, the second
problem is like, you know, we can only do this for two tastes for two feelings in one run.
Well, that's not a big problem, either. Like, you can just have different ones. Right. So
if you think about it, that's what we always do, you know, like you like if you think about the
early tests of the CSS H inequality, they weren't switching the settings like, you know, from run
to run, you just take measurements for one pair of setting and then fill in another pair. That's
all perfectly fine. So that we can do the third problem seems to be a lot nasty. And there the
problem is, is that, you know, that we we derive this elliptop inequality from the condition starting
that this the expectation value, this quantity is always greater equal than zero. Right. But the
point is that we cannot determine the value of this in one in one run. And it would seem that
if if all these three variables like can only take on values like plus or minus a half, that yes,
it's going to be greater equal than zero. But that inequality is not tight, because like, you
know, like we could easily the smallest we could get this is to something like, you know, a half,
like, you know, like a state plus and minus, minus here, and then we have a quarter. So this took
us a while to to to figure out and the the the answer actually hinges on like, you know, like
an interesting property of quantum mechanics, namely that in quantum mechanics, it's perfectly
possible for a sum to have a definite value, even if the individual terms in that sum do not.
Right. So the simplest example I can think of is like, you know, the Hamiltonian
for harmonic oscillator, clearly p and q cannot have like, you know, definite values at the same
time. But, you know, the Hamiltonian can. And so to look at this a little more clearly, right, so
if you if you were looking essentially at sort of a sum of like her mission operators, a linear
combination, and that in and of itself should be like a good operator. And so if you introduce
like, you know, now like analogy with a spin vector, like a taste vector, you get, you can write
like the taste in the a direction as like the inner products of like T with like the
unit vector in the a direction same for TB same for TC. And then the inequality becomes this and
you see that we're in a product thing like the the taste vector with this vector. And this will be
zero whenever this combination is zero. Right. And so if you if there are if you pick the right
peeling directions for starters that need to be in one plane, you can actually like achieve that.
So this this inequality is tight. And this result applies to so the general result of yield does
apply to to this to this quantum example. All right. So what do I want to conclude from this?
Okay. So the point is, is that this elliptop inequality that we derived first within quantum
mechanics from the geometry of Hilbert space can also be derived without quantum mechanics
as a general constraint on correlations between three random variables. And is this this distinction
like actually we've got from within from without from a song by Bob Dylan.
So the message then this is the big message of the of the of the talk is that what this suggests
is that the basic Hilbert space formalism of quantum mechanics is just a new framework
for handling probabilities. Right. And so this take on quantum mechanics, which has been dubbed
boobism is a pun on cubism by Robert Mischewitz belongs, I think, to a class of informational
makeovers of the much maligned Copenhagen interpretation. And so in order to to make that
clear, like I want to talk, I'll take five more minutes to make the point. And this is far more
speculative and tentative than what I've said so far. I think it's best to sort of think in terms
of like a genealogy of quantum interpretations. And so we got like two versions of quantum
mechanics around 1925 26. First, we have matrix mechanics and Heisenberg's big discovery was
that these problems in spectroscopy that he was running into, just call for a new framework for
dealing with with physics, just as like the problems that people had run into in electrodynamics
around the turn of the century, called for a new framework of dealing with spatial temporal.
Relations. Now, of course, a little bit later, like Schrodinger comes up with wave mechanics,
and his big discovery compatible with Heisenberg was very different, like, namely,
here, the idea is that something wavy is underlying the behavior that we're seeing,
and the analogy here is with wave optics in the 19th century. And so they famously didn't care for
each other's for each other's views, like, you know, like Heisenberg calling wave mechanics
disgusting, and Schrodinger calling matrix mechanics repulsive. And but of course,
like mathematical equivalence was rapidly proved in part by Schrodinger himself,
but then by the rock yard on for Neumann. And that kind of papers over like a very different
way of thinking about the state, the status of the state vector in the Hilbert space.
And I think roughly you can say that the descendants of wave mechanics, those are the
antique interpretations of quantum mechanics, think Everett, the de Broglie bomb pilot wave theory,
and the Gerardi, Romani, Weber spontaneous collapse theory. And the descendants of matrix
mechanics are the epistemic interpretations in where I would include Copenhagen, Cubism,
and now like, you know, bubism. And so just a quick way of sort of showing, you know, what I'm
what I'm after, like contrast boop with Everett. Right. So for boop, like what the Hilbert space
is doing you is doing for you, it's giving you the born rule. But it doesn't represent stuff,
right, in order to represent stuff, you need like some specific quantum applications running on this
new quantum operating system to use kind of the metaphor of Nielsen and Chang's book on quantum
information. Now for Everett, it's just the way it's just the other way around. Hilbert space gives
you stuff, you know, Sean Carroll, like says, like, you know, the world is made out of wave functions.
Right. So, but it doesn't give you the born rule now. Right. I mean, so for that, they appeal to
decision theory for agents in a multiverse. Okay. Now, so this is Oxford Everettians,
there's also another class of Everettians, Berlin Everettians, like Christoph Lainer,
who really have the courage of their convictions, who use like Hilbert space,
both to represent stuff, and to get the born rule. And of course, as a good Everettian,
like you take advantage of the fact that in a multiverse, you really can have your cake and eat it
too. So now for a more careful exegesis of all of this, you know, I'm going to refer you to our
book, where especially like, you know, micro faro, like, place this out, like much more patiently
than, than I just did. And I'm going to leave you like with one more version of this, of this Dylan
song.
Now, right, I'm happy to take some questions if there's time.
Yes, we have some minutes for comments or questions. If you want to make a comment or question, please indicate it in the chat.
I have a short question.
Do you think that, or my real question is, if you have some experience in the classroom with this type of
topological approximation mechanics, do you think that it can help in education?
I'm just making sure. Do you think the question is like, do you think that this way of thinking about quantum mechanics can help education?
No, that this, this form to present some results with the topological forms can help in education of quantum mechanics in the, in the courses in the university.
Yeah, no, I mean, like, I'm currently teaching a course on introducing like non physics majors to quantum mechanics where I very much use this, use this approach that I showed you, right, and so and like, yeah, and so but it, it's, I mean, it gives you like a particular way of thinking
about quantum mechanics, right, it really pushes this idea that quantum mechanics is like a, you know, the kinematics of quantum mechanics, right, the basic formalism is a new framework for handling probabilities.
Right, and that's, you know, in order to do anything else right now you need to do dynamics you need to like introduce like stuff, right, and what quantum mechanics is telling you that it had to, that it has to behave according to the rules of quantum.
Right, so so that's, that's the view on pushing. Historically, what I find interesting is that if you now look at modern books on probability theory and statistics is that Hilbert space methods are being used in these books, and somehow like, so as a historian
I'm very interested like how it came to be that there seems to be very little communication between people in physics using Hilbert space methods, and people in general statistics using like Hilbert space methods.
Thank you.
There is a question from Federico Holig.
Thanks, Michelle for for this wonderful talk. It's always great to hear you. I always get really excited. And I want to learn more about this approach. And my question is related to what is the stake or the take of your interpretation with regard to non locality, because if you interpret quantum
quantum mechanics as a new probability formalism.
What can you say about the strong claims that the word is local versus the word is non local. What will you say about that.
Yeah, so so the, that's a difficult question.
So what I would say is that, you know, in the spirit of what I showed you is that, you know, like you would, you would have thought that special relativity like requires you to, you know, like tell some story where you can like screen off like any correlation
with something you know that by a common cause. And it turns out that the constraints are not that tight you can have like, you can have like a very much more liberal constraint and still be non signaling in fact you can go beyond quantum mechanics, and you can have like
And so, I would say you just have to get used to the fact that you should resist the temptation that when you have these like correlations that cannot be dealt with sort of the standard way screening them off by conditionalizing on common causes that you think of these as just
not being produced by natures and not like, Oh, Alice does one thing and then like you know like it travels like instantaneously to to Bob or vice versa.
And if you, if you, if you go for this, if you go this epistemic route, that is easier, right, I mean like I think a lot of students in quantum mechanics, who, you know, like no matter how, how often you tell him that a Schrodinger, that the Schrodinger wave function is not a field on ordinary space,
you still have this picture like well then you do a measurement and the whole thing goes poof, instantaneously, and like now you're stretching your head like you know what is it that is traveling from like Alice to Bob that then like frustratingly you can never use to send a signal.
Right and so I'm hoping that this approach will sort of prevent people like you know from going down that particular rabbit hole in the first place.
Okay, thanks, thanks, it's clear. Yeah, I tend to agree. Yes.
