Okay, welcome to the session number two is now I have the pressure to present to Kevin
from the University of Albany and he will talk about quantity with uncertainty
defines the basics of quantum mechanics and spacing.
All right, great. Thank you for having me. Hello, everyone. And yes, I'm doing this. This work has been
I've been working on this with John Skilling from Ireland and so we'll dive right in as long as
everyone can see my screen here. So this work basically takes advantage of a slightly different
perspective of what we are doing in physics.
Instead of thinking about the natural laws, the laws of nature as being laws that are dictated
by Mother Nature that we all have to obey. I'm looking at this from the perspective of
of people wanting to quantify things and we've gotten so used to quantifying things and by that
I mean assigning numbers to things that we almost give it no second no additional thought.
And of course, this is a very simple process. We learn to do this as children. We assign numbers
for different properties of objects and the larger things are typically assigned larger numbers.
And of course, there's some arbitrariness here. There's some some choice you can make. So here I
have pictures of some batteries. 1.5 volt battery is 6 volt battery 12 volt battery. And so we are
assigning numbers to one aspect of these, this set of batteries.
And classically, we tend to, because we're so familiar with this, we have come to
think of these quantities as being properties of the objects themselves. So in fact, we even
use them in the name. It's a, this is a 12 volt battery. And that's the
that number 12 is considered to be a property of the battery, which I, which I think is a very,
that's a little too strong. And you can start to see where this is going to be problematic when we
consider things like very small objects where the probes that we're using to study them are
equally small. The assigned quantities in these cases really describe interactions rather than
describing properties of the objects. So we often, you know, our language often governs how we think
and how we think is described by our language. So these two things are coupled and very often
we'll hear people say or will, or will, I myself will say things like an electron has an energy E
or has a momentum P. And, and that's really not a good way to think about it. The electron can't
possess a momentum because the momentum of an, of an electron is really observer dependent.
You boost to another observer in a different frame and they'll measure a different momentum
for the object. They'll say this, no, this electron has this momentum P. And of course,
we know how these two numbers are related. But, but I think that one of the difficulties that we've
faced conceptually is, is taking these numbers that we're assigning as descriptions of,
of objects, descriptions of properties of objects, descriptions of the way that they're
interacting with observers and attributing them to being numbers describing properties of the
objects. And that I think that's really a wrong way of thinking. And it's caused us a good bit of
trouble. The momentum and position and energy, these types of quantities really are describing
the relationship between the electron and the observer. And so momentum is one description
of the relationship position is a different description of that relationship. And the fact
that the two descriptions are incommensurate really isn't surprising or unusual. They're just
two different descriptions. And so there's been in quantum mechanics, historically, there's been a
lot of puzzlement over the fact that how can, how can an electron not have a definite position
and a definite momentum at any given time? Well, the fact is the electron doesn't have either.
Those are descriptions of the relationship between the electron and the observer. And you can't
have both of those descriptions can't hold at the same time. That's really what's going on there.
It's really only mysterious if you think of these quantities as properties. So we've worked hard to
give up these ideas of properties and thinking of this more in terms of description.
So contextuality, in this case, becomes a little less mysterious, the context of the, or the details
of the interaction matter. And, and of course, what you are going to, how you are going to describe
in interaction depends on the details of those interactions. And descriptions need not be
commensurate. You can have complementarity. The electron doesn't simultaneously possess a momentum
in a position the electron doesn't possess either. That's a bad way of thinking.
So, so what this does is it gives you a bit of freedom, which is, which is interesting. And, and
the profitability of such a perspective then is measured by what it allows you to do. And, and
we've found that it allows you to, to actually do quite a bit. So if you're going to assign numbers to,
to objects or properties of objects or interactions between objects and, and probes,
or observers, then you need to do so consistently. And that's the question becomes,
how does one consistently assign quantities? So, so different operators may have different
frequencies and, or I'm sorry, may have different symmetries. And these symmetries
can be quite important because they will constrain the number of ways in which you can
assign numbers to things. So let's say I have two sets of candy taffy here. And I'm using candy
because what I'm going to be doing with these, these taffy is, is rather simple. You've all known
about this since you were kids. So I've got a set here a of some taffy and I've got a set B of some
taffy. And I'm going to combine the two. So let's say I've set a in one hand and set P on the other
hand and I'm going to put them together. Now, if I want to quantify these sets, basically assign
numbers to the, the, the sets of taffy, one way obvious way to do this that you're very familiar
with is to count them. We'll assign a number describing the cardinality of the set.
And one can then ask the question, well, how do you take the number that you assign to set A
and the number that you assign to set B? And how do you combine those numbers to arrive at the
a consistent number that you're going to assign for set A with B? Of course, you all know the
answer to this already. You add them. And my interest in this question came from the deeper
question that I had in graduate school, which was, why, why do you add them? And I know that it works.
It's obvious that it works. I've been doing this since I was a kid. But why is that the case?
Can you prove that it has to be that way? And indeed, you can.
There's several different properties that this with operator, basically combining stuff in two hands
exhibits this, this, this combination property with exhibits closure in this case. So if I take
stuff A and combine it with stuff B, the stuff that I have in A with B are the same kinds of
stuff. If I take taffy in my left hand and taffy my right hand and combine them,
then I still have a bunch of taffy. So that's closure. Another symmetry that you have with
this operator is the, is commutivity. It doesn't matter which hand I have set A of taffy and
which hand I use to pick up the sets in the first place, I could switch hands and I still have
the same result when I combine them. That's a symmetry. If I have three piles of taffy and
I start picking them up, I can pick them up in various ways. And the result is equivalent.
That's called associativity. And the idea is that the with operator is such that I can keep
grabbing piles of taffy if I want. And so mathematically, I ought to be able to keep
combining them. So these are the four conditions that the with operator has to satisfy.
And you can prove, this is a theorem, you can prove that if the with operator satisfies these
four conditions, and you can think of associative commutivity as just shuffling,
thinking shuffle up the piles and I get the same result, then you can show that if you're going
to quantify the set A with a, with a number representative of lowercase a, and you're going
to quantify the set B with a number given by lowercase b, then a with B is basically going
to have to be quantified by something that's isomorphic to a plus b. And that's a theorem.
And that's something you can prove. So you might say, great, that's something we've known this all
along, not very exciting. I've known this since I was three years old. But it turns out it's rather
profound. And so here's the example. If I assign number A of three to the set A, I assign 10 to
set B, a little taffy hiding under this one. So now when I combine them, I, the number that I assigned
to the set A with B is given by three plus 10 or 13. And that will give me a consistent means of
quantifying these objects. So how well does this work in general? Well, it works pretty well in
general. We use it all the time. We count all sorts of things from taffy and rocks to gallons of
gasoline to cars on the highway to stars in the sky. But let me give you an example where it
doesn't quite work. Because one might be led by, because of the generality of the application of
the mathematics, you may be led to thinking that this is some kind of universal physical law.
And it's not quite that simple. This is a description. I can emphasize the fact that it's a
description by showing that it is, it is observer dependent. So here's another example. I have two
sets of objects. Each of these sets contains molecules. In the ones on the left, I have
two butane molecules. And in the set on the right, I have 13 oxygen molecules.
This is in the way on my screen. So now I'm going to combine the two. So on the left,
I have two molecules. I could assign, you can conceive of assigning this a number two.
On the right, I have 13 molecules. I give it the number 13. And I'm going to combine them.
And you expect to have 15 molecules, which is nice. And that works as long as you don't
shake this up and make it too hot. Once you make it too hot, this happens.
And you no longer have 15, you have 18. And you have 18 carbon dioxide molecules and water
molecules both. So what went wrong with our little rule of additivity? In this case,
two. It should be two plus. Now you have the numbers up here wrong. But our two plus
two plus 13 actually gives me 18. So why did that happen? What went wrong? The answer is quite
simple. What went wrong is we violated one of the conditions for the width operator.
The width operator lacks closure. You don't have the same kind of stuff at the end that you had in
the beginning. So whether an addition worked or not depended on our description. If I were to go
back here to the beginning, and instead of assigning, instead of counting out molecules,
if I counted how many atoms I had, and here I have four times two, which is eight, and then 10.
So it's 20. So I got 28 atoms on the left. And I have 26 atoms on the right. And now I throw them
together and shake up the box. I still have the same number of atoms. You can add the number of
atoms and you get the right result. So addition works if you count the atoms, but it doesn't work
if you count the molecules. So that shows that there is a dependence on the level of description
that you choose. So whether additivity works depends on the description you chose. And the
laws of nature shouldn't depend on description if they're going to be some universal law. So this
isn't about a law of nature. This is about describing things with numbers.
So of course there are other operations you can do. You can take three copies of the set A.
And I'll call that three of A. So this is a new operator called of. I can replicate things. And
it turns out this of operator is obeys associativity. And the of operator is
distributes across the width operator. So you have distributivity. So here we have
associativity and distributivity. And you can prove again, similar to the proof before,
the associativity means that the number that I assign to, so if I assign a number to,
if I have this number A and I assign a number to B, a little A and little B, then the number that I
assigned to A of B is going to have to be, it's going to be some function of little A and little B.
And associativity forces that to be isomorphic to addition. But because we used addition for the
width operator, the fact that we have distributivity forces that isomorphism to
settle on one particular, one particular transform, which is basically multiplication.
So multiplication is isomorphic to addition. So it satisfies the associativity and the
multiplication will satisfy distributivity. So this is a theorem. And so the idea is you
multiply the numbers together. So now when I take three of A, if I assign a number three to A,
kind of unfortunately I use three here, basically when I'm done, three of A is going to give me
three times three or nine pieces of taffy. And you can prove that this has to be the case because
of associativity and distributivity. So these are rules rules for consistently quantifying numbers
or quantifying things with numbers. And now we're going to push this to an extreme.
We're going to consider the case that's that we encounter in quantum mechanics where we are
studying very small objects with very small objects. There are there's a point where we get to
where we are studying objects for which there are no smaller probes by which we can use to study these.
And we may obtain some number x in a measurement and which we would use to quantify this interaction.
But we have to acknowledge that we're going to have some uncertainty as to the value of this assigned
quantity x. You can also think of it this way, we have some quantity describing the system,
some describing the probe. So you put the two together, you really need two numbers to describe
the interaction between the system and the probe. Now this uncertainty,
the relationship may be more intimate than the usual x plus or minus sigma uncertainty that we're
used to from dealing with Gaussian probabilities and probability theory. And instead, and in fact,
I would like to, in this case, if I did want to quantify things this way, I would have to derive
this plus or minus as being a function relating these two. So to back up and work to do something
like that, we're going to not assume that this is the case. Instead, we're going to assign two numbers
here. One number is related to a number quantifying the interaction x and another is going to x1,
say, and the other is going to be x2, which will quantify uncertainty. We just have two numbers
here instead of one. So what happens when we consider similar operations like the width operator
and the of operator, and we start combining things, and we are using two numbers to describe
these interactions rather than just one. So we'll look at associative commutivity again,
which previously with scalars gave in the taffy gave us a sum rule. We find that that's the case
here as well. So if we have some set a something a that's described by two numbers x1 and x2,
and then we have a B described by two numbers y1 and y2, then a with B, where this width operator
is any operator that exhibits closure, associative commutivity and reproducibility,
then a with B has to be represented up to isomorphism by component wise summation.
So we would then assign for a with B, we would assign numbers x1 plus y1 is one number and x2
plus y2 is the second number. That's not so unusual, because it's not so different than
you can see the scalar case right there. Things get a little more interesting when you
when you consider operator an additional operation like the OV operator, where you have
associative distributivity as well. So here, upon interaction, associative distributivity, which
we'll use this operator as dot, as we're trying to figure out what dot would be,
we should have we will have distributivity here, we also have associativity. And
and we also have that we have component wise summation for the plus here. And that requires
that this dot operation has to be bilinear. So whatever numbers x and y you have in the original
pairs, the result is when you combine them has got to be some some linear bilinear combination
of these objects, where these gammas here are our coefficients that we have to identify.
So these basic symmetry, these symmetries are common in the systems that we work with. And
that is why we use addition all the time, because we have associative commutivity holds often so
addition works. And in physics, generally, we have associative commutivity and associative
distributivity. And that is why physics is fundamentally linear. Excuse me.
So now, whereas scalar quantification resulted in one multiplication rule, the pairwise
quantification where we're carrying with us a number quantifying some uncertainty results
in three multiplication rules, which is interesting.
So in that they these come about from looking and seeing what gammas are possible. So it turns
out that there are three sets of gammas that are are are possible. And they all the different versions
reduced to three different types of operations. One of these here, you'll see the first one a looks
like complex multiplication. So you're basically treating these as complex numbers. And B is similar,
but where we have addition here. And C C is also similar, but not the same. We can rewrite this
as this as a multiple as a matrix operation, where a looks like this be looks like that and that and
then we operate on the vector y 1 y 2. So these are the three different multiplicative operators
that we have. And we will see that much of physics comes from these three operators.
So without loss of generality, we set the determinant of these operators to one.
And we do that so that repeated application doesn't diverge to infinity or collapse to zero,
that would be pointless. And that means that there's really only one free parameter related
to the ratio of x 2 to x 1, which gives us three possibilities. We have something like a rotation
matrix for multiplication rule a, we have something like a hyperbolic rotation for
multiplication rule B. And we have this other
matrix for operation C. Each one, each of these three will obey those symmetries. So
they may be useful in quantifying things in the real world that obey the symmetries or interactions
in the real world that obey the symmetries. So we, of course, we can write these operators in
terms of infinitesimal generators. This is what the generators look like. And
we then see that generator a is basically rotation by some phase angle. And a little bit
just what I had originally said. So there's a rotation matrix. So generator a basically rotates
by a phase angle. And the sum and product rules in these case are those of complex arithmetic,
and the pairs are complex numbers. Unit quantities identified with unit modulus
determined, which is modulus squared. And we find that the inherent uncertainty in a unit
object refers to what is remains unidentified in x, which is namely the phase
this rotation so that every time we have an interaction, each new object you interact with
brings with it an unknown phase. So now we have to rely on probability to deal with this inherent
uncertainty properly. Our ignorance of phases uniformly distributed so we can assign a prior
probability to the phase one over two pi. And to obtain the likelihood of a given outcome,
which is what we're quantum, which is what we're computing when we do quantum mechanics,
we must marginalize overall of the unknown parameters, which are all of the unknown
phases in the interactions. And if we perform this marginalization, you see that we're basically
summing modulus squared quantities. And this is really why quantum mechanics is a probabilistic
theory. And the likelihood is additive because of the scalar sum rule. And it depends on the
modulus squared, which is the Born rule. So you can show that all of these things arise from these
simple symmetries. So here you can see here it looks like the foundation of quantum theory is
pretty elementary and simple quantity and uncertainty fused together into complex
numbers with uncertainty really referring to phase. And the observable quantity is the modulus squared,
which is the Born rule for arbitrary amount. And that represents ensemble averages,
which is what the experimenter measures. So we have that, what's nice about this is quantum
mechanics and probability theory are derived from the same symmetries that can't possibly
contradict one another for that reason. And in physics, we make predictions,
which are quantified probabilistically in terms of likelihoods.
And so given those likelihoods, Bayesian analysis then computes posterior probabilities,
which assess the models and the lights in light of the outcomes that are actually observed.
And that is the relationship between quantum mechanics and Bayesian inference.
Quantum mechanics deals with computing likelihoods. And likelihoods are used in performing inference
calculations. So now we can go a bit further and see how the multiplication rule B comes into play.
These three different rules are potentially going to be used to describe different types of
interactions. And so rule A, multiplication rule E, A we see is used in quantum mechanics.
What is B good for? Well, B, because these are all possible descriptions, we can then ask what
could we possibly describe with B or C. They're going to be consistent with the symmetry. So they
would be good descriptions of something. And I'll look into that briefly here.
So here we can consider objects that can exist in two states, let's say up and down.
This gives us a quantification consisting of a pair of complex numbers,
basically using the rules A, the multiplication rule A, and we'll have pairs of complex numbers now.
And qubits, we'll call these qubits, will obey associative distributivity. So the representation
is two-dimensional over the complex field. And these generators, these generators that we have
will give us the polymatrices. So B, the generator for multiplication rule B gives you sigma x.
I times the generator for multiplication rule A gives you sigma y, and then together
B times A gives you sigma z. So these are the polymatrices.
And so the multiplication rules A and B together give you the concept of spin.
And we see that we get the scalar quantifications come from these different, these three polymatrices.
And this gives us a relationship between these new quantifications that we can construct from
these operators. And this is really the first clue that 3 plus 1 spacetime emerges from quantum mechanics.
So with complex coefficients, these generators define the six-parameter Lorentz group,
under which ensemble averages of independent samples results in this relationship, which is
invariant, or this quantity, which is invariant. So if I go back to those original multiplication
rules, these two here together basically give us a six-parameter Lorentz group.
So we can see that when you think of these multiplication rules as being constraints
that constrain your description of things, you can see that the descriptions we use in physics
are actually coming from these constraints, and they ought to be.
It gives you the possibility of deriving physics, which is quite interesting.
One could have potentially derived physics before encountering the physical world, which is
which is quite a thought when you imagine that the physical laws are somehow laws dictated by
mother nature. If you think of the physical laws as being constrained equations that constrain
any attempts at quantifying physical things, then it's not so surprising.
So the shift in perspective on what you mean by a physical law gives you a great deal of freedom.
So we now have these symmetries of associativity, commutativity, and associative
distributivity, along with consideration of uncertainty, give us the basic mathematical
descriptions of the universe. We get that from this, you can get the quantum mechanics as a
probabilistic theory. The polymatrices and spin derive from multiplication rules A and B.
This also gives you concepts of energy and momentum and phase and action.
And from that, you can then integrate using rule C, which I don't have a slide for.
I should have made that. I didn't want this to take too long.
And you can see that operator C is an integrator. I'll go back to that. Here we go.
So here's operator C. If you imagine multiplying at times something like dt
on the top and then t0 down below, you can see that this is going to basically integrate phase.
So time, it comes about from integrating phase. And this basically allows you to integrate time,
which then when combined with the other to allow you to integrate,
integrate, you can integrate phase up to obtain time and you can integrate momentum
in the other two up to obtaining positions. So it works backwards from what we're used to.
What we're used to is we start out with wave functions and we have positions and times,
and we take derivatives to obtain energy and momentum, which are supposedly more fundamental.
So we basically work backwards in the traditional way. We start out with something higher level,
position and momentum, position and time, and we take derivatives to get momentum and energy.
This is actually going from the ground up, which is what I think would be a better foundation.
That's how you build things from the bottom up. So here basically we have energy and momentum
and phase coming in from the beginning. And then with operator C, you can then integrate
that to getting a three-dimensional spacetime and that comes out as an integral of phase
and energy and momentum. So this is the direction our work is taken. And why does mathematics work,
which is a question that's always had me wonder. Here it's easy to see the symmetries.
These symmetries constrain our mathematical description of physics,
which is why it works. And that's why it's derivable, which is interesting.
Universes can't just do anything. As long as you have these symmetries hold,
then your description of systems or interactions that obey these symmetries
are going to have to follow these mathematics. And that basically is the theorem.
So here's one of our most recent papers on this. So I hope you enjoy that and thank you.
Okay. Thank you very much, Kevin, for this nice talk. The people who want to make a question
or a comment can indicate it in the chat.
I have a little question.
Do you think that this analysis can be replicated in another physical theory
that use another type of space or space time?
Oh, I didn't quite follow that. I'm sorry. The connection wasn't so good for me.
Sorry. Do you think that this analysis can be replicated in another theories that use another
kind of space times, like in the string theories? No, that's a good question. And that's
basically where we're headed with this, is we want to see it from what we have so far. It looks
like these symmetries allow you to generate space time as integrals of more fundamental
quantities like phase and energy and momentum. And so we want to look into that to see if you
can build space time up from that foundation. And if you build space time that way, if you can do
that, then it's going to automatically be consistent with quantum theory. So we would have a theory of
space time that's consistent with quantum mechanics from the get go, which is really how you would
want it. There is a question from Federico Colli. Hi, Kevin. Thanks for this, from this talk. Yeah,
it's great. So I wanted to know what's your take on photons, because you mentioned that when you
count atoms and molecules, well, that the counting, it depends on the level of description that you
are taking, right? But then if I have a laser, an attenuated laser, and you prepare a coherent state,
then you will have a superposition of different numbers of photons. So you don't have a definite
particle number. So what would be your take in that situation? How many photons do I have? Or
photons in that case will not be real entities or only the quantum field? What would be your take?
Oh, that's a really good question. That's something I hadn't considered.
If, if additivity doesn't work, then you've violated one of those four conditions, and it would
be, and that would be my first, first guess. And then so, then the question would be which of the
conditions are violated in that situation. So, so in the case where I combine butane molecules
with oxygen molecules, the condition that's violated is that of closure. So it's hard to imagine
that you're going to have a problem with closure when combining photons. So yeah, so I'm curious
about this. I'll have to think about that. Thank you. That's a very good question. Thanks.
Okay. We are in time. So thank you, Kevin. Okay. Thank you so much.
