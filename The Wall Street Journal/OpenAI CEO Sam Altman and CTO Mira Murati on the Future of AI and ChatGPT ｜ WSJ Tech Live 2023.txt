So here's my first question for you very very simple question. What makes you human?
Me both of you you both have to answer what makes you human. Oh and one word you get one word
humor humor
Emotion, okay
To confirm you're both human. I'm gonna need you to confirm which of these boxes have a traffic light. I
Think I think I can do that too. No, okay. All right. Well, Sam you are actually here
nine years ago at our first tech live and actually want to roll the clip of what you said, okay
Certainly the fear with with AI or machine intelligence in general is that it replaces drivers or doctors or whatever
but
The optimistic view on this and certainly what backs up what we're seeing is that computers and humans are very good at very different things
So a computer doctor will out crunch the numbers and do a better job than a human
I'm looking at a massive amount of data and saying this but on cases that require judgment or creativity or empathy
We are nowhere near any computer system that is any good at this
Okay, does
2023 say I'll partially right and partially wrong. Okay, what have been worse could have been worse. Um, what's your outlook now?
People I
Think the prevailing wisdom back then was that AI was gonna
Do the kind of like robotic jobs really well first so it would have been a great robotic surgeon something like that
and then maybe eventually it was gonna do the
The sort of like higher judgment tasks, and then you know, then it would kind of do the empathy and then maybe
never it was gonna be like a really great creative thinker and
Creativity has been in some sense and at this point the definition of the word creativity is up for debate
But creativity and in some sense has been easier for
AI than people thought you can you know see dolly three generate these like amazing images
or
Write these creative stories with GBT for whatever
um
so
That part of the answer maybe was not perfect and
GP I certainly would not have predicted GPT for nine years ago
Quite how it turned out, but a lot of the other parts about people still really want a human doctor
That's definitely very true
And I want to quickly shift to a GI
What is a GI you're after you could just define it for everybody in the audience I
Will say it's a system that can
Generalize across many domains that you know would be
equivalent to
human work
they would produce a lot of
productivity and economic value and but you know we're talking about one system that
Can generalize across a lot of digital domains of human work and
Sam why is a GI the goal?
The
The two things that I think will matter most over the next decade or few decades
To improving the human condition the most giving us sort of just more of what we want to our
Abundant and inexpensive
intelligence
The more powerful the more general the smarter the better
I think that is a GI and then and then abundant and cheap energy
And if we can get these two things done in the world then it's almost like
Difficult to imagine how much else we could do
We're big believers that you give people better tools and they do things that astonish you and I think a GI will be
The best tool
Humanity has yet created
With it. We will be able to solve all sorts of problems. We'll be able to express ourselves in new creative ways
We'll make just incredible things
for each other for ourselves for the world for for kind of this unfolding human story and
You know, it's new and anything new comes with change and changes
not always all
easy, but I think this will be just absolutely tremendous upside and
Gonna
You know, we're gonna
Nine more years if you're nice enough to invite me back. You'll roll this question and people will say like how could we have thought?
We didn't want this
How I guess two parts of that my next question
When will it be here and how will we know it's here?
From here from you. Well, either one of you. I mean you can both predict how long I think we'll call you in 10 years
I'm gonna tell you you're wrong less than less than that. I mean, yeah
Yeah, probably in the next decade, but I would say it's a bit tricky because we you know
When will it be here, right?
And I just kind of give you a definition
But then often we talk about intelligence and you know, how intelligent is it or whether it's conscious and sentient and all of these terms
And you know, they're not quite right because they sort of define our
Our own intelligence and we're building something slightly different and you can kind of see how the definition of intelligence
Evolves from, you know machines that were really great at chess and
Off-a-go and now the GPT series and then what's next they continues to evolve and it pushes what how we define intelligence
We we kind of define
HGI is like the thing we don't have quite yet
So we've moved I mean, there were a lot of people who would have 10 years ago
So that art if you could make something like GPT for GPT five maybe that would have been an HGI
And now people are like, well, you know, it's like a nice little chatbot or whatever and I think that's wonderful
I think it's great that the goalposts keep getting moved. It makes us work harder
but I
Think we're getting close enough to whatever that
AGI threshold is gonna be that we no longer get to hand wave at it and the definition is gonna matter
So less than a decade for some definition
Okay, all right
The goalpost is moving
Sam you've used the word and and previously when describing AGI the term
Median human can you explain
What that is um
I think there are experts in areas that are gonna
be
Better than AI systems for a long period of time
And so like, you know, you could come to like some area where I'm like really an expert at some task and I'll be like, all right
You know GPT four is doing a horrible job there GPT five six whatever doing a horrible job there
But you can come to other tasks where I'm okay, but certainly not an expert
I'm kind of like maybe like an average of what different people in the world could do at something and for that
Then I might look at and say oh, this is actually doing pretty well. So
What we mean by that is that the in any given area
expert humans may
Like experts in any area can like just do extraordinary things and that may take us a while to be able to do with these
These systems but for kind of the more average case performance
So, you know me doing something that I'm like not very good at anyway. Maybe our future versions can help me with that a lot
So am I a median human?
It's some tasks. I'm sure and it's some clearly at this year a very expert human and no GPT is taking your job anytime soon
Okay, that makes me feel that makes me feel a little better
Mira, how's that GPT five going?
We're not there yet, but it's kind of need to know basis. I'll let you know that's such a diplomatic answer
I'm gonna make mirror to all of you. I would have no I would have just said. Oh, yeah, that's great
We're not sending him back here. There are these two who paired whose idea was this?
You're working on it. You're training it. We're always working on the next thing
I
Do a staring contest that's what makes us human
All of these steps though with GPT right is it or you know GPT 3 3.5
For our steps towards AGI with each of them. Are you looking for a benchmark?
Are you looking for this is what we want to get to yeah, so
You know before we had the product
we were sort of looking at academic benchmarks and how well these models were doing on academic benchmarks and
you know open AI is
Known for betting on scaling, you know throwing a ton of compute and data on this neural networks and
Seeing how they get better and better at predicting the next token
But it's not that we really care about the prediction of the next token
We care about the tasks in the real world to which this correlates too
And so that's actually what we started seeing once we put out
research in the real world and
We we build out products through the API eventually through charge a PT as well. And so now we actually have
real-world examples we can see how our customers do in
Specific domains how it moves the needle for specific businesses
and of course with GPT 4 we saw that it did really well in
Exams like SAT and Elsa and so on so it kind of goes to our earlier point that we're you know
continually
Evolving our definition of what it means for these models to be more capable
But you know as we increase the the capability vector what we really look for is reliability and
Safety these are very interweaved and it's very important to make systems that of course are increasingly capable
but that you can truly rely on and they are robust and
That you can trust to the output of the system. So we're kind of pushing in
both of these vectors at the same time and
You know as we build the next model the next set of technologies
We're both betting continuing to bet on scaling, but we're also looking at you know this other
Elemental of multi modality
Because we want these models to kind of perceive the world in a similar way to how we do and
You know we perceive the world not just in text but images and sounds and so on
So we want to have robust representations of the world
in these models
Well
GPT-5 solve the hallucination problem
Well, I mean
Actually, maybe like let's see
We've made a ton of progress on the hallucination issue
With GPT-4, but we're still quite
We're not where we need to be but you know, we're sort of on the right track and it's it's unknown
It's research. It could be that
Continuing in this path of reinforcement learning with human feedback
We can get all the way to really reliable
Outputs and we're also adding other elements like retrieval and search so you can
You have the ability to to provide more factual answers or to get more factual outputs from the model
So there's a combination of technologies that we're putting together to kind of reduce the hallucination issue
Sam, I'll ask you about the data the training data
Obviously, there's there's been maybe maybe some people in this audience who may not be
Thrilled about some of the data that you guys have used to train some of your models not too far from here in Hollywood
People have not been thrilled
Publishers when you're when you're considering now as you're as you're walking through and turning going to work towards this these next models
What are the conversations you're having around? Yeah data. So a
Few thoughts in different directions here one we obviously
Only want to use data that people are excited about us
using like we don't
We want the model of this new world to work for
Everyone and we want to find ways to make people say like you know what I see why this is great
I see why this is like gonna be a new it may be a new way that we think about some of these issues around
data ownership and
Like how economic flows work, but we want to get to something that everybody feels really excited about
But one of the challenges has been people, you know different kinds of data owners have very different pictures
So we're just experimenting with a lot of things. We're doing partnerships of different shapes
And we think like with any new field we'll find something that sort of just becomes a new standard
also, I
Think as these models get smarter and more capable
We will need less training data. So I think there's this view right now, which is that we're just gonna like
You know models are gonna have to like train on every word humanity has ever produced or whatever and I
Technically speaking, I don't think that's what's gonna be the long-term path here
Like we have existential proof with humans that that's that's not the only way to become intelligent
And so I think the conversation gets a little bit
Let us stray by this because what what really will matter in the future is like
Particularly valuable data, you know people want people trust the Wall Street Journal
And they want to see content from that and the Wall Street Journal wants that too and we find new models to make that work
But I think the the conversation about data and the shape of all of this
Because of the technological progress we're making it's about to it's about to shift
Well publishers like my mine might be out there somewhere they want money for that data
Is the future of this entire race about who can pay the most for the best data?
Um
No, that was sort of the point. I was trying to make I guess
The but you still needs
Some you will need some but the core like the thing that is the thing that people really like about a GPT model
Is not fundamentally that it has that it knows particular knowledge. There's better ways to find that
It's that it has this
Larval reasoning capacity and that's gonna get better and better
But that's that's really what this is going to be about
And then there will be ways that you can set up all sorts of economic arrangements as a user or as a company making the model or
Whatever to say all right now, you know, I I understand that you would like me to go get this data from the Wall Street Journal
I can do that, but here's the deal that's in place
So there'll be things like that but but the fundamental thing about these models is not that they memorize a lot of data
So sort of like the model we're also right now. You've got being integrated it goes out looks for some of that data
And can bring back. Yeah, and that's you know on the internet. We decided
Again back in the early days in that there were a lot of conversations about the different models could be and we all kind of decided on
You know, here's the the core framework and there's different pieces in there, of course
And we're all gonna have to figure that out for AI. Well speaking of Bing
You and Satya Nadella your ten billion dollar friends or frenemies friends. Yeah, yeah
I won't pretend that it's like a perfect relationship, but nowhere near the front of me category
It's really good. Like we have our squabbles
You know, we just like recently as you guys are releasing more and more products that they seem to compete in some places
um
I mean, I think that that's that there's something
Core about this language interface that is a big deal. And so there's gonna be a lot of people doing things for that and
And
Then there's other places like, you know, we offer a version of API they offer a version of the API
But like that just that's like a very
Friendly thing and we all like we work it out so that we all benefit and we're all happy and and we just want like we jointly want as much
Usage of our models of our as possible. So we're super aligned there
But yeah
Makes sense
Friends friends that's text we do a lot. Okay. All right. All right
Mira you you over the last number of months have started to roll out a lot more personalization to the model
Right, you can put in custom instructions
You get a get the voice now and we're gonna bring out one of the bring down the screen to hear one of these clips
But I wanted to play one of these conversations. I had with chat GPT just yesterday
It's a slow screen
Chachi BT responds quicker
We're gonna get that better though. Yeah, we're gonna work on that. We'll get it faster. That's that I can't help
Now I'm saying chat to BT is faster than this. Yeah. Yeah, and I'm saying that's like it's not
I've got a big interview with open AI executives and I'm nervous any advice
Absolutely given your background as a technology columnist, you're well equipped for this
Just be yourself do your homework on open AI's latest developments and trust in your expertise
Remember, they'll likely appreciate thoughtful and well researched questions. And hey, everyone gets nervous
Take a deep breath and rock it
Am I rocking it? Definitely. I'm rocking it. All right. Are we rocking it up here?
But what's so striking about that first of all, I want every that's that's the voice of chat GPT
They have one of five. Yeah. Yeah, I mean that is the voice. It is it sounds so human
It sounds so natural
It knows about me because I've already put into custom instructions. I'm a tech journalist
It also knows I'm allergic to avocado. It's always putting that in there. Don't eat avocado. I'm like, I'm not asking about avocado
Is there is there a future and this is what you're maybe trying to build here where we have deep relationships with this type of thought
It's going to be a significant relationship, right?
Because you know, we're we're building the systems that are going to be everywhere in your home in your educational environment in your work
environments and maybe, you know, when you're having fun and so that's why it's actually so important to get it right and
We have to be so careful about how we design this interaction so that ultimately it's, you know
Elevating and it's fun and it's it makes productivity better and it enhances creativity
And you know, this is ultimately where we're trying to go and as we increase the capabilities of the technology
We also want to make sure that you know on on the product side
we feel in
control of
This these systems in the sense that we can steer them to do the things that we want them to do and the output is reliable
that's very important and of course we want it to be personalized, right?
And as it has more information about your preferences the things you like the things you do
And the capabilities of the models increase and other features like memory and so on it has of course
it will become more personalized and
That's that's a goal it will become more useful and it's going to become
More fun and more creative and it's not just one system, right?
Like you can have many such systems personalized for specific domains and tasks
That's a big responsibility though, and you guys will be in sort of control of
People's friends, maybe people it gets to being people's lovers. How do you how do you guys think about that control?
First of all, I think there's
We're not gonna be the only player here like there's gonna be many people
So we have we have we get to put like our nudge on the trajectory of this technological development
And we've got some opinions, but a we really think that the decisions belong to sort of
Humanities society's a whole whatever you want to call it and be we will be one of many actors building sophisticated systems here
So it's gonna be a society-wide discussion. It's and there's gonna be all the normal forces
There'll be competing products that offer different things. There will be different kind of like
Societal embraces and pushbacks. There'll be regulatory stuff
It's gonna be like the same complicated mess that any new technological
Burdening process goes through and then we pretty soon will turn around and we'll all feel like we had smart AI in our lives forever
And you know, that's just that's that's the way of progress and I think that's awesome. Um, I
Personally have deep misgivings about this vision of the future where everyone is like super close to AI friends and not like more so than human
Friends or whatever. I personally don't want that. I
accept that other people are gonna want that and
You know, some people are gonna build that and if that's what the world wants and what we decide makes sense
We're we're gonna get that I
Personally think that personalization is great
Personality is great, but it's important that it's not like
person this
And at least that you know when you're talking to AI and when you're not, you know, we named it chat Gbt and not
It's a long story behind that but we need a chat Gbt and not a person's name
Very intentionally and we do a bunch of subtle things in the way you use it to like make it clear that you're not talking to a person
and
I think what's gonna happen is that in the same way that people
Have a lot of relationships with people they're gonna keep doing that and then there'll also be these like AI's in the world
But you kind of know they're just a different thing
When you're saying this is another question for you, what is the ideal device that we'll interact with these on and I'm wondering if you
I hear you and Johnny. I've been talking
You bring something to show us
I
Think I think there is something great to do, but I don't know what it is yet
It must have some idea a lot of ideas. Yeah, I'm interested in this topic
I think it is possible. I think most of the current thinking out there in the world is
quite
Bad about what we can do with this new technology in terms of a new computing platform
And I do think every sufficiently big new technology
Is it enables some new computing platform, but lots of ideas, but like in the very
Mason stage so it doesn't I
guess the question for me is
There's something about a smartphone or earbuds or a laptop or a speaker that doesn't quite work right now
Yeah, of course
Smartphones are great. Like I have no interest in trying to go compete with a smartphone
like it's a phenomenal thing at what it does, but I
Think the way what AI enables is so fundamentally new
That it is possible to and maybe we won't like you know
Maybe maybe just like for a bunch of reasons doesn't happen
But I think it's like well worth the effort of talking about or thinking about you know
What can we make now that before we had computers that could think was?
or computers that could understand whatever you want to call it was not possible and
If the answer is nothing it would be like a little bit disappointed
What sounds like doesn't look like a humanoid robot, which is good
Definitely
I don't think that quite works. Okay, speaking of hardware and making your own chips
You want answer no
Directed here
Are we making our own chips?
We are trying to figure out what it is going to take to scale to deliver
At the scale that we think the world will demand and at the model scale that we think that the research can support
That might not require
Any custom hardware?
And we have like wonderful partnerships right now with people who are doing amazing work
So the default
Path would certainly be not to but I wouldn't I would like I would never rule it out
Are there any good alternatives to Nvidia out there?
Nvidia certainly has something amazing amazing
But you know, I think like
The magic of capitalism is doing its thing and a lot other people are trying and we'll see where it all shakes out
We had Renee Haas here from arms. It is great here. You guys have been talking
We said hello. Yeah. Oh you said hello
Not as close as that you're not you're not as close as not as okay. Got it got it
Um
This is the really hard. This is we're good. Yeah, we're getting to the heart
We're about to get to the hard hitting so
My colleagues recently reported you guys are are are actually looking at the valuation is 80 to 90 billion
And that you're expected to reach a billion in revenue
Are you raising money?
No, well, I mean always but not like this minute not right now
There's people here with money. All right, let's talk
We we will need huge amounts of capital to complete our mission and we have been extremely upfront about that
There has got to be something more interesting to talk about in our limited time here together then our
Future capital raising plans, but we will need a lot more money. We don't know exactly how much we don't know exactly how
It's gonna be structured what we're gonna do, but
You know it like shouldn't
Come as a surprise because we have said this all the way through like it's just a tremendously expensive endeavor
Where which part of the business though right now is growing the most
Mira you can also jump in definitely in the product side
Yeah, with with the research team is very important to have you know density of talent
Small teams that innovate quickly the product side, you know, we're doing a lot of things
We're trying to push great uses of AI out there both on platform side and first party and work with
So that's the delay and and the revenue is coming mostly from that API
The the revenue for the company revenue I'd say both sides both sides
Yeah, so my my subscription to chat GBT plus is appreciate that. Yeah. Yeah, how many people here actually are subscribers to chat GBT plus
Thank you all very much
We'll talk about it. Yeah, okay, this is what we're really here for tonight
Moving out a little bit into policy and and some of the fears
It's not like super cheap to run if we had a way to like yeah say like hey, you know, you can have this for like
You can give you like way more for the 20 bucks or whatever
We would like to do that and as we make the models more efficient will be able to offer more
But it's not for like lack of us wanting more people to use it that we don't do things like family family plan for like
$35 for two people
That's the kind
Well, I gave you the sweatshirt
How do we go from the chatbot we just heard that told me to rock it to one that I don't know can rock the world and end the world
Well, I don't think we're gonna have like a chat about that ends the world
But how do we go to this idea of we've we've got simple chatbots are not simple
They're advanced what you guys are doing, but how do we go from that idea to this fear that is now pervading?
everywhere
if
If we are right about the trajectory things are going to stand and if we are right about
Not only the kind of like scaling of the GPT's but new techniques that were
interested in that could help generate new knowledge and
someone with access to a system like this can say like
Help me hack into this computer system or help me design
Uh, you know like a new biological pathogen that's much worse than kovat or any number of other things
It seems to us like it doesn't take much imagination
to think about scenarios that deserve great caution
And and again, we we we all come and do this because we're so excited about the tremendous upside and
That the incredibly positive impact and I think it would be like a moral failing not to go pursue that for humanity
But we've got to address and this happens with like many other technologies
We've got to address the downsides that come along
Uh with this and it doesn't mean you don't do it
It doesn't mean you just say like this eight day. I think we're gonna like
You know, we're gonna like go like full dune and like blow up, you know have not have computers or whatever
But it means that you like are thoughtful about the risks you try to measure what the capabilities are and you try to
build your own technology in a way and
That that mitigates those risks and then when you say like hey, here's a new safety technique. You make that available to others
And as you guys are thinking about
Building in in in this direction
What are some of those specific safety risks you're looking to put in?
I mean like sim said
You've got the capabilities and then there is always a downside whenever you have such immense and great capability
there's always a downside so
We've got a fierce task ahead of us to figure out what are these downsides discover understand them
Build the tools to mitigate them and it's not, you know, like a single fix
You usually have to intervene everywhere from the data to the model to
the tools in the product and of course policy and then thinking about the entire regulatory and
Societal infrastructure that can kind of keep up with these technologies that we're building because ultimately what we want is
to
Slowly roll out these capabilities in a way that makes sense and allow society to adapt
because you know the
progress is incredibly rapid and
we want to
Allow for adaptation and for the whole infrastructure that's needed for these technologies to actually be absorbed
Productively to exist and be there. So, you know, when you think about what are sort of the concrete safety
measures along the way
I'd say number one is
actually rolling out the technology
and slowly making contact with reality understanding how it affects
certain use cases and industries and actually dealing with implications of that whether it's regulatory copyrights
You know, whatever the impact is actually absorbing that and dealing with that and moving on to more and more capabilities
I don't think that building the technology in a lab in a vacuum without contact with the real world and
with the friction that you see with reality is
a
Good way to actually deploy it safely and this might be where you're going, but it seems like right now
You're also policing yourself
Right, you're setting these bad and and Sam that's where I was going to ask you
I mean you seem to spend more time in Washington than Joe Biden's dogs right now
And I think I've only been twice this year. Really that's I think that his dog like three days or so anyway
But what is it specifically that you would rather the government and our regulators do versus you have to do?
First the point Miro was making I think is really important that that it's very difficult to make a technology safe in the lab
Um
Society uses things in different ways and adapts in different ways
And I think the more we deploy AI the more AI is used in the world the safer AI gets and the more we kind of like
Collectively decide hey, here's the thing that is not an acceptable risk tolerance and this other thing that people are worried about that's that's totally okay
um, and
you know like
We see this with many other technologies. The airplanes have gotten unbelievably safe
Even though they didn't start that way and it was uh, it was like careful thoughtful engineering and
Understanding why when something went wrong it went wrong and how to address it and you know the shared best practice is there
I think we're going to see in all sorts of ways that the things that we worry about with AI in theory don't quite play out in practice
You just like a ton of talk right now about deep fakes and you know the the
impact that's going to have on uh
Society in all these different ways
I think that's an example of where we were thinking about the last generation too much
And AI will disrupt society in all of these ways, but you know, we all kind of are like
They're like, oh, that's a deep faker. Oh, it might be a deep faker. Oh that picture video or audio like we learn quickly
But but maybe the real problem. This is like speculation. This is hard to know in advance is
Not the deep fake ability, but the sort of
Customized one-on-one persuasion and that's where the influence happens. It's not it's not like the fake image
It's that this thing has a subtle ability these things have a subtle ability to influence people and then we learn that that's the problem
and we we adapt uh, so
In terms of what we'd like to see from governments, uh, I think we've been like very mischaracterized here. We do think that international
Regulation is going to be important for the most powerful models nothing that exists today
Nothing that'll exist next year. Uh, but as we get towards a real super intelligence as we get towards a system that is like
More capable, uh, than like any humans
um
I think it's very reasonable to say we need to treat that with like
caution and uh
And a coordinated approach, but like we think what's happening with open source is great
We think startups need to be able to train their own models and deploy them into the world
And a regulatory response on that would be a disastrous mistake for this country or others
um, so the message we're trying to get across is
You got to embrace what's happening here. You got to like make sure that
We get the economic benefits and the societal benefits of it, but
Let's like look forward at where this where we believe this might go
And let's not be caught flat-footed if that happens
You mentioned deep fakes and I want to talk about AI generated content. That's
all over the internet now
who
Do you guys think is responsible or or should be
Responsible for policing some of this or not policing but detection of some of this
Is this on the social media companies? Is this on open AI and all the other AI companies?
We're definitely responsible for the technologies that we develop and put out there and
You know misinformation and
That's that's clearly a big issue as we create more and more capable models and we've been developing technologies to deal with
The provenance of an image or text and detect output
But it's a bit complicated because you know
You want to give the user sort of flexibility and they you also don't want them to feel monitored
And so you have to consider the user and you also have to consider people that are impacted by the system that are not users
and so
These are quite nuanced issues that require
A lot of interaction and input from not just your users of the product, but also of society
More broadly and figuring out, you know, also with partners
That that bring on this technology and integrate it. What are the best ways to to deal with these issues?
Because right now there's no way or no tool from open AI
At least that I that I can put in an image or some of the text and ask is this AI generated
Correct for image. We have actually technology. That's uh, really good
Almost, you know, 99% reliable, but we're still testing it. It's early
And we want to be sure that it's going to work and even then it's not just a technology problem
Misinformation is such a nuanced and broad problem. So you still have to be careful about how you roll it out
Where you integrate it?
But we're certainly working on the research side and for for image at least we have a very reliable tool in in the early stages
And
Say it's work. When might you release this?
You said you said you're you're working on this right now. Is this something you plan to release? Oh, um, yes
Yes, for both images and text for text. We're trying to figure out what actually makes sense
For for images. It's a bit more straight straightforward problem
But in either case we definitely test it out because we don't have all the answers, right?
Like we're building these technologies first. We don't have all the answers
So often we will experiment. We will put out something. We will get feedback
But we want to do it in a controlled way, right?
And sometimes we'll take it back and we'll make it better and roll it out again
I'll also add that I think this idea of watermarking content is not something that
Everybody has the same opinion about what is good and what is bad
There's a lot of people who really don't want their generated content watermarked and that's understandable in many cases
Also, it's not it's not going to be super robust to everything like maybe you could do it for images
Maybe for longer text, maybe not for short text
But over time there will be systems that don't put the watermarks in and also there will be people who really like
You know, this is like a tool and up to the human user how you use the tool and I don't
Like this is why we want to engage in the conversation like we are willing to sort of like
follow the
the collective wishes of society on this point and
I don't think it's a black and white issue
Uh, at least I think people are still evolving as they understand all the different ways we're going to use these tools
They're still evolving the thoughts about what they're going to want here
Also to Sam's earlier point, it's not you know
um, it's not just about
truthfulness, right and
What's what's real and what's not real actually?
I think in the world that we're going towards marching towards the the bigger risk is really this individualized
Persuasion and and how to deal that then that's going to be a very tricky problem to deal with
All right, I realize I have five minutes left and we we're going to do some audience questions
So we can get to one audience or two audience questions. I'm gonna finish one one one last thought here
Um, I can actually not see a thing out there. So um, I will ask one last question
Then we'll we'll hopefully have time for one or two
So 10 years you were here 10 years ago
what
We touched on this as we were we're starting here, but
What is your biggest fear about the future and what is your biggest hope with this technology?
I mean, I think the future is going to be be like amazingly great. We wouldn't come
Work so hard on this if we didn't I think this is going to be like
I think this is one of the most significant inventions humanity has
yet done, um
So I'm super excited to see it all play out. I think like things can get so much better
for people than uh,
Then they are right now and I'm I feel very hopeful about that
We we covered a lot of the fears it like again, we're clearly dealing with something very powerful
That's gonna impact all of us in ways we we can't
Perfectly foresee yet. Um, but like what a time to
Be alive and and get to witness this
You're not so fearful, but I was gonna actually ask this, but I'll ask it now. Do you have a bunker?
This is the heart this is this is better than the audience question
It's not better than I'm gonna let that clock run. I'm not gonna pay attention to that
But I as we're thinking about fears. I just I'm wondering why if you have a bunker and I would say no that you have that
You'd say no, I have like structures, but I wouldn't say like a bunker
Structures
None of this is gonna help if AGI goes wrong. This is really it's a ridiculous question to be honest
Okay, good good good
Mira with your hope and fear
I mean the hope is definitely to push our civilization ahead with
augmenting our collective intelligence and
The fears we talked a lot about the fears, but you know, we've got this opportunity right now
And you've got summers and winters in AI and so on
But you know when we look back 10 years from now, I hope that
We get this right and
I think there are many ways to to mess it up
And we've seen that with many technologies, so I hope we get it right
All right, we've got time
right here
Hi, I'm Pam Dylan preferably
Sensory consumer products AI my question has to do with the inflection point
we are where we are with respect to AI and
AGI what is the inflection point?
How do you define that moment where we go from where we are now?
To however you would choose to define
What is AGI?
I think it's
It's gonna be much more continuous than that
We're just on this beautiful exponential curve
Whenever you're on a curve like that you look for it looks vertical you look back. It looks horizontal
That's true at any point on there. So a year from now will be in dramatically more impressive place than a year ago
We were in a dramatically less impressive place
But it'll be hard to point people will try and say oh, it was alpha go that did it
It was gpt3 that did it it was gpt4 that did it
But it's just brick by brick one foot in front of the other up climbing this exponential curve
Right here in the front
Thank you, my name is Nyariana Michael
I'm the chief information officer of the port of Long Beach, but I'm also computer scientist by training a few decades ago
I'm older than you I remember working with some of the early AI people
I have a general question. I agree with you. This is one of the most significant innovations to happen
One of the things I've struggled with over the last 20 years in thinking about this
We're about to change the nature of work
This is that significant
And I feel that people are not talking about it. There will be a significant. There'll be a transition time period
where significant population in the world and in this country
Will not have had the types of discussion and the sand that we have so they can like you mentioned society needs to be a part of it
There's a large portion of society that's not even in this discussion
So the nature of work will change it used to be that things that were just um going to be automated
There will be a time where people who define themselves by work
Since thousands of years will not have that and we're hurtling towards it
What can we do to make sure that we take that into account because when we talk about society?
It's not like they're all together ready to discuss this
Some of the effects of some of the technologies that we brought into the world have actually made people separate from each other
How do we get some of those not regulations, but how do we?
Come up with some of those frameworks and voluntarily bring things about that will actually result in a better world
That doesn't leave everybody else behind. Thank you
I I'll give you my perspective. I I think
I completely agree with you that it's one of
It's the ultimate technology that could really increase inequality and make make things so much worse for us as
human beings and civilization
Or it could be you know, really amazing and it could bring along a lot of creativity and productivity and enhance us and
You know, maybe a lot of people don't want to work
Eight hours or a hundred hours a week. Maybe they want to work four hours a day and do a bunch of other things
and you know
I I think it's certainly going to lead to a lot of disruption
in the workforce and we don't know exactly the scale of that
Or the trajectory along the way, but that's that's for sure and
one of the things that
I in retrospect, it's not that we specifically planned it by in retrospect
I'm happy about is that with the release of charge of beauty. We sort of brought AI into the
You know collective consciousness and people are kind of paying attention because
They're not reading about it in the press
People are not just telling them about it, but they can play with it
They can interact with it and get the sense for the capabilities
And so I think it's actually really important to bring these technologies into the world and make them as widely accessible as possible
You know, Sam mentioned earlier like we're working really hard to make these models cheaper and faster
So they're accessible very broadly
But I think that's key for people themselves to actually interact with the technology and experience it
And sort of visualize how it might change their way of life their way of being and participate as you know
as in providing
product feedback, but also
you know
I think that's a really important question
Every technological revolution
affects the job market
And over human history, you know every maybe 100 years you feel different numbers for this 150 years
Half the kind of jobs go away totally change whatever
I'm not afraid of that at all. In fact, I think that's good. I think that's the way of progress
And we'll find new and better jobs that we can do
So I think that's a really important question
In fact, I think that's good. I think that's the way of progress and we'll find new and better jobs
The thing that I think we do need to confront as a society is the speed at which this is going to happen
It seems like over, you know, two maximum three probably two generations
We can adapt society can adapt to almost any amount of job market change, but
A lot of people like their jobs or they dislike change and going to someone and saying hey the future will be better
I promise you and society is going to win but you're going to lose here. That that doesn't work
That's not a that's not cool. Like that's that's not a nice. That's not an easy message to get across
and
Although I tremendously believe that we're not going to run out of things to do people that want to work less fine
They'll be able to work less, but you know
Probably many people here don't need to keep working and and we all do like we we there's like great satisfaction in expressing yourselves
In being useful and sort of contributing back to society. That's not going away
That that is such an innate human desire like evolution doesn't work that fast
Also, the sort of ability to creatively express yourself and to sort of leave something to to to add something back to
the trajectory of the species is
That that's that's like a wonderful part of the human experience
So we're going to keep finding things to do and the people in the future will probably think some of the things
We'll think some of the things those people do very silly and not real work in a way that like a
Hunter-gatherer probably wouldn't think this is real work either
You know, we're just trying to like entertain ourselves with some silly status game. That's fine with me. That's how it goes
um
the
But we are going to have to really do something about this transition
It is not enough to just give people a universal basic income
people need to have
Agency the ability to influence this they need we need to sort of jointly be architects of the future
And one of the reasons that we feel so strongly about
Deploying this technology as we do
As you said not everybody's in these discussions, but more and more are every year and by putting this out in people's hands
And making this super widely available and getting billions of people to use chat gbt
not only do people
have
The opportunity to think about what's coming and participate in that conversation
Um, but people use the tool to push the future forward. Um, and that's really important to us
