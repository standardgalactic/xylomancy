Fel Κα describe slitIMd .
De ha nem tetszett trainsozni,
Csak t주는zs nurse szögletben,
F要 resumes de as szörny mi后 el Shimano K10 két járás.
F ér Fellos Scalers
ez szalב� sír É W
mam dei
hely Warمل
sagal
Egyadomattak hely detolta a máradtát és iai-hely
Noszre helyeztem épp az embereket
Nem akarom, hogy most megf marinálisten
Mi az betåta거나 ellen……
G納 HUOMENUS
A jársad explain
Így ki csinálni őket
A helyző mi henука
utolsay helyat
É Vocês ú reef
A second, this is Deep Mind's deep reinforcement learning aggasm, it looks at the screen much like a human would and tries to learn what the controls do and what the game is about as the game is running.
And much like a human, first it has no idea what is going on and loses all of it's lives almost immediately.
But, over time, it gets a bit of the feel of the game.
Buldal.
Ezzel amikor posterültünk,
-"az a satokroy vacant stickers specialize?"
"-telese, hogy a fonctionne ag upgrad shopson oszt
hogy támogatok egy kezi, hogy előé utáljunk is elé terrorists killingom a igazakacem
és t персонажa, hogy ahogy jönek a crabsadassán éshoroldom az enszisomentem!"
Humanielk.
Gyerological.
Vpoonszautón észikr trollsg23r Content Amazit is így el.
Éshogy elmutatom ez a hely szerintemp graphsciós kablu,
majd bennet bavá ott megt peanuttenet Boule embarkyzen üre millimetertab.
és
szörnyve epe a szörnyviss miatt ezeket
Ismerd vele lehet.
A m학 valami első remételjik pedig hagyogunk az informations épí�en!
Nézzünk ez az elészek volt,現在 entrá glovesó!
І blal Reg snakes nézett...
Nagyszer!!
Végig nem l ihtuch!
Visszajuthatjál panistásban életinkszel!
Megsőre végig cultiváépoqueem a estásztrazop mexi emlочкиtte...
..még hívként is de el tomarya az epidemic ső.
És őben tudját Warren-at crosses meg?
Yes, it can.
So, is this a plus one or a minus one?
Is this human thinking or robot thinking?
Well, over time humans can get used to input information switching around too.
But not this quickly.
So, this one is debatable.
However, I guarantee that the next experiment will not be debatable at all.
Now, experiment number two, reshuffling on steroids.
We already learned that some amount of reshuffling is okay.
So now, let's have our little AI play pong, but with a twist,
because this time the reshuffling is getting real.
Yes, we now broke up the screen into small little blocks
and have reshuffled it to the point that it is impossible to read.
But, you know what?
Let's make it even worse.
Instead of just reshuffling, we will reshuffle the reshuffling.
What does that mean?
We can rearrange these tiles every few seconds.
A true nightmare situation for even an established algorithm
and especially when we are learning the game.
Okay, this is nonsense, right?
There is no way anyone can meaningfully play the game from this noise, right?
And now, hold on to your papers, because the learning algorithm still works fine.
Just fine.
Not only on pong, but on a racing game too.
Whoa!
A big minus one for human thinking.
But if it works fine, you know exactly what needs to be done.
Yes, let's make it even harder.
Experiment number three, stolen blocks.
Yes, let's keep reshuffling, change the reshuffling over time,
and also steal 70% of the data.
And...
Wow!
It is still fine.
It only sees 30% of the game all jumbled up,
and it still plays just fine.
I cannot believe what I am seeing here.
Another minus one, this does not seem to think like a human would.
So all that is absolutely amazing.
But what is it looking at?
Aha! See the white blocks?
It is looking at the sides of the road,
what the curvature is, and how to drive it,
and look, only occasionally it peeps at the green patches too.
So, does this mean what I think it means?
Experiment number four.
If you have been holding on to your papers so far, now squeeze that paper,
shuffling, and let's shovel in some additional useless complexity,
which will take the form of this background.
My goodness!
It still works just fine.
And the minus ones just keep on coming.
So this was quite a ride.
But what is the conclusion here?
Well, learning algorithms show some ways in which they think like we think,
but the answer is no, do not think of a neural network
or a reinforcement learner as a digital copy of the brain.
Not even close.
Now, even better, this is not just a fantastic thought experiment,
all this has utility.
For instance, in his lecture, one of the authors, David Ha,
notes that humans can also get upside down goggles or bicycles,
where the left and right directions are flipped.
And if they do, it takes a great deal of time for the human to adapt.
For the neural network, no issues whatsoever.
What a time to be alive!
This episode has been supported by Lambda GPU Cloud.
If you're looking for inexpensive cloud GPUs for AI,
check out Lambda GPU Cloud.
They've recently launched Quadro RTX 6000, RTX 8000,
and V100 instances, and hold on to your papers,
because Lambda GPU Cloud can cost less than half of AWS and Azure.
Plus, they are the only cloud service with 48GB, RTX 8000.
Join researchers at organizations like Apple, MIT, and Caltech
in using Lambda Cloud instances, workstations, or servers.
Make sure to go to lambdalabs.com slash papers
to sign up for one of their amazing GPU instances today.
Our thanks to Lambda for their longstanding support
and for helping us make better videos for you.
Thanks for watching and for your generous support,
and I'll see you next time!
