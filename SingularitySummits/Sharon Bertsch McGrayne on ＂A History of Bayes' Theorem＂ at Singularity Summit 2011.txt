Sharon McGrane is next. She is the author of highly praised books about scientific discoveries
and the scientists who make them. She is interested in exploring the connection between social
issues and scientific progress, and in making the science clear and interesting to non-specialists.
Her first book dealt with changing patterns of discrimination faced by leading female
scientists during the 20th century, and her latest book is called The Theory That Would
Not Die, how Bayes' rule cracked the enigma code, hunted down Russian submarines, and
emerged triumphant from two centuries of controversy. The book describes how Bayes'
theorem has become a driver of scientific progress, and the New York Times book review
named it an editor's choice. McGrane's work has been featured on The Charlie Rose Show,
reviewed in Nature, and highlighted on NPR's Talk of the Nation, and she is a frequent
contributor to many other publications as well. She is here to tell the story of how
an 18th-century approach to assessing evidence was ignored for much of the 20th century,
but ultimately embraced. Please welcome Sharon McGrane.
Thank you for inviting me, and thank you for coming so early in the morning. As Nathan explained,
I write books about science and scientists. I'm not a mathematician or a scientist myself,
but Bayes' rule is the foundation of singularity and of artificial intelligence,
and when artificial intelligence overtakes the human brain, Bayes' rule will be there as the
foundation of that as well, I feel. I understand that some people have said that there was never
a great argument about Bayes' rule, and I am here to tell you the contrary. There was an enormous
food fight over Bayes that did not subside, went through much of the 20th century, and did not
subside until quite recently. So in a very real sense, you folks here are real revolutionaries,
and that's what I'm going to talk about today. Exhibit A. Air France 447 took off two years ago
last June from Rio de Janeiro, bound overnight for Paris. It hit a very intense electrical
storm, high altitude, and disappeared without a trace, 228 aboard. I spent the afternoon in Paris
a couple of weeks ago with Olivier Ferrante, the aviation engineer, who ran a two-year search
for the wreckage of Air France 447. It was the largest, longest, most high-tech undersea search
ever done, fruitless for two years. Then he hires a Bayesian search firm in Virginia, and many of
its members are profiled in the chapter on the development of Bayesian naval search theory,
in the theory that wouldn't die. They put together the most probable region to find
Air France 447, and a two-year search ended in an undersea search of one week.
Two-year search, Bayes finds it in an undersea search in two years. These are the black boxes
they were searching for. They're red and white. They're the size of shoe boxes.
This is the map that Ferrante put. They were searching a vast area the size of Switzerland,
and if I can work this thing on my bob, here's Zurich up here, Geneva over here.
This is basically Switzerland, and he chose to put it over Switzerland because the mountainous
terrain on 4,000 meters down under the sea was much like Switzerland's. The pingers they were
searching for were the size of cigars, and they found it. Now the remarkable thing to me is,
among other things, is that the authorities publicly credited Bayes, because as we're going to see
for decades of the 20th century, a lot of people didn't even dare mention the word Bayes.
Okay. Exhibit two. Bayes is all around us, the Google car last spring. Basically,
Bayes, they use the Google maps to start out with, and then they update that information
that comes in through the sensors on top of the cars about new travel conditions around them,
potholes, new deviations and things, and figure out the most rational way to drive at that particular
time. Bayes is all around us. Sundays, not yesterday's Sunday New York Times, but Sunday a week,
front page, two stories based on Bayes. Bayes is not mentioned. There's no Bayes word in there,
but the software report card is about a Bayesian program that teaches children mathematics,
and there's a controversy about the statistics involved in proving the effectiveness of the
instruction. The other one, of course, as we've just heard, is about the fast, the rapid trades,
and there was a question about that clamping down. Two stories on the Sunday New York Times,
followed by, two New York Times, two economists win the Nobel Prize for doing cause and effect
studies in economics using Bayes' rule. There are holdouts, of course, particularly in courtrooms,
and the story has been circulated in the last couple of weeks. A Guardian newspaper reporter
wrote about the appeals judge in Britain who has banned Bayesian statistics from British courtrooms.
He wants firm numbers, not approximations. Now, to appreciate how revolutionary this is,
and how revolutionary you all are, we have to understand how long and bitter the assault on
Bayes was. I'm going to very briefly show you an equation. I've been told that people who write
popular science must never mention an equation, but this is Thomas Bayes. This is actually not
the Reverend Bayes' formula. He used a geometric form of Newtonian calculus, but this is in modern
notation. The PA, that is the heart of the fight against Bayes. That's the Thomas Bayes told us
that we can start with a measure of our belief about a situation. We can assess the probability
of our prior belief, and if we don't know very much about it, we can guess. He uses the word
guess, and then he goes even further. He says, if you don't really know how much to guess,
just guess 50-50. It was that suggestion, that subjective prior, they call it, that so inflamed
the anti-Bayesians. They called it subjectivity run amok. They said it was ignorance coined into
science, and as the 1700s, 1800s, 1900s accumulate much better data, more trustworthy data,
statisticians mostly decided that they would prefer to judge the probability of an event
or a situation by how frequently it occurs, and they become the frequentists and the arch
opponents of Bayes. Nevertheless, although by 1939 when the Second World War breaks out,
Bayes is basically taboo among statistical sophisticates. A number of people, including
Alan Turing and the great Soviet Russian mathematician Kolomogorov, used Bayes during the
war. It's very good for dealing with very uncertain situations in which you have to make
quick one-time decisions, and that's what they had to do during wartime. However, much of that
work was class, particularly Turing's, for decrypting the enigma code and other German codes,
was highly classified immediately after the peace by the British government,
and so Bayes' rule emerged from the Second World War as suspect as it had been when it entered the
war, despite having been used for critical projects. And we have a small group of maybe 100 or more
fervent Bayesian believers who are stymied because they can't prove that Bayes works
because much of the proof is classified in secret. The great founder of statistical science,
an anti-Bayesian, Ronald Fisher, kept up a very personalized fight against Bayes' rule,
starting in the 1920s and 30s, and continuing into the 1950s when a Bayesian at the National
Institute of Health was using Bayes to show that you could use statistical data, and Bayes in
particular, to prove that cigarette smoking actually was a cause of lung cancer. Another
example, when Jack Good, Alan Turing's assistant during the Second World War, to break the enigma
code, and knows Bayes' works, but can't say so, he gives a talk about the theory at the Royal
Statistical Society, and the next speaker's opening words were, after that nonsense,
during Senator McCarthy's witch hunt against communists in the U.S. federal government,
the Bureau of Standards called a Bayesian there only half jokingly un-American,
and undermining the United States government. The National Bureau of Standards actually suppressed
a Bayesian study that was going to be sent to the Fortney, to the Aberdeen Proving Ground
because it was subjective Bayesian. Harvard Business School professors, I have a sense that
some of you have used Howard Rayfa's decision trees. Highly Bayesian, Howard Rayfa was a convert,
first an intellectual convert, then an emotional convert to Bayes. But the Bayesians who did the
decision tree at Harvard Business School were called socialists, and so-called scientists.
The Harvard Business School at one time was called a Bayesian hot house.
A Swiss visitor to Berkeley's very anti-Bayesian statistics department in the 1950s realized
that it was kind of dangerous to espouse Bayes. Now during this period of the Cold War, the
military, of course, continues to use Bayes' rule and develop it, but kept it secret. For example,
the 1950s wrestled with the problem of how do you judge the probability of an event
that has never occurred? Now obviously an event that's never occurred has no frequency to it,
so the frequentists couldn't deal with that question. There had never been an accidental
H-bomb explosion. There had been deliberate tests of the H-bombs, but not an accidental explosion.
So if you all have seen Dr. Strangelove, the movie that satirizes General Curtis Lamey's
strategic air command, you could get the David and Goliath overtones of the story of a young
postdoc named Albert Medansky at Rand, who uses Bayes to show that expanding Curtis Lamey's strategic
air command would in all probability cause 19 accidents involving H-bombs armed or unarmed
each year, and the Kennedy administration would eventually add safeguards.
There were other Cold War projects, of course. The National Security Agency cryptographers used
Bayes and cracked the Soviet codes. John Tupi was an immensely powerful advisor to the White House
and to the National Security Agency. He was also a professor at Princeton and at Bell Labs,
and he used Bayes for 20 years to predict the winners of congressional and presidential elections
for the Huntley-Brinkley News Hour, the most popular news program at the time.
But he insisted on keeping Bayes secret, apparently because he wanted to keep his
Bayesian connections to cryptography secret, and he's been widely regarded as an enemy of Bayes
all this time. And of course, the Navy uses it to develop search theory, undersea search
theory, first for finding a hydrogen bomb that is inconveniently lost in Spain,
for the lost nuclear sub, the Scorpion, under the Atlantic, and then to catch Russian submarines
in the Mediterranean and the Atlantic. Now, as a result of this onslaught and the fact that they
couldn't prove that Bayes worked, the Bayesians spend this period on a lot of theory. And many
Bayesians of that generation remember the exact moment when the overarching logic of Bayes' rule
descends on them like an epiphany, and they talk about their conversions. We've seen Howard
Rafe and the decision trees. Now, during this period, both sides are proselytizing that their
version of probability is the only one that should be used, and both used religious terms.
When Dennis Lindley, who is one of the founders of modern Bayes, became the chair of an English
statistics department, the frequentist there called him a Jehovah's Witness elected pope.
He, in turn, when asked how to encourage Bayes said, attend funerals.
The frequentists retorted, if only the Bayesians had done, as Thomas Bayes had done, and published
after they were dead, we should all be saved a lot of trouble.
As a result, there were very few visible civilian applications in the mainstream during this period.
And when, for example, a physicist from MIT, Norman Rasmussen, was asked to make the first
assessment of nuclear power plant safety in 1973, 20 years after the industry had been established,
he had to use Bayes because there had never been an accident involving a nuclear power plant.
He used Bayes to unite not only things like the failure rates of pipes and valves and so on,
but also expert opinion to flesh this out. And he comes out with many of the things that
actually happened at Three Mile Island. But Bayes' rule was so controversial that he had to hide
the word Bayes in the appendix of volume three of his massive multi-volume Rasmussen report.
There was one big Bayesian application in the mainstream that was really public.
And that was a study using the words in the Federalist Papers for data, the classification project.
The Federalist Papers, of course, were essays written by our founding fathers to convince
the New York State voters to ratify the U.S. Constitution. And Frederick Musteller of Harvard
and David Wallace of the University of Chicago used Bayes to conclude that the 12 anonymous
Federalist Papers were almost indubitably written by James Madison, a decision that's held still
today. But they also discovered as a result of their massive Bayesian study an awesome result,
they said, that the century-long argument over the PA, the subjective prior, is irrelevant
if you have a lot of data to update it with. The problem was that Musteller had had to organize
an army of 100 Harvard students to input data and traipse the stuff across Boston and Cambridge to
the MIT computer center because Harvard didn't have one at the time. And it was a project that
no one else could even imagine organizing. Now, this begins to change in the 1980s, late 1980s.
Imaging from industrial automation, from medical diagnostics, from the military are all producing
blurry images, and they want to go back to the cause of those blurry images,
the original object that's portrayed. There were a very, there were a number of techniques
floating around at the time. Bayes, of course, Gibbs sampling, Monte Carlo, Markov chains,
iterations, and Ellen Gelfand, an American who's spending his sabbatical in England
with Adrian Smith, they put, all of a sudden they realize their breakthrough synthesis
and put all of these pieces together into what we call MCMC today, Markov chain, Monte Carlo.
They worked very fast because they were afraid everyone else would put the pieces together too,
but they also wrote very carefully. They only used the word Bayes five times in 12 pages.
And I asked Ellen Gelfand why, and he said, there was always some concern about using the B word.
It was a natural defensiveness on the part of Bayesians in terms of rocking the boat.
We were always an oppressed minority trying to get some recognition. And even if we thought
we were doing things the right way, we were only a small component of the statistical community
and we didn't have much outreach into the scientific community.
Bayesians thought their paper was an epiphany. And using the new powerful desktop workstations
that became available at the same time, and using the off the shelf computer programs developed
by a Bayesian, David Spiegelhalter, the bugs programs, Bayesians indulged in what they refer
to as a tenure frenzy of research. They could finally, after two and a half centuries,
calculate really complex real world problems. Outsiders from artificial intelligence, from
computer science, from physics, pour in. Bayes is broadened and refreshed. It's depoliticized,
secularized, and Bayes is accepted almost overnight as scientific revolutions go because
it became pragmatic and useful. Prominent frequentists even moderated their positions.
Bradley Efren, a national medal of science winner who had written a classic defense of
frequentism, recently said, I've always been a Bayesian. Thank you.
We've got about nine minutes for questions. Let's start over here.
Hi, I'm Rick Schwell, saving humanity from Homo sapiens. It occurs to me that one of the solutions
that could have been was to just replace the Bayes name and say, we have decided to use the Laplace
rule. And, you know, anybody who was a historian would know, oh yeah, Laplace again. And that would
have gotten around the security restrictions because who is going to be bright enough within
the government to realize he's talking about Bayes rule. And we classified that because it works.
Thank you. That's a very clever question. Until about 50 years ago, Bayes rule was known for Laplace's
work. He's now known mostly for the Laplace transform. But he was a French mathematician who
in the late mid 1700s, early 1800s, mathematicizes every field of science known to his era and works
on Bayes over 30, 40 years. But this idea of avoiding the word Bayes actually occurred to
Hans Bullmann. He is the Swiss statistician who works particularly in insurance theory
and becomes president of ETH and Zurich. And he's the one who said after a stay at Berkeley that
it was really kind of dangerous to talk about Bayes in the U.S. He goes back to Europe and
writes some very important essays, but he avoids using the word Bayes. He cooks up some generic
term, just very blah. And he thinks that helped avoid the continent, avoid this British North
American furor over Bayes rule by avoiding, just as you suggest, avoiding the names.
Could you walk us through a simplified Bayesian decision process so we get a concrete example
of what it is? Well, I'm putting together some simple problems that will show important parts
of Bayes rule. I'm putting them on my web and eventually they'll be put in the book,
either in the e-book immediately or the paperback. But basically what happens if you have a big
problem, if you don't have much data, you're going to, your prior is going to become very important.
And you can, how do I say this verbally? Sorry. If you have,
Bayes is filled with stories about people in bars or people dealing with black and white balls in
urns. Okay. Well, I'll do the bar one. Someone, you come into a bar and someone says,
I'm going to flip this coin and you're going to figure out whether it's heads or whether it's a
false coin. That is, it's two-headed or whether it's an honest coin. And he keeps flipping and
flipping. Now, your idea of whether he's honest affects how you, the probability of the outcome.
If you think he's dishonest, you make one probability that this coin is going to be
fair or not. If you think he's slimy or honest, really affects it. And that subjectivity, the fact
that the prior can affect the outcome is what enraged people. That's not a good explanation.
It's much better on my webpage. It's really nice there. I got Adam Albert Medansky actually suggested
it to me because he, he didn't think the example used in the New York Times book review showed the
crux of the issue. So he comes up with a really nice one. Yeah. Oh, sorry.
I'm Steve Kilpatrick. As an Irishman, I appreciate your bar analogy.
Makes the Bayes theory much, much easier to understand. At least it's not earns filled
with black and white balls, right? Very good. Is Bayes being used right now to solve any problems
that we might be familiar with? Is Bayes being used to solve any problems that we might be familiar
with? Right now, currently. Of what? Is Bayes being used right now to solve problems that we all
know about? Air France 447, they were able to retrieve the remains of 100 people and took them
back to France and gave the remains to their families. That's pretty powerful. They found
the pingers, the size of, of, they found one of the pingers the size of a cigar
and retrieved it. They found that the reason for this enormous search was that
it had been damaged in, in the crash when the plane hit, it hit in the back first and that absorbed
most of the energy of the crash and the pingers in the black boxes were back there. So the pingers
never worked. What can I say? I think that's, that's so, for those families it was and, and for,
for people like us who take planes all the time, we, we, they've come up with a lot of safety
resolutions that, that I hope will make things much better. One here in the middle.
Another important application of Bayes is in clinical trials. I think if Bayes serum was
more widely applied in adaptive clinical trials, we'd get a lot, a lot better data and have a,
a lot lower failure rate because it's hard enough to develop drugs as it is.
Any thought on how Bayes and frequentist statistics feed into medical trials today?
That's been quite slow. It hit the medical exams for quite, quite early in the 1980s,
I think it was, and they put some Bayesian probability problems on the exam and one of the
biggest, most read series of articles in the annals of internal medicine involved how you do
Bayes to pass these tests. But clinical trials, it's been much slower.
On the right, near the aisle? If you look at the autonomy literature, they claim that their
intelligence search and other things is based almost completely on Bayes'
theorems. It's British work. The company CEO who invented the technique got a lordship out of it.
And now they have the Dugas honor of having been bought. A stock market company
valued at about $4 billion was bought for $10 billion by HP. So I don't know whether that's
a plus or a minus, but here's some more Bayesian for the...
Now, a lot of artificial intelligence does not use that prior. It eliminates it.
And that's the cause for controversy still among Bayesian theorists. And they go across the spectrum
thinking that to have Bayes rule pure, you must have the prior. And then there are those who say
you don't need it. And there are the ones in the middle who say whatever works is okay.
We've got time for one more. Is there one on the left here on the aisle? Yeah, coming to you.
So I just have a question about any thoughts on why it works? Like, you know, I've got no
knowledge about anything. I'm just going to incorporate my random guess about a particular
probability into an equation. Why does that improve the... What's the philosophical
underpinnings of why that produces a better answer? Well, that was what... It took me seven
or eight years to write this book. And what kept me going all that time was to answer your question
that many people see this as the natural way of learning, of you start out with an idea,
but you modify it as you learn more and you get more data. And to me, we live in such a dogmatic
age that to say we can have an initial idea about a situation, but we must... We are committed to
updating it as each piece of new information arrives. I found that very congenial. There was
the British economist, John Maynard Keynes, who said it with kind of a knife. He said,
