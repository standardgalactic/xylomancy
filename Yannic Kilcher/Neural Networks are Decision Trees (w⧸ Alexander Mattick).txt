Hello, everyone. Today we're talking about neural networks and decision trees.
I have Alexander Matic with me, who is maybe you want to introduce yourself.
Yeah, I'm currently a student at FAU in Germany.
And most people don't know me probably through for Yannick, for his discord.
Well, I'm one of the people who manage the paper discussions every week
and present more of the theoretical papers, usually.
So we came across this paper all across social media.
I saw it at one point and I'm like, meh.
And then I saw it like all over LinkedIn being like, whoa,
neural networks are no longer a black box.
We now know what's going on.
I saw it on Twitter.
I saw it essentially like it like really got some some push behind it.
As I said, when I first saw it, it was like, meh, this has been known for a while.
So what does this paper say in a general sense?
And has it been known for a while or is there actually something in there?
OK, so basically what this network does is what this paper does,
it shows how you can basically take a neural network,
which is like a sequence of weights with nonlinearis in between.
And then you can kind of each virtually if you rewrite them
by effectively pulling out the right slopes
and merging them up into new weights.
And that would give you effectively this kind of structure.
It's important to say this is only for if the if the nonlinearity is
piecewise linear, for example, a ReLU nonlinearity.
Otherwise, we would have an approximation, but this is actually
any exact mapping that we're doing right here.
So we just rewrite the neural network somehow and then we get out what?
So we get out such a tree and effectively you can see these
W hats here and these W hats, I think they're defined somewhere.
Yeah, I think somewhere up here.
Yeah, effectively just unroll the piecewise slopes always from the layer above.
So effectively we go and we draw the different cases that happened
through the previous layer, we draw them up into the subsequent weights.
And that gives us kind of this tree structure because we, of course,
get this unfolding of kind of which path can we go in the neural network?
And then the next net then the next lake and kind of enhancing that path and so on.
I think it's still a bit unclear, maybe to some people who are not super familiar
with this, they might be under like the general notion is a neural network
is a nonlinear function, right?
Therefore, I wouldn't just be able to represent it with a single,
even if the W and the W hat are different, right?
I still at the bottom here, I see, you know, X times W something.
Which is a linear function.
So why all of a sudden I have a neural network?
Why do I arrive at a bunch of linear functions?
This mostly has to do with the fact that neural networks intrinsically
are just compositions of these piecewise linear functions.
For example, there's been more recent work here in the spline theory of deep learning.
So more recent work, more recent than the paper we're looking at.
No, recent in a sense of it was published after 2000.
OK, this is paper from, I think, 2018, and there they make this very,
very explicit where effectively they show that you can unfold almost every
network into what is called splines.
And you can think of splines as regions, which then in and of
themselves are affine linear.
So it's a linear transform with some bias against it.
And these deep neural networks are just different regions, all of which have
their own slope and slope and bias.
If we imagine a neural network with ReLU nonlinearities,
if we imagine a point somewhere in the input, if we move that point,
like just a tiny bit, then we move it small enough so that none
it crosses none of these boundaries.
So ReLU is essentially like this.
So it has like a boundary here where the slope changes.
But if we move just small enough that either the signal is in the slope,
so it changes a bit in the slope, or it doesn't change at all because
it's in the zero part.
So if we move just a bit, we don't change the ReLU activation pattern.
And that essentially means since all the functions are either linear or
piecewise linear, but we don't switch the piece.
That means that within such a ReLU cell, it's essentially a linear function.
I think that's what we see here at the end of the decision tree.
The decision tree essentially says with this particular input,
which of these ReLU cells am I in?
And at the inside of that cell, it's actually a linear function.
And that's what's described here.
The neural network in total is nonlinear because obviously we piece together
super many of these tiny ReLU cell regions and that can make
something that appears almost like smooth.
Because if we zoom out, then it's like a video game where everything is
made of triangles, but you zoom out and it kind of looks round.
It kind of looks smooth.
The paper shows you can rewrite the neural network and you get something like
this. What does it mean?
That's an entire different question because there are many different ways
of viewing such a conversion.
One is through a practical lens.
Another one is from a lens of what does it help us to study decision trees?
Another one is how does it help us to study neural networks?
From a position of studying decision trees, it doesn't really help us that much
because neural networks are inherently a lot more
impenetrable than decision trees.
Really studying a neural network and that helping us to figure out something
about decision trees is rather hard.
Additionally, we have the problem that decision trees
fundamentally, so the decision tree learning algorithms we built are,
they themselves don't map to neural networks perfectly.
What I mean by that is you can take a decision tree like this thing here
and transform it into a neural network.
However, during the decision tree training process, what you usually
do is you take one of those effectively edges and then you split it up
into two lower ones.
And for that, you may need a new neural network because the capacity
of the original one doesn't work out anymore.
So from a perspective of taking a neural network and then helping to figure
stuff out for decision trees, it's pretty hard.
On the other hand, we can use these decision trees to find,
figure out stuff about neural networks.
There's a lot more promising, but there's often the case that to do the kind
of analysis you can do with the decision trees, you don't necessarily have
to explicitly build this tree, like the spline theory of deep learning
paper, which does lots and lots of analysis.
So for example, there was a recent paper, which specifically looks at
what batch norm actually does through this lens, but they don't need to
build the explicit decision tree because they are just interested in
this piecewise linearity, they're not necessarily interested in how exactly
this fits to the actual neural network part or the actual tree part.
And then last but not least, we can also analyze it through the view of let's
take an existing neural network like a ResNet and try and make it more
interpretable.
So that's where I also saw a lot of the hype going on because decision
trees are more interpretable.
They, you could obviously go and take a ResNet, transform it into a decision
tree and have this great interpretability.
But in practice, this doesn't really line up that well.
And the reason is again, kind of connected to this idea of decision
trees making it being small and then progressively growing when neural
networks are large and just basically large enough to fit everything inside of
them.
That means that the actual size of these neural network trees can become
rather gigantic.
The way we can do analysis with theoretical lens is by studying something
called the VC dimension or the Vapnik-Schevenenkin's dimension, which
effectively just tells us how many different points can network distinguish,
which of course for a decision tree, if you have a fully balanced tree like
this one would be two to the power of the depth of the tree.
While for a neural network, it's a lot harder to figure out because you have
all of these different architectures.
What you can do though is we can go in, we can bound this and there's been like
lots of work in trying to figure out bounds.
So for example, the best bound I could find is from this paper from 2017,
which provides nearly tight bounds.
And specifically, they provide this kind of theorem for a lower bound, meaning
what they basically shows there's some universal constant, which has this
constraint.
So effectively the square of it has to be less than number of weights.
You get a minimum amount of regions of resolution for a neural network.
Of W, so the number of weights times L, which is the depth of the network,
times the logarithm of W over L, and then you have this C constant in here.
So it effectively means the number of regions we have scares a little bit more
than linearly because we have this W in the log and it stays a little bit less
than linearly with the number of layers because we divide by L here.
So if we now take this absolute lower bound, so what we can say is because we
divide by C here, we can just set W equals to, so we can just set C square
equal to the square root of W because that's kind of the worst case scenario.
It gives us the smallest bound and we can try to run this.
So I have here this very trivial neural network, which has one hidden layer.
We go from one to one.
So like this, or we can also look at something like 1024 to look at something
that would happen, for example, in a transformer, we have these individual layers.
If we run this, we get for this relatively small network, we get a depth
of this full decision tree of about 16.
If you would try to plot this, so this is now going to run for a very, very long time.
I mean, 16, it doesn't seem that much, but this is essentially an exponent.
This is an exponent.
So it is a giant number.
Yeah, we have two to the power 16.
Again, I'm taking here that I'm routing the depth down to the power 16 different regions,
which is going to crush most algorithms.
Even if you could build such a decision tree, so actually build one,
it becomes rather hard to reason about them simply because the reason
their networks are hard to interpret is not necessarily because each individual
component is hard to interpret.
It's because the emergent properties of putting all of these things together
and these billions of parameters or millions of parameters even together,
that makes the problem hard.
Yes, and I was so just to say that this 16 depth tree, that's kind of the best
case scenario, right?
That's our bound on what would be possible in order for a
transferring a neural network to like, what's the minimum size of tree we need
to even represent that it could be the case that it's more.
But that was my impression as well is when I look at a decision tree,
I have sort of one path to go down to make the decisions by, right?
But if I look at a classification problem, it's not always one path.
It's not just, you know, is the picture bright or dark?
Well, okay, if it's dark, is it this and this?
At some point, you get the same question, right?
Is the picture bright or dark?
Yes, is there a small or a large object in it?
Let's say this question, you might want to ask whether it's light or dark.
So you have like a matrix, right?
Light picture, big object, light picture, small object, dark picture and so on.
And but these are represented by two different nodes in a decision tree.
No matter how you, how you structure it, you have to ask one question first
and the other question later.
And that means one of these questions is necessarily going to be represented
by two different nodes in the decision tree.
And so that just for me, looking at the decision tree, I no longer notice,
I no longer recognize or the algorithm doesn't anymore tell me that these two
things are actually related in some way.
So whereas in a neural network, I have internal representation, I have features
or weights that, you know, look at particular features inside of these
representations, one set of the neural network might look at the lighting
condition, the other part of the neural network may look at the shape of something
and they can work in parallel.
In a decision tree, it's one after the other.
And therefore I'm no longer, the analysis gets way harder because stuff
in the decision tree happens everywhere and it doesn't.
No algorithm can tell me, by the way, these things represent the same feature.
It kind of boils down to this fundamental tension between having
parametric and non-parametric approaches.
Because for the people who don't know the, the distinction here is effectively
a neural network is a fixed skeleton with lots of blank spaces and the
objective of fitting to that, fitting the function in that neural network is
figuring out what should be put into its blank spaces.
This is a parametric approach because we have lots of parameters.
Decision trees are non-parametric approaches.
So what you do is you effectively say we have this entire family of different
trees which not only have parameters like this W, but also you have effectively
the architecture which gets optimized along the way.
And if you have non-parametric approaches, this usually gives you way different
classifiers because in a parametric approach, because we have stuff like
gradients, which make a lot of sense in parametric approaches, you can say
something like, I don't necessarily want an optimal split, I just want some split
that effectively amounts to you go and you take this W and just move it around
a little bit to go, to go closer to a good split, but decision trees do it a lot
differently because this decision trees have to work with this gigantic family
of functions.
We now have to do optimal splits, at least to some optimality constraint because
you just randomly kind of pull out decision trees and try to figure out is
this the right decision tree, you're never going to be able to finish.
This is also why decision trees tend to work well in stuff like tabular data
sets because you have relatively few features which are very well defined and
you can compute the statistics for them, which help you to figure out what would
be the perfect split for a specific feature and which feature should split
next, while for something like an image, think about it, you have an image which
is 224 by 224 by three RGB channels.
The statistics you can get even with a massive data set are not that great,
especially since you have to consider things like shifting around the image a
little bit to basically make the statistics more robust.
And that means it's very hard to fit a decision tree because statistics are
always bad.
Under network performs way better because it doesn't care about how well it
split us, it just does some split and hopes for the best.
This means that under network is by its nature going to be less optimal, but it's
also going to make some progress, even if they are only very bad statistics.
Well, decision tree always has some sense of optimality if you fit it with
something like cart, because you only do somewhat optimal splits.
Of course, at the cost of you have to have some notion of what optimal means.
So you have to know, so you need those statistics.
Yeah.
And something like this algorithm, it is a decision tree.
So it's what one would call a simple function in like Mathematica speak.
So decision trees are effectively just nice representations of simple functions,
but it's not really a decision tree as it would be produced by a decision tree
algorithm.
And that's the problem what makes them unintroparable because they just grow
without bounds, these neural network trees.
So when we look at, let's get back to the paper at hand.
By the way, this is still running, which I like.
Back to the paper at hand, is this, is the proof sound, the proof that neural
networks are decision trees, right?
It's like, it is, it is absolutely sound.
It's not wrong.
All good.
Is it new or unknown?
No.
So there are multiple things to that.
One is there are already papers in the past which did that.
So for example, this paper I think is from 1999.
Yeah.
November 1999.
They also showed like algorithm for extraction of decision trees from
artificial networks.
So this is known.
And it's also one of those things that often just happens to plop out as a
corollary.
So there are very few people who go and explicitly write this proof down
because it's kind of a natural thing that occurs.
If you have some algorithm which splits the world up into kind of classification
polygons or simple or simplices or affine regions, which for example, this
paper does, then getting this decision tree form is effective.
Just a corollary.
It just plops out passively.
So this paper here, for example, the spline theory of deep learning paper
could easily just say, well, yeah, the decision of which spline we're in is
made hierarchically in the form of a decision tree.
So it would be a one sentence and that just plops out.
The same would be true for many of these theoretical proofs where first of all,
very rarely do you actually need this decision tree kind of realized.
But oftentimes the proof behind it that, for example, abuses the fact that we
have this really max function, which effectively tells us to go either to the
left where you have the zero region or to the right where we have new values.
That is often just there.
You don't need to do any more to get the actual decision tree out.
I also, I know this from, um, because I used to work quite a bit in the
field of adversarial examples.
And there I think it was made oftentimes quite, quite explicit to some degree
because obviously people, as long as stuff is linear, you could have some,
some kind of bounds on how worse it can get.
But then as soon as it's nonlinear, uh, it gets a bit more
tricky.
And you've also shown me before, like a paper on verification of neural
networks, which is exactly right, uh, sort of in this area where people are
trying to say, well, how bad can it get?
And they use the fact that also there we have these, essentially these,
these cells of linearity.
So what are the problems?
That's also what this real complex algorithm, the idea is that you can view
this max operation effectively as splitting everything up into a simplex.
Then you can make arguments about, uh, with something like an SMT solver,
you can try to make arguments.
Okay.
What happens inside the simplex or basically what can happen inside the
neural network, and you can do that to guarantee some safety,
guaranteed to have some safety guarantees, but even this algorithm gets
crushed at scale and the scale, as we've seen here, I think it's still running.
Yeah, it, it explodes rather quickly.
So, and they of course don't explicitly build this, but yeah, this,
this idea of neural networks mapping well to decision trees,
kind of boils down to the fact that a feed forward network is effective.
It's just a gigantic graph.
You can just take every, you can effectively compute the spanning tree of that
graph and that gives you a decision tree, at least in the case of a relu.
And that's basically also what this paper does.
We compute the spanning tree by computing these w hats,
these w hats, take the slope from, uh, take the appropriate slope from the
previous layer and come and build up the appropriate w hats.
So maybe for, for people, so the, if you, we can just go to these formulas
with one of the A's, because that's kind of the crucial part of the math
right here is these A vectors.
Uh, and you have to like, it still seems a bit like magic.
We have like the nonlinear composition of function.
And then all of a sudden, we have these A vectors and somehow now all is
linear, but one has to remember that.
So on the bottom here, we have the nonlinearity that not, essentially what
I do is I take the signal that comes through the network at, and I look at
the signal at the nonlinearity.
And there I say, well, where is the signal such that the relu is active?
And where is the signal such that the relu is inactive?
And I just replace that by a vector of ones and zeros or, or the, the slopes
and zeros, right?
But these, these vectors are dependent on the signal.
And that's why the, they're going to look different if the input is different.
And that's why it's a linear function for a given input in a given very tiny
circle, right?
So that's, I think that's the connection.
Now the paper also has some experimental result.
And there is a small claim, but there is a claim that the decision tree
representation might be advantageous in a computational manner.
So they have a table one comparing the decision tree and the neural networks
for the same function in terms of their computational complexity.
So it turns out the decision trees have more parameters, which is, which is
a odd for nonparametric function, but I guess they're not learned parameters.
Yet the neural networks use more multiplications and additions than the decision tree.
What do we make of that?
Well, computation often is not the same as computation because you may have
more multiplications or additions, but they may be in a forum, which is just
nicer for, for you to work with.
So for example, if we look at the trees or like here, or let's go back up to
the, this kind of prototypical tree, where effectively we have these, these
multiplications with the, with this X zero input.
What happens is that we do have fewer multiplications using that structure
because effectively we abuse the fact that we don't have to compute the entire
matrix.
We only have to compute the part which is actually going to be relevant for us
later on.
That of course reduces the amount of multiplications.
But on the other hand, we now have this spreading out.
We have more decisions in here and less multiplications.
And depending how your, how your hardware ends up, it might be that basically
paying for more computation and having less decisions is better.
That's why training a decision tree on a CPU makes more sense than training it
on a GPU.
On the other hand, there are also approaches which take decision trees and
basically compile them into, well it's effectively binary matrix multiplication.
These algorithms tend to, of course for inference in that case, but these algorithms
tend to be a lot faster simply because even though you do more addition and
multiplication and stuff like that, you end up having so much parallelism that
this, what is it, a factor of four roughly is not that meaningful.
Or it's closer to three.
Well, on the left, it's eight, but it's two versus 16.
Well, in any case, but, but that's, that's the point, right?
If, if one were to actually implement the decision tree on like a GPU, one
would actually regain all of these multiplications and additions because it
just makes more sense to put the binary vector there with a lot of zeros and then
multiply all of these zeros instead of trying to mask out stuff.
And because the GPU can just parallelize so hard.
Yeah, it's mostly that GPUs don't tend to do well with lots of decision making
and lots of sparsity because just of the way they are designed, they're designed
to do large operations on a lot of data very basically monotonically.
They, they just do a large matrix multiplication with very little decision
making every single one of these thousands of course, effectively does exactly the
same thing.
And that then gives you kind of this boost because there are thousands of
cores doing very simple, very repetitive actions.
And if you have more decision making, you have more decision making in there
that just makes it slower.
I think I interviewed a near chavit of neural magic and effectively they're
they're doing something very similar where they say, okay, what we do is we
take like a BERT or something like this, we prune it very in a, in a, in a
special way such that the rest is something we can infer on CPU really
well, which is essentially like very similar to, to this paper right here.
So the idea of sort of pruning it down and all of a sudden you may end up with
something that sparse requires more if else, but then is very much suited to a
CPU.
If we think about maybe the last question for today, if we think about, okay,
this, this, this paper is, is, it's certainly correct and all, but we think
it has, it has been known or it's, it's, I don't like the word trivial, uh,
because nothing like I used to hate that as a student because to me, nothing ever
was super trivial and it's, even if it's trivial, it's good that it's written
down explicitly somewhere, right?
You can point to a place here, but in a sense, it is like something that a lot
of people have just kind of done on the side because it, it is fairly like
natural, a natural outcome of working with these, these systems.
But if we look at it a bit beyond that and say, is there a, a way in which
decision trees can kind of make a bit of a comeback in today's world of deep
learning, maybe not as a substitute, but as an augmentation of neural networks.
Can we like, what kind of properties does a problem need to have such that a
combination of something like decision tree algorithms, like decision tree
learning algorithms and neural networks are the best?
So decision trees really like to have these very, very well-defined statistics
because that helps them to do their splits.
Effectively, neural networks scale with gradients.
So if you can't get gradients, you have a hard time and they also scale with size.
Simply because as we've seen here, you just get more possible, uh, more
representational power.
So it's just better.
You can effectively simulate a small decision tree inside a large neural
network, but just setting everything else for zero around it.
The trick that makes decision trees work well is if you have these statistics.
So that's why decision trees work incredibly well on something like tabular
data.
Like you can also tabular, like deep learning, but that's probably like you're
going to go, you're going to do research, you're going to do probably a PhD and
out plops, a project, which may or may not be competitive on tabular data.
Well, in the other hand, I can just use XJ boost and get great results right now.
What it would want to do to get decision trees to work well is it would want to
take these very, very high dimensions, very, very information spars, for example,
images and transport it into like a lower dimensional space where it can then get
the statistics.
So for example, if we have a two-stage approach where you have a main neural
networks inferring different features of the same thing.
So you first try to classify whether it's a cat or a dog, then you try to
classify, I don't know, its size or whatever, and you put them all down.
Then you can start doing a decision tree learning.
And the decision tree is probably going to be a lot more performance simply
because you get this smaller size through the fact that the decision
tree is much more optimal in how it uses its splits in capacity.
It seems like the current wave of self-supervised learning might actually
be a good candidate to build something like this on top because the self-supervised
algorithm, they tend to sort of extract many different kinds of features.
Whereas like if I pre-train a classifier on ImageNet, let's say, that classifier
is going to be a tune to very few features for the bunch of classes it needs to
classify, but just from what I can observe the self-supervised approach is
they just tend to kind of get this rich representation out of images.
And we see that if we look at anything that uses a VQ GAN encoder nowadays,
which is almost all of the AI art projects.
So they're so rich, such a rich representation.
So this could be, especially maybe the quantized stuff, could be like a very
fertile ground to then put like decision trees, random forests, whatever on top of that.
Yeah, cool.
All right.
I think that's that's about the paper is kind of really short.
It's, I guess, four or five pages.
If you if you if you, you know, it is it is very like, I think it's very approachable.
So, you know, if you've never heard of any sort of equivalence like this or
or any math in this area, it's very helpful, I think, to actually look at it.
And just see how it's done.
I give you a bit of an insight.
And yeah, Alexander, thank you so much for being here.
It was a pleasure.
Thank you for having me.
Cool.
And everyone, if you want to hear more rants of Alexander and myself, we have
discussions on Discord almost every Saturday evening.
Well, in at least evening in Europe.
Right.
Cool.
Bye, everyone.
Bye.
