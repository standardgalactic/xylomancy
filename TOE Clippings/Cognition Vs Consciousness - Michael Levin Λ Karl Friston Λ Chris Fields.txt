Professor Levin, what puzzles do you find most important?
What do you think about on a semi daily basis or even perhaps multiple times a day?
And then we'll go around the table here with Chris Fields and Carl
first and next, and then it's essentially me taking a backseat and allowing you all
to free flow just for the audience to know.
I know you all know this template already.
Yeah.
So the thing I think about many times a day has to do with the scaling of cognition.
So I want to understand two major things.
One is how it is that some collection of competent parts comes together to form
an emergent self with preferences, goals, memories, cognitive capacities that belong
to it, but not to the individual parts.
So I want to understand how that how that emerges, how the goals of sort of humble,
simple, simple kinds of systems scale up into much more grandiose goals that we see
in during development, during behavior, during culture and so on.
And I'm also very interested in the sort of the left side of that spectrum.
Where does it begin?
Is there really a zero on the spectrum?
I think that all of us here would agree that there is a spectrum for these things.
It's not a set of binary categories.
But what happens at the very left side of the spectrum?
And so one of the first questions when we get to that that that I'd written down
to ask both both Chris and Carlos to sort of comment on what does the what
does the Venn diagram look like of the set of things that are alive versus the set
of things that are cognitive?
Yeah, how do those two categories relate to each other?
Do they overlap as one is subset of the other?
And what really happens at the very beginning?
You know, like, can we can we develop a kind of
which I think I think both of them have been working on a kind of basically a kind
of panpsychism that doesn't doesn't sort of paint on new cognitive mysteries
on top of a physics that works perfectly well, but instead to try and to try to
view physics from the bottom up as having already a useful cognitive lens on it.
And how does that help us to build up cognition?
So that's that's something that I think about every day.
Is there a difference between cognition and consciousness?
Is one distinct? Is there overlap?
Someone to subset?
I actually can't conceive of cognition without consciousness,
which I I prefer to call awareness
not just to be perverse, but because in many cases
consciousness is used in a way that implicitly means self consciousness.
Whereas awareness is often used in a way that does not make that implication.
And it's I find it difficult to conceive of cognition without any kind of awareness at all.
So so so I'll ask a question based on what
Chris just said and what you know and what Carl has to say about it.
So so what do you think about the so-called hard problem?
Is there in fact a hard problem at all?
I would.
I would take Andy Clark's view on this,
who has worked closely with David Chalmers.
I don't think so.
No, I don't think that the hard problem in and of itself is
is the interesting focus of inquiry.
I think the the move that I see in philosophy
has been to the meta problem or the meta hard problem, which is,
as Andy Clark puts it, quite succinctly, is why do we spend so much
time puzzling about why we are aware?
So just asking that question
speaks to, I think, the nature of the hard problem, which is a sort of very much
a second order meta, a meta capability that we can make sense of our own sense making.
And we associate that with selfhood.
So one has to ask the question, what kinds of systems, again,
I think, particles or creatures would have the capacity to represent selfhood
and, furthermore, represent the counterfactuals
that would enable you to ask the question, why am I conscious?
That immediately just logically presupposes that there is an alternative
hypothesis of other counterfactual that I'm not conscious.
So imagine now you're talking to a creature, you're talking to me,
there has this capacity to imagine counterfactuals that cannot exist.
So that's a remarkable capacity to have,
from my point of view, an internal world model or a generative model
where counterfactuals can exist is quite remarkable.
I don't imagine that a thermostat or a virus or an E. coli will have a
sufficiently sophisticated set of electrochemical dynamics or kinetics
that would enable them to physically represent counterfactuals of this sort.
And I could go on,
the usual line of argument is why do we have models?
Why do we have the capacity to represent counterfactuals?
You end up with saying, yes, you have to have them.
Just if you
contemplate things a plan.
