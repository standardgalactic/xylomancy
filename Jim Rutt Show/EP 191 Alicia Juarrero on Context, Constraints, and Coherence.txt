Howdy, this is Jim Rutt, and this is The Jim Rutt Show.
Listeners have asked us to provide pointers to some of the resources we talk about on the show.
We now have links to books and articles referenced in recent podcasts that are available on our website.
We also offer full transcripts.
Go to JimRuttShow.com.
That's JimRuttShow.com.
Today's guest is Alicia Herrero.
She's a professor of philosophy emerita at Prince George's Community College in Maryland.
This is kind of old home week.
I actually grew up in PG County as we used to call it in the day.
They tell me you're not supposed to say PG anymore, but that's what we always call it.
No, we still do, yeah.
I lived there from the time I was two to the time I was 22, and my wife is from PG also.
So it's really, my brother is a distinguished alum of Prince George's County Community College,
and probably half my friends went there, so it's great to connect with Alicia.
You know, she is a complexity person.
She is the author of Dynamics in Action.
I have not read that book, but I ordered it and look forward to reading it.
It looks actually very interesting.
And she's co-editor of Reframing Complexity, Perspectives of North and South,
an emergent self-organization and complexity precursors and prototypes.
And she's written lots of publications and refereed philosophy journals.
She's also written a couple of things that I read while I was doing my research for this episode
that I think the audience might find interesting.
One's called Downward Causation, Poliani and Progosian,
and another one called Western Science and Philosophy.
Can't deal with the relations between parts and holes.
You know, they're pretty serious, but they're not quite scholarly papers, right?
And so I think our audience could deal with them.
And as always, links to those papers and the books will be on our website at JimRucho.com.
So welcome, Alicia!
Thank you for having me. It's a pleasure to meet you.
Yeah, it's a very good conversation.
I really enjoyed reading the book. It's quite short, 235 pages, but it is chock-full of stuff.
I mean, there's lots of ideas in this book.
In fact, we probably aren't going to get to them all.
My topic list is, I try to keep it to seven pages, but it looks like I got more like 11.
So we'll see how far we can get into it.
I'd also like your writing styles very clear.
Oh, no, it is not.
You must have not read much of it because it is horrendously...
No, no. For a philosophy book, it's damn readable.
No, no, no, it's awful. I wish I were here.
No, no, no. I would disagree. I would disagree.
But today we're going to talk about her newest book just published called Context Changes Everything.
How Constraints Create Coherence.
So the book was just published a couple of weeks ago, right?
A couple of weeks ago, yes.
Yes, we'll have a link to the book on the episode page.
So let's actually start with something.
We talk about a fair bit.
A number of our guests, for some reason, have found this framing useful.
And that is Aristotle's Four Causes.
This is a theme that runs throughout the book.
Why don't you remind the audience what the Four Causes are and what they are?
Well, I think Aristotle probably got it from the potter's wheel.
You know, he started thinking about causes and effects using the example of the potter's wheel.
Four Causes are material cause, the clay, the stuff from which the pot will be made.
Then final cause or purpose or teleology, which is the goal to which the thing that you're making will be put,
which is pouring water.
So the final cause of the pitcher would be water.
The formal cause, it's not quite shape.
It's sort of the, what makes a pitcher a pitcher?
So it is the essence, the basic fundamental identity of the thing.
And then finally, efficient cause, which is the actual force exerted by the hands and on the clay to turn it into the pitcher.
So it's energetic.
Efficient cause is energetic exchange.
One of the things, a point you make is that prior to maybe the late 16th century,
people tended to consider all those causes when they were thinking about nature and the pre-scientific era.
But one of the moves that probably came off accidentally more or less from the invention of modern science
was a very heavy focus on the efficient cause.
Correct, correct.
In a sense, material cause, people figured well, science will take care of that.
And formal cause and final cause were sort of discarded.
They went out with a bustle.
You know, this is something we don't have to worry about anymore.
So we can explain everything in terms of forceful causes.
It seems to me that when you're talking about complex dynamical systems,
somehow final cause and formal cause kind of gets snuck in, indirectly, not the way Aristotle thought.
Aristotle thought people were born with organisms or all natural phenomena,
had an inherent internal entelogy, internal, kind of like an acorn,
has the form of an oak built into it, and all it has to do is unroll and unfold into the final form.
But I think what we have now with complex dynamical systems is that interactions with the environment
and, in my view, constraints are the contemporary version of formal and final cause.
Yeah, and the over focus on efficient cause, matter and motion bumping into each other,
I often refer to that as naive Newtonianism.
And, you know, most nerdy smart kids go through that period, right?
They make the error of thinking the famous Laplacian area, where he says,
yeah, give me the position and velocity of everything in the universe,
and I can predict the future and the past with total precision.
But fortunately, once you get exposed to ideas of complexity, you realize it's completely crazy,
and that is actually caused for those people who've gotten the complexity lens
to realize there's much more to our universe than naive Newtonism.
But it's amazing how it's persisted, and you can't blame people.
I mean, it seems to do a hell of a job predicting eclipses,
but even Newton knew the three-body problem would mess things up, right?
But that was a warning Newton gave us that went unheated for many centuries.
My first paper was about Kant and Prigogene and exactly about that subject matter.
And then, as you talk about in your book, one of the current manifestations of it,
it depends where you are in the sciences.
Now, I've had the good fortune to be around complexity people for the last 20 years,
and so there's much, much, much less of that there,
but I suppose out in the wilds of solid state physics and places like that,
there's still a lot about what you call nothing but ism, right?
Explain what nothing but ism is.
Well, the idea that the whole is nothing but the sum of its parts,
and therefore anything that appears to be an emergent property is really an epiphenomenon.
It is sort of froth that's thrown up, but it really has no causal power.
Well, of course not, because if causal power is only thought of as efficient causality,
then clearly the synchronization of the photon streams in a laser beam
don't align their component laser beams as another efficient cause, so that's the problem.
Yeah, it leads very quickly to absurd conclusions,
which makes me wonder why did it hang in there so long?
Well, and you know where it hung in?
I came at this because I wrote a dissertation on the difference between explaining and justifying behavior.
Well, justification has to do with moral reasons so on, but explaining behavior,
the first sense of that first book that you quoted is what is the difference between a wink and a blink?
Presumably it's the cause, right?
Meaning that an intention causes a wink,
but a, my throwing some sand in your face would cause you to blink.
Well, but then the next question is what the hell's an intention,
and how can an intention cause the action in an efficient cause way, correct?
And my answer was obviously, well, there can't be just one neuron pushing another neuron pushing.
I mean, forget it, that doesn't work that way.
And at the time I was living in Berkeley and I was hanging around people who were into network theory
and systems analysis and so on.
I'm going, you know what, there's got to be a network property.
We're talking the 70s, Jim.
There's got to be a network property that somehow produces emergent properties,
which in turn can loop back down and cause the neurons that are responsible for motor control
to move the arm in a way that it satisfies the intention that I started out with.
All right, so how is this going to work?
You were talking about PG Community College.
The nice thing about teaching a community college is nobody gives a damn if you publish anything or not.
You're going to be judged by how well you teach.
So nobody cares about whether you publish.
On the other hand, nobody's forcing you to write papers on the fifth decimal point of the existing theory.
So I could play around and in this area in DC, I could hang around NIH and start listening to people come talk.
And so you start understanding how patterns in neural systems work and so on and so on.
It's got to be something like that.
So that's when I decided, all right, you know what, I'm going to give the term cause to the Newtonians.
I'm not going to fight that battle.
It's going to take me forever to fight that battle.
So instead, what I want to do is look at the notion of constraint because as soon as the hard scientists get into trouble with that Newtonian,
silly understanding of efficient causes, you mentioned, they retreat and hide behind the notion of constraint.
And I thought, you know what, that's going to work.
So that's how the whole, that's how my trajectory towards reconceptualizing causality and especially formal and final cause in terms of constraints developed.
It's interesting and actually it worked well with the little analogy I use when I'm trying to explain complexity to just random people at a party or something.
I will say, you can think of reductionism, you know, classic science as the study of the dancer while complexity is the study of the dance, right?
And a dance is not random motion.
It has constraints, right?
If it's going to be, it's going to be a jitterbug.
It has one form of constraints.
If it's going to be a waltz, it has another.
And so when I read that and saw the movie you were making, I say, works perfectly with my good old.
Absolutely.
Absolutely.
My good old analogy.
Absolutely.
And it held together quite well.
So now let's move on to your next topic, which is a term that most non-philosophers will have never heard of.
I've heard of it a few times, but it's not term we use very often at the Santa Fe Institute.
Myriology.
Is that how you pronounce that?
Myriology.
Myriology.
That's, again, the whole parts, parts whole.
Because let's use an example from Brian Arthur's note.
I love that Santa Fe book on complexity of economics, economics and complexity.
What an economy is are a bunch of individual elements that interact in a constrained way to result
in an emergent phenomenon that has certain properties that the components don't have.
An economy has certain characteristics that the individual trader and seller don't.
But once that whole WHLE, which is a coherent whole, and I really want to emphasize the fact that a coherent whole is different from a
mass clump of stuff because it's organized.
And what organizes it are the constraints.
But once it's organized, then all of a sudden the components also acquire different properties because suddenly they are now traders and regulators and so on and so forth.
Correct?
So there you have the whole part.
The parts of the components, correct?
And the inter, the constrained interactions among the components.
The whole is what I'm calling in this new book a constraint regime.
Because one of the problems we've also had, I don't know if it's Newtonianism or what, but we tend to reify things.
Things, no pun intended.
We tend to reify things.
But an economy is nothing other than all these constraints all held together by an overarching set of constraint regimes once the constraints close into a coherent whole.
But they can then loop back down and affect their components and they acquire, they acquire, now they have a role, right?
In a society, once a society is a socially organized structure, people can be citizens, they can be senators, they can be teachers.
Those roles don't exist except within an organized society.
So then the next question is, well, on a more general level, what is the relationship between the parts and the holes and the holes and the parts?
If you really buy the whole Newtonian idea, ain't no difference between the parts and the holes, the holes are nothing but the sum of the parts.
But that means you cannot explain how it is that my behavior is constrained top down by my living in a particular culture.
The fact that I was born and raised in Cuba, the fact that all of these affect my behavior, but they don't do that as an efficient cause.
A culture, an economic system doesn't cause my behavior to differ in any kind of efficient cause way.
But since the Newtonian Revolution, pretty much myriology got thrown out of the picture.
So that messes up philosophy of mind because you cannot explain mental events.
If you think of mental events as emergent properties because they should be reducible to a bunch of neurons pushing each other around.
But where does the emergent property go when you have that?
I'll tell you a little example. Again, my little homey examples that I love to use on this is people who doubt.
We'll get this later, the idea of top down causality.
I say, let's imagine me dead and run through a blender and poured into a bathtub.
What's the chances that those chemicals are going to hop out of the bathtub, walk down the hill and go to the ice cream store?
Essentially, zero.
On the other hand, if it's me and I'm operating up in cognitive space and it's after dinner and we just had a nice dinner
and I feel like a walk with my wife to go down and get something nice, then we may decide to haul all these atoms and molecules
and they have nothing to say about it because this top down idea, let's go get some ice cream, causes the,
and by the way, Newtonian physics is never, let's say physics is never violated, right?
The atoms are dragged along and they are dragged along through efficient causes.
They're all stuck together and bound by various forces, but the decision to go get the ice cream came at a higher level in the stack.
And again, some of the attempts to deny that that happens is just bizarre, right?
Well, it is to me and you, but it isn't to an awful lot of people.
And even folks, and I may, I hope there hasn't been a change in the last couple of years, but even somebody like Brian Rockland,
who recognizes the reality of emergent properties, nonetheless gets very weary about ascribing causal properties, causal powers.
Let's use that for causal powers to those emergent properties.
In a sense, the notion of supervenience is continuous.
So there are very few of us, people like Carl Gillette, people like Robert Bishop.
There are very few of us who are willing to go the next step and say, not only are emergent properties real,
they have causal powers with respect to their own components and that's what homeostasis is for God's sake.
The homeostasis readjusts the metabolism, the neural system and so on in order to maintain the integrity of the whole.
But the idea that nonetheless that should be explicable in a reductionist fashion,
the power aspect of it is still not quite the physicists haven't bought it.
The philosophers, I hate to say this, I never read philosophy anymore,
because all the, I grew up, I was trained as an analytic philosophy in the United States,
so they're worried about it as a meaning of words, I mean there are very few people.
And you can tell why, how this is when you have people like Chalmers and Christoph Koch,
who Chalmers has sort of thrown in the towel and he's really saying,
oh the only way you're going to have mental properties is if you build them in,
from the get go, from the bot, you know, so therefore electrons have mental quality.
Oh come on, give me a break.
Yeah, we had Christoph Koch on the show some time back and he actually is a panpsychic.
But do you understand why?
Because if all of reality comes from innate, internal, fundamental properties
that only interact with efficient causes, there's no way you can get a coherent whole,
and that's the key word, coherently organized that then, from which emergent causal powers come.
And it's interesting that another extremely bright guy named Ben Gertzel has been on my show many times,
good friend of mine, I think he's a panpsychic for exactly that reason,
because otherwise he's wedded to his model of the universe, and where does consciousness come from
if it isn't innate, while a complexitarian would say, well it's obviously emerged,
just another level on the stack, right, and that's not that hard.
But it's this notion that my nature, you know, oh it's in my nature,
is somehow given as an essence in the fundamental tiny-tiny bits that make up the rest of it,
that's still much more widespread than one would think.
We'll get to supervenience later, and I think we have a somewhat different point of view,
but not entirely different, we'll get to that later, but I think we're on the same page that, hey,
this need to smuggle in something like consciousness or cognition as a fundamental property of matter
seems to be a big overreach, I mean do we try to smuggle in the fundamental nature of digestion?
I don't think so, right, but we get overly confused when it comes to cognitive processes.
But digestion is a good example, and that's the one John Searle has always used.
That's why I always use it.
Yeah, exactly, and I used to fight him, we were on the NEH board together,
but the thing about digestion is, digestion really doesn't do much, I mean it is an effect.
Digestion is an effect of all these other processes, the reason I like homeostasis
is because the metastability of homeostasis is causally effective.
It does, if I have the fudge brownie, it's going to switch all my glucose and everything else around
to keep the integrity of the whole.
So it has, it has caused what I would want to call causal powers,
but I've given up that term because people will say, oh, but it isn't efficient causation.
No, that's right, it isn't, but it is DS Lewis's notion of cause meaning without which not.
If that weren't the case, it wouldn't be.
So that's the causal notion I would espouse.
Okay, let's now make the next step, which is why don't you start to define what you mean by constraints
and lay out a taxonomy of different kinds of constraints.
This is where the book really started to get into new territory for me and I've had it very interesting.
And that's what the new one is all about.
That's what the new one is all about.
I think in the first book, I made a distinction barring from Lila Gatlin's book called Information in the Living System,
which was from 1960, something or other.
A distinction between, I use the term at the time, context free and context sensitive or context dependent.
I've got to agree from people saying, ain't nothing that's context independent.
All right, so in this one, I call it context, I mean, nothing's context free.
So in this book, I call it context independent and context dependent.
Context independent, according to Lila Gatlin, are conditions that take a system far from equi probability.
So whatever takes conditions away from random, from white noise, from random noise.
So if you institute a gradient, you have instituted a context independent constraint.
If you institute polarity or charge, we were talking the early universe here probably,
those were probably the earliest constraints.
And I call them context independent because in a sense what they do is they set the context.
In a sense, they set the boundaries of possibility space and inhomogeneities within that possibility space.
So it's no longer white noise.
Lila Gatlin calls context dependent constraints those that take a system away from independence.
So one of the things that I find interesting also is that we might poo poo Newtonianism now,
but when you look at the second law of thermodynamics, and I'm petrified because I kind of talk about the second law of thermodynamics in this new book,
according to the Boltzmannian everybody's interpretation of the second law of thermodynamics,
the events in the particles are independent of one another.
I think you're never going to get complexity if you have independent particles.
That's the beauty of Stuart Kaussman's button example, button mesh example.
You tie one button to another and all of a sudden the thing turns into a mesh.
You have a phase transition and you have a mesh.
So what would I consider context dependent constraints that take a system far from independence?
I would consider catalysts, context dependent constraints.
I would consider feedback loops, context dependent constraints.
And I think since that first book was published 20 some years ago,
what's nice to me is the burgeoning of epigenetics nowadays,
because if epigenetics isn't an example of context dependent constraints with a vengeance,
I don't know what is.
So once you have all these context dependent constraints acting inside a context independent possibility space,
set possibility space, then I think the possibility of complexity appears.
You don't have a possibility of complexity just with emergent, just with efficient causes.
But these forms of constraints do.
I also make a distinction between temporal and spatial constraints.
I give two examples from playground devices.
A playground swing, the child learns very quickly that when they kick is as important as how strong they kick.
And the timing of the kick does not impart more energy to the kick.
So that's an example of where Newton alone, efficient causes alone won't work.
Does that make sense? I mean, you have to otherwise it won't kick.
A seesaw is another example of a spatial context dependent constraint,
because depending on the length of that plank on the top and the plinth on the bottom,
the base on the bottom, then when where the child sits,
will be determined by those context dependent constraints in order for them to be able to teeter daughter.
Another example that I like a lot, which I know you know Dave Snowden and he likes to use a lot.
I think I used it first, but that's okay.
Is the roundabout, the traffic circles.
The architecture of the roundabout is a context dependent constraint that affects the behavior of pedestrians and drivers in a system.
So that's another example of a context.
I think sequencing is a beautiful example of temporal constraints.
A has to be done before B, which has to be done before C, which has to be done before E.
And it's done in a different order.
The order of the make a huge difference in the outcome.
So all of these I consider context sensitive constraints.
I lump a lot of those into enabling constraints because I think of enabling constraints as the particularly those context dependent constraints that together achieve closure such that this coherent whole emerges.
Interesting.
And you also, I think that was interesting about your, your use of the word constraint is you use it very broadly.
Yes.
I mean, for instance, one of my mentors in the complexity space was Harold Morowitz.
Oh, sure.
He was here nearby at George Mason for a long time.
Yeah.
I used to live out in Loudoun County and see him quite once a week.
And he has this idea, you know, the 27 emergencies or whatever it is, and then each one is defined by a set of pruning rules, which, you know, tilt things one way or the other.
And I think that those, those changes are fundamental inflection points in the evolution of the universe. And some of them may have been some of them probably are contingent and some of them aren't.
And the ones that aren't maybe, maybe correspond to your non contextual constraints.
For instance, one of his steps is defined by the poly exclusion principle, for instance.
I mentioned that in the second book.
I think notions of symmetry and conservation.
You know, it's funny, physicists all use word causality and so on.
They use half of the time they're talking about the Tony cause, then when they figure it can't fit, then all of a sudden they move to principles.
Right.
To, to con that sort of thing.
And I absolutely agree.
I think rules, regulations are examples of constraints.
They set the possibility space and they determine what is more likely within it than otherwise.
And I did like the point, and this is Harold makes the same point that especially higher up in the stack, we're talking more probabilities than we are blacks and whites.
Right.
Absolutely.
And perhaps what I speculate on in this new book is that whenever you have the emergence of a coherent dynamic, you have a phase transition to a continuous function.
If you have that, if I'm right on that, then it seems to me that top down control is analog.
It's a, it's a change in the setting of the system to an analog notion.
So you're going from your old fashioned toggle switch to a dimmer switch.
And that's why homeostasis can keep the timeliness because that's very important for homeostasis and most ecosystem.
And it also can keep the sensitivity to local conditions.
I think only analog them do that.
The Dysons have been, were poo pooed a lot, but there's something that tells me that their emphasis on analog control somehow might be, might be on to something.
And to make it clear with the audience, you're talking about Freeman Dyson.
Freeman and George, both deceased now.
Yeah, George died.
Did George die?
Yeah, recently, about the last six months or a year.
Yeah, he used to come by the Santa Fe Institute a lot of time.
Freeman, I don't believe ever did.
At least I never met him there.
But very interesting family.
Also new.
Very interesting family.
And then I went to Esther Dyson, who was George's brother, who was a very extremely influential thinker in the early days of the computer industry.
And then later has become a brilliant venture capitalist, particularly in the Eastern, Eastern Europe.
That was her area.
Oh God, I didn't know.
Yeah.
A quite amazing woman, really quite.
Yeah, she really was.
Really quite.
Okay, let's, I haven't, way later in my topic list, but let's talk about it now, which is analog versus digital.
I actually have a fair bit of background in this.
Two of my companies back in my business career, they weren't mine.
I was on the, I was a chairman of one.
I was a investor and director or another.
We're both involved in software for designing computer chips and in particular for designing analog computer chips.
And so I learned quite a bit about analog versus digital.
And for instance, I learned, I probably should have known it, that digital actually is analog below some level, right?
And then there's, there's a whole series of clever things they do to go from analog to digital.
But then the other point, what you allude to is that on comparable computational tasks, analogs, literally six orders of magnitude more efficient.
That's it.
And that's not to be the reason why the brain doesn't overload.
Correct.
That has to be the reason why the brain.
So the brain is a good example of that.
Why the, why the mind?
Or when you transit, when you do the face transition to a mental event, what you're doing is you're transitioning from neuronal electrical exchanges to control on the basis of some kind of typology, a facial recognition.
So now you're talking on the basis of how close is that pattern to this exemplar face?
Though, again, to keep in mind, the brain is a good example because the brain is both digital and analog.
Exactly.
Exactly.
Exactly.
And it switches.
Correct.
And it switches back and forth.
Correct.
Yeah.
And so, you know, the domain of ideas or concepts or objects, you know, the, you know, the very important object ontology that at least mammals and above develop probably Burge too is continuously variable.
And it's not perfect.
It's classic analog classification.
And yet it's actually implemented on digital circuitry.
Correct.
Correct.
So it's carried up digitally, but the command top down is cut is analog.
That makes perfect sense to me.
Yeah.
Though I would also just add that the continuously variable while true of analog versus digital is maybe less important than people think is one of the principles of computation is you can simulate analog at any level of detail you want.
On the other hand, to simulate analog at extremely fine detail is very expensive computationally while you get it for free with analog.
So that's the, that's the cool thing about analog.
So that George Dyson used to use as an example, you know, even though the internet and all the computers that we use now are digital.
When you look at social media and that stuff, it's what's connected to what.
So we're back to the dance, right?
Yeah.
And that's the people who are analog, right?
And it's the dance of the people.
And the people in a sense are the condensated nodes of the intersections of all these constraints, right?
So that's what I argue in this new book that everybody's all bent out of shape about identity because they all think of identity as something internal, essential, same thing as coach.
And, and, and Chalmers were concerned.
But we need to transition to identity as a set of interdependent constraints.
That's what makes me mean, right?
I am a set of interdependent constraints.
And high dimensional.
Very high dimension.
That's the thing that's so annoying about the stupid identity politics of both the left and the right is both sides want to condense down to just one or two dimensions.
And there's hundreds of dimensions, right?
You know, I'm a cat.
You know, someone's a dog fancier who loves mountain laurel but not Rotodendrons.
There's so many dimensions.
And I say that these two are the ultimate ones.
Just like just kind of dumb, right?
You know what did it for me that I finally decided I can finish that first book where was worked by Hinton Jerry Hinton, who's now a big shot.
Clout and Chalmers and they were doing early work in artificial neural networks that read words, right?
It was one of the early text reading networks.
And they were working on simulating.
I had never heard it at the time.
Have you ever heard the difference between surface and deep dyslexia?
No, I was very interesting.
I thought that was in your book.
You gave a great example in your book.
I've got it and I use it in a sense.
No, well, it was their example.
It was their example.
Do you want me to repeat it here?
Sure.
I want you to tell the story.
It's very interesting.
I'll tell the story.
Surface dyslexia is what most dyslexic human beings have.
They transpose letters.
So they read cot for cat or they read tag for cat.
They just transpose letters or four gets read as a seven, that kind of thing.
There is the point being, there's no semantics involved.
It's purely the appearance of the input.
Okay.
Apparently deep dyslexia is very different.
Now what I'll give you the example first.
What Hinton Plout and Chalice and the reason I plunked them all together is because Hinton
and Plout would write Hinton and Chalice Plout and Chalice.
So there's zillions of papers that came out about 25 years ago about this.
And they trained these early reading neural networks.
And when they had, when they trained them with feedback loops, so they were current,
recurrent networks, and they lesioned the networks above the feedback loops.
The network would be shown cat and it would say tag.
It would do surface dyslexia.
It would produce surface dyslexia kind of errors.
But then if they lesioned the artificial neural network below the feedback loops,
they might show the network again.
These are, these are silicone networks.
They're not organic.
They would show them B, A, N, D band.
And the thing output would say it had read orchestra.
Or they would show it B, E, D.
And the thing would say it had read cut.
That is, and so somebody, not me, asked one of them, Hinton Plout and Chalice,
how do you explain this?
And their answer was the only way I can explain this is to postulate that the system,
because of the middle layers that we don't quite know what's going on.
And that has got to be what's going on with Chalice and BD, by the way.
The middle layer has created semantic attractors, period.
Case closed.
And the output is just showing from the semantic attractor.
That makes perfect sense.
That makes perfect sense.
But there's your emergent property being causally powerful.
Interesting.
By the way, for all my computer people who listen, and there's a lot,
the GE Hinton she's talking about is the Jeffrey Hinton.
He's the Jerry Hinton.
I shouldn't say this on the air, but I will.
I said to John Sturle at one of these NEH meetings,
John, I think Hinton's work is so very good.
I don't understand why everybody's so interested in Hinton.
I thought, he's very good.
Trust me, he's very good.
It is the Jerry Hinton, right?
He's the guy that broke through the breakthroughs that drove all the stuff that we're doing today.
Absolutely.
Nobody was paying attention to these reading networks a long time ago,
or at least not as many people should have been.
Yeah, I was actually doing neural nets back in 2001, 2002.
In fact, that's how I got invited out to the Santa Fe Institute.
It was my work on evolutionary neural nets.
Well, my book was published by MIT 1999,
and this has been published before,
so I think that stuff was published in 95, 98, thereabouts.
Yep, that was.
It did it for me.
I thought, now I can write this book because I have some kind of evidence
that the semantic attractor in the brain, in a culture,
whatever you want to call it, has causal effects.
Now, when I was reading the book, I write a lot of notes I always do.
One I wanted to ask you about,
because how does it fit into your concept of constraints?
It certainly is one of Harold's pruning rules,
and that's the idea of the Species Competitive Exclusion Principle,
which actually, my core field is evolutionary computing,
and so I understand a lot of how speciation works from a mathematical perspective,
and it's more or less a thing that is just true, right?
If a competitive dynamic has these attributes, there will be,
and a fitness landscape has a certain shape,
there will be a competitive exclusion principle around species.
Does that fit into your idea of constraint?
Well, if what I speculate about there existing a constraint regime,
correct, then that is the constraint regime for that possibility space, right?
Yeah, it basically says that if anything is competitive,
if you get too far away from the center of what's efficient in that part of the fitness landscape,
inevitably you'll be less, not inevitably,
most of the time you will be less fit than the ones right near the peak,
and therefore your numbers will go down,
so it's very hard to move away from the peak of the species definition.
The phenotypical collection, of course, as you point out,
they're not all the same, they're an ensemble,
but they nonetheless cluster around a species type.
Correct, correct.
I don't know if this is an attempt to answer your question or attempt to evade it,
I'm not sure.
Tim Allen, T.H. Allen and Starr will have that book,
and they've got two editions of it, I like the first one, the first edition better,
called Hierarchy Theory,
and they use as an example prairie grassland ecosystems in the Midwest,
where apparently the prairie grassland competes against flowering plants.
It also competes, obviously, against forbs, horses that eat the grasses, correct?
Apparently, if you look at that whole ecosystem,
and you look at it from the point of view of the grass, right,
competition with the flowers is a lot harder than competition with the horses.
Apparently, flowers will really do a number of flowering plants,
I don't know, daikotilidons or whatever those things are called.
So over a period of time, the prairie grasses have sent out,
and of course this is the whole selection, I'm not at all disputing, obviously,
they're winning, they have sent out merry stems,
merry stems are these shoots right below the surface,
but they stick out enough that the horses can eat them.
And so in a sense, Jim, the grass invites the horse to come in to feed
and incorporates it into what is now an enlarged ecosystem.
So instead of having two competing species,
what you're having is the enlargement of the niche,
or the constraint regime,
and Tim Allen says it's kind of like a Shanghai what was a predator
to incorporate it into an enlarged constraint regime,
now the horse is part of the grasslands ecosystem,
and that's how they keep the flowers at bay.
I think that way of looking at it as a dynamical, mutual adjustment system
is an awful lot better than two species competing.
Yeah, two species are competing, but this other stuff,
and then I get from the fact that I didn't realize until fairly recently
that the understanding of the term fit during Darwin's era
meant more like you go to a tailor to get a fitting for a new suit of clothes.
So when you think of fit in that sense,
what is it? It's a mutual adjustment, correct?
Which means that when I talk about constraint,
the form of bottom-up and top-down relationships
has to be one of mutual constraint adjustment.
That's what it basically is.
You're adjusting all the constraints to see how you can best satisfy
the overarching dynamic.
Yeah, then to your example of the grasses and the horses, etc.,
it's always in a co-evolutionary context.
Exactly.
And that's your idea of context, right?
It's temporal, too. It's temporal, too.
You've got to include temporality, absolutely.
Yeah, and all right, so let's move on here.
Yeah, that was good, actually.
In the interest of time, I'm going to skip over the COVID example,
and let's talk more about time temporal constraints.
And I think you did a really nice job of talking about cardinality,
ordinality, and indexiality.
Inexicality.
Inexicality, okay.
I want you to distinguish those, particularly the distinguished
cardinality from ordinality.
Well, cardinality is just a mount, correct?
So a pile of sand has a cardinality.
A pile of sand is bigger or smaller, correct?
But ordinality is first, second, third.
I don't see where you can get first, second,
third's much out of Newtonian mechanics.
Whereas once you have temporal constraints instituted,
this has to occur, and this sets the stage for then the next
thing to occur, and that sets the stage for the third thing to
occur, then you have ordinality, which is first,
second, third orders, right?
Indexicality takes it a bit further.
It's like perspective, or the position you are in in a
complex dynamical structure means there are certain properties
that are indexical.
This is to the left of this.
This is to the right of this.
That's what I mean by indexicality.
It really has wreaked havoc in philosophy of mind because
intentional causation again is eminently indexical.
So one example I use in this new book is that philosophers
use all the time.
Mary told John's wife that he was cheating on her.
But Mary doesn't know that John's wife's name is Alice.
So the way, so did Mary tell John's wife that it was Alice?
Or do you see what I mean?
It has to be interpreted, I think in terms of the emergent
dynamics and emergent properties.
So it has to be treated in terms of indexicals inside and out.
So I think once you have emergent constraints in place,
that's what, and I wish there were a verb that makes,
how could you make a word out of the word rugged?
Ruggedify.
Yeah, ruggedify.
I like that.
It ruggedifies the possibility space, right?
And each one of those valleys and tractor basins or
tractor separate tricks is right.
They are the ruggedness of a possibility space.
And that explains why the view from inside an attractor looks
real different from the view from the hill overlooking the
next basin of attractor, correct?
And when we talk about causality,
we have to take that kind of indexicality into account.
Yeah, then with respect to ordinality,
many things are inherently ordered.
In fact, I just published last night a very interesting
podcast, Currents Number 100 with Sarah Walker and Lee Cronin.
Ooh, I've got a note to her.
Sarah and Mary Walker.
Her stuff's really interesting.
Yeah, yeah, yeah.
And on time, it's an object.
And their hypothesis is that evolution and other expanding
complexity is essentially a series of steps that get taken,
right?
They point out that the most complex chemicals created by
abiotic processes never have more than 13 or 14 steps.
But biotic processes can go much higher than that.
And then manmade processes can go a bit further than that.
And so I thought it was a very interesting juxtaposition with
your idea of ordinality.
One of the examples you gave was the social evolution of the
processing of cassava.
I believe it was in South America.
That's from Heinrich's book on the secrets to our success or
something.
Heinrich is what, head of sociology or something at Harvard.
It's apparently something that's poisonous, but yet
nutritious if it weren't poisonous.
The indigenous community in South America has figured out a
way of leaching out that poison.
But the preparation for that root vegetable has to be done in a
particular sequence because if you don't, you're going to kill
out the entire population.
Going back to Sarah Walker, somebody told me day before
yesterday that apparently there's something I'm not on
Twitter, which I probably should be neither on Twitter nor on
Facebook.
Somebody told me that somebody wrote a Twitter comment saying
that Sarah Walker's driving forces are my constraints.
Which is flattering, I think, for me.
She's very good.
She's very good.
And Lee too, the two of them were one of the better hard
science episodes I've had in a while.
Lee probably is very good.
Yeah, I like his stuff.
Interesting.
Okay.
Now you mentioned, why not hit on these because they're
classic rich examples.
Kaufman's Buttons, Huygens, Pendelums, and Binard Cells.
Binard Cells.
And paint those in with your ideas around.
Well, the Binard Cells was what was the source of all my
interest in complexity theory.
It was the early 1980s, Jim.
Could you tell us, folks, what it is?
Not everybody knows.
Okay, a Binard Cells is you take a pan of water.
They're called Ray Lee Binard Cells, and they were discovered
at the beginning of the 20th century by Ray Lee and Binard.
Take a pan of water, any kind of viscous fluid.
And you heated uniformity from below.
All right.
You still have conduction.
After a certain gradient, after a certain threshold of
instability, that's my context independent constraint, Jim.
After you pass a threshold of that gradient, the system cannot
handle any kind of fluctuation.
And the context will amplify any minor bubble or perturbation,
and all of a sudden you will get convection cells, those
rolling, hexagonal cells made of billions of molecules of
water that all align in a self-organized way, and that the
cell itself constrains top down the individual molecules of
water, shall they behave as if they knew what the one next to
them was doing.
All right.
So it was the 1980s, and I had to go to jury duty here in Montgomery
County, and so I took a bag full of stuff that I had to read,
and I figured, and I was reading, cons critique of practical
reason.
Cons critique of practical reason said the problem with teal,
and by the way, at the time that Kant wrote, teleology was
synonymous with self-organization.
Go figure, 1804.
Kant said in order to understand this kind of phenomena, he said
we need an understanding of circular causality that is unknown
to us, because remember Kant had bought the Newtonian-Humian
collade that was all effective, efficient causality.
So he said, but look at how nature works.
A tree produces the leaves and then is produced in turn by the
leaves, so the whole tree is produced by the component parts
and in turn loops back down and produces the components that
created in the first place.
And so I'm reading this, going all right, yeah, but how do we fit
into modern science?
And then the Prigogene and Stenger's order out of chaos had
just come out of print, come in print.
And he's looking at dissipated structures which all have that
process, yet individually constrained interactions that after
a threshold of instability, cross a phase transition and
self-organize to produce a whole which then loops back down and
constrains the component parts.
So that to me was, whoa, I found a scientifically respectable
way of explaining teleology and formal cause.
That's what did it for me in the 80s.
You were at the right place in my time because Prigogene
certainly-
Well, it just, again, not having to publish so that you-
Go where you want to go, right?
Decimal point of whatever you already exist allowed me to be a
patent and play around with ideas just because they were
interesting.
Yeah, and one of the things that Prigogene predicts is that
these, especially these abiotic complex systems will actually
be more efficient at burning energy than their predecessors.
And that's the Bernard cells for sure.
They actually move more heat through by convection.
And one of my favorites is the whirlpool in the toilet actually
allows the water to go down faster.
So it actually is dissipating the potential energy of the water
in the tank more quickly than if it didn't form the whirlpool.
You know what I used in class when I taught courses about
mines, rains, and machines?
I actually taught a seminar on mines, rains, and machines at PG.
But I take the two, you know, the standard two large gallons.
Oh yeah, put them together rather than watch the tornadoes in them.
And the students would, ooh.
Yeah, we made one of those for my daughter when she was like a
middle school student.
Yeah, that was a cool thing.
They can really appreciate it intuitively.
Yeah, so the idea of Prigogene and the idea of dissipative systems,
even though they have more structure and more interesting
things going on, are also, generally speaking, more efficient
at burning energy.
And so the good old second law never actually gets violated.
It's at a different form.
So this, then, you've set me up perfectly.
But thermal equilibrium gets retarded a bit because you have a
structure that gets created in the process that persists a bit
longer than the component parts.
But that's the explanation for social systems.
That's an explanation for cities, right?
Cities are more energy efficient than they're organized, right?
Yeah.
They burn a lot at per unit square foot.
They burn a lot.
But per person, they're less, which actually now it sets up to
my next time.
You're not going to fool the second law.
No, exactly.
That's the one law.
If anyone ever comes to you and tells you they beat the second
law, tell them to go pound sad, right?
And so now we get to where it gets more interesting.
And this, of course, is the secret of life is catalyst loops,
autocatalytic networks, et cetera.
This is where we go from whirlpools, which have a self-forming
part, but they're not fully closed loops, right, Ed?
Well, I really liked a book that came out about seven years ago
by two, well, a lot of them worked out of the University of
the Basque country in Spain.
And the good thing about those folks is they published in
English, otherwise they would go into black hole.
But they published in there, unfortunately, this book is
Springer and Springer sold them expensive.
Nobody buys the book.
But I think they're very good.
And the book is called Biological Autonomy.
And their argument is that, well, things like the Krebs cycle
and so on, these are closures of process.
But once you start having autocatalytic and hypercycles,
and so on, what you have that the loop that the constraint loop
that closes is a loop of constraints themselves.
And so the constraints create the constraining conditions
that make them possible to begin with.
And that is what enables their self-reinforcing,
but their self-perpetuating.
And so these Matteo Moreno and Mocio argue that is where
that is what makes living things different from,
say, even the BZ reaction, where the boundary conditions,
the constraints are, in a sense, self-set from without.
You set the conditions of the pan of water or the chemicals.
But once you get a situation where the constraints themselves
become self-perpetuating, then you have the possibility
of reproduction of species and that sort of thing.
Now, you didn't really hit on it as hard as I thought you might.
But the perfect example of that is that the autocatalytic reactions
within a cell are also responsible for building and maintaining
the membrane that allows the concentration.
And that's hugely important to my mind.
Absolutely.
Absolutely.
I think that's what they mean, because the membrane,
we've always thought of it as boundary conditions.
And that was my beef with Polanyi.
Because Polanyi says, Polanyi was ultimately religious.
And so Michael Polanyi, the philosopher at the beginning
of the 20th century, I guess it was,
he believed that God sets the original boundary conditions.
And then once you've got that, then everything else self-organizes
within it.
But the whole point of, I think, the closure of constraints
is that it creates the boundary conditions within which
it self-organizes as well.
So yes, you're absolutely right.
Yeah, I think that's hugely important.
And of course, as we've learned, the nature of these membranes
changed over time.
And it's continually changing.
And the fact that they're semi-permeable with different rules
for what goes from the inside out,
and what comes from the outside in,
are hugely important to maintain the reactions that are going inside.
I think we finally understood that because of the role of interfaces
in computers.
Yeah, I think that helps.
And then the allies and so on.
And therefore, what that also means, I think,
is once you have a phase transition to a new dynamic,
you have a new code.
And a new code means simply the settings and the rules that govern
that membrane, that boundary conditions, what it allows in
and what it produces as waste and as action.
Absolutely.
And then the other interesting example you gave,
which I had thought of before, is you talked about the architecture
of the circulatory system as another.
That's Moreno and Masio, which is a really nice example,
because the vasculature of the body, the lymph node and the blood
circulating system, really prevents the seeping out, right?
But it is not an energetic force.
That's what the heart does.
But the vasculature is more like the timing of the playground
swing in that it controls the settings.
You know what?
After I submitted this MIT, which was, jeez,
it was almost a year and a half, two years ago, but it took so long.
I am fascinated recently by the inflammatory system
and the immune system connection because they are now talking
about three levels.
They're talking about structure, function, and then regulation.
And that, you know, if my arm gets cut off,
then the inflammation hits it immediately to try
to repair the wound.
All right?
If all of a sudden the interactions in the body are out of
kilter, then the function of homeostasis may not work as well.
That you get diabetes and so on and so forth.
But the idea recently is that perhaps there is a third level,
and that is the setting of the functional system.
I'll call it the set points or the settings,
and that perhaps things like PTSD, chronic inflammatory disease
syndrome, that kind of thing is that on and off switch,
for example, the dimmer switch, the analog is screwy.
So it's the set point.
It's the regulatory control of that function that's off.
And that maybe that's the way to attack PTSD, for example.
There's nothing wrong with the function of PTSD.
We're supposed to freak out if we think someone's attacking us at night.
What's wrong is the fact that we are now reacting in a different context
the way it should have been before.
Then that means there's something wrong with the toggle switch.
There's something wrong with the switch, which I find really interesting.
Because I think that has a lot to say with, too, for social systems.
It has a lot to say, not just for the inflammatory system.
Perhaps all of complex dynamical systems have those three layers.
Structure, function, and then regulation.
And then, of course, the question is, how do these three levels interact?
And they do not interact by efficient causes.
They interact by constraints.
That everybody who's done hierarchy theory in biology is comfortable with that.
Okay, let's move on to another topic here, which is you described them as constraints,
though I would not normally think of them that way.
But I think in your lens, they work.
And that's the idea of scaffolds and scaffolding of affordances, et cetera.
Talk about your thoughts on scaffolding and how you can use the language of constraints around that.
I think you have the old-fashioned architectural scaffolds that are external artifacts
that are temporary and that guide the construction of new buildings, correct?
But if you think of constraints, of context-sensitive constraints,
as conditions and factors that take a system away from independence,
they link things together.
What scaffolds do, and I love the work of Bishop and especially the word of,
whimsap, they've done work on scaffolding long before they got fashionable.
Fashionable recently.
They provide a temporary equilibrium point from which to take the next step.
And it's not only, it's like a ratchet.
I think of scaffolds almost like ratchets.
They provide a temporary, metastable position from which the next step,
whose direction the scaffold itself also suggests, can be more easily taken.
But that chapter you're thinking about from the new book,
there's so many other different types of constraints, that kind of constraints.
There's entrenchment.
That's a hell of a constraint that we use a lot, especially in social systems, correct?
To retard any innovation or buffers.
I think probably the difference between a buffer and an entrenchment might be how long it lasts, right?
But it's a way to control the relationships between the inside and the outside,
and the next step, that's why I think of it as a form of constraint.
Because the scaffold, again, is not, my bet noir is always efficient cause.
I'm always thinking, well, this is something that has effects, but it not as an efficient cause.
So I have buffers, I have entrenchment, I have scaffolding.
I have that kind of process that we use a lot.
And now you could throw those in with catalysts.
Absolutely.
And certainly, let's say scaffolds and catalysts both have the effect,
while they don't necessarily provide energy themselves,
they lower the activation energy for something to occur.
Correct, correct.
And even those scaffolds that are not temporary like the flying buttresses of Gothic cathedrals
that end up being part of the structure, and that is also true of these lattices.
They implant that are embedded with nutrients that promote bone growth, right?
The point being that the location and the direction of the holes in that lattice are what pattern the bone growth.
But then they end up getting absorbed and becoming part of the bone itself.
So these are all forms of affecting consequences that are not, or that are in addition to.
I don't want to discount efficient causes, obviously.
I just don't believe they're the full story.
Yeah, and this, in some sense, the basic laws of physics continue to be true,
but there's much more interesting structure being built that's in addition.
And that's what the naive reductionism misses.
Correct.
And go ahead.
I'm sorry.
I interrupt.
I'm Cuban.
I'm sorry.
You talk with your hands.
That's right.
That's right.
And again, I think that it's kind of this myopia of over-reductionism.
Nothing wrong with reductionism.
You need to know both the dance and the dancer,
but there's a sense that somehow the relational dynamical are not real.
Every bit is real as the primary properties.
And that's my problem with myriology and nothing but is so on.
The problem that everybody complained about top-down causation is not possible
is because it would violate physical closure and it would violate the conservation of energy.
Sure, if you think of it as efficient causes, of course, it's going to do those two things.
But if it operates as constraining dynamics,
you're not violating physical closure or constraint or conservation.
So that's why it works very nicely.
It's not violating any basic physics tenants.
Why don't you do a little riff on that?
Because that is one of the questions in complexity.
And it befuddles the layman in particular.
What?
Top-down causality and how you can have top-down causality and no magic needs occur.
Well, in the very same way that homoestasis changes my glucose production,
or how does a culture affect me?
That is top-down causality.
That is causality from the hole in which I am embedded.
If I were not part of that culture, it would not affect me.
Correct?
Right.
So that means that the constraint dynamic of the culture in which I am embedded
be the college at which I taught, the society in which I live,
the family to which I belong,
the constraint structure of each of those organizations
changes the likelihood of different behaviors that might otherwise have been open to me
that are not in the very same way that once entrained into a Benard cell,
the molecule of water has different probabilities of where it's going to go
because the constraint structure of the Benard cell affects it.
And that's what I mean by top-down causation.
There's nothing magical about it, but it's not efficient causality.
If you think of it as efficient causality, then of course it's magical.
Gotcha.
And you know, there's been many, many pointless conversation on this
as you no doubt have experienced it.
Absolutely.
Well, my centuries of this going on.
Indeed.
Let's move on.
We're getting kind of late on time here.
We've got about another 13 minutes.
And this was something new to me.
Very interesting to always run across something new.
And that's the idea of many to one transitions.
Maybe you can dig into this in some depth.
Okay.
That was all right.
When at the beginning, once behaviorism got put to bed,
then functionalism came into play or the identity theory.
So the idea was that mine is to brain as a computer software is to its hardware.
So then people said, all right, just like a lot of different Microsoft
Office can be run on different on Apple and the different hardware devices.
Then perhaps that's the explanation that gives some legitimacy to the notion of a
mind.
These are the notion of the brain.
The brain is the hardware, the mind is the software fight.
But there was also always the idea that the notion of supervenience and
Donald Davidson's term is there.
Will be no change in the supervenient properties without any corresponding
changes in the subvening in the hardware.
So there was always implicit in the notion of supervenience, a one to one
relationship.
And the reason I think that was true was because I don't think they ever got away
from the physicals out.
So there was always that one to one relationship.
So the idea was, all right, so a mental event.
My thinking of my grandmother, my pain and my leg will always be correlated
one to one with this particular neuro pattern in the brain, which indicates
pain in my leg.
This one about indicates that's my, my grandmother, but very quickly, multiple
realizability, many to one relationships.
All of a sudden came about and that was that.
Well, though, and behold, if this part of the brain is excised, the, the hearing
function might be taken over by the other part of the brain, another part of the
brain that was supposedly not at all dedicated to hearing, but all of a
sudden it was.
So the notion, and I almost wanted to name this title, this new book,
in praise of degeneracy.
Don't get so, don't get cutesy here because biologists have always been very
comfortable with degeneracy.
That is, there are many ways for the same amino acids to produce different
amino acids to produce the same protein.
That's what I mean by many to one, many different lower level paths to realize
the same emergent property.
That's what I mean by many to one.
And that seems to be true in general for the higher level properties of complex
dynamical systems.
An economy can stay itself despite many different varieties or many different
configurations as long as that overarching constraint structure remains within a
certain range.
Does that, have I made sense here?
Yes, ish.
Let me drill it a little further.
But you also talk about many to one, because we do have multiple realizable
domains and the idea of degeneracy is very important.
And for the audience, degeneracy basically means that things with different forms
can have the same function, right?
Different lower levels, same higher level.
Same higher level.
There's a bunch of famous examples in biochemistry where it's more famous.
But you also talked about many to one as something analogous to dimensional
reduction in systems.
And think about the fact that, you know, with the example I gave before,
Jim gets up out of his chair and goes down the hill to the ice cream store.
There's lots and lots and lots of predicate signals that probably led to that,
right?
And they eventually got concentrated down to a single decision.
Should I get up, go down the hill, get an ice cream cone,
or should I go to the freezer and pull out a frozen yogurt bar, right?
And the fact that there's many, many, many inputs, but there's a single decision
around the affordance was also the way you described many to one.
The reverse of it is pluripotentiality, which is one lower level that has the
potential for becoming much more different functionality.
And of course, stem cells are the example of that, right?
They are pluripotents.
They are not totipotent, which people thought they might be for a while,
that they could become any other.
They're not quite their totipotentiality.
But that was the problem with supervenience.
Because then the question was, how can the same neural processes in the brain
produce such very different, differently property functions, higher level properties?
And Davidson said, if you can't identify a causal relationship between the two,
then you might as well go back to behaviorism.
At that point, Jay Won Kim at Brown, who had been a big advocate of supervenience
at the time, decided supervenience won't work.
It either is one-to-one or it's not.
And that's why he titled that.
Was it a paper or was it a book called Descartes' Revenge?
Because then again, the problem was, how do you get top-down causality in that?
Once you decide to go to the fridge, Jim, you could decide to walk directly to the fridge.
You could decide to go outside because somebody is going to watch you take something from the fridge
and you go outside and you go all the way around.
So there are a lot of different ways to implement that top-down decision, correct?
And the problem with, again, efficient causality is that it only worked for instantaneous relationships.
Efficient causality cannot handle what used to be called in philosophy standing causes.
In other words, I decided I'm going to write a book and it took me two damn years to do so.
So how on earth does that intention continue in force and continue exerting an influence
all throughout those two years?
That's what I meant in that sense by multiple realizability top-down.
Yeah, and then of course that goes back to the very classic Greek philosophical question of the ship of Theseus, right?
Our audience goes, okay, the supposed ship that Theseus took to Crete, I guess it was,
then it was preserved in Athenian harbor and over the years the boards rotted and they replaced one by one.
Eventually every plank on the ship had been replaced.
There was nothing original, but it was the same ship or was it, right?
Correct.
And we can say the same thing about organizations and cultures and societies and, you know...
And humans, you know, basically every one of our atoms gets replaced, what, every year or something like that?
Every seven, whatever, seven years, any cells or whatever.
Exactly.
So I think I stick my neck out more than maybe I have a right to, but that's why I wanted to show in this new book
that people say, oh, you're reducing everything to physics and chemistry.
No, I'm showing that there are, I never know the difference, homologous analogous constraint dynamics
that operate all along the spiral.
It's not a, it's not a reduction.
It is to show that once you do the phase transition from physics to chemistry, then you've got new
emergent properties, new codes, new everything.
Once you go there from chemistry to biology and so on down the line.
Got it.
Well, let's wrap up with the future of these fields.
And you talk a fair bit about the relatively new 4E approach to cognitive science,
which I think is maybe getting closer to your way of thinking.
Yes.
I mean, I really like the work of de Paolo, probably Andy Clark started the whole thing with the embodied mind idea.
And people like Merlin Donald, who I love his book, all of these folks started realizing the mind just ain't in the brain.
Because it takes me forever to write because I literally realize that I work out the ideas as I write.
Now I type, but it's not that I sit down thinking all through and then I just write it out, you know, because it's all been worked out in my mind.
I literally, so, so the notion that, that, that, that our minds extend beyond the boundaries of our body to artifacts to tools, for example, when you're driving.
I'm a designated teach your grandchild to parallel park person because their parents are petrified.
Nobody else wants to do it.
And I'm a good parallel Parker.
You know, I say, look, after a while you realize that that you can almost feel the car as the extension, you know exactly where it's going to fit in a, in a tight space.
So the idea that the mind ain't just in the brain, it's embodied.
But then it's also enacted because it's not just that it's embodied in my in the agent's body, but it's also the mind is enacted in their behavior within a particular context and so on.
What I, what I try to do in this new book is then the question is, well, how does this holistic ecosystem within which this embodiment and enlightenment, how does that coherent dynamic come about.
And that's why I want to show that before you have a, an enact.
I don't think that if you're not Japanese, a tatami mat affords sleeping.
I don't think a Victorian throne enacts seating to somebody who's never seen it before.
So to somebody who's used to sleeping on the ground, and I don't think it does it automatically.
It's part of a whole ecosystem, a whole coherent dynamic.
And my question is, how do those coherent dynamics come about?
And again, my answer seems to be, I don't know what else to call them constraints.
All of these processes.
An accumulation of constraints over time and their channel.
But it's not just accumulation in that one, one damn thing after another.
It's how they inter, how they interweave with one another.
That's what creates this overarching interlocking set of constraints.
Yeah.
And then, and that, that, and those constraints are real in some sense.
See, I say from the beginning in the book, I'm, ever since Kant, every, every time something gets bored, we all, we all hide behind epistemology.
Oh, well, it's the way we make sense of things.
No dammit.
I think that's the way reality works.
And you know, I don't need to, I have to, I have tenure.
I don't need to worry about pleasing somebody else.
I can say this if it's wrong, it's wrong, but that's okay.
All righty.
Well, I really want to thank Alicia Herrero and her new book, Context Changes Everything.
As you can tell by our conversation, I learned some things, had some new ideas I'd never been exposed to.
I thought it was really interesting.
And despite what she said, I thought it was damn well written.
So thank you, Alicia.
Thank you so much.
