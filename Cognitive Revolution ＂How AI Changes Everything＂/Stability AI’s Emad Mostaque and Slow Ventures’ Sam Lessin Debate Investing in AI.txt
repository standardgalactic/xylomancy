I think the key question of this is like, you know, people say hallucinations.
I was like, what does that mean? Well, I mean, it doesn't get every single fact completely right.
ChantGPT is probably like 100 gigabytes down from like 10 trillion words.
The fact you can get anything right is an absolute technical marvel that
no one's really sure exactly how that happens. What if you had an AI tutor for every child?
What does that look like? What if you had 100 AI tutors for every child?
For the first time, every single person can have hundreds of characters that like and support them
all the time. Basically, you log into social media or whatever, and you're like, hey, I'm Sam,
and it's like, cool, what type of people, instead of who do you want to follow? It's like, who do
you want to follow you? For example, there aren't enough therapists in the world, you know, and it
is a regulated industry. But at the same time, there is a gap for therapists, just like, you know,
the meditation apps kind of step in, and they created calm and they created these other things
that were huge. Hello, and welcome to The Cognitive Revolution, where we interview
visionary researchers, entrepreneurs, and builders working on the frontier of artificial
intelligence. Each week, we'll explore their revolutionary ideas, and together we'll build
a picture of how AI technology will transform work, life, and society in the coming years.
I'm Nathan LeBens, joined by my co-host, Eric Tornberg. Hello, and welcome back to The Cognitive
Revolution. Today's episode is a super interesting one on a number of levels,
as we're hosting a discussion between two super influential technology thinkers. Sam Lesson,
former VP of product at Facebook, now early stage technology investor and writer,
Andy Modmostock, founder and CEO of Stability AI, whose work at Stability, highlighted, of course,
by stable diffusion, has already been incredibly influential, but has also come under intense
scrutiny in the months since he raised $100 million at a $1 billion valuation. This conversation
started on Twitter with a short essay that Sam wrote, arguing that AI is mostly a bad investment
for VC. Imad responded and suggested a podcast on the topic, and Eric and I were naturally happy
to volunteer to host. Both Sam and Imad talk fast. This is a 1.5x speed episode for me,
down from the usual 2x. And both had a lot to say, so we mostly let them speak directly to each
other before I jumped into the end to ask some concrete questions. I think regular listeners
to the show will know that I definitely share Sam's point of view around investing in AI.
AI may well disrupt society at large, but it doesn't seem likely to disrupt many existing
SaaS markets between now and then. There will, as Sam says, always be exception,
but for someone whose focus is on looking for those early-stage companies with 100x
potential investment returns, I think he's quite right that there'll be few and far between,
at least at the model and application layers. For what it's worth, though, I do think Sam is
quite wrong to limit his thinking about LLM function to the no real intelligence, just association
between words, paradigm. There is now ample mechanistic interpretability work that shows
quite conclusively that AI models are indeed grokking much more than statistical correlation.
But that's a topic for another episode. For today, the subtext of the conversation seemed
to be this question. Will stability AI prove to be one of those exceptional, highly successful
startups deserving of its unicorn status and valuation? From my standpoint, the answer may
depend on your definition of success. Stability is as much a movement as a company and has already
left an indelible mark on AI open-source culture. Their impact goes beyond the groundbreaking
stable diffusion, including major dataset releases such as the Lyon 5 billion image dataset,
various language models and accompanying open-source RLHF libraries which enable further
downstream training and customization, and many, many other projects across a wide range of modalities.
They've also established themselves as tremendous identifiers of and supporters
of talent, including another upcoming guest, 19-year-old PhD Tanishk Matthew Abraham,
who just published a literal mind-reading paper that converts fMRI data into reconstructed images
of what the person saw, truly mind-blowing work. But perhaps more important than any of that has
been a mod's unique ability to articulate an inspiring vision for the future of AI. While the
positive vision of AI that we tend to hear when we hear one at all often centers around the possibility
of large and powerful AGI's, of which there might only be a few, presumably built and owned by
leading technology firms. A mod has not only signed the AGI pause letter and the extinction risk
statement, but has articulated a very different positive vision for a panoply of smaller AI models.
Mostly presumably derived from the open-source standards that he and the team at Stability
are creating, but all highly specialized for specific purposes and localized to specific
contexts and culture. This is an extremely appealing notion to billions of people around
the world who don't want to be beholden to American or, for that matter, Chinese corporations
for their access to AI. A mod has been criticized recently for allegedly exaggerating certain
claims and affiliations, and for some operational problems at Stability that resulted in people
sometimes being paid late. And while some of that may well have happened, I will say that I've
followed a mod quite closely now for at least a year, and have generally found him to be very
reasonable. He has, for example, always recognized the reality of open AI and Google's modes,
and has projected that open-source models will continue to lag leading closed-source models
by a year or more. All of this seems quite right and reasonable to me.
Given a mod's comments about the centrality of stories, I think it's safe to say he
understands the task of developing a positive vision for AI, a vision that others can really buy
into as a core part of his role and strategy. This is quite different from other AI CEOs who
often seem to be sharing their plans more for your information than for your input,
and it really does seem to be working. I've joined the discords of many Stability-affiliated
projects and have been very impressed with the quality of people and conversations that they
contain. So whether Stability will ultimately deliver a great return for the investors who
bought in at that $1 billion valuation is, for me, not the most interesting question about the
company. I'd be very surprised if they failed outright given the quality of talent that they
have. And so the question that matters more to me is simply, what impact will they have?
Will their push toward decentralization prove democratizing, destabilizing, or both? If you
fear centralization of power and you want to see a rich ecology of AIs developed around the world,
you might expect their contribution to be extremely positive. If, on the other hand,
you fear chaos and see AIs as invasive species, colonizing niche after niche and ultimately,
perhaps competing with humans, you might feel quite the opposite indeed. For my part, as you
can probably guess, I expect the outcome will ultimately be a bit of both. Throughout this
conversation, you'll hear just how much change both Sam and Imad take for granted as they think
about the future. Culture, entertainment, and relationships, they agree, are in for a shock.
The Global South may well have leapfrog moments in education and even medicine.
Online communities may come to contain AI characters that we can't even identify as non-human.
Given the magnitude of all these changes and the resources and talent that Imad has amassed,
the inspiration he's provided, and the tremendous global need that AI seems so well suited to fill,
I think stability has a real chance not only to become a great company,
but to help shape a global universal basic intelligence standard, a potentially historic
development. How humans ultimately wield the new power that Imad and others unlock,
and whether we can control AI long-term at all, is much harder to predict,
but can ultimately only go one way or the other. Now, I hope you enjoy this fast-paced
conversation with Imad Mostak and Sam Lesson. I think that large language models and a lot of
the AI stuff that we're seeing kind of start to get consumerized right now and become real,
it's super cool. There's no question about that. There are absolutely going to be
great product experiences improved by it and opportunities to create more efficiency,
create better interfaces. I am not negative on how some of the stuff will find its way
into consumer product experiences and make things better. My wife's company,
the publication of the information, we've already deployed a bunch of AI stuff that
makes search for the information go from absolutely terrible to pretty good. There's a
bunch more stuff coming that will get better. I'm not against that. I do think the things that I
keep in mind, one as an investor, is I think the case about why a bunch of this technology is going
to make meta and Amazon and Google and a bunch of big players, an assload of money are clear.
Right? I think the idea that it is a wedge or an angle that's going to allow a bunch of companies
from zero to come out of nowhere and then become wildly profitable or compete with those types
of big players, I think is much more sus as they would say. It's because I mean to really take
advantage of the stuff, you need a ton of distribution, you need a ton of data. I really
see a lot of what I've seen is opportunities to extend innovation that already exists versus
kind of completely reshuffle the deck. So that's my big thing. I am very bullish on crypto long
term. Crypto is undeniably whatever you think of it, a deck reshuffler. AI and what we're seeing
is not a deck reshuffler from my perspective as an extender. People come pitch me, we're going to be
the Adobe of AI. Adobe is going to be the Adobe of AI from my deployment. So I think
it's a very tough one to see. Will there be exceptions? Of course there will be exceptions.
There are always exceptions, but I think it's a seen thing. I think it's hard. I'd also say as
an investor, a seed investor, which is how I earn my daily bread. I'd say that the opportunities
to deploy a few million dollars, turnover a card and have an experience like, oh my god,
there's something here. Now let's have a series A investor put a ton more money in and see it scale
up, I think are few and far between. And because everyone's so excited, everything's way mispriced.
And so for me as an investor, I think it's an extremely hard market to get excited about.
What else can I say? I mean, look, I do think that the elephant in the room, which I'm sure
we can discuss or not, is for the companies that have gone out so far, talk about chat,
GPT, I think there's huge regulatory problems which are becoming clearer. And it's not about
like the machine is going to eat us all. I think that's a load of crap. And it's been in the record
for quite some time, being very, very negative and cynical about kind of a lot of those narratives.
I mean, at the end of the day, token guessing, guess the next token is not a fundamentally
dangerous piece of technology. I do think that the copyright issues are deeply real
and complicated. And there's a bunch of other challenges that these guys are going to face
that, you know, again, because the world has a general viewpoint of like, fool me,
one shame on you, fool me, twice shame on me is, you know, the era of from social media to Uber
to whatever, like, I think people are going to be way more quick reactive to like, what's going on
from regulatory environment here, I hope, then historically. But I don't know, that's, that's
a ton of ground. And I don't know, where do you want to go? Yeah, no, there's a ton of ground. I
think, you know, there's this question of, is this a disruptive or sustaining innovation? And
the question of what this is, you know, you have the classical big data and then you extrapolate
it to sell you ads. And that was good old internet. And it created these kind of behemoths in meta
and Google in particular. But then you have the application of computer vision and these other
things largely to the incumbents. So value was captured there. I was at your mobile and mobile
is a great example of like, just doubled down, right? Yeah. And that's why I tried to Facebook's
first shift. My mobile was good. Next shift to matter. And maybe they'll rename themselves
spatial or something. But, you know, this becomes very interesting. Because like,
these models are something a bit different. So like, with stable diffusion, we took 100,000
gigs of images and the app was a two gig file. And it was four of the top 10 absolutely app store
in December. We're having that as the entire backend. You put words in and images pop out and
it makes pretty pictures in your face, right? But then they all dropped off and they disappeared.
Because there are more features than apps, they're cool features. But they weren't kind of product
experiences. That is exactly what happened when the apps were launched, right? You had like fart
apps as number one for $5.99. There's a brief moment where it's cool and you're experimenting
with it and you have these kind of poops, right? But they're not. Yeah, I think like poops, poops.
Yeah, you're right. Exactly. Literally. It's not real because you have to have the user experience
and build products like normal. But where I feel right now is that we're at the primitive stage
and very boring interactions. One to one interaction is very boring. I think it is,
again, very surface level without any memory. And it's ephemeral and fleeting. My thing is
that probably iPhone 2G, iPhone 3G bit, we're just getting copy paste. Because what's happened
is you've got technology that's gone from research and is now starting to go into engineering.
What are the design patterns for this? How is it implemented? Was it good for?
I think the key question of this is like, you know, people say hallucinations.
I was like, what does that mean? Well, I mean, it doesn't get every single fact completely right.
ChantGPT is probably like 100 gigabytes down from like 10 trillion words. The fact you can get
anything right is an absolute technical marvel that no one's really sure exactly how that happens.
You know, it's like in a pipe pipe from Silicon Valley. Like, that Weissman School would be even
more intense if we could repress all that knowledge. Because what these really are,
they're reasoning machines. They're not fantasies. Because we've got two parts to our brain.
Are they reasoning machines? Aren't they guess the next token machines? Like,
that's the, I think, I think that's a really fundamental thing. Like, I think that my model,
I think the easiest way for most consumers to think about this, and I think it's basically
accurate, right, is like, there's no actual intelligence to be systems, right? All they're
doing is saying, okay, based on all the words I've seen in the graph of language that I've been able
to observe, here's the most likely next token. And that's really cool to be clear. That's like
super useful. But calling that intelligence is a real stretch in my mind. Well, I think it depends
on your definition of intelligence, like you're applying the free energy principles of Carl Friston,
and where everything's just intelligence from energy kind of dropping to its last date or
different definition of intelligence. I think what I look at it is like this. One to one is
getting the next token for language models, for image models, they're diffusion based and now
generate all sorts of other architectures. But it's about output, and what can it do? So one on one,
it's a bit dumb, it doesn't have memory. You have the meta paper by Cicero, whereby they had eight
language models interacting with each other, and it outperformed humans in the game of diplomacy.
You know, you just like all that good old AlphaGo type stuff, which he's reinforcement learning.
Is that intelligence? Probably still not, but it can augment intelligence. That's something that
we've been focusing on a lot, because you could use it for actual intelligence augmenting things.
You can use it for reasoning things. Give it a PDF and say, well, on Earth, this is PDF talking
about. You can do that right now. And that's a useful thing that reduces frustration. I used to
invest in video games. I used to look at time to fun flow and frustration. I look at things like,
you know, this podcast we're doing in a year, it'll be automatically transcribed and edited and
added to our knowledge base through next token prediction. Does that require AGI? No.
Yeah. Although interesting. Let's talk about this podcast. It's a really interesting case. You know,
in the early days of Clubhouse, when Clubhouse was ripping, I used to like go after Paul all the
time. And I wrote about this being like, you're so stupid for not recording this stuff. I was like,
look, here's the reality. These conversations in Clubhouse are dribble, right? Like 99% of them
is crap. And I don't want to listen to it. However, if you've created a magical pump
that says the internet is full of SEO shit and Wikipedia, we have a magic pump of people
wanting to talk to each other live. Here's the thing, people want to talk, no one wants to listen.
But if you transcribe and record it all, and you can create an index out of it, and then all of a
sudden you have this meta, this next generation search engine, but that's fucking interesting,
right? Here's the problem with Paul said at the time, which I think turns out to be totally wrong
given where AI is coming. He's like, yes, Sam, but like, there's no way to index it and blah. I'm
like, there will be like, there's clearly going to be, right? We're just, and it turns out I'd like
to, you know, because I like seeing, I told you so, like, I told you, they're definitely the way to
do that. Right. And like, that would have been super sweet. I think we're great. Here's the problem,
though, is with a lot of these visions of like, Oh, well, we'll just like take all the recorded
podcasts, right? And then kind of put a front end and tie them and like compress them down and be
done is there's no economic model to that. And maybe we can get into business models for a second.
That's going to make sense for anyone to publicly share, right? Like the way the reason that like
people put things on the web was because they were getting paid for it in one form or another,
because the whole ecosystem of Google, where it created was a trade. It was, okay, like you get
to index this shit, but you're going to send me traffic and I can monetize. And like, you know,
the publishers got snowed by that for a while, right? And like almost lost almost went away.
Until they figured out paywalls, right? We're doing this now because it's kind of fun and
bullshit and we'll learn, right? But we're also kind of doing it. At least I'll do it. I'll post it.
Maybe someone will follow me out of it. It's a fun hour to spend with interesting people, right?
But there's an economics to it in some form, social or financial capital. This model, I actually
think that the interesting thing about AI, if you take that view, whatever you think is interesting
is like, it's already going to crush the information economy of the web, right? I think that if you
roll it forward, like this conversation will not be in the public domain, right? Going forward,
because there'll be no, there'll be no social economics to it, just be a compression on top
of it. And if anything AI, again, if you take the model of, oh, it'll take a bunch of podcasts
and compress them down into tweets, right, will end up kind of collapsing on itself. If you need
people, what you do, right, to ultimately be the source of truth and information about the world.
I'm super happy with that point of view, but I'm not sure I entirely agree,
because you know, it's fun to shoot the shit. And Tony, you do have help podcasting. They've got
their ads, which is about, but I think the attention economy is a very interesting element to this,
particularly because these models are based on attention. So the differential of these models
versus previous is that you have the attention of all you need, Peko, where it's like, from an
information theory perspective, information is valuable in as much as it changes the state.
So you take this whole podcast and compare this down to a few tweets, that's all you need to
see. But sometimes people want to see the full kind of thing. No one really wants to do the whole
thing. Oh, no, they do, they do. Sometimes it's quite fun to kind of do it because, I mean,
let's say the Christiansen thing of a job to be done, right? You have a functional component,
a social component, and an emotional component. You know, why does everyone want to go to a
concert? You know, why do people want to have collectors items things? Products have different
aspects and different elements to it. People still read full books. They don't kind of read the
summaries of books. They don't read the simulacrums of it. I mean, like, look, to me, there's there's
two different, again, this gets into some more Facebook stuff. But like, I think we can talk
about let's take financial economy out of it and just talk about like informational and social
economies. There's the entertainment economy, right? For sure, AI is going to crush the entertainment
economy, right? Like, there's no question about that, right? Like, you start with porn and go on
through and the reality is, is that, you know, we went from, you know, people magazine to your
friends and your friends are more interesting than people magazine and gets with more and
plus than your friends is professional friends who are like Connor and funnier and guess who's
more interesting than hot funny professional friends, it's going to end up being actually I
said there's a more tick tock was it turns out algorithmically, find the best person from the
universe, you'll find some niche that's better. What's better than that? Synthetic, right? We will
get to the point where we say, Hey, like, there will be like a hotter funnier, more interesting,
more personalized AI thing, which is derived, like, I totally buy right. And I think that's
why actually some it's been funny to watch some pretty interesting influencers who are
smart, be like, Oh, my God, this is the end of the world for us. Right? I agree with that.
Information is a very, very different beast, right? And entertainment though, right? Because
the value is not like engagement. That is, that is actually the in the broad sense, the attention
is everything where it's totally wrong, right? Which is like, that is for sure true if you're
trying to optimize for entertainment. And it's not true, right? If you actually know what needs
to know what's going on in the world, right? Or you need to like, you're, you're dealing with a
real world. And that interface between the real world, the digital world, where the systems have
no knowledge of what actually is truth is to the point where I think it's probably that argument
falls down the most. Well, I mean, maybe this is why, you know, if you say that kind of hallucinations
are kind of core and it's the creativity machine, media is where it's more impactful, where the
truth is in the element there, right? What happened a little bit today is a few of the AI
companies wanted to talk about themselves as information machines. And they realized, right?
And so they'll be like, you're like, we're not, instead of we're creative, don't trust us for facts
is like, fine. And I agree, they'll be useful entertainment machines. But I do, I think that
goes into the whole like, what are we actually talking about here? What are the actual value is?
And like, how scoped it is, which is not, again, it's not zero. It's just not like everything.
We're so societies are based on stories. You know, like, all of my view on finance, pretty much
all of finance is securitization and leverage, telling stories. And then how did you tell them?
Like, we can see the power of stories as they move around. So Silicon Valley Bank was a story
that was true, and led to an $18 billion dollar outflow like that. All of us are kind of familiar
with that. Probably this is this podcast. I think it's pretty cynical to say it's all in the stories.
I mean, it's like, I think there are news reality in the world, like the economy is not based just
on storytelling. No, I mean, the dollar is a story. The economy is based on the dollar.
And so you have the Fed confidence, you have confidence in the stock markets,
it's kind of layers of these things. And then you have this technology,
you need trust, that's for sure true. And trust, I mean, ultimately goes all the way down to like,
is there a military behind it, which is somewhat of a story that I agree with. But I think that's
like, a pretty abstract view, right? Like, companies earn cash flows, they're real or not real,
they release products, they do work, it's real or not real. It's not just storytelling. What is
the multiple? Maybe it's because I'm a former hedge fund manager. So I always look to what was
the incremental story for a stock that adjusted the multiples and other things. Sure, I agree that
if you look at the world of multiples, you say, why do you get multiple expansion or compression,
right? And that's based on people's feelings about the world and future cash flows, right? And in
theory that that is a lot of storytelling. I don't think that's actually the vast majority of the
economy, right? That's the stock market. So I think that separating out what is the stock market
from what's the economy is pretty important. Hey, we'll continue our interview in a moment
after a word from our sponsors. Omniki uses generative AI to enable you to launch hundreds
of thousands of ad iterations that actually work customized across all platforms with a click
of a button. I believe in Omniki so much that I invested in it, and I recommend you use it too.
Use Kagrev to get a 10% discount. And I think this is the important thing. We separate it out and we
see, where does this technology affect? And when does it go to the incumbents versus startups?
All of these things kind of fundable, right? And so we have one area of media. We can discuss
that very concretely. I think it will have a massive impact on media at stability. We have
leading media team, right? And so we haven't agreed with that, but we can dig into that.
The other area is a lot of these things are language models right now that chat books,
and it's like, it's nice, but Bing is not the top search engine. It's not even top 20
on the app store, right? Because it's still a terrible experience, relatively speaking.
Yeah. So even though some people like why use it for all the things, you don't really,
you know, chat GPT rows really fast. And it's useful for things like doing your own work.
But do you really use it that much? So where I find it interesting is really looking at where
companies are trying to go beyond the basic search patterns and have the classical kind
of feedback loops with engaging content and see how that grows. So I think mid journey is a good
example of that, whereby David delivery built a community, took it to like 14 million people,
and is making money hand over fist, because he built even though discord is freaking weird,
a good experience on an existing infrastructure Facebook app style. But how many of those have
you seen looking across the entire AI space? Most of the stuff right now is terrible.
But again, the question is who gets the value, right? And I think like, let's talk about the
internet because we actually agree on the entertainment thing. Like, you know, world of
closed loop, it's all about what's the most engaging thing and attention is everything,
right? Yes, like these systems are like quite assuming that you don't end up getting into
hell, which I do think is a really big problem around human creativity and copyright and a
bunch of other points of legal leverage on these things. I agree that you can make really compelling
cases and it's going to hurt a lot of the human entertainment industry, right? That that I agree
with. But the question is who's going to win it? It's going to be the Hollywood studios? Is it going
to be, you know, is it going to be the existing publishers who just start adding incrementally
more of this stuff in, etc. Or is it going to be new startups or new people? You know, look,
there's always exceptions to the rule. But I think almost the entire pie is going to be the
people who have the distribution, they have the IP, they have like all the pieces they need to
just plug this shit in. Well, but I mean, maybe we can look at it in terms of the consumption
of content went to zero with streaming and kind of all these things that led to some winners
coming. Because you have Netflix, you have Spotify, etc. The creation of content basically goes to
zero with this technology as well. And you may see, I believe in a few years, who will feature films
using this. Yeah, but I guess you own and distribute those, right? And like the reality is,
I think I'll be the Hollywood studios, because they have the distribution, right? Like, if you
believe that's kind of the distribution mechanism, but there's a whole ecosystem that can build around
that. Things like Dnegg, things like industrial light and magook, do you need that when you have
rendering? You know, it's clear. To be clear, I think the thing I think you could totally see
changing or evolving is going to be the factory, right? So like, you know, meeting like, yes,
are there capital investments that people have made that will become less relevant because of AI?
Absolutely. There's no question. Will you almost certainly still have human writer rooms for the
foreseeable future? For sure, right? Like is whatever it is. So there's going to be hybrids. I just,
I think saying that and but my basic point is that IP matters, distribution matters,
like there are things that matter. I agree with you that the factory plumbing in some of these
places gets a lot less valuable if you have better AI tools. I just don't mind matters.
Well, I think it's a bit of a disruptive innovation for that side of things,
increasing the pace of output. So Pixar can do six movies a year rather than two.
And so the question around the industry, so a few weeks ago, I was at Cannondale gave a talk,
so I used to be a video game investor and player. And I was like, the video game industry over the
last 10 years has gone from 70 billion to 170 billion. The average score has gone from 69% to 74%.
Movies are 40 billion to 50 billion. The score is 6.4 on IMDb. Are you going to be able to make
better movies and have a bigger market then, in which case there's more room for people to make
money? Or is it going to be a case of, it cannibalizes itself? There's some key questions
around kind of media, right? And media consumption. In the end of the day, the media consumption
thing, though, again, depending on how you want to factor it and look at it, it really just comes
back. There's 24 human hours in a day, right? And the reality is, is like where time spent,
it shifts, right? As a result of this stuff, like for sure, time spent dramatically into social,
right? Off of other things, right? When that thing. Will social get more compelling, right,
with AI? Absolutely, right? And so will more attention shift into Instagram because of it?
Absolutely. Do I believe there's going to be another platform that comes out of nowhere
and swipes Instagram because the cost of production goes down? Nah, right? Like,
do I believe that like some new studio is going to come out and take out Pixar? Nah,
Pixel will just make a few more films, right? And like, that's cool. Like, I'm not against
that happening. I think that's completely fine. And like, people will make money on that in some
places. The cost of production and therefore the war of content gets more intense, for sure.
You'll get to a point where like, if you don't use this stuff, you're going to get fucked.
But like, just because the competition level rises, doesn't necessarily change the scorecard
very much through that, how these things go. So believe this question of do you use legacy
systems? Or do you use systems such as runway MLs, such as one of the dynamics, and some of
these other ones that are engineered differently? I think there's a lot of kind of legacy stuff
where you used to Photoshop and use continue to use Photoshop. And now they're introducing
features like infill, but is there room for a ground up kind of interface? And we see that
sometimes kind of a character. And my assertion is broadly no, but there will be exceptions.
And the broadly no is going to be, it's just, it's not to your point about, about is it a
sustaining or is it disruptive? It's like, Photoshop will get it 95% right. They already
have everyone's payment on file. They already have the infrastructure. This is not like the
internet. People like, in the internet, there was a bunch of companies that were fundamentally
unprepared for this, right? I do not think that most of the incumbents are fundamentally
unprepared for this. Yeah. And you know, there's a question of, do you create brand new markets?
So I was an early investment here, the Chinese kind of Twitch, and there was two hours a day
on average per user. Now on character AI, I think it's still number two on the app store. We're
seeing two hours a day on average of usage, which is some insane kind of engagement metrics.
It's quite nice to have a chat with it. But there's a question, can that become
then a product or a network? I think that we may be looking at some of the wrong areas here,
because what you have is you have the consumer experience, the media experience and enterprise
experience. I think one of the things that's most interesting for me in terms of where money
could potentially be made is actually the regulated experience. So at stability, we make
open models, open source, but actually what we do is open auditable models for enterprise,
private data, governments, et cetera. So we've got a whole bunch of stuff that doesn't have
anywhere to cross, et cetera, employed via bedrock models. But I think that's valuable data.
So one of the things we do is kind of education. And that's where I look at some of these areas,
and they've been the main contributors to US inflation and CPI education and healthcare.
And I'm like, you can do something different there. And maybe that's where a significant
amount of value will be. I mean, I think it's sad from the Silicon Valley story if the answer is
like, well, the money's all going to be made on regulation. I don't disagree with you for what
it's worth. Disrupting regulated industries, which is different. I do believe that someone's
going to make a lot of money on AI regulatory points, right? There's no question. AI insurance.
There we go. Like, you know, like, there's a bunch of things that are like really sad things
that you have to do as in like, you know, people will make money on, there's no question that
people will find these markets, they're super boring. And not the type of thing I want to be
involved in. But like, yes, like some enterprise investors will have will make bank on like, you
know, the whatever Europe comes up with certifying your models are compliant and GDPR 8.0 to like
deal with fucking data request removals, like that will happen as kind of the stuff happens.
I'm like pretty uninspired by that, right? Like, I think that's like, pretty sad that that's if
the net income of like new opportunities in AI is just going to be like opportunities to like
interface with government and rain it in will be sad. Yeah, but like said, regulated industries.
So the example that I have there is education and healthcare. So like, one of the things you work
with a range of charities and multinationals on is deploying tablets into entire countries in Africa
with AI that teachers have left, you give every kid a tablet, the young ladies industry primer,
what does that do to an entire nation? You know, the only thing that's been provably
to work in education is the bloom effect, the two segment effect. Right now,
trying to assist a charity Imagine Worldwide has been deploying the global enterprise for
learning adaptive learning. And we're teaching 76% of kids literature to the university in 13
months and one hour a day with older kids teaching younger kids. I look at this technology and I'm
like, there are certain areas where there's a gap, nothing could fall before. What if you had an AI
tutor for every child? What does that look like? What if you had 100 AI tutors for every child?
I get it. And like, I do think that we can always go back to the industries that tech has been trying
to disrupt for a million years. And like, for lots of structural reasons has not and say, ah,
but now with this new tech world disrupted, you know, I look forward to the, to the years of
debate in the, we'll talk about the US between the teachers unions and people trying to deploy
tablets for AI. We can say, Oh, no, no, no, no, we're going to do it in Africa, skip the regulator
like the teachers. But I'm just saying it's like, yes, there's always hope that the next wave of
technology will somehow unstick a bunch of problems technologists hate because of the
regulatory or the structural issues with them. But I, I have no confidence that this one is
meaningfully different. But I mean, this is the question structural issues, right? Regulation
is one thing. You look at kind of BG use some of the other Indian kind of education companies,
you look at the Chinese ones across emerging markets, maybe it'll be the case here. And this
is what I believe that much of the productivity enhancements, aside from maybe coding and things
like that, which we can get on to. And the biggest leaps will happen in the global south,
because they left a mobile and there's a whole mobile economy and massive companies created
from that. What if they make a leap to intelligence augmentation with this technology? Because right
now they can't service that. Now they could potentially service it, given the decreased
cost of creativity or engagement and other things from education to healthcare to other things.
I think if your argument is that there's a bunch of countries outside of the US
that have lagged in a bunch of infrastructure effectively or ability to like execute certain
things and education, et cetera, that will be able to allow the cell phone have like a leap
frog moment and move forward to that. Yeah, I don't object to that. I think that's like basically
true. Again, I goes back to the thing where like, I'm excited about kind of like the US,
I think lives in the future relatively speaking to most other people in countries. And like,
I think the thing most people are excited about is how like we can how AI changes like
the top of the top. I agree with that. So I think if your argument is it doesn't change
the top of the top, but it does kind of catch up a bunch of the third world, like I do think
that there are places that will be true. Well, so let's look at the top of the top then. So
I think Microsoft put out that 50% of all code is AI generated on GitHub now from co-pilot,
et cetera, and there's 40% improvement in efficiency. I mean, my top coders
really enjoy it because they train them in models. We have code models too, and they
are showing more and better code. What do you think about it with respect to that industry?
Because that's obviously a large industry, which is technology disrupted.
The only thing that I actually think is fucking awesome for chat GPT effectively is a call it
Stack Overflow 2.0. It's fucking great for that, right? And like, if you think about it,
why is it great for that? Like, why? Right? Like, I think it is the perfect problem
for the existing technology we have. You have a shitload of open source code that these models
can look at, right? Plus, you scrape all of Stack Overflow, which Sayonara Stack Overflow,
right? And that goes back to the whole copyright issue as well as the issue of where some of the
inputs come from, but most of the copyright issue. Plus, the nice part about computer code,
right, is that it's test driven in a lot of cases. You either pass it to the fucking test or it
doesn't pass the test, right? So you have like the perfect, the perfect data set of digital-only
self-contained reality, right? Which I totally agree, like, chat GPT is great at. And frankly,
like, I'm the type of person who like, I code, but I would never consider myself an engineer.
It makes coding for me so much more fun because all this shit I don't want to deal with, like,
what the fuck is this random error? What package do I have to install to manage this?
It's all great. Now, it does lie, and it does make up wrong answers, and it's not perfect,
but I fully agree that the co-pilot s thing is very powerful and like a really great specific
use case. And I do agree that, like, talking about business models or, you know, what happens is,
like, like Stack Overflow is the poster, Stack Overflow is the Yelp of this generation, right?
You know how Yelp had this, like, huge lawsuit with Google that's gone on forever because Google
basically just stole their results, right? Like, Stack Overflow is going to be that of this because
they are screwed, right? And, like, it is a great example of a place where the tech is better,
because it was basically worth it. Yeah. And, you know, it becomes very interesting as well,
because now what you have is regulatory arbitrage alleging, like the good old double Irish with
the Dutch sandwich on taxation, whereby Israel and Japan have said you can scrape anything for any
reason, which is kind of crazy, commercial or otherwise. So you maybe scrape in one area,
trade in another, and you serve it up in a different country. So I think this technology is
kind of inevitable. But then what is the implication of that? Like, my take is that as we move through
the next kind of five years or something like that, the nature of coding will change. Like,
I started coding what 22 years ago, we had, like, assembler and subversion and stuff like that.
Kids these days have it so easy with GitHub, you know, and all these libraries. What does it look
like in a few years when you've got these technologies that you can describe something and
start building apps? You know, what does the whole ecosystem look like again when the creation of
these tools? It will just make them much less valuable, right? Like, this is what it basically
comes down to. And what ends up remaining valuable is distribution and data, right? Because like,
right now you can be a great engineer or solve a problem, whatever, and there's like a value.
You can create a product that's actually worth something. If everyone can make products,
this is just theoretically, that are like cost nothing, right, or really easily, then like,
there's just no leverage in that anymore. And again, this goes back to who wins, who wins with
people with distribution data, right? That's the answer, like it from existing. Now, to your
point of a regulatory arbitrage and data, I think this is really, I think the sad part about a lot
of this AI stuff, everything is going private, right? Like, that's what the net of this is going
to be is like any, anything that has historically been an open data set, or people are able to say,
like, okay, well, like, I'll share this, but in return, I get traffic or notoriety, and that's
like a share economics rate over, right? And so what's going to end up happening is walls are
going to go up everywhere. Everything's going to go private. And that's going to be the interesting
question about where you end up from all this stuff from an economics perspective in the next
few years. But what is where this has happened many times before, right? Like, this is not the
first time in human history, this happens that, you know, people, you know, if you look at news
industry, you know, people are like, Oh, like the news industry used to be so great, and then
whatever, it's like bullshit. It's like the number of times that the history of news,
basically, you had growth and distribution, right? Things get super scammy. The elites
retreat to private newsletters, like in its cycles, it's happened like six or seven times.
And like, I think this is going to be a hard pin. In some ways, I think the biggest thing is
that I'm very confident of is that AI will be the death of the public web and will be the death
of a lot of open information, specifically because of what you said, right? Which is that just will
not, that it's going to be too valuable and too, and too, too important. But the reality is AI
doesn't need any more information because it's a future learner. But it does, it does, it doesn't
for entertainment. And that's why I think entertainment is screwed. I think it absolutely,
the, the Oracle problem in crypto, where how do you keep a system, a digital system in sync with
reality and being meaningful is exactly the same problem that AI has, which is it can go in any
direction it wants, as long as the data is self-contained. The second it's not, and it's trying
to be synced to reality or a real world, it does need more data. It does need to be continuously
updated or all dressed in whatever direction, you know, cars attention. But then, you know, you
have public broadcasting data, you have some of these other things as well, whereby the Oracle
problem comes a lot easier to do when you can do retrieval augmented models and other things like
that. I mean, there are sources of verifiable data for leasing. Maybe it comes down to the use case.
My basic point is that they're going to be increasingly cut off, right? If there's no
economic model for supporting them, and they're all getting abstracted and scraped by model.
I would disagree with this. So, you know, like, I made it deliberately open so that we could
highlight abstracts. I think they're unsafe as well. And we're the only company that's lost rocked out,
but we work with multiple governments on national data sets and national models using broadcasts of
data and other things like that, that are continuously updated as national infrastructure.
Because I think these models are a form of infrastructure. They're a weird type of primitive,
they're like a mega codec type thing, where stuff goes in, stuff comes out. But people do
want to have relevance and updates. So, I think you will have an open version that is updated
continuously. But then maybe, again, that's where value is. Which parts of information go private
and are served up through models and who is providing them? Is this financial data? Is it this?
Is it that? And what is the quality of these fine-tuned models? Because what you just described
as well is a bit of a Armageddon for consumer apps in a way, right? Because it goes down to zero.
So then what becomes useful is that Apple takes it massively forward because they've got this
identity structure. And they have all the data there and they can do apps quicker than anything else.
Yeah, except for the fact that Apple's entire shtick about encryption and privacy is going to
make it literally impossible for them to play in this. I actually think Apple's role in the future
of this stuff is going to be one of the most interesting big tech questions. Because they
have positioned themselves so hardcore against all the things you would need to get leveraged
right from AI that is going to be very interesting to see how they navigate. Google, fine, meta, fine.
But despite the fact I am very skeptical of what Apple's AI approach is going to be,
or I will say on the flip side, they're incredible at government relations and PR. So if they see
you have to figure out a way to totally recant on all their encryption and their approaches to
this type of stuff and have a new model where they somehow are the privacy heroes, but also doing AI
I'm very curious how that's going to work. They can keep in encryption and they can keep
a customized rule. Because again, you don't need to take everyone's data to the trainer.
You have a generalized model. I think your local model, many models on your local device,
like a general model behind it. Exactly. I think in practice, we'll see how it plays.
I'm skeptical. It works with an embedding layer potentially, but it is kind of very interesting
because again, the technology doesn't matter. It's the use that matters. What use can you get
out of it? So yesterday, they have the thing whereby they said, oh, it learns automatically
with a little ML model in there. It learns through a small embedding layer. They don't talk about
the technology that much because Apple always just talks about what the use actually is.
So I think the question is, what is disruptive? What can engage more? What can attract more?
And so I think that you've got apps coming down there, which is why the bar generally rises.
I think we see this with technology as it goes. The bar generally rises, and so attention becomes
even more difficult where it does come down to distribution. I think that that, but I mean,
what's your take on the nature of morality in this type of age? Because these things are good
at optimizing for morality, potentially, right? Like, again, you can build better content,
you can build better engagement once you get the funnels down. And that is the start of many of
these apps. Yeah, I just think virality is a war, right? In a lot of ways. So like, look, I think,
you know, in the end of the day, it's like, will newsfeeds get more compelling for people?
Absolutely, right? Will ads get more compelling for people individually? Absolutely, right? Like,
there's no question if these things are true and the existing players will get the vast majority
of the pie of that type of stuff. You know, I do think you'll tend towards more and more niche
interests, right? So like, let's talk about like porn for a second. Like, porn is always fascinating
as like a leading edge thing on this type of stuff. It's like, you can go on Reddit and find the
weirdest fucking porn in the world of all these sub communities that like have filtered into these
like weird things that they're interested in, right? AI will make this 10 times weird, right?
And like, or if 100 times, right? And like, people are just going to keep filtering. Now,
why does this like weird filtering happen? Right? Like, I mean, there's a bunch of reasons
and different things. I think part of it that moving away from porn for a second, the broader
people are desperate for a sense of purpose and place, right? And like the reality is the
internet makes you feel very small. There's millions of people just like you. And that encourages
people to seek out right sized communities that are smaller and smaller with AI, right? I think
the interesting thing will be when it comes to attention and things like that is look, for the
first time, every single person can have hundreds of characters that like and support them all the
time, right? Like the math of it all, right? You know, you used to be okay, like you're trying to
find a community that's the right size and knows you that you have a price and you're valued in,
right? But like it's hard to you're not necessarily the hero, right? So you go find out a smaller
niche or a different niche where you're more of a hero or like you create a fit of it and try to
lead that, right? I think a future where like, basically you log into social media or whatever,
and you're like, Hey, I'm Sam is like, cool, what type of people instead of who do you want to follow?
It's like, who do you want to follow you? Right? And like you end up with like hundreds of AI
characters or frankly, I think what's more likely is it's a mix of humans, AI's and you're not really
sure which is which, but they're caught, they're the ones commenting on your posting, like, you're
fucking great. Or like, here's a cool question or whatever, or like, I think that's the world we're
going to end up on is like more and more segmented niches, right? Where the ultimate end would be
the her model where it's like, you just have one AI girlfriend, I'm not sure we'll go there. I think
that's really hard to pull off. And I think like this, that's a tough thing. But if you told me
that like, in the future, you know, on Twitter, good example, you know, everyone has 100,000
followers, right, you're not exactly sure who's a person and who's a robot, right? And they all
fucking love you and it makes it super compelling and you feel great. Like that's a very plausible
future. Oh, man, birth rates are going to do that. And you see that child of young male virginity
13 the US for the Washington Post, they went from 8% in 2008 to 27% in 2018.
Do you see what happened with replica on Valentine's Day this year? So replica was originally
about it was designed to be your mental health buddy, right? Until they did realize you could
charge $300 a year for a lot of roleplay until the 13th of February 2023, when they get a message
from Apple saying shut this off. So on Valentine's Day, they shut that off. And then 68,000 people
joined the Reddit the day after and said, why'd you do the boss of my girlfriend?
You know, like, it was quite a massacre. That's where we're going. And look, there's a whole
history. I mean, again, like, we'll go back to porn for a second. Like the whole it's always
fascinating. It's like such an interesting base human thing. But it's like, look, it's like the
whole dynamic of like, you know, you know, how Tinder has affected sexuality, right, is like
fascinating. Like there's all these really interesting studies on this, like technology
has a deep impact on this type of stuff. Right. But if people ultimately want to care about
validation, titillation, whatever it's going to be, there's no question that place one place you
and I will agree is that AI does dramatically shift the power on these things, they will end up with
weird or sub communities. And he says, here's my question to you, though, we talked about
power dynamics. I still think, and in this I might be wrong about, I will admit, because it's a little
bit of a niche weird industry. But my bet is that porn hub is still the winner. I actually, I assume
they're the biggest porn company, like I or whatever Reddit is, it was like, the place porn is
doesn't shift the platforms don't shift. It's just going to be like, weirder, weirder stuff, and more
and more AI generated. I don't know. I mean, this porn hub is an update. So Mind Geek is the company
behind it. They were just bought by ethical capital partners. Because you know, life is weird.
Reddit could be a big winner of this. But I think, you know, I've been already like Reddit is already
just full of porn, right? So it's like, I just, I'm sure they're going to be very smart about this,
you know, and engaging porn. But really, what you're saying is go long AI waifus, you know, like
this kind of loneliness that they fill in, that could be a good investment team. Because again,
you have the whole whole life stuff that then emerges to these engaging people. I think it's
going to happen, but I don't think it's a good investment. And like, let me just go back to
like, just because it's going to happen doesn't make it a good thing to invest in. And like,
to me, it's really unclear where the leverage is in that, right? Like, it's like, you're,
you'd have to believe that somehow you're going to have dramatically more compelling characters
than like the next company also provide, right? Or you'd have to believe that like, I just don't
use any lock in, I think. And I don't think there's any like other. And so it's really unclear,
just because it's going to happen doesn't make it an investment. Well, I think there is kind of,
if you kind of look at hook dynamics, there is kind of that trigger reward kind of dopamine rush
and lots of stuff that you invest into each characters, there's probably going to be a lot
of first movement advantage here. On the other side, you have the licenses, you have the IPs
that can be brought to this, like not on the form side, but as a whole gamut from board to your
mental health buddy, right? I mean, I think ultimately, if you're basically saying, is there
a solution to loneliness and solution to making you feel good, there's a whole gamut of different
things that can happen here, where you've got IP, where you put these other things, again,
the example I think that comes from that is the hollow life influences, they're going up like that.
Not to push you with it. I mean, it sounds like you're agreeing with me, which is like the leverages
in IP, right, or the leverages in distribution, right, for this type of stuff, because the pure
tech stuff to it, it's like, yes, there'll be good jillions of, you know, virtual girlfriendy,
whatever things, but it's not those are not platforms you can invest in. And they're like,
they're not really valuable, even if there's a lot, I think bringing it all together is something
that will take time. So I think there will be a lot of first movement advantage. So like with
stability, again, data distribution, a key, right? So my thing is take the best of open,
which we stimulate and we fund lots of build the stable series of models of every data and
distribution to it. So open data, commonsense data, national data, and then we take it through
clouds, system integrators on prem, and I take a share of all that revenue. So I agree, that's kind
of cool to a good business. But what I'm saying is, I don't believe in this particular area going
from port at one end to mental health bodies in the other end, there are established distribution
networks. I think there'll be a lot of opportunity there for first mover advantage.
In the history of investing, first mover advantage has generally turned out to be a
pretty bad investment. Okay, maybe not first mover advantage, just say first proper
entity advantage that takes advantage of classical good company dynamics. There aren't
big companies there yet. Yeah, maybe. Again, I think it's a little hard to know exactly.
There's a huge spectrum here is it's hard to like, exactly react. But I would say like, look,
I think we're agreeing that like, entertainment's gonna get more entertaining, right? And super
to produce, right? I think we're agreeing that IP is very valuable and maybe it's more valuable.
Like, so maybe the answer is by Disney stock, because Elsa is going to be a way cooler character
when she like, that's kind of obvious, kind of obvious, right? And like, I think we can all agree
on that. I think what is not clear to me is outside of the IP plays outside of the
existing distribution plays, like what IP what AI really unlocks is a new disruptive
vector for this type of stuff, because I don't I do think that there are some pure AI type things
you can do. Again, we'll talk about the AI girlfriend thing is just unclear what the payoff
is there, right? Because they don't have any modes. Well, I think if you look kind of you can scale
a certain type of human endeavours, shall we say, for example, there aren't enough therapists in the
world, you know, and it is regulated industry. But at the same time, there is a gap for therapists,
just like you have the meditation apps kind of step in, and they created calm and they created
these other things that were huge. Now this is more engaging. So I think one of the areas to look
at is where can you not find enough people that can fill in some of these things, and then build
good experiences around by if you're looking at companies that can come to the fore, because there
is an existing solution. This is why, like I said, for me, I look at the global south, I'm like,
there's lots of gaps. I look at kind of here, and there's again gaps where the gaps that you want
to go because you can basically create a market need to fulfill a key customer need. And so again,
I looked at mental health in particular, and that goes again from the porn AI why things all the
way through to proper mental health, kind of therapists, there's a huge gap in that particular
market, and there's a huge chasm of loneliness, and a lot of products that could be built that are
genuinely useful. And that can go quite fast enabled by this technology where they were not
enabled before. I think this has been fascinating. I have kind of a handful of concrete prediction
questions that I kind of want to get you guys on record with if you're up for it, and see if you
have similar concrete predictions or different, and then we can obviously check back in on in the
future. How does the market for inference shape up? And for a jumping off point, how do you think
it might look different from the current cloud infrastructure market? I think inference will
be the vast majority, but I think it's like GPUs to assets with Bitcoin mining. Because these are
big research artifacts that I talked about, but the output is a little tiny part of binaries,
and that's not a complicated thing to run inference on. You see in Forensia 2 on Amazon
Cloud, you see kind of the TPU v5s and others. I think there'll be more and more customized
solutions as you move from that research to engineering bit, and then the cost competition
goes massive in a few years' time. Over the next few years, I think there'll be a shortage,
because everyone will try to use this technology, there won't be enough, and then eventually it'll
move towards the edge, because I think there's just all this magnitude optimization that we
can do from here. Yeah, I mean, this is a little bit beyond my direct wheelhouse, but I think in
the end of the day, what I'd say is like I highly suspect, because the distribution is indifferent,
right, and the patterns aren't different, and any of this stuff that we're going to see is
everything from chipsets all the way through to cloud providers. Things look basically the same
as they do today. Everyone's just making more money. Yeah, I think inference is also interesting,
because in the cloud, you just move to wherever the cheapest inference is for these models.
And so it's quite a mobile thing. So you've got NVIDIA coming forward for that reason.
Question two, what happens to the price of primary care medicine in the United States over the next
10 years? Unfortunately, given the issues, I think it should go down. The regulatory capture is far
too strong, and that's something major, major happens. Question three, you guys both have
kind of said there's a ton of junk out there. It seems like broadly, we're not expecting
that many major incumbents to be disrupted. What would you guess would be like the most likely
incumbents to be disrupted if you had to pick some? Stack overflow. I think a 4.1.6 billion by
process, right? Whoever it means, stack overflow. I mean, I think the process is probably fine.
You know, you've seen disruption in CHEG and other things. We didn't really get into this,
but I do think that some SaaS companies with less switching costs will be at risk from some of these
higher context window companies where you can put 10,000 words of instructions in, because some of
them are relatively basic in that way. Actually, for words, I think we once again mostly agree. The
only thing I think is at risk for things like Zapier, right, or something like kind of like,
and it's kind of a 50-50 because they also get way more powerful, but I think there's a bunch of
SaaS tools that probably end up looking more like features where they used to look maybe like
companies because of the AI. But real incumbents like public big multi-billion dollar companies,
I mean, I don't think any of them are really at risk of disruption. I think they're all just going
to get stronger. I think a bunch of startups or series A companies are going to get swiped out
or all of a sudden not going to be able to grow, right? Because I think the big guys will just get
better faster. Will the big tech companies that are currently open sourcing,
for example, Meta, Salesforce, will they continue to do so, or will they stop?
Well, I think Meta has moved to non-commercial open source for all their open source. I think
Salesforce has kind of continued to do full open source. I think it's just very difficult because
the regulatory environment become tougher and tougher, and it's not called to their business
to open source. I think that it would be 100% driven by business models, right? So like Meta,
if you think about it, he's incredibly well positioned, should generally the level of AI
continue to grow in the world, right? If you think about it, it's like the way they're going to
monetize that is having dramatically better ads, right? And like dramatically better content in a
bunch of ways. And so I think they have a heavy incentive to think about it, to like keep open
sourcing, if they want the talent, they want, you know, the reason companies also open source is
like, there's like a real internal, external interplay, right? In terms of how you build an
ecosystem that attracts great talent. So I think they'll still keep happening. But I think the
list of people who are supporting open source stuff will shrink, right? If that makes sense,
as people get super competitive about this stuff, and the battle lines are drawn.
If you had a billion dollar company, you know, of any kind, could you come up with a story?
Could you identify a type of company that should not, you know, where it wouldn't make sense, or
let's even frame it more decisively, where it would be defensible to not be investing, say,
at least a million dollars in figuring generative AI out today? In other words, is there anywhere
where this is not relevant? I mean, I'm sure there is, but nowhere I can think of offhand.
I think it's relevant just about everywhere, just because you always get a level of productivity
increase. But you know, as Sam said, for a lot of industries, is this sustaining innovation? It's
just the next stage as opposed to massively well changing, shall we say? What happens to the marriage
rate and the birth rate in, say, the United States as AI companions of all sorts become available?
It clearly goes down everywhere. I mean, like look at South Korea, they're at 0.8 now on the
fertility rate thanks to video games and a few other factors. There are negative and positive
ways to spin this. Actually, like I think I personally, I have the negative take on this,
like I mean, that the future and a bunch of other things, but here's the reality. It's just a simple
economics thing, which is like, if the world is more entertaining, then like, that makes doing
unentertaining hard long things like having kids and raising them like less appealing, right? It's
like Tinder Tinder is going to hurt the birth rate. Like AI is going to hurt again. It's just
sustaining innovation, which is technology generally is going to hurt the birth rate.
Yeah. And then you see places like Japan where you've got declining birth rates,
really embracing this because they want the productivity increase, which is the other flip
side of this. So if you're productive, that's people. Yeah. I mean, that's the irony that you
talk about a lot. The diamond age you referenced earlier, like a really long term sci-fi story
is pretty simple, which is like a highest, highest, highest level, like technology will drive there
to be fewer people. And then because there are fewer people, we need more technology, right?
And like it becomes a symbiotic thing. That's the really sad part. I mean, like it's all
sort of people thinking about like, oh, shit, like the entire human population is going to fall off
a cliff, right? It's because we're like, we're like entertaining ourselves to death. Do you think
any AI leader, you know, open AI right now or somebody who takes, you know, the leading position
from them in terms of having the best model can sustain super high gross margins for a few years
into the future? Based purely on the AI? No. It needs to be distribution data. I think the
proprietary side, it's just unless it's super data unique, you're going to zero. I think that you
have Google and open AI as an economic actors. And that's incredibly difficult.
You know, so just to unpack that, you mean that basically they won't allow, they don't intend
to make a ton of money on this and they won't allow anything else to either because they're
going to provide it at cost. They don't care about, yeah, they're quite under cost to get the data.
You know, again, they have different business models, Google cost shifts all the time, right?
This is why I went to the other side for models to private data and standardizing that.
No one's making money out of models alone. Well, I mean, there is a way. There is a way.
So what basically what I do with my business model is standardizing it.
And then providing all the services around it as a blueprint for my partners to take forward.
Yeah, I mean, there's a consulting nexus version of this, like that you can probably pull off.
Again, consulting models, I think, again, obviously, you're pursuing but very difficult.
I build the models, I give it to my consulting partners and they take it forward.
That's my business. My theory of stability has been a partial theory. It's obviously a lot of
facets to the organization. But I kind of view stability as the provider for like the non-aligned
countries, if you will, like those that are like, we definitely don't want to buy from
corporate America. We want to own our own. We want control. Those folks seem like they have
nowhere close to the resources domestically to build their own systems. But they do have kind of a
point of pride and also just practicality, right? Like if you're an African government and you want
to get your own legal system into a language model, you know, who's going to do that for you?
That feels like a real sweet spot for stability. How much of the future do you think is kind of
serving that kind of third set of countries? No, I mean, look, we're carrying subsidiaries
and dozens of countries bringing all the top family offices for data and distribution and
national models and national data sets based on broadcasted data. We take a subset of that,
make that open, and we've got the rest of that for our commercial side. So I think the Global
South is the focus for us, plus some of these big multinational companies building dedicated teams
without because we're the only company in the world that can build you a model of any single
majority or type. Is that sustaining? Who knows, but it's a decent business. And so my thing was
well to decent business, doing decent stuff, doing something different to other people.
I'm sure there'll be more competitors, but again, let's see how it goes.
Omniki uses generative AI to enable you to launch hundreds of thousands of ad iterations that actually
work, customized across all platforms with a click of a button. I believe in Omniki so much
that I invested in it, and I recommend you use it too. Use CogRab to get a 10% discount.
