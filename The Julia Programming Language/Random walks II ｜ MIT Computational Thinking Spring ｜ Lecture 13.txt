ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ �
ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ
ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ �
ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ �
ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ ლ �
ლ ლ ლ ლ ლ ლ ლ ლ ლ Bonnie
ლ ლ ლ ლ ლ hours
ᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠ�
Is that yet?
This is something you don't like.
Is that even going to happen to you?
readers
That's fine, I can believe it.
ლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლ�
ლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლ�
ლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლ�
ლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლ�
ლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლ�
ლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლ�
ლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლ�
ლლლლლ ლლლლლლლლლლლლ ლლლლ
ლლლლლლლლლლ
ლლლლლლლლლლლლალლლლ river
depending on the time, and depending on the time to also have a fun discussion on discrete versus continuous.
Was that was on me that had no that was me I killed it.
And you see my slides.
We see random walk up.
There's another one.
Sorry.
Great.
So hi everybody.
Welcome back to another lecture in spring 2021 semester of computational thinking at MIT.
So as Alan said today we're going to have the second lecture about random walks.
So we actually had a small technical problem with the video of the last lecture.
And so we have only just been able to actually upload that video to the YouTube channel.
So if you're watching this, you probably want to actually look at the previous video first, although they're reasonably independent at least to start with.
Okay, so what are we going to see today?
Well, we can just more about random walks.
And what we're going to see is that in Julia.
Let me just zoom in.
If we have an object, we can actually define a way that we want to visualize you that object when we when we asked Julia, you know, to just display the value of the object.
We can actually customize how it does.
So and we'll see that in action using structured matrices.
So if you remember from a few lectures ago, we had various kinds of matrices with structure by which we mean that we know where there are zeros in the matrix.
And then it turns out that in Julia, Julia has predefined types that represent such structured matrices like lower triangle, for example.
And when we display them, it will display them in a nice way.
And we'll see this function called CUME sum, which does cumulative sums.
And we'll see how we can do vectors, which contain vectors inside each element of the sort of outside vector is itself a vector.
And then we'll want to construct it a vector of vectors.
We often want to put them all together.
And that's called concatenating them.
And we do that with, for example, the h-cat function, cat for concatenate.
And also look at two ways we can draw plots in three dimensions.
I think we've already mentioned these, which are heat map and surface from both from the plots.jl magic.
Okay, so let's start off with a nice diversion, apparently, which will turn out to actually be related to what we've been talking about.
So that's Pascal's triangle.
So probably you saw Pascal's triangle at high school or sometime previously.
And just to note that, of course, as usual, I think it's Stigler's law that says that the person after whom a concept is named is never the person that actually discovered it.
And indeed Pascal was not the first person to study this triangle.
It had already been studied centuries before in India, Persia, China, etc.
And here's a link to the Wikipedia page, which has links to documents that show how it was being studied in other countries much before Pascal.
But Pascal apparently did contribute a lot to the understanding of this triangle.
So what is Pascal's triangle?
So we can generate it in Julia with a little function that takes in a number capital N.
And it generates this matrix that we're seeing here.
And the way it does that is by calling this function called binomial, which generates what are called binomial coefficients.
So what are the binomial coefficients that actually you can think of them as the case entry on the nth row is the coefficient of x to the k when you expand out one plus x to the power n.
So we could actually do this symbolically in Julia, but maybe maybe I don't have everything set up right now to do that.
But if you think about, you know, what is one plus x squared?
I'm just going to expand out the brackets and I'm going to get one plus two x plus x squared.
And so if you look at the coefficients of each power of x, you get one multiplying x to the power of zero, which is one, two, and then one.
And that is exactly what we see on this row of the matrix one, two, one.
And so, you know, if we do one plus x cubed, we'll get one plus three x plus three x squared plus x cubed.
And so that's where these numbers come from. That's one place they come from.
And this is called binomial. It has two terms. That's what binomial means.
And so these coefficients that we get when we expand this product of all of these things, what are we actually calculating?
You can think of writing this out. I write that out as one plus x times one plus x.
What am I actually doing? I'm just choosing one of these two objects from each set of parentheses.
And so the coefficient is actually the number of ways that I can choose, you know, one one and one x.
The number of ways I can choose that is one from the first bracket and x from the second or an x from the first bracket and one from the second.
So there are two ways of doing that, and that's what this coefficient is.
And so there's this function binomial to calculate within Julia.
What is that actually doing? There's a formula for that in terms of factorials and you can write that out.
And as usual, you know, if we wanted to know exactly how Julia was calculating it, we could do sort of edit binomial of one, two or whatever, and it would take us to the source code and then look at exactly how it's implemented.
Which we won't do right now. Feel free to do it yourself.
Okay, so note that in this matrix, because of the way these binomial coefficients are defined, it does not actually make sense to talk about n binomial of nk, also called n choose k.
It doesn't make sense to talk about that, at least in this interpretation as coefficients for k bigger than n.
And so it just fills all of those elements with zero.
If you look at this matrix, it's actually kind of difficult to visually note, notice that all of those elements are zero.
So actually you would kind of want to, that's kind of, there's too much visual noise, those zeros are too, you know, it's difficult to pick out which are zeros and which are not zeros.
And so we might want a different representation of that matrix.
And so if you notice this matrix, the coefficients that we're interested in are actually on the lower diagonal, the lower triangle, the lower half of the matrix.
Basically they're on the diagonal and below the diagonal.
And so this matrix is actually what we call a lower triangular matrix.
And Julia has a type called lower triangular, which we can apply to this matrix that I generated, which is coming from this Pascal function I wrote.
So I'm passing in 10, that's the size of the matrix, 10 by 10.
And now I'm passing it into this lower triangular constructor.
So this is a new type called lower triangular, which therefore has a constructor, and I can pass in the data I want to put in that type, an object of that type.
And we see that when I do that, it displays it in a nicer way so that these zeros are now just become dots.
And so this is an example of a type that defined in Julia where we actually can tell, you know, decide how to display objects of this type.
So the way we would do that is actually, we do this by extending the show function from base.
There's a function called show in base Julia, and we would extend that by doing something like, so let's make a new type with my type which has an int inside.
And then we're going to do base dot show.
I need this IO object, which is input output, and an object X of my type, how am I going to display that.
And then I'm going to put something like I'm going to print to that output stream.
You know, this is my type with value.
The value, I'm going to interpolate into that string of X, so let's not call it X, we will call it obj.
Hello, hello dot, the value of X inside the hello object.
And then if I make an object of that type, let's call that Y.
I'm going to make an object of that type by calling the constructor that Julia automatically provides my type of 10, and it should display Y equals, you know, this is my type with value.
So that's basically what they're doing.
So when you generate this lower triangular type, it prints out the size of the matrix, and it tells us that it's lower triangular, and these are the types of the objects inside.
So in 64 means that the elements of this lower triangular matrix are of type in 64.
And matrix in 64, even though it's duplicating and repeating this in 64, it just means that the underlying data that is being fed into this lower triangular object comes from a matrix
with interest in foreign site.
Okay, so these are called type parameters, and we've seen that a bit before.
So yeah, so what's happening here is that, you know, because I'm telling it that Julia that this is a lower triangular matrix, it actually knows that these zeros are what are called structural zeros.
They are zeros that we know are in those positions in the matrix because we know somebody told us that this matrix is lower triangular lower triangular matrices occur in various important algorithms in computer science.
Because of the way the algorithm works, for example, Gaussian elimination, you know that the result of this algorithm will be a matrix of this type.
And so you know that there are going to be zeros there, and then we can use that later on to, for example, solve a linear system with this matrix in a simple way.
Okay, so as a another structure matrix representation as a sparse matrices, we've already seen those in the previous lecture.
And when we display those in Julia 1.6, the display has actually changed.
If you remember, before we saw that, basically, when you tried to print out this matrix, it would give you a list of positions i, j with their associated values.
But that hasn't actually changed in Julia 1.6 to make it nicer to visualize.
Now you see them printed out in this way, just like the lower triangular matrix, with these dots representing structural zeros that we know are zero because of this.
I love that change, because whenever I just saw that list of i, j and a, i, j, it never meant much to me.
Yeah, that was exactly that.
You know, it was pretty difficult to get to understand the structure of the matrix like that.
But the point about sparse matrices is actually, you know, they really become interesting when the matrix is big.
And so let's for fun look at bigger matrices from Pascal's Triangle.
And what we're going to look at is actually where the elements of Pascal's Triangle are odd, are odd numbers.
So if you look at this table, you'll see that there are some odd numbers like these fives and these 15s, but there are also a lot of even numbers.
And so the question is just, what is the pattern of odd and even?
And that turns out to be actually rather interesting.
So let's do that.
So here I'm printing out the sparse matrix and I'm getting from Pascal with this size, right?
So here's a...
I think it's one more than the size.
Pascal's Triangle starts at row zero and column zero.
And so here I've actually got, yeah, I'm numbering starting at zero.
Okay, so as I increase the size, well, we see that indeed the matrix grows.
But at some particular point, you see at 16, it decides, oh, that's getting too big.
And since I want to, since I have a sparse matrix that I want to visualize, it actually gives me a much more compressed representation.
So this is called the sparsity pattern of the matrix.
And now the dots actually are meaning the non-zero elements.
So the zero elements are now just displayed as blank space.
And what you notice is that this pattern of odd elements is actually rather interesting.
And when I keep increasing the size of the matrix, you get this amazingly intricate pattern, which you might know is called Sipinski's Triangle.
Or a sort of squash version of Sipinski's Triangle.
And so why is this happening?
That's a much more complicated question that we're not going to go into, but it's just nice to observe that Julia is actually showing us this in a very nice way that's actually giving us much more information.
And so the numbers printed out with all those zeros.
I think there's also sort of a simple but big point that I think people sometimes miss, which is that when something gets very, very large, you really sometimes want to lose information to make it understandable.
I mean, like, you know, you go to something like Google Maps, right? When you go outward, you don't have the level, the street level detail anymore, right?
I mean, we've all seen that, right? And then the county level, the state level disappears as you go out further, right?
And then when you zoom in, you get more levels of detail.
So, you know, one might think that, oh, well, when you zoom out, you should just keep everything because who wants to lose information.
But it's always somehow better that like when you go outward, like less is more.
It's such an obvious thing, but you know, we don't always remember to sort of portray things that way.
Yeah, thanks, people.
Okay, so by the way, there is an alternative way to look at Pascal's triangle with just sort of change the variables and then it actually rotates it.
So you now get Pascal's triangle rows on the diagonal of this matrix and then some sort of looks more symmetrical in this representation maybe.
And yeah, thanks.
And I, exactly, those are the rows of Pascal's triangle in the way that we are used to seeing them and it's basically symmetrical now with respect to the y equals x for the diagonal line.
And actually, this matrix, this new version can be produced from the previous version by doing this particular matrix multiplication of the original Pascal triangle in the lower triangle form.
You transpose that that's what this prime means it means transpose it's a flip rows and columns.
And this is an upper triangle triangular version of Pascal same Pascal triangle and we do matrix multiplication between those.
We actually get back this same version.
That's when you thought you everything about Pascal's triangle new fun things come along.
Right.
So, okay, so.
So how do we actually get Pascal what is Pascal's triangle actually come from.
We, we, we were using these binomial binomial coefficients, but you know, you probably didn't learn Pascal's triangle like that when when you were in school, rather, you learn how to build up the rows.
So if we look at, you know, this smaller version, let's remember how do we build up this one to one row.
Well, this where is this to come from it comes from adding this one that's just above it with this one that's the left of that one.
So it's sort of adding the north to the northwest component at each time.
And that's true for each of these.
Thanks for each of these things I did.
I was going to draw that out but I didn't decided not doing it but yeah it's easier to do just by sketching my hand.
And so, well, if we think about it sorry so you start with this initial row with just one one and all zeros and then you just follow this rule and you construct all of these previous, all these next rows one by one you construct the
And so, so if we think about how we would actually do that in a program, or we do literally start with a vector, and then we would apply this rule to get the next vector the rule that I just said is adding the upstairs and left hand elements.
So what is that rule actually.
Well, if you think about it, what we're doing is multiplying this number by one and adding this number multiplied by one, adding those together to get the next one.
And that is exactly a convolution. So we've seen convolutions come up several times and here is another example of a convolution.
Remember, let's remember that basically we're thinking of convolutions as some kind of local operation local meaning that it only deals with a neighborhood of your current point.
But we're doing the same operation at each on the neighborhood of each point right so we're doing exactly the same kind of thing to each each element of this vector.
And the output is the output of applying that little local operation to each element in turn.
Remember the pixelated Mario, which was a two dimensional convolution, and it was like that little three by three window that moved along the pixelated Mario well now we're kind of in one dimension.
So it's not like it's not a three by three it's just one this case it's just a two right it's the numbers one one which slide along any one row of this matrix and produce the next row of this matrix.
Yes, this is kind of like an image filter except we're applying it in a different way now, because we're now, you know, taking the results of the first operation and making that the new next column and then we're taking the result of that operation and
applying the operation, the convolution again.
So this is actually a new new application of convolutions where we repeatedly apply the same convolution operation on the output of what we just got.
So if we do that we build up literally the same matrix that we had before.
Okay, so what does this have to do with random walks well this is almost exactly what a random walk does so let's have to go around.
So let's look at that.
So let's remind us ourselves what a random walk is.
So, you know, the, well, so what is a random walk it's just you start somewhere, and you move the simple simple random walk in one dimension, you start at zero, for example.
And at each step, each time click of a clock, you move left to minus one, or you add minus one to your current position, you jump by my distance minus one with probability one half you jump right with probability one half.
And then you keep doing that right just like you kept doing something to Pascal triangle, just now we keep adding random random steps to wherever we just got to.
And so, okay, so that those random jumps and can think of as random variables as we discussed a couple of lectures ago.
Each step is a random variable, which has as I said, you know, the outcome minus one with probability one half and the outcome plus one with probability one half.
And so every time I generate a new copy of that random variable that that is very similar related to the newly random variable.
Every time I do that, I will get a different answer I'll either get plus one or minus one with randomly and when I, you know, do it some some probabilities of distribution with a histogram, I should see that approximately a half of the time I get plus one and a half of the time I get minus one.
And that but now what that you know that's that's what we've already covered before but now random walks what do they do they take me that that that random variable.
And now they do it a lot of times, and then to each you know when when they have all those different random variables, we're now going to add up the outcomes of all of those random variables to make the value of the random
walk at time and so time and will add up and of these jumps to get the position of time and of the random walk or rather the displacement right so it could start somewhere that's not exactly at zero at the initial position.
So the random walk is in configuration is actually the displacement at time.
The distance from the origin. And so, if you think about it often what we do is we have that each of these steps is actually independent of the previous step.
So, if I take a random step at time 10, and then the next step at time 11 should not depend on which, you know, choice I made at time 10.
There are other kinds of random walks that are more complicated where that choice will depend on something, but we're not going to talk about those.
And so basically what we have is that each step is it is has the same distribution the same chance of jumping left from right, and it's independent of all the others.
So these, this is the very common case of probability theory, which is called the case of independent and identically distributed random variables.
It says what it is that I always thought that was a very long term for the term and that's why it's often abbreviated as I ID independent and identically just do the same thing without any link between them.
Yeah, exactly repeat the same thing over and over again.
They're all independent, but then for a random walk we want to take all of those I ID independent identically distributed random variables and do something with them we're going to add them all up.
And so what do we get we get something like this so if I, we is the is the name that we're giving to the ice step, that's a random variable.
Then x one is that the random variable course one to the first step with this particular jump probability distribution x two at the second step etc and x and the end step, then the sum of all of those those is the position of the random walk and time and just the
sum of those random variables, which you could write with a signal equation.
And so again, what we what we mean by the sum, we mean a new random variable, which whose outcomes are the sums of the outcomes of the random variables that we put in, and the probabilities behave in a particular way that we're going to cover in
Okay, so what we have but but but but there's a key point about a random walk which is that, okay, once we've we've got the result and time and we also want the result of time and plus one.
And how do we get that we get we take the sum of these x is all the way up to time and plus one.
And that is supposed to be actually the position and time and plus the end and the step at n plus that time and plus one.
And so you think about it, although the x is independent, you know, a mutually independent or independent of each other of one another.
The s is the distance of the positions at time and not the right so if the position, if you, if you happen to have a path around the walk path trajectory that goes very far in time 100, and at time 101, the position will still be very far away.
And so then no longer independent so that makes it actually harder to generate samples from this from this object is a more complicated object because actually what we what we need is in need what's called the whole trajectory of this random
which is the sequence of positions at each time state, and those are given by partial sums like this, right so the position at time one, or just, we're thinking of just random walks that starts at position zero.
Then the position at time one it's just given by the outcome of the first jump, but the position at time two is the outcome of the first jump the same outcome, plus the outcome of the second jump and then at the time three, it's the sum of the first those first two that we already recorded
that's the point where basically sort of recording these in order, and we are just the recorded value is going to be the previous value plus whatever the random outcome at the end step was.
So we're recording those in order and then we need to sum them all up in this way. And this process is called a cumulative sum.
So here's an example with numbers here are my random steps plus or minus one is the same way that we've been doing all along.
And now I want to add those up in this way right so the first first result is going to be minus one, then the second result is going to be minus one plus one which is zero, and the third one will be minus one plus one plus one, which is one, etc.
So that is what this Q sum function doesn't do.
So Q sum of this vector of steps indeed goes minus one zero one just like I did by hand and then it carries on and gets all the results into these partial sums.
And that's called a cumulative sum or prefix sum or scan only has some other names.
And you can do this with this Q sum function.
So here's another example 1234 the Q sum is 13610 which you might recognize as the triangle numbers.
So I noticed the trajectory doesn't.
It doesn't have the zero step so to speak.
Right so yeah exactly.
Yeah so okay that's true actually for that.
Yeah, so you can do that by.
So instead of just Q sum of steps we want to make a new vector where we start with zero, and then we're going to concatenate that zero.
I'm making an array with these square brackets and then I'm concatenating that whatever is before the semicolon with whatever is after.
And then that gives me the whole random walk trajectory.
So it has one more entry in the vector than the number of steps.
So this is also like if I had a bank account and every day I either added or withdrew a dollar and I'm allowed to go negative.
And this is the graph of my balance on each and every day.
Yeah that's a great analogy.
Yeah so yes he is just plotting that vector in time you can see that indeed it's doing the right thing.
So just to note that if you come from some other languages especially things like Python or Matlab and you said simulated random walks there, you probably would have been told to use Q sum.
And that you should not do it, for example with a for loop, but in Julia.
And that's because Q sum in those languages is more efficient is more performative faster, much faster.
And so you might think that that's because Q sum isn't an inherently a faster function than writing a for loop that is, that's not, that's not correct.
In Julia is just as efficient to write a for loop yourself.
And Q sum is basically just another way, approximately, at least of writing a for loop yourself.
And so what's happening is that in those other languages, it's not that Q sum is fast, it's actually that for loops are slow.
And so basically those languages are just preventing you from doing the natural thing which would be to write a for loop, and then forcing you to use this sort of other other other way of thinking about this.
This process to use this, this function, because that function is actually implemented in C code is not implemented in Python or Matlab at all.
Whereas in Julia, it's just all implemented in.
Yeah, in those languages, in Julia, in those languages in Julia, this is just just writing out a for loop, effectively, that you could write yourself right so I could have written a function my Q sum of some data that's going to be a vector.
What do I need.
I need a new vector.
That's going to be, let's say the same length as the so I could do that by making sort of new be equals similar of the.
So that makes a new copy of a new vector with the same length and type of the.
And then I'm going to do a for loop for I am one to the length of the new V number I is going to be where so the first one to stop up at the start new V at one is just the same as, as be at one, and then from to to the end to to the length of
I'm going to do new vi equals new V at I minus one, plus be at I, and that will show that that should give me the same, the same thing.
So let's just check that this is all unprepared so.
And my Q sum of steps.
They should give the same result they do that's great so my logic seems to be right.
You know I did it just to the test of my logic.
Actually, by the way, there is a module in Julia could test for the capital T, which enables you to do these kind of unit tests.
You know, is my my Q sum of steps equal to Q sum of steps, and it will run that test and it will tell you that oh yes that test pass right so you can actually sort of add these tests, your code to make sure that, you know, suppose I now modify this.
In some way, so I, you know, I start with 100 by mistake. Well, when I rerun the test, it will now tell me that the test failed. There was an error and it will, and it should tell me I do where that test is failed.
In this case, it's not telling me that I think I should do with puto, but you know, when I put it back, puto will rerun and now the test passes. And so this is a great way to make sure that once you have some code and you want to refactor it.
Or modify it in some way, you should write tests that tell you when you rerun the code with those tests, you know, is the code still working in the same one.
Okay, and so now what we need to do is test the performance side, I'm going to load the benchmark package, and then we're going to do at the time of Q sum of steps and you need this dollars.
Actually, I didn't mention that last time when we looked at QV time.
And then we need with terminal do because we're inside puto to print out the result in here instead of in the terminal to display this timing information in puto instead of in the terminal that I ran it from.
So Q sum that built in Julia one takes 66 nanoseconds and now the moment of truth, what does my Q sum take and let's see.
So it's almost the same speed right so.
I'd be more interested if you did something a lot larger like 10,000.
Okay, so let's say it goes steps.
Oh, just change steps here.
Yeah.
Well, let's just do steps too.
So steps to the random minus one one with 10,000 that's 10 to the power four elements, and then let's do Julius built in Q sum and steps to how long does that take, and then how long is my my Q sum take.
So the point is, you know, this is so easy to write in Julia.
This is exactly the code, you know, once you've understood what Q sum is doing, this is exactly the code that you would write.
I just like looking at Q sum.
I mean, I know what it is.
It's sort of like a higher level of abstraction.
Yeah, it's a high level of abstraction.
That's very important to have definitely.
So yeah, so Julius Q sum took this amount of time.
So what is these these two allocations is actually making the array by the similar command makes a new array.
And you can see that actually my Q sum is much lower than Julius built in one.
And he was, you might think, oh, that's because we were using a for it.
And no, it's actually because I need to annotate this line, right.
So Julia.
Don't you need the attendee or something?
What, right.
So Julia by default has bounds checks on a race.
So when you do something like V square brackets, I or checking, you're extracting this element number I from from V.
And the, but Julia will actually, you know, if I do steps of 11, it will actually tell me that I out of bounds.
So it's doing a check every time I access this element.
Are you in bounds or not?
Are you accessing an element that actually exists in your array or not?
And so I actually want to turn that off if I write a function like this, because I don't need it.
You know, if I write the function correctly, I can guarantee that I'm always in bounds.
Sorry, dangerous, right.
Let's, let's give people warnings here.
No, yeah, this is dangerous.
Yeah.
At inbound is dangerous because, you know, I'm having to guarantee myself that I'm not stepping outside bounds.
Julia is not going to do the work for me anymore.
That's why I have to explicitly turn it off.
So this is turning off, turns off bounds checks, right.
So at inbound turns off bounds checks.
And this is dangerous.
Okay.
So when I do that and I rerun my, my benchmark, what happens is that it's actually now apparently.
So I think, yeah, it's basically the same.
It takes the same time.
Right.
So that is showing that a for loop in Julia, as long as you include this bounds check to turning off the bounce check, which is what QMSUM is doing internally, then you will actually get the same speed.
So that's a proof that your for loops and this higher level construct in Julia are equally fast.
Okay.
So you go and look at the code for QMSUM.
You probably will find that it's actually a bit complicated because it's trying to deal with cases where you have a higher, a higher dimension array like a matrix.
I mean, I don't think I actually want to do that right now.
Okay.
So to finish today's lecture, let's look at a different way of thinking about these random walks.
So so far we've been drawing trajectories of random walks.
And actually, let's, I don't think you're drawing.
Oh, you did draw one trajectory.
Okay.
I drew one trajectory.
So let's, let's draw some more trajectories.
So you definitely didn't draw trajectories today.
So let's just not sure why it's taking quite so long.
Oh, because it's rerunning these benchmarks every time.
Let's just comment these out.
Okay.
So I'm going to just rerun this a few times and we'll see some different trajectories.
So let's actually add some limits on why going from minus 10 to 10 say.
Not sure it's still taking a long time.
Okay.
So now it should be fast.
So.
Okay.
Okay.
So there we have a sequence of different random walk trajectories.
Stop all starting in zero and you know, some of them go off the end because I didn't,
didn't put enough space on my axes.
By the way, I, I'm sort of.
Well, if we make this the circle smaller, smaller, but I want to make a point.
Yeah, that's much better actually.
You know, the idea that a trajectory is a random object just like a number is a random object might be worth shouting out a little bit, right?
That the random object is no longer one number, right?
It's an entire.
I mean, it's practically a function, right?
Like I could look at the value of five or something.
Exactly.
Yeah, exactly.
We are generating in some sense random functions.
And if I generate, you know, if I make it make the length a bit longer and expand by why limits again.
Then you can see that it actually starts looking much more like a sort of stock price like we were talking about last time.
And that's, that's going to go to 10,000.
And this may be easy.
Yeah.
Now we really have, yeah, it's sort of literally you can think of that as a function from zero to 10,000.
And it's, it's sort of really a random continuous function.
And you really can't think of these, these, these things like that.
We're basically sampling from a set of random functions with certain properties, a certain probability distribution actually.
Right.
So what we really want to know is what is the probability distribution of these sort of random paths, random functions or.
Yeah.
So if you mind blowing to realize that a, a trajectory is, is a random object.
Yeah.
If it's own or not.
Right.
It's definitely mind blowing to me.
Yeah.
So for example, if we fix our attention that, you know, in this case time 2,500, just, just look at this vertical line is grid line here.
And let's generate some paths.
Okay.
Maybe 10,000 too many.
It's too slow.
Let's go back to 100.
Okay.
So let's fix our attention at a time 25 and just regenerate us.
That's not good.
Sorry.
My limits are too.
Okay.
Fix our attention at time 25 and ask, well, where is the random walk at time 25?
You see that it dances around right at this, this particular point.
Let's actually maybe add that in.
So we'll just do a scatter at 25 and steps 25 and we'll color that in red.
And I didn't quite get it right.
It's steps 24.
Okay.
So that's the one we're going to, to look at.
Like the title to be the value of q steps of 24.
So we can actually see the number.
So.
Okay.
Okay.
So it's the position at time 25.
Equals.
Yeah.
Okay.
Equals.
Okay.
So now let's regenerate them again.
And so you see that this point is dancing around.
And now we want to ask, well, what is the probability distribution of that position?
So that red point is now a random number.
Right.
That is a random number at, at time 25.
So when we can ask, what is the distribution of that random number?
Really an even number.
Just, just, you could try it a few times, but,
or you could think about why that's true.
Yeah.
Well, certainly.
Yeah.
If you look at the value that's coming out, it's always even.
Right.
Because it's the result of the random number.
It's a random number.
Right.
That is a random number at, at time 25.
So when we can ask, what is the distribution of that random number?
Because it's the result of 24 plus ones or minus ones.
Right.
24 odd numbers.
So there's a parity argument going on.
Yeah.
So we can ask, what is the probability distribution of that thing?
And so what is that thing, that value, that height?
It's, as Alan said, the sum of 24 plus ones or minus ones.
So we actually saw what happens when you add random variables and many random variables
together a few lectures ago.
What we expect to happen is that we get something that is close to a Gaussian distribution,
a normal distribution.
And so we should expect the position at time 25 to be something looking,
something like a normal distribution.
Okay.
Now, if I repeated that same experiment at time 50, well, I would see a different distribution
because at time 50, I might expect to have gone a bit further away from the origin
than at time 25.
But here I'm going to get a different distribution that also should look something like a Gaussian distribution
or a normal distribution.
And I can do that actually at all of these times in between.
Well, let's think about that a second just before we do anything, right?
The mean of that distribution is sort of, I guess, obvious, I think.
Right.
And I guess I would expect the, since at 50, I figure it could go, you know, it's wider, right?
It can go further than 25.
I guess I expect the variance to go up in some way.
Yeah, exactly.
Good point.
Yeah, so this is probably we're going to, you know, if you sort of try now to fix your attention on 50
when I generate some new samples.
Hello.
Maybe it's wiggling around more than 25 is wiggling around.
So can we characterize, you know, can we quantify all of these qualitative arguments?
What are we going to try and do?
So we could literally take, you know, literally generate a lot of paths and literally calculate these distributions.
We could do that, or we could use a different approach, which is what we're going to do.
So what's the different approach?
We're actually going to think about, well, if I have the probability distribution at some time,
how can I get from that probability distribution to the probability distribution at the next time?
So let's call PI, P sub I, P with a subscript I and a superscript T.
So I'm going to use T for the time so that it's easier to understand.
So I'm going to call that the probability that ST, which is the position of the random time T,
the probability that that thing is equal to I.
So I is the position that we were just drawing and T is the horizontal time.
It was just 25. We were focusing on T equals 25.
Exactly.
So we were wondering, and I said that I has to be even or else the probability is zero.
Right.
Exactly.
So, exactly.
So S 25, we wanted to know, well, how likely is it that S 25 takes on the value 10, for example?
So how likely is it that it takes on the value nine?
It has probability zero because it's always even.
How likely is it to take on the value 10 in some number that we want to calculate?
And the sum of all of those numbers over all the values of I,
over all the possible endpoint positions at time 25 has to be equal to one.
It has to be somewhere.
So, but we have to figure out, like, if I'm tossing 24 coins and getting plus one or minus one,
what is the chance that I'm going to add up to 10?
Exactly.
Yeah.
So that's, you know, yeah, exactly.
So let's collect all of those values together, all of those probabilities for different values of I,
that should, as I said, sum up to one.
And those, that collection of probabilities for all the possible heights is a vector, actually.
So let's call it the vector boldface p at time t.
This is not a power.
It's just a label saying that it's on time t.
I could be negative.
Yeah, these things have a weird indexing.
They can go from sort of minus 10 to plus 10 or something.
Yeah.
The I, the value of I, thanks.
So what happens at the next time step t plus one?
Well, at the next time step, if we were to take the histograms,
we would get a different probability distribution, which is called, you know, p vector t plus one.
So how are those two vectors actually related?
And think about it, how, so let's fix our attention on 25 on position and not 25.
Sorry, let's fix our attention on now on height 10 at time t plus one, right?
And the question is, that's not, that's not right.
Yeah, well, let's say that.
Yeah, so how could I arrive at position 10 at time 25?
For example, well, I had to have been at position nine or position 11 at time, the previous time 20 times 24.
And then I had to jump from those positions in the correct direction.
So basically, I have however much the probability was at that point,
times the probability that it jumps in the correct direction.
So that I can write down in this very compact formula.
So what does this say?
It just says in a formula, what I just said in words,
the probability that I'm at position I at the next time step t plus one.
Well, I had to be at the previous time step t.
I had to be at position I minus one and then jump towards position I,
which I'm doing with probability a half or plus is all I had to be at position I plus one and jump towards position I to backwards.
That also happened with probability a half.
So this is a formula that tells me if I know what the probabilities are,
the vector of all the probabilities at position at time t,
how I get the new vector of probabilities at time t plus one.
This isn't.
So it's telling me how these probability vectors evolve in time.
And this equation is often called.
So it's a tiny evolution equation discrete in discrete time and discrete space.
And it's often called the master equation,
which is a really terrible name that often what it's called.
I think that dates from the 30s or something.
And yeah, as I said,
it describes this time evolution of probabilities.
And so if you think about it, what is this doing?
Well, it's actually rather similar to something we already saw at the beginning of the lecture,
which is Pascal's triangle.
This is almost exactly the same as Pascal's triangle,
except for this factor of one half.
But we're adding two things together from the previous row.
Basically, if you think of these as rows or I guess they were columns,
if you think of them as columns and you rotate your head, now they're rows.
But basically each column,
you get from the previous column by applying the same kind of convolution
that we applied in Pascal's triangle,
except now we also are missing the one at position I.
So before we took the one just above and the one to the left of that,
now we're taking one to the left and one to the right,
and we're missing out the one in the middle.
It's almost the same.
So there's another convolution.
And so these probabilities are actually evolving just like the rows of Pascal's triangle.
Okay, so we can implement that in Julia.
So for example, let's write a function called evolve,
which just does this calculation.
So here's the calculation.
So again, we're taking in, we're supposing that we have a vector of probabilities
at time, at some time,
and we're going to make a new vector of probabilities with again this similar function.
And then we're going to loop through all of the whole system
and do this rule that I just wrote down.
So the time, you know, the probability at position I,
the new time is a half of this sum,
this convolution, we could write that as a convolution.
But then just like we did in images,
we have an issue, a problem,
which is what to do at the boundaries.
So what happens at the boundaries if some probability wants to jump
or if you're random walk, you know, thinking about the random walk,
if you're actually going to fix some boundaries of the system,
why do we need to do that now?
Because we're actually talking about the probability of being at each point in space,
and we can only store a finite number of them.
So we actually have to impose some limit on the size of the system.
And then we have to worry once we've imposed that limit,
you know, when we were simulating trajectories of a random walk,
we didn't have any such limit because it could just wander off as far as it went.
But now we're actually trying to store information at each of those points.
We really need to stop and say, oh, you can only go up to this distance.
And then we have a problem with the boundaries.
And so we need to decide what the random walk will do when it hits the boundaries.
So it could do different things.
It could bounce off and come back.
It could go around and sort of jump off one side of the system
and come back on the other side as a periodic boundary.
When it bounces off, it's called a reflecting boundary.
And what we're doing here is called an absorbing boundary.
So we're just setting the value there to zero, the value of the probability.
And that actually corresponds to probability leaking out of the system.
So any probability or random walk that hits the edge just disappears,
just vanishes into sort of an infinite sea.
You can think of my system being in contact with the sea.
And I'm thinking of this random walk as heat moving around
and when it hits the sea, it just sort of dissipates into the ocean.
The point is your sum of probabilities will no longer be one.
Right.
This has a weird property that the sum is no longer one
because some of your probability, a part of your probability leaks out of the system.
Right.
I mean, you could think of it as like the piece that, you know,
the remainder that would bring you to one is now like the probability of being in the sea.
Yeah.
It's the probability, exactly.
You have some probability that by this time you have already escaped
and that a probability adds up to all the other probabilities to give you one.
And so yeah, as I said, this is just a convolution.
Now the kernel looks like this.
So you could write it like that.
Okay.
We've done the probability that boundary conditions.
Now we have another thing, which is the initial condition.
What is the initial distribution?
Where do these random walks start?
Or what is the probability that they start at different places?
So if they all start at site at position zero and time one,
then the probability of being at position zero is one.
Everything is there with certainty.
The probability of them being anywhere else at any other site I is zero.
It's impossible.
And so we just set up a, an initial condition that looks like that.
So, you know, we can just call this function initial condition with 10,
let's say 11 positions.
And you see that there's a one in the middle and zeroes everywhere else.
And then, so now we can just run the time evolution.
And so in order to do that, we, you know, here's a,
here's a function that does that.
So what are we doing?
We're put passing in an initial vector P zero,
which is the probability distribution at time zero.
And then I'm making a vector that contains that object.
So that is actually going to be a vector of vectors, right?
So if I have sort of P zero is initial condition at,
with 11 cells, I already have a P zero somewhere else here.
Sorry.
Yeah.
So there's P zero.
That's the initial condition.
In this case, I put a hundred and one cells and it's taking ages to run.
Maybe I'll just point out that your micro century is sort of coming to an end.
Yeah.
So if I put square brackets of P zero,
I actually get a vector and inside that vector,
it has just one element, which is itself a vector.
So that is what I went by a vector of vectors,
a vector containing vectors.
And then so let's run this time evolution.
And what I'm going to get back is a vector of vectors where the vector
at time at the vector number element number four, for example,
is the probability distribution of random walks at time four.
Then I can visualize that in various ways.
I would jump to the 3D visual at this point if you don't mind.
Okay.
Yeah.
So this is the time evolution of the histogram spreading out.
So this is a spreading process.
And then we can show this in three dimensions.
So here we have time on this axis.
So we're starting with everything in position one.
And then you see that it's spreading out over time as we go along.
And we can also see that with the random walk trajectory,
which is this line on the bottom.
And every time I generate a new trajectory,
you can see how it moves around.
And so these bars are actually telling me how likely it is
for this blue dot to be in each of these positions.
Okay.
So that's the...
So you want to run a few more random walks
so people can see where it is.
So thanks to the final line.
It's kind of fun to watch that.
If you fix your attention, for example, on this blue dot,
you should see that it visits different sites
with these proportional to these probabilities.
So it's very unlikely to be kind of far away.
And it's very likely to be to end up...
Not very likely, but it's more likely to end up in the middle.
Sorry.
So hopefully that visualization makes it kind of clear
in what way...
What does it mean to have a probability distribution?
We're drawing each of these histograms at that time
is a probability distribution for the position
of the random walker at that time.
And averaged over all of these paths.
And then we have a probability distribution for each position.
And I hope people actually could see that there's...
Pascal's triangle is basically there in the sense of...
Yeah.
You know that...
I mean, if you want to think of this as one and one, one,
literally divided by two, so it's half, half,
and this is one, two, one, right?
It's divided by four, right?
And this is one, three, three, one divided by eight, right?
And if you recognize those numbers, that continues down.
And so this is in some sense a kind of picture of Pascal's triangle,
normalized by two to the n and each row.
Right, exactly.
Yeah.
Okay, so random walks, as we said last time,
very important and very interesting
and actually contain a lot of beautiful mathematics.
So this is a kind of triangle comes back to, you know,
suddenly without us kind of expecting it.
And yeah, so there'll be some more questions about that in the homeworks.
Yeah, I guess we'll do discreet and continuous next time.
I have some fun stuff to say, but...
Yeah.
We'll have to wait for Wednesday lecture.
Yeah, okay.
So see you all next time.
