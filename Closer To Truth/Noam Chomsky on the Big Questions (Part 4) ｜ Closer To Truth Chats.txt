of the ape was able to do things that made them think,
oh, he's asking for a banana.
But when they looked at it closely,
and then was just producing science,
which somehow got him what he wanted sometimes.
Welcome to Closer to Truth Chats.
Today I'm speaking with Noam Chomsky,
the distinguished theoretical linguist,
analytic philosopher, cognitive scientist,
and public intellectual.
He is Institute Professor Emeritus at MIT,
and Laureate Professor of Linguistics
at the University of Arizona.
Closer to Truth is presenting this four-part mini-series
with Professor Chomsky.
Part four now covers applications of Chomsky's
linguistic theories to other fields and issues,
and his thoughts, opinions, reflections
on Closer to Truth themes and big questions.
So, Noam, let's begin with an overview of what
has been called, what you've been called,
the basic property of language.
And it's three parts that you've
talked about, the internal computational system that
has hierarchically structured, the sensory motor system
that expresses through externalization, speaking,
et cetera, and then this internal conception system
for inference, interpretation planning, what
is we informally call thought.
So just want to get your sense of this big picture of language.
If you take a look at the human species,
what sharply differentiates it from any organic species
we know of are two things, the possession of language,
possession of thought in any form
that we can grasp what thought is.
I have two identifying features of a species.
First question that comes to mind
is what's the relation?
Simplest relation would be identity.
And in fact, that's a fair statement.
It's been understood through history for millennia, actually,
that language and thought are intimately related.
Language has historically been called audible thought.
It's the mechanism for constructing
thoughts over an infinite range, which we then
can access and use in our various activities.
The internal nature of until the 20th century,
when mathematical theories of computation
were developed clearly and precisely,
it was very difficult to capture the essence of this system.
The last 70 years, we've been able to do it.
What we need, what is somehow coded in our brains
is a finite procedure, kind of like a program in your laptop,
a finite procedure which generates
an infinite number of hierarchically structured
expressions, each of which is an expression of thought
and which can be externalized into some sensory motor medium.
Usually, sound could be sign, could even be touch.
Sound is the usual one.
That seems to be the basic character of language.
It's not quite the instrument of thought.
It is thought.
We have thought insofar as we have language.
In any significant sense of thought,
there are a couple of dogs at my feet,
and they have a kind of thought, but it's finite bounded.
If I say a couple of certain words, I can say which I won't say,
and they'll be running to the door, it's a sort of thought.
But it's not what we're doing now or what humans do normally.
Constructing modes, expressions that can be used
for reflection, analysis, planning, inference,
all the things that our minds uniquely do.
They basically do with language or with instructions
that language provides to other cognitive systems,
just as the internal language that we have
provides instructions to the articulatory system
which we can then pick up and use to pronounce things.
Sort of similar on the side of conceptual analysis,
reflection, thought, generally.
That seems to be the general picture.
So if this basic property is really basic,
where and when did it first appear?
I think you've written so much.
I'm not sure when this occurred.
But you've said that the origin of mind-dependent,
word-like elements remains a mystery.
Other people don't think it's a mystery,
but you still think it's a mystery?
Total mystery.
We have no idea.
But we know a lot about it.
So for example, Lilik Leitman's work
died recently, an outstanding cognitive psychologist
and linguist.
She, her work, showed that a child of maybe two or three
has an enormous knowledge of language
well beyond anything it can express,
and particularly with regard to words.
Children pick up words at a fantastic rate.
At that age, they may be picking up one word every waking hour,
pick up on very few presentations, no training,
nothing like that, very little evidence.
And they know the words and all of their richness
and complexity.
Then comes the second part, investigating
the character of the words.
And it turns out even the simplest ones, the ones we use
to refer to the things around us,
have rich, complex, internal structure.
So there's a question, two questions.
One, a question of acquisition.
One, a question of evolution.
Question of acquisition is how infants
are able to hit upon the rich, complex notions
that they have mastered at a very early age
with very little data.
One question.
The other question is, where in human evolution did this arise?
Well, my own feeling for a long time
was that this was lost in the mists of pre-human history.
I think now that that's mistaken.
If these complex concepts, even notice
that even the simplest concepts, tree, desk, person, dog,
whatever you want, even these are extremely complex
in their internal structure.
If such concepts had developed in proto-human history
when there was no language, they would have been useless.
They would have been an accident if they developed,
and they would quickly have been lost because you
can't do anything with them.
So chances are very strong that the concepts developed
within human history at a point where
we had computational systems which satisfy the basic property.
Well, that reduces the mystery somewhat.
It means it was within the last couple hundred thousand years,
which is a blink of an eye in evolutionary time.
Anthropological research has succeeded
in giving a fair amount of information
about up to 20,000 or 30,000 years ago
how indigenous cultures, they were quite rich,
indigenous cultures developed and operated.
So this kind of narrowed the time window
in which this evolution presumably took place.
That doesn't solve the problem, but it makes it a little more feasible.
It's during this era that we do begin to get complex, symbolic behavior,
fantastic artwork, evidence of complex societies,
and so on, roughly in this period about 100,000 years.
Would you use the term human to whatever primates were prior
to that language explosion or that language event?
Well, these are just technical usages.
Those are hominids, hominids, homo sapiens,
especially our species, separate species.
Its origins seem to be in the order of 200,000 to 300,000 years ago.
Co-terminal with language.
Well, that we don't know, but there's evidence.
Prior to the appearance of homo sapiens,
there's no evidence in the archaeological record
for any significant symbolic behavior,
maybe a mark on a stone or something.
So the kind of complex behavior that seems to require language
doesn't appear before homo sapiens.
So that puts one kind of bound.
We have another firmer bound.
Genomic analysis has now placed the separation of humans
at about at least 150,000 years ago.
So we're now down to a very brief period,
and all known humans have the same language faculty.
So it seems clear that the language faculty existed
before the early separation of humans,
which leaves a very small window,
means something pretty simple must have happened.
50,000 years sounds like a large number,
but not an evolutionary time.
In terms of the purpose of language,
it's generally assumed by evolutionary biologists
that communications is the primary purpose,
the driver of it, with analogs from animal communications,
whether it's bird songs or monkey calls,
that that evolved into human language.
I think you've taken quite the opposite position,
which is not unusual for you to take opposite positions,
that language is more an inner mental tool
as its driver or as what it was as opposed to a linear evolution
of communications capabilities.
Well, let me first step back a step.
Talking about the purpose of a biological system
is not really appropriate.
Biological systems don't have purposes.
They appear, then maybe they're put to use in one or another way.
But if you look at the process of evolution,
it really has three stages.
The first stage is something disrupts the existing system,
maybe a mutation, maybe symbiosis.
So sometime a couple billion years ago,
a billion years ago, a bacterium swallowed
another microorganism that led to a disruption of the system.
It's the beginning of eukaryotic cells.
The basis for complex life was an accident.
Well, first the system gets disrupted.
Then the second stage, nature tries
to form the simplest, most elegant solution
to how to deal with this new phenomenon.
That's the second stage.
The third stage is winnowing of the various things
that are around, which ones are going
to have higher reproductive success, natural selection.
Let me take a look at the language.
The initial stage, some stage of disruption, evidently
produced a recursive function of a computational procedure
that can be coded on a computer effectively.
That's basically what a recursive function is.
So the first stage that appeared somehow, presumably
some small rewiring of the brain,
led to the appearance of this second stage.
Nature formed the best possible solution
to how to incorporate this into the brain.
Well, the goal of contemporary linguistics
is to find out what that system is.
But what about the winnowing stage?
That never came for language.
There never was any choice, partly maybe
because there just wasn't enough time,
but partly for probably for a deeper reason.
When you look into this system that nature
constructed in detail, you find that it's
so tightly integrated, so elegantly put together
that any modification of it in the whole system collapses.
So there was just no way to select.
It looks as if selection just didn't operate for language.
At least the core parts of it, it certainly
may operate for peripheral parts.
Now, if we look back at the, so I
think we can't really talk about the purpose
of the system, we can talk about how it's used.
OK, now if you take a look at how language is used,
sometimes it's used for communication,
like you and I are doing.
But that actually is a very peripheral use.
Almost all of our use of language goes on.
All of our waking hours, most of our sleeping hours,
is just thinking.
We just can't stop.
Almost impossible to stop.
It takes a tremendous act of will to stop thinking.
That's our overwhelming use of language.
We don't know.
We only know what's going on there from the outside.
We can't introspect into it.
What we call inner speech is not inner speech.
It's externalized speech, where the articulatories have
been put on hold.
What's actually going on, we can only
discover the way you discover how the visual system works
from the outside.
And that's basically what linguistics is about.
At least the kind that interests me
try to find out what this system is that Mother Nature put
together that is used entirely for thought.
Now, there are other reasons for thinking that communication
is a peripheral use of language.
When you look at the nature of this internal system,
you find that there are conflicts
between computational efficiency and communicative
efficiency.
And in every single case, communicative efficiency
is sacrificed, as if nature just didn't care.
It only cared about computational efficiency,
constructing a beautiful internal system, which
is typically the way evolution works.
That's how evolution generally works,
for perfectly good reasons.
During the second stage of reconstruction,
nature can't have any idea how the organism's
going to put it to use to take a ridiculous example
when nature was designing human beings that didn't design
ears so that they could keep masks, just didn't care.
And it probably didn't care that humans could use
language for communication.
That's the way things seem to be developing.
There is actually no, the only reason
to believe that language is used for communication, which
is a modern idea, incidentally, is
misinterpretations of evolution.
It somehow must have developed, you
know, language must develop out of animal systems,
communication systems.
Actually, no reason to believe that none.
And the evidence is overwhelmingly that it didn't.
There's nothing similar to the basic elements of language,
either the conceptual elements or the computational ones.
Nothing similar in the animal world.
Animal communication differs from human use of language
in radical ways.
And if the course of evolution was,
as I recently just suggested a few moments ago,
it's not going to have any connection
with animal communication.
Now there, I should say that there's
a kind of a baby talk, Darwinism,
which isn't evolutionary theory that
holds that any complex system must have developed
in very small steps from earlier ones.
I think Darwin himself believed that,
but that's been shown to be untrue.
There are many sharp changes in evolutionary history
from disruptions of one kind or another,
like eukaryotic cells or mutations and so on,
and many other things.
So are we saying that those who claim that language
is the result of a transformation of animal language,
animal communication?
Does that mean that they are bringing to the question
what I can only call an ideological bias
that language has to be the small increment development
of what looks similar in previous animals?
First of all, it doesn't look similar.
It looks radically different.
The most elementary features of language
have no analog whatsoever in the animal world.
And remember, our closest relatives,
the higher apes, are actually about 12 million years
separate from us in evolutionary time.
So throughout this, they've evolved.
Our common ancestors about six million years ago,
they've evolved, we've evolved.
It's impossible to teach with most intensive efforts.
It's impossible to teach the most elementary mimicry
of language, even to higher apes.
Every effort that's been tried has been a total failure.
It's just a common myth.
There's no evidence for it.
What about, I mean, there are claims
that animals of parrots and chimps
have a rudimentary number of words they understand.
You know, your namesake, Nim Chomsky, if I...
Nim, how do you interpret that?
It's also true of my dogs, they do better.
The Nim project was a very interesting project.
Very fine scientists involved,
number of them, close friends, former students, even.
They tried very hard to raise a chimp from infancy
about the way a human child is raised,
as close to it as they could come,
to work very hard, very seriously.
For a long time, they thought they were making progress.
Later, when they reviewed their evidence,
they were very careful.
They had a video record of everything that happened.
When that was analyzed, turned out that it was zero.
The ape was able to do things that made them think,
oh, he's asking for a banana.
But when they looked at it closely,
turned out that the ape was making random signs.
Maybe banana was in there,
want was in the bunch of other things were there,
but the investigators were interpreting it
as Nim wants a banana.
Nim was just producing signs,
which somehow got him what he wanted sometimes.
In fact, it turned out that even the most elementary concept
of an object was Nim could never learn.
He had a symbol for apple,
but for Nim, it meant an apple,
the place where an apple was,
something was near the apple,
anything associated with apple,
concept apple was impossible.
So, and this has been true.
There are a lot of claims about animal achievements,
but where investigators have been willing
to provide actual data, primary data,
there's nothing that can't find anything,
which is not very surprising.
It wouldn't be easy to teach us to behave like apes,
which is not ready to build for it.
We didn't evolve to it.
I know some people that would be probably pretty easy
to teach them how to behave like apes,
but that may be just a commentary on my friends.
Noem, you have brought into scientific thinking
the concept of deep structure.
I know that affected me many decades ago,
and I started thinking intellectually about the brain
and about the way everything is structured
and the concept of deep structure
you have embedded in intellectual content.
Now, you later modified that in terms of language,
in terms of minimalism.
We talked about that in the earlier parts,
but what I'd like you to do is just reflect
on the power of the deep structure paradigm
in many diverse fields from architecture, music, politics,
which I know you've had some association with,
certainly cognitive science,
this way of thinking of deep structure,
just want to get your sense of it.
It's a concept that is ubiquitous in the sciences.
So if you look at a, I suppose I drink a glass of water,
well, I have no idea what the components of it are.
There is an internal underlying structure.
There's hydrogen atoms, oxygen atoms,
lots of other things,
all put together in a complex form
with an underlying rich structure,
which I don't see.
You have to do complex.
It took centuries of serious investigation
to discover what the internal structure
of a water molecule is, okay?
That's deep structure.
All over the, we don't see the nature of things.
We see peripheral superficial aspects of them.
Language is the same.
We don't see its internal nature.
We see superficial aspects.
And deep structure happened to be a technical notion,
which had a specific meaning,
but the general idea that there is a hidden inner form,
internal structure, not visible to us,
but only can be discovered
through intensive inquiry and investigation.
That's a ubiquitous concept.
And it was understood in the study of language
in the 17th and 18th century.
It was forgotten.
But if you go back to the origins
of the scientific revolution,
Galileo or no, Descartes, others,
they recognized that there's a inner form to language
that we don't see.
Famous Fort Royal Grammar, 1660.
I don't know others.
It had something comparable to deep structure.
They didn't call it that.
And they didn't have the means at the time
to develop a computational theory
that came later.
For example, one of the examples in the Fort Royal Grammar
is the sentence, invisible God created the visible world.
And they argue that underlying this are three propositions.
God is invisible.
The world is visible.
God created the world.
And some kind of operations
turned these internal propositions
into invisible God created the visible world.
It's pretty similar to deep structure.
It's a great example.
The cognitive science revolution transformed,
really it's transformed our lives.
It certainly transformed understanding
how we think in the human sciences
and of course all the computer sciences.
Your work in linguistics is given credit
for at least in part triggering that revolution.
Why is that the case?
Well, first of all, I hate to be a contrarian all the time,
but my own view is that the real cognitive revolution
took place in the 17th century,
along with the rise of modern science.
It's been mostly forgotten, but there were real achievements.
Started mentioning some, there are many others.
I've done a fair amount of work on that.
The second cognitive revolution in the 1950s
developed actually mainly in Cambridge Mass
where I happened to be a grad student at the time.
If you look at what constituted it,
there were basically two things.
Jerry Fodor, late friend,
important cognitive science and philosopher
that once quipped that cognitive science
as the study of language and vision, not totally false.
Those are the fields that really developed
a lot of rich investigation
of how visual perception takes place,
a lot of study of the nature of language.
And it was all integrated.
We all know each other.
So Dave Maher is one of the founders of modern visual science.
We were friends and some of his work
was kind of modeled on some of the things
that were being done in language,
but a lot of integration.
So it's kind of understandable.
These are two topics that you sort of know how to study.
Other things are very hard to study,
like for example, the nature of concepts.
That's a tough one to try to figure out.
What is the nature of the concept,
tree, river, house, and so on?
Actually here the classical Greece had some answers,
which have been forgotten.
So Aristotle considered this question
in a different framework.
And his framework was metaphysical.
So not what's the meaning of house, but what is a house?
It was the cognitive revolution of the 17th century
that shifted that from metaphysics
to epistemology to cognition.
But in forgetting that, Aristotle asks what's a house?
He says it's a combination of matter and form.
The matter is the bricks, the timbers, and so on.
The form is the design, characteristic use,
the intention of the architect,
all sorts of mental things.
And that's quite correct.
Something could look like a house,
but not be a house at all.
It's used to store books, it's a library.
It's used to put forces in, it's a stable.
Could be a paperweight for a giant, you know?
What it actually is, you can't tell,
but it's physical character.
I think all the terms that are used for us
when we talk about the world, have that character.
What the thing is, is largely a mental construction.
And that brings us back to Lila Gleitman's crucial work.
All of these concepts must be basically innate,
or at least they're the elements
that constitute them must be innate
because a child acquires them on virtually no evidence.
Actually, one of Lila's favorite examples was a young child,
very early, says things like, that's not fair.
Try to analyze that.
Sean Rawls has a huge book on it,
Foundation of Modern Political Science,
just as his fairness.
The concept fair is extremely complex to describe,
but a young child has no trouble noticing
that things aren't fair.
Same with lots of other things.
When people talk about the history of modern computer science,
programming languages, compiler construction,
automata theory, many give your linguistic work credit
for the conceptual ideas behind those concepts.
What is it about your work in linguistics
that has enabled programming to be as accurate as it is?
I wouldn't.
That's much too strong.
I did work in finite automata theory,
which had certain relationships to early programming languages.
And there were mutual investigations,
cooperative investigations, looking at these contexts,
but it's basically forms of formal languages,
properties somewhat similar to natural languages.
I worked on them in the early 50s around the period
that programming languages were being developed
and that to interact in a number of ways.
So if you look at a textbook on programming,
you'll find things about sometimes called
the Chomsky hierarchy,
the hierarchy of possible formal languages,
which have various analogs in programming theory.
They capture some features of natural language,
but they also correspond to certain types of automata,
linear bounded automata, pushed down storage automata,
standard interrelate with formal systems
that capture some of the properties of language,
which is a topic of some interest,
but it didn't enable programming.
I want to mention some theories
of incognitive science and philosophy
that you have attacked.
I don't know of a softer word to accurately describe it
and want to just get your reflections on it.
After many decades of looking back,
first is behaviorism.
What was it about behaviorism that you found erroneous
and how do you reflect now looking back over the decades?
In my view, behaviorism was a radical departure
from the sciences.
First of all, behaviorism varied,
but the form of behaviorism that was pretty much dominant
in the period of creation of modern cognitive science
was largely skinnerian behaviorism.
It was picked up by Van Quine,
one of the most influential philosophers of language,
his work like Word and Object based very explicitly
on operant conditioning, skinnerian behaviorism.
And that was all the rage in Cambridge in the 1950s.
It was virtual dogma.
Skinners, William James Lectures came out in the late 40s.
The book itself, Herbal Behavior,
came out about a decade later,
but it was whatever it was doing.
Well, there were various chips in the armor
that began to develop.
Some of them were within psychology itself.
So George Miller, one of the founders
of cognitive psychology, a close friend,
worked closely with him for many years,
we published together.
Even before this started,
he did some crucial experiments
which raised serious questions.
So for example, take the sentence,
John went to the store from any sentence.
The standard theory of perception of speech was,
you have a certain guess about the first word,
then you have a guess about the second word,
the probability that you're right both times decreases,
of course, by the time you get to the last word,
should be very hard to understand in a long sentence.
Well, George showed that it's the opposite.
You don't understand the early words
until you get to the last word,
which means that you're forming the thought in your mind.
And the thought in your mind is telling you
what those early noises were.
By now, there's lots of work on this.
Well, that just didn't fit at all with behaviorism.
There was very important work in neuroscience
by Carl Lashley, his work on serial behavior around 1950.
It just totally undercut behaviorism,
showed that there are overall patterns in behavior
that simply just don't work anything
like the behaviorist model.
And nobody looked at that.
It was brought to, I found it in the early 50s
because it was brought to my attention
by an art historian, Harsh Pura.
You might be interested in this.
Looked at it, so totally wiped out behaviorism.
There was other work going on in European,
what was called ethology, comparative biology,
the Lawrence, Tinberg, and others,
which was foreign to the environment
in which cognitive science grew up.
But the main thing was the work on language
that I and others started doing in the early 50s
was completely inconsistent with all behaviorist assumptions.
And there was just no connection between them.
You couldn't relate them.
And then when Skinner's book appeared,
you could read through it and you could see
that it's all hand waving, there's nothing there.
Instantly around that time,
even within the behaviorist framework,
there were cracks developing.
So there was work by some of Skinner's students,
incidentally important work,
which showed that animals just didn't behave
by these pattern paradigms,
that they seemed to be working only
if you picked experimental conditions
that essentially adapted instinctive behavior.
So you can teach a pigeon to play ping-pong
because pigeons peck, so you can modify the pecking behavior.
But basically it was all falling apart
from many points of view.
And my own view as it was a bad mistake
from the first place.
You don't study any subject by saying,
let's keep to the superficial manifestations
and not look at what's going on internally.
You wanna understand it,
you're gonna have to look at what's going on internally.
You don't see it, you can't do experiments right on it.
You have to study it in indirect ways.
The way physics, chemistry, biology,
every other subject to go.
Linguistic relativity, the so-called Worf hypothesis
where language determines thought in the strong version
or at least influences thought in the weak version,
that the structure of a language
affects the speaker's worldview or cognition.
And therefore when people have different languages,
their perceptions are related to the languages they speak
as opposed to a broad human capability.
That hypothesis, the superior Worf hypothesis
has been around for 80 or so years.
Investigation of its series investigation
began in the early 50s.
First person to study it was Eric Leneberg.
We were grad students together, personal friend.
He went on to found biology of language.
But his first work was actually as a student
on the Worf hypothesis, experimental work.
Couldn't find anything.
Everything you tried,
you got some superficial results, but nothing.
Well, it's now 75 years later.
There isn't a lot more to say.
There's some evidence.
Some of the Lila Gleitman who I mentioned before,
carefully analyzed and did experimental work
on some of the alleged evidence that fell apart.
There's a few things around that seem possible,
but the pickings are very slim.
There's some respects in which it's obviously true.
So as Leneberg pointed out, 75 you found 75 years ago,
if you study a language that we have a distinction
between red and orange and pink, say,
but their languages that don't,
they haven't been setting hope.
He just uses the same word for that spectrum.
So he found, perfectly predictably,
that if you use, say, memory texts, tests,
did you ever see this shade of color a minute ago?
You'll do better if you have names.
So in a way, the language affects perception,
but in such a trivial way that it's of no interest.
And there isn't much more than that.
Logical positivism, which was the rage
in the early 20th century that said
that really there are only two kinds of truths
and even only two kinds of intellectual activities
worth pursuing, those that are empirical
or the scientific method,
and those that are purely logical with a deduction.
Everything else is basically non-stets.
Well, logical positivism was an important movement
in the 20s, early 30s.
By the late 30s, its major figures were drifting away from it.
Karnap, Temple, others, Quine,
just moving away from it.
And it became influential in linguistics and psychology
after it was declining philosophy
and declining for good reasons.
There were internal critiques,
but it did have a big influence on linguistics
through Leonard Bloomfield,
who was a strict, saw himself as a strict,
he was the major linguist in the early 20th century.
He did very good work in many areas,
but in this area, he was very much misled
by picking up an early form of logical positivism,
which was not viable.
But so I think it's an important,
made important contributions, important residue,
developed since in other directions.
So if you look at Quine, Hopper, Karnap,
major figures, Wittgenstein was one of the,
totally rejected, then it just,
it's no longer a coherent viable movement.
What is your view of contemporary field
or subfield of philosophy of language,
which subsumes a great deal of what we're talking about
and even more than that?
And what are the categories?
What are your reflections on it?
Well, I've been a pretty sharp critic of it
in book after book, I don't wanna go through that.
I mean, there is important work,
but a lot of it I think is seriously misguided.
I could go into details if I've written about it.
So for example, take, say, Quine,
who was the Quine and Wittgenstein
to the leading figures of modern philosophy of language.
Both of them accepted for Quine,
who was a strict Schenarian.
Language in his words is a complex of dispositions
to respond to present stimuli.
There's nothing to do with language.
I mean, and it didn't develop that way,
it's not used that way.
Wittgenstein, the late Wittgenstein,
who was interested in language,
it was kind of aphoristic, you know,
and give a try to give a organized system.
But if you look at his comments on acquisition of language,
they're strict behaviorist, you know,
his language games, somebody is shown a rock
and somebody says rock and imitate it.
That's how you learned rock.
Nothing like that happens.
I mean, there's tons of experimental evidence by now,
even just observational evidence.
And I think, well, there are countless major contributions
as some of the, a lot of the work,
I think is off on the wrong track.
So the main contributions I think have been in semantics.
Donald Davidson's work on event semantics
has turned out to be very productive and influential.
It was picked up by Blank linguists, philosophers,
James Higginbotham, Paul Trotsky, others,
and turned into, my view, one of the most promising approaches
to the general semantics of language.
It's called philosophy.
I don't know why it's called philosophy.
It's basically a good, serious study
of the semantics of natural language.
Analytics philosophy versus continental philosophy.
You're classified as an analytic philosopher.
You've had some engagements
with the continental philosophers famously.
What is your reflection on the dichotomy between them,
the artificial, how do you see going forward?
Well, actually a good deal of my work
is on continental philosophy
from the 17th through the 19th century.
Decorium lock onto the philosophers of Humboldt,
on through the 19th century.
Contemporary continental philosophy is quite different.
This work that I find interesting,
most are all a number of others,
but most of the modern work either I don't understand it
or I don't find it very interesting.
My own background is in what's called analytic philosophy,
though I was, as I've just mentioned,
I've been rather critical of a lot of the ways it's developed,
but I think basically on the way to finding serious
understanding of the way the mind works,
the way the world works.
What I'd like to do now, Noam,
and I've really been looking forward to this,
is to get your quick sense of some of the big questions
that we ask on Close to the Truth,
the themes that are kind of the core of our work
over two decades now.
And we've asked these questions
to all leading scientists,
maybe physicists, philosophers, neuroscientists, et cetera,
and just want to get your sense.
So we'll start with philosophy of mind,
which is a very broad category,
but from your point of view,
what have been the major issues
or the problems in philosophy of mind
and where have you staked your own personal claims?
I don't know how to distinguish philosophy of mind
from science of mind.
The science and philosophy
were pretty much the same field until the 19th century.
Then the names diverged, but not in a serious way.
So the most serious work in cognitive science,
in my view, is a development of a suggestion
by clock John Locke in the wake of Isaac Newton's discoveries
who showed that the mechanical conception
of the nature of the world that was developed
in modern science just didn't work.
So Locke concluded, he phrased it in his theological framework,
I'll drop that, but just as the material world
has properties that we cannot comprehend,
but that are there like interaction without contact,
so the mind might just be,
might let me take it in his theological framework
because it sounds better just as God provided matter
with properties that we cannot understand
like interaction without contact.
So God might have super added to matter,
the certain forms of matter, the property of thought,
meaning thought is a property
of some organized form of matter,
whatever matter turns out to be.
That's a fundamental insight.
And it was developed carefully through the 19th, 18th century
by major figures, it culminated in Joseph Priestley's work,
famous chemist, philosopher distinction
wasn't made in those days.
Then it was pretty much forgotten.
It was rediscovered in the latter decades
of the 20th century, was then considered
a radical new idea in philosophy,
astonishing hypothesis, new thesis in biology,
actually Locke's suggestion on the work that was done on it.
So that's a core part of philosophy of mine, I think,
finding out what it is in the structure of the world,
whatever the world is constituted of
that has this property of thought.
Well, that's the kind of thing we were talking about before.
And there are many mysteries there.
One of them by mystery, I mean,
things in which there's been no progress for millennia.
One question is what we were talking about,
the nature of concepts, where to come from,
how do people acquire it?
Another one is simply what was crucial for Descartes,
the fact that our ordinary use of language
is constantly innovative,
new things that were never said before,
they're not random, they're appropriate to situations,
not caused by situations.
Some, I've called it the creative aspect of language use,
total mystery, nobody knows where that comes from.
Actually, nobody knows anything about voluntary action,
but this is a complex case of it.
So that's another major problem.
There are other problems about, you can go on,
problems about what constitutes thought,
what the animals do, how's human thought different
from the cognition of other organisms.
These are mixtures of philosophy and science,
which I don't think divide very clearly.
Philosophers are studying some of the more general aspects
of what the science is doing.
And plenty of people just cross the boundaries.
Don't pay any attention.
Are you committed to a purely materialistic,
physicalism approach to anything having to do with the mind?
Another way to put it is,
what is the ontological status of the mental?
To be contrary, and again,
I've always taken exactly the opposite position.
And my, as I've argued at some length,
there was a concept of matter
in the early scientific revolution.
It's called the mechanical philosophy.
The world is a complex machine,
a much more complex and intricate version
of what skilled artisans were developing
all around Europe at the time.
The world is just a far more complex variant of that.
Now that was held right through
the major part of early modern science.
Galileo, Descartes, Newton, Leibniz, Huygens,
all the great scientists assumed this.
Newton disproved it.
He showed that the world is not a machine in a sense.
He didn't believe it.
He thought it was the most so absurd
nobody with any scientific understanding
could possibly believe this.
Now that's why he called his major book,
Mathematical Principles, not physical principles.
He said, I don't have a physical theory.
All I have is mathematical principles that seem to work.
He was sharply condemned for by Leibniz
for the great figures.
Well, at that point, the concept of matter disappeared.
Matter is just whatever we postulate
in our best theories of the world.
That's no bounds.
If it turns out to be massless particles,
okay, it's massless particles,
turns out to, whatever it turns out to be,
that's what it is.
But there's no fixed notion
of the material or the physical.
Some philosophers try to hang on to it.
They say, well, maybe the physical is spatio-temporal.
Now we're back to Locke's suggestion.
My thinking does not take place in my feet.
It doesn't take place in a tree outside.
It takes place up here.
So it's spatio-temporally contained.
So therefore, all of mine is physical.
Since the word essentially has no meaning,
just whatever our best theory say,
you can say that if you want.
But I think the question's just disappeared.
There is no coherent notion of materialism
as far as I can see.
It's just whatever the science has come up with
as their best explanations, that's materialism.
The trend in philosophy of mine in the last decades
has been moving away from what is classically
called materialism, that everything mental
can be reduced in some way in some future science,
maybe not for a thousand years,
to physical processes in the brain,
whether it's at the neuronal level
or the internal neuronal level
or the quantum physical level,
but still physical within the brain.
And so many philosophers today are moving away from that
and say that we'll never be able to explain
the quality of the inner experience that we all have
and that you need to go beyond
what is traditionally called physicalism,
whether it's panpsychism,
where everything has a little bit of mental capacity
or some kind of dualism
where there's a non-physical reality interacting,
but there has been a trend in that direction
that purely physical explanation of the brain
will never fully explain the mental.
Well, the problem with that is there is no notion of physical.
Actually, this was put very well by fine psychologist,
Gell and Strossen, who does commit a depend psychism.
Yes.
But he was talking about consciousness.
He said there's no problem about consciousness.
We all know exactly what it is.
Consciousness is what I'm experiencing now.
The problem is with the physical.
When you talk about reducing consciousness to physical,
you know what physical is?
Physical is just whatever the sciences say.
So consciousness is gonna be part of it.
Actually, it goes back to Russell pretty much.
And I think that's correct.
There is no physicalism.
So whatever is going on in my mind
and your mind is in your brains.
It's not going on somewhere else.
Well, the brains are,
if the brain isn't a physical object,
I don't know what is.
So therefore, it's going on in your brain.
It's some sort of process going on in there,
not anywhere else.
The rest is just idle talk.
But Gell and Strossen, who's a very good example
and people can see his videos on Closer to Truth.
He's a good friend.
He would say that you need to have some deeper understanding
of the nature of all physical properties
in order to understand how the brain can generate,
in some way, the concept of consciousness.
You put in the word physical.
You have to, as I understand his views,
which I think I agree with,
you have to have an understanding
of the nature of the world
in order to find how the mind functions.
Because the mind is just part of the world
as Locke famously should be famously,
unfortunately he's forgotten.
But as he pointed out,
there's no reason not to regard thinking
as a property of organized matter,
whatever matter turns out to be.
We don't know what it's going to turn out to be.
Sure.
I think that is an approach
that there's an expanded understanding
of what reality is that we call matter and something else.
But whatever it is,
that's the total reality of the world.
And there may be things
that we totally don't understand that now,
whether it's panpsychism or something else.
I don't go along with Strawson
as far as he does to the panpsychism.
His argument for panpsychism is based on a serious point.
Can there be what he calls radically emergence?
Entirely new properties,
somehow developing without any elements
of them in earlier structures.
I think that happens all the time.
There's nothing in the hydrogen atom,
which says your liquid changes take place
with other levels of complexity increasing
that bring about entirely new phenomena.
So that's a strong argument.
The critical mass of an atomic bomb is a good example
where you have uranium-235,
a certain purity of it,
and it'll be inert, it'll be radioactive,
but you add one more microgram
and then you have an atomic bomb
because it hits that critical mass.
It's a simple analogy, but.
It's just that everything in nature is like that.
Back to eukaryotic cells,
or water.
Water aren't detectable in hydrogen and oxygen.
But this is a critical point,
and I'm gonna push it a little bit further,
because with hydrogen and oxygen,
we can understand how,
when you understand the science of bonding and flow
and molecules slipping by one another,
that with advanced science,
you can, in fact, predict or reverse engineer
from when you know the structure
to why that becomes wet, liquid.
Now the question is,
is everything about the mind of that same character
where eventually science,
given as much time as you want, 10,000 years,
be able to access it?
Or are there aspects of the mental
that are forever beyond the purview of science?
No more than aspects of motion.
Go back to Newton and Leibniz.
They recognize,
they had no problem understanding Newton's theories
of gravity.
It was what they described that was unintelligible.
We cannot conceive, as Locke said,
we cannot conceive of objects interacting
in a mechanical fashion.
And we can't, it's a fact.
Science just gave up the task of trying to.
Galileo through Newton and Leibniz,
science was trying to develop
a picture of an intelligible world.
That was given up.
We don't try to do that anymore.
We try to find intelligible theories of the world,
like Newton's theory,
or the theory of hell,
hydrogen-axing molecules yield water,
but it's unintelligible.
We can't, we have no grasp of what's going on there.
We understand the theory,
we can follow it, as you say, we predicted.
That's now the goal of science for hundreds of years,
since basically since Newton,
which abandoned the Galilean hope
of developing an intelligible world.
So can you do that for the mind?
No reason why.
Maybe we can't, maybe we don't have
the intellectual capacity to do it,
but that doesn't mean there's no explanation for it.
I mean, we're not angels, we're organisms.
Our mental capacities have certain scope, certain limits,
but no reason to believe that we can understand everything.
So in the philosophy of science,
would you classify yourself as an anti-realist
in the sense that we have access to empirical information,
we can sense regularities,
but there's really no hope of understanding reality
as it is qua-reality in itself?
No, I don't.
We can understand it to the extent
that humans are capable of understanding things.
We're, I don't know about you,
but I have no grasp of,
I can follow the theory that explains how hydrogen
and oxygen end up feeling like a liquid,
but I don't have any grasp of it.
I can follow the theory, okay?
And that's the way science works.
I have no grasp of it, field of force, let's say.
I understand it can work with vector spaces and so on,
but that doesn't give me what Tom Nagel
calls a feeling of what it is.
We don't have a feeling of that about anything,
but we can do the best we can to try to find theories
that explain the properties that we discovered.
Now we can understand the theories, maybe get better ones.
Can we get good enough ones to explain,
say elements of consciousness?
You never know.
You can, you know, as you learn and study more,
you find more, then you find more problems.
Not science, it's like hill climbing.
You climb a hill, you think you've gotten somewhere,
you look up and there's a big hill.
It's all the whole history of science.
No, one of the questions we'd love to ask
on Close to the Truth is a two word question,
two word sentence, what exists?
And by that, what we mean are,
what are the minimum number of non-reducible categories
that you need to explain all of reality?
Science has its own answers, partial answers.
So they might say elementary particles.
Then you pick up a quantum theory journal,
and you find a symposium of great scientists
about what is a particle, all kinds of views.
Basically, we know some things about it,
but we really don't know what a particle is.
Okay, so you go on to the next step.
I don't think these are questions that can have answers.
So they have answers, but only answers
that you move towards as you learn more.
How far you'll go is never any way to know.
Along the way, you cast aside problems
as ones we can't deal with.
The way science afternoon cast aside the problem of motion.
You go back to the 17th century,
they had a concept of hard problem.
Today, the fashion is to say
that the hard problem is consciousness.
17th century, what they called the hard problem was motion.
Problem was never solved, it was abandoned.
And then the last question,
which in one sense is the very first question
that we'd love to ask is,
why is there something rather than nothing?
Why is there anything at all?
And the question I wanna ask you,
is that a legitimate question to ask?
Because we ask it, but one of the claims is that
that's not a question that you should be able to ask.
Well, the best answer to that that I heard
was by a great philosopher, personal friend,
you know, Sidney Morgan Besser.
Sid was asked that once and he said,
look, if there was nothing, you'd be fetching about that.
Convectioning in terms of our common answers,
this means complaining.
I learned that from my grandmother.
No, and this has been an absolute delight.
I wish we could go on forever.
You have made such contributions,
not just to linguistics,
but to ways of thinking,
challenging us in linguistics,
certainly in political science,
even if some of us may disagree
with some of the things that you say in all categories,
you've had a tremendous contribution to intellectual thought,
to the enjoyment and the appreciation of reality
over these seven decades for you,
certainly my entire lifetime on a personal basis.
It's great to experience this real interaction with you.
Now, as I said, we met at MIT very briefly 40 years ago.
So it's just a great pleasure for me.
And I look forward to another session,
70 or so years from now.
We'll discuss some of the same things
and see how you've progressed over that time.
We'll have the same mysteries, I think.
All the best, all the best.
Thank you.
Good to be with you.
