What should you do if you're spending too much time on social media, asking for a friend?
Well, you try to convince yourself that social media is actually good for, well,
something. It's gotta be good for something, right? But they say that social media increases
polarization and gets you stuck in echo chambers full of fake news and so on.
How bad is social media? That's what we'll talk about today.
Social media has changed society profoundly. About 60% of the world's population now uses
social media. It has made it vastly easier to find people all over the globe to connect with them
and to get insulted by them. What does that do to society? It's complicated. American social
psychologists Jonathan Haidt and sociologist Chris Bayer have compiled a public Google doc
in which they collect references on questions such as, does social media make people angrier?
And does social media create political echo chambers? The most relevant thing you'll learn
from this document is that whatever your opinion, you can find a paper that supports it.
Honestly, I began working on this video thinking it'll end up being one big shrug,
because that's how sociology generally looks like to a physicist. But it turns out it isn't
quite as bad. You just have to be really careful with phrasing the question. For example, you may
remember the headlines claiming that fake news spreads faster than the truth. Then again,
there were headlines saying that those headlines about fake news were themselves fake news.
What is going on? Well, the original headlines were based on a 2018 paper published in Science
by researchers at MIT. The authors compared how true and false news stories spread on Twitter.
They had a sample of about 126,000 news items from 2006 to 2017,
tweeted by about 3 million people over 4.5 million times. So, not a small study.
These news items were classified as true or false according to certain fact-tracking organizations.
The conclusion of the study was, in the authors' own words, that
falsehood diffused significantly farther, faster, deeper and more broadly than the truth
in all categories. The facts were most pronounced for false political news.
And it wasn't a small difference. They found that it took two stories approximately six
times as long as false stories to reach 1,500 people. But in 2021, other researchers pointed
out that the 2018 paper looked at news that had been fact-checked by certain organizations,
but that those organizations pay more attention to news that have already spread quite successfully.
An article in Science then claimed that this means the original study had been debunked.
This is why you've seen the headlines saying news about fake news is fake news.
That wasn't the end of the story. Because the authors of the original study then said
they'd never claimed their study applies to all fake news, it had just been misreported.
And the authors of the new study said they had never claimed the earlier study was wrong
because they knew it had been misreported. Then the author of the Science News article
who had claimed that the misreported fake news study was fake news,
apologized that his article had misreported this story. I hope that clarifies it.
But wait, what does all of that mean now? Do fake news spread better or do they not?
The answer is they do, but it turns out that the major difference between true news and
fake news is that fake news spread to a larger audience. And since they appear to a larger
audience, they also spread faster. But if you compare true and false stories that have reached
an audience of the same size, then the sharing pattern looks the same. This was the point of
the 2021 paper. It's not like fake news networks have a different connectivity.
The size of the audience that they attract is the major difference.
And yes, that was strictly speaking only demonstrated for fake news stories that were
fact-checked by certain organizations. One of the authors made this diagram to show the difference
between what they said they did and what the headlines said they did. But the authors also
say they're reasonably confident their finding will carry over to false news more generally,
but that remains to be seen. I'm guessing there are people working on this as we speak.
But the 2018 science paper made an interesting point that didn't spread widely. They found that
bots accelerated the spread of true and false news equally. This means that if false news spreads
better than the truth, that's because humans are more likely to spread false news. We can't
blame it on the bots. The authors conjecture that the reason may be that people like novelty and
it's easier to be original with something that's made up. Anecdotal evidence. I had my first encounter
with fake news on Facebook in 2016 when Trump ran for president. It was a quote attributed to Trump
from some anti-Republican Facebook page shared by an American friend. Several people pointed
out that there was no evidence Trump actually said that. The guy who shared it reacted by saying
it's funny even if it isn't true. And that's why false news spreads. We share it for reasons
other than accuracy, because it's funny or upsetting or because it allows us to express our
opinion. Whether it's true doesn't really matter for that. The problem is that the next person
who comes across shared fake news believes that the person who shared it believed it to be true
and is therefore more likely to also believe it to be true. What can be done about it?
It's easier than you think, because most people agree that fake news is bad and they're actually
quite good at spotting it. You just have to occasionally remind them to think before sharing.
At least this was the conclusion of a paper published in Nature last year.
The authors recruited about a thousand Americans and presented them with 36 actual news stories
taken from social media. Half of the headlines were false and half were correct. Half favourable to
Democrats and the other half favourable to Republicans. The participants were then asked
to evaluate the accuracy of the news items. They quite reliably rated correct headlines as correct
and false ones as false. And while they did rate headlines in favour of their own political
orientation as correct more often than those in favour of the other camp, the partisan influence
was much smaller than that of the actual accuracy of the headline. So the problem is not that we're
just bad at spotting bad news. But the authors also found that whether the headlines were right
or wrong had little effect on whether people intended to share a news item. They then encouraged
people to consider the accuracy of the news item and afterwards asked again how likely they'd share
it. This simple tactic led to a big reduction of the intention to share false news but didn't
affect the intention to share real news. According to the paper, accuracy often has little effect
on sharing because the social media context focuses users' attention on other factors,
such as the desire to attract and please followers and friends or to signal one's group membership.
According to another paper that just appeared two months ago, the misinformation problem is
particularly pronounced in the United States. The authors of the paper found that while people
from the UK, Canada, Australia and New Zealand are exposed to misinformation on social media
at about the same rate, Americans are three times more likely to share it. Earlier this year,
a review paper in the journal Nature Medicine looked at the spread of misinformation about
public health in particular by reviewing 123 papers. The two major conclusions that the
author draws from his literature survey is that A, people are sometimes duped by misinformation
just because they are distracted or not paying attention and B, some people believe in and
share misinformation because it reinforces their beliefs. So that's consistent with what the other
papers had found. As to what to do about it, one thing he suggests is also just reminding people
to think about accuracy before sharing. Another interesting suggestion he has is to give people
information about the tactics of misinformation spreaders with browser games. There are two of
those games, one is called Go Viral and the other one Get Bad News. Studies have found that people
who played these games were much better at spotting health-related misinformation.
You can try them out yourself, links are in the info below. I think this is a really good idea
and I'd like to have a game like this about physics please. So yes, social media spreads a
lot of misinformation. The good side of social media is that it also seems to generally benefit
information literacy. In 2018, a team of American researchers recruited almost 3,000 Americans.
They offered half of them $20 to deactivate their Facebook accounts for four weeks,
just prior to the 2018 midterm elections. Four weeks later, those who disconnected from Facebook
were less able to correctly answer factual questions about recent news events. But they also
reported increased well-being and less political polarization. Let's therefore look at what we
know about polarization and echo chambers. If you watch a few of my videos on quantum mechanics,
soon all your recommended videos will be about quantum mechanics. Suddenly, the whole world
is quantum mechanics. Such an echo chamber seems to be an inevitable side effect of algorithms
that want to help you find what you're interested in. And as a result, you get more of the same.
This leads to the dreaded conspiracy rabbit holes that you fall into on YouTube as it happened to
me when I was working on my video on flat earthers, though YouTube seems to have tweaked their
algorithm since to prevent that from happening quite as easily. These more of the same algorithms
help you make contact with people who think like yourself. So the idea that we live in echo chamber
sounds plausible. But plausible ideas are the ones you should be most skeptical about. What does the
data say? According to a 2021 paper by a group from the University of Oxford, echo chamber issues
are real, but the problem's been hugely overstated. They looked at surveys from seven different
countries in which people reported what news they typically consumed. Turns out, only about
5% of social media users are properly stuck in a political echo chamber in which they almost
exclusively consume news from one political side. Though the numbers differ somewhat by country,
the overall largest fraction of people in echo chambers is that of the American left.
The previously mentioned Chris Bale is lead author of a 2018 paper about an experiment
in which they try to get people out of their echo chambers. They surveyed about 1,500 Americans,
about half Democrats and the other half Republicans, who visited Twitter at least three times each
week. After one week of tracking, a randomly selected group of those people was offered
$11 to follow a Twitter bot for one month, but they were not informed about the purpose of the
study. The bot initially just tweeted landscape pictures, but then began tweeting opinions that
promoted the participants' opposing political ideology. At the end of the month, the participants
were surveyed again. Turned out that Republicans who followed a liberal Twitter bot became even
more conservative. The more they were exposed, the larger the effect. For Democrats,
the change was not statistically significant. By the way, Chris Bale is the director of an
institute called the Polarization Lab that lets you check how deeply stuck in an echo chamber you
are on Twitter. Turns out, rather unsurprisingly, I'm deeply stuck in a liberal camp. That's
what you get when you mostly follow people with PhDs. The question whether social media
increases polarization in society has been extensively studied, especially in the United
States. The risk, sociologists say, is that social media makes it easier to find people
whose opinions we like and we get encouraged by like-minded people to distance ourselves from
the perceived enemy. Indeed, in 2018, a leaked internal presentation at Facebook warned senior
executives that Facebook algorithms exploit the human brain's attraction to divisiveness
and that if left unchecked, the algorithm would feed users more and more divisive content in an
effort to gain user attention and increase time on the platform. Now, it's quite well established
among sociologists already that increased levels of polarization in society are associated with an
erosion of constructive political debate, social trust and interparty cooperation. The question
we're interested in here is whether social media increases this polarization. In 2021,
researchers from the UK and the US set out to answer the question whether out-group animosity
drives engagement on social media. They analyzed almost 3 million Twitter posts by news media
accounts and US congressional members. They found that posts about the political out-group
were shared or retweeted about twice as often as posts about the in-group. And almost all of the
posts about the other political camp were negative, leading to more negative engagement.
Again, though, you have to be really careful to keep in mind what question a study was asking in
the first place. Because this finding doesn't necessarily mean that the negative engagement
caused polarization to increase, it might just mean that social media is a good platform to live
out your feelings. Just which way the causation goes is at the moment rather unclear. For one thing,
a study from 2017 found that self-reported polarization is higher among elderly Americans
who are less likely to be online to begin with. Another thing to keep in mind is that the USA
isn't the only country in the world. A team of American researchers pointed out last year
that while social media usage has increased worldwide, polarization has not. It has increased
in the US, but in many other countries, polarization has in fact decreased. Indeed,
a 2021 study among more than 3,000 Dutch citizens found that self-reported polarization
correlates with social media use, but the causation goes from polarization to social
media use, and it depends on the platform you're using. At least in the Dutch sample,
people who became politically more polarized spent more time on Facebook, but less time on Twitter.
It's hard to interpret what this means, because God knows what's up with Dutch Twitter. But I
think what we can take away from this is that the idea that more social media use increases
polarization is almost certainly too simple to be correct. What happens depends both on cultural
context and on platform design. So what do we learn from all this? Most obviously,
we learn that this is a very active research area. I certainly hope that the results will
eventually lead to better algorithms for social media. While we wait for that to happen, I think
the best we can do is focus on the part that's in our hands, which is to decide what we pay attention
to and what we share. What I have taken away from all those papers is that we have to be especially
careful with headlines that upset us. Yes, they might get a lot of comments, but they might also
spread misinformation and hate. So be careful out there. How is Sabina talking about nuclear power
one day and about social media the other day? Is she omniscient? I'm afraid the answer is no.
I work with several other people who helped me sort through the scientific literature
to bring the information to you. And the only reason this works is thanks to our sponsors.
Today's episode was made possible by MelScience, which is a subscription service for science
experiments. And I have to say, my family is having a lot of fun with their products.
MelScience has experiments for children in different age categories and different scientific
disciplines. And not only this, their experiments come together with AR in VR lessons and
live online classes. The experiment I got this week is a gyroscope labeled for children aged five
and up. It's a great opportunity to talk about color perception and the preservation of angular
momentum and the solar system and why we always see the same side of the moon and why the length
of the day depends on which way the wind blows. And well, I guess I got a little carried away there.
I found the MelScience experiments extremely well designed and also high quality products.
This is not cheap stuff that breaks when you touch it. It works like you expect it to work.
And of course, we do have a special offer for viewers of this channel. You can get 50% off the
first month for any MelScience subscription if you use our link in the info below or scan the QR
code. So go check it out. Thanks for watching. See you next week.
