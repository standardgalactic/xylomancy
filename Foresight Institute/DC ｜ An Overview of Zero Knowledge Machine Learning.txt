Hi, Vern. Welcome to FOSAT's Intelligent Cooperation Group.
We're really excited about this seminar.
We have DC here from Wolfkind.
Thank you so much for joining us to give an overview of ZKML,
which is a topic that has come up so much,
especially, I guess, the data coming up
already a few years ago in this group,
and then much, much more to have really ramping up
in the last year.
And so I'm really excited for you to share a little bit more
about it because we have not had a dedicated seminar
to this topic yet.
So thanks a lot for joining.
We're really excited about you guys' work.
And without further ado, please take it away.
I'll be in the chat, monitoring questions,
and we're off to the races.
Awesome. Thank you for having me.
So today, I'll be talking about the zero-knowledge machine
learning.
I'll be giving a very brief introduction.
But first, maybe let me start by saying a little bit
about myself.
I'm a research engineer at the World Coin Foundation,
and World Coin is this project that
is trying to build the largest identity and financial network.
And there is an interplay of various technologies
in the products and things that we're building at World Coin,
and some of which are AI, and some of which
are cryptography.
So we've had expertise in both realms
from different teams internally.
And there have been some essentially experimentation
that naturally occurred.
We have some AI parts of the stack,
and there are some reasons why cryptography might
be useful in the AI side of the stack.
And so this prompted us to think about this topic
about two years ago in August, almost two years ago,
August of 2022, when one of my teammates
was just playing around with cryptography
and trying to prove machine learning models.
But so this is a little bit of a background.
I mostly run our grants program, where
we give grants to people to help decentralize World Coin
and solve some more problems, and also help
with a bunch of different R&D efforts
as an individual contribute.
So without further ado, let me start with the presentation.
Usually the way that I like to start with this presentation
is that I like to decompose the statement into its constituents
so that people have an understanding of which elements
or what is zero-knowledge machine learning?
What is the zero-knowledge part?
What is the machine learning part?
I like to decompose it into its fundamental compositions,
so the competition.
And the first one that I want to talk about
is zero-knowledge cryptography, or called zero-knowledge.
I don't know if many of you understand the reference that
or get the reference that I put here, which is Waldo,
finding Waldo.
Waldo essentially is a character or one specific analogy,
which is very easy or very friendly
to explain what zero-knowledge cryptography is
to people who have never heard about it,
because there is this essentially like poster
that many people know where there's just lots of characters
which are in the city, and there's one Waldo,
and it takes some amount of time to essentially find the Waldo,
and that's like the challenge of these specific games.
And so there is one specific analogy
which allows people to explain what zero-knowledge is,
which is that if I put a bigger like white paper
on top of the poster, defining Waldo game,
and if I put a little tiny cutout for the head of Waldo,
and I place the cutout just on top of Waldo's head,
but covering the entire game itself or the poster itself,
then I'm able to prove to anyone that I know where Waldo is
without revealing his location within the poster.
So this is like the good analogy
for explaining what zero-knowledge cryptography is,
because I'm able to prove things that I know
to someone else, to an outside observer,
without them learning everything
about the things I'm making a proof of.
I can selectively prove specific statements
because I have information,
but I don't have to reveal everything
in order to be able to prove that statement.
So this is like a good analogy to explain the game.
So some of the properties that zero-knowledge cryptography has.
So the first one, which I think is the most important one,
especially in the context of blockchain,
I saw that many of you were like in previous presentations
of this specific group.
I saw that there's a few crypto people
that were talking about different things.
I'm sure that came along a few times.
So succinct list essentially just means
that in order to verify a proof of a statement,
it's a lot less computationally expensive
or a lot less expensive
than to actually prove the computation
or to just perform the computation yourself, right?
So essentially verifying that I know where Waldo is,
as an outside observer,
it's a lot easier than me finding Waldo myself.
So this is really important in the context of blockchains
because for example, for scalability solutions,
instead of everyone having to re-execute
the same transactions in a block,
I can just verify a proof
and I can just update my state
without having to secure it myself, for example.
So this property is important for the kid
because it allows us to very easily,
computationally easily verify things
without having to do computation ourselves.
This is a really important property.
The second one, arguably the one that is most known for
is correctness.
So correctness essentially means
that I can have almost 100% certainty
that this statement that I'm proving is correct, right?
That I cannot lie.
There is no way that I as a prover
can lie to a verifier
unless if the cryptography is sound in this case.
There's two specific properties
that constitute correctness.
One is soundness.
So soundness means that I, if I'm a prover,
someone making this claim, someone making a statement,
I'm not able to fool a verifier with invalid proof.
And completeness is another property
where I'm not essentially able to create a valid proof
unless I know the truth.
If I don't know the truth,
I cannot make a valid proof as a prover.
And the third one, which is name after, zero knowledge,
is this property where I can hide parts of the statement.
For example, let's say that I have,
I don't know, this is a good example.
Let's say I have my passport.
So I have my name, my nationality, my date of birth,
where I'm from, which country I was born in,
for example, the place of birth.
So something that would be useful
or like something that would constitute a zero knowledge proof
is that I can make the statement
that my age is over 18 years old
without revealing to anyone my age,
but anyone can just verify that I'm actually over 18.
The way that this is actually implemented
is that within a zero knowledge proof,
I can verify a signature from some issuing body
like a government.
And then I can make a statement that like A,
this age, which was attested to
or essentially committed to by a government is over 18
and you don't learn my age.
So this is the zero knowledge part
where I'm able to hide parts of the state
that I'm making a statement about or proof about
according to some constraint or some statement, right?
Like I can say greater than, less than,
equal to a bunch of other properties that I think can put.
So the second part of the statement
of zero knowledge machine learning,
this machine learning, right?
I think that one is much more familiar to most of you
since it's been generating such a buzz everywhere,
like machine learning through a generative AI,
like in things like ChagYPT or Dali
or a lot of generative AI models
or natural language processing, categorizing models,
like robots, the machine learning essentially,
the way that I think about it is that it's a tool
that allows us to give us not the non-deterministic solutions
or just estimates for short,
for problems that don't really have a concrete solution,
right?
Usually there's some problems
which we can solve algorithmically
and we can just have a set of steps
that we can just execute in order to solve it
and we will have a perfect solution every time.
In the case of machine learning, however,
most of the problems that are being solved
by machine learning are not such problems.
Therefore, we need to,
because maybe like the space of solutions is too big
or the space of the steps that we can take is too big,
so it's really hard to navigate deterministically,
then we just have this sort of juristic.
A juristic essentially is a good enough approximation
to the real solution which we can work with
and which has some form of accuracy, right?
So in the context of machine learning,
we have some sort of juristic for some problems.
So let's say I want to categorize
whether an image that I see is the image of a dog or a cat.
This, I can train a machine learning model
to essentially solve this task,
but the machine learning model will never be 100% correct.
It will have some accuracy, right?
It will have some that will fail on,
it will have, most of them it will get correct.
But essentially the way that the machine learning model works
is that it trains on some data.
So I feed some data to some model
or to some machine learning algorithm and it gets better.
And this juristic keeps getting better and better
for things that it hasn't seen before.
It generalizes over the data
and it's able to make essentially like predictions
or classifications or all sorts of things.
So in the case, for example,
of foundational models for large language models,
they get better at creating like cohesive explanation
or at reasoning or at mathematics
or at all sorts of different things.
And we can have these benchmarks
and with more data, they get better at these benchmarks,
which essentially provide better juristic problems
that we're grading them on.
So another concept that I want to explain here
is that there's two specific parts within machine learning
or two specific things you can do usually,
is that when you have a model, you can train a model.
The act of training a model is the act of creating a function
which gets actually better and better
at giving you the juristics,
the more data you feed into it, right?
I'm able to update the parameters of this function
by learning, this is what learning is, right?
I'm updating parameters of a function
in order to get a better jurist.
And this process is really expensive, right?
It's really hard, you have to co-locate a data center,
it's running lots of graphics cards in a big place
and consuming lots of electricity for months on end
in order to be able to create something useful
or meaningful, this is really expensive.
But the end product is very easy to run.
So once I've trained this function,
once I have my set of parameters,
evaluating this function at some input
is usually inexpensive or very inexpensive
compared to actually training it,
several orders of magnitude less.
So these are like the,
how I usually explain machine learning,
just very briefly.
And so now I want to get,
what is zero knowledge machine learning, right?
We have some intuitions from the ZK side,
some intuitions from the machine learning side.
Now we can discuss what ZK machine learning can be
or is within the modern understanding of it.
So essentially what ZK ML is,
is the creation of zero knowledge groups
of machine learning algorithms, right?
So zero knowledge, cryptography,
allows you to create proofs of arbitrary computations.
It can be a proof that I've computed some specific thing.
It can be a proof that some variable is bigger than another.
Essentially it's making proofs about computation
and you know the person who's verifying that proof
knows that someone has executed that computation
on some inputs and has produced some output.
So in the context of machine learning,
usually you have some input, a function or a model,
and then some output, right?
So if it's let's say like charge EPT,
I have a prompt which I feed into the model.
The model just takes that prompt and evaluates its model
and it gives you an output,
which is the thing that you then read in the end,
which is the result, right?
So zero knowledge machine learning
would be the art or act of creating a proof
that I've fed an input to a model
and I've produced some output.
And I can verify that this output came from a model
without essentially having to evaluate this myself personally.
I just know that this comes from a model
because I have a cryptographic proof that this indeed happened.
So something that many people in the space
actually use as a good analogy that accountable AI, right?
Usually AI or machine learning models,
you don't know that they're actually correct
unless you run them yourself, right?
If you run it yourself on your own local machine
or your own data center, which you have privileged access to,
then you know that you've run the right thing.
But let's say that you're using some form of server or API, right?
If I go to chat GPT, like the website,
how do I know that OpenAI is actually serving me the right model?
They claim, like in the UI, in the front end,
they claim that I'm using GPT-4, but how do I know that?
There's no way of me of actually verifying that this is GPT-4.
They might be serving me a worse model, which is cheaper to run
and just pocketing the difference, for example, right?
I don't know.
So one good thing that ZKML provides
is this form of accountability,
where I, as the consumer of some API or some model,
I know that this actually came from something
because I can verify a cryptographic proof that this indeed happened.
So we can make AIs accountable.
We can make anyone using AI accountable
because we can make proofs of computation.
Many of the framing for ZKML in the modern way
is that they want to essentially bring machine learning on-chain
or onto the blockchain in this case, right?
Like we have the blockchains where we have very interconnected networks
of low-end hardware, mostly.
It's like consumer hardware, which is available everywhere,
to run these decentralized networks.
And the problem with this is that every single computer on this network
needs to re-execute everything that the network sees
in order to validate that the network is progressing correctly.
And this is a big problem because now everything is really expensive.
If it's already expensive running it on your own machine,
if you have to run it on 1,000 machines
or 10,000 or 100,000 machines,
it's as many times more expensive.
So it's unfeasible to essentially do machine learning on-chain right now
because it's just too expensive.
And the computational environment that these usually like blockchain have,
like virtual machines, let's say if they're about the EVM,
Solana has SVM, the Solana virtual machine,
that every single blockchain or most blockchains
do have some form of execution capabilities or computing capabilities.
And these are very constrained.
So some of the things that blockchains are good at is cryptography
because they're usually subsidized within the cost of execution in blockchain.
So I can verify a zero-knowledge proof on a blockchain
and I can bring something that I run off-chain on-chain by providing a proof, right?
So for example, if I'm evaluating a model locally,
I'm able to create a zero-knowledge proof that I've evaluated a model on some input
and I can just send the output to the chain and verify a proof
and then the chain or the smart contract can know
that I've actually run a model on some inputs
and I don't have to run that within the environment,
the computing environment, the blockchain, so I can save a lot of cost.
And if I make ML more accessible on-chain, I can actually bring it
and I can build application that leverage machine learning
for lots of different things, which I'll get into a little bit later.
And the last one is the zero-knowledge part of things,
where I'm able to hide specific parts of the computation
or specific parts of the data that I'm making proofs about
and therefore I can make machine learning private.
In order to make machine learning private, there's other techniques as well,
which is like fully homomorphic encryption and multi-party computation.
Each of these other types of cryptography
or types of distributed systems engineering and computing
usually have different trade-offs.
So for example, fully homomorphic encryption
does not give you this correctness assumption or like probability.
I cannot verify that something happened correctly,
but I can, for example, make computations on Cypher text.
So if I encrypt from data, I'm able to perform computations on encrypted data.
And when I decrypt, I have the computation performed
on the original input, on the original plain text,
which is something that is quite fascinating.
However, I do lose this property of ZK,
where I cannot verify that something happened correctly.
Multi-party computation is like the better of both worlds,
but for example, these protocols require multiple parties to work in unison,
and this is really hard to manage, for example.
So yeah, so I want to talk a bit about
who is actually building zernolage machine learning nowadays.
Like which startups, which teams, what are they're focusing on?
So full disclosure, I am an investor in Giza and Modulus,
so I don't want to put that out there, just so you know.
So essentially, there's different avenues
on what is there to build on within the ZKML domain
in order to make these systems better
or to make this more interesting or faster and all sorts of different things.
So the three main companies that usually go around
are Giza, Modulus, and Ezekio.
On Giza, for example, they're building on top of the StarkNet ecosystem,
which is like one specific scalability solution in the Ethereum space,
and they're implemented a bunch of machine learning models
within this computational environment that this blockchain had,
which is called Cairo.
The computational environment is called Cairo, the blockchain is called StarkNet.
And they're building products, right?
So they're building, for example,
tooling so that financial products that are deployed on StarkNet
can leverage machine learning within their, for example,
like prediction models for financial services
so they can predict where the highest deal is to route my money into
so I can get the highest deal on my collateral or my assets
so I can use machine learning off-chain or machine learning on-chain
within this computational environment.
I can prove it, et cetera, et cetera.
So essentially, Giza is building a lot of the product side of things,
like different abstractions, different SDKs,
different representations of models, on-chain, et cetera.
Modular is mostly working on the foundational side of things,
and by foundation, I mean the primordial science of doing cryptography
and doing engineering.
So they're essentially building their own,
the thing so-called like approving system,
which is how do you implement a zero-knowledge scheme?
Like the zero-knowledge, it boiled down to mathematics
and working with polynomials and finite fields
and mostly like linear algebra and abstract algebra
and modular arithmetic and bunch of things of this sort.
So essentially, they're trying to build better cryptographic models
and better cryptographic steps in order for zero-knowledge machine learning
to be more efficient within the actual representation of it
in the computing sense, right?
So this is what they're working on.
I'm happy to then, after this presentation or in the FAQ,
I'm happy to share more, if anyone wants.
Like there's plenty of resources to learn more.
And Ithiko is mostly building, cooling,
and also some of the products type of things and infrastructure,
a lot of infrastructure as well.
So Ithiko, for example, is building an abstraction layer
that allows developers that come from the machine learning world.
So people who usually know Python or right now in this context,
it's just Python.
So people who know Python and know the standard tools
for building machine learning models,
whether it's TensorFlow or Pycorge or I could learn
or any other library for machine learning,
they even have a standardized representation of a model
which can be exported to this model representation
called ONIX, ONIX, Open Your Network Exchange Format.
And this format is essentially something that represents
what the model looks like in the computational sense.
It's a computational graph of different operations
that you need to perform.
And Ithiko allows you to convert whatever you're building within Python
to something that can be ZK-proven,
that you can make a proof of in a very easy way.
So you just import a Python library, you create your model,
and then you just do model that's ZK-proof.
And you are able to ZK-proof that without you as a Python engineer,
as a machine learning engineer,
you don't need to know how ZK works.
You just create a proof of it because Ithiko has built a tool
that helped convert the way that you work with ML
to something that cryptography can,
the cryptography tooling can create proofs of.
And of course, academia, academia has been a crucial element of all of this.
There's lots of cryptography, new cryptography coming out every week almost.
There's new proving systems.
There's new types of final field arithmetic.
There's new discoveries in different field.
There's different optimizations,
like computing optimization from representation,
better models on the machine learning side.
There's also improvements.
And since usually ZKML, you need both things to become more performant.
If academia comes up with better models
and better quantization schemes and whatnot,
all of these improvements, compounds, right?
It's usually the worst of both,
the thing that becomes the worst for the aggregate.
So the worst of KML, or sorry, the worst of ZK and the worst of ML
become the worst of ZKML, like the bottlenecks.
So academia is working a lot of the foundational bottlenecks
when it comes to cryptography
and all these other things that I mentioned.
So some of the use cases,
I do want to talk about use cases
because I've seen a lot of people
who are really deeply interested in the technology.
But the only way that I've seen technology actually progress forward
is if there's funding
and people actually are interested and excited about it.
For example, in the case of Zeronology Cryptography,
because I mostly spend most of my time in the blockchain space,
Zeronology Cryptography has become really popular in the last two to three years,
mostly because there's been products that actually use it,
whether it's scalability solutions, whether it's privacy solutions,
whether it's digital identity solutions,
there's been product market fit for this technology,
and so new companies have been created
and a lot of capital has been poured in.
And this capital was reinvested
into the actual development of better cryptography,
better tooling, better hardware.
And also there's a lot of network effects, right?
So if there's lots of people using something,
other vendors, like hardware vendors,
might want to create hardware for these people,
so it will even speed it up even further.
So I do believe that, for example,
ZKML needs a lot of product market fit or products or catalysts and use cases,
which would improve the state of the art,
just by the fact that there's many people looking at it,
there's a lot of mindshare, there's hype, excitement.
So of course, there's negative parts to this as well,
but mostly I think it's good.
So some of the use cases that I've seen around,
so I personally work at WorldQuint,
and that's like the way that I got exposed to it.
I'll explain our specific youth case towards the end.
So provable inference is one,
so I mentioned earlier on that I do not know if I'm using chatGPT,
that someone is actually serving me the model that they claim they are.
So provable inference is just this concept
where I can know that whomever who used a model to infer some output,
I know where it came from.
I know which model it came from.
If it's public, of course, the APIs can choose to keep the model private,
but at least they can, for example, commit to it.
Something that I can do with, let's say, GPT-4,
OpenAI is not open source.
OpenAI did not open source GPT-4, as of now.
And so if, for example,
I cannot know that someone used GPT-4 because I don't have the weights, right?
It's not a public thing.
But something that OpenAI could do or anyone else with a private model could do
is that they can commit to a specific model, let's say a hash,
and, for example, I know that for the entire user base,
they're using the same model.
So they cannot fool any single user that they're using specific different models
for anyone else.
At least they can commit to it with a cryptographic hash.
So I can just hash.
I know that there is one deterministic output for this model.
And I know every single user knows that they're using the same model
because within the zero-knowledge group,
they have a commitment to some specific set of weights,
but they do not reveal the weight.
They're just committed.
And maybe later, they open source the model,
they can reveal the weights,
and you can see that the commitment does indeed match the weight.
So you actually learn that you did indeed learn about that,
that they did actually use the model they claimed they were.
In this case, GPT-4, they managed to open source the weights.
So that's provable inference.
It can be used for APIs.
So I mentioned chat GPT, that there's many others.
Like video games, if I'm playing an on-chain game and there's some form of ML,
how do I know that the game is not cheating?
How do I know that I have fair rules on there?
The second one is bringing AI on chain.
So there's lots of smart contracts, lots of applications
that people are building within the blockchain domain.
And within the blockchain domain right now,
it's very limited in terms of things it can do.
And machine learning can provide lots of cool solutions
to a lot of different problems, right?
At the end of the day, machine learning is able to provide
good enough approximations to problems that people have.
And so if we're able to bring that on chain,
we might be able to bring some interesting opportunities to the table.
I mentioned the financial ones, where, for example,
I have a yield protocol on chain,
where I deposit assets to this protocol,
and it tries to optimize the yield that I get on those assets.
But it can, it has to use a strategy.
Usually these strategies are closed source and hidden,
but at least I can commit to a strategy.
And this strategy can now leverage machine learning,
and I can indicate proof to the protocol
that we're using a machine learning strategy fairly,
and we're not updating the weights.
And we can also, for example, prove that it was trained
on some historical data with some accuracy, right?
I can make a proof that my model is accurate
on some historical data in terms of yield routing
with some accuracy, and it's routed
to the most performant way, for example.
There's also another one, which is agents or intents
in the context of blockchain.
So agents is a word that comes from the ML lingo,
which is like a program that has the ability
to do actions on their own, right?
They're a player, some system,
like game theoretical system in this case.
So if we have some system, let's say that, I don't know,
like we have a program and we allow
this machine learning algorithm, let's say robotics.
Robotic agents are, is a good analogy, right?
So I have a robot, and the robot is able to interact
with the real world because it has limbs,
it has different tools, like cameras, et cetera,
and it's able to interact with the real world.
The robot in this case is an agent, right?
It's a program which is able to perform actions
in the real world.
It doesn't have to be a real world agent.
It can be a digital agent.
It can interact with a website.
It can browse the web.
It can watch a video and give me some information
about it, but essentially on-chain agent,
good for example, interact with a blockchain
if they have maybe some knowledge, right?
So if it's a smart agent, it sees that,
okay, something happened here.
So maybe I see that as the liquidation happening.
So let me do this, let me buy this, let me sell that.
There's different agents that can learn based on information
and if they have a set of steps that they can do,
they can maybe try and optimize for some goal
and then they become agents in the system.
Blockchain people like to call this intense, yeah?
And another one is attestations, for example.
So I can make attestations about things, right?
I can prove to a smart contract that I'm over 18.
I can prove that also it's a different thing, right?
Essentially, I'm just able to use machine learning off-chain
and I can prove that and bring it on-chain.
Private and machine learning proofs.
So this one is a cool one.
So for example, in the context of medicine,
let's say that there's a cancer diagnosis model
and I as the patient, I do not wanna reveal to anyone
like my personal health records.
But for example, there's a doctor or some health institution
which signs some form of report or some form of certificates
to some personal health records or data.
And then there's a machine learning model
which uses this data to essentially evaluate it
and tells you whether you're likely to have cancer
or whether you have cancer and with what's uncertainty.
So something that you can hear is that if you want to prove
to for example, let's say that an insurance or a payout
had a condition that you've been insured against
or something like that, you'd be able to prove to them
that there's some health institution
or a specific health institution if you want
that has concluded that I am indeed this
or have been diagnosed with a specific thing
without revealing the model, without revealing the weight,
but you at least know that there's some specific thing
that you can make a proof about.
The possibilities here are early big
in the sense that there is generally programmable.
So this is like just one concrete example,
but people can essentially make proofs about any thing,
any data that they have and computations that they did
when they're machine learning base or not
without revealing the data itself, right?
The only person who learns about the data
in the context of ZK is the person making the proof.
I mentioned earlier that this property called completeness.
So in order to make a valid proof,
I do need to have the data.
So the problem is that there's always a prover,
always learns the data,
but if the prover is controlled by myself,
then only it's the same thing as me learning data.
So it's something that is a worthy trade-off.
So if I'm making a proof on my own computer, that makes sense.
And I can prove to anyone else anything
without revealing my data.
But if I am, for example, delegating it to a server,
the server doesn't need to learn my information,
so I need to be careful.
And digital identity.
So I do want to explain very briefly like,
how did we come to this at world coin?
So we have this hardware device, it's called an orb.
I do have it with me.
Maybe if you guys want, I can just go grab it
and one second in the FAQs I can show it.
But essentially the world coin orb is a piece of hardware
that verifies two things.
It proves that there's a real person
in front of this hardware device.
It does this bunch of phenomenally detection like methods
and some other like statistical-based methods,
some sensors that it has like infrared sensors
and it has like field of depth sensors,
it has high resolution cameras, et cetera.
And it's able to determine that there's a real person
in front of the hardware device, the orb,
with like a shiny ball, I'll show it in a bit.
And it can also prove the person in front of it is unique.
And the way that it does that is that it takes
a high resolution image of the person's IRC's
and it's able to compute a unique representation of them
called an IRS code.
And this IRS code, the good thing about it
is that it's not deemed personally identifiable information,
it's just the representation of the uniqueness
or of the randomness of a person's IRS.
And I can use that to measure how unique they are.
And if the distance between two different IRS codes
is big enough, I can prove that this user is unique.
And then once I prove that the person is unique,
I'm able to essentially put them in a set of verified users.
And then what we do is we have a protocol called WorldID
which allows you to prove that you're a member
of this set of verified users
without revealing which member you are
using zero knowledge cryptography as well,
but not DKML, just traditional zero knowledge cryptography.
You're able to prove that I am a unique verified human being
without revealing who you are.
And the data that we collect, which is just this IRS code,
is not personally identifiable information.
We don't collect the raw biometric images, which is cool
because you're able to essentially leverage modern cryptography,
modern biometric literature and the modern tools
like modern hardware like GPUs and everything.
Everything happens client-side,
like within this actual hardware device, right?
The hardware device does this computation.
Nothing leaves the actual orb.
And then the orb deletes everything
within its secure enclave and computational environment.
Within this model of how work can work,
very simplistic model, there's one specific problem,
which in our biometrics pipeline,
if you change the pipeline in any significant way,
you change the outputs of this uniqueness representation.
If you change the output space of the IRS codes,
you can pick them as vectors, right?
So you essentially take this vector space
and you convert it to a different one.
So the same user will have a different representation
in this new space.
Therefore, you will not be able
to measure uniqueness anymore.
So if you ever update the model,
you have to re-sign up all users.
And since you have this physical hardware device
that people have to go to,
it means that all the users that have signed up to date
to WorldID have to go in person again
to this hardware device and get re-signed up.
And this is terrible because it's already been really hard
enough for us to get 5 million plus users
and to have to force our users to re-sign up
every single time that we update the biometrics pipeline,
it would be really bad.
And it has like really terrible user experience.
And so this is where one of my coworkers,
his name is Remco, at the WorldCon Foundation,
he came across with a solution or an idea,
which was what if users self-custody their own biometrics,
meaning that the ORB,
which has essentially a secure enclave
and a trusted execution environment.
So essentially these two pieces of chips
or these two chips allow you to sign things.
So I'm able to cryptograph and define something
that the ORB sees.
So whenever the user gets verified
that they're a real and unique person,
the ORB can sign their raw biometric
which it has in its memory for a given lifetime
and it can give it to the user
and the user can store their own biometrics in their phone
and they can encrypt them, of course,
store them safely in an encrypted fashion
on their own phone or cloud or whatever they prefer.
And they would be able to then have a signature
from the ORB on the actual biometric, right?
You know that this image was seen at one point by the ORB
and it said that this is a unique human being
and this is a real human being.
Most importantly is the real part.
Whenever we want to update the model,
what the user could do is they would be able
to download the new model, the weights of the model
and the ZK approving library for that specific model
and they would be able to create a group
that created this IRS code within a zero-knowledge environment.
So they would be able to create a zero-knowledge proof
that they've created a valid IRS code
from an input image which was attested to by the ORB.
So essentially the pipeline of trust here is not broke, right?
I know that I've created an IRS code
from an original biometric which was verified
by the ORB to be unique.
And with this, I'm able to permissionlessly
or out of my own accord, I'm able to permissionlessly
insert myself into the set of verified users
without having to go to the ORB again
because I have the entire set of stats that I need
in order to prove to the protocol,
to the world ID protocol that I'm a unique user
without revealing why I'm again.
I just proved to you that, hey, the ORB saw me
at one point in time, the ORB did indeed sign this,
my image, I store my images, and then I make a proof
that I've created this derived representation
of uniqueness from my biometrics.
And I can prove to you that I'm a unique human
and this new representation and this new model
without revealing why I'm again, right?
So this is like perfect things,
like a perfect solution for us.
It's actually quite crazy that the knowledge
and that this specific problem didn't exist,
at least that's what I felt when I first covered it
through Remco.
And so right now, for example, we're working with
one of the companies which I mentioned earlier,
Modulus, to essentially do this client-side
zero-knowledge machine learning proving
inside of a user's phone, right?
So that people can self-cassellate the biometrics
and permissionlessly insert themselves.
It's like very early stages, R&D is not yet in production,
but there's been a lot of good progress here.
And two years ago, it seemed like sci-fi.
Now there's already like concrete proof concepts
and implementation and there's benchmarks
and things that are improving.
But yeah, this is like one of the things that I saw.
One last thing that I do want to mention
before I leave you to ask me questions
and for me to go grab my orb as well
is technical bottlenecks.
Zero-knowledge machine learning, right?
We've seen some use cases.
We've seen what people are working on,
what people are doing, what it is,
some of the things that we are doing,
but where do we go now, right?
If you're someone who is interested in this topic,
where could you contribute if you want to,
if you end up learning more,
how do you contribute to these?
Or what are the problems that are hard
and that would help us improve in the front?
So one is better cryptography, right?
Because it's better ZK.
As I mentioned, the worst in ZK and the worst of ML
create a joint bottleneck.
So if you improve ZK or if you improve ML,
you improve the KML.
But there is also an intersection
where if you just focus on the ZK parts
that would make ML better
and on the ML parts that would make ZK better
or is simpler, that's the most focused effort
that you can make to essentially improve everything.
The one is better cryptography.
So remainder, for example,
the thing that I mentioned here,
remainder is a proving library
that is built by modulus labs or modulus,
which essentially uses a type of cryptography
which better models the structured nature
of machine learning computing.
Where like machine learning usually have matrix multiplication,
they have some non-linearities.
So functions that are non-linear, in this case,
there's activation functions or a good example of this.
So there's things like ReLU,
which is one of the most popular ones,
defined linear units, something like that.
Like tanh, there's a bunch of activation functions,
non-linear function.
So they built a cryptographic system
which is able to represent the structured computation
in a much more efficient way.
So when it comes to proving these structured computations,
it takes a lot less computational power to do so
because the representation is much more succinct
and much more efficient.
And so it makes it a lot faster
and a lot more performant
and less computationally intensive.
So this would potentially make it feasible
to run a DK machine learning prover
on the person phone, for example.
Another one is better hardware.
So hardware and specialized hardware
is one of the things that modern science
has benefited from the most.
We've seen the transistor consistently shrinking
and shrinking, we fit more transistors on a chip,
almost like 2X every 18 months, right?
There's Moore's Law, which goes exponentially.
And now we're at like the two nanometer scale
where we have transistors that are two nanometers wide
and we're able to pack trillions of them on modern GPUs.
And for example, in the context of machine learning,
machine learning was really terrible
on traditional computers, like CPUs back in the day,
like in the 60s and 70s and 90s.
So no one actually did machine learning back then.
But when these people were playing video game for some reason,
people started building chips
that represent graphical interface a lot better.
And it happens that there is an overlap of the mathematics
that are used to represent graphics and graphics card
and the machine learning, right?
Machine learning is the metric multiplication
and the way that you represent pictures is matrices, right?
It's just zeros and one that represent the RGB values
of every single pixel on the screen
and transformations between them.
And so you have to do these operations
between pixels really fast
and it just happened that it's the same thing
as doing machine learning,
like neural network fast multiplication
across multiple connected layers,
like very similar structure.
And so people started using GPUs to speed up machine learning
and machine learning became feasible all of a sudden in 2012
with convolutional neural networks
and all these new like booms that we've been writing
until now with modern LLMs.
Like LLMs and all these new generative AI models
are only possible because of this specialized hardware
that come from NVIDIA, DCMC, AMD, ASML,
like all these like transistor manufacturers,
graphic car manufacturers, specialized hardware manufacturers.
These ones are for machine learning, GPUs
and tensor processing unit, GPUs.
Cryptography, on the other hand,
they work with a different type of math.
Instead of working with floating points or arithmetic,
they work with finite fields and sixth point arithmetic.
And so you need to design fundamentally different hardware
and so we need to build better hardware
to improve the computational capabilities
of Zerunov's machine learning.
Just zero knowledge, cryptography in this then.
So there's lots of things to be done here.
So I'm, for example, I'm also an investor in Fabric,
I'm sorry for that,
but Fabric is one of the ZK hardware company.
In Gojama, not size thick is size thick.
Sorry about that.
Some misspelling without the T and irreducible.
There's some of the biggest ZK hardware companies.
And yeah, so these are trying to essentially model
the software in hardware so that it's faster
and there's less overhead.
Another one is better tooling.
So I mentioned Ezekiel and Giza.
They're building tooling
that makes it easier for developers to use ZK.
And if I'm a machine learning engineer,
there's no way in hell I'm gonna spend
six years learning cryptography
and learning the state of the art
and trying to contribute there
so that I can prove my machine learning model.
As a machine learning engineer,
I just care about something that ZK can bring to me.
And vice versa, if I'm a ZK guy,
I just care about something that ML can bring to me
to get better or like somehow make it on chain.
So whenever we've brought down the cost of barriers,
that the cost barriers that prevent us
from doing something, people start experimenting.
Same thing happened with the web.
Like anyone can build a website nowadays
and you can build a business,
you can just Shopify and if I'm a business guy,
I don't need to know web development.
Shopify and I have my store
and I can process millions of dollars of payment.
I can have a truly user and everything.
And otherwise I would have to learn web development,
servers, everything.
I don't have to care about that.
I just do my business and I use web technology
without having to know how it works.
So the same thing applies to the KML, of course.
More robust than secure implementation.
That one is a bit like self books by Antory,
but essentially like the more secure it is,
the less prevent like if we can prevent hacks and exploit,
then if it's more robust,
it can sustain more users, et cetera.
And the other one is like what I mentioned before,
pretty much at the same point,
like better tooling and easier interfaces
is pretty much the same thing
because the easier it is to use,
the more experimentation there for the more products,
the more product market fits,
the more businesses we can build
and the more technology can accelerate
towards the direction of growth.
So yeah, that's everything about my presentation
and I would love to answer any of your questions.
I don't know how long we have.
I think it's 14 minutes for FAQ.
I can also go run, get the work if you guys want to see it.
And thank you for having me.
This was fantastic.
Thank you so much.
What a world and we have a few questions
already here from people in the chat.
And then maybe after a few,
we give you some time to breathe, get the orb.
That would be great.
Okay, so first one, Shadi,
if you want to unmute at your first.
Hi, yeah, thanks for the great presentation.
It's very informative.
I had a question about the personally identifying information
from the hash from the Iris biometrics.
Isn't a hash, will Iris still uniquely identifying
if you know the hashing function to produce that digest?
Or did you mean that make the function is kept secret
and nobody can easily take like a photograph of someone
and then produce the same hash and then look on chain,
for example, I don't think you posted on chain,
but look on chain, for example, to try to match that.
Yeah, there's one unfortunate naming collision here.
So in biometric literature,
people use a hash in a non-urgorous way.
And so what we mean here or what we used to mean,
we've changed the way that we explain these things.
We no longer use the terminology of hash
because we work in the intersection of AI
and cryptography and if you use a term
that means a different thing in both,
it's like ambiguous and it can cause problems
like this one right now.
Actually the way the biometrics biometrics pipeline works
is that there's this essentially convolution-like algorithm.
It's called the GABER wavelet or GABER filter,
which essentially applies convolutions
into original biometrics many times over
and it's able to compute like a randomness representation.
And this one essentially compresses the image so much
like after performing all these operations,
you end up with a pretty much a small representation
of a few bit, like I think it's 200 something bit.
So the vector in the end, like the embedding in the end
is like a few bit and this one is not able
to be reconstructed to its original,
at least like a lossy function, right?
If I go from a compressed representation
to a fully try to expand it back,
I lose information in the process
of converting it to this compressed representation.
Therefore I'm not able to reconstruct the same one
and the good part of this is that I'm not able to,
I'm able to reconstruct something similar
but it's not personalized identifiable,
at least not considered so in modern literature, right?
This may change and this is why we've been working
a lot of other things within world-going,
like multi-party computation solutions and whatnot.
We're gonna be publishing a lot about this
in the coming month, but if you're interested
in like all of us, the biometrics pipeline works
and have the definition of it and how it works
and what is actually going on,
I recommend going to the link I just said in the chat,
whitepaper.worldcoin.org.
Also one of my teammates is in the,
actually one of my former teammates,
he's at Tools for Humanity, which is the labs entity,
I'm at the foundation, different legal entities,
but they're both contributing to the world-going project.
His name is Daniel Gershiewicz, he's in the Clause as well.
So he's also able to explain a bit more.
He's on the orb software team,
so he works a lot more with the biometrics pipeline
than I do, I'm more still in the cryptography
protocol side of things.
But yeah, within the whitepaper,
whitepaper.worldcoin.org, you have a biometric action
and you have the third definition of what it is
that we're doing and how we preserve privacy.
So to answer your question in a specific way,
it's not a hash, it's not a cryptographic hash,
there's no digest, there's no plaintext,
it's essentially a convolutional like operation,
which happens many times,
and it leaves the input unrecognizable
and you compress certain detection of the randomness
that you get, you cannot use that to reconstruct
the original thing that you put into this function
because it's a very lofty function.
And this is good enough to prevent
like getting the raw biometric out again.
Got it.
So the idea is even if I had access
to the kernels that you used to train,
then I wouldn't be able to deconvolute the output.
I see.
Ideally, to try and break our own assumptions
and try to reverse engineer
and actually get the original image.
And now we've gone ahead a step further
because if it was possible, we've gone a step further
and we're now storing everything in ciphertext
and the uniqueness check,
it's happening on ciphertext with multi-party computation.
So yeah, that's like cool, cool new research stuff.
Love it. Dan also shared, I think the white paper
that you referenced directly here in the chat
already a little further up.
Thanks for that, Dan.
Next one up, we have Richard and then we have Micah.
Yeah, I think the previous discussion
answered my question there.
Thank you.
Awesome.
Wonderful, Micah, you go.
Micah, we can't hear you, free free
if you can't unmute to put your chat.
New question in the chat.
Okay, he's going to rejoin.
This could be a great opportunity for you to get the orb.
I also have a few questions, but you go.
Can you hear me?
Yes, Dan, we can hear you.
I want to go back, there was this question about
and things being personally identifiable
or uniquely identifying information.
And then the question turned into
ashes versus wavewritten coatings.
I don't know, I think the question actually
got lost at discussions.
And the interesting thing is that even if you've had
either a hash or an encoding and you somehow broke this
and could reverse the back of the image,
actually the privacy comes from
what was briefly mentioned in the talk,
which is that when you prove your ownership of such,
you're proving ownership of a key that was
linked to this biometric encoding.
So when you prove ownership of that key,
you're not pointing to which encoding is yours.
You're a member of the set without revealing which member.
And that means that these encodings are cryptographically
de-linked from anything else, your transactions,
your accounts, nothing can be linked back.
So if you did reverse the codes, you wouldn't know.
Also, one additional thing is that these encodings
are not public.
They're hidden in a database that we have.
The thing that is public is the public key associated
with the user that has undergone a unique question.
So if I have this unique testing coding
and I prove that I am a unique within the coding set,
which is kept not on any public sphere,
it's now kept in this like multi-party computation
and encrypted environment in a database
that is run by three different parties,
in an MPC setting, again, multi-party.
And when the user is verified to be unique,
we take the user's public key,
which was generated by the World app,
which is the way that you interface with World ID
and the wallet and a bunch of public things that we're building.
Essentially, the public key that was generated by the World app
by the user, which is a unique person
that is just verified by the org,
gets inserted into the set of verified users,
and then I'm able to make a knowledge proof
that I own a private key, two-way public key,
and the set of verified users.
So even then, there's one more step
that removed from your biometric completely
because the public key is just random,
cryptographical, gibberish that I can make proofs about,
and I'm able to prove to you
that I'm a unique member of the set
because I own a private key to a public key in the set,
but I don't know which one.
And there's another cool part,
which is the nullifier scheme that we have,
which allows you to represent unique actions.
For example, one is like unique governance,
like one person, one vote digital governance
or voting protocol.
Currently, there's no way
to prove that you're not a bot online.
So if you, for example, let's say, I don't know,
Elon Musk puts a poll on Twitter or on X
that, hey, is this doc cute or no?
I can create a bajillion X accounts and vote for no, right?
There's no way for me to prove
that this is a one person, one vote.
So whoever would post a poll and whatever thing,
doesn't matter, like the opinion doesn't matter,
the result of the poll doesn't matter.
There's million bots that have incentives
and both, like presidential elections,
if Elon says, is this candidate a good guy?
People can vote yes,
but it can be like a third external nation state
actor trying to just civil attack,
which means like attack a protocol
where you need unique members
in a way that just make the protocol broken
completely beyond repair.
So this is where we step in,
where we create a unit of account of uniqueness
for humans in a digital environment,
whether it's on chain, whether it's off chain,
doesn't matter, as long as you're able
to make these cryptographic attestations
that I am a unique person and I've not done an action for.
So I'm able to prove that I'm a unique actor.
I'm a unique member of this protocol
and I only voted once.
So I can say that this dog was cute only once.
And if I want to weigh the outcome,
the only way to weigh the outcome
is that I need to convince a thousand other members
to vote for the same thing,
but I'm not able to just create a million accounts
and vote for a same thing to weigh the outcome.
Yeah.
Awesome. Yeah, I think Bramco talks a little bit about that,
especially like with possible future applications,
also that you also listed very briefly,
including in medicine and so forth,
that I think these groups are just like really incredible for
because it can't, for medicine, for financial risk,
for insurance and stuff,
you just can't really access the data any other way.
Or you just can't do too much anyways with that information.
Okay, we have another question,
but you also have the orb now or?
It's right here on my left.
Wonderful.
By the phone, the battery.
At least, all right, sorry.
I'm going to unbler my background.
I do have a, I just moved into a new apartment,
so forgive me for, but yeah.
Battery right here.
Yeah, that is able to say a lot more about the orb than I can.
If you work on the orb software team,
you've been working on this for three years plus.
Yeah.
Yeah, it's come in multiple close contacts with the orb already
and I think in 50 years you even have it like taken apart,
you know, and it's different components,
which is really fun to see.
So yeah, thanks.
The orb hardware specs are publicly available
on GitHub as well.
So people can see the PCB design,
they can see like what components it's made out of.
There's also an hour paper,
there's like an annotated set of every single component
and like what it does, how it works, et cetera.
Yeah, I've been following like just how many people are signing up
and like the very, very long lines
and sign up stations, which has been really interesting.
Okay, Micah, you rejoined and you raised your hand.
Do you want to ask you any question?
Testing, can you hear me?
Yep.
Quick comment and then a question after that.
The, I believe that while the transactions,
your transactions made using your unique ID
can't be linked back to you,
you can be linked back to your transaction.
Someone has an orb or the algorithm in the orb
and they can get a picture of you, so to speak.
They can then regenerate your unique ID
and this is an unnecessary piece,
you can't get rid of it because in order to have
a unique human, you need to be able to verify.
There needs to be only one outcome,
you can't introduce randomness here, right?
And so if your goal is to not have someone be able to tell
which transactions you did, that is not possible here,
but someone can't tell just by looking at the transactions
that they were yours.
It's a one-way thing,
this one held you down and put an orb in front of your eye,
they can then figure out all your transactions,
but they couldn't look at your transaction
and figure out which I may belong to, so to speak.
Yes and no, there's one step that helps us mitigate this,
which is the separation of the public key, right?
Like your transactions are not being done
by your iris code or whatever.
Intellections are being done by a public key,
which would own by user,
which just happened to verify at the orb, right?
You would have to get the user's private key
to learn what they did on game.
And then you would also have to bid their buy-mit for it
to try and interlink too, right?
You'd have to get their buy-mit for it,
generate the iris code,
and then get somehow steal from them their private key.
And then with the private key,
you're able to de-anonymize the on-chain state
that they performed in a DK way,
because you're not able to just get the virus.
You know you can generate them.
And so there's two things that you need to compromise there.
My actual question, I'll try to keep it brief.
I know I've got one minute left.
Last I checked, DK approved of an execution takes
on the order of a thousand times or so,
executing the same thing without a DK proof.
Even though inference is significantly cheaper
than training, execution costs is still very non-trivial.
That's why you need giant GPUs and whatnot,
just to do inference.
The use cases you're thinking of,
are they all things that are like become useful
once we can get the DK approving costs down by a hundred times?
Or do you think there's some things that are usable
even with that thousandth increase in execution costs?
Right now there's already like DK use cases on-chain, right?
And there's equally expensive in the ML lens,
like already proved a hundred million parameter models
in an inexpensive way, in a usable way.
Let's say you have a small convolutional neural network
classifier with 200 million weights, like flowing point,
or in this case for a DK ML with field elements,
but you're able to make proofs in reasonable time,
one to two minutes for inference, right?
Where the evaluation of it in the normal world
is a thousand nights less, 20 millisecond, like 0.2 second,
or 200 million, my bad.
So yeah, this is like the costly incur,
but it makes sense for some things.
And right now, as I mentioned,
the things that we're doing could prove the thing,
like cryptography, better implementation,
better hardware, specialized hardware, et cetera.
It's gonna bring down this cost significantly.
It's gonna make more things feasible.
Like now we can maybe prove an LLM.
It may take 10 minutes,
but maybe proving that a LLM once
for something that's really important enables a new thing.
And it's always happened like this,
that the use case and the demand for it
can bring the proving time down,
the overhead down, the performance up,
and we still have a bunch of things to do.
So it should work out eventually.
Love it.
Any final words?
How can people find out more?
I know that you said, for example,
there's an announcement coming on soon,
but if people are really excited about this,
or they just wanna learn more,
what are any possible action items that people can take?
So action items.
So if you have a specific question
about this presentation you wanna ask me,
I think my Twitter or my Telegram,
or like my X and my Telegram are the best.
So my handle is dcbuild3r, so dcbuilder,
but with a three instead of an E at the end.
So that is for asking me questions.
If you were interested in ZKML itself,
I do have a resource aggregator for ZKML things.
It's on my, or one of my GitHub's,
which is github.com slash ZKML dash community slash awesome
dash ZKML.
I'm able to leave the link in the chat real quick,
but I think like the spelling makes sense.
Besides that, there's a bunch of startups working in ZKML,
mostly like what I mentioned,
like Modulus, Giza, and Ezekio.
And these three keep coming out with new developments,
new things, new announcements, et cetera.
There's cryptographic papers coming out on ZKML,
which I also try and keep up to date on my resource.
So yeah, those are like the best ones, I think.
Love it.
And I just saw from Dan that he's bringing
up to our upcoming May workshop, though.
If you're going to that one, you may be able to try it.
Hey, thank you so much.
This was really fantastic.
Thanks for staying on three minutes longer.
I really appreciate it.
Thanks for all of your great questions, everyone.
And I hope to see you guys soon.
Bye-bye.
