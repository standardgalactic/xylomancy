Even Wolfram is a mathematician, computer scientist,
physicist, and businessman.
Have I lied so far, Steve?
I don't know.
Some people would not put mathematician first,
but that's OK.
He's known for his work in computer science, mathematics,
and theoretical physics.
A fellow of the American Mathematical Society,
founder and CEO of the software company,
Wolfram Research, where he works as chief designer
of Mathematica at the Wolfram Alpha NSERC engine.
Now, I'm going to move that away.
And I'm going to give it.
You have also, besides the people in the attendees,
there's also one, two, three, four, five panelists
that are here so far, and there might be some more.
Carl Friston, Ronnie Katzier, Sammy Benjiro.
I can see the names, yeah.
Hi, Carl.
The rest of you, I don't know, so nice to meet you.
Sammy, it's the other Benjiro.
We'll find out more about that.
He's the brother of Yoshua, who is the co-sponsor of this event.
OK, it's all yours.
Wing it.
OK, so well, let's see.
So I think you guys want to talk about language and computation
and AI and all those good kinds of things.
And I was thinking, I could talk about things about LLMs
and so on.
I wrote this little book last February about chat GBT.
You can find a version of it online.
I can put it in the chat.
Let me not talk about that, but if people want to ask about it,
I'm happy to chat about it.
I thought what I would try to do in 45 minutes
give you a very rough tour of my last four and a half decades
of developments of a worldview and see how that relates to things
about AI and language and so on.
So to begin, I think the thing that there's
kind of this progression of paradigms
to do with how we formalize the world.
So there's sort of this question of what can we do?
When we see the world, we're interested in finding ways
to have sort of formal descriptions of it that we can build on.
So historically, kind of the first of those,
the big one for our species, was the invention of human language
and the idea that you didn't have to just point at each individual rock,
but you could have this kind of symbolic name rock,
wasn't rock originally, obviously, for that concept.
And you could communicate abstractly about that thing
using human language.
Now, then we've had sort of a stack of other ideas,
another big ideas logic, being able to as a way of sort of abstracting
things about the world, formalizing things about the world.
Another big direction is mathematics,
being able to something that sort of became big in the late 1600s
of being able to describe our world by mathematical concepts and constructs.
In this century and the end of the last one,
the big new thing has been using computation
as a way to formalize and describe the world.
Being able to specify kind of the way I think about computation,
it's a way of setting up rules and then saying, let these rules run.
And the question is, can we set up rules that describe the way the world is
or the aspects of the world at least that we care about?
And my kind of day job for the last four decades
has been building our computational language,
Wolfram Language, Mathematica and so on,
as a way to kind of take the things that we humans care about,
whether they're molecules or cities or algorithms or whatever,
and create a systematic computational language
to let one describe those things
and not only describe them in a way that humans can read,
but also something where computers can help humans to execute those things.
So that's been kind of the way I see sort of that effort,
is take the things that we humans care about
and find a way to formalize them computationally
so that we can provide sort of the raw material
that we need to work with the world computationally.
It's kind of the effort is a bit like the effort that happened maybe 500 years ago
with the development of mathematical notation
where people went from kind of talking about math in terms of words
to having sort of a streamlined notation with plus signs and equals signs and things like that,
and that idea of notation, that sort of streamlined notation for mathematics,
is what ended up launching algebra and then calculus
and basically the modern mathematical sciences.
Kind of my day job mission has been to create a computational language
that lets one kind of launch computational X for all fields X.
So, okay, that's so kind of this idea is computational language
as a way to sort of formalize things that happen in the world,
things that we care about in the world.
Now, the next question is what is the intrinsic description of the world,
so to speak, how should we describe the world in general?
And the thing that sort of had been the tradition of exact science for about 300 years
was use mathematical equations, write down an equation
that describes this or that aspect of the world.
The thing that I got interested in in the early 1980s
is how does one generalize that idea?
How does one, what kinds of raw material can you find to talk about the world?
And the thing that I started studying a lot
was using computation as kind of the raw material for describing the world.
And so the question, the first question is, well, okay,
what kinds of, how do you set up kind of computational systems to do that?
And for example, let's see, let's actually do something here.
Let's say we are just kind of, we want to see what do programs
that might be computational descriptions of the world,
what, let's just look at some program that,
let's just say, what do the typical programs out there do?
So this is a very simple example.
It's just you imagine a line of black and white cells
and you have some simple rule that says, given the colors of cells on one row,
these are the, this is the color,
this is how you determine the color of the cells on the next row.
So if you run this and just run this starting, let's say, from one black cell,
let's run it for like 40 steps, according to that rule,
you start off from, you end up with something where you have this very simple rule,
very simple computational rule, you run it, you get this very simple pattern.
Now the question is, what happens if we look at other kinds of rules?
What happens if we kind of turn our computational telescope
out into the computational universe and just look at what's out there?
So we can do that, let's do this.
Let's just make a, let's just make a table of all possible rules.
Let's say the first 63 of these rules, 64 of these rules.
Okay, so each one of these rules corresponds,
each one of these pictures corresponds to a different rule
for how the colors of cells are determined by colors of cells above them.
And what we see is many of these patterns are very simple.
Sometimes we'll get slightly more complicated patterns,
we might get a nested pattern, for example, here.
But the thing that is kind of my all-time favorite science discovery
that I made almost exactly 40 years ago, it was 40 years ago on June 1st,
is this thing that I call rule 30.
It's specified by this set of cases here.
And if we just run, just run this, we started off from single black cell.
Let's run it for, let's say 200 steps.
This is what we get.
And to me, this is something very surprising and kind of intuition breaking.
We have a very simple rule, and yet when we run that rule,
we're generating something that looks, at least to us, very complicated.
And actually, you can go and you can sort of work out
what's the center column of cells here,
and for all practical purposes, it seems completely random.
But so what this is telling us is out in the computational universe,
even very simple rules can easily give one very complicated behavior.
And there are a lot of consequences of this.
One thing that this led me to is this thing I call
the principle of computational equivalence.
So the thing that is sort of a big question is,
how do you characterize what's going on in a system like this?
Well, you can think about the system as performing a computation.
It starts from its initial conditions at the top,
and then it's going crunch, crunch, crunch, and executing a computation.
The question then is sort of how sophisticated is that computation?
And one might have thought, well, it's just a simple rule, it's doing what it does.
If we think about the kinds of computations that, for example, we do in our brains,
well, those are going to be much more sophisticated than this.
But what the principle of computational equivalence says
is that actually that's not true.
Above some very low threshold, essentially all of these kinds of systems,
regardless of how simple their rules are,
are equivalent in the sophistication of the computations that they can do.
So that means that in a sense this little rule 30 thing
is doing a computation that's just as sophisticated
as the computations that go on, for example, in our brains.
Well, what consequences does that have?
One consequence that has is this phenomenon I call computational irreducibility.
So let's say you want to know how this pattern is going to work out
a billion steps from later from now.
Well, how do you figure that out?
One way you can figure that out is just to follow those billion steps
and see what happens.
Another thing you can do is to say, wait a minute,
I'm much smarter than this system.
I'm just going to jump ahead and I'm going to say,
I know what the answer is after a billion steps.
That's the thing we've become used to in doing, for example, mathematical science.
You imagine an idealized planet orbiting a star.
You say, do you have to work out where it's going to be a million years from now?
Do you have to follow those million orbits?
Or can you just use a formula and kind of fill in the number of million
and jump ahead and see what the answer is?
That kind of what we can call computational reducibility
is what we've become used to from kind of what happens in mathematical science.
But the principle of computational equivalence tells us
that will not generally be what one can do.
In general, the systems that we're studying will be just as computationally sophisticated
as anything that we can muster in studying them.
And so that means we won't be able to do that kind of jumping ahead.
We won't be able to do that kind of computational outrunning of the system
and will be reduced to something where to work out what the system does,
we basically have to follow every step and see what the outcome is.
So this is something which for kind of in a sense for science,
it's telling when there's a major limitation on science.
And by the way, this idea is something, things like girl's theorem,
a sort of a special case of this idea and lots of other kinds of things
that one knows about universal computation and so on is also related to this.
But this is kind of a tighter version of those kinds of ideas
and one which I think shows one kind of the relationship of these things to science.
And so the big consequences, there's lots of stuff
that you won't be able to have a theory for, work out, jump ahead,
know what's going to happen.
You'll have to just follow every step and see what happens.
And so in a sense, that's a limitation on science.
From within science, one is seeing kind of a fundamental limitation of science.
It's actually something which for many purposes might one might not think of
being such a bad thing, because in a sense, it's the thing that makes,
for example, the passage of time meaningful.
If it wasn't for computational irreducibility, then if you live for 50 years,
then in a sense one that would not be nothing would be achieved by that.
One would be able to say, oh, I know what's going to happen in the end.
I can jump ahead and say what the outcome is going to be.
But because of computational irreducibility, there is something sort of really
happening in the passage of time.
It is a sort of an irreducible computation that's going on.
There are many other consequences of computational irreducibility.
For example, when it comes to things like AI, we can ask the question,
what in so far as AI is doing computation?
And we'll talk about the sense maybe later in which typical modern neural nets
are doing only very weak levels of computation.
But let's imagine that we have a system that is doing computation
as computation can be done.
Well, we sort of have a choice.
Either we can say that system is we're going to make that system computationally
reducible, so we know what the outcome is going to be.
And so, for example, we can say, we're absolutely sure this system will never
do the wrong thing, because we know it's outcomes, and we can constrain it
to set it up so we can sort of prove that we'll never do the wrong thing.
It's reducible enough that we can know enough about what it's going to do
that we can know it isn't going to do the wrong thing.
So that's plan A, but the problem with plan A is that means that the system
can't do irreducible computations.
The system can only do computations where we can jump ahead and foresee the outcome.
So in a sense, that means we're crippling the system.
We're preventing it from doing what it could do as a computational system.
We're saying it's only going to do those things which are kind of reducible.
So in a sense, I think it's going to end up being sort of a big societal choice,
is do we want the AIs, computational systems, to be able to do all the powerful
things that computational systems can do, or do we want to insist that they'll
only do things where we can foresee what they'll do?
And in a sense, it's kind of like we have a, we're,
you could say, well, I'm going to set up all these rules for the AIs that make
sure they only do the right things.
Well, to make that work, you have to have the AIs be sort of computationally reducible.
If they're computationally irreducible, well, maybe you can constrain it in all
sorts of ways, but there'll always be surprises.
There'll always be things where you can't foresee that particular outcome.
By the way, computational irreducibility has many, many consequences, but another
consequence it has is that sort of science will never be finished.
There will always be, if we think about kind of, there'll always be things where
we can't foresee the next thing that will happen.
There will always be surprises in mathematics.
There will always be new theorems that can be proved and so on.
The thing that is an issue there in terms of things like will science be finished
and so on is, well, okay, there might be things that were surprises, but are they
surprises we care about?
If we were exploring all of mathematics, we would prove more and more and more theorems,
but it could be that we get to the point where we know all the theorems we care about
and anything else is something we're not going to care about.
So in a sense, it's a, there's sort of this, this connection to sort of human
issues in, in what, but, but, but the point is that there is ultimately an
infinite and unlimited frontier of what's possible to discover in science and so on.
By the way, that also relates, maybe we can talk about to, to things like, well, okay,
let's, let's maybe talk about, so, so kind of this, this idea of computational
irreducibility that you can't know the outcome of a computational process in general,
except by running it and seeing what happens.
Limitation on science, thing that makes the passage of time meaningful kind of dichotomy
for thinking about, about AI and so on.
It's the, so that, so let's see, the, one of the things that's sort of interesting
about, about this is we can, we can just sort of, in this computational universe, we'll
find all sorts of, of things that go on.
The question becomes sort of, are those things that we find out there, things that we care
about or not?
In other words, we can go and we can, oh, I don't know, we can, you know, that's an
example of just a simple rule and what it does and we can get the lots of other, lots
of other examples.
We can, we can, we can go, go and do this ourselves if we want to, let's see.
And just go find very simple rules that do very complicated things, it's, it's, it's
easy to kind of launch out into the computational universe and find these things.
The question ends up being, so how, what, do we humans care about these things?
Well, it could be that this particular thing, we will be able to use it for technology in
some way.
It could be that we'll think this is something very important for art, but it's something
we're out there in the computational universe that's kind of an infinite supply of original
things.
The question is, which ones do we humans choose to care about?
And, and for example, if we imagine kind of the, the, the future of AIs, you can say,
okay, I go out into the computational universe, you can go and create things that have never
been seen before, all kinds of things.
The question is, are those things that are of, of the kind of human relevance to us now?
Well, one thing you might do, you can actually do a little experiment here, let me show you
something.
Oh, where is it?
Um, so for example, we could say we could take some image generation AI, and this is just
a diffusion image generator, and we could say, let's, let's look, let's ask the thing
to make a picture of a cat in a party hat, okay?
But inside the AI, it's got some, you know, embedding vector, it's got some, some set
of numbers that describe that is its version of what that concept is.
But one thing we could do is something very simple to sort of explore the universe of
possibilities.
We could say we're going to take this AI that's very aligned with human interest because
it's been trained on billions of human images.
But nevertheless, we could say, let's take this AI and let's sort of move around in this
space of possibilities.
And so for some set of numbers, we've got the cat and the party hat, but as we change
those numbers, we're moving out from that.
And we have this kind of, in the middle, we have this thing we might sort of describe
as kind of cat island, that is things that to us kind of look like cats.
But then we go further away and we'll get into things which aren't like cats.
If we go far enough, you know, we'll, we'll be able to go, I don't know, as an example,
we'd be able to go from, what is that going to?
That's, well, okay, here's one that goes from a cat to a dog.
We're going through, through this kind of meaning space from a cat to a dog.
But in general, what we'll find is that we, in this sort of space of possibilities, there's
this region that corresponds to this concept that we have of a cat and a party hat.
As we go away from that, eventually we move far enough, we'll get to a picture of a, you
know, a dog wearing a sweater or something.
But we go through a large volume of inter-concept space of things which are images which were
generated by this AI using, you know, computationally generated out there in the computational universe,
even set up to be quite aligned with kind of the pictures that we humans have put on
the web.
Nevertheless, they're not things which are normally described by a word like a cat or
a dog or whatever else.
So you might ask the question, you know, in an image generation AI, what volume of the
space of possibilities is covered by concepts that we have already defined?
The answer is maybe one part and 10 to the 600.
So in other words, there's this vast kind of inter-concept space of possible images,
only tiny corners of which are described by words that we have in human languages.
So in a sense, as we look at this kind of inter-concept space, we could say, you know,
we don't necessarily have a word to describe some of these patterns, but we might say,
oh, that's kind of a cool pattern, and maybe we decide at some point that that's a particular
style of art, and eventually we get a word for it, and then we develop this whole kind
of human interest in that particular piece of what was inter-concept space, and now that
becomes a concept in our languages and so on.
So this idea, this sort of this core idea that there's this huge space, this huge kind
of computational universe of possibilities, even reduced here by ones that are sort of
images aligned with images that we put on the web.
Even if you reduce it in that way, the part of that space that we have so far explored
that we have so far come up with words for and described with concepts is a tiny part
of the space, and there's vastly more that is kind of be found in the sort of inter-concept
space.
Now, what, you know, can we describe kind of the way that kind of we think about sort
of our progression in kind of the progression of human civilization and so on?
In some sense, you can think about us as progressively colonizing inter-concept space.
We're progressively coming up with things, coming up with, we're coming up with sort
of this social construct of language that different ones of us sort of collectively
understand that corresponds to these different points in the space of possibilities, and
sort of the progression of civilization we can think of as being this progressive kind
of progressive exploration of inter-concept space.
And you know, as we invent new paradigms for things we get to kind of or new ways of describing
things we get to kind of move outwards in the space.
Now, for example, in my day job of creating computational language to describe things,
my mission in a sense is to find those places in the space of possibilities that we humans
care about and that we can use as kind of building blocks to construct kind of in a
computational way a description of what we want.
But there's kind of a broader science of what's in principle out there, which is broader than
the things that we humans have so far chosen to come up with words for and so on and have
languages for.
Well, just to kind of fill out a little bit, kind of the, a little bit more of kind of
the world view that develops from all of this.
We can ask questions about, okay, what about our physical world?
How is that constructed?
What is the, what's kind of the underlying structure there?
And one of the things that's been very exciting to me in the last few years, something I really
did not expect sort of to happen, is that it's turned out that we've been able to work
out that how this kind of computational ideas provide sort of an ultimate infrastructure,
an ultimate kind of machine code for the physical universe.
And what, let me describe that a little bit because we're going to come back to this question
of concepts and inter-concept space and so on, but we're going to come at it now from
a different direction from understanding the structure of the physical world.
So sort of big picture back in antiquity, people were arguing, you know, is the world
discreet or is it continuous?
Is it made of atoms or is it just things that are sort of flowing?
And one didn't know.
End of the 19th century, it became clear, yes, there are molecules, matter is discreet.
A little bit later became clear, there are photons like can be thought of as being discreet.
At that time, people mostly assumed that space would turn out to be discreet as well.
For various reasons, nobody technically managed to make that work.
And so physics kind of went on with the space is continuous, you can kind of put things
anywhere you want in space.
Well, if you're thinking about things in kind of computational terms, you're immediately
led to say, wait a minute, you know, perhaps space is actually fundamentally a computational
construct, fundamentally a discreet kind of thing.
And the big surprise of four years ago now was that, yes, we actually managed to figure
out how to make that work and managed to figure out how that connects to the big theories
of current 20th century physics.
And actually the really remarkable thing that maybe I'll have a chance to describe is that
the big theories of 20th century physics, essentially general relativity, the theory
of gravity and spacetime, quantum mechanics and statistical mechanics for the second law
of thermodynamics, those are sort of three big theories of 20th century physics.
It turns out that all three of those theories are not just things that we can kind of say,
oh, that's what's true.
There are actually things that we can in some sense derive from fundamental considerations.
I had not expected any such thing to be the case that we could derive the laws of physics,
so to speak, but we can and I'll explain how that works.
And that's going to loop back to questions about language and concepts and so on.
But okay, so what's the universe made of?
Well, in our models, the universe consists of a bunch of sort of discrete atoms of space.
We tend to call them eems, kind of atoms of existence.
They're things where the only thing you can say about them is they exist and they have
an identity and they're distinct from each other.
And then there's one more thing, which is you can say how these eems, how these atoms
of space are related to each other.
You can say this one is related to these two other ones.
It's kind of like what atom of space is friends with what other atoms of space?
And you define this whole collection of relations between atoms of space and you can represent
that by a graph, a network, or actually more formally in our models, a hypergraph, but essentially
one's just dealing with this big network of relations between the atoms of space.
And so everything in the universe in our models is just made of the relations between
atoms of space.
So for example, if something like a black hole, for example, is just a structure in
the...
I might even be able to show you a picture of one.
Let me see if I can pull this up.
Let's have this.
Let me see.
Am I going to get this to work?
Maybe.
This is actually in kind of the fabric of space.
This is two little tiny black holes and we'll see in this video kind of space.
Most of the activity of the universe actually is knitting together the structure of space,
but there are two black holes there and you can kind of see they eventually merge.
They produce gravitational radiation.
Actually what we get from this model where we're looking at kind of the discrete structure
of space, we can successfully reproduce the actual things that are observed in black hole
mergers and so on.
But in any case, the basic point is what the universe is made of, everything in the universe
is just a feature of the structure of space.
And when it comes to time, time is the progressive rewriting of the structure of that network
that represents space.
So time is actually a very different kind of thing in these models from space.
Things like relativity emerge as a feature of the model.
They're not things that are put in from the underlying structure of the model.
Okay, so we've got sort of the notion of space, the notion of time.
It turns out quantum mechanics is a thing that inevitably emerges from the fact that
when we are updating this network, there isn't just one possible path of history.
There isn't just one possible way that the network can be updated.
There are many possible paths of history that branch and merge and essentially the structure
of those things is what leads to quantum mechanics.
Well, one of the issues is when we're looking at the system and we're seeing all these rewrites
and the structure of space and so on, the question is, how do we experience that?
What, there are all these things microscopically happening, but we have a certain experience
of that.
And it turns out that sort of a critical feature of what's going on is that we are observers
of a certain kind.
So let's take the case of, let's look at, for example, let's see, let's look at something
like statistical mechanics.
We've got a bunch of molecules bouncing around in a box and one of the kind of big principles
is the second law of thermodynamics that says when you start those molecules off in an orderly
way, their motion will tend to eventually look disordered and random.
It will look as if it has higher entropy.
And the question is sort of what's really going on there?
And it turns out that what's actually happening, something I finally understood, I've been
thinking about this for like 50 years, actually, is that what's ultimately going on, you can
look at different kinds of versions of this, what's ultimately going on is that these molecules
are bouncing around in a certain determined way according to some rule, and in fact that
rule can be reversed.
So you can take this pattern of molecules you get at the end and you can say you can
figure out, oh yes, that pattern of molecules came from the simple initial state.
Well, in principle, you can do that, but it's a computationally irreducible process.
And the difficulty is that we human observers of things are computationally bounded.
We can't do that, all the computation that's needed to reverse what happens in the molecules.
They just stuck saying that we can get this impression of what's going on.
And with that impression of what's going on, with that computationally bounded impression
of what's going on, all we can say is, oh, it looks random to us.
And that's kind of the ultimate origin of the second law of thermodynamics is something
which has to do with the relationship between underlying computational irreducibility and
our computational boundedness as observers.
Well, it turns out that both general relativity and quantum mechanics come from the exact
same thing.
They both come from this idea that there is computational irreducibility underneath.
But we are, well, actually, there are two attributes that we have to have as observers,
that we're computationally bounded and that we believe we are persistent in time.
So in this model, for example, we are at every moment in time, we're made of different atoms
of space.
Yet we all have the impression that we are experiencing things through that it's still
us a second later, so to speak, and that we experience things.
We are persistent.
We have a continuous thread of experience through time.
Well, OK, so the really ultimately big concept here is this thing we call the Ruliad.
And so here's how this works.
When we look at these, this underlying hypergraph and its rewrite rules and all those kinds
of things, we can, we say, OK, there are these underlying rules.
And if we run those enough times, we'll eventually get something that seems like our universe
that satisfies Einstein's equations of general relativity.
That shows the Feynman path into quantum mechanics, all those kinds of good things.
But we still might be asking the question, well, why did our universe get one particular
rule and not another?
And that had me very confused for quite a while until I realized that actually we can
think of the universe as running all possible rules.
So what we imagine is that there are these possible computational rules that can be used
to update this hypergraph and so on.
But let's just imagine that we use all possible rules.
What we get are all these different parts of history that branched and merge and so
on corresponding to the application of all these different rules.
And this whole object that is the entangled limit of all possible computational processes,
we call the Roulillade.
And the Roulillade is a completely unique thing.
It is you take every possible Turing machine, every possible computational system, you
run all of them, and you run them in such a way that they are producing kind of, that
they don't just have one possible outcome, they have all possible outcomes.
You might say, what an incredible mess.
How could you ever conclude anything from this Roulillade object?
It is the case that this Roulillade object is a unique thing.
It's not like there's seven different Roulillades.
There's just this thing that is the entangled limit of all possible computations.
And so then the question is, well, how can you conclude anything about this Roulillade
object?
Well, what you have to realize is the Roulillade object represents everything that's possible,
everything.
And so, for example, we, as observers of what's going on, we must be embedded within this
Roulillade.
And so, what we can think of is that this, this, was I sharing the screen or did I stop
sharing?
Well, anyway, the, so the issue is we are observers embedded within this Roulillade, observing
the Roulillade.
And the question is, what do we conclude about the Roulillade?
And the Roulillade is a necessary thing, there's no choice about it.
But the nature of us as observers is contingent, so to speak.
And so what turns out to be the case is that observers like us, observers that have certain
attributes necessarily conclude that necessarily describe the Roulillade in certain ways.
So in a sense, by being an observer who is computationally bounded, who believes they're
persistent in time, those two attributes alone are sufficient to tell us that the slice of
the Roulillade, the way that we parse the Roulillade is exactly the way that corresponds
to the laws of physics that we know.
So in other words, what we're saying is you can derive the laws of physics.
The laws of physics are derived by starting with this Roulillade, which is a necessary
unique object, and then saying what, for observers like us, which happen to have the properties
that we have of being computationally bounded and believing we're persistent in time, any
observer with those very coarse properties will necessarily conclude that the universe
operates according to Einstein's equations and the path integral and so on.
So that's a rather interesting philosophical conclusion.
Now you could ask, well, what would observers not like us conclude?
Well, we don't know.
You can kind of, and that's sort of a question of how do we think about observers not like
us?
Well, one thing to realize is we can think of in the Roulillade, we can think of different
possible observers as being sort of at different points in the Roulillade.
There are different places in Roulillade space.
Just like in physical space, we could be here on this planet.
We could be on a galaxy on the other side of the universe.
We can be at different places in physical space, and each different place in physical
space will give us a different point of view about how the universe works.
So it is in Roulillade space.
Each different place in Roulillade space will give us a different point of view about how
the universe works, how things work.
So here's a way to think about that.
We can think of essentially different minds as being at different places in Roulillade
space.
It's as if, and these different minds are kind of experiencing possibilities in a different
way.
So if we think about that in terms of the LLMs and so on, it's kind of like we could imagine
just having a differently trained LLM, and that differently trained LLM basically exists
at a different place in Roulillade space.
So for example, minds that are sort of similar and sort of similarly trained will be fairly
close in Roulillade space.
Minds that are different, like let's say cats and dogs, further away in Roulillade space.
And I tend to, I think that one of the consequences of the principle of computational equivalence
that I mentioned earlier is that one could sort of attribute mind-like things to lots
of systems in the world and lots of abstract systems.
And so for example, when one says the weather has a mind of its own, in the principle of
computational equivalence says, yes, that's a meaningful thing to say, but in a sense,
the mind that corresponds to the weather is pretty far away from us in Roulillade space.
Also now there's a question, how do you communicate across Roulillade space?
How do you, what is it, what's involved in doing that?
Well, at some computational level, one point in Roulillade space corresponds to sort of
computing according to let's say one Turing machine, another point in Roulillade space
computing according to another Turing machine, another computer.
We know that in principle, we can make a translation from one place in Roulillade space to another
place in Roulillade space, takes effort.
We have to actually create that interpreter that's going to interpret the instructions
of one machine as the instructions of another machine.
It takes effort in the same way as it takes effort to move in physical space.
In a sense, when we move in physical space in our models, we're reconstructing ourselves
at a different point in physical space.
And by the way, you can understand things like time dilation and relativity, there's
a nice kind of mechanical explanation of that.
If you're always in one place, you're spending your kind of computation budget figuring out
what the next behave, what the what the next stage you'll be in is.
But if you're moving, then you're using some of your computation budget to kind of recreate
yourself at a different place in space.
And so that's used up having used up some of your computation budget, you necessarily
sort of moves go through time more slowly time, time goes more slowly because you used
up some of your computation budget in moving in space, but in any case, you can you can
think of so so by the way, in our models, the possibility of motion is non trivial.
It's not obvious that you can, you know, pick up a glass and move it somewhere, and it'll
still be the same glass.
That's something that we generally assume about the world that pure motion is possible,
but it's something in our models that you have to prove that pure motion is possible.
And even in traditional physics, if you're sufficiently near a space time singularity,
for example, no, no material object will maintain its identity as you move it around that that
singularity.
But in our models, the possibility that that thing can just move and that it's still the
same thing is non trivial.
And actually, in a sense, the particles of motion are exactly the kinds of particles
that we know about, like electrons and quarks and so on.
What is an electron?
An electron in some sense in an abstract level is a lump that is capable of pure motion.
It's something where you can have an electron in one place, and you can move it and it'll
still just be that electron.
So particles are kind of the carriers of pure motion in physical space.
So here's a thing in rural space, we can ask sort of what is motion in rural space
about?
Well, in a sense, what it means to have motion in rural space is you're effectively transporting
something from one mind to another.
If different points in rural space correspond to the positions of different minds, you're
asking the question, what does it take to kind of transport things around rural space?
And I think this is one of the very bizarre kinds of things that one realizes is it seems
to be the case that concepts are the analog of particles.
So what in physical space and an electron, it doesn't change as you move it from here
to there.
In rural space, it's the concept of a cat, for example, that can be moved from one mind
to another without change.
I mean, the particular details of the neural firings that exist in my brain, when I think
of the concept of cat, in any of your brains, the particular neural firings will be different.
But yet, we can package up the concept of a cat, and I can say the word cat, I can transport
it to you, and then you can unpack it.
And in your place in rural space, you can end up with the same thing, so to speak.
So it's kind of a way of understanding that that's sort of the fundamental thing that's
going on, and we can think of kind of concepts as being the particles of a rural space.
Well, there are lots of things I see I'm running out of time here, but there are lots of things
we can talk about, about what.
Well, let me just say a couple of other things about, I'll talk a little bit about AI.
I mean, the AI has had many different meanings over the course of time, and many things
where people have said, if we can only have that, then we have AI are things that I've
built as kind of pure computational systems, and then people say, well, it's just a computational
system, it's not really AI.
And in more than a second, just one second, I want to, you do have more time, because
for some reason, and I can't explain, Kayu has been extremely conscientious in everything,
he's not here, which may mean that he had misunderstood being a discussant for being
a member of the panel, which means he won't be here until the panel starts, in which case
you have more time if you wish.
I just compressed four and a half decades into a remarkably short time, I hope people
could follow it.
Nothing, you could have taken quite some of this time.
Well, okay, so let me let me finish what I was saying here, and then maybe we can turn
this over to discussion, which is more fun for me.
So talking about kind of modern AIs, and you know, to many people, modern AI is neural
networks, and the, there's sort of a question of, well, what can, how do neural networks
relate to all of the things I've been talking about?
And one of the questions we can ask is, okay, we have, we have our friendly neural nets
here, let's see, oops, share the screen and then, okay, we have some typical trained neural
net, let's say we're trying to train it, let's say we're trying to train it to reproduce
the sine wave.
So what we're doing is, we're going to feed in the X value at the top there, and we're
going to have set up these neural net weights, and it's going to compute the Y value down
here.
And actually, we'll do a pretty crummy job of that typically.
And you can, you can change the neural net, you'll get different kinds of behavior, it's
usually not particularly good at computing something like this.
Well, so one thing you can ask is, you know, neural nets, let's say if we have a big enough
neural net, maybe we can break computational irreducibility, maybe we can just predict
what's going to happen in a kind of system.
That is not going to work.
I mean, the way that a neural net of this type works, it's just having kind of numbers
ripple through the sequence of layers.
And we're ending up with something where you can, this is something trained, I used a modern
transformer architecture and trained it to try and recognize what was going to happen
in a cellular automaton.
And it has certain, it says, well, there's certain probability of what's going to happen.
But when the behavior is pretty simple, it'll nail it.
When the behavior is more complicated, it's like, I'm sorry, I can't figure that out.
This is different levels of training of one of those neural nets.
So in a sense, not surprisingly, the kind of very finite computation of these layers
of a neural net can't do the unboundedly large computation required to kind of solve
a computationally irreducible problem.
And you can see that again, let's see, where do I have an example here?
This is, these are examples of the three-body problem in celestial mechanics, Earth, Moon,
Sun, all idealized, all with interacting through gravity.
You can ask the question, if you train a neural net, can it correctly reproduce the behavior?
The answer is the neural net is the kind of solid line here, that's its prediction.
When the behavior is fairly simple, yes, it can do it.
When the behavior is kind of computationally irreducible, no, it can't do it.
None of this is really very surprising.
But there's kind of a question, for example, when we look at something like chat GPT and
we say, oh, my gosh, it actually worked.
It produced something that is like human language.
How did that work?
What I think is the main thing going on is something which tells us a lot more about
human language, probably, than it does about neural nets.
Because what it's telling us is, if we think about how does chat GPT work, it's basically
just saying, I'm going to predict the next word by figuring out certain probabilities,
and it's going to do that by, at the very simplest level, it might just do it by knowing
the frequencies of different letters.
And then if you just use the frequencies of different letters, you get pretty much nonsense.
If you use blocks of letters, you'll start getting more sensible kinds of things.
If you use kind of whole words occurring with the probability that they occur in English,
you'll get things that don't make much sense, but they're kind of things that can construct.
Now the big thing that's interesting and surprising is that when you kind of train a neural net
kind of all of the text, a trillion words of text or something, that the extrapolations
it makes about what make meaningful sentences tend to agree with the extrapolations that
we humans would make about that.
It's very similar to the fact that if we train a neural net to recognize cats from dogs and
images, that the distinctions it will make seem to be similar to the distinctions we
will make.
At a theoretical level, if we say, where's the dividing line between cat pictures and
dog pictures, there isn't a good mathematical characterization of where that dividing line
is.
It's really a question of where do we humans say is a dividing line between cats and dogs?
And the thing that's interesting about neural nets is they tend to make the same kinds of
decisions about that that we tend to make.
Probably the reason is that ultimately their architecture is similar to the architecture
of our brains.
But the main point is that those kinds of distinctions, there's not a theorem, there's
no theorem that says the neural net will reproduce the distinction between cats and
dogs because you don't know what the target is.
The target is what do humans think is going on there and it does a pretty good job at
that.
So now the question is, in the case of language, what's going on?
And I think what's happened is that the thing that allows an LLM to produce reasonable
language is something that is a regularity of language that we could have recognized
a long time ago, but we didn't.
And so we know certain regularities in language.
We know that, for example, in English, you tend to have sentences that go noun, verb,
noun.
But there are plenty of sentences of the form noun, verb, noun that are total nonsense.
So the question is, you have this kind of syntactic grammar of language that says that
you go things like noun, verb, noun.
But now you have the question of, well, what noun, verb, nouns actually make sense?
And so what I think chat, you know, chat GBT and LLMs and so on are kind of showing us
is that there is also a semantic grammar of language.
There's also a construction kit, not only of what the parts of speech might be, but
also what kinds of words they might be to have them make sense.
And that's something that eventually kind of sort of expands up to write a whole essay
and have these puzzle pieces fit together in a way so that the whole thing makes sense.
So in a sense, what one's seeing and one can kind of look at, let's see if I have some
pictures here, maybe I have some pictures.
Yeah, these are very ancient, actually.
There's better ones now for GPT-4 of kind of, to what extent can you kind of imagine
semantic laws of motion where you're kind of moving around in meaning space and where
just like Newton's laws tell you in physical space how you move from one, you know, how
motion happens when in the absence of a force you just keep moving in the same direction
and so on.
So you can ask questions about rural space and you can ask questions about kind of the
structure of rural space and how that works.
And I think we're kind of learning some scientific things from the operation of LLMs about how
that works.
Now another question would be, so in other words, I think the reason LLMs work as well
as they do is because there are a bunch of regularities in human language that we kind
of didn't know were there and that we've never really codified.
People started codifying these things back in the 1600s, for example, people tried to
invent these so-called philosophical languages that would be kind of not specific to any
particular language, but they would be things that sort of represent the meaning of things
without the specificity of particular languages.
Well, actually, I've had a project for a while now much more energetic to make what I call
a symbolic discourse language, a language where just like in Wolfram language, we have
this computational language that describes many aspects of the world.
I mean, we might have all sorts of different sort of categories of thing that we describe
in our language.
And the question is, can we kind of describe all, can we describe sort of things that come
up in everyday language?
Can we describe those kinds of things in a sort of precise symbolic way?
And I have to say that I can't say I've got the full answer to that, but it's going really
well and it's become clear, and by the way, LLMs are quite helpful in this, to having
a way to take something not the level of language where we're actually putting words together,
but the representation of the core meaning of what's going on.
Just like in our computational language, we have that representation of sort of the
core meaning of what's going on in a way that can be read by humans, but also executed
by a computer.
So in any case, that's sort of one direction about things with LLMs and so on.
Another question I was curious about is, okay, why does machine learning work at all?
Why is it the case that you can train one of these neural nets to do something like,
I don't know, recognize digits or recognize cats and dogs or generate language or whatever
else?
Why does that work?
You know, when I played around with neural nets back in 1981, and I couldn't get them
to do anything interesting, and I kind of thought at the time, oh, if I've got a simple
enough problem, I'll be able to get a simple neural net to do things, didn't really work
very well, wasn't very interesting.
The big thing that got sort of accidentally discovered basically in 2011 was that if you
have a big neural net and you bash it really hard, you show it enough training examples,
it'll learn, well, lots of different kinds of things, it'll learn almost anything.
And the kind of the big meta discovery of modern machine learning is that if you bash
a neural net hard enough, it'll learn almost anything.
We don't know quite what the almost is, we can't really characterize what kind of thing
it can learn.
For example, as I said, it can't break out of computational irreducibility.
So there's limitations to what it can learn, what it can do, but nevertheless, there's
a broad class of things that seem to correspond a lot to kinds of things that we humans can
do easily that the neural net can successfully do.
And so that's sort of the meta discovery.
Question is, why does that work?
Why is it the case that this neural net can be successfully sort of bashed into learning
things?
Why doesn't it get stuck?
Why doesn't it get to the point where you just can't get there from here, you can't arrange
it?
Why is it the case that it's possible to do it and then why is it the case that you can
iteratively do it by sort of adaptively training it?
I got interested in this very recently, actually, and I don't know that I can show you pictures.
Let me see.
I can show you some things that I did recently, and then maybe I'll be able to pull up some
pictures just from the last few days that, let me see here, right.
So actually, I decided to look at a simpler problem, which is the problem of biological
evolution, which is sort of another case of adaptation that is a little simpler than
neural nets.
But let me explain what I figured out about biological evolution.
For a long time, I'd wondered what sort of the minimal model of biological evolution
that was always very unsatisfied because models, natural selection seems like a simple principle,
but when you actually try and make explicit models for it, you end up with all kinds of
hair about how many suboptimal organisms do you keep and all this kind of thing.
So I was interested in sort of a minimal version of that.
So here's a version of that.
This is actually one of these cellular automata.
It's got these rules here, starts off from one red cell here, and with these particular
rules, you get a pattern that lives for this amount of time and then dies out.
Okay.
So let's imagine that you're interested in doing something where you just keep on tweaking
the rules, you keep on resetting the rules, you keep on making single point mutations
in the rules to try and get it to live longer and longer.
This is what happens.
You start off from something that is just a blank rule.
For example, it dies immediately.
You keep tweaking the rule, you have to go through many different tweaks and so on, but
eventually you'll get to the point where it lives there for 50-something steps.
Well, and you can see that the sequence of mutations that got made there, and if you
look at how the fitness of this organism, the length of time it lived, varies as you
go through all these different steps of adaptive evolution, you'll see it's going along and
there are many things that don't work out, but it'll cruise along here at a certain fitness
and then it makes a discovery and then it can go to higher fitness.
And actually, you can end up with all kinds of discoveries that it makes.
These are different parts of evolution, and you'll see that for example here, it's going
along and eventually it manages to discover a lot, it manages to live a long time.
You could sort of imagine in the fossil record, you might find a critter from the Cambrian
period that looks like this and then it uses that idea to extend further and by the time
it's in the Silurian period, it's looking like this and maybe it makes it to this in
the Triassic period or something, but what's happening here is that it's having progressively
more ideas in a sense about how to live longer in this particular case.
And actually, you can even go ahead, this is a simple enough system that you can actually
work out.
Let's see, that's an example, a better example, there we go.
This is the path of all possible paths of evolution for a simple system like this.
So every different picture here is a possible organism and the arrows show the possible
adaptation paths.
And what you see is something that's very much like what happens in biological evolution.
There are different branches in the tree of life.
There are one set of ideas leads to long life over here in this way, a different set of
ideas leads to kind of long life over here in a different way.
Okay, what does this have to do with machine learning?
Well, you can ask the question, let me see if I can pull this up.
I am going to have to pull up something that I just made, so I'm not sure whether I can
find it here.
Hold on, you can get hot off the press or not really off the press at all.
Where is it?
Let me see, maybe, see, maybe this will have it, oh yeah, this might be it.
This is a very minimal model for, let's see if I can get this bigger, it's a very minimal
model for a neural net where it's actually a cellular automaton as well.
But instead of having a fixed rule that it keeps on applying, kind of like a recurrent
neural network, it has something more like a feed forward neural network where you have
a discrete choice of one of let's say two different possible rules and at every point
in space time, so to speak, you're picking a different rule.
And so then the learning consists of what's the pattern of rules you should pick to get
a particular outcome.
In this particular case, we're trying to learn to live as long as possible.
And what's interesting here, and again, this is just raw, literally raw material from a
couple of days ago, this is kind of showing in a sense how the thing does what it does.
So in a standard neural net, it's just much more complicated to display what's going
on.
You've got these neurons with continuous weights, and you've got connectivity all over
the place, and so on.
This is a much simpler case, so you can kind of see more about what's going on.
What's non-trivial is that training actually works in this case, and it does.
You can find this arrangement of bits that will cause the thing to do, I don't know
whether I have it in this example here, but that will cause it to learn, let's see if
I have one here, now those activation levels, well, it doesn't matter.
That will basically cause it to learn something like, you know, to tell whether the number
of bits at the beginning is even or odd or something like this, and we actually even
tried training this on the MNIST training set, and it doesn't do too badly.
So the point here, the thing that's interesting here, these are all different solutions that
this kind of very idealized neural net found to living for this exact number of steps.
What's interesting about these is they're very bizarre.
They're not sort of engineered solutions.
They're not solutions where we can say, oh, yeah, let me look inside and see how this
works.
Let me show you another example of that.
This is more back to the biological evolution case, this is kind of all the different ways
that a certain class of systems manages to live a long time, and some of them it's kind
of pretty structured.
You can imagine sort of this was an engineered thing, but some of them, it's like it just
seems to sort of happen to live that long and then it dies out.
So in other words, there's a lot, and by doing this sort of adaptive evolution, you're ending
up finding these things which are very not, they're not mechanical, they're not engineered
kind of ways that things work.
They're things where kind of this is sort of what's happening inside.
This is the thing that's going on, but it's not something where you can say, oh, I've
got a mechanism.
By the way, if you're interested in neuroscience, this is something you should pay attention
to because in a sense, if you're trying to explain what's happening in the brain and
you say, oh, I'm going to figure out how this works, well, how this works is an attempt
to have kind of a human understandable narrative for what's going on.
But if I were to look at these pictures in the background here, if this was something
going on in a brain, I might be able to say, okay, I can have some human narrative about
what's happening here.
If this is what's going on in a brain, it's just, well, it happens to work that way and
it happens to give this result.
It's kind of a computational irreducible story.
It's something where there's no sort of narrative mechanistic explanation.
It's something which just works that way and it's computationally irreducible, but it just
comes out in that fashion.
And I think there's sort of an interesting question in machine learning, why does machine
learning work?
Okay, so let's look at, there's a nice picture of that.
Yeah, by the way, this is in biological evolution.
People often talk about fitness landscapes.
This is an actual fitness landscape, correctly drawn, so to speak, and you can start seeing
all kinds of things about things evolving on fitness landscapes, but the thing I really
wanted to show you, here it is.
This is kind of the local behavior at a particular point in rule space at various steps in the
adaptive evolution.
So what's happening here is at this step, for example, in the adaptive evolution, here
are different possible directions in rule space that you might go.
And the ones inside the circle are ones that are losers relative to where you've already
got, they're ones that would live less long than what we have here, but there are some
that would make progress.
And in fact, this is the one we happened to choose in this particular random sequence
of adaptive evolution steps, and that was the thing that made progress.
So the thing that is not obvious is, in this sort of high dimensional space of possible
ways you could go, the question is, will you always be able to make progress?
Will there be a direction that makes progress, or will you get stuck?
Well, I think that this is again a computational irreducibility story, that basically what
would make you get stuck, well, if the structure of this rule space was very orderly, very
reducible and easy to predict, you might end up in a box with very precisely defined walls
and you just can't escape from that.
But the presence of computational irreducibility kind of implies a certain degree of unpredictability
a certain degree of intrinsic randomness effectively in the structure of rule space.
And that's what means that in these high dimensional spaces, there's always a kind
of a path to success.
So in a sense, I think computational irreducibility, which is a limitation on what one can do with
for example, a neural net, what kinds of things computations one can expect to do is also the
reason that training of neural nets, for example, can work.
And so I think that's anyway, this is still an in progress kind of investigation.
But I sort of think it's an interesting connection between a lot of different things I've talked
about.
All right, I've gone on longer than I intended to.
So let me wrap up there and I'm happy to have a discussion, questions, whatever else.
I just fed you an awful lot of material.
Yes, let's first applaud this present one.
The problem was that Caillou had an emergency during the during your talk, so he couldn't
hear it.
Caillou, do you think that you have from the background material you might have looked
at you have a basis for saying something?
Sorry, I missed most part of the time.
So probably you won't be able to.
If you haven't seen this is this is a large amount of material you won't I would be surprised
if we could have a useful conversation without having some some anchor to this.
Then could you please explain to Caillou and to me and to us how computational irreducibility
differs from ABC, Cormagor of complexity, the church touring thesis and NP completeness.
Okay.
All right, let's start off with Chaitan-Cormagor of complexity.
So when we look at a picture like this, the the algorithmic complexity of this picture
is tiny.
That's the program that's needed to produce it.
Just a few bits.
The thing that is remarkable is that even things with very low algorithmic complexity
are very complicated.
In fact, they're complicated enough that to us humans, we wouldn't even be able to distinguish
them from things that have high algorithmic complexity.
One of the things I've sort of had a long running discussion with my friend Greg Chaitan
where the question is, is the universe like Pi or like Omega?
So Omega is this thing that Greg invented 50 years ago, actually, that is the halting
probability for a universal Turing machine.
It's a fundamentally non-computable object.
It's an object with with infinite algorithmic complexity.
It is a thing where there is no there's no small program that that you can't specify
it by a small program.
Pi on the other hand is a thing that is specified by a, you know, a quite a small program.
And once you once you generate its digits, it looks for all practical purposes random.
So the question that one can ask is, in our universe, is there anything of high algorithmic
complexity, or is the whole universe actually a thing that is like Pi generated from something
which is a very simple underlying sort of program?
And in our model of physics, the answer is, the universe is is like Pi, the universe is
something that is is generated from a thing of very tiny algorithmic complexity.
So so that's kind of the distinction between everything I'm talking about is things of
incredibly low algorithmic complexity.
The remarkable fact that is not obvious, it's kind of a breaks one's intuition is
that things very simple programs, things are very low algorithmic complexity can produce
what seems to us like great complexity.
And the seems to us becomes much harder when we start talking about our computational boundedness.
It's not the case that it's just, oh, it's sort of it seems complicated.
It's that for a computationally bounded observer like us, there is no way to compress it.
So in an algorithmic complexity, algorithmic information, one saying, this is the program
and there is no shorter program, one can say, for a computationally bounded observer, this
is the set of bits, and there is no way to make it shorter.
So that was that was algorithmic information theory algorithmic complexity.
I think the second one you had was some, what was it, church churning, okay.
So, so, okay, the, the thing that if you go back to the beginning of the 20th century,
and you'd wanted to get an adding machine, might go to a store, you buy an adding machine,
you want to get a square root machine, okay, you go to a different store, perhaps, and you
buy a different machine that is the square root machine.
The big discovery that actually originally got made by Moses Schoenfinkel with combinators
in 1920, but nobody understood it then or since basically, but then kind of got clarified
by by by Turing in 1936, is that there exist kind of, there exist systems that are universal
in the sense that you can have a single piece of hardware that by feeding it different initial
conditions by feeding it different inputs, you can make it compute different kinds of
things.
You can have a Turing machine that has some, where just by feeding it different initial
conditions, it will emulate any other Turing machine.
So, for example, if we go to, in terms of Turing machines, there's some, I'm going to
show you something, there we go.
Well, so, so the big point is, there exist machines that are universal in the sense that
they can at least emulate all other machines of their type.
The thing that then became clear, starting in the 1930s, is that Turing machines, you
can have a Turing machine that emulates every other Turing machine, it also, by the way,
can emulate every register machine, every lambda, piece of lambda calculus, every con
combinator, and so on.
So there's this notion that in the class of computational devices, there's a certain
degree of universality.
People had not thought that that extended to physics.
That was a thing that basically was my effort in the 1980s, was to kind of imagine that
this notion that what is computationally computable would also be what is, what can happen in
physics.
People had sort of assumed that physics kind of breaks out of kind of this computational
paradigm.
It has real numbers, precise real numbers, has other kinds of things like that.
So the first thing is the realization in the principle of computational equivalence.
The first thing is kind of the claim that, well, first part of it is sort of a physics
part that, yes, actually, in the physical universe, this is all we've got.
We can't say, oh, we're going to make an analog computer that jumps beyond kind of the church
Turing level.
Second point is this.
People imagined that to make a universal machine was a complicated matter, was something that
would be kind of, you know, you have to build this whole microprocessor, it might have a
billion gates in it, it has all these instructions, it's got if statements, it's got all this kind
of structure.
And the question is, well, what's, you know, is that really necessary?
Or is universal computation actually something much more naturally occurring?
Is universal computation a special thing, have to go to a lot of trouble to get?
Or is it something that's just sort of lying around the computational universe?
One of the big points to the principle of computational equivalence is, yes, it's just
lying around the computational universe.
So, for example, if we look at these different possible rules here, some of them behave in
such simple ways that we can readily see what they're going to do, they're computationally
reducible, there's nothing more to say.
But some of them behave in a complicated enough way that we're kind of not really sure what
they do.
Let me show you an example of one of those.
So this is, let me show you rule 110.
This thing actually only grows on one side here, but to show that, I shall make it just
show just the part where it's growing.
So that's that's if after 200 steps, let's run it for 1000 steps.
Okay, there it is.
It's a little bit unclear what it's going to do.
This is kind of computational irreducibility in action or undecidability ultimately in
action.
What's it going to do?
Is it going to have all those little little things, structures, are they going to survive
or are they eventually going to die out after I think it's about 4500 steps?
They do eventually all die out and they just get left with this one single structure here,
but it's kind of computational irreducibility in action.
You can't tell what's going on.
This particular rule turns out if you just look at it, let's start it off from random
initial conditions.
Let's say 600 across, no, let's say 1000 across, and let's say 800 down.
Okay.
Oh boy.
It's a little bit on the screen here.
Let me make it a bit bigger.
Okay.
There we go.
So what you see there is that's like that's the initial condition.
This is what happens.
What you see is a bunch of little structures here, and you might imagine as you look at
these structures, oh, they're kind of interacting and maybe that's like a logic gate and maybe
we can make an OR gate out of this and so on.
It turns out with considerable effort, you can do that and you can show that rule 110,
which is kind of just the 110th rule in this very simple enumeration of possible rules,
it's universal.
The first one that you might imagine could be universal is actually universal.
So in a sense, the church-turing thesis is saying it is possible to have a universal
machine, at least universal within the class of computational devices that we're talking
about.
The principle of computational equivalence says not only is it possible, it's also generically
the case that it is ubiquitous, and in fact it goes on to talk more about individual computations
rather than programmability, but that's kind of a bonus.
By the way, in terms of Turing machines, I was very curious what is, you know, if you
just look out in the space of possible Turing machines, just start enumerating Turing machines.
The first one whose behavior is not obviously simple as this one here that I found sometime
in the 1990s, and so then I was really curious, is this in fact a universal machine in 2007,
I put up this little prize and a chap called Alex Smith managed to show that, yes, this
particular Turing machine, the first conceivably universal Turing machine actually is universal,
which is a nice piece of evidence for the principle of computational equivalence.
So that's kind of the relationship between church-turing and principle of computational
equivalence, and computational irreducibility is something that is sort of, it's made tougher
by the fact that this property of universality is ubiquitous in the computational universe.
Okay, thank you.
MP completeness.
What's that?
We have a question here already, so.
Wait a second.
You get me.
Go ahead.
My software is not empty yet.
So you asked about MP completeness, so let me try and address that.
So normally in a Turing machine, for example, you have this Turing machine, it has a rule,
you start it off from some initial condition, it just evolves in some specific way, it has
a specific history.
But you can also have, let's see if I have a picture of this, I have a bunch of these
multi-way systems well here, let me show you, find some multi-way Turing machines, there
we go, multi-way Turing machines.
Okay, so that's a typical Turing machine, has a rule, it evolves in a particular way.
But you can also have a multi-way Turing machine in which there isn't just a single
possible path of evolution, but there are many paths, so you can end up with this kind
of branching structure.
This turns out to be closely related to what happens in quantum mechanics, that's a separate
issue.
And so this idea of NP completeness, NP problems versus P problems and so on, it's this question.
If we have a Turing machine and it computes something and it takes a certain number of
steps to compute it, an ordinary Turing machine might take n-squared steps to compute a size
n version of some problem.
But we can also have a non-deterministic Turing machine, we can have a multi-way Turing machine
that follows many different possible paths.
And we say, if we have a path that gets to the answer, then it's a winner, so to speak.
And that's the story of NP problems, non-deterministic polynomial time problems, are ones where there
exists a path in this multi-way Turing machine, which gets you to that answer.
So in a sense, this question of NP, sort of the big question, is P equal to NP, is the
class of problems that you can solve within polynomial time with an ordinary Turing machine,
the same class or different class, than the ones that you can solve with a non-deterministic
with a multi-way Turing machine.
And actually, that question, so, well, let's see, I mean, we can talk about computational
irreducibility and its relationship to computational complexity theory in general, but NP completeness
in particular, there's perhaps a more interesting thing to say, which is, if I can make, find
this one, this one here, okay, so we can look at all possible Turing machines.
This is, in a sense, in rural space, where is this nice picture somewhere here, do I?
Yes, here we go.
Okay, so this is a picture of kind of the behavior of all possible multi-way Turing
machines.
So in a sense, all possible programs.
And this is showing sort of all possible non-deterministic programs.
The red part is the part that's showing deterministic programs only.
It's not allowing the possibility of the rules changing, so to speak, as you go through the system.
So the P equals NP problem, one of the things that's pretty interesting that comes out of
our physics project is essentially a geometrization of the P equals NP problem, that is a question
of the structure of these objects in rural space, that P equals NP becomes the question
of whether essentially the red bit here eventually fills out the gray part of this picture.
So you can kind of have a geometrical version of this ball in rural space that corresponds
to the P problems and the NP problems.
So that's a little bit of an indication of that, but you can, I mean, this whole question
about non-determinism and so on, it's a, oh gosh, there's much to say about that.
I've studied this a lot because it ends up being a sort of a proxy for quantum mechanics.
What happens in quantum mechanics is that you are following many paths of history and
the observer in quantum mechanics is effectively a sort of an interesting situation.
The observer is branching in the same way that these actual paths of history in the
universe are branching, so quantum mechanics becomes this question of how does a branching
mind perceive a branching universe?
And so it's interesting to kind of see a bunch of different examples of multi-way systems
as a way to get sort of more intuition about that.
Okay, another question, apparently.
Well, let's bring it back to our universe just for now.
I want to, if possible, in a few minutes left, because I don't want to say anything, I want
to make a connection between what you said and what Kyle, what you said before.
His program was related to computer aided proof and transformation of verbal, verbally
stated truths and conjectures into formal form called auto formalization.
And my question to you is, what does the irreducibility principle say about all the possible
theorems and the possible paths to their solution?
And Kyle, I mean, Kyle, you can say a couple of words in response, but you have to say it
in your own words first because you missed your talk.
Well, let's see, I wrote a book recently about the physicalization of metamathematics,
which I think is pretty relevant to this.
And so, you know, we can imagine some, let's see, where's a good example?
This is, that might be some axiom in a mathematical system.
And we can ask the question, what are the consequences of that axiom?
That axiom is saying x dot y is equivalent to y dot x dot y.
And now we can say, well, what things are also equivalent based on that axiom?
We can start figuring out, so every path here is a theorem that that's equivalent to that.
We can start just following, we can start making this network of all possible equivalent things.
And actually, and so a proof becomes a path in this whole network.
And actually, it's a little bit trickier than that when you start looking at
what's a good example here.
The way one actually does, let's see where I've got a good example.
Okay, so this is an example of what more is actually what's happening in mathematics.
You have basically, let's say two axioms here, and you are combining them to get a new theorem.
And so you can kind of build up this kind of this structure you get with those two green axioms.
You're deriving all those theorems.
You get this big network that represents all possible theorems derived from a particular
set of axioms. So you can go on, you can get pretty complicated versions of this.
You can derive all sorts of theorems that are true based on certain axioms.
And what's happening is in this in this graph, the every blue dot is a theorem.
Okay, so then you can ask the question, if you look at, I have an example of this,
if you look at actual axiom systems in present day mathematics.
So for example, you can look at, there's the axiom for semi groups.
You can start proving theorems about semi groups.
Okay, so we've got this whole network of theorems about semi groups.
And so one big question is, if you do that, well, okay, so here's an example based on
the axioms of Boolean algebra. So this is proving theorems based on axioms in Boolean algebra.
And you can go and you can build up this giant network of theorems of Boolean algebra.
And this is kind of the enumeration of all possibilities.
Okay, so now the question is, is we enumerate all those possibilities?
Where are the theorems we care about? We've got gazillions of theorems that we can just build out
eventually. And this is kind of spoiled. If you didn't know, you don't haven't followed this,
but this really odd object that I talked about in the talk I gave, that is the ultimate limit
of all possible mathematics is this really odd object. And the question of what
theorems are, so all these theorems here are true. All these theorems can be constructed
from the axioms. But these are the only two theorems that people give names to in textbooks
of logic out of this collection. We can keep going. We can find, we can go to lots of other
theorems. If we use a theorem proving system, we can, in that big giant explosion of possible
theorems, we can go and say, this is the theorem we're searching for, and we can find a path to it
using theorem proving. And those are the paths in that structure of possible theorems.
Okay, so one question then is, well, out of all these possible, this complicated network
of all possible theorems, where are the ones that we humans care about? And so I looked a little
bit at that. And so, for example, you can, you can look, well, that's, that's, for example,
that's Euclid. So Euclid has 465 theorems, and you can start off from the axioms at the top,
and you can see what are the connections between those theorems according to the proofs in Euclid.
Perhaps more interestingly, you can take a proof assistant system. I looked at Lean.
I looked a little bit simpler to look at the system called Metamath,
which is a formalized math system. And you can ask questions like, well, that's the Pythagorean
theorem, proved from the axioms in Metamath. And you can see they're a different, it's a pretty
complicated thing. This somewhere, I think at the bottom here is the Pythagorean theorem,
and you start from the axioms there, and you can kind of count up of the various axioms,
you know, how many times did you use the axiom of equality? Five times 10 to the 31 times.
This is a, you know, this is kind of a, this is what happens if you start from sort of the
axiomatic foundation, and you build up to something like the Pythagorean theorem.
So okay, so one interesting point here is, this is the axiomatic sort of structure of the Pythagorean
theorem. The question is, do mathematicians care about this? So, you know, a decade ago,
I was very interested in formalization of mathematics, I organized this conference,
we invited all these formalization of mathematics people, all these people interested in mathematics
itself, the formalizers all showed up, the mathematicians didn't show up. The, and so the
question is, what does a working mathematician actually do? You know, working mathematician
who's, who's thinking about the, you know, the Pythagorean theorem, are they thinking about it
in this kind of axiomatic way? Are they drilling down to kind of this, this low-level axiomatic
structure? Or are they just saying, it's the Pythagorean theorem, and I'm going to do things at
that level. The thing that's pretty interesting and relates to a lot of what I was talking about is,
at this kind of axiomatic level of mathematics, it's kind of like molecular dynamics in a,
in a fluid, you've got all these molecules bouncing around, they're doing all these complicated
things. But then at the higher level, at the more human level, what we get to see is fluid dynamics.
And we can ask the question, can we make conclusions at the fluid dynamics level,
or do we get dragged down to the molecular dynamics level and have to address things at
that level? So in the question of, you know, using the Pythagorean theorem, for example,
do you need to go down to the level of these axioms and worry about how you define the real
numbers and so on? Or are you actually operating in practical mathematics at a higher level,
at this level where you're, you're just operating in terms of, of, of these kind of
sort of fluid dynamics type concepts. So I have to say, I was curious in, you know,
in the, in sort of the world of LLMs and so on. So I will say that the mission of taking kind of
a piece of informal mathematics and formalizing it seems like a fairly, fairly promising use case
for things like LLMs. I don't know whether the formalization in terms of, you know,
existing proof assistance and so on. I don't know how useful that will really end up being.
I was curious whether you could use LLMs as a way to, as a way to,
to kind of guide theorem proving. So I looked here at, here we go.
May I make another suggestion instead of looking at, let Caillou answer, just a second,
because there's so little time now we can continue. Right, please. Let me just ask a very
practical question. I have another thing in 30 minutes. Am I, I could push it back,
but am I going to make that or not? Yes. The other thing in 30 minutes is the
plan. Is the panel, were you, were you planning? Really? Are you going to do something else?
Well, I don't know. It really depends. But Daniel said that you were going to do both.
Okay. All right. I think she, if you got the other thing from Danielle,
it is in fact the panel. No, no, no. It's a completely different thing, but that's okay.
We'll, we'll, we'll, we'll tell you a panel. That's great.
Say, please. Yeah. I think the short answer is yes. Yes. People are using informal mathematics
and auto formalization, which means translating informal to formal to guide theorem proving.
For example, given a proof, you can use language model activity for to, you just ask it to
generate the informal proof or even a sketch, some ideas of could be high level idea of how
this proof might go. And then conditioned on this informal sketch, you, there will be a
second step to generate the formal proof. And, but I think a caveat is if you rely on auto formalization
to give you the proof, it only works if human already discovered this proof. Because then there's
no, if not, if it's completely alien to mathematics, then there's nothing for you to auto formalize.
I think another direction related to what Stephen mentioned is, how can we even take
one step further? Can we use language models to generate conjecture, like generate the huge graph
Stephen was mentioning, but of course the graph, I think it might be infinite or it may be simply
too big. So a really interesting question I want to maybe learn from Stephen is say we want to
generate this graph, but how do we tell if a node is worthy? Like if a mass statement is
interesting, because I imagine in this infinite graph, most of the nodes will be just garbage,
like two greater than one, three greater than two. But we really want to focus on this
interesting nodes. Yes, it's an interesting question. So I've looked at this a bit.
And I can tell you that in the case of Boolean algebra, there is a criterion. So if you, maybe
I can pull up a picture of that. If you order, here we go. Hold on. Let's see. If you,
if you order the theorems of Boolean algebra in, in lexicographic order, then you can ask which
are the theorems of all possible theorems, which ones are given names in logic textbooks.
And sort of a surprise to me is the theorems that are given names in logic textbooks are the
theorems that have, in this case, no backlinks. So there's a backlink from this result here,
which might be one of your boring results. This result is derivable from something earlier in
this lexicographic list. So in a sense, it gives you no new information. It turns out the ones that
get given names are precisely the ones that do not have backlinks. They are not derivable from
lexicographically simpler theorems. So in other words, I was surprised that I discovered this
sometime in the 90s. I was surprised by this, that there was actually a criterion for
what would be given a name in a logic textbook. Now, the general case of, is this theorem interesting?
You know, can we learn enough about the humans to know what they'll think is interesting? It's
a good question. I mean, by the way, in this, in this connection to informal and informal, obviously,
you know, orphan language gets connected to LLMs. And we've done lots of work in kind of tool calling
from LLMs to orphan language. And there's this whole question of, can you take, you know, to what
extent can you get the LLM to crisp things up to the point where you can, I don't know, I mean,
if I say something like draw a pentagon and a hexagon, for example, let's see what it does. I
don't know if it'll figure it out or not. You know, it might be able to, or, you know, we could,
you know, the question is, can we generate, okay, can we generate a, can we turn that informal
statement into a piece of formal orphan language code? Okay, not bad to manage to do that one.
And if we, if we look here, I'm sure we can get it to, yeah, there we go. So that showed us the
actual code that did that wouldn't have been the way I would have done it, but it's okay. That was,
that's a, that's a reasonable way to do it. But so this is a case where we're going from an informal
description to this computational language, which we can then compute from. And that's a very
powerful thing to do. And in fact, we even have a product that's coming out soon that is based
precisely on that idea. But so I think, you know, this question of whether you can sort of, you
know, can you guide the proof this way? I suspect you can. Now, this question of what, what is a
human proof? What's, okay, this is an example. So in, in automated theorem proving, one of the
shocking things about automated theorem proving, I believe you might correct me and tell me one day
somebody is going to tell me I'm wrong about this. But so far as I know, essentially, all the theorems
that have been proved by automated theorem proving were theorems that somebody already believed were
true. In other words, there is no, there's no newly discovered thing that came from automated
theorem proving with one counter example. The one counter example is something I found 24 years ago
now, which is this is the simplest axiom system for Boolean algebra. So you can, this is, that's a,
you can think of that as a NAND operator. This is of all possible from that one axiom,
you can just derive all the true statements of Boolean algebra. The proof of that is this
long 100 step automated proof. Let's see if I have a picture of it. Yeah, I mean, that's sort of
some kind of visual representation of that proof. It has various popular lemmas in it and so on.
In the last 24 years, despite quite a bit of effort, actually,
nobody has ever understood this proof. But it is interesting because it is a proof of something
surprising, potentially interesting, depending on whether you care about simplest axiom systems
for things. But it was found by automated theorem proving without, you know, without already knowing
what you were searching for, so to speak. And, you know, that's a case where now you ask the
question, if you're out in the wilds of, you know, in the, I mean, we can, we can look,
do I have a nice picture of this? We can look at, oh, here, let's, is that one? Yeah, this is,
this is, these are axiom systems down the left. Those are theorems across the top.
And there's a dot, a blue square, whenever that theorem is true in that axiom system.
So we can ask the question, given an axiom system that we decide is exciting, and how we decide
that is an interesting question, it's unright. But given an axiom system, we can say, you know,
here are the theorems that are true. Now, which are the theorems here that we care about? And that's,
you know, that's essentially a model for humans. And I think it's an interesting question. We've
done some experiments kind of grinding up archive and so on, and trying to figure out, you know,
can we deduce what, you know, in a space of possible theorems, what theorems are likely to be
interesting? I don't know if you've looked at that. Is that, I think that's an interesting
thing to look at. Have you looked at that? Yeah, I think the way I'm looking at it is more,
so I kind of am not considering its relationship with other theorems. I'm taking the theorem
statement itself and try to have some, for example, have the language model telling me
whether it's interesting. I believe the language model can look at some kind of superficial cues,
like how long the theorem is, and how, what are the variables, how they are arranged,
how messy it is, and which can already give us some way of, like, judging how interesting it is.
But I agree, like, maybe ultimately, what an interesting theorem is,
it can help you prove a lot of other theorems. Is that your definition of an interesting theorem?
I'm not sure that's right. I mean, in other words, there are, you know, that is one possible
way, I guess. I mean, there are many different criteria you can imagine for
interestingness. That particular one would be saying that if that was the correct criterion,
okay, then what you could do, like I was just showing that picture, actually, in the Boolean
algebra case, wherever it is, then I would deduce from your statement that the theorems that are
big here are the ones that have many, those are the high out-degree theorems. So in other words,
those theorems, that theorem there should be the one I should care about. I don't understand these
theorems, honestly. What's that? I mean, in that sense, yes, because they are special in this graph.
That's right. But the question of whether those are human useful is, I think, a different question.
I mean, in other words, what is, you know, there's this question. It could be the case that two,
okay, first question is, if you look at many different possible things you might prove,
you can ask the question, are there repeated theorems that often, are there repeated lemmas
that often come up in those proofs? Okay. So I looked at that. And the answer is there are.
And so, for example, that axiom system of mine for Boolean algebra, if you use it to prove
theorems in Boolean algebra, you can just look at what intermediate lemmas does a theorem prove
are typically proved to make progress. And the answer is, for example, it takes it 100 steps
to prove the commutativity of NAND, and it often does that and then goes on and does other things.
So in that sense, you know, you can, I mean, it is an interesting experimental question.
To what extent are there repeated lemmas that show up? And that might be a criterion, but
that's the criteria has nothing to do with LLMs and so on. That's a criterion that just has to
do with the mathematical graph. I think this question of, you know, if we look at images,
for example, you didn't see what I was showing earlier, but here I'll pull up a,
I was just showing something like this. This is in, you know, embedding space of a generative AI
system with in the middle is the cat in the party hat, then there's sort of a cat island of cat-like
things. And then you're out in sort of inter concept space that we have not yet explored.
And so you can imagine the same kind of thing for mathematics. You say, here's a theorem that
somebody wrote down. Let's sort of change the embedding in some sense and say here are nearby
theorems that weren't necessarily, you know, where is the island? How far out does the island of
interestingness go? What happens in this kind of inter concept space between this theorem that
we thought was interesting and this other one we thought was interesting? So I mean, I think it's
a, it's a, I mean, let's take an example. Let's say, I don't know, let's take, well here we've got,
you know, these are random pictures generated in inter concept space that maybe are of things
that we care about. I don't know. I mean, that one on the right, we might kind of think it's,
I don't know what it is, but, you know, it was just generated by a genitive AI. And similarly,
imagine that was a theorem. The question is, is this a theorem that we care about? You know,
it's just like, is this a picture we somehow seems relevant to us? And I think, you know,
this question of whether, I mean, if we look, one of the things that's sort of interesting that one
can do is to kind of look at this whole space of, let's see, we can kind of look at
metamathematical space. And we can kind of ask, let's take a look here. I think I had a nice picture
and find it. I mean, we can ask all sorts of questions about, about different possible proof
structures, which are, that's a meta mathematical thing, but let's see if I can find a picture here.
Yeah, that's a picture of, I think this is metamath. This is empirical metamathematics.
It's asking, in the space of all 200,000 theorems, discussed in, you know, presented in the metamath
corpus, where do these famous theorems of mathematics lie in that space? So it's kind of asking this
question, this isn't all possible theorems. This one is reduced to just the ones that are in the
the, I think it's set.mm corpus for metamath. But, you know, this is again related to this question
of where are the ones, where are the ones one cares about, so to speak. And you can kind of, well,
you can kind of see, this is kind of how the different theorems and different areas of mathematics
kind of get related to each other. But I think it's a really interesting question. What, you know,
and you mentioned that, I mean, I suspect LLM is a really good at picking up on cues from humans.
And so I'm sure there's ways that people will write their master theorem, you know, they'll
make, there'll be more trumpets blaring when they present the master theorem in their paper,
than when they present a little lemma. But here's a good question. Here's a question.
If you try and make this, this is an easy thing to test. Okay. Can an LLM classify,
given a statement, can it decide whether the, whether the author of the paper will have called
it a theorem or a lemma? Well, I would guess yes, because there are different subtle cues,
but I didn't try. What I tried, what I did try is I gave LLM some inequalities, like very simple
elementary inequalities, some were written by humans from the problem sets, from MO problem
sets, for example. And others are just generated randomly by machines, which typically look very
messy. And LLMs can do a reasonably good job at that task. Although I would say that task may not
be very difficult. Well, okay, so we've tried to do things like this, because we've been interested
in automated testing of Mathematica and Morton language. So we're interested in generating
tests that are plausible input, so to speak. So we've indeed tried doing things like that.
Not been particularly successful. I mean, in other words, you can, you can generate an expression
at random just by some Markov process, for example, and you can generate an expression
by using some LLM like device. And you can ask the question, you know, given, given that you've
seen, I don't know, we've got billions of sort of human related Wolfram language expressions.
And then the question is, can we generate others that are like those? That's one question. Another
question of great practical interest for us is, can we guess whether something that somebody entered
is likely to be what they meant? Or is it something in other words, it's like asking the
question, is this a, a plausible sentence? Or is this the sentence nobody would ever write,
which is something which LLMs in a sense implicitly are capable of doing?
I must make an executive decision now. And it's a calculated risk. We may lose
Steven Wolfram if it turns out he has something else of higher priority. We may use, lose other
people for the panel, in which case I will have called closure on this needlessly. And there may
be nothing in the panel, but I have to call closure because we have to stop this session
and then restart for the next session. I want to thank you very much, Steven, for your, for your
talk. And I hope we'll be seeing you again in 10 minutes, but we'll see. Okay.
Are we the same thing for the panel? Are we the same Zoom link for the panel?
I will redo it on, I'll restart it for the panel and I hope you'll be there. And Steven's there
too, but I have to break, break it now. Hoopie.
