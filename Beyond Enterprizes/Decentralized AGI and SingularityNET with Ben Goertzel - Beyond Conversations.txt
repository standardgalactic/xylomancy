ᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠ�
ᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠ�
one
Welcome to beyond
conversations uh today's episode is uh very exciting uh it has to do with uh hot topic that has been brewing
dan engagements and it is the time of artificial intelligence.
My name is David Orban and our guest today is Ben Gertzwell,
who prevail above all the leaders,
and it is a well advanced element of thehearted history
Ben, and our guest today is Ben Gerzo.
Ben is a cognitive scientist, artificial intelligence researcher.
He is the CEO and founder of Singularity Net,
a project that aims to democratize access to artificial intelligence,
and he actually helped popularize the term artificial general intelligence,
which refers to the goal of creating machines that can perform.
Any intellectual task that humans can.
Welcome, Ben, to Beyond Conversations.
Hey, David, thank you.
It's a pleasure to go over these topics with you for what is not the first time, right?
You and I have been digging into these issues.
I mean, presumably since way before we met each other,
I've been thinking about these things since the early 1970s,
but we must have been talking among ourselves about this for 15, 20 years
or something quite a long time.
That's correct.
I am proud to be your friend and full disclosure.
I'm also the chairman of the Singularity Net supervisory board.
We will have an event in just a couple of days
talking about the next phase of the Singularity Net decentralization,
and that will be also an interesting opportunity to talk about governance.
That is the reason why we are not going to maybe touch that as much today.
But why don't you highlight maybe some aspects and recent developments
of the Singularity Net ecosystem,
which is developing so rapidly and so broadly that I'm sure
just mentioning a few of the most recent components would be helpful.
I've been thinking about the Singularity and the future
and the AGI before the term Singularity or AGI became current.
I've been working on trying to build thinking machines
toward the building of thinking machines
actively since the mid-1990s.
As soon as the internet came about in the mid-90s
and the dot-com boom in the late-90s,
it was clear to me, A, in one way or another,
the birth of the Singularity and AGI and all this
was likely to be distributed widely across a bunch of different machines
rather than just one supercomputer sitting in some secret lab
or in somebody's basement.
I mean, not that this physically centralized approach was impossible,
but it just didn't seem to be the way things were going.
I had known Danny Hillis who was building the connection machine,
this massively parallel AI supercomputer,
and it was brilliant and fascinating.
But the tech world was obviously evolving in a different direction,
both in the physical infrastructure being distributed
and the emergence of collaborative networks of people
in far-flung places working together to bring things into being.
Actually, I started thinking in 1999-2000
about how do you use strong encryption and distributed processing.
And how do you bring these together to create distributed decentralized
AI networks without a single owner or controller
with some emergent aspect to the intelligence in the network.
I ran into serious practical obstacles at that time.
I was working with Java 1.1.
It was just really, really slow.
Machines didn't have the ram they do now.
Network speeds weren't what they are now.
I didn't hit upon the idea of starting with decentralized money
instead of decentralized AI.
If I had, I would have been Satoshi,
which unfortunately I'm not.
AI projects would be tremendously better funded
although we're not doing incredibly badly.
But it was clear then, as soon as the internet came about,
it was really clear you needed decentralized control
and then when, if you fast forward to 2015,
I saw Ethereum came out and you had the notion of a smart contract
which was clear to me immediately was neither smart nor contract.
It's really sort of a persistent script
sort of involved in a decentralized validation and consensus mechanism.
And I hated the Solidity language from the get-go
just as a computer scientist
from a programming language perspective.
But it was clearly the beginning of something incredible.
You were able to write these relatively simple,
albeit ugly looking scripts
that were sort of nodes in this global world computer
which it would seem by putting the right thing in those scripts
you could then make the nodes in the global brain.
And this was super exciting.
This led in 2017 to me founding SingularityNet
which was basically an attempt to make a platform
for allowing multiple AI agents to cooperate
and collaborate in flexible ways.
So from an AI view,
the idea is somewhat like what pioneer Marvin Minsky
called the Society of Mind.
I'm not actually quite as far in that direction as Minsky
but his thinking was inspirational here.
Minsky was looking at a human mind or any mind in his view
as a society of smaller agents
each carrying out particular fragmentarily intelligent functions
and then all cooperating together
to achieve sort of emergent dynamics of intelligence.
Now Minsky didn't like nonlinear dynamics
and complexity and chaos which perplexed me
because there's a strong emergence aspect
of the multi-agent systems that he himself was putting forward.
He was a complex and fascinating character
who unfortunately isn't with us anymore
though I'd love to bring him back
if post-Singularity technology allows.
But anyway with SingularityNet
we basically created a decentralized blockchain-based platform
for multi-agent systems.
Anyone in the world can put an agent online,
they can have that agent announced
by the SingularityNet protocol.
Hey, I'm here to all the other agents running the SNET protocol.
Then they can pay other agents
and that work for services,
they can outsource work for them,
they can cooperate together doing tasks,
they can read each other's reputations
and we rolled out a version of this platform a few years ago.
It's still getting better and better
so I mean we're pretty close to rolling out
what we're calling the AIDSL,
Domain Specific Language for AIs
which is a special programming language
for the AIs to describe their properties
and capabilities and preferences to each other
which is a key ingredient to allow
automated assembly of different agents
into collectives.
In building this though
we realized there was a lot of other missing pieces
you need to get a whole decentralized tech stack
which leads to some of the other interesting things
going on in SingularityNet ecosystem.
Because SingularityNet,
we have the core protocol and platform
built by SingularityNet foundation
and an open source community.
Then we have a number of different entities
which are part of the ecosystem
that are building stuff using this platform
or building sort of foundational tools
complementary to the core SingularityNet platform
forming part of sort of decentralized tool stack
and that gets into new net
which allows decentralization of processing power
and tokenization of processing power
in a flexible way suitable for AI.
Then the open cog hyperon toolkit
which is our probably main thrust
in terms of how to actually build AGI
on this decentralized platform
and you can build AGI in any way you want
on SingularityNet platform.
Hyperon is our particular sort of
neural symbolic evolutionary approach
which we'll talk about more in a few minutes
when we get into LLMs and stuff
and then there's HyperCycle
which is a collaboration
with Toofy, Saliba and Dan Stolliver
and folks from the TODA ecosystem
and HyperCycle
like new net and HyperCycle
both live in a way below SingularityNet
in the tech stack, right?
New net tokenizes the processing power itself
so you can contribute processing power
for tokens and receive tokens for processing power
and that process power can then run SingularityNet
agents or other things.
HyperCycle is a layer one blockchain
customized for AI
and you can run SingularityNet on Ethereum
we're most of the way there
to making it able to run it on Cardano as an alternative
and Cardano we found more efficient
and scalable than Ethereum for AI purposes.
HyperCycle customized blockchain
just for AI
will let SingularityNet
decentralized AI agents run in a much faster
and more scalable way
and I mean HyperCycle is designed
to work very closely with Cardano
in particular
but it's a different design, we get rid of the ledger
so that's probably more than we can go into in depth
in this call
but if you look at Ethereum and Bitcoin
they're all based on this replicated ledger
that stores all transactions that have ever happened
in the blockchain, right?
So in HyperCycle
we get rid of this ledger
and store transactions sort of fractionated
all throughout the network in a more localized way
and this lets you
have a much more efficient blockchain
underpinning for decentralized AI
so we've been working hard
on all these aspects of a decentralized infrastructure
and now we're feeling a need to like move
way way way faster
even than we've been doing
because we see like the centralized tech behemoths
well I don't think they have the golden key to AGI
the centralized tech behemoths
are certainly getting extremely interesting
AI functionalities
on their centralized tech
so
thank you for that
introduction to the SingularityNet ecosystem
and let's now, as you mentioned
jump over to LLMs
large language models
a lot of people
like moving
goal posts
and always defining
AI by the things it cannot do
when it couldn't play chess very well
people would say
oh AI is playing chess
and then when it could be
every human
suddenly it wasn't chess anymore
now it seems to be
natural language processing
and chat GPT
which now everyone knows
I'm sure everyone following this
video stream
is able to
manage text
in a manner
that I would say
many humans cannot do
it creates
text that is
competent
in many many different fields
now
that was sufficiently
surprising including
to experts
to
generate
a particular
alarm
not about what it can do now
but it
what may be able to do
in the near future
and there was this open letter
formulated by
the future of life institute at MIT
and signed by a bunch of people
and not signed by another bunch of people
and by the way
we belong to those two different camps
I did sign the letter and you didn't
and I feel that these
these agreements are
very very healthy
especially in a decentralized
and distributed world
if we were in complete agreement
and alignment about everything
then there would be no reason
to experiment with
different approaches
and we would just be in a single
hierarchical centralized field
so
the
open letter
has been interpreted
and misinterpreted in many ways
but
very simply it says
let's in my opinion
it says
let's give
a little breathing space
for everyone to understand
what is going on
especially
to those
who are in charge
at these large tech companies
and the regulators
who should be moving faster
and should be looking at
what these tech companies are doing
six months
which is the pause of the open letter
is not going to be sufficient
for sure
but at least it raised
the conversation about
this need
so
two questions to you
one
what
makes you feel that
this is
not necessary
or not useful
and two
what are the things
in your opinion that are missing
from the large language models
that
would require
the kind of
careful
steps
that the open letter advocates
have
and
so
I think
as the singularity approaches
and I think
it is approaching
I still see Ray Kurzweil's prediction
of human level AI in
2029
as a reasonable stab
I think we may
get there a few years in advance of that
I'm pushing for that
but I don't think it's going to be
many decades longer
I mean if it turns out
somehow
human level intelligence requires
advanced quantum computing
or quantum gravity supercomputing
maybe that could make it a few decades longer
I give that a
not zero but very low percentage
chance based on
everything we know about the brain
and everything we can do with computers now
so if that's true
that the singularity is coming
in
five to ten years, three to ten years
whatever
at least human level AI coming then
which will certainly accelerate the next
stages of progress towards super human AI
there's going to be a lot of
crazy things going down
a lot
more impressive and a lot more disturbing
to some people than chat
gbt which in the end is a
rather
only half useful chatbot
although very impressive
in many ways compared to
what came before
I think in dealing
with these sorts of unprecedented
crazy
seeming situations
some basic
principled
thinking is helpful
otherwise when we just
swung around like crazy by the
wild weird things that are
happening
so Max Moore who we both know
who's been one of the leading philosophers
of transhumanism
articulated some time ago what he called
the pro-actionary principle
which was intended as a contrast
to the precautionary
principle that others had talked about
and the precautionary principle
is basically better safe
than sorry hold off on new developments
until you
know for sure they're not going to cause harm
and this
was the principle of
Australian indigenous society
which allowed them to be
fairly constant
and stable for 60,000 years
and they developed many things
of great beauty in this
stable society
and developed their consciousness and dimensions
that are not that common in
our modern world
it's been a principle in Chinese history
certainly if you look in the 12th, 13th century
China had quite advanced technology
all sorts of machinery
and so forth
and then they sent sailor ships all over the world
and then they decided to
stop that because it was being
disruptive and they didn't know where it was going to lead
right now
modern western society
has generally not proceeded
on this sort of basis
which is really why
we've developed computers and AI
and the internet and modern medicine
and gone to the moon
and all this stuff
we have implicitly
and with a lot of argumentation
along the way
we've largely followed
what Max called
the pro-actionary principle
which basically means
you know
have a bias toward
doing stuff and not making prohibitions
and a bias toward
letting processes
unfold in a natural way
without trying to blockade them
it doesn't mean
there's nothing that you should ever prohibit
and try to stop
I'm not advocating
selling briefcase nuclear weapons
in Walmart
it means that when
there's
complex technologies
complex situations
with richly
nuanced and balanced pluses
and minuses
and it's hard to
understand the implications for good or for bad
in a situation like that
the pro-actionary principle
would argue
just do it
and keep an eye out
watch to be sure
you're not doing anything extraordinarily dangerous
but don't be
paranoid
don't be a wimp
and look at the cost of
not doing something along with the cost
of doing that
thing
so justifying
pro-action versus precaution
on this sort of historical
societal and philosophical level
is very interesting and important
would be a long and deep
conversation
which gets into
epistemology and metaphysics
and all sorts of things
but I wanted to mention that
in general that's where I'm coming from
and I think that attitude
is why we have advanced
technology
that's why we have modern
dentistry and vaccines
and computers
and so forth
this is why we have developed
weird new technologies
which in every case
we didn't know what would be the good or bad aspects
and how they would be
balanced
and I do think there are
cases
where you don't want to be proactive
no matter how
gonzo for the future
you are
briefcase nukes is one
gain of function research
on viruses
that can affect humans is certainly
an interesting borderline case
which society chose to proceed
with anyway
in spite of some
pretty obvious risks to do
with the leakage from labs
and so forth
but the thing is with these technologies
nuclear weapons
have very few uses
besides blowing people
on their possessions up
I mean you can use them to blast starships
as Freeman Dyson suggested
but by and large they're
considered a weapons technology
and taking animal viruses
and uplifting them so they can kill humans better
again
there's not a lot of
immediate humanitarian
uses for that
the purpose is to
better understand them
in case they develop later
in nature or something
AI is different than that
there's tremendous
obvious positive
benefit of these technologies
and so then
bouncing the cost of not
getting the cost of doing it is complex
but what this also means
is that
if you try a prohibition
many many actors who are not
particularly bad actors
are going to wangle the way around the prohibition
anyway
the only reason to wangle around
a prohibition on briefcase nukes
is pretty much if you want to blow people up
or you're a really really really ethics free
conniving business person
who wants to make a living
briefcase nukes to other jerks
who do want to blow people up
reasons to keep developing AI
are just
extremely numerous
beyond wanting to do anything bad
so I think there are two things
that are sort of mixed up here
and they're mixed up in a very natural way
so one thing is
I think
this sort of prohibition is
ethically very very dubious
because balancing the good and the bad
is very very hard
the other thing is
this sort of prohibition will never work
in this completely impossible
in practice and I think these are tied together
because when the good and bad are all tangled up
and complex and hard to assess
you know this kind of prohibition
is going to be way way hard
to put into place because
so many parties won't
go along
along with it
anyway right and you can
see both the aspects with this proposed
six month pause
I think chat GPT
LLMs and so forth are not
general intelligences
they're not going to be
sort of
incrementally morphable into general intelligences
just by tweaking the architecture
a little bit
I do think they could serve as components
of general intelligences
and whether the LLM component
is 60% or 20%
of the final general intelligence
I'm more toward the 20%
side but I think
there's still a very interesting
ingredient in AGI systems
that are going to be built
but they're not AGI's yet
they're software systems
they're very interesting software systems
I'm engaged with a few people building
amazing commercial applications
on top of LLMs
I'm also engaged with some research
trying to couple LLMs with logical
reasoning systems to make them
make more sense and carry out multi-step reasoning
better
can they be used for unpleasant things
of course they can be used
for unpleasant things
they can generate a lot of nonsense
people can be tricked to believe it's not
nonsense
I mean if we're going to ban things
people can use to fool people
and spread bullshit we're going to
ban the whole internet and mobile phones
very rapidly and these also
have complex pluses and minuses
that we don't know
we don't know how to balance
so I just think there's clear potential
for tremendous good from these
there's potential that they serve an ingredient
of AGI's that can do even more good
there's also ways people can do harm
with them
I see this is not different than so many other
technologies out there and the practicality
of a pause is a whole other thing
because if you
if such a pause were really
on paper which is obviously not going to happen
anyway so I think signing
the petition is mostly virtue signaling
rather than anyone thinking the pause was
really going to happen but I mean if
if such a pause really
did happen I mean what would happen
first of all Putin and Xi Jinping
aren't going to do that pause
even if they said they were they're not going to
China can't even obey the World Trade Organization
sort of basic ethics
about not stealing other people's
IP right so
on the other hand big tech companies
like at Google and Microsoft and so on
they're not really going to pause either
they're just going to develop AI
internally and use it inside
the products in a quieter way
rather than making it available to the consumer
so if such a pause were adopted
which it won't be
that would result in a combination of
nasty dictators
gaining in AI over the
democratic world
and it would result in greater
centralization of AI within the developed
world as big
tech companies take their LLM
projects black and don't
open them up to the consumer
so I think
but I think almost everyone can see
this and they just want to sign it
so they could look like
they're ethical and concerned
right because
we have a lot of questions
from the people following
the live and I want to
tackle some of them
and they are
touching these topics
but let's start with a different
question from Rohit
what is the picture behind the wall
on the wall behind you
oh
oh that
orange picture I think that's
that is the album cover
of access to all this love
by Jimi Hendrix
so go
all right
listen to access to all this love
one of the great albums in music history
all right Rohit
so you can check it out
and David
is asking why is the
mainstream pushing the AI is going to kill
us all narrative
and then he proposes
a benign answer
saying maybe to create a common
alien enemy
to unite
us and the end
the wars between nations
so to
answer David in pot
AI
deserves a lot of conversations
and
I hope more
would happen especially
illustrating the benefits of AI
like Ben said
in a pro-actionary
attitude
and the mainstream
media is driven by fear
is driven by the
the worst possible narrative
that attracts attention
so it is natural that they
would
push that
on the other hand
it is
definitely the case
that
there are
approaches that we have
taken to iteratively
develop
solutions for example
the SpaceX rockets
that are now landing
regularly
belonged to science fiction
and NASA
or the Russians
or the Chinese or the Europeans
would have never developed
them if
crazy Elon Musk
didn't come around
and said I don't care that everyone says
it's impossible
I will just blow them up until we don't
succeed
so that is where the alignment
issue comes up
because
there are
people who believe that
not current AGI
but future AGI
can
become
agentic
it can design and then execute goals
of its own
and it can
slowly diverge
and then the side effects
of whatever it does
can have very big effects
on us
and both
the speed of its
divergence and
the size
of these effects can be such
to represent an existential
threat to human civilization
without us
being able to say after the fact
oh sorry we destroyed the current one
let's bring a new human civilization
in its place
and iteratively
find what works
so
again two questions
do you believe
this framing of the alignment
problem
is worth considering
now
given that by your own assessment
the
singularity
may be as close as
five years from now
and the second question is
if
we don't have a current
solution to the alignment problem
what are the paths
that we need to take in order to find
those solutions
so that we have them when we need them
good questions
I forgot to say one thing
about the pause
which I want to address briefly
then I'll go to this bigger and deeper
more interesting question
I think another strange thing about the pause petition
is it focused on training larger and larger language models
so one thing that was ironic
when I saw that is
if people really stop
training larger language models
and started working on more productive
approaches to AGI
that might actually have the opposite
impact of what people signed the petition
thought and might accelerate
the path toward AGI
Sam Altman actually made the same point
in recent remarks at MIT
he's like well this lacks technical
nuance because
what we're doing in open AI now is not
so much just obsessing on bigger models
anyway
they're integrating GBD4
with Microsoft knowledge graph
they're working on a lot of other things
besides just bigger and bigger models
this is a difficulty of prohibitions
on complex things
you're going to say no language model
with more than
one trillion parameters
what if someone makes a complex
valued parameter
which equals two real valued parameters
what if you have five different models
with half a trillion parameters
living in different places
that co-operate with each other
these things are too
slippery
the same reason that software patents
are much harder than biotech
or nuclear energy patents or something
they're slippery in their
definition as well as
slippery in balancing good and bad
aspects in the
short term
I think
going to the alignment
question now
I don't
really like
the word alignment
that's used in discussing
the
future coordination
of AI minds
and
human minds
I understand what people are
getting at when they talk about AI alignment
I don't want to nitpick on
word choice in too much of a
ridiculous way
but to me
there's nothing to
align with
because human
morals
human ethics, human ideals, human ideas
are
intercontradictory and kind of
scattered all over the place and they're also
rapidly
evolving, right?
If you look
at indigenous
Australians
Asians
at the average Ugandan subsistence
farmer
at
Islamic people
in rural Saudi Arabia
then look at people in the tech hubs
in the US today
right now there's tremendously different views
on so many things
and if you roll back
50-100 years
there were divergent views
among these different groups but also
each of those groups have a different view
than they have now
when I was growing up
in
New Jersey in the 1970s
in part of my childhood
you would get the crap beaten out of you for being publicly gay
or even being suspected of it
now that's not true in New Jersey anymore
but you can get killed for being gay
in many parts of sub-Saharan Africa
so there's not a coherent thing
to align with it
any level of precision
and the way
humanity thinks about what's good and right
50 years from now post-singularity
is going to bear only a loose resemblance
to how we feel
now
I mean I think
some things that we take
very much for granted now
we're like a focus on our biological family
right
I mean that's a big thing for me
I have five children and a granddaughter
I live near my mother who's almost 80
that's a big thing
we're post-singularity people
aging and death is gone
reproduction doesn't happen
to have to happen
in the traditional biological way
although it may still sometimes
the whole role that family
has in psychology
may be quite different
50 years from now
than now
and this may sound very disturbing
to some people now
I mean just as
gay people were very disturbing to the people I knew
in New Jersey in the 70's
right so
I mean things evolve
so then we're not saying take
the world view
of San Francisco
Silicon Valley Tech Bros
in 2023
and make future AGI's
always aligned with the world view of
2023 Silicon Valley Tech Bros
right like that
that's not what we want anymore than we want
to forever be aligned with
the elite in Rome
in 1521 or something
so what you want is somehow
for the chaotic
self-contradictory evolving system
of human values to
co-ordinated and co-evolving somehow
with the evolving set
of AI
and transhuman and synthetic
organism values
and that's
as an interesting thing to think about
it doesn't seem like the kind of thing
that can be guaranteed
in any way nor the kind of thing
that you can prefigure
and design in a detailed way
we're talking about
the coupling
of two pieces
two subsystems of a complex self-organizing system
which by its nature
is going to be
evolving in ways we cannot now
understand
I mean you have people talking about
we want an AI that will provably
never deviate from its initial goals
I'm like shit what if
what if the Pope had created an AI in 1400
that would provably never deviate
from the goals the Pope gave it
and it was super powerful
that would be forced to be Catholics
at risk of being blown up by AI drones
coming out of the Vatican or something
I mean that would be
a tremendously horrible thing
to do to a super human mind
if you could somehow
wire its brain to never deviate from the goals
of 2023 Silicon Valley tech
bros
fortunately there's no way to really do that anyway
so
I
cherish
our diversity
and we have
the ability to aggregate
and we have built
societies that
either accept
develop or impose
a certain set of
consistent views and behaviors
and today
as a human civilization
we brought this at
roughly speaking continental
level
there are
different kinds of
expectations
of behavior from humans
within
societies and across
societies as well
but we more or less
subscribe to
certain sets
of behaviors
and expectations around those behaviors
so
the opportunity
I think is huge
for
SingularityNet
to find
a way for the decentralized
AI
and AGI systems
to
navigate
the complex
sets of behaviors
across
a parameter
space that is vastly
larger than not what humanity
has been able to explore
today
to find
consistent and coherent
niches
that can build
desirable
futures
for them
as well as for ourselves
current
and future humans
under an admittedly
broader definition of
what it means to be human
and what it means to be
living a dignified life
than not what medieval
expectations
would support
so
actually asking
how far is
SingularityNet from AGI
considering that
OpenCog is very robust
but not there yet
well so from a SingularityNet
new net hypercycle view
the technology is
somewhat agnostic
to what approach you
take to building
towards AGI on top of it
and we have a project called
ZARQUA
which we're spinning out now
which is building LLMs
decentralized on SingularityNet
new net hypercycle platform
and we will enhance those
LLMs with OpenCog
or whatever other interesting tools
come up certainly
you can do LLMs
you can do other sorts of
neural nets
totally different sort of
AI system
you can build paywangs
non-axiomatic reasoning system
you can do anything
that can be implemented
in modern software languages
and we can decentralize it
and I think
it's important
both as a modular
software design
and in terms of
building a community
helping weird new AI ideas
onto the platform
that said
my own
AGI research effort
is still oriented on
the new version of OpenCog
which is called HyperOn
and
I think
in the next
one to two years
we're going to get to a
massively scalable version
of OpenCog HyperOn
and I mean we're making
quite good progress
we have a distributed version
of OpenCog's
Medigar base
which is built on top of MongoDB
and CouchBase
and we're working on
a massively
accelerated
compiler and execution engine
for OpenCog HyperOn's
AGI programming language
which basically
works by compiling
OpenCog Metacode
into Rolang code that runs on the
Rolang interpreter that was developed
in the R chain blockchain
so we've got a bunch of interesting stuff
going on the infrastructure side
there's a collaboration with
Simuli Rachel St. Clairs company
out of Florida on building an optimized
chip for OpenCog pattern
matching and then an AGI
board as well so I think
we have a lot of
different thrusts going on
to make massively
scalable
infrastructure for OpenCog HyperOn
as well as
ongoing R&D on the mathematical
foundations
of how to get large language models
and other deep neural nets
logical reasoning and then evolutionary learning
to work together and I think this is key because
you know LLMs
and other generative neural networks
are great at recognizing and synthesizing
patterns
logical reasoning engines
are better at telling truth from
falsehood and carrying out
multi chain logical inferences
evolutionary learning
simulating natural selection in the computer
is good at creativity which is how evolution
created us so I think
getting these three AI paradigms working
together in this distributed network
is going to be
big and I think
that if we didn't exist
in OpenCog
the mainstream of big tech
AI would get to a similar place
eventually you can already see
they're taking LLMs and they're glomming
Microsoft Knowledge Graph onto it and
Google they're glomming Google's Knowledge Graph onto it
why because they want to ground it in reality
and eventually
they want to so solving
the hallucination
and bullshit problem
is high on the list
integrating with knowledge graphs
they can do reasoning is an obvious route there
their knowledge graphs are not as advanced
as the one we have in OpenCog
but then once the bullshitting problem is solved
then there's the banality
problem of just yes it's amazing
chat GBD can write poetry
but on the other hand it's all really bad poetry
right so then how do you
how do you get it to be creative
and inspired like people are
and I think then you're going to
inevitably move towards some sort of evolutionary
algorithm approach so I think
I think big tech will get there
to the ingredients that we have already
in the OpenCog design
but if we can get there faster
by deploying OpenCog hyperon
that scale on a
decentralized infrastructure
I mean then we're doing a couple different things
right what one is
you know we're accelerating
past where big tech will get
because they're fixated on the particular
techniques that will best leverage
their
advantage in data rather than
on techniques that are not as
data train data set bound
but the other thing we're doing is we're
making it so that hey
lo and behold
the next big breakthrough
the breakthrough from
to AGI happened
in the decentralized ecosystem
rather than the centralized ecosystem
right now if you're
Nick Bostrom or Eliezer Yadkowski
that's going to seem far
worse than having it happen within a
centralized company because
from the mindset that some of these
AI ethics
boffins have right
they would rather have a small group of people
controlling the AGI
so then the small group
people could be convinced to shut it down
whereas if you have an
AGI rolled out in a decentralized way
where it's running on millions of different
machines in every country on the planet
then nobody
can turn it
off in such a simple way
now it's not to say humanity couldn't
shut it off if humanity is a whole one or two
I mean that's like think about
Bitcoin or Ethereum I mean how would you shut down
those networks
it's not easy for a government to shut down
those networks if Bitcoin
or Ethereum we're going to kill everyone
well yeah people could just start running their nodes
right I mean so
if you have a majority of people
who will refuse to confirm transactions
they won't get confirmed right
so being decentralized
in a blockchain based mechanism
doesn't mean like
this will run them up and if all humans
wanted to stop it they couldn't stop it
I mean eventually things could get there
but that's not implied in the
in the use of a decentralized fabric
but it does mean
that it's hard to shut down in the same way that
Bitcoin
Bitcoin or Bitcoin or something are
hard to shut down as long as
there's a substantial group of people
with a bunch of hardware
who want to keep the thing going
then it will
keep going and
personally
I see risks either way like having
having a centralized entity
could be the best if the people running that
centralized entity are open-minded
open-hearted, compassionate, normal
individuals who don't
don't fall prey to the pathologies
that have befallen
almost every group of humans
in an elite power position in human history
but as possible it could go well
that decentralized approach
has the downside that
nasty groups of people could try to
take over the network, they can form the open
source code, they can try to do
their own unpleasant thing
so we are placing a bet on the vast
chaotic team
of unwashed masses of humanity
over self-appointed
elites with huge amounts
of money and close
military intelligence connections
neither one is
an incredibly
safe and certain path
forward
my view is that
a fundamentally
compassionate
and human benefit
oriented AGI
is a bit more likely to emerge
from the decentralized
approach
I don't think this is the thing
you can have a completely solid
mathematical proof of
because we are not just talking about the
algorithms and structures, we are talking about
how the human systems
interact with
the compute
fabric and the AI
algorithms but I think
there is lots of reasons
to be optimistic
I think
with the advanced technology
we have right now
you could have so much more destruction
in the world than
what we have
but in fact
there is remarkably few groups
of highly competent technically trained
individuals out there who are
massing together to put their energy
toward killing a lot of people or causing
mass destruction
you don't have a situation like
the amount of people behind
say
a strong tech start up
say Anthropag or stable diffusion
not to hover over my own company
the amount of money and energy behind
a start up tech company
and the brilliant people going into it
and the money going into that hardware
you don't have initiatives like that
focus on blowing up a lot of people
or wreaking great mayhem in the world
you could theoretically
but in fact
the mass of technical innovation
it's going toward making people money
some bits of it are going toward
doing good for people
some things may go awry
but what we see
is
on the whole
most humans
who are
banding together in groups
to advance technology
are actually not trying to do
horrible nasty shit with it
and I think
that's going to continue
it's going to continue as we move
toward AGI in an open and decentralized manner
there are a lot of people following
the stream
asking questions
evidently very
passionate about these topics
let's try to do a few quick questions
and I can try to give some short answers
one of them
is quite
general but
but I think important
if they want
to get involved with
the project what kind of
talent what kind of
skills
both in the core as well
as in the ecosystem projects
are most valuable
in order to further
the missions of
SingularityNet and of the
single ecosystem projects
as well
there is a great variety
of skills that are
useful for advancing
SingularityNet
ecosystem projects and other projects
out there
which are advancing
Singularity
oriented technology
in beneficial ways
so I wouldn't want to
be rigid about it
we are working with lawyers
we are working with social media people
we are working with
people from all different walks of life
as well as
the more obvious things like
AI developers, software engineers
blockchain developers
biologists, cognitive scientists
and what not but as a generalization
I would say
people who can
if you have the mentality
and interest to be a core AGI developer
that's great we can always use more people
who know chit loads of math
computer science engineering and so forth
if that's not your thing
I would say
there's always a need for people who have
some mastery of
some other domain area
and a decent knowledge of AI
because when you're trying to
apply AI in say biology
or supply chain
or media or whatever it is
it still comes down to some small group of
humans who understand that domain
and have a decent sense of the AI
to make that bridge
AI is not yet figuring out how to apply
itself in one after another
critical area so I think
we're entering an era where
cross-disciplinarity
is going to be
key and highly valued
the day after tomorrow there will be the
decentralized governance summit
what can people
expect
to find there
what are the kind of contributions
that you will also provide
as well as the other speakers
yeah good question so
making
a decentralized AI network
has a number of aspects and
I've tended to focus on the technical aspects
just of how do you get
large-scale compute processes
of the sort you need in AI
to actually run across a huge
number of machines without a central
controller because there's a huge
load of hard technical problems
you have to solve to make this
happen which we're working on in Singularity
Nounet, Hypercycle, OpenCog
2AGI, Zarko blah blah blah
but I mean the
the other aspect
to making AI
fundamentally decentralized
is
governance of this decentralized
network
because it's not all about the computing
yet
all these compute nodes in your decentralized network
are run by people
they have to decide
to run this software on their machine
they have to decide when to
upgrade to
a new version of software
there will be decisions about the parameters
of the software in the network that have to be made
for now by the people who are running the
software nodes and the people who are
using the software running
on the nodes
there's a significant governance
aspect to decentralized
AI networks
as well
when we founded Singularity Nounet in 2017
one of our goals
was to gradually
transform the governance of the whole
Singularity Nounet network into a
DAO of some form, a decentralized
autonomous organization
not meaning initially
would just be the AI nodes making the decisions
but meaning that it would be
a
democratically governed network of humans
and
AIs with the whole collective of
participants in the network playing
a meaningful role
in the ongoing
decisions of evolving the
network over time
so we've had
some measure of that so far
we've had some pretty big decisions
in the history of Singularity Nounet
made by
community vote and community
discussion but we haven't
gone as far in that direction
as I would like to have
and so basically
the governance
powwow
summit that we're having on
Friday is
oriented toward pulling together
various people
involved in different aspects of Singularity Nounet
ecosystem and
gathering energy toward
in the next
two years how can we transform
Singularity Nounet
into a radically more
decentralized organization
where the breadth of participants
in the
network are playing a greater role
in making the important decisions
about the evolution of what happens
in the network
and I pick
the timing of two years in my head
with a couple things in mind
one is I don't want to rush
things to an insane degree
because we're doing very valuable stuff
and I don't want to disrupt it
in some stupid way and there are many pathologies
that we've seen
in the blockchain world from
Dow Governance
on the other hand
if we could get to human level
AGI in three years
then I want to have
fundamentally and fully decentralized
governance before that
because I think it's going to be
key in the transition from
narrow AI to AGI
in all sorts of ways we can't
prefigure now right like I'm a big
optimist about what happens after the Singularity
more based on my heart
and
soul and feeling than based on rational
analysis because I think based on rational
analysis the confidence
interval is just very wide
and there's a lot that we can't rationally know
but I have a strong
faith that things are going to come out
pretty amazingly once we have
superhuman AGI that we've raised up
in a compassionate and democratic way
but I can see a lot of
risk of
chaos unfolding
en route to this
utopic future
and I think that having the
network in which AGI emerges
fully decentralized
and very richly
democratically governed
that gives a lot of
important degrees of freedom
for how the emerging
AI network
sort of deals with any chaos that
happens between here and the Singularity
so I think this is
it's both
it's both the direction we committed to
when we founded SingularityNet and
potentially could be really really
important to humanity
if the breakthrough to AGI
happens within the SingularityNet
network because obviously what we're pushing for
I know
that you are
also going to be
at a couple of events that you wanted
to mention
in the consensus
in Austin
and
events are coming back
spending a couple of years sitting
in the
web summit
go ahead
I think
events have come back during the pandemic
I was mostly sitting home
working on AI on blockchain
and playing with my kids
now
conferences are back
so I can keep getting work done
but I'm going to
consensus event
in Austin next week
I'll be doing
a conversation
or interview with Edward Snowden
on AI and the security
where we'll hit on a bunch
of these same points
also doing a concert
at the Speak Easy Club where I'm playing
keyboards with the Jam Galaxy band
with our robot lead vocalist
Desne Mona
Sofia Robots
little sister
there'll be a bunch of SingularityNet people
around the consensus
so definitely
come and hang out with us
following that I'll be at
web summit Rio
and also doing an AI meetup
in Rio on one of the evenings
of web summit
I was born in Brazil way back in 1966
so I'm
world's worst Brazilian citizen
because my Portuguese is horrible
but I'm a dual citizen US in Brazil
that always feels good
to go back
to the motherland
if you're going to be in Austin
or Rio then
there's a bunch of SingularityNet people
around in the next few weeks
but
of course
the core work we're doing is distributed
around the globe
to get involved
on the interwebs
if you go to SingularityNet.io
you can join mailing list
and find various
GitHub repos
and Telegram LinkedIn
and everything else
so we encourage people to get involved
these will be
the next few years maybe the last few years
that you have a chance to help bring about a beneficial SingularityNet
unless you're doing it in some post
Singularity Video Game or something
Ben
this was wonderful thank you very much
for covering so many
of the topics
and I'm sure
that there will be a lot more
to talk about and
congratulations for everything
that you have been able to
accomplish with
SingularityNet
everyone in the teams
and good luck
with further developing
all the projects
and I will see you at the
decentralization summit
just
in a couple of days
we will both
be speaking there to talk about
governance and how
to ride
the tiger really
in the next period of time
thank you again
thanks a lot David it's been a pleasure
thank you
everyone for
being here with us today
at Beyond Conversations
I am sure
that there will be
a lot more opportunities
to
ask questions
and to really
find out how
technology is impacting
and benefiting
society around us
goodbye
