Okay, let me just tell you what the two main points are that I'm going to try to touch
on in this talk.
The first is that to understand human level intelligence, we are going to need to understand
creativity.
It's a big part of what being intelligent means from a human level is our creative aspect.
But the second part, which may be a little more subtle and a little less discussed, is
to create human level AI, which is sort of the topic of the conference, is what we want
to do is create this stuff, or maybe call it AGI or whatever we want to call it to talk
about really high level artificial intelligence.
We may need to actually implement and run some kind of creative process or open-ended
process that produces this general intelligence.
So that's a thought that's interesting that I want to touch on over the course of this
talk is the idea that we may not be able to get to this really high level of intelligence
without some kind of process that's creative generating the intelligence itself, and that
is something that doesn't get discussed that often.
So optimization is often the topic that we hear about in machine learning today, and
optimization solves problems.
But creativity is something different because creativity changes our perception, and creativity
has more in that sense to do with sort of being human, when we talk about the new designs
for all kinds of things, buildings, architectures, clothing, et cetera, new forms of art and
music, new experiences in entertainment and video games, vast collections of solutions
to problems that we have not yet even encountered, like these are the kinds of things that creativity
provides.
And the point is, this is what we mean by human level.
If somebody can multiply two really big numbers together, that's pretty impressive, but it's
not like, wow, the humanity of it.
The humanity of it is in this kind of a stuff, and that's pretty interesting.
But there's another observation I want to make about creativity, which is that we are
not the only creative force in this universe, not just humans or animals for that matter,
it's this other thing here, it's a very creative force, which is evolution, evolution, which
is the source of all of nature, and think about creativity.
That is the most prolific demonstration of creativity that exists today, is the thing
that produced everything, all of living nature that we see, and that means things that currently
engineers can only dream of reproducing in all their glory, so things like flight and
photosynthesis, and guess what, human level intelligence, that is a product of evolution.
It produced the human level, it's the only thing we know that produced the human level.
In fact, it may be the only viable path, but what I mean is some kind of creative process,
and I'm claiming here that evolution is a creative process, but some kind of a creative
process may be necessary to get to these extremely high levels.
It's important that we grapple with what we actually mean by creativity.
I think that the creativity of evolution that I'm sort of representing with this Tree of
Life can't be understated in the sense that we're talking about prolific creativity in
a single run of something, you could think of it algorithmically, is like a run that
lasted for over a billion years, it kept producing more and more interesting stuff.
This is not optimization that we're talking about here, it's not an optimization process,
it's not optimizing towards some objective or converging towards some objective.
In fact, it's very much the opposite, this is what we would call open-endedness, that's
another theme I want to talk about, or touch on in the talk, is open-endedness, which means
processes that basically run forever and keep producing interesting things, but are not
converging towards some point that's predefined.
What can we learn then from evolution about open-endedness because we may need open-endedness
in order to get to such a distant point in the search space of all possible algorithms
that it's actually equivalent to human level intelligence.
Let's think for a second about open-endedness, what kind of thing is open-ended?
Well, I'm claiming that evolution, evolution in nature is open-ended in some sense, a billion
years and so forth running and still producing interesting stuff.
Well, we have something in computation based on this idea, at least inspired by this idea,
it's called evolutionary computation.
What about this?
Is this a candidate then?
Does this capture these ideas?
This is something that extends back to the 1950s, and many of the pioneering ideas come
from the 1960s.
This is a really simple idea at heart, and a lot of you have heard of it, basically just
to really simplify it.
Let's generate a bunch of random things, call that a population, and then let's take the
better of them, and we can call that the parents, like the better ones.
We have some metric saying what's better, and then we'll made and mutate those, which
just makes me perturb their representation in some way, to create a new generation of
stuff, and that's the next generation population, and we just repeat this over and over again,
and it can be done for any task, because it's very generic.
Great, so here's the algorithm.
By the way, you can also evolve neural networks.
We've had a lot of talk about neural networks, you can evolve them too.
That's called neuroevolution, so it's kind of like evolving brains.
So there we go.
So is creativity solved?
And I'm regretting the color that I chose here, because it doesn't show up well here.
But basically what this says is that, no, there's something wrong here, because evolutionary
algorithms, what we're just talking about here, they also converge.
They converge, and then they basically give you your solution, or they get stuck, like
any other machine learning algorithm, and then that's the end.
And it basically, by the way, is the same story with deep learning, or like anything basically,
they find what you're looking for, maybe they find a few things you're looking for, then
it's the end.
Or if it doesn't work out well, they don't, but either way, it's the end.
And the whole point here is with open-endedness, there should be no end.
Here's some things I've worked on, these are various things I've worked on, and they're
all really kind of cool, but they all end, and that's not what I'm talking about.
What are we missing here?
It comes to algorithms that just keep producing interesting stuff and never end.
So there are some more imaginative ideas, people have thought about this.
What would keep this kind of going and being interesting forever?
And so people talk about things like co-evolutionary algorithms, and this means where the individuals
inside of the population are interacting with each other while the evolution is happening,
and that interaction then can presumably lead to things like arms races, which might just
keep on ratcheting up forever, and that would be cool, but unfortunately it hasn't proven
itself yet to work, it generally will eventually get stuck.
You can look at things in deep learning like a GAN, which is something like a creative
process, but really it's just interpolating among points that it's already seen.
It's not like creating completely new concepts, nothing truly new, like in the way that humans
are completely new with respect to back in the day when there were only flatworms sort
of at the cutting edge of life, because actually one of our ancestors is a flatworm.
That's something really new.
What kind of process does that kind of novelty?
And so we don't really...
This is a very difficult question, and what kind of process explains open-endedness and
complexity explosions, like things where things just keep on getting more and more complex,
up to really an astronomical level like the human brain with its hundred trillion connections.
And I want to tell you that I think we're beginning to understand, but beginning, it's
important, it's like beginning, so I still haven't seen a program that just produces
amazing stuff forever, that doesn't exist yet, like a never-ending algorithm, but we're
beginning to understand some of the important facets of such a system, and one of the most
important ingredients is divergence.
It's really important because a lot of the time we're worrying about convergence, all
the time, converging towards the optimum, converging towards the objective, minimizing
this loss, but for open-endedness, if it's important to get divergence, then a lot of
our intuitions that we've been building up are not relevant to that kind of a process,
because divergence is like the opposite of convergence.
And I want to show you through an example what I mean by divergence.
I'm going to show you on this system called Pick Breeder, which is actually an experiment
that we put on the web years ago to allow people to collaboratively breed basically
pictures.
So it's sort of intuitive, you know, like breeding dogs or breeding horses, but here
they're going to breed pictures.
So we put it on the web because we're interested, like, if you crowd-source people and let them
sort of do the breeding on their own, what kind of stuff might they find?
Like, this could be pretty interesting, but it turns out that it revealed some really
pretty profound stuff, which I'm going to get into.
So while it may seem like a digression for a moment, like, well, what are we talking
about now with this toy?
It's actually really interesting what it leads us to seeing about divergent processes.
So let me just show you how this works.
Like, if you came into Pick Breeder, and it's on the web, so you could go in there, and
if you said, I want to start from scratch, that's one thing you can do, it would give
you, basically here you see 15 random blobs basically.
And then what you could do is you could choose one of the random blobs that you like.
So I'd say, so I put a star there, so I said, that's the one I'm going to choose.
So now this thing can have some children there.
So you see how children look like the parent.
There are slight perturbations of the parent.
There's been a fairly significant mutation over here that's interesting perhaps.
So I could say, okay, well, let's breed from there, then that's the new parent, and then
so forth and so on.
And then I breed more images.
And if you look at these things, it looks pretty modest and it's like, okay, this might
be fun for a few minutes, maybe.
It turns out that what people found for me was really amazing.
I think this is an amazing result.
I'm going to show you a little sampling of what people found.
I mean, just think for a second, if you haven't seen Pick Breeder, I know some of you have,
but if you haven't seen it before, just sort of try to project ahead.
What are we eventually going to find if we play this game for a while?
And the result is this kind of stuff.
And this is really, you wouldn't expect this from such modest beginnings as this.
And I think there's a lot to learn here in terms of understanding how did this happen?
And look at these things.
They look reminiscent of things that we see in the real world, like you see a butterfly
and a skull and even a car.
And look, even Jupiter even has the red spot there, so that's accurate.
Now how did all of these discoveries get made?
And it turns out that one important ingredient here that I want to emphasize is that if I
found something in Pick Breeder, I can press a button and have it sent back to the website.
And then anybody in the world can come back and branch, basically say, I want to keep
evolving or breeding from that point.
So we can all branch from each other's discoveries.
And what do you get from something like that is something that looks like this.
And this is a small sub phylogeny, you might call it from a biological perspective, but
it's called a family tree.
This is a small sub family tree of the entire Pick Breeder phylogeny, which is thousands
and thousands of discoveries.
But so what you're seeing here is basically every node there is something that somebody
published to the site.
And then every connection there is a point where somebody else said, OK, I want to branch
from that and do my own evolutionary sequence.
And what you're seeing is that people are branching off of each other and branching off
of each other and branching off of each other.
And this is which leading to the leaves of the tree, which are like the discoveries that
we see in this kind of a thing.
And this is what we call divergence.
In other words, the system rather than converging to like the Uber image, whatever that might
mean, is actually diverging across the space of all that's possible and collecting stepping
stones.
In other words, everything that's found that somebody publishes back to the site is something
that has potential to lead to something else.
And one of the more profound things that we discovered about the discovery of about how
the discoveries were made on this site is that actually in almost every case, when people
discover stuff like these, they were not looking for them.
And so they just that for a second.
The way to find things in Pick Breeder is by not looking for them.
And this is basically like a rule.
And the reason is because the things that lead to these don't look like them.
So like the reason that these were possible to discover is because someone else discovered
some predecessor, you might call it a stepping stone that led to them.
And that person who discovered that predecessor was not thinking about these
ultimate discoveries.
If they had been, they would not have discovered the predecessor because the
predecessor does not resemble the final discovery.
So it's necessary for people to not be trying to find the things that are ultimately
found in order for all these things to be found.
And this is the power of divergence.
Divergent systems are stepping stone collectors.
They collect basically oases of potential from which you can jump off and get to other
places. And the more we collect, the more places we can get.
And this is what's leading to a kind of an open ended process in Pick Breeder.
And I want to point out that this is one of the only examples that exists.
I think maybe the only of an artificial system that actually does show an open
ended dynamic, except I do want to acknowledge the caveat that they're
humans in the loop.
So it's cheating a bit, you know.
So to create an automated system that has this property is much, much harder.
But that's okay, because this system is for us to learn from.
And the data here is extremely valuable as sort of an example of how an open
ended process can develop, because we know every single choice that was made.
And that's how we learned that you can only get to these things by not trying to
get to them. Okay.
So that was interesting, that insight, that you can only get to things by not
trying. And that's what led Joe Lemon, who was a PhD student of mine at the time
and myself, to develop what's called the novelty search algorithm.
We were inspired basically by Pick Breeder, by the observation that there are
many things in life we will never be able to get to if we're actually trying
to get to them.
And so to create a process that's more like what happens through divergence
in Pick Breeder, or you could say divergence in nature, which is basically
just expanding out the number of stepping stones that it finds, that it may be
able to get even more far.
And we called this novelty search.
And basically the idea was that we could tell the system to just keep on trying
to find new things starting off from things that had been deemed new in the
past or novel in the past.
And we mean novel in non-trivial ways, so not just in terms of representation,
but in terms of behavior.
And so what it does is it keeps on branching off and finding more and more
new stuff based on new stuff.
And so basically it's an explicit implementation of a divergent search
process without an explicit objective.
And that was important.
So no objective at all, just try to diverge.
And so it's kind of like saying, go everywhere that's interesting.
Now, interesting is a very slippery word, but ideally we want an algorithm that
does that, but I don't know how to formalize what's interesting.
But so novelty here was kind of a proxy for interestingness.
Well, novelty is part of what makes things interesting.
It's not the whole story.
And the story for you is different than the story for me, but it's enough to
get some leverage and start this process going, actually see what an algorithm
like this would do.
So it's pretty interesting.
And so sort of the lesson that this is based on and that actually shows, like
if you look at the results, because it has some results I'm going to show you
in a second that are really interesting, is that basically to achieve your highest
goals, you must be willing to abandon them.
There are some things that we're only going to find by not looking for them.
Now, think of what that means for the pursuit of human level artificial
intelligence. And by the way, this particular principle turns out to be
more true, the more ambitious your objectives are.
So like if your objectives are modest, you probably can achieve them by simply
pursuing them or converging towards them.
But if your objectives are extremely ambitious, like human level, I would say
extremely ambitious objective, then you probably can't converge towards them
simply by measuring progress.
So what does that mean for the progress of the field where, like we actually
are sort of guiding our field in an objective way?
Like we actually act like this is an optimization problem.
Like we have benchmarks and then we measure our performance on those
benchmarks and then we say, okay, the systems that meet the old systems on
the benchmarks that are established are the better systems.
And thereby we have progress.
It's like the higher you get in this tree, the more likely you are to get to the moon.
This is not a very good way of thinking, especially based on this kind of
non-objective paradox I've been talking about, where I call it the objective
paradox that sometimes you can't find things, sometimes actually looking for
something makes you not able to find it.
And so if some things can only be discovered by not looking for them and
that's especially true for ambitious outcomes, then what does it mean for
human level AI, AGI and so forth?
This is a field driven by metrics, benchmarks, increasing performance.
We act like it's an objective driven search process.
At some level we could predict that.
We need to be more open to following the interesting, you know, because the
interesting is sort of this proxy for a divergent concept.
You know, it's not that we're going towards something or even some cluster
of things is that we're trying to build off stepping stones, which have potential
that's unknown, and to collect those stepping stones, we have to be open to
interestingness, and that means not necessarily being so like myopic about
objective increases in benchmark performance.
And so I think there's important lessons at sort of meta level about the field
of AI here, including like sort of like the more kind of ground level insights
about what actually drives creativity in terms of divergence.
So it was interesting that like you can see a novelty search walker on the
right and one from basically trying to optimize walking distance on the left.
And it was interesting that there's many results like this with novelty search
where we actually saw that it would produce a better behavior, like if we went
for novelty, but which by the way means like like falling down is a good thing
from a novelty search perspective as long as you fall down in a new way.
And we saw that that kind of an algorithm is actually producing better walking
gates than one that was actually trying to walk as far as possible.
So it's very counterintuitive again, and it's this objective paradox which is
there, but it's basically because the stepping stones to walking don't
necessarily look like walking.
So we need to be open to things that are interesting because they could be the
thing that leads to the ultimate best behavior.
And many demonstrations like this one, this one just happens to be very sort
of easy to watch.
I have shown this principle.
So this novelty search principle led to a new field called quality diversity
algorithms, or we call them QD now.
And so this field basically said, okay, like knowledge, there's a very radical
proposition, and I obviously understood that from the start, which is that like,
well, if you don't have any way of inserting your notion of quality into
the process, then it's a fairly frightening feeling to launch the algorithm.
We don't know what the heck it's going to do.
And while sometimes it does actually solve a problem, it's no guarantee that
it's going to solve a problem.
It doesn't even know what the problem is because there is no objective function.
And so like, of course, we'd like to insert back a notion of quality into these
kinds of divergent processes.
And that's what quality diversity was about.
And so these new algorithms started appealing, appearing like something
called novelty search with local competition.
There's a map elites algorithm, which basically what they were trying to do is,
is basically collect a repertoire.
So this word repertoire starts coming up.
So not solution, but a repertoire.
And the repertoire would be basically a collection of things that are the best
possible representative, representatives of a set of very diverse niches.
And that means so it's a little different than saying, show me a bunch of top
level things. That's not what it means.
What it means is basically for any extreme niche, like say you're a walker,
you're trying to get ambulating creatures, like even for niches that are clearly
not going to be competitive with the best, like, like a telephone pole is not
going to be a good walker.
But nevertheless, I'd still like to see the best telephone pole walking
gate anyway.
I'd like to see all the best of everything that's possible.
We call that, that's what we mean by quality diversity.
And these algorithms do that.
And you can see that actually they have some practical impact like this
cover of nature that I'm showing here is actually from the map elites algorithm.
And what it did was it was able to evolve a repertoire of walking gates.
So a whole long wide diversity of different ways for this particular
quadrupedal robot to walk.
And then once you have this repertoire, what could happen is if the robot
suffered damage or something changed about the robot, you could just go back
to your repertoire and pick the gate that's most appropriate for the new
situation. So because it had this huge collection of possible gates.
And this was just, I think it's a nice demonstration that this notion of
quality diversity, which is related to the notion of divergence does have
practical ramifications.
It's not just about like creating images or something like that.
But even quality diversity won't invent forever.
And I want to really hammer on this because I like to be like, you know,
super critical about like where things are going.
It's not like, OK, now we can celebrate.
Thank you. Quality diversity is the end.
Now we're going to get human level intelligence.
The problem is that like open-endedness is a very profound problem.
It's as profound as artificial intelligence.
Because think about it, what happens when the space of the possible is
filled even by an algorithm like that?
Like there's only so many gates that are possible, at least only so many
gates that are of any interest to us that are possible, at least for any
given robot.
So where do the new possibilities come from?
And how could they come around forever?
Like what will lead to something like that?
Nature looks a little bit like that.
You know, the word forever is an extreme word.
And of course, I don't know that nature would somehow top out at some point.
Or obviously the sun will explode or something like that.
But let's give it credit for going for at least a billion years.
That's as close to forever as we're ever going to get.
And so these algorithms are not going to go for a year or even like a few
weeks, we'd be lucky.
And so what's missing then?
How do I would keep it to keep finding new things to do?
And the answer is that the system needs to generate not just an endless
variety of solutions, but new opportunities for solving things.
They're basically new problems.
The system has to generate the problems and the solutions and they have to be
self-generating since no one can anticipate a curriculum all the way up
through a billion years.
It's the system's job itself to generate that curriculum.
And this is the key to Earth's open-ended creativity.
It's generating both the problems and the solutions.
And that's an interesting thought because where are the problems coming
from that we're solving?
Well, they're coming from each other.
You know, the thing is we are both the problems and the solutions like we as
the organisms that are being evolved, you know, because the existence of
anything creates the opportunity for something else.
So like the existence of trees now makes it possible for us to have
drafts and drafts are solving a problem.
But the problem was actually created by the trees, which is how do you get to
the leaves of the trees when they're high up?
And so all of us are creating or maybe I shouldn't even call it problem
opportunities for each other.
You know, the fact that I'm standing up here gives you an opportunity to learn
something, but also the fact that you're in the audience can be an opportunity
to talk to you and so forth.
And so we're all creating opportunities for each other all the time.
And that is the source of why this process can go forever.
And so this is the inspiration for new kind of cutting edge algorithms that
are trying to get closer to open-endedness.
And we really would love to produce a truly open-ended algorithm.
And the space of problems is a lot different from the space of solutions,
isn't it?
Like the space of solutions is we've been grappling with that for a long time.
And like deep learning is all about a space of solutions.
They happen to be a neural network space is a kind of a neural network space.
But the space of problems is much harder to understand.
Like because what is it seems to encompass like everything we could
possibly imagine.
And so like if we need to deal with representations, then how do you represent
problems as opposed to solutions?
And what keeps them interesting and meaningful forever?
And so like one recent example, just to give you a taste was like we introduced
this thing called minimal criterion co-evolution about a year ago.
And so the idea there was let's have just the problem space be that be mazes.
And then the solution space are neural networks that can solve these mazes.
And we created this kind of co-evolutionary scenario where the mazes keep getting
more complex and so do the solutions to the mazes.
And so what happens is that the mazes are expanding over time and you're
constantly getting solutions to those mazes.
And it's kind of interesting in the sense that actually it might be the case
that if I could run this for like a billion years and had sufficient
hardware, which I don't, so this is just a hypothetical, then maybe this
maze would be the size of the galaxy and maybe there'd be a neural network
solving it.
And so while that's not quite as great as like creating new forms of life,
it's still kind of interesting that this could be an algorithm where
something interesting or something truly different than something that we have
access to right now could arise, given like hundreds, thousands,
millions of years of computation.
And so this is just sort of scratching the surface of like where we might be
able to go with open-endedness, of course.
I wanted to end by just showing some examples of creativity or open-end or
attempts to move towards open-endedness in some applications today, just to
give you a taste so that you can kind of basically spark your imagination.
You know, because it's one thing to talk theoretically about these things,
but it's probably going to give you a different kind of a way of thinking
if you see, well, what could I do with something like this?
Like, here's a video game called Galactic Arms Race that we introduced
where it was using a pick-breeder-like process to actually open-endedly
generate new kinds of weapons.
And so basically the game just generates weapons like endlessly inside of the
game based on the players playing.
And these are all new inventions of types of weapons I've never seen in
other types of games.
And it's, it actually sold a couple thousand copies.
And I'm not saying that to show off, but basically I'm saying that because
it's worth noting that, that, that, you know, there's actually
economic value in open-endedness.
You know, people do want things that keep on inventing forever.
You know, you can imagine designs of, of, of objects and manufacturing.
Music is something that is now being generated a lot.
This is interesting.
This is where people, we let people on Facebook evolve
flowers in a pick-breeder-like way.
But look, the interesting part, which I just, it's maybe spark your imagination
is that you could press a button and order one back to your house.
And so you could like give it to your girlfriend or your boyfriend.
And this is a custom flower unlike any other flower.
And there it is in 3D.
What other things could we do like this?
It's pretty interesting.
So if you're interested in more thoughts on, on Divergent Search,
we wrote a whole book about this, myself and Joel Aiman.
It's called Why Greatness Cannot Be Planned.
I can't obviously cover all these ideas in just 30 or 25 minutes.
And actually I'm already over 25 minutes trying to end.
But there's, there's a place you could hear more of our thoughts.
So if we're interested in open-ended creativity and we want to match
what we see in nature and even perhaps to achieve human level AI,
we must travel the road with no destination.
We must be willing to do that.
And that's going to require us to change some of our thinking.
There are many destinations that are reachable through no other process
than not trying to reach them.
And therefore we have to confront the grand challenge of open-endedness.
And I want to highlight that grand challenge of open-endedness.
I believe this is a challenge just as worthy as AI of huge amounts of resources.
If we could conquer open-endedness and create algorithms that create forever,
we will have opened up a massive sphere of possibilities that's currently not
not available to us.
The power of creation is the power of open-endedness.
I wrote this article with some co-authors to help introduce the field.
And so if you wanted to get into the field and you never heard of it before,
this is a really nice layman's intro.
And finally, please feel free to email me.
I'll really like to talk about these things or tweet me or whatever.
Here's some links to some of the things that I've mentioned.
OK, thank you.
OK, thank you for your talk.
And here I am again, the voice of the people.
We have one from Martin Rabovec from Revolvec.
Martin.
OK, got him.
Isn't evolution just a reactive process towards more effective reproduction?
Open-ended because of the always changing environment?
So that's actually any time so it's a it's a what evolution is like is a very
complicated topic, you know, and any time that somebody might say, well,
evolution is just this, like so to like this question, just this, this is what
it really is, OK, let's let's then then write that as an algorithm, you know,
sort of my bar is that, like, if you really think you understand something
and you're not sure what it is, you know, what it is, what it is, what it is,
what it is, what it is, what it is, what it is, what it is, what it is,
if you understand something from an AI perspective, then you should be able to
formalize it and write it down and then it should give me what I'm asking for.
So if that's all evolution is, then let's just write it down and then we'll
have open-endedness and you've just revolutionized the field.
And which is why I think it probably is not just that.
It's probably not just anything that anybody here thinks it just is.
You know, you may have read your biological biology textbooks and you
may think that you know what evolution is and it may make sense.
But actually, I can almost assure you that there's going to be a few counter-intuitive
kind of curveballs that are thrown into that, that story that we learned in high
school which aren't in the textbook because if there weren't, we would just
take the textbook and formalize it and it's not that simple and people have been
trying to do this for 50, 60 years.
So evolution is a very complicated and subtle process and what we mean by it is
different than just optimization if we're talking about the open-endedness aspect
of it, which is probably the more interesting aspect of it.
But just saying from an optimization perspective, like, how can I explain why
hyenas are as fast as they are?
Okay, there maybe you can give me an explanation.
But that's not the same as sort of formalizing the whole thing as a process
that's going to produce this kind of grandiosity of nature on Earth.
Then Lukas Linnhardt strikes again.
How would you evaluate whether something is creative?
That's a really good question and it's really hard and actually it's one of the
obstacles that we face towards creating systems like the type that I'm advocating
because they're so hard to evaluate.
And that actually causes us to not want to create those systems because we've created
a culture in the field of artificial intelligence and machine learning where
everything has to be evaluated in order for us to make progress.
So like, I can't submit it to a conference if I don't have a very, very
concrete evaluation metric that's very objective.
And so what we may have to do is to acknowledge that some things are actually subjective.
You know, I mean, we're talking about creativity.
Ultimately it is kind of in the eye of the beholder.
I mean, I could argue with you actually that everything in nature is not interesting.
You know, it's just a matter of opinion.
I find it interesting.
There's no objective proof that everything is interesting, including us.
But we've accepted that it's interesting.
We accepted intelligence is interesting.
You know, why are we all pursuing it?
And so ultimately like creativity is partially a subjective matter.
And so yeah, there's some interaction between our subjective view of the kinds of things
that we find interesting and some like modicum of objectivity, which is sufficient at least
to present to you an experiment.
And that's something we're very uncomfortable with, like we want it to be entirely objective.
So you may have to grapple with that in order to actually start to really flourish with
creative systems.
Okay.
And for the sake of time, final question.
And for once, let's take the most controversial one, Jeff Thompson.
Over there.
I don't want my taxi creatively evolving while driving me to the airport.
Why is Uber creating human level AI?
Okay.
So I 100% agree with that comment.
Like I do not.
I don't advocate creative driving at all.
That's just I'm just speaking for myself here.
But but yeah, that's that's not a good idea.
And certainly there are tasks here that that machine learning is addressing that we just
do not want to be creative.
You know, let's acknowledge that.
And I don't mean to convey through what I'm saying that everything should be creative
and creative driving is one of those.
Now human level is a different matter, I think.
So so you think why is Uber pursuing human level I human level AI Uber?
So Uber is is just pursuing artificial intelligence and machine learning because these are very
important and have a huge potential impact on their businesses as is obvious across many
aspects of the business, not just cars.
So I don't think Uber necessarily would would have an answer on the human level AI.
I mean, I'm at the human level AI conferences isn't necessarily an endorsement by Uber for
human level AI.
And so but it just it does so happen to be the case is with many companies, I think that
that in the pursuit of increasingly sophisticated and effective artificial intelligence technology,
moving, you know, in a direction that has some relation to the human level.
So so of course, like moving in that direction is important for being able to compete in
the world of machine learning, which is really important today.
OK, let's thank Kenneth.
