Great. Yeah, so hi, I'm Hyunjin Chung. I'm a PhD student at bio-imaging and signal
processing and learning lab at KAIST Korea. I'm honored to give a talk in such a prestigious
group in other lands. And so thank you very much for having me here. So today I'll give
a talk mostly about diffusion models and how to use them to solve inverse problems in imaging,
focusing on a few recent papers that I wrote. So specifically it will be focused on base and
inference in the context of inverse problem solving. So I believe it will be of quite a
relevance to you. And I'm pretty sure that most of you are already familiar with diffusion models,
but some of you may not be familiar with inverse problems. So and since we have a rather small
group, I feel free to speak up with your microphone. I'm very sure that I'm going to miss some chats,
so I hope the talk will be as interactive as possible.
Yeah, so the talk will be structured in a bit of an odd way because we're going to first talk about
two closely related work in a reverse order. So the first part of the talk will be about a paper
named DPS, accepted to iClear recently. Then we will move backwards and talk about MCG,
which was supposed to be the main content of the talk today. And finally, if time allows,
I would also like to briefly touch the most recent work that applies these methods to more advanced
problems called blind inverse problems. So I'll just briefly cover the basic concepts of diffusion
models. I don't want to bore you too much, but I'll just speak in a briefly in a score perspective.
So what we do in diffusion models is we try to estimate the gradient of the lock density with
the neural network S of theta, which points to the high density most of the distribution.
In order to circumvent the intractable explicit score matching, you train your network with
denoising score matching, which boils down to essentially training a residual denoiser.
Once that is done, you can use the train score functions to sample from the distribution p of x
with, for example, Langevin MCMC. And another interesting view is that one can view the data
noising process as some linear forward SE, and the data generating process as the corresponding
reverse stochastic differential equation, where the drift function is governed by the score function.
Hence, when we want to sample data, you can discretize the reverse sd and numerically solve
it using the pre-trained score function. On the other hand, here we are interested in solving
inverse problems. In the inverse problem setting, our aim is to recover the ground truth x
from the noisy measurements y obtained through some integral imaging system A.
And there will be some pollution of noise, and the problem is naturally opposed,
which means that there exist infinitely many solutions to this problem.
Meaning that given this noisy blurred image of the leopard, there could exist a lot of
different feasible answers to the actual clean image. So in order to correctly specify which
one of the solutions is the one that we want, we need to specify the prior of the data distribution,
and in other words, how the images would actually look like in real world.
Examples of such inverse problems include in-painting and deep learning in the context of low-level
vision. They're also called image restoration problems. And in the context of biomedical
imaging, there could be compressing MRI, sparsive CT, and so on.
So we'll go over how we can solve such inverse problems with diffusion models.
So let's first consider the following measurements model.
Now, given y, what we want is to sample from the posterior distribution p of x given y.
And using Bayes' rule, it's straightforward to see that the gradient of the log posterior
is the sum of gradient of the log likelihood plus the score function.
Here, gradient of the log likelihood in red gives us the information about the measurement process.
And the score function is what we've already estimated with the neural network.
So one should note that the likelihood function p of y given x is in most cases known
and in 95% of the cases, it can be modeled relatively well with the Gaussian.
And among the rest of the 5%, 4% is Poisson, meaning that the likelihood function is often
known a priori. So hence, in the perspective of Bayesian reconstruction, all we have to do when
posterior sampling is desirable is to specify the correct prior distribution. Then the measurement
process is hand wavy, it's known so we can sample from the posterior.
So let's consider the case where we modeled the data distribution with the diffusion model.
From the score or the SDE perspective, recall that the generative process is defined by this
general form of reverse SDE. So in order to do unconditional sampling from the prior distribution,
we can use the following discretization steps of the reverse SDE.
So for simplicity, I denoted Euler-Maruiama discretization here, but other forms of sampling
can of course be used such as ancestral sampling of DDPMs or hybrid methods that incorporate
MCMC chains within the numerical integration solvers. They're called predictor-corrector
solvers in score SDE paper. Moreover, when we want to do posterior sampling,
we can use what we've derived from the Bayes rule and incorporate the gradient of the walk
likelihood. So here comes the problem. Can I ask a question?
I'm sorry, I'm decently new to the diffusion model, so maybe there is something I didn't
understand. I don't understand the sign, why there is a minus sign in front of the even
in the original paper, why there is a minus sign in front of the gradient of the score.
Oh, so you're asking, how did the reverse SDE come along here, right?
Well, I'm saying that with that minus sign, it will do the opposite of going to the high
probability regions. It will go away from it. So am I missing something?
Oh, yeah. So intuitively, if you want to sample from the high density modes of the distribution,
you would kind of do gradient ascent with it. And yeah, there's a caveat here because
the differential dt here is a time running backwards. So yeah.
But then the sign of f is wrong, because the sign of f should have the same sign of g, doesn't it?
Actually, no. So the derivation process of this reverse SDE comes from a thing called
Anderson's theorem. So if you plug in this general form of forward SDE, then there's a
theorem that states that this reverse SDE is the correct form.
I understand. But so if there isn't, let's say that there is no score, so there is no goal,
then if you have a, let's say, a all-ston-Ulenbach process, the forward and the reverse dynamics
are the same. So you're saying that f dt is running backwards, then f should be negative.
If you have a stationary process like an all-ston-Ulenbach, regardless whether you run it forward
or backward, you have the same dynamics. Therefore, you are not going to flip the sign of f if you
change the time. Let's say in an all-ston-Ulenbach process, f induces the mean reversion. So if you
actually flip the sign, you will have the process going away from the mean, which is not the reverse
time process. The reverse time process wants to go back to the mean exactly like the forward process.
Right, right. I'm also a bit confused myself.
Because everything works, I think, I don't know. So again, I could be misinterpreting something.
Because I do see this in papers, but I just,
it's, again, if it's an all-ston-Ulenbach process, the forward and reverse dynamics,
assuming it's called zero, should be the same. So you cannot flip the sign. Otherwise, you get
the opposite. You get the diverging process. And if you assume the generative direction to
be forward, then the sign of the score should be plus, not minus. But of course, it would become
minus if you are actually considering that going backward. But, okay, but maybe we can discuss
this offline. And also, I mean, again, it could be that I'm missing some details of the notations
that for which things will match up, you know. I'm not sure if, especially in the case of
Einstein-Ulenbach process, is there, is the score function zero there?
Well, so if the forward process is all-ston-Ulenbach, then f of x of t is just minus alpha x.
Right. And that would be true both in the forward and in the backward. Because again,
it's time invariant. If you flip, you don't change anything. The score happened in order
to enforce the terminal condition that the process has to fit the data.
So it, in this sense, it's nothing to do with the all-ston-Ulenbach process. It's just a
starting point of the process, which if then, if you want to reverse, it will actually go back to
there. Yeah, I think we should come back to this later. I think it's better to discuss.
Yeah, I'm sorry.
So coming back to where we were, I think it was right here. So I was talking about how we
could switch from prior sampling to posterior sampling by just plugging in this Bayes rule.
And here I said that care must be taken here because the gradient of the log likelihood
is, in fact, intractable. And note that this is different from my claim earlier that the likelihood
function is, in most cases, known. And this arises from the fact that there are noisy x i's here,
rather than x zero. So let us dive into closely examine what I mean by this.
To see why this is the case, I'm sorry that I'm switching notations with i and t.
For i's, I'm denoting discretized things. And t, I'm just pointing at some general
continuous time instantiations. So here, consider the following probabilistic graph
in the context of diffusion models. So we know two conditional distributions, p of y given x
zero and p of x t given x zero. And for now, let's assume that the first one is the measurement
distribution is given as typically Gaussian. So, and the second word, the forward distribution of
the diffusion is also Gaussian. However, the reverse distribution p of x zero given x t,
shown with blue dotted line is intractable in general. So hence p of y given x t is intractable
because we have no information about this blue dotted line.
So in our work, we aim to approximate the intractable distribution. The first key comes from the
factorization. Since x zero is conditionally independent on y and x t, we can factor the
integrand as follows. Where the former term is what we know, and the latter term is what we
partially know. And by partially known, I mean that we know how to obtain the posterior mean
which is given by the 3ds formula. Note that 3ds formula is used widely in diffusion model context
as it states that the posterior mean or the denoist estimate can always be achieved when we
know the so-called blurred score function. That is the score function of the intermediate
noisy variables x t. Here we see that we can plug in 3d denoising
to achieve some posterior mean of the distribution in the context of ddpms.
And to fully enjoy the effectiveness of 3ds formula and because leaving the expectation
outside is intractable, let us push the expectation inside for now.
When we do that, by the 3ds formula proposition, we have a fully tractable distribution
where the condition is now given by x zero hat, the denoist estimate from x t.
Now, since we propose an approximation here, it is important that we quantify the approximation
bound. And for that, we have a theorem that states the approximation error,
where the so-called Jensen gap, and used by pushing the expectation inside the function.
And we show that this approximation error is upper bounded by this constant
with three constituents. So the latter two parts are usually bounded in most practical
situation. And the interesting part here is the first one, where we see that when sigma
goes to zero, the entire constant goes to zero. This is useful because it states that in cases
where we have negligible measurement noise, the approximation will be tight. However,
in practice, even when we have high measurement noise, the method also works very well.
So just summing everything up, thanks to theorem one, we can achieve what we call
diffusion posterior sampling, or DPS in short. We start with standard Bayes rule in the context
of diffusion models. We can apply theorem one to get the approximation,
the
high loss thing. I don't hear anything anymore.
Any more? Oh, okay.
That's great. Do you hear me now?
Yeah. Yeah. Yeah.
Sorry. Where did the
screen?
Yeah, I don't have any sound anymore.
Yeah, now we're here. Yeah, now it's back.
But we cannot see the screen.
And you can try to share the screen again.
I can see a screen. I can see the screen, the Gaussian and Poisson.
Yeah, me too. Yeah, I'll show you.
I don't. Yeah. Can you try to just stop sharing again? We share it again.
Yeah, sure. Thanks.
So is this where the connection was disconnected?
Yeah, you were just starting about the Gaussian and Poisson.
Yeah. So I was saying that these gradients can be analytically computed
because these functional forms are already known.
So we see that for Gaussian, we're essentially performing gradient descent
that minimizes the square del 2 norm of the residual.
I cannot see the slides.
Yeah, neither. No.
Oh, they just dropped out in the halfway through your sentence.
Okay, so let's try to reshare.
Yeah, now I can see that.
Yeah, me too. Thanks.
So does this work?
Yes, it works.
It seems like it.
Yeah, so yeah, I was saying that for Gaussian measurement models,
we're trying to do gradient descent that minimizes
the square del 2 norm of the residual.
And for Poisson measurements, we're minimizing the square weighted norm of the residual.
So incorporating ancestral sampling for DDPMs, we have our algorithm of DPS
where we can derive separate algorithms according to the measurement model in hand.
Note that line 7 is where DPS takes place.
If we were to remove line 7, we would simply be sampling from the prior distribution,
the usual diffusion models, what they do.
And hence, our algorithm is just very simple modification of the usual DDPM sampling.
When we do that, we achieve these results.
So since our method is not dependent on the measurement model,
we can apply the same score function to various problems.
For example, this is the result of applying our method to super resolution
that are contaminated with Gaussian noise.
We can also apply our method to noisy in-painting.
And this is the case where 92% of the pixels are blocked out in a 256x256 image.
This is noisy Gaussian deep learning.
We can do noisy motion deep learning.
Since we're not restricted to the choice of the forward operator A,
for the first time in the context of inverse problem solving with diffusion models,
we show that we can also solve nonlinear inverse problems,
such as phase retrieval presented here.
And for those of you who do not know what phase retrieval is,
it's a problem that tries to estimate the phase and the Fourier domain.
And this is a notoriously hard problem because most of the information of the image
is actually concentrated on the Fourier phase,
rather than the Fourier magnitude of an image.
And we can also solve problems like non-uniform deep learning,
which is another nonlinear inverse problem,
given that the forward measurement model is actually differentiable.
This is one application that I want to highlight
because we actually used a complex neural network that emulates the nonlinear blurring here.
And neural network is one of the most nonlinear forward models that you can imagine.
So even when the forward operator is highly nonlinear,
we can see that DPS is capable of recovering the image with high fidelity.
So that was it for DPS. I think we can briefly stop to
see if any of you have any questions.
I have a question. So basically, did you also show,
because you can have, due to the stochasticity,
you can have posterior distribution of the denote samples, right?
Do you notice a difference compared for the one you, the blur, for example,
this image, do you get some deviations that are meaningful in one sense?
Yeah. So I'm sorry that I don't have examples here, but yeah,
you do see quite a bit of stochasticity, especially when the degradation is heavy,
as for example, the example here, blurring is heavy.
So the posterior samples have high standard deviation in terms of reconstructions.
Yeah. Next question. I don't know if you already explained it and maybe
let me study that, but you also mentioned that reconstruction is possible if you have a prior,
right? Right.
But how do you choose the prior? Do you learn it or is it something that you'd have to?
Oh, yeah. So the thing that we're proposing here is that we're using the diffusion prior, right?
So we're using this generative prior and the prior is learned through the usual training
process of diffusion models. So whether it be score matching or epsilon matching or whatever,
we only, what we only need in the sampling process is the pre-trained score function,
S theta here. So all the examples that I show you here are generated by
pre-trained models available online. So specifically, we use the open AI model,
and we don't need any fine-tuning for any of these problems. We can just plug it into the
solver and it will, that will act as the prior of the distribution.
Okay. So the prior is trained on the data that you use it on. So you use the same version of
the model pre-trained on different data. Yeah. Okay. Thanks.
So how this method would differ from the paper also from song et al for inverse problems in
medical imaging? So is there a likely difference? They are different and that will be covered more
in detail in the second section where I explain the nearest paper.
Yeah. So if you could summarize, for example, in a few words, because the main paper from song et al,
you can also do inverse problems straightforward. I mean, you can do the painting. What would be
like the main contribution is this non-linear approach to inverse problems or what would be
the main difference? So it's two things. I guess I'll try to explain it later. So you're mentioning
the original paper of song et al at iClear 2021, and there was a paper that you mentioned that
tackled medical imaging in the next year of the same author. They solved inverse problems by
using a so-called projection approach, which means that you're directly replacing what you have as
the measurements, and you're keeping only the rest of it. So this is the visualization of such
projection process. And this projection process works for certain inverse problems, for example,
in painting. And for in painting, when you have like a small degradation, for example,
the mask is small or the blocked out pixels are not dominant. In those cases, projection
approaches work fine. But for example, when you have a large mask, for example, a 128 by 128 mask
cure, when you apply Song's method, projection type approaches tend to fail dramatically.
This is also relevant to the case of medical imaging, where you have high degradations.
These projection based approaches will typically fail, whereas DPS that I
proposed in the last section, and the MCG that I will explain soon after,
does not have this property. And like the methodological main difference is that
you Song et al. use projection type approaches, whereas MCG or DPS uses gradient type approaches.
So it's a smoother transition towards the that adapts to the measurement process.
Yeah, that's pretty nice. Yeah, that's pretty clear. Thanks.
Yeah. Okay. Should I should I move on to the next section?
Okay. Yeah, thanks. Yeah, so the next paper that I'm going to talk about is is actually a paper
that came before DPS. But I explained DPS first, because it really uses the same gradient. I would
say similar, but almost the same gradient method with DPS. But at the time of development of MCG
paper, we did not really understand how mathematically the solvers would be derived. So here in this
paper, we focused more on the explanation in the geometric context of diffusion models. So I hope
that this also helps the understanding of the underlying intuitive
things about these gradients based methods. So in order to understand the paper, let us review some
of the important properties of high dimensional, a Gaussian random variables. And specifically for
very high dimensional Gaussian random variables, while the mode of the PDF may be near the mean
of the distribution, the measure is actually concentrated in the annulus that is distant
from the center. This is the reason why when we add fixed variance Gaussian noise to an image,
you never really see a clean image, even when the highest probability of a Gaussian noise would
be zero noise. We always get images with very similar noise levels. Now, extending that,
let us think of a random variable y that is corrupted with Gaussian noise by adding some
noise. Sorry, can you maybe rephrase that? I mean, I think that's interesting, the slides before.
So the concentration of Gaussian measure, right? Yeah, so this is a Gaussian annulus theorem,
right? And then the effect that we see, what you said is that we don't see like, so we see the same
effect, right? Or what do you mean? Definitely. So because of the Gaussian annulus theorem,
what we see when we add Gaussian noise to images with, let's say, fixed variance Gaussian noise to
an image, like, I guess the highest probability instantiation of this Gaussian distribution would
be no noise, right? Zeros. But that never happens. So if you add some random Gaussian noise to an
image, you will always see some very similar noise level images that are corrupted in a very
similar way. So that was what I was talking about. Yeah, okay. Yeah. So it's also due to the convolution,
right? You can observe this as a convolution. Yeah. So this is kind of related to what I
was talking about before. So let's say you have like a linear space of X. And what you would do is
you add some Gaussian noise to that random variable X. Because this is a convolution,
we can show that the marginal distribution P of Y is actually a, the measure actually
concentrates on the hypercylinder that is distant from the center of PX. So this is kind of intuitive
reason why the noisy images with the fixed variance have similar looking structure.
So in this work, we propose to interpret diffusion models using some assumptions about the data
manifold. So the usual manifold hypothesis states that the data lives in a low dimensional manifold
with much smaller dimensionality than the ambient space. And in this work, we add an additional
strong assumption that the manifold, the central data manifold is locally linear. And in order to
leverage, and this is because we want to leverage the results from the concentration of Gaussian
measure. And specifically, when we assume that our data manifold is locally linear,
what we can show is that the geometry of diffusion model is given by the successive
manifolds where there exists a clean data manifold in the center. And there are continuously
noisy manifolds where the noisy samples reside. So these are the manifolds of the noisy images.
Extending that to a continuous limit, we propose that diffusion model is an onion, because where
when we push T to infinity, the distribution actually becomes a pure Gaussian. And since the
measure of a high dimensional Gaussian resides in a Gaussian hypersphere,
the intermediate manifolds are covers of the central manifolds that interpolates between these two.
And therefore, this diffusion process would correspond to these red arrows,
and the reverse diffusion would correspond to the blue arrows.
And furthermore, when we are considering the case where we are trying to solve inverse
problems with diffusion, we are left with the figure on the right. Here, we are not only trying
to find points in the central manifold M, but we're trying to find the intersection between
the manifold M and the line y equals hx. So I've already said this earlier, but let's examine
some of the representative methods that solve inverse problems using diffusion. These methods,
Song and L and Choi and L, are type of projection based approach, since they directly replace the
part that is known, and keep only the unknown part. Another way to impose data consistency
in the Bayesian framework is to incorporate likelihood. In other words, try to minimize the
residual by gradient descent. However, with diffusion models, if we were to use naive gradient
descent with a noisy residual, we will acquire no meaningful gradients, as the residual between
hxi and y will only be focused on the Gaussian noise part of the residual.
Now, as we saw in diffusion posterior sampling, one can actually approximate the correct likelihood
by switching to 2D denoised estimate x0 hat here. Here, visually and intuitively, we see why this
may help. This is because after denoising, the residual is more likely to focus on the structural
differences between hx0 hats and y. In practice, using this gradient step over the projections
work much, much better. And you can see the kind of the resulting differences when we use
projection type approach and the gradient approaches. So in the paper, we properly
analyze why this would be the case, leveraging the geometric understanding of diffusion models.
So first, under our assumptions, we show that 2D denoising corresponds to an orthogonal projection
to the data manifold. However, note that we have to consider two components of the data manifold,
the orthogonal one that is related to the noise components, and the tangential one that is related
to the data fidelity. So score function alone cannot handle the data fidelity. And here comes
our theorem, which states that the proposed manifold constraint gradient term points to a
direction that is tangential to the central data manifold. And therefore, our solution will move
closer to y equals hx every time we apply this mcg step. Another important aspect of this is that
since mcg lets the sample move on the data manifold, whereas projections move the sample
off the data manifold because projections are hard constraints that try to make y minus hx
equals 0. Note that mcg will not do that. It will move on the data manifolds in the direction
tangential to the manifold. So those falling off the manifold will not happen.
So here, note that the score functions that are pre-trained were not trained with
samples that are off the data manifold. So they were trained with the samples that were on the
noisy data manifolds. So it will not be able to properly denoise samples that are off the data
manifold. So by using projections, the intermediate error will probably accumulate. And we conjecture
that this is the reason why projection-based approaches often fail to produce a good sample.
But however, as I said, in the time we wrote mcg, there was a gap between theory and practice
because even with the mcg steps, we had a hard time trying to solve inverse problems. So we had to
resort to some projections within the denoising and the gradient steps. But in DPS, we managed to
achieve a general solver that only uses these gradient steps. Now, for the Gaussian case,
the only difference between mcg and DPS is that we do not use projections for DPS.
Leveraging the geometric viewpoint of diffusion models, we can think that DPS is superior to
mcg specifically because we avoid such projections. As projections here can potentially throw samples
off the data manifold. Hence, DPS will typically be more stable by avoiding such throw-offs.
And by the way, this is just an illustration. It doesn't really guarantee anything that
our solver will always stay on the noisy data manifolds.
Yeah, so that was about it for mcg. Any questions up until now?
I just have a question, but maybe a very simple question. At the beginning of this slide,
when you were explaining the next one, two after this one.
And then, but yeah, this one, the previous one. Because how do you define this k? So n,
I am, what is n and what is k? I would have to look for the definition of n and k here.
So one of them. So I would, from my memory, n is the dimension of the ambient space in case
the dimension of the locally linear low-dimensionality of the data manifold.
I guess you're assuming that this, so the brown, the mean is basically use the mean of
each intermediate distribution, right? So it's the mean of the diffuse or denoise distribution,
right? And then this, I'm just wondering, shouldn't start going from a big
standard deviation to a small standard deviation? Because basically, when you do the denoising,
you start with a high variance and then you start denoising and the variance slowly decreases.
That's just something I was thinking that if that's not the case, so I'm missing out something.
Can you repeat the question again? I'm not sure if I understood it correctly.
Yeah, so the point of this is to interpret what's going on, like how the denoising samples
behave in the data manifold through the trajectory. So when you do the denoising,
so you start with the isotropic Gaussian, which is the highest entropy you can have. So you start
with the maximum variance that you have and then slowly you start removing the noise and by doing
that, interactively, the variance at each intermediate step goes down, right? So what I was
expecting is to have this behavior when you have the mean and then the variance is large at the
beginning and then starts decreasing because ideally you would reduce the variance, but I don't
know if I'm missing something there. Oh, but I think it's what you're saying is kind of
different from what this slide is saying. So I'm not really stating anything about denoising anything
because the flow here is that we're first assuming that there exists a central data manifold M here
and then we're trying to visualize how the manifold of the noisy images would look like
if there exists the central data manifold M. And I'm claiming that these noisy data manifolds will
be covers of the central data manifold, where the distance between from the central data manifold
will be defined by this constant value. So it's really not about starting from high variance
Gaussian noise and reducing it to anything. We're starting from a clean image and then
we're defining the manifolds of these noisy images. Okay, so I would have to look at the
paper I guess also more too. Yeah. Yeah, thanks. So I guess we just tell me if I'm
okay. It's a good cliffhanger.
Um, do you hear me okay?
Yeah, you know, yes. Yeah, so I think it's about 48 minutes. So I don't think we have to go over the
final section. So yeah. So I'll just try to. We just, we cannot see you or the slide anymore.
If you can do the same thing as before to stop sharing and start again. Yeah.
Well, well, the talk is basically done. So. Okay. That was the last slide if we don't cover
the last section. I'm not sure if this is the correct way of saying thank you very much in Dutch.
Maybe you should put it in Italian.
Yeah, so yeah, that is the right way to say thank you. Thank you too.
