Hello world, it's Siraj and we're going to build a convolutional network using no libraries,
I mean just NumPy, but no libraries, no TensorFlow, no PyTorch, none of it. We're going to look at
the math behind it and we're going to build it with just NumPy for matrix math in Python.
Okay and what it's going to be able to do, let me just start off with this demo to start off with,
what it's going to be able to do is recognize any character that you type in or not type in but draw
in with your mouse. So you could draw a six like that and then hit submit, it'll start working
and then it'll say it's a six and then if you don't want to use a six you could say a letter like
a any number or letter it's going to be able to detect slash predict. So it's going to be really
cool because we basically were wrapping it into a web app using the Flask web framework. So it's
going to be it's going to be super awesome. Okay so that's what we're going to do today
and this is our first neural network that we're building in this course from scratch.
I mean we made one in the weekly video but this is the real you know hardcore convolutional network
with all the layers all the functions everything. Okay so let's start off with what it's inspired by.
Well it's inspired by Jan Lacoon, the genius, no it's not. So Jan Lacoon is a director of AI at
Facebook. He's a total G, he is awesome because he was inspired by these original two guys right here
who published a paper in I think 68 or early 60s or 70s but the paper was on the mammalian
visual cortex and the idea they had was and so here's a great image of it let me make it a lot
bigger this has to be a lot bigger. So the idea they had was that mammals all see in a very similar
way and that way is hierarchical. So you have a collection of cells and these cells are neurons
and these cells cluster and and these clusters represent different features that are learned.
Okay so here in terms of neuroscience they call these clusters v1 v2 you know they have names
for all these clusters in the brain these clusters of neurons before it posterior all this
neuroscience terminology but what we need to know is that at a high level what's happening is every
time you see something a a series of clusters or layers of neurons are being activated whenever
you see something whenever you detect something to be more accurate. So if I detect a dog or a
you know face or whatever it's going to be a series of layers or clusters of neurons that fire
and each of these clusters are going to detect a set of features okay and these features are going
to be more abstract the the higher up the hierarchy of clusters you could think of it as a vertical
hierarchy or even a horizontal hierarchy what it doesn't matter but the idea is that there is a
hierarchy of features and at the start these features are very simple they're lines and edges
but then they get more abstract then they become shapes and then they become more complex shapes
and then eventually at the at the highest level at the highest cluster level exist the entire face
or the entire dog or whatever it is and this is how the mammalian visual cortex worked and so
what Yanlacun said and his team in 98 when they published probably the landmark paper of convolutional
nets which is kind of arguable I guess because Khrtchevsky's ImageNet paper was pretty good in
in I think 2012 but anyway Yanlacun is a G I just wanted to say that he had the idea to be inspired
by three things three features of the human or the mammalian visual cortex local connections
and that means the clusters between neurons how each neuron each set of neurons in a cluster
cluster are connected to each other and they represent some set of features and then the
idea of layering how these how there's a hierarchy of features that are learned and spatial invariance
what does this mean this word spatial invariance it means that whenever you or I detect something
whether it's let's say we're detecting a shoe right we if you see a shoe you know it's a shoe
right if it's a Yeezy if it's uh you know Adidas whatever it is you know it's a shoe
it could be shaped this way or this way it could be rotated or transformed no matter how it varies
we still can detect that it's a shoe we know it's a shoe so we are it is the way its position is
it's spatially invariant we can still detect what it is and so those three concepts were what inspired
the birth of convolutional neural networks programmatic neural networks designed to mimic
the mammalian visual cortex how cool is that that's so cool so how does this thing work
let's look at how this works so we have a set of layers okay and we'll talk about what these layers
mean right what is layer a layer in each case is a series it's a series of operations that we're
okay so let's let's talk about this right so we have some input image so let's see
this is the orange that's the image and you'll notice by the way that this image this is a
convolutional network by the way this is what we're building okay you'll notice that this image
right here or this image of the convolutional network isn't what you normally look at when
you think of neural network right you always see that image of the circles and everything's
connected so why is it different for convolutional networks because every layer in a convolutional
network isn't connected to every so every neuron in every layer isn't connected to every other neuron
in the next layer why because that would be too computationally expensive i'll go over that in
a second but the idea is that if you if you see here there is a part of the image that is connected
it's this little square of that orange and that is called the receptive field okay i'm going to go
over all this it's going to make more and more sense you're going to be more confused it's going
it's going to make more and more sense as as i go further and further in depth here so so so stay
with me here so we have a receptive field okay that is some part of the image that we are focused on
we are by focused i mean that is the part of the image that we apply a convolution operation to
okay and we take that receptive field and we slide it across the image okay you're going to see
exactly what i'm talking about in a second i'm just going to go over at a high level we slide
over the image we are applying a dot product between our weight matrix at a layer and every
part of that image iteratively okay and so that the reason that they look different the convolutional
networks look different is two reasons really the first reason is that not every neuron in each
layer is connected to every other neuron in the next layer it's only a part of that because it
would be a to borrow from discrete math a combinatorial explosion to connect every single pixel
value in an image to every single pixel value in the next layer of features right it would be
just a huge amount so what we do instead is we take a part of that image and we iteratively slide
over it okay so at a high level you understand the sliding part right think of it as a flashlight
okay think of it think of the uh the filter at each layer that shines over the receptive field
that box as a flashlight and you're shining over the image and you're and you're applying dot products
to all of these numbers okay just like that okay i'm going to keep going into this that was just
the highest level you're not supposed to understand it all yet okay that was that was very high level
we're still going deeper we're going deep we're going deep okay so check out this beautiful image
right here isn't it beautiful it's very beautiful also you're beautiful for watching this so thank
you for watching this okay so i love my fans so much seriously you guys are amazing seriously
you guys are the reason i do this every week okay so i by the way i want to say one more thing
to go on a tangent the people who subscribe to my channel no one thought they existed we are
programmers who are smart and we are also cool no one thought these people existed but we exist
okay we are smart and we are cool so you are amazing okay anyway back to this what this is
is another way of looking at the network right we're just looking at different ways we're looking
at different ways so we can build a spatially invariant image in our head of what a convolutional
network is like right no matter what that image is we're going to learn to recognize a convolutional
network when we see one i'm just trying to you know meta applying this logic to what we're learning
so what happens is that each layer we are applying a series of dot products between the
weight matrices and the input matrix okay and so what happens is let's look at a third image okay
so this is a third image what happens is we perform a series of operations okay at each layer
and so we could think of of different we could think of splitting up a convolutional network
into two separate categories the first category is feature learning and that's what's happening at the
at the at the head of the the head to the middle to almost the tail end of the network and at the
very tail end is classification so there's two parts there's the feature learning part and then
there's the classification part and so for the feature learning part what happens are three
operations over and over and over again and we can call them convolutional blocks let's just call
them convolutional blocks i'm coining the term so what happens is we first apply convolution
then we apply relu or any kind of activation and then we apply pooling and we repeat that that's
that's a single block three operations in a single convolutional block okay so convolution relu pooling
repeat convolution relu pooling repeat convolution relu pooling okay and usually you know you have
three blocks at least unless you're building inception by google then you have 15 15 of these
but you you know you have these convolutional blocks and at the very end then you flatten
that output into a smaller dimensional vector and then you apply a fully connected layer to it so
that means that you then connect all the neurons in one layer to the next one just because we want to
then harness all of the learnings that we've learned so far that's why we fully connect at the end
and then we take those learnings and we squash it into a set of probability values with our last
softmax function and then we take the max value of those probabilities and each of these probabilities
is a probability for a for specific class that it could be and we take the max value let's say 72
percent as and we'll say okay well 72 percent for banana and now we know it's a banana okay so
hopefully you get some of it but it's very confusing still i know we're about to go even
deeper okay so get ready for this i haven't even started yet so i haven't even started yet okay so
anyway step one so for step one we are preparing a data set of images right so when you think of an
image you think of a matrix hopefully a matrix of pixel values if you don't think of it that way
think of it think of it that way now you're thinking of an image as a matrix of pixel values
rowed by columns and each of these um each of these uh
points in the matrix represent a pixel right between 0 and 255 but it's actually better
in terms of convolutional networks to think of an an image as a three-dimensional matrix
and you're like what no what it's no so it's three dimensions so the first dimension is the length
of the image the second dimension is the width and the third dimension is the depth so wait what
is the depth because the depth represents the channels and there are three channels for images
red green and blue unless you're talking about gray scale then there's black then there's you
know black and white but we're talking about color images okay so there are three channels and you
have these dimensions for each of the channels so these values in each of these um in each of these
2d matrices for and there are three of them represent the the amount of redness or the amount of
greenness or the amount of blueness between 0 and 255 so in terms of convolutional nets we think of
images as three-dimensional pixels okay so i wanted to say that part okay so that's that's
that's what we think of our image as our input image and it has an associated label right we're
talking about supervised learning learning the mapping between the input data and the output
label dog image dog label learn the mapping given a new dog image what is a label well you just
learned it right so and we learn it through back propagation back propagate to update
weights remember the rhyme you know what it is hey i haven't wrapped yet in the series but i will
don't worry it's coming anyway so every image is a matrix of pixel values we know this we know this
between 0 and 255 and we can use several training data sets there are two really popular ones there's
seafar and there's cocoa and there's a bunch of other ones as well but basically these are
huge data sets and you can find smaller versions of them and each of these images they're dogs
they're cars they're airplanes they're people whatever they all have labels for them handmade
labels by humans which is great for us okay so that's that's it that's step one step one is to
get your training data which is your images which are your images step two is to perform convolution
now you might be asking what is convolution well i'm here to tell you that convolution is an
operation that is dope as f here's why it's dope because it's not just used in computer science
and machine learning it's used in almost every field of engineering think of convolution as two
paint buckets you have one paint bucket which is red another one which is blue and what you do
is just smear it all over yourself no you don't do that what you do is you take these two paint
buckets and you combine them into one paint bucket and that new paint bucket is going to be a new
color whatever that combination of colors is that's convolution convolution is taking two separate
types of data or two matrices and then apply and then it's an operation that combines them so you
could think of convolution as synonymous to combination okay and why do we apply why do we
say that for convolutional networks because what we're doing is we are combining the values for
each of these layers with the input matrix so think of the input as that matrix right and so
well it's a three-dimensional it's a it's a it's a it's a 3d tensor right but we're applying it to
each of these dimensions right so three of them so just think of it as a matrix for right now
and so what we do is we take this so at each layer at each layer there is a weight so by the way
okay so there's a lot of interchangeable terms in machine learning and it's easy to get confused
here but i want to set the record straight for a second weight is the same as feature matrix is
the same as feature map is the same as a filter in this case in for convolutional networks so you
see these or even kernel kernel is a different one there's actually five interchangeable terms so i
can see how it can be confusing but if you get the basic idea of you have an input matrix which is
your image and then you have a set of matrices which are your features that are learned you know
edges shapes more abstract shapes that's it that's that's all it is matrix dot product matrices that
are being multiplied by matrices all the way through that's that's all it is matrices that are
being multiplied by matrices all the way through just a chain of them okay so what happens for
convolution is we take a matrix and we multiply it by all the values in this matrix at a certain
region right and so this is what i was talking about when i was saying we have a receptive field
because we don't just multiply it all at once we multiply by a little part of it okay the receptive
field and we slide it and we can define what that interval is that sliding window i know i'm talking
a lot without coding the coding is coming believe me the coding is coming but just check this out
for a second we got to learn this uh conceptually first so we are multiplying the the feature matrix
by that input image just for every row and every column we're just multiplying multiply
multiply and what happens is we have this new matrix that results the output and that output
is considered the convolved feature okay and so what we do is we use that output as the input
for the to the next layer and we repeat the process over and over and over again obviously
there's two more parts here there's the activation the relu and then there's the pooling which i'll
talk about as well but that's the basic idea between convolution and that's why we call it
convolution because we are combining or convolving the weight matrix or filter or kernel whatever
you want to call it feature map by that input we're combining it using the out and using that
output as the input for the next layer after activating it and and pooling it okay so that's
convolution and also um right so we apply it to all of those dimensions for that for that input
matrix okay and that gives us our activation map or feature map or filter right so many different
interchangeable terms here so anyway so it's computed using the dot product so you might be
thinking well okay i see how there is a dot product i see how there's matrix multiplication
but how does that really tell us what features there are i still you're still not making the
connection probably why understandably why this these series of matrix operations help us detect
features well here's what happens what happens is this and here's the great thing about matrices
and having several of them when we learn a filter or a weight whatever you want to call it well this
you know what moving forward let's just call it filter okay i'm just saying let's just call it
filter moving forward for the rest of this video when we learn a filter over time by
training it on mouse mouth pictures for example a filter is going to look like this at let's say
at the first layer we we learn a filter for detecting a curve that looks like this right
this curve right here and so what's what this filter is going to look like for detecting
the specific type of curve is it's going to be a very sparse filter that means there's a lot of
zeros except so there's all these zeros except for right here you see this 30 30 30 30 and notice
that these values represent the shape they go in this direction of a shape and so what happens is
when we take this filter and perform the dot product you know we convolve it with whatever part
of the mouse if it's over a part of the mouse that matches that feature exactly then we when we
multiply all of those uh when we when we perform the dot product between all those values and sum
them up that's the convolution operation right there okay just it's going to be a big number
okay and so then we know that we've detected a feature because we've we've multiplied it sum it
up and there's a large number and if there's not if we multiply if let's let's say we have that
receptive field over a different part of the mouse and that that curve doesn't exist then it's going
to be zero right because if you look between these 30 30 30 values and that the equivalent
locations on this pixel representation of the mouse image these are zeros and so what happens
when you multiply zero by 30 you get zero right so that's why it's important to make the rest of the
so the data that's irrelevant we want it to be zero right in the in the feature maps or in the
filters that we learn in the filters that we learn we want the irrelevant parts to be zero
and in the images okay and and in the input images so I so I could actually go even more into
convolution but it's not really necessary but it's it is super dope it is super dope though
this is a great blog post by the way I definitely encourage you to read this blog post it's linked
in the notebook but this dude Tim Tim he goes into these this idea of convolution and he talks about
how it's applied to all these different engineering fields and he goes into the formula the formula
for the convolutional theorem is what he called is what it's called okay and I'm just going to go
over this at a high level but the convolution theorem is this general theorem for discrete well
there's a discrete version and a continuous version right discrete is if there's you know one or zero
black or white you know definite classes that something could be whereas continuous is if it
could be an infinite amount of values between zero and one point five point two five you know
point seven infinity in that direction but here's the here's the formula for it and so
let me make it bigger just really quickly and then we'll get back to it because it's
it's really cool but the convolution theorem states that we and so in it's a general theorem
that can be applied to any any any set of problems but in terms of what's relevant to us is is the
convolutional theorem applied to matrix operations so what we can do is we can say what it what it
says is it's the input times the kernel and it's the dot product it's a dot product between
two different matrices and we perform that for every value in all of those matrices and we do that
for all of the values that we have and we sum them up together and that's what the sigma term
represents and we and we actually express that right here right this operation right here this
multiplication and summation it's the same thing but it's a more complex way of looking at it or
more mathematically accurate way and also the fast Fourier transform is is brought up by this and
the fast Fourier transform takes some spatial data and it converts it into Fourier space which is
like a waveform and you see this a lot in your day-to-day life whenever you're looking at some
sound you know you're listening to some sound and you look at your mp3 player and you see the waves
that's a that's a Fourier transform happening but i won't go into that that's that's for sound and
audio but anyway it's a really cool blog post definitely check it out okay so back to this
so we talked about convolution now we're going to talk about pooling right so what is pooling so
whenever we apply convolution to some image what's going to happen at every layer
is we're going to get a series of feature of so each of the weights are going to consist of
multiple images and each of these images are going to be at every layer there's going to be more
and smaller images so the first few layers are going to be these huge images right and then at the
next few layers are going to be more of those but they're going to be smaller and it's just going to
get just like that okay and at the end we squash it with some fully connected layer so we get some
probability values with a softmax but anyway what pooling does is it is it dense is it makes
the matrix the matrices that we learn more dense here's what i mean so if you if you perform convolution
between an input and a feature matrix or a weight matrix or filter it's going to result in a matrix
right but this matrix is going to be pretty big it's going to be a pretty big matrix what we can do
is we can take the most important parts of that matrix and pass that on and what that's going to
do is it's going to reduce the computational complexity of our model okay so that's what pooling
is all about it's a pooling set so there's different types of pooling max pooling is the most used
type of pooling by the way so basically multiply so what happens is we we strive we have some we
define some window size and then some stride size so how what are the intervals that we look at
and we say okay so for each of these windows let's take the max value so for so for uh this one right
here four six zero eight the max value would be eight and so for one three twelve nine it'd be
twelve right so we just take the biggest number it's really simple actually we just take the biggest
number and we just do that for all of them and so that that's what pooling is all about and so
it's going to just give us that the most relevant parts of the image and if you if you think of these
these very these values in in the in the matrix as pixel intensities by taking the maximum intense
the the pixel with the most intensity or the the highest intensity we're getting that feature that
is the most relevant if you see what I'm saying it's a least opaque feature to use a term from
image um math anyway so we so we talked about pooling and we talked about uh we talked about
activation and so now
no we talked about convolution and we talked about pooling and so now the third part
is normalization or activation so remember how I said how it would be it's so important that we
have these values that are not related to our image be zero we want it to be zero so the result
is zero if the if the feature is not detected well the way we do that is using relu and so relu
stands for rectified linear unit it's an activation function it's an activation function okay we use
activation functions throughout neural networks and we use them because it is you can also call
them non-linearities because they they make our model able to learn non-linear functions not just
linear functions but non-linear functions so any kind of function right the universal function
approximation theorem we talked about that activation functions help make this happen and
so relu is a is a special kind of activation function that turns all negative numbers into
zero so that's why it's going to make the math easier it won't make the math break
for our convolutional network so we'll apply a relu so basically what we do is for every single pixel
value in the in the input to this relu activation function we turn it if it's a negative we just
say make it zero it's super simple it'll be one line of code you'll see exactly what i'm talking about
okay so that's that's those are our blocks so that's how our convolutional blocks work
however there is another step that I didn't talk about that is a nice to have and state of the
our convolutional networks always use it and that's called dropout so Jeffrey Hinton the guy who invented
neural networks invented a feature invented a technique called dropout and what dropout is
is a good analogy is old people or not old people but people who are stuck in their ways let me let
me okay so what dropout does is it turns neurons on and off randomly what do I mean by that that I
mean the the matrices for each weight value is converted to zero randomly at some layer of the
network and so what happens is by doing this our network is forced to learn new representations
for the data new pathways that that data has to flow through it can't always flow through this neuron
and the reason we use it is to prevent overfitting right we want to prevent overfitting we want to
prevent being too fit to the data think of it as you know the older you get the more set in your
ways of thinking your you are right and so it's harder to think of new ways of of of thinking
right because you're so set in some ways so a way to prevent that is to have a novel crazy
experience whether it's skydiving or ticking psychedelics or whatever it is and what that
does is it creates new pathways so you're not so you're kind of forced your brain is forced to make
new pathways and this increases your generalization ability and you're not so overfit that's a very
rough abstract analogy but basically dropout is not as complex as that sounds dropout can be
done in three lines of code so definitely check out this blog post as well that I've linked
but what it does is it just randomly picks some neurons in a layer to set to zero right so it's
just it's just three lines okay and you can look at it in this notebook right so that's and then our
last step is probability conversion so we've got this huge set of values right all these little
small images that are represented by this huge output matrix and we want to take this huge set
of values and make some sense out of it we want to make probabilities out of it and the way we do
that is using a soft max at the end a soft max is a type of function and it looks like this this
this is a soft max function right here but what we do is we plug these values into the soft max
function and it's going to output a set of probability values discrete probability values
for each of the classes that we're trying to predict okay and then what we'll do is given
all those probability values will pick the biggest one using arg max the arg max function in numpy
and that's going to give us the most likely class okay those are the seven steps of a
full forward pass through a convolutional network looks like that and so now you might be wondering
well okay so how do we train this thing well using gradient descent right and when applied to neural
networks gradient gradient descent is called back propagation exactly i hope you got that right
anyway okay so how do we learn these magic numbers right how do we learn what these weight values
should be what the feature should be back propagation is how we do it right and so we've talked quite a
bit about back propagation and gradient descent but i'll do a little i'll go over it again um
but the idea is that we have some error that we're computing right this is super this is
supervised learning we have a we have a human label right for some data so we put in a dog image
or a bicycle image to look at the summit to to relate to this image here we put in a bicycle
image and the bike label we pass it through the each layer dot product dot product dot you know
dot product activation function pool dot product repeat repeat soft max or squash into probability
values pick the biggest one and we have some prediction value and what we do is we compare
the prediction value to the out the actual value and we get an error and we take our error
and we compute the partial derivative of the error with respect to each weight value
going backwards in the network okay like this okay and so for regression we use the mean squared
error if we're using linear regression regression and for classification we use the softmax function
so remember how in the first neural network we built and in their linear regression example
we used a uh we use mean squared error to compute the error and now we're using the softmax
so we'll take the so we'll take the partial derivative of the error with respect to our
weights and then that's going to give us the gradient value that we then update each of those
weight values recursively going backward in the network and that's how it learns what this features
what the ideal feature the weight matrix value should be but what about the other
what about the other magic numbers what about the number of neurons and the number of features
and the size of those features and the pooling window size and the window stride well those that
is an active area of research there are best practices for values that you should use for those
for those hyper parameters right the tuning knobs of our network and andrew karpathy has some great
material on this and he's probably the leading source for convolutional networks right now in
terms of um written contents and uh yeah i mean this is an active area of research finding out
what the ideal hyper parameters for our neural network should be and we're still learning what
it should be what what what what how we can get them rather than just guessing and checking which
is what we do right now which is kind of like you know not it's not as optimal right so anyway
last two things and then we're gonna get started with the code when is a good time to use this
well we know to classify images we've talked about that but you can also use them to generate
images and that's for later on that's a little more advanced but to give you a little spoiler
a little teaser in fact this is in my intro to deep learning playlist you take a convolutional
network you flip it and then you call it a deconvolutional network and then you can take
some text and create an image out of text how crazy is that okay there's also generative models
where you have two networks fighting each other and you can generate new images a whole bunch
of really cool crazy stuff you can do but anyway when should you use a convolutional network
anytime you have spatial 2d or 3d data what do i mean well obviously images are spatial the word
spatial implies that the space the positioning of the data matters so sound you can apply to sound
images or text where the the the position of the text matters right because we have a flashlight
our filter and we're convolving over an image right but if you have some data like say customer
data where if you were to just flip the rows and columns it doesn't matter what order they're in
they're still you know they're still features so a good rule of thumb is if you swap out the rows
and columns of your data set and it's just as useful like the space doesn't matter then you
don't want to use a cnn else you do okay and a great and last thing the great example of using
cnn's are for robot learning you can use a cnn for object detection and you can use a cnn for
grasp learning and combine the two and then you can get a robot that cooks which is really cool
i've got a great tensorflow example and a great adversarial network example okay let's go into
the code now and so what i'm going to do is i'm going to look at the class for the convolutional
network in numpy as well as the prediction class there's two classes here okay so these are our
three inputs pickle is for saving and loading our serialized model what do i mean pickle is
python's way of having a platform or language agnostic way of saving data so you can load it
up later tensorflow uses it a bunch of other libraries use it as well numpy is for matrix math
and we've got our own little custom class for pre-processing the data because we don't care
about that part we care about the machine learning part okay so let's talk about our light ocr or
object optical character recognition class in our initialized function we're going to load the
weights from the pickle file and then store and then store all the labels that we've loaded
we'll define how many rows and columns in an image load up our convolutional network using the light
cnn function with our saved weights so assuming we've already trained our network we load it with
the saved weights from the pickle file and then we define the number of pooling layers okay so once
we have that then we can use this predict function so given some new image we'll reshape the image so
it's in the correct size to perform the dot product between that image and the first layer of our
convolutional network and we'll we'll we'll put it we'll feed it into our network and it's going to
output a prediction probability for a class and we'll return it okay super high level we haven't
even coded our cnn that's that's our first class that's our prediction class now now we're going
to look at the convolutional network class and what i'm going to do is i'm going to i'm going to
go over the code and i'm going to code some parts of it so now we'll look at our convolutional
network class okay so in our initialized function we'll initialize two lists one to store the layers
that we've learned the the weights of each layer and then the size of the pooling area for max pooling
okay we'll load up our weights from our pickle file just like this and then we have our predict
function now in our predict function that's where the real magic is happening right let's
code what this looks like so given some input x we're going to feed it through all of these
layers right so what happens is we will say okay so the first layer is going to be a convolutional
layer okay and we're going to define what all of these functions look like look like but the first
layer is going to be that convolutional layer we'll feed in that first image and we'll say okay
well this is the first layer so it's a zeroth layer we'll say border mode equals full and i'll
talk about that part later on but that's it for that and so what happens is x equals this layer
okay so that's our first layer and then our next layer is going to be relu so we'll say okay now
let's apply an activation to the output of the previous layer okay and then we'll set it equal
to that okay so we'll set the output from the previous layer equal to the input of this layer
and then we keep going we say okay so we've got another uh cnn we have another convolutional layer
and we do the same thing here we say okay take the in output from the previous layer we'll define
what the uh name of this layer is as well as the border mode which i'll talk about the very end of
this we have a border mode which is valid and then we say okay well we'll set the output of that
equal to the input of this and just keep repeating now it's time for us to apply a
another non-linearity so we'll just go ahead and apply our non-linearity again remember these are
convolutional blocks oh and we also want to pool so also the the order with which you can do this
varies right you can do this in different ways and yeah so i'm doing it a certain way right now
you know we could change it around it would change our result but the order map the ordering within
the block can be can be different okay so right so we're going to pool it we're going to pick the
the most relevant features from from that uh from that output and then we're going to perform drop
out to prevent overfitting and we're going to say there's going to be a 0.25 chance that a neuron
is going to be deactivated that will turn it off set it to zero and that's our dropout probability
value and then now we're getting into our our the second category of our network not the feature
learning part but the classification part and we'll say okay so let's flatten this layer let's
reduce the dimensionality of all of that that data so it's something that we can then learn from
and we'll say well let's let's set it equal to seven and then we'll say once again turn that output
into our uh inputs here okay and so then we have another dense layer we just we just keep going
with or our first dense layer and that means we are going to it's a fully connected layer so we're
combining everything that we've learned because we're getting really close to squashing these values
into a set of probability values so we want to take all of our learnings and combine them
with a fully connected layer and so we'll combine them with a fully connected layer
and then uh we'll squash it now with our sigmoid or no not our sigmoid our softmax function okay
and then that's going to give us our output probability and then we're going to say well
which of the probabilities do we want we want the max one right we want the max probability
and we'll classify it just like that and return that value okay that's the highest level and so if
you were using keras or one of these high level libraries this is all your code would look like
but what we're going to do is we're going to look at these functions as well okay so let's look at
these functions so we'll start off with the convolutional layer function and have your
notebook open with me as well so you could go over this the the link is in the description if you
don't know now you know if you don't know now you know so for our convolutional layer given some
input image we're going to say well we'll store our feature maps and the bias value in these two
variables features and bias will define how big our filter or patch is going to be how many features
do we want how big is our image how many channels rgb so three and then how many images do we have
so given those values we'll define a border mode so a border mode so is so when you apply
fold to border mode in this case it means that the filter has to go outside the bounds of the input
by filter size divided by two the area outside of the input is normally padded with zeros and
the border mode valid is when you get an output that is smaller than the input because the convolution
is only computed where the input and the filter fully overlap okay and they'll give us different
they'll give us different classification results accuracy results and it's good to test both
options so what we'll do is we'll initialize our feature matrix for this layer as conv as convolve
zeros it's going to be a bunch of zeros and then we'll say okay so for every image that we have
for every feature in that image let's initialize a convolved image as empty and then for each
channel so we're doing this for each of the three channels let's extract a feature from our feature
map define a channel specific part of our image and then perform convolution on our image using
that given feature filter so notice this convolved 2d function it's where the actual convolution
operation is happening this is more of a wrapper for that actual mathematical operation so once
we have that we'll add a bias and a bias acts as our anchor for our network it's kind of like the
y intercept it's kind of like a starting point for our model to exist and then we'll add it to our
list of convolved features for this for this layer okay and we'll return that as the as our feature
map our set of filter values our weight matrices and so let's look at this convolved 2d function so
in our convolved 2d function we'll define the tensor dimension of the image and the feature
we'll get a target dimension and then these two lines perform this this operation this convolutional
theorem that we defined right here we're performing the dot product between the input
and the kernel or feature for for all of those weight values and then we're summing them all up
and that's going to be our output and so the fast Fourier function in numpy does this very well
and so we can just use that as fft2 but that's it's a multiplication and a summation operation
okay and so then we have our target value and then once we have our target value we could say
okay let's have a starting point and an ending point and our target value is going to be within
that range of what we want to return as the convolved feature right so we have some bounding
box that we want to apply this to okay so then so we have that so what else do we have so we start
off with our convolutional layer and then we had our relu so what is relu relu super simple relu
relu is just forgive so for for some matrix of zeros it will go through every single pixel value
in the input matrix and if it's a negative number we just turn it into zero that's it that's relu okay
and then so we have we have talked about relu we've talked about convolution we have to talk
about pooling so what does max pooling look like so given our learned features and our images
let's initialize our more dense feature list as empty and so here's what we do we're going to
we're going to take the max values of all of those parts of the input image right so we're
going to say we're going to say for each image and for each feature map begin by the row define a
starting and ending point okay which we define with our pool size hyper parameter and so for each
column so we've got a set of rows and columns for each image there's a notice a lot of nesting
happening here we're going to define starting end points for the columns as well and then we're
going to say define a patch given our defined starting and ending point so some some bounding box
and then take the max value from that patch using nmp.max and that patch is what moves around right
for all parts of that image and then we return that and we're going to store all of that in our
pooled features matrix right here and we return that as the output and that's what we pass on in
the convolutional network okay so that's what max pooling is okay so we've talked about convolution
relu max pooling and then dropout so for dropout right we have our probability value that we define
as 0.25 and we just multiply it by the input okay and that what that's going to do is it's going to
turn on or off some part of the matrix into so by on and off I mean zero it'll make it either
zero or not zero so it'll so then our data will have to learn to either be multiplied by it or
find a different pathway and that's for dropout and then we talked about dropout and convolution
flattening dense and softmax so for flattening it's just a it's a tensor transformation we just
reduce the dimensionality of the input okay and then for our
dense layer our denses are fully connected layer now this is the generic layer that you would see
in a feedforward network input times weight uh and then you add a bias right which is the dot
product right here this is this is a dense layer we just take our input times our weight at a bias
so that means we we just perform the dot product between the full weight matrix and the full weight
matrix instead of doing it at all the layers because that would be way too computationally
expensive for image data we perform it at one fully one fully connected or dense layer at the end
and that's a way for us to combine all of our learnings together so we can then
promptly squash it with a softmax function okay so then for our softmax layer and then we have
classify so for our softmax layer we will uh so this is the this is the formula for softmax
programmatically speaking uh but what it does is going to output a set of probability values
and then we'll classify those values by taking the arg max the largest probability
and that is our output okay so that is our forward pass through the network okay and so
yes that is our forward pass through the network
so back so back propagation works pretty much the same way as i've talked about before several
times gradient descent back propagation works the same way we take the partial derivative of our
error with respect to our weights and then recursively update our weights using that gradient
value that we gradient equals partial derivative equals delta interchangeable words but here's
a great simple example right here where we after the forward pass we do the same thing in reverse
order so we calculate the gradient of those weights and then back and then multiply them by
the previous layer and then for our javascript portion we are taking the drawing from the user
here's the main code for that paint window in a canvas and we are going to say capture the
mouse's positions capture all those points in that image with an event listener and then we're
going to say on paint so whenever the user actually starts moving that painting whenever that mouse
stops clicking and then the user hits the submit button we'll save that snapshot of that image and
then feed that into the network and that's our flask app we'll define two routes one for our home
and then one for that image for the network we can deploy to the web there's a heroku app you
could definitely check out the link link is in the description as well check out the notebook
and yeah that's it please subscribe for more programming videos and for now
i've got to do a 4a transform so thanks for watching
