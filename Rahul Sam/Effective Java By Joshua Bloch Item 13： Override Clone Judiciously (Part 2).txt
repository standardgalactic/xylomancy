Hey everyone, welcome to part two of item 13 in Joshua Blocks Effective Java, which states
override clone judiciously. And if it's not obvious already, since item 13 is a pretty
big item, I've broken it down into two parts. And if you've missed part one, I'll leave a
link down below in the description for you to go check it out. Saying all that, let's get started
without further ado. So as we continue on from part one, item 13, when it comes to cloning,
we have to keep in mind that recursively calling the clone method may not be sufficient at all
times. So in part one, we kind of calculate how when the clone takes place between a class and we
create a new object or a clone of that class, we should recursively copy all the fields to
properly clone the class when using a cloneable, although that might not always suffice. So
firstly, let's take a look at a demo using a hash table and indeed show a broken clone,
which will give us a shared medieval state, especially a hash table is a good example,
because at least the hash table we're going to use uses an array and an array that can happen
quite often. So let's take a look at this class. Obviously, let me zoom in a bit.
Hash table implements cloneable. This is a hash table we are designing. I'm not saying this is how
a good hash table to such should look like. It's just a rough design we have just for
the purpose of the demo. And this is where the carpet is. I wouldn't call it the carpet,
but here's where the problem lies. It's this array, the buckets array that creates a shared
a medieval state. Someone is skip over all the other implementations of a hash table,
things like the constructor or well, actually, I should probably mention this, there is a
inner class called entry. The buckets array is of type entry. That's kind of important for the
purpose of the hash table. But still it's kind of out of scope to one for our demo here. But as I said,
I'm going to skip over the puts, the gets, all of that. That's a part of the hash table mechanism.
Although if you look at the clone method, now this is a broken clone method because it results
in a shared medieval state. And here's where the issue lies. When we do the clone, and we simply
clone the buck across. So the buckets array, the elements in the buckets array are not copied,
rather they're shared between two hash table objects. And that can obviously create corrupt
state or go this clone method being broken. As Joshua Block states, though the clone has its
own bucket array, this array references the same length lists as the original, which can easily
cause non-deterministic behavior in both the clone and the original. Now this issue can be resolved
using the concept of a deep copy, which we've covered in previous items. But essentially what a
deep copy does is, well, as the name suggests, recursively goes through the array and copies
each element into the new object. It does a deep copy. So I didn't mention before, when I was showing
the broken clone method that we have this inner class called entry. So in this inner class,
we've defined a new method called a deep copy to this deep copy, which, as I said,
does the recursive copying. And then what can be done is when the recursive copying is done
using the deep copy method, the client or other client, the outer class can use this
deep copy method in its clone method. So if you can see here, it does the cloning and then in line
number 90, it's doing a deep copy of the bucket's array. This ensures that all the elements are copied
too. Ergo not not just resulting in, I keep saying Ergo because I've been reading a lot of philosophy.
Ergo is a Latin term, I should probably say therefore, therefore not resulting in
a non deterministic state or a shared mutable state. A deep copy will solve that problem. Although,
although we've got a small issue here, you can probably see we're doing a recursive copy here.
And I'm going to admit, I find it a bit hard to get this concept that Joshua Bloch has
outlined in the book. But he states, when it comes to recursive copying,
while this technique is cute and works fine, if the buckets aren't too long, so he's referring to
the buckets array, it is not a good way to clone a linkless because it consumes one stack frame for
each element in the list. If the list is long, this could easily cause a stack overflow error. So
the problem is that every time the deep copy takes place, per element, it creates a new stack
frame. And that can obviously not a memory leak, but it can cause a stack overflow error
because this happens runtime. Now, I found this good article on a digital ocean, which kind of
explains the difference between the heap and the stack. There's one item, I forget which one,
where we covered quite deeply Java, memory management, garage collection, allocation,
all of that. But I had to put this in Chargipiti to get a bit more, let's say, elaborated definition.
And here's what Chargipiti states, pertaining to this point that Joshua Bloch makes to choose.
Oh, I didn't mention that. He says, because recursion can cause this stack overflow error,
it's better choosing iteration over recursion. And here's why. And I'm quoting Chargipiti,
verbatim here. Using iteration instead of recursion helps prevent a stack overflow error by avoiding
excessive stack frame allocation. When a method is invoked recursively, each recursive call creates
a new stack frame, as he stated, which consumes additional memory on the call stack. If the
recursion goes too deep, or if the data structure being processed is large, it can result in the
stack running out of memory, causing a stack overflow error. So we need a mechanism or an
algorithm that doesn't create a new stack frame every time an element is created in the data
structure. And that's where iteration can be much more handy. So let's take a look at how
the iteration method works. Let's comment out the deep copy and take a look at the
deep copy that uses the iteration. So in iteration, because we're not calling the deep copy method
within the function, it's not happening recursively, it doesn't require a new frame on the call stack
every single time the loop runs. And therefore, for larger data structures or larger array,
using iteration probably is a bad idea over using recursion. Even though, obviously, as you can see
here, the recursive method is much simpler. And it kind of makes a lot more sense compared to this,
where you got p.next and your parsing generics and whatnot can be a bit more complicated. So
depending on the use case, you can use whatever method or we can implement the method however
may you think it'll suffice or it'll be apt. Okay, saying all that, let's move to the wrong side.
Saying all that, let's move to the next point, which is how in cloning, how we can utilize the
super dot clone method in your class. So you can use the clone method in your super class.
Firstly, here's what Joshua book states, a final approach to cloning complex mutable objects is to
call super dot clone, set all the fields in the resulting object to their initial state,
and then call high level methods to regenerate the state of the original object. So at first
glance, this looks quite straightforward, because all we're doing here is by creating a new instance
of hash table clone table object, and we're setting it to its special book states initial
state, and then simply invoking the clone method of the superclass, which in this case would be
the object class, and repopulating this new object with with whatever the super dot clone method
or superclass superclasses clone method returns. But but here we have an issue. And the issue is that
this type of cloning, because we're doing a deep copy, especially with the buckets array,
it doesn't abide by the the clonable architecture contract, because we're implementing
the clonable interface here, which is a contract that the class is supposed to follow. But by
doing it this way, by doing the deep copy, it is taking place without a field by field copy of
the object. And that is anatomical to the clonable architecture. I just realized as I was rereading
this, sorry, I wrote this script for this a while back, that I made a mistake here. In fact, this
is correct. The problem would have been if we did a shallow copy, similar to what I've
coded here, without doing a deep copy, a few which which is a part of the field by field
copy, that's a part of the architecture. I mean, this is correct, because even though we're
invoking super dot clone, and copying the state into the new object, and then creating the buckets
array, we're still doing a field by field copy. So I should probably really rewrite this into
saying deep copy taking place with a field by field copy of the object. Now this is correct,
as it should be, because because a clone method should act very much like a constructor in a class,
and that's the point Joshua book makes the I'm so sorry for the misunderstanding that even I
got confused, but I realized I was written that in the wrong way. And this is correct, we need
a deep copy to take place in the clone method. And it can happen, even when invoking the super
dot clone method just to clarify. It's a bad mistake. Okay, so here's what Joshua book states,
pertaining to the clone method and how it should behave. Like a constructor, a clone method must
never invoke an overriding method on the clone under construction. If okay, so that is this can
be a problem because of that. Because in the clone method, we're invoking another overriding
method. Now this can be an issue. So the issue isn't with the deep copy, the issue really is
with line number 65. Just to clarify. If clone invokes a method that is overridden in a subclass,
this method will execute before the subclass has had a chance to fix its state in the clone,
quite possibly leading to corruption in the clone and the original. So what does that mean if clone
invokes a method that is overridden in a subclass, this method will execute before the subclass has
had a chance to fix its state in the clone. An example of that could potentially be this. We
have this put method, which is extended from hash table. But because it's public, it can be overridden.
Now let's say in the subclass and extended hash table, we define another clone method, which
should be allowed to be overridden. But we've overridden the put method too. And what that will
do is it'll increase the size by an additional one. For instance, let's say we're in the superdark
put, we're doing the key and value. And then in the array, we're changing it. I haven't implemented
that bit. But let's say the put changes it where the array will also increase the size. This put
will also increase the size by one. And then what will happen is in the clone method,
it'll create an inconsistent state because this put, which shouldn't be the private or final,
is being invoked again in the subclass's clone method, which you will see here in line number 22.
So roughly this is what the block means. Obviously I haven't implemented the whole code,
but the idea being in the clone method, we shouldn't be invoking methods of the superclass
that can create a corrupt state or non-deterministic behavior between objects.
Okay, now let's discuss the objects clone method. And sorry about the background noise,
it just started raining. When it comes to the objects clone method, so when I mean object,
I mean the superclass and Java of all other classes, the Java object class,
Joshua Block states this, objects clone method is declared to throw clone not support exception,
but overriding methods need not. Public clone methods should emit the throws close as methods
that don't throw check exceptions are easy to use. So here's how the objects clone method is defined,
which throws a clone or support exception. And then if you have this class here,
which overrides this clone method from the object class,
as per the contract of the colonial architecture, it's a contract that the JVM makes or it's
a contract with the JVM that the clone will take place properly. Therefore, this bit isn't
required. So we can get rid of it really. But, but it's not that simple. Joshua Block states
that there are two ways to do this when designing a class of inheritance. Firstly, on what you
should not do. If you have a superclass that is designed for being inherited, this shouldn't
happen. We shouldn't implement cloneable, because then it'll create corrupt state. As you can see,
this resource array here would be shared between these two objects creating a medieval, not
available state, sorry, corrupt state. But given that though, we can still have a clone method
in a class designed for inheritance without implementing cloneable. There are two choices
that Joshua Block gives us. The first one is implement a properly functioning clone method
mimicking that in the object class. So not a clone method like this. This is wrong.
We should mimic what's being done in the object class, despite not implementing the cloneable
architecture, or prevent the subclasses from implementing a clone method completely by making
the clone method protected final. And then there can't be any overriding taking place.
Okay, a small caveat. The caveat is what to do when writing, not a caveat really, but more of an
axillary point, what to do when writing a class for threat safety, for an object to work with
multiple threads. So firstly, the objects clone method is not synchronized. Therefore, it is
not thread safe. So we have to keep that in mind when writing a class. And let's take a look at a
demo as to how we can potentially write a thread safe class. And again, this code isn't complete,
they can certainly improve it's simply a blueprint on writing a thread safe class.
Really like, that was a mistake, like writing other threats threats, a threat safe classes,
what we can do is define the fields as being synchronized. So now it's atomic. And then
in that class, so I have a class called safe kind of which implements cloneable.
This class here is not thread safe. And we can make it threat safe by giving it the
synchronized keyword, which will make this clone is synchronized. And in that in that way,
two objects will be able to invoke this method at the same time. Sorry, not two objects,
two threads will not be able to invoke this method at the same time. So to recap what we've
discussed in both part one and part two of item 13. Joshua block states to recap, as I said,
all classes that implement cloneable should override clone with a public method whose return
type is the class itself. This method should first call super dark clone, as we went through a bit
before, then fix any fields that need fixing. Typically, this means copying any mutable objects
that compromise internal deep structure of the object and replacing the clone's references
to these objects with references to their copies. So that's kind of what we discussed before in
using either recursion or iteration by doing a deep copy. And then just another point he makes,
if the class contains only primitive fields or references to mutable objects,
then it is likely the case that no fields need to be fixed. So then he asks, is all this complexity
really necessary when designing a clone method or when overriding the clone method of the object
class? When he means all this complexities, we're talking about what we discussed in part one and
now in part two. So a better approach is using a technique called a copy constructor or a copy
factory method. But before we get to that, before we look at the demos, I'll read out what he said.
In regards to the complexity, he said, really, it's not needed. If you extend a class that already
implements cloneable, you have a little choice but to implement a well behaved clone method.
That's the advantage of using an interface like cloneable, which kind of forces us to
abide by the contract. Otherwise, if we don't use cloneable, you're usually better off providing
an alternative means of object copying. Here's where we get to what I said before. A better
approach to object copying is to provide a copy constructor or copy factory. A copy constructor
is simply a constructor that takes a single argument whose type is the class containing
the constructor, for example. Now, this was really interesting. I don't think I've actually worked
with a copy constructor before. So I found this part quite interesting, despite it coming towards the
end of the item to kind of finalize and conclude on what he was trying to outline in this item.
So firstly, again, this is what the implementation or the signature of a copy constructor would look
like and then the copy factory. Similar kind of signature, but obviously the way it's implemented
is different. So the right, in fact, many advantages to using a copy constructor over a clone method.
Firstly, something that I think I touched on in part one, a clone method can be extra linguistic.
And what I mean by that is that generally a good rule of thumb in Java or OOP programming is
only a constructor should create a new method. Sorry, one more time. Only a constructor should
create a new object. But obviously the clone method creates a new object, making it extra
linguistic. And since it is doing it in a kind of a unforeseeable adherence to
purely documented conventions, it's doing it in a way that's not conventional to how an object
would be created. It can create issues. And the documentation isn't that good. At least that's
where Joshua Block states. Now with the copy construct constructor, it is in fact creating a
new object. You create a new object. So when the copy construct is being implemented, you probably
see here, we pass a new object into the copy constructor, and it's that, that, that is the
copying to the new object from the current object. So the construct or the constructor itself, in
this case, doesn't do any work of creating new objects and whatnot. All it's doing is taking
in the past object and then doing the copy. And the other advantage of using a copy constructor
would be that when it comes to final classes or immutable classes, if you have, if you have this
immutable point class, so the first class I was showing you was point, but now we have another
variant of it that is immutable. We've used the final keyword. When using the clone method,
there can be issues when it's copying across final fields. Now this again wouldn't happen
with the copy constructor because again, we're creating a new object outside the constructor
and passing it into the method and then doing the copy. And another advantage is that a copy
constructor doesn't require casting because what we're doing is, as I said a couple of times already,
the new object we create is already of type whatever the class is, and that's what we pass
into the copy constructor. So if you use a clone method, for instance, you need to
do this kind of casting, which can be a bit of a pain. Oh, and as I said before, the copy
constructor doesn't have the issue with throwing unnecessary checked exceptions or whatnot,
which is again a part of the clone architecture. So this is an example. I was showing you the
copy constructor and I'm going through this code quite, quite quickly today. I'm sorry about that.
I'm in a bit of a hurry. But obviously, all of it will be available on GitHub. You could go take
a look at it and go through it carefully. Here we have an example of how the copy factory would
work. It's quite similar to, it's just a static factory method. So it's similar to the copy
constructor. It still does the copying and returns a new point by doing, with the copy fields in
the new object. Another advantage is that a copy constructor factory allows you to take in
an argument as a type argument when implementing the method or when using the method as a client.
You can pass in the type and that will return you an object of that type. So an example that
just should look as highlighted is between hash and entry sets. So assume you have a hash that
defined like this of type string and you have an hash set. And then if you want to, so hash,
hash set S. And if you want to copy that across to let's say a tree set, simply all we got to do
is to go new instance of tree set and then pass in that object with the type tree set and let
it do the conversion automatically. And this is allowed as to how the copy constructor is implemented
in hash set. So this won't be possible with the clone object. Oh, sorry, with the clone method.
I'm going to get a bit tired clearly. Alrighty, that's it. That was part two. I hope all of that
makes sense. If I wasn't clear on certain parts, I apologize. I wrote the script a while back and
I got really busy so I can record the video. But all the codes available on GitHub and I've kind of
commented what I've done so that it kind of makes sense, despite some of it not being complete code
rather being blueprints. But to conclude, Joshua Block states, given all the problems associated
with cloneable, new interfaces should not extend it. And new extendable classes should not implement
it. While it's less harmful for final classes to implement cloneable, this should be viewed as a
performance optimization reserved for the rare cases where it is justified. As a rule, copy
functionality is best provided by constructors or factories, which we saw with the copy constructing
the copy factory and all the advantages they have for us. A notable exception to this rule is arrays
which are best copied with the clone method. Alrighty, that was item 13. And hope you found that
useful. And I'll see you in the next one, item 14, which is consider implementing comparable. Cheers.
