Okay, this is really interesting because I was going to ask you before and I wasn't even sure
if I should ask this question because initially I thought you were purely an analytical philosopher
and then the more I read your work, I saw you mentioning Foucault, I saw you mentioning psycho
analysis, I was like, oh great, now I could ask you this. What are your general views on psycho
analysis? And personally, I come more from the continental psychoanalytic tradition, that's where
most of my reading. So getting to this conversation and then what's your general
view on psychoanalysis and how it pertains to cognitive science and AI, let's say, and does
it have anything useful to add to those fields? So I would say that there's a kind of conventional
scientist attitude of like, isn't this all just nonsense? We've come up with better psychological
theories since then. We have science, like why do we need psychoanalysis? Why are we reading
these people from 100 years ago? And I think that's a view I used to hold. I think partially
I've updated because I think the overall quality of scientific or experimental psychology is lower
than I used to think it was. And I think in popular discourse, this corresponds to things
like the replication crisis of like, maybe a lot of these things can't actually, like whatever
we're currently doing that we're calling psychological science is not actually producing very reliable
results. And I do have more respect for more like deep thinkers who are more generalists who
think about a variety of things using various methodology, not just scientific methodology.
And so I haven't actually read very many of these people, but broadly, it seems like they have
important ideas. It seems like it's probably worth people who are into psychology reading them.
Yeah, I think some of these have like very kind of general psychological concepts that are possible
to apply to lots of situations. There's things like the ids, the ego, the super ego, and like the
idea of repressed desires. There's things like the Lacanian trichotomy between the psychotic,
the neurotic, and the pervert. And I think that they can be pretty useful models for
thinking about a variety of things. They're not quite at the level of science in the sense that
it's like not enough of a theory that you can say like, here's exactly what it predicts,
here's what would falsify it. But I think it's often fruitful to think of a situation and apply
some of these models to it, and then at least be able to come up with something. Like some
interpretation of the situation, that's like a starting point, even if it's not like,
like, therefore, my interpretation is correct. It's like, therefore, I have an interpretation
and I can think about like what that implies. Is it at all testable? And so on.
Oh, sure. So on the note, Jessica, you know, you had another post called a critical
agential account of free will and causation or free will causation and physics. And then you use
so the term agent, it's used across all your work, which makes sense. You know, if you're talking
about AI and whatnot. And what are your views? Because in psychoanalysis, we have what we call
the subject, right? And the subject is a loaded term, even older from Khan, the German idealist
use it. And then subject, it means many things, right? Whereas the term agent, I think, is more
apt for conversations around AI and even perhaps cognitive science. So in your view,
what differentiates a subject as to how it's used, let's say, psychoanalysis from an agent
of as to how it's used in, let's say, game theory, or even AI or cocci?
Okay, so I would say that I, to be clear, I haven't read a lot of the psychoanalysts,
but in my mind, a major distinction is that the subject is primarily something like a world model.
It's a way of ontologizing the world and determining what is in the world.
And some idea of the self and how the self relates to the world. And I definitely think of Khan's
philosophy as specifying what a subject is. Like the idea of the a priori space and time
is isn't objective clock time. It's a kind of subjective timeline in which the sensory phenomena
or organized and so on. Whereas I would say that agent is more about, it does include a world model,
but it especially focuses on action and values. So an agent is capable of doing something,
not just perceiving the world. And these actions are often for some purpose. So in game theory,
it would be to maximize a utility function. And it, and I think in my post on critical
agential metaphysics, it's not so much about optimizing a utility function so much as taking
actions so as to do things such as test scientific theories or operationalize them.
Instead of simply being more like a passive observer.
Yeah, yeah, that makes sense. Okay, on the note, in fact, I found you through this post,
you're posted on Les Ferron, a short conceptual explainer of Emmanuel Khan's recent,
and at the time I was reading a lot of Khan and I was not that I in any way I'm an expert on this,
but I couldn't believe how succinctly you've explained all of Khan's concepts. Because
as you may know, the German idealists and the Kantians in general are notoriously very difficult
to read. So, okay, again, general question. What do you think modern coxsai and AI can learn from,
let's say, Kant, and then the post Kantians such as the German idealists, you know,
Hegel, Victor Schilling, all of them, do you think there's anything worthwhile to get from
these philosophers, or are they just, you know, artifacts of the past?
So I would say Kant for sure, and I think I can testify that more. So like I do think of
Kant as in some ways an AI and cognitive science person, before those were much of a thing.
Because what he's doing is he's saying there's this task of understanding the world in general,
which seems like fairly unbounded. But for philosophy specifically, there might be a more
bounded thing I can do here, which is determine what what is the cognitive machinery that the
human subject uses to conceive of the world. And if I can complete this task, then perhaps the
general task of understanding the world is mostly just iterations and things following from this,
rather than then like basically having to work out the foundations anew each time.
And so when he's thinking about the the the subject, there's there's a notion of the a priori,
which is which is certainly a concept used in cognitive science and AI in terms of
Bayesianism. And I in the post I give some relationships between those and Bayesian theories.
But a lot of it is like what what do you have to assume at the start before you even
take in data and use those two test theories? Like you you have to have some machinery already in
place for doing things like organizing perceptions into space and time. You can't learn about time
without already having time because time learning takes place in time. And so that that that certainly
would if if clarified that would have implications about AI, because that that would say something
about what you have to put into an AI at the start in in its mind for it to even be able to
learn in the first place. Some of his ideas about things like like schemata or or like combining
a concept such as the cat with your visual field where you you kind of see a splotch of orange
and then you're like oh it's a cat. That seems to have a lot in common with computer vision
because computer vision is about mapping a concept like the concept of a cat to a visual field.
And so I I wouldn't particularly say that that he's that like he knows how to solve a lot of
these problems like computer vision but his work certainly raises a lot of them and like fairly
over on early on even before they were computers. So I think in part it might be useful as a sort
of reference point of someone in the past thinking about a lot of the questions of
how a mind works and who's been commented on quite a lot by others even before computers
and so and so on. I would say even more speculatively there might be things to learn
about ontology from Kant in terms of things like like defining ontology in terms of things like
space time and sensory fields a phenomena might have utility if you if you want an AI to have a
kind of ontology of the world that you can talk to it in then you might want it to have
something like a 3D model of subjective space time that is somehow related to your 3D model
of subjective space time and have something like a common language for specifying objects. I mentioned
before the problem of even if you wanted a paperclip maximizer how would you specify a paperclip
and you might want to do it using a sort of Kantian method where you think about
like the paperclip in terms of does it have a location in space time and what are its properties
in terms of in terms of phenomena and like extension and so on.
