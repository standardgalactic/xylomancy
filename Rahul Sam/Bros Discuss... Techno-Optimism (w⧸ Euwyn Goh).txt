Okay, so to get the ball rolling, as they say, I'm going to read
off, um, Adiga's, uh, the question concerning technology,
although, although it's very important, a caveat, Adiga was a
serious Nazi. So whenever you read him, you need to have that
in the back of your mind. He wasn't some kind of peripheral
Nazi. No, no, no, he was deeply involved with the Nazi party.
He was an ideological Nazi. And, you know, I even read this
good analysis of Padiga that in many ways he was a, a
metaphysical and SMI, not just the kind of the, you know,
run up the mail and SMI in Germany during World War II. He
was a legit and SMI. So it was a Nazi. So whenever we read him,
we need to keep that in mind. Regardless, I personally think
one of his best essays I've ever read is the question concerning
technology, uh, which he does an analysis, a metaphysical
analysis of technology. Uh, so I'm going to read really two
tiny excerpts from that essay, and then we'll go from there.
So here's what he says. Everywhere we remain unfree and
chain to technology, whether we passionately affirm or deny it,
but we are delivered over to it in the worst possible way when
we regard it as something neutral. So that's a really
important point. For this conception of it, to which
today we are particularly like to pay homage, make us
utterly blind to the essence of technology. This is essentially
in the second paragraph of the essay. So he starts off this
and like that. And then this is the important bit for me at least,
which I thought was really, uh, perspicacious. He says,
yeah, we're questioning, uh, we're questioning concerning
technology and we have arrived now at Altaire, which is a Greek
term, which means, well, it translates to ad revealing. What
has the essence of technology to do with revealing the answer
everything for every bringing forth is grounded in revealing
bringing forth indeed, gathers within itself, the four modes
of occasioning, causality, and the rules and rules them
through throughout. So the four modes he discusses as in his
essay, we don't know how to get to that, but the important bit
is about what revealing, um, within its domain belong, belong.
Wait, what's that? He writes in such a weird way, man. It's so
hard to read how to go within its domain, belong and, and means
as well as instrumentality. Okay. I don't know what the sentence
means. Ignore that instrumentality is considered to be
the fundamental characteristic of technology. If we inquire
step by step, what technology represented as means actually
is, then we shall arrive at revealing the possibility of all
productive manufacturing lies in revealing. And now this is
perhaps the most important little excerpt. Technology is
therefore no mere means. Technology is a way of revealing.
If we give heed to this, then another whole realm for the
essence of technology will open itself up to us. It is in the
realm of revealing, i.e. of truth. So the after reading this
a couple of times, my fist inside and the way I connected
this to kind of techno-optimism and tech bros of our time is,
I feel like a lot of us, at least tacitly, view technology as a
means to an end. A lot of tech bros think of it as some kind of,
as Heidegger says, instrumentality. It's, it's a way to get things
done purely pragmatic, utilitarian kind of way of viewing.
However, actually I have some notes here which I took down.
That bit about instrument, sorry, that bit about revealing
shows that technology is not a mere instrument. It's rather a
way that truth reveals itself to us. And when I mean truth, I
don't mean truth in like a scientific and perical sense,
like facts of, let's say, the physical world, but rather
truths of being as such. So the brilliant inside Heidegger had
in the 20th century, which I think revolutionized philosophy
afterwards, at least so-called colonial philosophy, is that
he showed that truth isn't something that just kind of
prima facie just presents itself to us. It's always something
that's revealed through us, a subject, or as he calls it, a
design. And then he used that kind of concept that truth is
always something that's filtered through a framework or
framework, again, reduces it to some kind of like algorithm.
It's not in that sense. Rather, it's through a mode of being,
through an orientation, let's say. He extrapolated that idea to
every other part of being. So technology, art, obviously history, and what not.
This essay is on technology. So the first thing is,
technology is not a means to an end. It is much more deeper and much more
profound. Its essence is it makes metaphysical claims, which means
technology deeply, profoundly changes who we as human beings. And that's
not an eye-opener, especially with social media. People just accept
that kind of, now it's a given, right? Although it's not just in the sense
of our social reality, but our metaphysics, our values itself changes
with technology. And then the other critique of, let's say, tech
bros or tech broism is that there's this kind of naive optimism,
what I'm going to talk about, where there's this assumption we have that technology is good
just for the sake of technology. So if we keep advancing and developing our
technologies, that's just good for its sake. It's not so simple.
What Heidegger talks about, this thing called, he has technology as revealing,
but then he also has this thing called enframing, which, okay, I hate to be the
annoying leftist that blames everything on capitalism, but I'm going to be that
annoying leftist. And framing us, we start viewing other human beings also as
technical objects, as resources to be exploited, case in point, human resources.
So in that sense, the technological metaphysics have become our metaphysics.
We view other human beings as means to an end, as things to be optimized,
to be used, to be technically exploited, certainly in capitalism. And a good example
is when the whole, as we are going through the current AI revolution, when the whole,
with open AI, a Chudge APD thing came off, the first question, a lot of the kind of spontaneous
reaction most people have is, oh, what's it going to do to this job, to marketing that job?
What's it going to do to the economy? But rarely did we ask, what is it going to do
to the human subject as such? And I think the reason we asked that previous question,
not the latter one, the reason we asked, oh, what's it going to do to our economy? What's it
going to do to, I don't know, different kinds of jobs, is because again, we human beings,
because we have this kind of technical metaphysics, we view human beings as agents of capital.
Simply that's all there. We just, you know, we trade and we pretty much move around capital.
So the most important thing isn't the human being, but what the human being is useful.
And that's my critique of tech bros, who kind of, they have this kind of massive
optimism where technology will liberate us. It's a typical tower of Babel from the Bible,
typically liberate us. It'll be a saving grace and it's good just for its sake. And in many ways,
the human being doesn't even matter what matters is the technology as such.
And that is something. So by the way, Heidegger was not a Luddite. He was not saying technology is
bad. I think the best way to read Heidegger is through the Hegelian lens and be like, okay,
we need to see technology for what it is with its contradictions. And I'm not saying that's
obviously the good and bad and you kind of weigh out the pros and cons and get the pros.
It doesn't work like that. Heidegger's point is more, I'd say more solemn even, that with the good,
the bad comes along. It's concomitant to the good. We can't have our cake and eat it too.
That's the point Heidegger makes, in my opinion. And I think that's the best way to read his essay
on technology. Yeah, saying all that, Yun, right, I said a lot there, but the flow's yours.
Yeah, well, you know, I agree. And I have the same kind of orientation or like
views on technology. And so I think what I can do is kind of build on what you've said.
But first of all, yeah, like Heidegger's take on technology, I think is a really,
really important one, right? Like I think he sees very deeply. You could call him a prophet,
in a sense, because he wrote the book in like 1950. Was it 1950, 1900, something like that?
The essay, no, 1950. I don't know when the essay was published. In fact, you keep going. I'll find
out when it was published. Yeah, it was early enough. But he saw through these things that
he basically saw through how much of an impact to use a simple word, you know, like
exactly, exactly 1950. You hit the nail on the head.
Yeah, that's great. But he saw all of this before any of it happened, right? Like in 1950,
the world doesn't look like how it did today, but he saw all of this coming.
But I think one of the main points again, I want to reiterate is like, and an interesting
thing here, I think is, I think, Raul, you made a few points around like tech bros and like
techno optimism. I think in this context on what, what everything Heidegger is writing about,
you can kind of extrapolate that to kind of the whole generation, at least the whole new generation,
because they're all brought up within this setting, right? Like technology is inherently a part of the
new generation. So in a way, like tech bros have this kind of techno optimism view. But I think
it's inherent in everyone who grows up, everyone who grew up in this kind of way of being, right?
Which is times our religion. Yeah. So I think the important point to make is that
it's one of those things now technology is one of those things now where it's, it's so deeply,
it's so deeply encapsulated our ways of thinking. And I think here it's probably more accurate to
say the Western way of thinking that you don't even notice it. Like no, like people on the street
wouldn't be conscious, nearly conscious of like what sort of effect technology is happening to them.
And I think that's kind of the real baseline idea we kind of trying to, trying to like expound on
as well, right? Because as you mentioned, and like from Heidegger, it's technology is not morally
neutral, right? And this is what most people think. Very important point. It's not just tech bros,
it's kind of most Gen Zs, even most parents, I'd say, although they have more, like more of a
conscious idea of like what life was like before technology. I think most people will,
I think it's most, it's rather acceptable for lots of people nowadays to say technology is
neutral and it's just a means to an end. But as you mentioned, like that's kind of missing
like a lot of the point, right? Technology has a fundamental essence to it. There's a fundamental,
fundamental metaphysics to technology. And when you pause it, when you think technology is just
a means to kind of missing the deeper picture. And like, as you mentioned, one of the ways in
which in which it's affecting us, like the essence is in terms of how we view people, right? Like
we view people as resources, we view nature as resources. And in a sense, it's kind of like
the critique of technology is somewhat similar to a critique of capitalism, right? As more people
might be familiar with. And I think that's fine. Because like, if you think about it, I think like
capitalism thrives on technology, right? Like, in a capitalist society, what are you looking for?
Like, efficiency of production, something like that, right? Like, absolutely, that's exactly it.
Yeah. Yeah, if you want to excel as a company, as a producer, as a whatever, like what you're
trying to do, you're trying to produce more, more efficiently. And basically, technology,
technological innovation is kind of what drives it. And so I think you can't really divorce
technology, a critique of technology and a critique of capitalism. So you can kind of
treat everything we're discussing as kind of interchangeable in this respect.
But that's it, right? It's this very deep and trench thing that we're trying to kind of expound
on. And like, we're trying to discuss the revelation that it's had that everyone like kind of sees
past nowadays. And I suppose the biggest, the biggest threat or the biggest, the biggest kind
of effect I see these days is, from my point of view, and then we can kind of launch into kind
of a couple of different points, because there's a lot out here as well. The biggest point of view,
I think, is that people are, there is like the fundamental metaphysical idea behind technology
is also a form of self-worship. It's a form of like, from a Nietzschean point of view,
like the Nietzschean idea is like a revaluation of values, right? And so what technology is,
is basically an attempt to create like a new order. It's an attempt to create a new order in
which, you know, human nature or man is mechanized in different ways, let's say, like you can impose
a rational order on the way we do things and make it more efficient. And I think you could then kind
of interpret like the whole movement of technology being techno-optimism, kind of somewhat similar
to scientism, right? It's this idea that, you know, we are our own gods and we can decide whatever
the world should look like, we can do whatever we want. And our goal here is to kind of,
kind of overcome nature. But then in doing so, like there are a couple of, there are lots of
risks, right? Like we kind of overcome nature, then we overcome ourselves, we overcome ourselves,
right? Like, like, and that's the point you raise with human resources as well, right? Because
once you see nature as something to be overcome, or something to be used as a resource, what's
stopping you from seeing a human, right? As something to be like, something to use as a
resource and something to like, kind of have power over, it's all, it kind of all exists within the
same framework. And so I think the two things that kind of comes to mind firstly is where this is
all taking us. Because there is a kind of development, there's a development to technology,
right? Like, it doesn't just end with us having, being in a utopia. It's never that simple, right?
And here, if I want to bring it down to, to, to kind of the ground level of practical, on a more
practical level, right? I think there's a lot of simple, kind of simple ways, like you don't even
have to talk about philosophy. There's lots of simple ways now where people are beginning to detect,
like certain faults or effects in which technology is, is, is, is putting us all at risk, right?
And a simple example is like Jonathan Hyde, he's a sociologist. He talks a lot about the risk of
social media and what it's doing to humanity. It's not morally neutral in that sense. And
if we're going to go down the road, the route of social media, it's not a morally neutral route
where it's a pure means in which we are just doing whatever, like we're just
using technology for our own sake, right? Like it's doing something to us as well. And I like
what CS Lewis said, I think it was in the abolishment of man. Let me try and find a quote.
He said this, each new power won by man is a power over man as well. In every victory,
besides being the general who triumphs, he is also the prisoner who follows the triumphal cup.
Beautiful quote. And so you're being, you're kind of, the more you kind of
overpower nature, you overpower kind of everything, right? You're not, you're also
being taken along for the right. You're in a way a prisoner of what's being done.
Yeah, yeah. Actually, can we revisit that quote because that was a really good quote.
I think, you know, CS Lewis and I, for me, he's a bit too conservative, but I think he's a brilliant
thinker. Isn't it really interesting that you brought up Jonathan Hyde and social media and
then you quoted CS Lewis? Because social media perhaps is the quintessential example to exemplify
that quote. It shows the inherent contradiction in social media because think about social media.
Its promise was we're going to be global citizens. We're all going to be connected. We're all going
to be knowing what's going on. And it's just this beautiful utopian liberal dream, isn't it?
But then CS Lewis would be laughing at that and saying, oh, look, now we've become slaves and
enslaved to social media. And this, this thing that was supposed to liberate us ended up enslaving
us. And I think that's where he points out that I don't know, I know he's coming from a very kind
of Christian perspective, and that's completely fine. I mean, so am I in many ways. But, but he's,
I think what's more perspicacious is that him pointing out the contradiction in what social
media is. It's what it promised and what it became. No, 100%. And yeah, that's where that's
what I was going. So like to finish my point, it's, you know, where we're at now, technology
has done something to us. It's not morally neutral by any means. And one of the ways that this is
reviewed is, you know, there are lots of simple practical ways in which people are being becoming
more conscious. But also, I think it's quite clear that, you know, going more and more further and
more deeply down this path, it's not a utopia we're kind of ending up with, you know, it's, it's
something weird. It's kind of, and there are lots of words that people use that are quite
interesting, right? Post humanist post humanist. I think I like the word, I think Paul King's
north as well. He, he used this word, like we're all kind of entering into a hyper reality.
Yeah. Oh, uh, John Baudrillard hyper reality. Yeah. Yeah. Yeah. Like I really like that word,
right? We're not, it's not like, when you talk about utopia, that's kind of the
thing that techno optimists look at, right? They romanticize the idea of technology,
really, they romanticize the idea of innovation and like overcoming nature and overcoming,
like human nature, even, right? Like when I see human nature, I mean, like the limitations,
supposedly, but what that doesn't include is this whole, you know,
what's the way to put it? Yeah. Yeah. I'm getting an English of what I was going to mention.
Oh, it's so, it's so weird to like juggle many thoughts. If I'll just finish it,
wherever I'm going to take it now, right? But it's like, basically the fault of techno
optimism is this whole idea of you, you romanticizing the whole idea of changing the way people do
things without seeing, and this was in the CS Lewis quote, right? That you become a prisoner
of what is what, what becomes as well. It's like, it's, it kind of goes both ways. And
I also had a couple more. So I think, so social media is a pretty common way in which
the common person can easily detect like thoughts, right? Where and where this is all taking us. It's
not a perfect thing by any means. And it might be even like immoral in many senses, right? And that's
the, that's, I think, like a lot of heights research around social media is like social
media is like affecting us badly in many ways, which we never expected. And that's already a pretty
simple. That's a good, that's a good example, I think. And also this morning, I read a newsletter
by a tech person, so a technologist. And I saw a few interesting like things on here, which is also
like what people can easily perceive, like to be dangerous or risks, right? And firstly, this
relates to what Heidegger mentioned, but what she wrote here, and there's much more simple
language as opposed to what Heidegger would have written, but part of the problem with the lean
startup mindset, lean startup meaning basically kind of the methodology around startups and tech,
right? Is that it sees life and work as an optimization problem. The point is to help
people live a good life, not just an efficient life. The goal is human flourishing, not convenience.
The goal is a good future, not a technically advanced future. And so it's pretty like technologists
and kind of everyday people are perceiving this. And this was written by, sorry, I think I'm not
sure you pronounce her name, but she's a technologist. And I'll put up her, is it a
subject or what is it? Yeah, yeah, subject. Put up the subject. Yeah. And the second thing she wrote
also kind of in more simple words, it's like, I've lost a lot of faith in tech solutionism,
the idea that most problems can be solved by technology. Why? Because most problems are
people problems, not technology problems. I don't believe very important. We need to touch
on that. That's a very important point. Yeah, I don't believe we are about to surrender to a
robotic new dawn, where an AI will replace McKinsey or your therapist. Why? Because a company
doesn't hire McKinsey because they're better than the AI. They hire McKinsey because if something
goes wrong, nobody will blame you for hiring McKinsey. Humans are complicated. And so on this
level, you can kind of see as well, like lots of kind of tech solutionism, that's an interesting
word, is missus the point that kind of that most problems are people problems. And even on this
level, kind of the applied technological level, there are already gaps. You could say problems,
right? For me, the word I've been using recently, thanks to Tom McGavin, is contradictions. Human
existence is, ontologically, there's this, we have built in contradictions that we can't get away
with or jettison out of existence. Okay, I took down a lot of notes here. We know what you were
saying. I want to get back to the self worship point because that is something that I hadn't
thought about much. And because pretty much everything you said, I've kind of thought about
written on and obviously I resonate with. But the self worship bit isn't something I have
thought about. And the reason I want to talk about that is I realized in my initial long
monologue, I kind of missed a certain point I was going to make, which was that technology is not
neutral, as we discussed, but also another misconception tech bros have is they think that
all technology will do is that it'll just amplify who we already are. And that comes with a lot of
assumptions and ideological presuppositions that we already know who we are, that yes, human beings
are static and that we have a specific nature of some kind. And secondly, that technology will
just make, quote unquote, better versions of what human beings are. Whereas I would say if a lot of,
well, I would certainly religion, but also philosophy, 20th century philosophy, history,
and now more recent sociological and psychological research is showing us that no human beings are
malleable, not in a bad sense, nor in a good sense. We are malleable as such. And therefore,
it's a mistake to assume that the human subject, even at an individual level, can just,
we can amplify who we are. That doesn't happen. Our social environment deeply affects us.
But saying all that though, is it because I don't get it, because for me, my whole view
with technology is we're moving towards a, thanks to capitalism, and I mean that obviously,
sardonically, a post-humanist society where human beings simply become agents of capital,
we become technical agents in society. But when you talk about self-worship,
that kind of gives it a bit of a different thrust. So perhaps you could expand on that a bit.
Yeah, but yes, also, so what you're mentioning around the technology having kind of its own
essence, that whole thing. I think, and so most people now, they see it as neutral,
but that misses the point. Because I think when you say all technology is self-augmenting,
you kind of assume that it's neutral, like it just augments. But no, it has its own essence,
it has its own metaphysics, as we were discussing, right? Yes, its own reality in some sense, which
I mean, yeah, it's a hyper-reality as well, as we mentioned. And I think
the last thing I read is from Jack Elal, I'm not sure you pronounce his name, but he's also
written quite a bit of it on technology, and he recognized it as a self-augmenting force,
but one that kind of engineers the world on its own terms. And so I guess that's the way to kind
of, that's how Heidegger ends his essay. Heidegger makes the point towards the end of his essay,
that technology has a being of its own, that does change and augment the world. Yes.
Yeah, because it is self-augmenting in its application, right? And so in that sense,
it's like, it's neutral because it just augments the human subject. But no, it kind of does it
on its own terms, because then you create something, you create a being, almost a mode of being,
right? And that has its own essence, its own metaphysics, that's what we've been repeating.
And I want to give an example on that. I think the kissing point would be the stock market.
Majority of the stock market, it's not human beings, the actors in the stock market aren't
human beings anymore. It's virtually robots. It's programmed machine softwares that are doing
stock trading and whatnot. And yes, you could argue that the capitalists by workers and by
human beings, but regardless, the stock market now is a system with its own metaphysics,
with its own reality. And human beings are becoming unnecessary for it. We're becoming...
Actually, so before we get into the self-worship bit, I think it's important to kind of get into
what we mean really when we think about the essence of metaphysics of technology, right?
Because I think we've said this many times, but I think it's not... We can make it clearer what
that actually means. And so kind of self-worship, if I were to talk about the art, I would kind of
think about it more towards the end. Self-worship is kind of where we're leading ourselves to,
but even right now, what we're participating in, like this whole hyper-reality that we live in,
is it's got its own metaphysics, it's got its own essence. And what that means, right? I think the
example, Raul, you mentioned earlier, was that we start to see people as resources. But that's kind
of one way to look at it. Well, okay, to really, really break this down, because I know that you
and I tend to get very abstract without thinking, is metaphysics, in a very pragmatic way of putting
it, is it's simply telling us an ought. That means what are we supposed to do? Now, of course,
if you go to Aristotelian metaphysics, you could look for the metaphysics or the essence of a tree.
What's a tree? Is there a platonic tree somewhere? Let's forget about all of that for a moment.
Let's just simply think at a social level, metaphysics is an ought. So what are we supposed
to do with our given reality? And connecting that, in my view, connecting that to human resources
would be, okay, the metaphysical sort of injunction or what we're told to do is to take these human
agents and use them to, I don't know, maximize profit or maximize productivity, optimize,
or be more efficient. So that is kind of the metaphysical injunction or ideological injunction
that is metaphysical after all. And that's kind of the way I view the metaphysics of technology,
although, although, and I want to kind of put this caveat here, because we started off with
Heidegger. Look, this port isn't on Heidegger, but we started off with Heidegger. It doesn't have
to be about Heidegger, but for Heidegger, it's not just that. It's also he's looking for an
essence of technology and what that entails. But sorry, did my kind of point about the,
you know, that's good. That's good. So it's kind of, and I think there's one more layer to it as
well. Like, I think, you know, we see each other, we see each other as capital resources,
essentially, and that's a danger to her, obviously, right? But I think there's one, like,
another layer of ought as well is I think we kind of blend on this idea, like this intrinsic idea
that we don't talk about that. If we, if we liberate ourselves from everything, we would be happier.
It's that kind of, like, it's just the classic capitalist kind of ideology, right? And that's
something very inherent in technology, right? It's like, the thing that causes us unhappiness is
like systems or structures that we have to be liberated from. And that's, that's sometimes true.
But I think now we're getting to the point where we, we're trying to liberate ourselves from reality
itself, right? And so, but then the thing is that in a far more fundamental way, it's just
making far more people more unhappy, which is, which is, which is a contradiction, almost ironic
contradiction you pointed out before. And you know, you would, you, you in fact hit the nail on
the head because this guy Ray Kurzweil, who is kind of like a futurist, he, I remember reading,
I haven't read any of his books, but he is kind of known as well. He, he perhaps is like before
Balaji and Elon Musk and all these types. He was kind of the OG tech bro. And he was writing about
these things, you know, in like the nineties. And he has this really interesting essay, which I read,
I forget where, but he talks about how you could just live in a simulation and you won't be
limited by your physical reality. So you could live kind of the mind of that machine. So if you,
one day, if you feel like a woman, you are a woman. And not to go to the whole gender,
you know, to debate about that, like forget about it. But no, but no, I think it's true.
Like if you feel like, look, let's say a biological female, right? Just all you gotta do is
kind of cognize that in your, in your, in your brain. And then you become that thing. So
we kind of completely let go of our physical embodied reality, which for Heidegger,
Maurice Mollepointi, or modern Cogsci, the cognitive science would be an,
and complete abomination, given that we are deeply embodied creatures to be human.
Well, at the end of the day, we try and liberate ourselves from reality. So precisely,
that's why we're going to the point you were making about reality. Yes.
Yeah. Yeah. Because also that's Heidegger's kind of metaphysics, right? It's not just about
you, but it's about, it's not just about subject and object. That's kind of his metaphysics.
He breaks it. Yeah.
No differentiation there. It's kind of the subject participating subject and object are one.
Yeah. Yeah. I mean, look, he has got many, he calls it does man, he calls it life world.
But the idea being that you can't just, yeah, you can't isolate the subject
from their life world as such.
Yeah. Yeah. So to put it simply, right? It's like kind of man has a certain relation to nature,
right? Man has a certain relation to others, like the other, right? And there's a certain kind of
without going into what that should look like. I think what technology does is it comes in
and imposes a certain view on that, right? Like, because traditionally, like pre-modernity,
like man saw nature as something to be worked with. Correct. Like man saw fellow man as like
something to be treasured as friends. In fact, the kind of what technology does,
what the whole technological worldview does, this is again, talking of discussing its essence,
is firstly, kind of nature is seen as something to be used as a resource, right?
Is to be overpowered, right? And overpowered means used, right? It's kind of the same thing.
And the danger is that the same thing is applied to man, right? Like man becomes human resources,
as you say, it's something to be used. And so in that sense, you can kind of see how technology
is not neutral. It imposes a worldview. That's the essence. I mean, also, on your point on
pre-modernity, the Hegelian point there would be in pre-modern society, and obviously I'm not a
historian, but from what I've read, it's not even that we, that individuals saw other individuals
as, oh, that's someone that I'm related to. No, no, no, they saw their subjectivity in them.
As in, I am you as much as you are me. Yeah, oh, no, no, oh, yeah, no, but I'll give you a
technological spin, right? It's not like, because nowadays, what's the phenomenon we call the social
phenomenon? Everything is kind of networking, right? Yes. Oh my god, dude, you read my mind again.
I was like, when you speak to other people, you are like, what's the career gain here? Correct.
I hate the term networking. It's a circle term. It's just even something as intimate as friendship
becomes something where I need to get something from that person for me to rise in the social
hierarchy or whatnot. Exactly. So that's the imposition of technology, right? Sorry,
I interrupt you. Can you say that, make that point again a bit more, like flesh it out a bit more,
because I feel like you were getting out, making a really good point and I got excited.
So clearly, so people get what you're saying. It happens between us. But yeah, so technology
has an essence, right? And two clear examples where I can see it playing out and I think which
Heidegger touched on it as well, is like nature and fellow men, right? So you, we used to see nature
as something to work with. We used to see men and women as friends, right? Friendships would be
cultivated. We kind of saw everything on equal ground. But then when the capitalistic slash
technological ideals, ideas started playing in the picture, then we, that started twisting our
worldview, right? It started twisting our relation to the things around us. And as Heidegger's
metaphysics goes, and which I actually, like I personally agree with, like man is not just
an individual, right? That uses things. No, like it's not just a subject and the relation to the
object like being separate in any way, right? In the subject very much participates in the object in a
very, like you can't, you can't separate them in a very inseparable way. And so when technology
comes in and twists certain views, you know, it's, it's, it affects the human, it affects the mind
to an understated degree. And that's why I think these days, right? It's something that's so heavily
encapsulates everyone's thinking that they kind of not, you're not even conscious of it.
I mean, it changes you. It makes you something human.
Yeah. Yes. Like nowadays, like meeting someone purely for career gains normal, whereas it wasn't
50 years ago. And that's what technology is done to us. And like using nature is normal to us, right?
Yeah. I mean, we can monetize nature, but if you tell that to like an Indigenous,
you know, someone in, in this, I don't know, 1400s, that would sound like even our own Aboriginal
people in Australia. Like, I mean, I'm sure, obviously, don't get me wrong. I'm not making that,
I hate to make the racist argument or their primitive native one with nature, none of that
nonsense. But if you, if you speak to, let's say, it doesn't have to be, leave aside the Aboriginal
people, because I hate that argument, you know, noble savage, it's very racist. But if you study,
if you do like, let's say, an anthropological study, anthropological study, and explore these
communities, certainly they don't have this concept of exploiting nature or using, seeing
nature as a resource. For them, nature was very much alive. And it was, it was a part of them
as much as they were a part of it. Yeah. Yeah. Yeah. Precisely. And that's, and that's one of the
things, right? Because now the danger, I think, is kind of a metaphysical problem. Like, it's a,
it's a kind of a spiritual crisis, right? As you will call it. That is, we're losing our relation
to everything around us, right? We start to see nature as something to be used. We start to see
humans as something to be used. And there's something that you lose there. There's something
that you lose there. And I think that's where kind of my whole idea around self-worship comes in,
because that's the position of Brian, right? That's to say that, you know, kind of my imperative
theory is to have power over everything. It's to kind of reinvent, like impose a new order
and everything. It becomes a Hobbesian nightmare, you know, it's just. Yeah. Yeah. Yeah. And I think,
like, and that's probably the Christian worldview in me speaking, as opposed to the Nietzschean,
because the Nietzschean ideals will be like, no, let's reinvent the way things are done. But
I don't think that's possible in many ways. And that's why I kind of refer to C.S. Lewis, because
like in the abolishment of man, abolition of abolishment. No, no, no. Abolition. Abolition.
Abolition. Abolition. Abolition of man. Yeah. Yeah. Not abolish. My favorite Lewis book.
Yeah. Yeah. He writes, he basically writes precisely about this subject, right? Which is,
like the Nietzschean ideal kind of falls on its own head, because you can't,
you can't revalue values using the values, using the values themselves, right? And so
there's, there's a lot to be. I have a slight disagreement there, but we don't have to get to
that. I have a slight philosophical debate there, but this and that. We can do it another time. But
like the whole danger there is one of pride, right? And I think putting aside the Nietzschean
ideal, which I think there's some problems there, I think if you look at it from a Christian point
of view, it's like pride goes before a fall to put it more simply. And also to cover a bit of what
Lewis prophesied in the Abolition of Manbook is if we keep on trying to go down this path of like
gaining power over everything, we gain power over nature, we can use, we can extract everything as
resources. We start doing the same to other people. And eventually we start doing the thing to human
nature itself, right? And there's the whole kind of thing around the whole, he prophesied this
endpoint to be kind of the eugenic event, right? The event at which basically man takes on the
position of God as a creator. Yeah, yeah. And you know, connecting that to a bit better for
the Heidegger's talking about here, that's sort of what he means by enframing. And the grand irony
of all of that was Heidegger was a big old Nazi. And the Jews were exactly, they were
enframed, they were just used things to be covered, to exploit and used upon. And certainly, you know,
even the Nazi ideal has an element of self worship. But for them, it's more that they worship a system,
they worship the organic union, the whole of being, which for me is a fascistic idea.
So as you were, as you were expounding on the self worship, but I was trying to figure out,
how can I juxtapose this with kind of my thesis, which is the post humanist idea that we are becoming,
we're becoming something that is not human. The future of humanity is going to be without human
beings, so to speak. I'm going to try to make a point here, but you were going to say something,
you go first? Yeah, I think that's the hyper-reality element to it. But I don't think Lewis saw it
from that lens, right? So says Lewis specifically saw it from the lens of eugenics. And I think
there's something to that point as well, which is the final stage of man's conquest over nature
is basically when, in the course of reality, when one age really attains by eugenics,
the power to make its descendants as whatever it pleases. Yeah, I mean for me now, I would still
say that's post humanist, because the post humanist idea is that there's no human being per se,
we're just again, we're biological entities and we can be optimized, used.
And so and so what Lewis points out is that in a way, all men who live after this age are
patients of that power. So then they are weaker, not stronger. Yeah, so like no matter what kind
of power that's a supreme irony. Yeah, we put in their hands, it's this people in this age which
has preordained how they are to use them. So in a very interesting way, Lewis prophesized this
endpoint, this event at which we are bringing ourselves to this route, which is we, our conquest
becomes over human nature itself. And I think a very vivid image of this is in Huxley's Brave New
World, right? Human nature is the last part of nature to surrender to men, right? And in Brave
New World, in Huxley's Brave New World, there's eugenics, there's like prenatal conditioning,
I believe, right? Basically, you perfected the human species, right? And there's like a perfect,
I don't know, applied psychology, whatever, and men has perfect control over it.
Behaviorism, behaviorist behaviorism, man, it's a monastic, yeah, yeah.
Yeah, and basically Lewis points out that that's the point at which
man reaches the pinnacle of the power and everyone else is kind of, you know, a prisoner of that.
Yeah, that's something I find interesting. But the artificial piece, artificial intelligence is
something else, it might be something else or it might not be. I'm also wondering how we can kind
of... Well, in fact, when I was going to bring this up to you at the end of the point, but I think
with this whole conversation, we can end on a positive note. And I'll tell you why. And as you
know, I'm very cynical. I don't know the end things on positive notes generally. But this
this topic of technology, there is in the typical Hegelian move, in the failure, there can be
something good that comes out of it, I believe. So firstly, the reason, you know, I was initially
a bit confused about the self worship point was the way I view the kind of post humanist idea is that
human subjects, they stop viewing themselves as human beings. Whatever this deep down identity
we have as human beings, it's just, it's jenisin. But then I realized, in fact, no, the self worship
point is perhaps more perspicacious because in post modern society, we live in this kind of
ruthless pragmatism. So being a self worshiping egoistic narcissist is one of the best ways to
get around post modern capitalist society. If you are a bit Machiavellian, because then, you know,
as we were discussing, if we view other human beings as not really human, but rather some other
biological agents to be used and exploited, then pretty much the best way is to play the game,
play the game and get to the top, whatever the top and the funny thing is in post modernism,
the top doesn't even matter. It's just climb the hierarchy for the sake of climbing the hierarchy.
There's no, there's no, let's say the typical values of beauty, love, truth or God, none of that.
It's just climb the hierarchy. We discussed this in the previous pods, isn't it? So, and then in
that self worship kind of works because it's not self worship in the sense that you think,
I don't know, at least this is my interpretation of it. There's something special about me that I'm
unique, I'm divine and none of that. It's just, I am who I am. It doesn't even matter, but what
matters is the game, is the task, it's the partaking in the social game, so to speak.
Yeah, yeah. I think there are two ways to look at it, right? And earlier, as I mentioned,
like there's kind of a Nietzschean approach, which is to lean into it, because if you are going to
think about, like, because Nietzsche's idea is like the Uberman, just like the Superman,
that's the ideal you want to be, right? You want to be the person to kind of
revalue valuations, right? Yeah. Rebuild and kind of, I mean, you want to even,
you want to rebuild the the meta values itself, not just values, but reevaluate what values are
itself. Yeah, yeah, yeah, yeah. And so kind of, as we discussed, technology is a major imposition
on like the way things are done and how like worldviews, like to the modern worldviews, right?
If you were to work and build within that space, you kind of have the opportunity to do something
like that, right? Well, I mean, actually, I guess the easiest way to say how much of an
impact technology is, is if we were to boil down the ages into one word, like you wouldn't call
this current age we're in and, you know, a postmodern age, like that does some, that's
mean something. If you call it an atheistic age, like, yeah, that's something I think people
usually call it a technological age. Correct. Cause I mean, postmodern age, you could even call it
the last century, but our specific age is perhaps a technological age. So I think you can conclude
from that and say to say, technology has been like the genre, like the era defining thing, right?
And so if you were to pursue the Nietzsche ideal, you have the opportunity to redefine the way
everything starts, right? In that lens, I think, although on the Christian kind of religious path,
I think there's a, there's quite something to the whole idea of, I think I saw this coin somewhere,
but it's like technological acesis, I think like, like, like acicism, like being a technology,
technological aesthetic, right? Basically, distancing yourself from technology and its
metaphysics. And the whole imperative there is like, be aware that, you know, technology in
everything, there is a trade-off, right? Like no technology is perfect, everything comes at a price
and prices that we're not aware of. And more importantly, that you can't have your cake and
eat it too. Exactly. Because the trade-off argument for me, that's too pragmatic, because that kind
of makes the assumption that, oh, you can have the good without the bad. I don't think that's how
the reality works. I agree. But I think firstly, you'll become aware of it, right? To be aware of it.
Certainly. The whole imperative there from the Christian point of view is to kind of keep the
means the means and keep the ends the ends, right? Yes. I actually made a note earlier, but I think
Ivan Illich, I think that's his name, he's also written quite a bit on technology.
You're going to have to send me all these things because I need to put them in the show notes.
Yes, I will. But he argues for what he calls a convivial use of technology.
Sorry, what was that word? Convivial. Right. I don't actually don't know what it means.
That's what he called it. But what that entails basically is firstly, technology
exists to fulfill man's existing needs and desires instead of generating new needs and desires.
And so, technology, capitalism, you can kind of, like that's when you place the means as means and
ends as ends. I think the other points, quite simple, increases man's freedom, independence,
enhanced welfare, physical man. Okay, okay. Now here's where my cynical side is coming out.
As a Zhezhekian lecanian, I don't know if that's possible. This is the way I become very cynical.
I don't know if it's possible for us to purely use technology as something that, as a tool,
which is how most of us think it was used as a pure tool that fulfills our desires.
Because firstly, I don't think human desire can ever be fulfilled. We are desiring beings.
For me here, lecan is, he is a prophet. He gets it. He gets it precisely, which again is the problem,
which the problem is that our desires are unfulfillable. Therefore, the technological
metaphysics or whatever you may call it can exploit those desires. And for me, though,
for me, though, I don't know, as far as I can say, my only way to approach this is to take on
that contradiction. It's not to, it's not to try and take the good without the bad,
because that, as CS Lewis points out, would make things worse, is to take on the contradiction.
And of course, that doesn't mean coming and giving into the bad. I'm not saying,
oh, I'm going to become a porn addict in, I don't know, Mark Zuckerberg's meta word and just
like, I don't mean that. I mean, as you said, first be aware of it. And then the only solution I see
is through critique, through perpetual critique, through, through working through, through the
contradictions and doing, and doing all these things, which some people who are a bit more
intellectual might find silly things like, you know, social media detoxes, digital minimalism,
those are good things. We should not sneer at them and kind of look down upon them,
because that's the, again, that's our life world. We can't, don't play the Buddhist game or the
quasi Buddhist game where you, oh, everything's a cosmic phenomenon, detached, no, no, no. For me,
it's partake in the contradictions and work through them, which is hard, which is difficult work.
Right, you know, that's a good point. But also, yeah, I guess from a psycho and analytical point
of view, it's like desire is everything, kind of. Yeah, desire is fundamental because we're
lacking beings. That's an interesting one. But I think very much there are kind of different
levels to it. And where my mind goes with that is like, to go back to kind of the whole essence
of technology, right? I think one of the major, like one, I'd say even it's, it's driving force
is that within technology itself, its essence, it's not just that you're engineering tools,
but you're engineering desires. Because it reveals. It reveals, yeah, you're kind of,
and it's, that's a very deliberate thing, right? And that's the whole, that's the whole concept of,
that's not concept, the whole driving force of capitalism and social engineering, social
engineering or propaganda, right? Yeah, I mean, I mean, social engineering, ideology,
it's also kind of how like people like Balaji, they talk about a network state where
in the network state, we can create it where it's not top down planning, but it's bottom up
planning. But nonetheless, there still is an ideology that tells people what to do, which,
which communities. But it's like, that's, like, that's, that's technology. Oh, yeah, certainly.
Yeah, he, I mean, he is around technology. It's like that, to me, that is technology.
And you know, something interesting as, as I mean, I'm kind of braver, you know,
your line of thought that I'm sorry for, like, interrupting or breaking a lot of thought.
So tech name, here's where I really like Heidegger, because he plays these,
he's, man, he's brilliant. Like he's, his knowledge on language is unbelievable. Tech name
in ancient Greek was also used for art. So art was referred to as tech name and art is perhaps one
of the, you know, perhaps the typical example of something that reveals, right? Art reveals to
us, it reveals new realities, reveals truths. So what's really interesting is that word tech name
that was used for art, historically, especially in ancient Greece, is now used for, for technical
tools for technology. And I don't, I don't know what to make of it, but Heidegger thinks, oh,
he's like, okay, why is that? Just got a question, why that is? That's really,
Yeah, no, that's just a really good point. But then, yeah, though it becomes clear, right? It's
like, kind of propaganda is, is not part of it. It's like propaganda is almost like,
it is a reading air. It's like the breathing air for technology itself, right? Yeah,
it's not like a byproduct. No, no, no, it is it. It is the ideology is it. Yeah.
Yeah. Obviously, this very interesting layer as well, where to the whole worldview or essence
of technology where it's like, engineering, the engineering of desires. And obviously, that's
kind of its own, like we can run a whole separate discussion on it. Well, yeah, I mean, one thing
I want to do, in fact, one thing I want to do is, because I know we're going to do some book
discussions in the future, is to discuss, because I think, you know, this book here by Todd MacGowan,
Capitalism and Desire, you know, I've spoken about this a couple of times.
I mean, this book could easily be technology and desire, and the message of the book would
still stand. Because the two things go hand in hand that are tightly related.
Yeah, what was the, is there any insights from that book that relate to what we're
I mean, it's the idea of, the idea of desire is metanomic, that it desire desires for the sake
of desiring. And, and then the idea of object, we don't desire something that exists, it's a
virtual category. And then he connects that to our capitalism functions. But like, I haven't,
I need to like, prepare properly, if I'm gonna do like, I might do a pod that kind of it's on the book.
Oh, yeah, well, because I guess like the, you know, the accompanying idea there is like,
it's ruling by desires, right, like it's, it's to bring back the brave new world,
right, like, because what that contrast is, in a few centuries ago, Orwell wrote 1984.
And that was basically the ruling of a nation, whatever you call it, the ruling of people
via control and power, right. Totalitarian top down, basically. But then Huxley,
I think Huxley wrote Brave New World before Orwell actually wrote 1984. Oh, is that right? I think
Huxley, I think Huxley was right. I think Huxley was actually Orwell's lecturer, I think I got the
order right. And the very interesting thing is they had some correspondence between each other,
where basically Huxley disagreed with Orwell. So it was like great writing and whatnot. But
he thinks that, you know, at some point, the totalitarians of the 1984 idea will realize that
it's a lot more efficient to control people, my by means of desire alone, right. I mean,
we live more in and Huxley in reality than a Orwellian. Yeah, yeah. Well, it's like, it's,
it's powered by giving us what we want, basically. Or by, by, by creating false needs.
By giving us what we want, just enough. And that's the point that Todd McGovern makes,
like capitalism or capitalism works in the contradiction of it works by not working.
It gives us just enough. Yeah, even like, I think probably like Stalin and Mao even would be impressed.
Yeah, that kind of, like so much control can be. Yeah, yeah. I mean, what's interesting is, you know,
Rijek talks about having the Soviet Union, they always
allowed people a certain level of freedom. They always gave people, so you could make jokes
against the state, against the party. There was a certain level of, you know, kind of
unsaid humor. And that, that allowed people to, that, that, that's exactly how control works.
It's not this kind of the way Orwell imagined it. I think personally Orwell is a bit overrated.
This kind of where it's just tight. You can't say anything. You can't, you can't utter a word.
It's a complete censorship. No, no, no. It's by, it's kind of by teasing us with a bit of freedom
where kept in control, which is why I think we live more in a Huxley and reality than a
Orwellian reality. Hey, look, I don't know, pretty much what I've kind of wanted to discuss,
I think I've made the points, although I did say that I have, I'm a bit optimistic about all of this,
right, regardless of my cynicism. So shall we, shall we get there or are there any more points
you want to make? Yeah, yeah. Well, yeah, we can talk about optimism because I think
even though that's the kind of ruling, the ideology, happiness ideology, yeah, yeah, yeah.
Technology is going to save the world in, you know, but what Dostoevsky wrote, beauty will
save the world. I think the modern consensus is something more like technology, which obviously
for me, I side with beauty over technology. But okay, my, okay, I don't even know if this is
optimistic. All I'm saying is this, the way I view in the failure, there'll be something good that
comes out of it is, in fact, this is interestingly, the part I did with Dr. Grace Tapi, the Lacanian
psychoanalyst, she kind of put this thought in my head. But before that, I've also been thinking
about this a bit. I think given the fact that technology is doing what it's doing to us, it's
kind of taking us towards this hyper-reality or post-humans' reality, people are starting to have
these kinds of conversations. And I know this is like a very cliche thing to say, but people are
starting to question what is the human subject. People are, people are, people are delving more
into metaphysics and philosophy. And if you think about it, Stephen Hawking and his, he said that
philosophy is dead. For me, now philosophy is revivifying because we are, first of all, we are
seeing the drawbacks in science with quantum theory, all the... Artificial intelligence, people are
questioning... Yeah, yeah. So AI is, for me, the ultimate, the epitome of where it concludes, where
with AI now is where philosophy... Oh, certainly religion, philosophy, religion, and religion,
not at this kind of fundamentalist naive, but deep, platonic, neoplatonic, that sense of religion,
or mysticism, whatnot, because we're starting to ask questions about what is the human subject,
what's our relationship to reality? What is reality as such? And therefore, that's why,
you know, I believe with these, with the failures of our society, it creates way for
potential successes, but not, again, not successes or not good in the techno-optimist sense, where
it's kind of moved towards some kind of synthesis and everything's kind of work out. No, no. The
best way to approach this is to take the contradictions on and critique them and work through them
individually, do the hard work. It's suddenly true, because we're critiquing technology while
using technology. Yeah, I mean, look at this is the ultimate irony, right? This is the ultimate irony,
isn't it? Yeah. And, you know, we'll go one step further. You and I both are tech pros. We work in
tech. You work for a Web3 accelerator, which is the full front of technology. I'm a software engineer.
So, this is an example of that. Yeah, no, but yeah, we're actually full on tech pros.
Yeah, I mean, the problem with tech pros is, I would say tech bro-ism. It's, again, it's the
ideology and it's, again, it's not that you can step aside from ideology, but the problem is this kind
of, yeah, look, I'm going to say, despite this is going to sound very arrogant, but naive and
rather an infantile way of viewing technology without any depth. And again, the point I made
before, Heidegger wasn't a Luddite. He was full of science and technology. He makes the point, in
fact, towards the end of the essay that, but we need to start asking these questions about what is
technology and what's, what's its relationship to us as human subjects. And then again, what are human
subjects? And I think AI is allowing us to really have those conversations, which is why AI is an
interdisciplinary field, you know? So, for me, that's kind of where the bit of the optimism comes
and although I'm very careful when it comes to optimism, because again, it's a prevalent ideology
of our day. So I'd rather be cynical and pessimistic. I think you're right. And that's, yeah, that's a
very important thing to make clear, right? It's like Heidegger wasn't against technology, right?
It's like Heidegger, I think you could say Heidegger was against the mode of being that kind of
encompassed technologies, like kind of, let's be aware of that. But it's what Heidegger is not
saying is like, do away with technology, become an aesthetic, right? And just, yeah, yeah. Although
he kind of was like an aesthetic, he lived in a heart most of his life. Oh, right. I didn't know
that. Yeah, look, he's a Nazi weird guy. Honestly, Heidegger personally, he wouldn't want to be him,
but take his, take his philosophy, you know? Yeah, yeah, yeah. But yeah, obviously, I think there
is reason to be optimistic, right? Like, as you say, and even from our like, what we're doing now,
this is enabled by technology, right? Like the fact that I can have this conversation,
like remotely, and that we can put it up and we can, like it's scalable, right? Like people can
watch it from wherever they want. And whenever, right, that's something, right? That's not something
that we could do. We talk a lot, we might romanticize pre-modernity and like this analysis.
Yeah, yeah, yeah. I romanticize certain parts of it. But if you ask from me, what's the best
time to be alive? It's now. Yeah, yeah, yeah. I agree. I agree. And so like right now, we're a
lot more technologically enabled than we were before. We have like extract, we have machines
everywhere we look, right? We can do a lot more than we once did. And that gives a lot of like
power in terms of ideas such as this, right? Like it means that we can discuss ideas such as this
and like have much more reach. And other people can discuss ideas like this and have much more
reach. And so like that's the reason to be optimistic within the information age, I suppose.
You and I think you misunderstood me there. My point wasn't even the functionalist pragmatic
point. That is true. That I agree with you, certainly. But mine was more, I was still
working on the level of the metaphysics of technology. So given we're doing this
metaphysical analysis and we've technologies reveal these things to us about being as such,
what I'm saying is because technology does that, that allows us to look at, I'll put it this way.
Let's say all of these tools, modern technology, whatever the zoom, all these things want that
they didn't exist. But technology, the metaphysics of technology was still there.
That's a bad way of putting it. What I'm trying to say is it's not the, I'm not trying to make
and it's not the instances or it's not this mic or zoom or the internet or whatnot. What I'm saying
is what, what technology reveals metaphysically, that itself allows us to have a conversation
about what the human subject is. If you could say it's kind of like, like Christianity technology
allows itself to be questioned and doubted. Yes. Yes. In fact, yes. The Nietzschean point
That's the Nietzschean point about Christianity. Yeah. Yeah. So that's kind of the point
I'm trying to make. I mean, of course, these things are great, but by what technology reveals,
we start having these questions on being as such ontologically, ontological questions.
But not man. Yeah. And that's, I think I kind of exhausted everything I had to say. Anything
else you want to add? I think I got the main points too. But like, I always find it interesting,
like even a line of thought that my mind is heading to right now is, you know, even though
we're so much more technologically enable now, we can do a lot more. We've got power.
It's all, you know, an interesting questionable sort of power, right? Perhaps it's a good way to
kind of conclude. And I think there's a certain element. There's a certain element to human existence
that's, I haven't quite figured this out, but it's the element of purity, right? Like with
the purity of being human, the purity of engaging with nature, there's a purity of engaging with
fellow humans, and somehow technology defiles that. And if we already discussed, we've already
discussed how that looks like, right? But I do wonder if there's a kind of, you know, ideal state
between an ideal relation between man, nature, and, you know, other people in which technology
can be a part of the picture. That's probably a crucial, one of the crucial questions that we have
to ask, right, these days. But not one, it's not one that I have, you know, a proper answer to.
It's like, there are many different ways to approach it. And it's kind of like, I don't know,
do you want to lean into it? You know, do you want to become a techno futurist and like reinvent how
everyone does things? There's something there. Do you want to become, you know, a primitive, you
know, like, like, go and retreat into nature and like, you know, like, yeah, like, yeah, like,
there's also something there. So yeah, they are not co-primitivists. I'm not a fan of it. Yeah.
Well, I mean, I guess we both want to conclude by do what Heidegger did and ask the question
concerning technology. Yeah. And let the answer be, you know,
let your answer be a truth for you, as Kierkegaard would say. Yes. And make it a truth that shakes
you. Because the Kierkegaardian truths are always the kind of truths that uproot you. And that's
important.
