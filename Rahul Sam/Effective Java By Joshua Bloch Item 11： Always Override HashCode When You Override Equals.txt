Hey everyone, welcome to yet another episode of my video series on Joshua Block's effective Java
and today we're gonna cover item number 11, always override hash code when you override equals.
But of course, before I get to the item as I usually do in the series, I want to go through
this proviso and make a few points. Starting off, this is not a tutorial. I'm not a teacher,
nor am I certainly an expert in Java or object-oriented programming in general. So please
don't take what I say as gospel's truth. Always double check, do your own research. This is simply
me sharing my learning experience. That's purely it. So don't treat this video series like a tutorial.
I may spew or give out false information, unfortunately, though I will try not to.
Think of it more as the blind, leading the blind, that's an analogy that I've been using
for a while now. I am as blind or perhaps even more blind than you are. So this is merely a
exploratory disquisition. I'm just figuring this thing out and hopefully we can learn together.
In fact, I've already been corrected in a few of my other videos and I've been trying to rectify
those errors. Therefore, again, not to repeat the same point, I will inevitably make mistakes.
So please do point them out more for the benefit of the videos than myself. But yes, of course,
for the benefit of myself too, selfish speaking. And given this is a, in fact,
programming video series, all the code that I used that I've been using for all the previous
items that you can see here, it's all available on my GitHub repo. I'll leave a link to the code for
today's item, item number 11 to my repo, but also to Joshua Block's sort of
official repo that he has for this book. Saying that without further ado, let's get started.
So yeah, as I said, item number 11, which is always override hash code when you override equals.
And the item starts off like this. Joshua Block states, you must override hash code in every
class that overrides equals. If you fail to do so, your class will violate the general contract
for hash code, which will prevent it from functioning properly in collections such as
hash map and hash set. But before we continue on with the item, let's get some key phrases or key
terms out of the way, get some definitions out of the way. So what is hash code? And who better to
ask than chat GPT and oh, I forgot to mention this item is a part of chapter three methods
common to all objects. So back to it. What is hash code? Chat GPT states, and I think it's accurate
here because I did double check with a few other resources or definitions online. In computing,
a hash code also called a hash value, hash sum, check sum or simply a hash is a fixed array,
sorry, is a fixed size string of characters that is generated by a one way mathematical function
called a hash function. From an input of any size, often call the message. The resulting
hash code is typically a hexadecimal number that is a unique representation of the input.
The main purpose of a hash code is to take an input and produce a fixed size string
of characters that can be used to identify or verify the input. Hash codes are commonly used
in data structures such as hash tables or as Joseph Locke stated, hash maps and hash sets
and in various algorithms such as message, sorry, such as message authentication codes,
digital signatures and check sums. Oh, this is an important point regarding hash functions.
Hash functions are designed to be one way and deterministic, meaning that the same input will
always produce, let me zoom in a bit actually, meaning that the same input will always produce
the same output, but it is computationally infeasible to determine the original input from the output.
And then more in the context of Java, I got this definition from educative.io when the
hash code, which is the hash code method is called on two separate objects which are equal
according to the equals method. So by the way, we discussed the equals method in the previous
items. If you want to understand, get a, in fact, a really deep understanding of the equals method,
I suggest or recommend you watch all four parts for item number 10 because it was such a big item,
I had to break it down into four different videos, but in that I delved deeply into the
equals method. In that case, getting back to this, which is called on two separate objects,
it returns the same hash code value. However, if it is called on two unequal objects,
it will not necessarily return different integer values. So that's the definition in the context
of Java. So to get started, here's a really simple straightforward class as to how the
hash code is used, example courtesy of educative.io of course. So there's a class called hash,
declared two strings, and keep in mind that these strings are immutable. And if a equals b,
this function will indicate that object a is equal to object b. And it's important to keep
in mind if there's logical equality between two objects, if the hash code wasn't overwritten,
then unfortunately, we would get two different hash codes for these two objects
that have logical equality. And that in fact is a anti-pattern or a violation of the hash
code contract. And that's what we're trying to demonstrate here. So also if it's not equal here,
it'll say that it's not equal. So if I run this, you'll see that a is equal to b and c is not equal
to d. So we have the equal variables. And then we have, let me zoom in a bit.
We have the equal variables and the unequal variables. And you can clearly see in the equal
variables, because the string class follows the hash code contract, the hash code is the same.
And for unequal variables, there are different hash codes. So that's good. That means the string
class has overwritten the hash code method. Speaking of the hash code contract, what does
that mean? What is the hash code contract? As we saw from the demo, if two objects have
logical equality, if there's an invocation of the hash code method, it should always consistently
return the same value, whatever it may be. Although a caveat is it can differ depending
on the application state, but that too should be considered when designing the hash code method
or to put in a bit more clear way, let's say, using chatGPT. For example, if you have an object
that has a unique ID that is generated when the object is created, the hash code method
could use this ID as a part of its calculation. Because the ID is unique to each instance of
the object, the hash code method would return a unique value for each object. However, if the
application is run again, the ID may not be the same. And thus, the hash code method would return
a different value. This is the example that chatGPT gave me when I asked to give an example,
let's say in the real world, of how the hash code would differ depending on the application state.
So that kind of makes sense because it's kind of depending on this kind of external resource,
which is the unique ID in this case. And of course, this seems like an obvious point,
but it has to be stated. If they don't have logical equality, then it would probably give
different hash codes when the hash code method is indicated. However, that also does not mean
or is there's no requirement that it should produce distinct results. Despite two objects
not having logical equality, it's possible for it to return the same hash code. Though the vice
versa, the opposite of that would be if they do have logical equality, then most certainly the
hash code should be the same. Or put more succinctly, logical inequality doesn't necessarily mean
objects will have different hash codes. However, as I've said it here, if hash code,
the implication of the method hash code does return distinct integers for objects,
this will improve performance in hash based collections as this will reduce collisions.
Because there could be collisions if while they don't have logical equality,
it still returns the same hash code. So if we can design a good quality hash code method,
that will even try and prevent this where we know for sure that two logically
unequal objects will always have distinct hash codes. It will reduce these collisions.
And the collection, so whatever the collection that's using a hash based collection won't have
to look for logical equality prior to putting an object in a location or a hash bucket to be more
specific. Now what I mean by this latter point, putting it into a location in a hash based
data structure, it'll make more sense as we go through the demos, but the idea is
in a hash map or hash table or whatever hash based data structure, when we give it objects,
it'll look for, it will do the calculation and get the hash code, and then it'll put it in a
specific hash bucket depending on the hash code, but also it will look for logical equality.
It'll look for logical equality because if there is logical equality, then without doing
any more calculations, it could straight away put it in the specific hash bucket.
The thing though is, I believe, and I think it works this way, it'll also create a kind of
link list if these objects have the same hash bucket. So it'll compare,
actually on second thought, I may be talking out of my arse here, so I'm just going to shut
up and keep going and not try and make that point with such certainty. The point being,
generally considering both logical equality and inequality, it's perhaps a good idea to reduce
collisions, just take that as a general rule of thumb, let's say. Sorry man, I've been thinking
out loud here and I don't know, sometimes when you think out loud, you clearly do say bullshit,
and I apologize if I did say something false there. Okay, so to clean up my mess and to not
keep digging myself into this hole, I'm just going to go read off the book as that in fact is a
good source of truth. On the point that I was trying to articulate here, here's what Joshua
Block states. The key provision that is violated when you fail to override hash code is the second
one. Equal objects must have equal hash codes, that's a really important point. Two distinct
instances may be logically equal according to a class's equals method, but to objects
hash code method, they're just two objects with nothing much in common. And of course,
therefore, objects hash code method returns to seemingly random numbers instead of two equal
numbers as required by the hash code contract, which we discussed just here. So the idea of
logical equality giving the same hash code for hash code method invocation can be simply
demoed with this phone number class that Joshua Block in fact has used. And this class was also
used in item 10, I believe. We have a class called phone number that represents a phone number with
an error code, a prefix and a line number. So if we go to the main method in this class,
I've created an instance of, well, I've got a hash map here, sorry. And this hash map has
a key values of phone number and then a string, which is a phone number.
If I put a new phone number object with the name Jenny into this hash map, what I'd expect is,
as you can see here, I'm creating a new phone number object and I'm putting it in. Now, this
hash map, because it's a hash based data structure, it's going to use the hash code of this object
to find the location in the map to put this object, the key and the value. So there's going
to be the key with the hash code and the value is going to be Jenny. And it'll do that based on the
hash code of this object, as I said, like 10 times already. Then in the next line, I'm trying to get
that same value Jenny from the hash map. So what I'm doing is I'm saying m.get. So that's the hash
map. And I'm saying, hey, here's the key, give me that value. But unfortunately, because we haven't
overwritten the hash code method, when this code is run, it returns a null. Because what happens
is in the get, it'll create a different hash code, a new hash code, and you look for it in the
hash map, and it can't find it, so it'll return null. Despite both of these objects,
this one here, and this one here clearly having logical equality because they've got the same
error code, prefix and line number. Now, simply the way to fix it is to override the hash code,
which we've done here. I'll go through all of this stuff a bit later, much more punctiliously.
But at the moment, just assume it has been overwritten to reflect logical equality.
And now what'll happen is the same bit of code that I'm going to run, it'll return Jenny. There
you go. Which is good because that's what we want. Because that means the hash base collection
identified that we're in fact looking for this, the same object. Or as Joshua Block states,
the phone number classes failure to override hash code causes the two equal instances to have
unequal hash codes, which is why initially before the overwritten in the retrieval, we got a null.
In violation of the hash code contract. Therefore, the get method is likely, so I'll leave it in
the code because it makes more sense than that. That's the get method. Therefore, the get method
is likely to look for the phone number in a different hash bucket from the one in which it
was stored by the put method. Even if the two instances happen to hash to the same bucket,
the get method will almost certainly return null because hash map has an optimization that
caches the hash code associated with each entry and doesn't bother checking for object equality
if the hash codes don't match. This kind of relates to the previous point that I tried to
terribly articulate using a bloody link list and all that. But the idea is that the idea is that
if they do have a hash codes that don't match, it's because the value is cash, it'll just return
the cash value. In this case, a null. Now fixing the problem would be overriding the hash code
method. The example I showed here is, in fact, this is a good way of overriding it. But the worst
way, despite it being legal, would be to simply return the same value returning 42 here. One
should never do this because in this case, for every single value, it's going to return the same
hash code and that is that is hell. Or instead of invoking biblical references to put it the way
Joshua Block would, it's legal because it ensures that equal objects have the same hash code.
It's atrocious because it ensures that every object, in fact, has the same hash code. And
that shouldn't be the case. Therefore, every object hashes to the same bucket and hash tables
degenerate to link lists. Ah, this was the point I was trying to make before. And I kind of confused
the both, confused the two. And then he said it's programs that should run in linear time instead
running quadratic time. So just to get a bit of that computer science out of the way, I wouldn't
say out of the way, it's in fact quite interesting. This is quite important to understand when it
comes to designing algorithms, the difference between linear time and quadratic time. In linear time,
the number of steps required is directly related one to one. So big O of n. So it's a number of
elements, let's say in a data structure. So if it's in an array, it's the number of elements in
that array. If the array is of size five, big O of it would be big O five here. In quadratic time,
the number of steps is taken to accomplish a task is n squared because each item has to
be compared with with each other. Now, because I'm partially retarded, I had to tell
Judge GPT to explain this to me like I was Michael Scott from the office. Because in many ways,
I embody that archetype. Yes, Michael Scott is an archetype, in fact. And I asked from,
sorry about that, a bit of background noise, let the plane pass. It's passing. And it's passed.
Excellent. So I told Judge GPT, explain linear time versus quadratic time in computing,
like Michael Scott from the office. And here's what Judge GPT told me. And in fact, this is really
good. This is a really good explanation. Sure. Let's imagine you're trying to find a specific
paperclip, haha, office reference, because you know, it's a paper company, find a specific paperclip
in a huge pile of paperclips. If you use a linear time algorithm, it's like you're checking each
paperclip one by one in a line, which is why it's called linear, I guess, until you find the one
you're looking for. It takes a little longer with more paperclips. But the time it takes to search
for the paperclips grow at a steady pace, just like a straight line. So it's, would it be called
exponential? No, it's, it's correlated to the, to the amount of paperclips or simply put big O of N.
But if you use quadratic time algorithm or a quadratic time algorithm, it's like you're
checking each paperclip against every other paperclip in the pile over and over again,
as the number of paperclips grows. The amount of time it takes to search for one,
you're looking for growth at an exponential, right? So sorry, just to keep in mind, quadratic
time is exponential, like a big square. So linear time is like searching through a line of paperclips
while quadratic time is like searching through a pile of paperclips. The former is faster and
more efficient as the number of paperclips grows. So it's because of that reason, a good hash function,
leaving aside the legality, so to speak, should produce distinct hash codes for unequal instances
to prevent this, this mess of linear time and quadratic, quadratic time when putting into a
hash-based data structure. Or as put in the book, this is exactly what is meant by the third part
of the hash code contract. Ideally, a hash function should distribute any reasonable
collection of unequal instances uniformly across all int values. And I kind of wanted to
a more elaborated definition of this. So, of course, I once again asked Czech GPT
and it said, for example, if the hash function returns integers, it should distribute the hash
values evenly across the possible integer value. So the hash function is applied to 10 unequal
objects. The hash values produced for those objects should be spread across all the possible
integer values, not just a small range of values. This helps to ensure efficient hash-based data
structures, such as hash tables, where hash collision should be kept to a minimum. Now,
all of this explained here, this is, I think it kind of seems not self-evident, but after this
explanation, it seems to make sense. It's about uniformity. It should be spread across uniformly,
depending on the int number of values you give it. But how do we achieve this? Because that's
the ideal, and it can be a bit tricky at first glance, but fortunately, Joshua Bloch has stated
there's a recipe for it. There's a recipe for a high-quality hash function. So I don't want to
send this hash function. Firstly, let's go through the theory step by step, and then I'll jump into
the demo, and it'll obviously make a lot more sense when you see the actual code. Step number one
is to declare an int variable called result, and simply assign the value of the first significant
field into this result variable. And keep in mind, as Joshua Bloch has stated here,
recall from item 10 that a significant field is a field that affects equals comparison. So whatever
it may be, assign that to this variable value. Obviously, I screwed that up. I re-read that a
couple of times, and I made a blunder. I made a huge error there. You don't assign the value of the
first significant field. You assign the hash code value of the first significant field. That is a
bad mistake, because that can truly screw up the whole recipe. So keep in mind, whatever the first
significant field is, you calculate the hash code, and you assign that to the result here.
And then step number two, for every other remaining significant field F in your object,
do the following. Compute int, the int value, hash code C, so all the other fields. If the field is
of primitive type, so that could be an int, a char, whatever, use a box primitive, and then
use that and sort of like what I described here. So there's a primitive field, 42 here, primitive
int, use the box int and use value of, and then use the box primitive hash code method to calculate
the hash code value, because the primitive type won't have a way to calculate the hash code method.
So obviously, each primitive type in Java will have a corresponding box primitive,
like here, where int has integer. So the second part of that is that it's important to consider
how the equals method compares field values. What I mean by that is, if the equals method
recursively invokes equals on the object reference fields, then the hash code method should recursively
invoke hash code on those fields. So in an object, whatever the fields that the equals method invokes
equals to, the hash code method should do the same. I will put this way. What I realized
when I was going through this item, or more specifically, this recipe for the hash function
is that a lot of the things that the equals method does, the hash code method should do too,
or a lot of the patterns that it follows, that the equals method does or follows,
the hash code method should follow too. So the second part of that is if the equals method
requires a more complex comparison for the object reference field, the hash code method
should compute a canonical representation for the field and invoke hash code on that representation.
So what does this mean? We discussed canonical representation in item 10.
As the name suggests, it's a canonical value. So if there's a certain field value
in the object that's proved to change, that is rather dynamic, for the sake of comparison,
or in this case, for the sake of calculating the hash code, we could assign
a sort of static variable value that we consider to be the canonical representation
of that field. And that can be used for all the computation and all the calculations of the equals
method calculations, but also in the hash code method. That makes it gives our methods a bit
more structure for object fields that have rather dynamic and volatile. And I don't mean
volatile in the Java sense. I mean volatile just conceptually speaking, significant fields in an
object. And the third part is if the value of the field is null, obviously, the hash code method
should use a constant value such as zero to represent the hash code for the field. That seems
pretty self-explanatory because given that this result variable that we're using is an integer,
is of type int, we need something to correspond to a null where zero probably would be the apt
value to use. And if the field is an array, with all fields of the array being significant,
use arrays or hash code. So we can use this method from the arrays class in the library.
Or as Joshua Booker said it here, if the field is an array, compute a hash code for each
significant element by applying these rules recursively and combine the values per step to be.
So per step to be is the next step. We'll get to that too. If the array has no significant
elements, use a constant preferably not zero. That makes sense because zero would normally
be used for something like a null. We don't want to have that kind of conflict or confusion.
And then step to be of course is to all the values that we used here, that we computed here, sorry,
combine them to get the hash code where we have the result value multiplied by 31 plus c. And
what's c? It is the computed hash code value. And then you return result in the hash code function.
This will all make sense once we look at the demo. In this demo, I've got a class called person.
And this person class has some significant fields. Their first name, type string, last name,
type string, and address. And the address is a class that I've defined in this file, in fact.
And the address essentially has a street, city, state, and zip code. So the address is of
address, as you can see clearly. And then we've got the age, which is of primitive type int.
And also we have a string array, which I've called language is spoken. So the language
is this person speaks. And then we've got the constructor. And the equals method also I've
overridden. I'm not going to go through that because it's kind of on a scope. And I kind of went
through this already in the previous item. And then we've overridden the hash code. So this
hash code theoretically should be a high quality hash function or a hash code method,
because I've followed the recipe delineated in just your blog's book or in effective Java.
Initially, the result as we saw in step one has been arbitrary number 17 has been picked
as a constant. This will reduce collisions. Keep in mind, don't pick a number like zero,
start off with something like this. And then we've used the significant fields to calculate
the result using the hash code, hash codes, and then adding that to the result value.
And again, multiplying by 31, this again is to give it give it more uniqueness or more,
more, more distinctiveness and preventing collisions. And then in the address, we've done
it a bit differently where we're in fact looking for the hash value of the address object. And if
it has been cached, or pardon me, if it if it's now, then we get a canonical address value.
And if it is now, then we're gonna return zero. So we're gonna want to make sure that the address
is not now, and that this person has an object. And so we get canonical, the canonical address,
which by the way, this method is defined in the address class. So back to this.
And then we are also given that the age is of type int, it's a primitive type,
we're using the box primitives. Sorry, yeah, box primitives and using the value off and getting
the hash code. And then for languages spoken, because the string array, we're using array
sort hash code, again, as stated in the hash function recipe. And then simply we return
that result. So here's an example, the client using that class, we use Alha Camus, my one of my
favorite essentialist authors, highly recommend you read him, start off probably with the stranger.
And then if you're more philosophically inclined, perhaps the myth of Sisyphus, I love the stranger
so much that I, in fact, I'm trying to learn French, just because of Camus. It's a beautiful book.
So the language is Camus speaks, I found out in fact, he speaks Arabic too. So it's English,
French and Arabic. And then they're giving his address, I just randomly found this online,
not even sure if this is accurate, but this is probably where he lived. And unfortunately,
he only lived to an age of four to six years because he died in a car crash, which is quite a
tragedy, given I would have loved to read more of his work if he didn't live up to old age.
And then when you run this function, it calculates the hash code for the Albert Camus,
Albert Camus object. And then Joshua Block states, when you are finished writing the
hash code method, ask yourself whether equal instances have equal hash codes. And then he
states to use unit tests and whatnot to figure that out. Now, I haven't written unit tests for
this, but clearly the way this client has used it, this can be converted to unit tests and used
in a variety of ways. And then obviously, if equal instances have unequal hash codes,
figure out why and fix the damn problem. He doesn't say damn, I just put it in there because
why not? He's a nice guy. So that begs the question, or perhaps it doesn't, but at least it begs the
question for me, what to exclude from the hash code computation? That's the typo that's on hash
code, hash code computation. And he states you could in fact exclude so-called derived fields.
And let's understand what they are before we get to the demo. Those are values that can be computed
from other field values already in the hash code computation. So we did go through this idea of
derived fields before in the, in item 10, I believe using a Pentagon or some mathematical structure.
But let's take a look at another demo. I think it was a polygon we used in item 10. And I didn't
want to use that example here because, you know, firstly, my math is shit. I'm quite embarrassed
about that. Therefore, I found it a bit hard to explain using the polygon class example.
That's something I should work towards. And in fact, teach myself some mathematics,
some basic mathematics at least. But this is way more straightforward. So what's the derived field?
We have a full name. And obviously, a full name can be derived off the first name and the last name.
And in the hash code, we don't have to, when calculating the
hash code, we don't have to use the full name in the hash code calculation, given that it's already
derived from first name and last name. That's it. That's what a derived field is. And that could be
excluded in a hash code method. Okay, so this next part, the order of the fields. And the point is
that the quality of the hash code method is contingent on the order of the fields
if a given class has similar fields. Now, to be totally upfront, I found this part
quite difficult to understand. So I'm going to try my best to try and explain this. I think I got it,
but I think I'm going to struggle a bit to articulate it because it's not
intuitively, it's hard to get it on first glance. It requires a bit of thinking. So the reason for
this is because of 2B. That is this calculation we make here. This is the reason that makes the
ordering contingent for the hash code method. So Drusselberg states, for example, if the
multiplication were emitted from a string hash function, all anagrams would have identical
hash codes. The value 31 was chosen because it is an odd prime. If it were even and the
multiplication overflowed, information would be lost because multiplication by 2 is equivalent to
shifting. Another way to think about that is that this multiplication here, 31 times i, that can be
replaced by the shifting of the sum or the left shift operator in Java. As far as Java is concerned,
that and that are mathematically equivalent. Now, we'll get to the definition a bit later,
but firstly, let's take a look at some demos. So in this example, and this is a bad example
where the order hasn't been considered. If you run this, there's a possibility that these two hash
codes, so for object A and object B, which are two anagrams, that the hash code could be the same
because all they're doing in the hash code method, if you can see here, is we're simply
returning the hash code of the string value. So we're just using the hash code method in
the class string. We aren't really considering anything else apart from that. In fact, I don't
even know why the overridden mistake in place here, it's like this is a superfluous or unnecessary
method. And even though I ran this a couple of times and this is why I said it depends on the
application state, it is possible theoretically for this to return the same hash code despite
these two being different. And then here we are in fact multiplying by 31 and we are even having
this arbitrary value initially. The chance of these hash code values being the same is a lot
more different in comparison to the previous example that I showed in the other class. Both
classes are called anagrams, that's a bit confusing, but they're in different directories or yeah,
the packages are different. So that's because we have modified that a bit in hash code.
This is a bad example. I only put this in here because it kind of goes along with
what Joshua Block had stated in the book. I in fact thought using a separate class called person
would be better to understand this. The reason I use anagram is because that's the example that
he's used. But frankly, as you can see, so I didn't really get it much. So maybe you would try not
to stand it with the person class. I put that other part in there just to stick with what's in the
book. And I thought that'll help in some way. Given he said if the multiplication were omitted
from a string hash function, all anagrams would have identical hash codes. Ah, I now seek my confusion.
He did say if the multiplication were omitted from a string hash function. So the reason we're
getting different ones here is because in fact in the string hash function, it wasn't omitted.
If it wasn't, if it was kind of like this, just simply returning it, it could have been the same.
But in the string hash function, if you look at the hash function, there is some multiplication
being done. There's some work being done here. I'm not going to take a look at it. It's a bit
too complicated for me, but it's not just simply passing, taking that value in and passing the
hash code. So anagrams themselves would have different hash codes, which is great. Apologies
about that. I should have gone through that a bit more carefully beforehand, but it kind of makes
sense now what he's trying to say here. And then the part I was trying to explain before about
these two statements being mathematically equivalent. Joshua Bock states a nice property of 31 is that
the multiplication can be replaced by a shift and a subtraction for better performance on some
architectures, because as I said, these two are equal, mathematically speaking. And modern VMs
do this sort of optimization automatically. I perhaps did a terrible job at explaining that
because I too am trying to understand this idea of the shifting operator and all that.
So I asked JudgeGPD and I think this is much more clearer than what I could ever say.
Here's what JudgeGPD states regarding this. The double listed operator is the left shift operator
in Java, which shifts the bits of an integer to the left by a specified number of positions,
effectively multiplying by 2 to the power n, where n is the number of positions shifted.
That's why it's shifting. The minus operator is the subtraction operator, which subtracts the
second operand from the first. So the expression I double less than 5 minus I shifts the bits of
I to the left by 5 positions, effectively multiplying it by 2 to the power of 5 or 32,
and then subtracts I from the result. Since 32 minus 1 equals 31, the expression is equivalent
to 31 times I. That's what it's this bit that gives this equality that Joshua Bloch speaks of.
By using the optimization, the hash function implementation can take advantage of the
efficient left shift operation on some architectures potentially leading to improved performance,
and also JudgeGPD repeats what he stated. Modern virtual machines are designed to automatically
perform this kind of optimization, so the hash function implementation can remain unchanged
and still benefit from the performance improvement. So a simple example of this would be if I ran
this code, j would be equal to k. It'll print true because both these are equal. They both will be
310. And then let's take a look at another demo. I think we already kind of took a look at this,
sorry by the way, not related to this, is separate because Joshua Bloch states,
say all that, let's apply this previous recipe to the phone number class. Now I already did apply
and show the demo in my own way, but it's important to take a look at what Joshua Bloch has done too.
Here's the demo. As we saw, it returns the hash code of the initial value area code that he
said, says he said to take the first significant field and assign the hash code value to result,
and then do the calculation accordingly. And that returns the result. And on this method,
he states, because this method returns the result of a simple deterministic computation,
whose only inputs are the three significant fields in a phone number instance, that is area code,
prefix and line number, is clear that that equal phone number instances have equal hash codes.
It is simple, is reasonably fast, and does a reasonable job of dispersing unequal numbers
into different hash buckets. And of course, a bit of a caveat here, as we saw in item 10,
when it comes to equals comparison, even in the hash codes, he stated, if you have a bona fide
need for hash functions, less likely to produce collisions, see Guava's core Java library,
which is Google's core libraries for Java, and the hashing there, does it much better than you
and I ever could. And he's continued by giving a much more simpler one line hash function, which
you'll see here. Comment are the other one. So these are all hash functions, there's different
ways of implementing them. He's given three separate examples. The third one will go through soon.
This is a one line hash function using the objects dot hash. The caveat here, despite it being a one
line hash function, as it should only be used if performance isn't critical, because it does return
an array. And every time it's involved, it returns an array and also involves auto boxing, if we do
pass a primitive type. And that takes us to an interesting part in these hash code implementations,
which is thread safe, lazy initialization. So lazy initialization can be used if you believe
your class is immutable. And if it considers, oh, not considers, it involves the invocation of a
hash code involves recalculating the hash code every time it's requested. And he says, if you
believe that most objects of this type will be used as hash keys, then you should calculate the
hash code when the instance is created. Otherwise, you might choose to lazily initialize the hash
code the first time hash code is involved. Some care is required to ensure that the class remains
thread safe in the presence of a lazily initialized field. Now we shall look into that because
creating it to be thread safe is, in fact, an important, not even a national report here, but
it's, in fact, very much related to this idea of lazy initialization. But before we look at the
thread safety example, let's firstly look at the phone number example. And the phone number class
doesn't require this kind of thread safety. He's even stated that in the book. And what is
lazy initialization? It's quite simple, really. We have a private in hash code method. And we check
if the result is zero. If there is no cash result, we directly return that result. So that means
every time the hash code method is invoked, it doesn't have to go through this bit and do the
computation slash calculation. If it's cashed, it could just be it could just be returned. And
that's what lazy initialization is. And this is automatically initialized zero initially.
So as I've said here in the comment, apt for immutable classes with expensive hash code
calculation. Okay, now let's get to the thread safety bit, which is, in fact, despite it being a
bit complicated at first, I found most interesting in this item. I kind of enjoyed it, especially
because I'm, I kind of do enjoy that part of Java, the whole multi-threading bit in Java.
So here's an example of lazy initialization with with thread safety. So we have this class called
Kana. And Kana holds, it's an, this class is atomic as we're using the atomic integer method. So
atomic means and competing atomic means either the change happens or it doesn't happen. I always
understood atomic operations in the context of a database. So a good example is something like a
bank transaction. You either want the money to go go through, or you don't want it to go through at all.
It's very binary in that sense, no pun intended. And that's what an atomic computation is. There's
no, there's no murky territory. There's no half of the computation happening. So we're using the
count of type atomic integer. And then we have, we have another hash code value here, a field value
of also atomic integer. We have the constructors, whatnot. We're setting the count, getting the
count, forget about all that, not forget about all that, ignore all that for this context.
And then we have the hash code method. And the hash code method, remember, all of this is still
using the atomic integer. And here, though the hash code is computed lazily, it's still the same
thing that we saw in the phone number class, where we're checking if the value is there,
checking if the value is equal to zero, only if it's equal to zero, where we're setting the value
and passing it, we're setting the value and then returning it. If not, if it's not equal to zero,
that means the value has been cached. So we just returned that value straight away.
So that's the lazy initialization bit. But now we get to the thread safety bit,
the multithreading bit. So I've started two threads here, T1, T2, and they're both,
they've both got two counters. So firstly, I've got an instance of counter called counter, of
course. In the constructor, I've initialized that bit 10. And then I've created two threads
that sets the count, that changes the count concurrently. So two threads are started. So here,
since we've used T1.join and T2.join, because of the use of this join method,
only the final state of the counter, that's this one here, this object, will be used,
in this case, forget count, but for anything else, because the main thread waits for both
child threads to finish execution. So there are two threads spun up and there's a main thread,
of course, that'll wait until both threads finish execution by using join. And since the atomic
integer has been used, the value will either be 15 or 20. It's atomic, because the type for
for the hash code is atomic. And 15 and 20, of course, comes from this set count that we used
here. So depending on which thread finishes first, it'll always be the final state will be
reflected. So if I maybe write a couple of times, this time it came final count. And so the final
count is, so the final count is 20. And the hash code also comes as 20. But I think that's
because the value is cached here. So if I run that a couple of times, let's see if at one point,
it's always the second thread that finishes last. So it's passing that value. But let's say I change
this, I don't know, I multiply this by 21, for some reason. And I write it again. In this case,
the hash code value will change. And then if I write it again, now it's going to keep returning
that because that value is cached. And the point being, because we're using type atomic integer,
these operations will be atomic. And this is what Joshua work means by creating lazy initialization
to work with with threat safety. So in this case, really, this bit doesn't matter too much. What
matters is when we declare the hash code value, we use a type of atomic integer that that ensures
its threat safe. So a few caveats here, the hash code initialization field value should not be the
hash code of a commonly created instance. So that initial value we set for the hash code calculation.
This is not a good example. If we go back to the phone number class, this initial value we set,
it shouldn't be the hash code of a of a value that's commonly created, pardon me, not a commonly
created value a commonly created instance or some kind of object that's used quite a lot. So that
initialization value, because that would obviously defeat the purpose of a caching as it'll constantly
be changing. And the other thing, and this is really important, like what Don Knuth stated, oh,
it wasn't Don Knuth, wasn't it? It's apocryphally attributed to Don Knuth, but the root of optimization.
Sorry, I'd push it back. The root of all evil is premature optimization. So always choose
accuracy over optimization. And the point is poor quality hash functions that are inaccurate
will degrade hash table to the point of being unusable. It's kind of connected to that previous
point where we just set one constant value that legally makes sense, but would make a
terrible hash function. So the Schubert states, do not be tempted to exclude significant fields
from the hash code computation to improve performance. So always pick accuracy of optimization,
especially with modern CPUs these days. Like why would you, well, why would you? It makes more
sense to focus on accuracy because, because there's pretty much infinite compute in the modern world.
Or as he's put it here, in particular, the hash function may be confronted with a
large collection of instances that differ mainly in regions that you've chosen to ignore. If this
happens, the hash function will map all these instances to a few hash codes and programs that
should run in linear time, which will, sorry, I push it that. If this happens, the hash function
will map all these instances to a few hash codes and programs that should run in linear time will
instead run in quadratic time. So if we take this class example, this is a poor, this is an example
of a poor implementation of the hash code. Last name in this person class, did I say class example?
If we take this person class example, last name of this class is a significant field, obviously,
but in the hash code, you've ignored it. Now, what, what that would do is to put it more clearly,
I use Treasury PD because I couldn't, I struggled to articulate that. If we treat, create a large
collection of person objects, so from this class, that differ mainly in their last name field. So
this field that we've ignored, the hash function implemented in the person class will be of poor
quality and the hash based data structure, so like a hash map, that use it will experience many
collisions. This can lead to poor performance and even cause programs that should run in
linear time to run in quadratic time, as the book suggests. So I'll propose ignoring significant
fields like what we've seen here. One example, just a book has given, like a real will implementation
is prior to Java 2, the string hash function in fact used at most 16 evenly spread characters to
calculate the hash code. However, unfortunately, any string with more than 16 characters,
as he said here, things such as URLs, would give a low quality hash function or a poorly,
a poor hash function essentially, as the name suggests. And that would be bad. That's the
point I'm trying to make here. So keep the hash function flexible and open for future change,
which is kind of isn't that one pattern in the solid principles in object-oriented programming.
So make sure that's flexible and not static in like the string hash function prior to Java 2.
And then the other important point is don't provide a detailed specification for the value
returned by hash code. So clients can't reasonably depend on it. This gives you the flexibility
to change it. Because if you do have a detailed specification, then people might rely on the
hashing algorithm when clients use your class. And also it'll make it hard to do this open for
future change bit because the hash function isn't flexible. And so an example here is in fact,
this string class where if you can see here, people will rely on this formula for calculating
the hash function. And that makes this hash code method less flexible. So a good example would
be to keep the hashing algorithm hidden, like what we've seen here, where all you see here is
return object star hash name and age, we don't know what the hashing algorithm is in the object
star hash. So that's what he means by not not being explicit or specifying how the the hash
code is calculated. Because as he states, if you leave the details unspecified and a flaw is found
in the hash function, or a better hash function is discovered, you can change it in subsequent in a
subsequent release. And then to end, he states in summary, you must override hash code every time
you override equals or your program will not run correctly. Your hash code method must obey
the general contract specified an object, that's the object class, and must do a reasonably,
and must do a reasonable job assigning unequal hash codes to unequal instances.
That was also a bit of a long item. And I did feel like I can't mess up a few parts in that
item. Got feeling. I don't know what I'm probably see when I'm editing the video. If I did, I
apologize. Please double check everything I've stated here. And if I made some significant
blunders, I'll try and correct them in some way, either in the description or in the video itself.
Nonetheless, I'm going to try my best. Because that's all one could do. Appreciate it. I shall see
you in the next one. Item number 12, which I've already started on. I don't know why I'm doing
this if you can see the book. Okay, there's the evidence that I've started on item number 12,
which states always override to string. So in that one, cheers.
