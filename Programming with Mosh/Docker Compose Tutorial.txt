In this video, you're going to learn about Docker Compose, so by the end of this video,
you'll be able to use Docker commands with confidence.
Hi, I'm Mosh Hamidani and I've taught millions of people how to code through this channel
at my online school code with Mosh.com.
This video is part of my ultimate Docker course, so once you finish this video, if you want
to learn more, you may want to look at the complete course.
Now let's jump in and get started.
We'll come back to another section of the ultimate Docker course.
In this section, we're going to talk about running multi-container applications.
So I'm going to give you a real-world application with three building blocks, a front-end built
with React, a back-end built with Node, and a MongoDB database.
Once again, you don't need to be familiar or use any of these tools.
Our focus here is on Docker and not on development tools.
I think this is the most exciting part of this course where you can see everything coming
together.
Now to talk about Docker Compose for building and running multi-container applications,
we'll also talk about Docker networking, database migration, and running automated tests.
So let's jump in and get started.
In this section, we're going to use a tool called Docker Compose, which is built on top
of Docker Engine.
It makes it incredibly easy to start applications with multiple containers.
So Google Docker Compose install.
You will find this page, docs.docker.com, slash compose, slash install.
On this page, you can see the installation instructions.
Now at the time of recording this, Docker Compose is shipped with Docker desktop for Mac
and Windows.
So if you're on Mac or Windows, you don't have to do anything extra.
You already have Docker Compose.
To verify it, just go to the terminal window and type Docker Compose dash dash version.
So I'm running Docker Compose version 1.28.5.
Make sure your version is the same or newer.
If you're using an older version, again, Google upgrade Docker Compose, or you might
just install the latest version of Docker.
Now back to this page.
If you're using Windows Server or Linux, there are specific instructions you have to
follow to install Docker Compose.
So go ahead and install Docker Compose and I will see you in the next lesson.
Before we get started, I want to show you a couple of techniques for cleaning up our
workspace.
So on this machine, we have a bunch of images and some running containers.
They're getting in the way.
I want to get rid of them all.
How do we do this?
Well, you know that we can remove images using Docker image remove command.
And here we can type one or more image IDs.
Now how can we get all image IDs and pass them here?
Let me show you a cool trick.
So we can run Docker image LS.
We see all the images, right?
But if we pass dash Q at the end, we only get image IDs.
Now we can pass this as an argument to Docker image remove.
So Docker image remove.
Now here we add a dollar sign and in parenthesis, we type that other command.
So Docker image LS dash Q.
Now if we run this, we're going to get an error because some of these images are already
in running containers or stopped containers.
So we should always remove containers first.
We're going to do that using the same technique.
So I'm going to replace image with container.
So we get all container IDs and then we're going to remove them all in one go.
Also I would like to add dash A here as well.
This will bring stopped containers as well, okay?
We can also combine switches.
That's another technique.
Let's go ahead.
All right, we get an error saying you cannot remove a running container because I forgot
to pass the force option.
So let's bring this up one more time.
And removing, we're going to use dash F, okay?
Great.
So all these containers are removed.
Now let's remove the images.
So Docker image LS and Docker image remove.
Great.
Now take a look.
We don't have any images here and no containers, including stopped containers.
So we have a clean workspace.
That's one way.
Let's shortcut for this as well.
If you're on Mac, you can find the Docker icon on the top status bar.
If you're on Windows, you will find it in your notification tray.
Let's click on this and then go to preferences.
Now on this page, let's click on the troubleshoot icon.
On this page, we have a bunch of useful utilities.
For example, we can restart Docker desktop.
We can also clean and purge data.
This will essentially remove everything in Docker, your images, your containers, your
volumes and so on.
Now be aware that if you click on this, this is going to restart Docker engine.
So on the top, look, you can see this animation showing that the Docker engine is not started
yet.
So at this point, if you go to the terminal window and execute any of Docker commands,
you're going to get an error.
So you'll have to wait about half a minute for the Docker engine to start.
That's another way.
So now that we have a clean workspace, next we're going to talk about our application.
So in this section, we're going to look at a real-world application with multiple building
blocks, a front end, a back end, and a database.
So below this video I've attached a Z file.
Go ahead and download it.
Inside that Z file, you're going to find this folder structure.
We have this backend folder, which is our node project.
This is a basic node project that starts a web server on port 3001.
Once again, you don't need to know node to go through this section.
Then we have the front end project, which is a React application that talks to the back
end.
Now, if you want to run this application outside of Docker, there are a number of steps we have
to follow.
Let's say we just check this out from a GitHub repository.
First we have to go to our back end project, install all dependencies, and then start the
web server.
Now at the same time, we have to open up another terminal window and do the same steps with
our front end project.
So we have to go to the front end project, install all the dependencies, and then start
the web server.
And of course, we need two more terminal windows for running our front end and back end tests.
And not to mention that, we should also download and install MongoDB on this machine.
So there are so many steps we have to follow the moment we check out the source code from
our GitHub repository.
Now with Docker, we don't have to do any of these things.
All we have to do is run a single command.
Let me show you.
I'm going to get outside of the front end folder.
Now we are in the root of this project.
If you look, here we have a file called Docker Compose, which is used for composing a multi-container
application.
We're going to talk about that in detail soon.
Now once we have this file in our project, we can simply run Docker Compose up.
That's all we have to do.
Now Docker is automatically downloading this particular version of MongoDB, so it's downloading
all these layers.
Then at the same time, it's going to install all the dependencies for our front end and
back end projects.
It will start web servers and run automated tests all in this window.
Now this is going to take a little while, so I'll be right back.
All right, our application is up and running, and we can access it at localhost port 3000.
So here's what we get.
We have a mini application for managing a list of movies.
Now you know what's the beauty here?
The beauty is that our database is populated with these movies as part of bringing up our
application.
I didn't have to manually insert these movies in our database.
So we have a migration script for populating our database, and Docker automatically executed
our migration script as part of bringing up this application.
This is a very common real-world scenario.
Now here we can add new movies, movie one, movie two, whatever, and we can also delete
these movies.
So we brought up this application using a single command.
Now I briefly mentioned this file, docker-compose.yaml.
Before we talk about this file, first you need to understand the YAML format.
This is a format that a lot of people are not familiar with.
So in the next lesson, we're going to talk about JSON and YAML formats.
Let's talk about JSON and YAML formats.
If you know these formats well, feel free to skip this lesson.
So in the root of this project, we're going to add a new file called data.json.json, as
you probably know is a language, it's a human readable language for representing data.
So in this JSON file, we can have an object or an array, let's say we want to represent
a course.
A course can have properties like name, price, and so on.
So in this object, we can add one or more key value pairs.
Our keys should always be surrounded in double quotes.
So we can add a key called name and set its value to, we can use a string, the ultimate
docker course, then we add a comma to define the next key value pair.
So we can say price, we can set this to a number.
Now the value can also be a boolean, so we can define another key value pair and set
the value to true or false.
We can define another key value pair and set the value to an array.
So we define an array using square brackets, now in this array we can have any valid objects,
so we can have strings, numbers, booleans, or other objects.
So I'm going to add a couple of strings, let's say software and DevOps.
And one last key value pair, author, I'm going to make this an object, so once again we use
curly braces to define an object.
In this object we add a couple key value pairs, first name is mosh and last name is
what?
I'm a darling.
And yes, I am Iranian, I get that question all the time.
Alright, so here we have a JSON file, now let's see how we can convert this to YAML.
YAML is another language for presenting data, but it has less clutter than JSON, it's easier
to read.
So I'm going to copy all this code, here in the project we're going to add a new file
called data.yaml, the extension can be YAML or YML.
Now on the top we add three hyphens to indicate the beginning of a YAML file, then we paste
our code.
Now in YAML we don't use curly braces to indicate hierarchy, this idea has come from Python,
if you have programmed in Python, you know that in Python we use indentation to represent
hierarchy, so we don't have curly braces.
So let's get rid of these braces and remove the indentation, good?
Now the next thing you need to know about YAML is that we don't have to use quotes, so we
can bring up the replace dialog and replace all these double quotes with nothing.
That immediately takes a lot of clutter away.
Also, we're not going to use commas to separate key value pairs.
So on the top we have name, price, it's published, now how do we represent a list or an array?
We use hyphens, so I'm going to remove this, we press enter, add a tab on a new line, we
type hyphen to define the first item in the list, software, then at the same indentation
we add the next item, DevOps.
That author is an object, but as I told you, we don't use curly braces, we use indentation.
So because these two properties are indented, they belong to the author property, okay?
So this is our YAML file, let's compare this with JSON.
As you can see, YAML is easier to read and understand, now why don't we use YAML all
the time?
Well, because parsing YAML files is a little bit slower than parsing JSON files, because
the parser doesn't know if this is a string or a number, so it has to read everything
as a string and then try to evaluate it.
In contrast, in JSON, strings are represented using quotes and more specifically double
quotes, so the parser knows that this is a string and it shouldn't evaluate it, okay?
So quite often we use YAML files for configuration files and JSON for exchanging data between
multiple computers, like a client and a server.
So now that you understand these formats, next we're going to talk about compose files.
All right, let's see how we can create a compose file from scratch.
So for this lesson, I'm going to rename this file to underline docker compose, we want
to set it aside and create a new compose file from scratch.
So here we add a new file called docker-compose, all in lowercase, make sure to spell it properly,
otherwise docker-compose is not going to find this file, because this is the default name
that docker-compose assumes, okay?
So YAML, now the first thing that we need to set here is the version property.
What version should we use?
Well, let's search for docker-compose file.
On this page, you can see various compose file formats and their compatibility with
docker-engine.
We are using the latest version of docker-engine, so I want to use the latest compose file format
so we have access to the latest features.
So we're going to set this to 3.8.
Now here we need to wrap this number with double quotes, otherwise it will be evaluated
as a number, but docker-compose expects this value to be a string, Y, I have no clue.
So here's the version, now in this file we define various building blocks or services
of our application.
So we have a property called services, now what services do we need here?
Well, our application has a front-end, a back-end, and a database, now your application might
have other moving parts, so you can define them here.
Now these names are arbitrary, so we can call them anything, we can change this to DB, we
can change the back-end to API, and the front-end to, well.
The idea here is that we're defining various services and telling docker how to build images
for each service and how to run these images.
So here we're going to have properties, and the value of these properties will eventually
be used when running our containers.
So in the previous section, we had to manually run our containers using docker-run, and here
we used parameters like dash-p for port mapping or dash-v for volume mapping, we also had
to specify an image like react-app, all these values can be defined in our compose file.
So we don't have to manually start our containers, docker-compose will take care of starting
our containers under the hood, okay?
So for each service, we need to tell docker how to build an image for that service.
So here we can use the build property and tell docker-compose where it can find a docker
file.
So if you look at this project, you can see that in our back-end and front-end folders,
we have a docker file.
This docker file is almost identical to the one we created in the previous section.
So we start from a node image, we create a user, we set our working directory, copy all
the files and install the dependencies, then expose port 3001 and start the web server.
We have a similar docker file in our front-end project, let's have a quick look.
So that was the back-end, here's the front-end and here we have a docker file, almost identical.
But the front-end application or the front-end server starts on a different port, that is
the only difference.
So each service should have its own docker file, okay?
Now back to our compose file, for our web or front-end, we're going to set the build
property to period, meaning current folder, slash front-end.
This is where we have a docker file.
For our API, we're going to set build to back-end.
Now for our database, we're not going to build an image, we're going to pull an image from
docker hop.
So instead of the build property, we're going to use the image property.
Now for this application, I'm going to use Mongo version 4.0-Xenio.
So that is Mongo version 4 built on top of Xenio, which is Ubuntu version 16.
Now if you look at docker hop, you can see that Mongo also has images built on top of
Windows, but Windows images are very large, over 2 gigabytes.
So that's why I prefer to use Linux images.
So for any of these services, we can either build an image or pull it down.
Now here we also have port mappings, so we set ports too.
Now because we can have multiple port mappings, here we need to use the array or list syntax.
So we use a hyphen and then define a port mapping.
So our front-end application starts on port 3000.
So I want to map port 3000 of the host to port 3000 of the container running this image.
That's similarly for our API, we're going to define a port mapping.
This one is going to be 3000 and 1, 2, 3000 and 1.
Now MongoDB by default listens on port 27017, so I want to map the same port so we can access
MongoDB using a MongoDB client like MongoDB Compass.
If you don't use MongoDB, you have the same concept with other database engines.
All these database engines listen on the default port.
You want to map that port so you can connect to your database engine using your favorite
database client.
What else do we have here?
Back to this page for Compose File.
If you look at version 3, on the right you can see all valid properties.
Now a lot of these are for really special cases, so you don't need to use them all the time,
but the ones that we use most of the time are build or image.
You also use ports, volumes, environment and so on.
So our API project needs an environment variable that tells where our database is.
So here we set environment, and here we can use the list syntax because we can have multiple
environment variables.
So we set DB underline URL to, here we need to type a MongoDB connection string.
These connection strings always start with MongoDB colon, two forward slashes.
Here we need to type the name of a host.
So as I'll show you later in this section, when we start an application with Docker Compose,
under the hood, a network is created.
On this network we're going to have three hosts.
The name of these hosts are equal to the names we have defined here.
So we're going to have a host called DB.
So that is the connection string to our MongoDB server.
Now on this server we can have multiple databases.
So we're going to specify the database name and the connection string as well.
So this is one way to set an environment variable, but instead of using the list syntax, we can
also use the object or property value syntax.
So we get rid of the hyphen.
We say DB URL is a property, and this is the value of that property.
I find the syntax more readable because we get color coding and it's just cleaner.
That similarly we can add additional environment variables.
Now we're almost there.
The last thing we want to add here is a volume because we don't want MongoDB to rate data
to the temporary file system of the container.
So here we set volumes, and again we can have one or more volume mappings.
So we add a hyphen.
We're going to map a volume called Widley, and of course we can call it anything.
Widley is the name of this application in case you didn't notice.
So we're going to map this volume to a directory inside the container.
Now if you look at the documentation of MongoDB on Docker Hub or just a typical MongoDB
documentation, you know that by default MongoDB stores its data in slash data slash DB.
So we want to map this volume to this directory.
So whatever that is written inside this directory is actually outside of this container.
It's somewhere else in our volume.
Now because we have used this volume here, we have to define it in our compose file.
So we press enter, remove all the indentations.
So now we are at the same level as services.
Here we're going to define another property called volumes, and here we're going to add
another property called Widley with no value.
I know this looks a little bit weird, but this is the syntax we have to follow.
We just have to define the volume first before we can use it.
So this is our compose file.
Now we can make this more readable by adding line breaks in between these properties.
We can also order these services any way we want.
So currently I'm ordering them from front to back.
We can also order them from back to front.
So we will put database first, then API, and then web.
So we're done with our compose file.
Next I'm going to show you how to build the images.
Earlier I told you that Docker compose is built on top of Docker engine.
So everything we have done with Docker engine, like building images, listing them, starting
containers, and so on, all of these operations are also available using Docker compose.
Let me show you.
So we type Docker compose, without any arguments, enter, look, we have all these subcommands
like we have RM for removing stopped containers, we have run, we have push, pull, and so on.
The difference is that any of these commands will apply to our application as a whole.
So most of these commands will impact multiple services or multiple containers in our application.
So let's look at Docker compose, build, and also use the help option.
So we have a bunch of options here.
A couple of them I want to point out that are useful to know is no cache.
With this we can prevent caching when building the image.
Sometimes you encounter weird issues and you want to make sure that cache is not used.
In that case, you use this option.
Another useful option is dash dash pull.
With this, we can always pull a newer version of the image.
That is also good to know.
So in this lesson, I'm not going to use any of these.
We're just going to run Docker compose, build.
This built our web and API services, and as you noticed, our build was super fast because
pretty much everything came from the cache.
So let's run Docker images.
So I have five images on this machine.
With the front end, with the web, with the API, with the backend, and Mongo.
Mongo obviously came from Docker Hub.
Now as part of this build process in this lesson, we built with the web and with the
API.
These two other images with the front end and backend were built when we started this
application earlier.
So back to our project.
In this original compose file that I included in this project, look, I call these services
front end and backend instead of web and API.
That is why we have these two images, with the front end and with the backend.
Also as you have noticed, when building images with Docker compose, our images are prefixed
with the name of our application.
Now where does this come from?
It is the name of the directory.
So currently we are inside a directory called Widley, and that is why all these images are
prefixed with Widley.
I think this is a great convention.
I got a question for you.
If you look at the created column, you can see all these images were created an hour
ago.
But didn't we just build the web and API images?
Why do you think this happened?
Here's the answer.
Because I built these images, front end and backend, an hour ago, when I was recording
the first lesson in this section.
Now when building these new images, Docker used everything in the cache because all those
files were already available, all those layers were there.
So Docker didn't have to do a full rebuild.
That is why we are still using the build from an hour ago, okay?
Now if you want to force a full rebuild, we can say Docker compose build dash dash no
cache.
All right, this is going to take a few seconds, so I'll be right back.
All right, our images are built, so let's run Docker images.
There you go.
Look at the first two images, API and web, we're built less than a minute ago.
So that's all about building images, next we're going to talk about starting the application.
You briefly saw how we can start an application with Docker compose.
We just type Docker compose up.
Now if the images are ready, Docker compose will run them inside containers, otherwise
it's going to build the images automatically.
Now before executing this, let's look at the available options.
So here we have a ton of options, a couple of them that are useful are build.
With this we can force a rebuild every time we want to start our application.
So we don't have to explicitly run Docker compose build and then up.
We can combine the two using the build option.
The other useful option is dash D for detached mode.
So we will start these containers in the background.
So take a look.
Now if we run Docker compose PS, we can see all the containers relevant to this application.
In contrast, if we type Docker PS, we can see all the running containers across all
applications.
So here we have three containers, Vidly, API one, Vidly DB one and web one.
What is this one?
Well, we can start multiple containers from the same image and this is used for high availability
and scalability.
It's something we'll look at in the future.
So here you can see the container.
You can see what command started that container.
So for our API, that was npm start.
For our database, that was Mongo D or Mongo Damon process.
And for our web front end, that was npm start as well.
You can see all these containers are up and running.
And over here, you can see port mappings.
So now if we go to local host port 3000, we can see our application.
Beautiful.
Now, how do we take this down?
Let's say we're done with this application and we want to free up resources.
Back to the terminal, we type Docker compose down.
This will stop and remove these containers, but the images are still there.
So next time we want to start the application, our application will start pretty quickly.
Let's talk about networking in Docker.
Let me run our application with Docker compose.
Docker compose will automatically create a network and add our containers on that network.
So these containers can talk to each other.
Let's see this in action.
So I'm going to bring up the application one more time in the detach mode.
Good.
Now look at the first line.
Creating network with the default.
So we can run Docker network LS.
Here we can see all the networks on this machine.
I think every Docker installation has three networks, bridge, host, and none.
Honestly, I'm not sure what these networks are for.
But what matters here is that we have a network called Widley default.
The driver for this network is bridge on Linux or not on Windows.
Now, this network contains three hosts or three containers.
Web, API, and DB.
So these hosts or these containers can talk to each other using their name.
Let's see this in action.
So back to the terminal, let's look at the running containers.
So we have Mongo, web, and API.
Now we're going to start a shell session on the web container and
ping the API container.
Take a look.
So we're going to execute in the interactive mode.
The container ID is 8c6 and we're going to run shell.
So let's ping API.
We got a permission error because we have logged in with the app user
that comes from our Docker file, remember?
So we have logged in with the app user and
this user doesn't have ping permission.
So let's exit.
I'm going to bring up the last command.
Now here we have to use an extra option for setting the user.
We're going to log in as the root user.
Good, now look at the shell prompt.
We have a pound sign which means we have the highest privileges.
So here we can ping API.
Now look, we're getting responses from a machine with this IP address.
Now on your machine, this IP might be different.
Now, let's press Ctrl and C to get out of this.
So this is what happens under the hood.
Docker comes with an embedded DNS server that contains the name and
IP of these containers.
Now inside each container, we have a component called the DNS resolver.
This DNS resolver talks to the DNS server to find the IP address of the target container.
So when we ping the API container, this DNS resolver asks the server,
what is the IP address of the API machine or API container?
The DNS server returns the IP address and
then the web container can directly talk to the API container using its IP address.
So each container has an IP address and is part of a network.
Let me show you one more thing.
So back to the terminal, here we can run ifconfig to see the IP address of this container.
Take a look.
So this container has two network adapters, one of them is Ethernet zero.
And over here, you can see the IP address of this container.
So 172.21.02 is the IP address of the web container.
Now back to our compose file, earlier when we defined the API service,
we added an environment variable that contains a database connection string.
In this connection string, we have DB, which is the name of the host.
That is the DB host or the DB container.
You saw that our API container can talk to this container because both these
containers or all containers in this application are part of the same network.
Now one thing I want you to understand here is that this host is only available
inside the Docker environment.
So if I open up my browser and go to localhost slash DB, I'm not going to get anything.
So the API container can directly talk to the DB container.
But if you want to access this container, we need port mappings.
And that is why we have this port mapping over here.
So this port on the host is mapped to this port on the container.
So if you open up MongoDB Compass, which is a popular MongoDB client,
we can establish a connection to localhost port 27017 because this port is mapped to
our container.
Let's verify this real quick.
So connect.
Great.
So here we can see all our databases.
Here's our fitly database.
And in this database, we have a collection called movies with four documents.
So here are the movies that we currently have in the database.
So this is all about Docker networking.
Next, we're going to talk about viewing logs.
Thank you so much for watching this video.
As I said, this video is part of my ultimate Docker course that teaches you everything
you need to know about Docker from the basics to more advanced concepts.
So if you want to learn more, I highly encourage you to take a full course.
It's much faster and better than jumping from one tutorial to another.
If you're interested, the link is below this video.
Thank you and have a great day.
