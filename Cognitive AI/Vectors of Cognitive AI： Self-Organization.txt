Hello, everyone. Can everyone see my screen?
You can see your screen, yes.
Excellent.
Alright, so my name is Tanya Greenberg. Today we're going to be talking about self-organization.
Biological and social agents are very different from our present approaches to design artificial agents.
Technological systems are constructed from outside in.
They extend the part of the world with known functionality by forging its deterministic substrate into required functions.
This is, however, this is true whether we are building a bicycle in a workshop or learning algorithm in a software development environment.
However, biological systems are growing from inside out.
They organize an indeterministic substrate with unreliable properties into a structure that converges to serving the required function and which will even self heal and regrow when they are being damaged or disturbed.
Today, we will be exploring this dichotomy and how it applies to technological systems, especially artificial intelligence.
So, our first presenter today will be Professor Christoph von der Malzburg.
Today, Professor von der Malzburg is a senior fellow at the Frankfurt Institute for Advanced Studies and a visiting professor at the Institute of Neurinformatics at ETH Zurich.
Previously, he served as a research scientist at Max Planck Institute in GÃ¶ttingen, and professor of computer science, neuroscience, physics and psychology at University of Southern California, and as director of the Institute of Neurinformatics at Bochum University.
He has founded two successful companies and has received many awards, including Pioneer Award of the Neural Network Council IEEE and the HAB Award of the International Neural Network Society.
Christoph, the floor is now yours.
Okay, thank you.
Can I share my screen?
Yes, you should be able to.
I will stop my show.
Yeah, continue.
Okay.
Here we go.
First, I would like to discuss the how to determine the information content of the brain and of the environment with which the brain is dealing.
And the right way of going about that is Kolmogorov complexity.
The information content, according to the information content of the structure is measured in terms of the bit length of the shortest algorithm that creates that structure that can create that structure.
Let me give you a simple example. The Julia set is a very complicated thing in order to describe it as is you need a literally an infinite amount of information you can blow it up as long as you want and it still continues to create more to contain more structure.
But in order to create it, it needs a few line algorithm, the guts of which are shown on the lower left.
The flip side of low Kolmogorov complexity is that the structure it is describing is highly structured it has high structural regularity, which is again displayed here you can see.
There is a lot of structural regularity, which never repeats, but you can see the inner coherence of the whole thing.
So what about our natural environment.
I claim it has very low Kolmogorov complexity. Otherwise we couldn't perceive it and science wouldn't work. And I think virtual reality is a very good tool to show that
the changing environment in including their dynamical interaction with a viewer can be created with very little information. So the basis of that is computer graphics in computer graphics.
That's an amazing field that has developed over 20 or 30 years the ability to create very realistically looking scenes and also dynamic scenes.
So we have created something like an ontology of our visual environment. And I guess you all know how it is done it is a is a compositional game you start with a representation of the shape in terms of shapes in terms of wire frame models.
You give them surface markings and reflectivity, you transform them by known laws into a scene in position them in the scene.
You, you project the scene with projective geometry into a virtual camera yet you eliminated.
So that is something that can be done was a few gigabytes of program code.
We all learn in a very deliberately designed simple environment in nursery.
And although this nursery is very limited in terms of numbers of samples and complexity, we later walk out into the world and can reflect it represented in our brain.
Now, as I said, to generate this kind of to simulate if one care to do that, that kind of environment including the social interactions, it would take a few gigabytes of a program like a computer games program virtual reality program.
So the color of complexity of our environment as far as is needed for learning is gigabytes only.
Let me remind you that, at least to psychologists, the speed with the rate at which we pick up information into our long term memory is a bit or so per second, so that over your whole lifetime you pick up a gigabit.
When I first heard that I found that offenses to the rich to the richness of my inner life, but turned the other way around and say it takes a gigabyte to create the world as I know it to to represent it.
Now the brain is a very complicated thing, a simple estimate of the amount of information you need to describe the wiring is a petabyte 10 to 15 bytes. Here's a little computation on the screen, how I arrived at that.
But the, the color of complexity of it must be very low. It takes one gigabyte of genetic information to create an organism like mine, including the brain.
And as we saw it takes a few gigabytes to train it to at least some level of competence. So the color of complexity of the brain is very low.
So that means the brain is highly structured. And I think this is the query theory has to shoot for to describe the particular kind of structure that is dominating the brain.
The question arises, what is the Kolmogorov algorithm by which the brain is actually created.
The, as I said, the brain is dominated.
No, here's my slide. The brain is the result of self organization, of course, where the genes play the role of parametric control.
And likewise the sensory signals they just influence this process of self organization, which however is totally dominated by the structure that we just concluded must be structuring it.
So the brain is dominated by attractor patterns and see that in, in analogy to crystals or to touring patterns if you heard of, heard of them to soap bubbles, or the Golgi apparatus that is in all the eukaryotic cells, all the cells of your button.
Those structures arise by the more or less chaotic interaction, dynamic interaction of the building elements of those systems. These patterns emerge as one, as one called someone speaks of emergence they just arise because they can self stabilize they can prevail in a dynamic game.
So that poses the very important question what are the emerging patterns in the brain.
There is, thank goodness, a very good paradigm for that that has been studied 40 years ago, very intensively I must say I was in the middle of this with dozens of different types of experiments done on frog and fish.
The question is, how come that the fibers that grow out in some stage in the embryo from the, from the retina on the left on the left, and grow out to target structures in the brain the optic tecton for instance here on the right.
And I found that these fibers, which at least in some species start out in a rather random pattern, order themselves in over some time.
Till at the end, you have a beautiful picture.
And appearing here in the tecton, when a picture is shown into the retina and a connectivity pattern when neighboring ganglion cells in the retina connect to neighboring cells in the tecton.
How come these five was nowhere to go. There was a handful of theories.
I might, given the enormous flexibility of the system.
It's resistance to experimental interventions and quirks of natural development, and the one that survived, and I was one of the people who proposed it with my friend David will show and Alexander Heusler is network self organization.
And my name is that is the color of algorithm of the brain. And it works like so a network and initially more or less random network create signals.
The signals act back on the network by synoptic plasticity. And this loop, this initially unstable loop continues until a network structure is reached that stabilizes itself via the signals that creates signals that stabilize that same.
Network and retinotopy is just one example of that.
So by some leap of faith, one has to see, or if you don't take it as a logical conclusion, one has to see the structure of the brain as an overlay of lots of self organized network patterns.
These attractor networks are characterized by two properties one is the consistency of different pathways, a single pathway can only grow if it gets cooperative help from other pathways coming from the same source.
And this is going to the same target cooperativity. And this is bridled in by a sparsity constraints varsity meaning a limited number of inputs to the same neuron or outputs from the same neuron.
That's a simple characterization of attractor networks.
And this is that the brain is an overlay of lots of attractor nets, each having its own support as a set of of neurons, and each time that set of neurons active, it works a little bit on on its connectivity until it has reached a tractor structure.
And then you can be part of a number of attractor nets.
The central thesis towards I have been driving is the emergent nets self organized nets are the brain spires.
And this is a very bold, it took me a while to sort of put my belief behind this. This is a very bold statement of course, saying that the mechanics or network self organization is at the base of the structure of our mind.
The structure of our brain. That is one half of that of the hypothesis and the other one is the structures that arise by this mechanics are a powerful Bay bias to understand the environment.
The statistical learning mechanism needs to have a very strong bias, it tunes it to the phenomenon that is to be learned from. And so the idea here is the conclusion here is that the buyers in our brain is network suck.
The attractor nets are the data structure of the mind they they form a construction kit for a mind states, other Lego blocks of the mind of the chunks of cognitive theory, and the syntax the grammar, under which they combine into
any combination of of co active networks has to form a stabilized a self organized a attractor net that would be given enough time to be stable under self organization is in principle a very simple system.
Let me just give a simple illustration to make it more concrete face recognition that was the base at the base of two companies I've co funded in the past in California in Germany.
Successful companies. So the idea is the image of an object or a face enters primary visual cortex as we all know, as a 2d array of local feature detectors.
And which are, as we also know, connected literally connected by a short range connections. So it is a tiny step from there to assuming that what the input image activates is local connectivity fragments fragments of connectivity, which seamlessly blend into
each other to represent the whole face, one order to record in, in order to recognize it, you need a model of that phase in another part of the brain if she was a form complex, and in order to establish the relationship the similarity
relationship you need fiber projections between a primary visual cortex and the, and the info temporal cortex, which links corresponding parts to each other.
These projection path networks have to switch as quickly as the images change in the primary cortex.
There are also circuits by Charles Anderson, and by David van Essen.
Now let me just point out that the whole structure here that arises in a fraction of the second when you look at the face is an attractor network is composed of lots of little net fragments that have been previously prepared, and that fuse into each other to form this representation.
So let me go one step further, and submit the idea that we comprehend objects by linking them sensory objects by linking them to schematic description there are schematic description that are put together by
these network fragments that have been trained before. So let me come to my end and repeat my central thesis emergent nets are the brain spires.
Thank you.
Thank you very much Christoph that was an excellent presentation.
So.
You want me to stop sharing I suppose.
Yes, you could do that.
I think the share will be interrupted when Yuri starts. So, um, our next presenter is Professor Yuri, because I was a key.
Yuri was a key is the biggest professor of neuroscience, NYU School of Medicine, and is among the top 0.2% of most cited neuroscientists.
He has contributed to the emerging under emerging understanding of the dynamics of hippocampal system, and the recognition of the importance of temporal firing properties in the formation of neural codes is overarching hypothesis is that the numerous
that the brain perpetually generates are responsible for segmentation of neural information and communication across brain regions. He proposed how these rhythms support a brain syntax, a physiological basis of cognitive operations.
His most influential work is known as the two stage model of memory trace consolidation, and has been adopted as a framework at several leading laboratories around the world.
Thank you Tatiana. Let me use this opportunity to ask a few questions and then, then I go to my presentation.
The first thing I like to ask is that, you know, what makes us so successful as a species. And the answer is that we are the, perhaps only or very exceptional species that was capable of externalizing brain function.
We expand the body and expand the brain we make machines clocks rulers computers to help us and obey us, not to substitute or compete with us.
Now, if you take this position and you can ask, you know, how is AI, and, and why do we call it artificial intelligence in the first place I always bug me know what if we are talking about artificial smartness artificial creativity thinking
about artificial consciousness.
It just happened that AI survived and because that was a community agreement, you know, and what if, for nine months, name the computer and artificial brain then we will be having a branch sponsored by governments and we will be all
researching artificial brains. Now, what is so special about intelligence.
Intelligence in biology is typically defined as the ability of the species to survive and prosper in its own niche.
And the emphasis to me is on niche, because it would be unfair to put a human underwater for 10 minutes and then conclude that the fish are more intelligent.
All all species survive and perform in their own niche.
And the question is then what is the niche for AI. If every intelligent agent requires a environment to leave, what is ai's defined environment.
When you would like to do a artificial version of something or anything, we need to have
a good definition of the real thing first.
And let's see how it works with intelligence.
Like space and time, intelligence is an abstract, deduced idea.
Ideas become scientific only, then we begin to measure them.
Measuring needs scales.
Experiment space became scientific terms where we began to measure duration and distance
by clocks and rulers.
Intelligence also became a scientific term where we made up a scale for measuring IQ.
Historically, this was introduced as a tool for selecting soldiers during the first world
war for particular goals.
Goals is a very important thing, because classification can happen only in the presence
of a goal.
But today, the goals of AI are very different.
Different groups of people come up with their own creative definitions and relate them to
their own rulers.
Unfortunately, there is no agreed common ruler against which we can measure intelligence
of humans, other animals, machines, and computer algorithms.
So when it comes to defining AI, one may wonder, this is a fantastic system or a field that
can live alone, or indeed as some people say, AI should be inspired by the brain, or whether
brain scientists like myself should be looking out for AI people like you guys to see how
much we can steal from you to understand the brain.
So in order to do that, we'd like to see what kind of aspects or hypotheses or statements
AI is using currently from brain models.
Now I have to share the screen here, and there we go, share, present this view, and let's
go.
We can distinguish basically three extreme versions of how we think about brains in general.
One is, I would say, is still dominant, and is based on the key words like random organization,
egalitarian, have rules, AI balance, noise, and sleep plays no importance whatsoever.
We create robots so they can work 24 hours a day, and we create algorithms to work 24
hours a day, but we humans and other animals sleep also.
Now the whole idea here is that you start with a simple brain and make it more and more
complex, and the complexity scales with experience.
You can call this model Tableau-Raza and writing in, and Christoph very eloquently already
pointed out that this is not the kind of brains we, or most brain scientists look at.
Imagine, brains have internal dynamics, and it's a common word, but we don't really explain
what it is, so I'd give it a try and explain what it is.
So the alternative of the AI-like, or the Tableau-Raza, or the Blake-Slang model would
be a alternative, which is an autonomous system, a self-organized system, which has very different
rules instead of egalitarian, it has strong skewed rules, and sleep is an essential feature
that is necessary to maintain its own dynamics.
And instead of the clean paper, the brains can be their preconfigured dynamics, and that
preconfigured dynamic gives you an enormous realm of possibilities, typically sequences,
and learning under this model is not a synthesis, it's not putting something into the brain,
but I'm masking and matching an existing pattern with the experience.
Now the way how we can summarize these two models in just very simple sentences, this
is the famous short summary of Hebb, is that neurons that fight together, why together?
In the other hand, you can say that neurons that are born together will fight together,
therefore they will fight together with a much higher probability that neurons that are not
born together.
Now this is a very simplified view of course of the brain, and I have checkmarks here saying
which side I prefer, and of course you would like to know whether there are supports for
any of these things, I have never met anybody in my neuroscience community who would say
oh the brain is a tabula rasa, but there are famous people such as this guy here who said
exactly that, it's not so long ago that there is a notebook and then you have to fill it
up with experience, he is another giant, John Hopfield who not so long ago said large number
of simple equivalent components.
So this is exactly where majority of AI people live on, and I'm happy to hear you contradicting
me, and of course there are new areas of AI that are different and they are more brain
inspired, but I think by and large even neuroscience is following these principles.
In contrast, if we are looking for fundamental laws or fundamental rules in the brain, then
there are not too many, this is not like physics, but at least we have one overwhelming
rule in the brain, this is called the wave effectal law, which describes our subjective
perception as a log rule, and there are many many attempts to show why this is the case,
and it's also not only for our perception, but it applies to almost everything, such
as short term memory, long term memory, space, duration perception and so on.
The reason, the fundamental reason I think why this log rule occurs is because the brain
has a dynamic range, extraordinary wide dynamic range in almost everything, from synaptic
ways to firing rates, population, synchrony and so on, they also show a lot of log normal
distribution, or log normal like distributions, and this dynamic is based by a skewed system,
which is as Christopher already pointed out, this is not from random organization at all,
but connectivity can be described by a log rule, which means that one area of the brain
is connected to a handful of other areas in the brain very strongly, 50% of these connections
are to a handful areas, but the other 50% is to a very large number of other areas with weak
connections, and this is what is expressed by the log rule. So of course these are interesting
observations, these are only statistics, but the question is whether these are statistical
curiosities only, or they serve something interesting, and I think what they serve is
exactly what the brain have to solve, which is a fight, it's a continuous struggle of a war
between wide dynamic range, stability, resilience, homoesthesia, redundancy, degeneracy, and this
is one end, the other end if you want will be plasticity and robustness. So if these are
fundamental rules of the brains, then we know that there are small brains and large brains, and how
would they react in their niche where they live, and the answer is that, not the answer, but my
hypothesis is that the main goal of the brain is to maintain its own dynamic, second is to generate
an output, and to see the consequences of its output, and predict the consequences of its
output. So this simple creature is generating an output, it interacts with the body and with
its own niche in the environment, and then it events sensors to make the prediction better,
and the goal of course is to predict the consequences of its own actions.
Now brains grow, they get larger, there are many many loops added to this, but the entire goal of
this is exactly the same, but now this organism such as your brain and my brain can predict the
future at a much longer time scale, and in the much more noisy complex environment.
Now this is not yet cognition, there is one more trick here, namely we have to disengage
the brain from the world. The reason why I see is not because there are photons on my retina,
I can see, you know I close my eyes and the screen doesn't appear, I can still see Tatiana and
everybody on the screen in my mind, is because what we see is actually the brain computation,
and if that is true then we can temporarily or for a longer time disengage or remove from the
environment and keep going on with the computation and do and compute what if scenarios, what if I
didn't wake up this morning early enough to come to this talk, and what would be the consequences
of this, therefore I put my alarm clock and so on. So these are the kind of things that
this complex brain can do. Now there is one more bug that is is complicated because all you see is
loops, loops, loops, loops and complicated loops and interactive loops and this looks like a
talamo cortical system, but besides our cortex and the talamos there are two tricks here, one is that
the brain's event is side loops, there are two side loops here, the cerebellum and the base of
ganglia, they are first cousins, they like each other, they compute similar things and they
complement each other, and the third loop is the hippocampus. So you may wonder if you would like
to make a AI system, you know why are these side loops, what they are good for and how they work,
so in the rest of my time I'd like to show you some examples how they actually work.
So my first claim was that the number one goal for the brain is to maintain its own dynamics,
is it expensive or does it come for free? So recently then Levin Steynagratz students in
my lab devoted his five years here and calculated. What we did is that what you see on the left is
the distribution of inter-spike intervals, that is how regular spikes spike or work,
and we know that they are pretty irregular most of the time and in the x-axis you can do this
inter-spike interval and every single line there are a few thousand neurons here in the hippocampus,
every line is the inter-spike interval distribution of a neuron, and you can see is that that there
is this nice shift that is different from neuron to neuron. So there are fingerprints, there are
neuron individual, neuron characteristic firing patterns, which is on the low end of the firing,
this can be 0 to 0.01, 0.001, very low frequency firing, which bordered many people for a long
time, you know why do neurons fire at such a low rate that doesn't make sense, you know they cannot
do anything except they're discharging their partner interneurons, but they don't have any
information value. Now it turns out that there are other regimes such as here you can see a band
here that all neurons are in the same band, this is in the hippocampus, this is the theta band,
or there is another band here about gamma, there's another one here is a bursting pattern and so on,
so by analogy to physics we call this state here the individual specific state, the ground state,
and then the other states that are common to all neurons or most of the neurons are the activated
states. So this is shown here in a cartoon manner that every neuron can have its own ground state
and is activated state, activated states means they are working together with many other neurons
for a purpose. Now what fraction of the neurons span in the ground state to do nothing or to
maintain neural dynamics, nothing meaning no communication, no perception, no thinking and so
on, and the answer is astonishingly high. This is a figure that shows the hippocampus, the piriform
cortex, basal autonomic delar, frontal cortex, visual cortex, the thalamus, it doesn't matter
where you go and what state but it's sleep or waking, most of the spikes everywhere in the
brains are devoted to maintain the brain dynamic. So I made my first point. My second point is that
there are many neurons that are silent or they are firing these scattered spikes such as the ones
I just showed you that they are in the ground state. So for example if you are a place neuron,
you can see my cursor here probably if the animal is running in an environment and you are
recording from the hippocampus then there are place cells and this is place cell number one,
place cell number two, place cell number three, four and so on, but there are half a more of the
neurons that are like these yellow cells that they don't do anything. What are, are they part of this
attractor that Christoph was talking about or they are distinct from each other. So how do we
know that? The way how to do it is do a trick what Manuel Valero did is optogenetically activate
this cell for a short period of time and again a short period of time, periodically 20 milliseconds
for thousands of times that doesn't perturb the system and ask you know how are you and then
the neuron fires a spike and then it fires a spike and another spike. So now this neuron,
the same neuron that you have seen before that doesn't have any place field, all of the cells
does have a place field. So we can, we show that and this place field is married to a particular
position just like normal place fields are and this here is another one and then there are many
of these, in fact most of them if you have the probing done right. So the middle one would be
the noisy one that you wouldn't see otherwise because the firing rates are too low compared to
outside the field and we don't know where the field is, but if you probe the neuron then we can
unmask place fields from every single C1 pyramidal neuron in the hippocampus. So it is part of the
same exact tractor except it doesn't spike, it doesn't have an output. So unmasking is as effective
as making. So remember that you know on the one hand you have to synthesize, you have to make
neurons and you make them fire the way how the world makes them fire or the other one is that
it just happens when you are searching into something there's a high probability that a
particular pattern occurs and that pattern can be associated or linked to something meaningful.
So where do these preconfigured lists of sequences come from and the answer is perhaps by from
either evolution or evolution or embryonic states. So now we are doing a little bit of
a neuro-ocular and we are asking is that if you are recording from an adult brain how would we
be smarter to know how this neuron should behave if we know that this neuron and another neuron
were born in the same day or in a different day. And to do that, Roman Hussari in my lab
he labels neurons at different stages of development such as embryonic states 13, 14,
15 and 16 days mark them permanently so when the animals grow up then we can compare the adult
animals and know which neurons were born on the same day and which neurons were not.
And the answer is even if we go to those neurons that that were born together they will fight
together the same theta cycle the same sharp wave cycles at the population level they like to be
together they form cell assemblies and even at the very extreme level this black neuron was born
on on 14 days if 14 days and it has one field and it has another field. The blue neuron was born
on the same day and it has a similar field and the red neuron was born on a different day at
this similar field and if you do the statistics on a large number of neurons we find that
neurons that are born together they do many things similarly and they fire together and fire
together. Well this brings us to the the new brain picture which is my spaghetti brain which shows
what suggests that we are not making complex brain from simple brains. Brains are devoted
devoting their enormous resources to maintain the dynamic that brain dynamic does not change
or scales with learning or experience. Mind brain, your brain or that of a totally
unexperienced brain or the brain of Albert Einstein are not necessarily different in complexity
because learning is not a not adding but it's a matching process the in this spaghetti the
thicker ones that have already been associated or linked to experience and so you know without
without analogy it would be like a Chinese dictionary where there are many symbols all the
symbols are there for communication which us don't understand them but we have to ground them by
knowledge such as knowledge of English words or in our cases is experience. So the interesting
challenge to the AI if you are interested in brain inspired system maybe we should be looking at
the right end of my first slide which is this slide here that we can create a system that already has
a realm of possibilities for matching but another requirement that that system should be
supporting a goal it has to live in a niche it has to be embodied it has to have a
a thing that is deciding or constraining the features that it can support with itself organized
complexity and you know I have a few more things to say but if you're interested then
just read this book thanks a lot. Thank you very much that was an excellent presentation
so next up we have professor Dave Ackley let me quickly create a spotlight
so David Ackley is emeritus professor of computer science at University of New Mexico
David received his PhD from Carnegie Mellon University before starting his academic position
at the University of New Mexico he was a member of the cognitive science research group at Bell
Core his ongoing research interests center on artificial life models and real artificial life
current research emphases include genetic algorithms and programming distributed in social computing
robust self-aware systems and computer security Dave the floors know yours. Thank you Tanya I wasn't
exactly sure how I fit in here Kristoff is an incredible legend I mean I started
doing computer neural networks in the 80s in graduate school and I was already reading his
papers and and Georgie's talk was just an incredibly perfect setup for what I want to say
you know I my interest is making computers do new things by themselves because that's cool
and so I've been doing that my entire career and I you know the big problem is of course is that
once I've gotten them to do it it's not cool anymore so I have to kind of keep moving on
keep feeding them off with new cool stuff so I went from neural networks to genetic algorithms to
artificial life started doing in the 90s started doing biological approaches to computer security
trying to do automated diversity generation to try to make it so that you know if there are
going to be bugs in software and there were going to be bugs in software well then maybe the attacker
would have to solve a different problem for each copy of excel rather than just being able to kill
all of them at once and you know by the late oos I was depressed about computer security I was
depressed about the impossibility of fixing computer security you know and the problem wasn't
that we couldn't get you know users to change their passwords or apply patches or that programmers
were incompetent or that managers ship crap although all those things are true the problem is
even if those were all fixed we still would have incredible computer security problems that are
just getting worse and are going to continue to get worse as people figure out how to exploit
the incredible fact that the way we've designed computers is one bug is all it takes to take
over the entire machine and you know physical systems living systems brain systems are not
like that I mean except in very very rare circumstances and so I said well you know what is the actual
problem here and the problem is I've concluded the underlying architecture of computation
the cpu and random access model is broken I mean it's fine for small systems but as the system
gets bigger and bigger and bigger it's terrible and so my my goal is to say well how can we come
up with a new architecture which will be more inherently robust much more like the attractor
networks the overlapping attractor networks that Christoph was talking about much more like the
brain spaghetti that Jory was just showing and yet still be able to engineer with it somehow
and my answer is well number one we have to stop eating the glass sandwich and this is the glass
sandwich the idea is the purpose of a computation is to connect physics to value to connect matter
to money to put it not to find a point on it and the way we do that is we build hardware we build
these digital electronic circuits that in fact have tremendous redundancy in them a wire that we
used to carry one bit could easily carry dozens or hundreds or thousands of different values
with some degree of error but we don't do that we send one bit down and we stick amplifiers
everywhere to squish that one bit back over and over and over again and that heroic act of redundancy
in digital circuitry is what makes the hardware so reliable that the software level can just
assume that it's perfect just assume a trick to present a synchronous unit
I need to find the best way to learn math and science
okay I'm not sure who I heard that
the circuitry of the of electronic circuitry is incredibly redundant and therefore software
can be incredibly non-redundant and that's bit baked into the DNA of computer science the whole
idea is you should never you know don't repeat yourself that's a mantra in software engineering
you should use caches if you've computed something you should remember it don't compute it again
and all of that is built on top of the idea of we have to trust the the hardware is perfect
but that guarantee that hardware provides always has an asterisk because of course there is still
some probability of failure some probability of an undetected error coming up from the hardware
level and reaching the software level we just engineer it so that it's low enough that we
can finish playing solitaire or doing whatever program we want to do with having vanishing
low chance of anything going wrong similarly once the computations get really really big like data
several data center level tens of thousands of these machines all owned by a single organization
they start seeing them failing because that remaining level of failure is there and they
start applying robustness features but for everybody else there's basically you know electronic
circuit robustness and then this fragile and incredibly efficient which equals incredibly
non-redundant incredibly fragile non robust software built on top and the claim is the
suggestion is we have to stop eating the glass sandwich and here's my conclusions
there's a 12 step program for inventing a new architecture that in fact almost completely
inverts the design assumptions that underlie deterministic execution with CPU and RAM and
I won't any have anywhere near enough time to go through all of these but several of them have
already been mentioned self stabilization was mentioned number seven look at life for lessons
that's what I take from both Yuri and Kristoff using their studying the brain and studying the
nervous systems of animals and people and everything for understanding about how these
things work and the fact that for example brains aren't just sitting there they're
doing stuff all the time if you want to do something with a brain you have to work with
the dynamics that it's got that's very different than a computer with memory just sitting there
empty you load it up with a program and then it does whatever you wish
so it begins with step one admit we have a problem and for me that is driven by computer
security I think you know 50 years from now hopefully less our great grandkids will not
believe the world that we've lived in as far as computer security goes today of the computers we
have today are so unbelievably gullible I mean one mistake I mean they're like completely you
know you just talk to them and they they become zombies it's like a horror movie where all you
have to do is say the thing and then they start sending spam to Russia for you or whatever it is
that they do and that is not the way it has to be that is the way it is because the way we've designed
the glass sandwich but we could do something else and so you know the idea is instead of
thinking about correctness and efficiency only at software we have to think in terms of robustness
first think robust first and admit we have a problem we can sing the whole song pick new
metrics and so on but I won't do that I just want to get a little bit more unpack the idea
show a few demos and then stop there and let's go with discussion for it okay
so so here's the answer the answer to how to stop eating the glass sandwich is go for structure at
all scales and rather than saying we've got physics we've got hardware that produces universality as
close to the physics as possible and then it's all just software we're going to say no actually we
want to delay universality and have that happen much closer to the value and we want instead just
like you were talking about just like we were talking about have attractor nets things that
self-stabilize things that have their own internal goals other than get the credit card number yes
we have to get the credit card number at the end otherwise we can't pay for the whole operation
but we want to do it with things inside that are worrying about their own goals you know
am I still is everything all cleaned up do I have enough room to work do I have enough copies or
enough cousins and brothers and so forth that are available to do it in case something happens to me
and so forth and they themselves are made of even smaller systems like that so rather than
saying you know it's turtles all the way down we want to build bottom up and say you know it's
thermostats all the way up made out of more and more and more complicated ones layered on and I
want to engineer that I want to actually build that learn by implementing them you know we can
learn by studying the brain we can learn by studying animals that's great but that's not
what I do I want to do it by building it and seeing cool new things happen all right so
I've already said this don't blame the users the programmers the managers blame the architecture
in particular blame random access memory you know which is this wonderful thing and it's far far
too wonderful because the instant we managed to knock a program off its kilter once you have this
huge field of opportunities you can find anything you need a little bit here a little
bit there 17 of these carry a loop make a thing five by one you're doing whatever you wish
how do you stop that what we have now all the stuff that we're doing now the people doing
computer security work you know it's there we got to do it because here's the the engineering
field that we're currently living and we got to play it as it lays but it's patch patch patch I
mean not just for the users but for the whole idea it's a glass dam that it's going to spring leaks
we have to keep patching it up the whole thing's going to go to hell but we could if we wanted
actually start to build another dam a little further away out of sterner stuff out of stuff
that's built out of ripstop nylon instead of out of brittle glass and in order to do that we have
to ditch random access memory and what are we going to replace it with if we get rid of random
access memory well the suggestion I make is it's going to be some kind of cellular automata now
if you're not familiar with cellular automata it's the idea of instead of having one big
central processing unit and one massive ram you have a whole bunch of teeny little processors
with little teeny bits of ram and they only talk to nearest neighbors or nearest two or three
neighbors or whatever it is some limited neighborhood that is all that they can get to
and there's no general purpose pointer they cannot go well I need that little bit and this little bit
so does that mean everything's guaranteed to be fine no does that mean everything is safe no
but it does mean that if an attack is going to be mustered in the most critical moments when you
first knock the system off kilter you have a very little bit of stuff to work with and it's all very
delicate and you have to do a land war you have to take over the next stop and the next bit and
the next bit and spread it rather than going boom I won now most people they're familiar with cellular
automata they're familiar with things like conways game of life and that has a two characteristics
that I don't like and in particular number one it's deterministic so it inherits that exact same
flaw that believing in perfect hardware that cpu and ram inherits from and if we're trying to get
around the problems that cpu and ram and deterministic execution are causing we have to give up on
deterministic execution we have to admit that there will be flaws and they have to be handled
software can't just say reliability is a hardware problem and number two it can't be synchronous
the whole thing can't go kachunk kachunk kachunk at once because the whole point of cellular automata
is that it can get bigger we can add more we can grow the thing out and the bigger the thing gets
the worse synchronization becomes there's a bunch of tricks you can do that people keep discovering
every decade or two about ways to kind of lay a synchronous thing on top of an asynchronous thing
but they all rely on deterministic execution if there's a possibility of errors that means the
synchronous overlay it actually locks up the entire universe grinds to a halt not a good outcome
for having one bit flip so we have to embrace asynchronous valuable hardware and say how could
we program on that and wow that's harder than programming on cpu and ram but hey we know a
little bit more about software now than we did when we first invented the von Neumann machine and
all the subsequent cpu and ram stuff so that's the idea how do we make a cellular automata got it
that's uh can be indefinitely scalable we make it by making an individual tile a chunk of
cellular automata that can connect with others of its own kind and we just keep plugging it out
so here this is a t2 tile this is the specific tile that i've been working on for the last decade
or so it's a small project so it's going slowly but in fact we had an earlier version called
the illuminato x machina back in 2008 that similarly it's a 2d thing that you plug them
together and so forth those were actually briefly marketed and now in more recently we have the
t2 tiles the one that i just showed you and these things are you know ridiculous huge heavy hot
$100 expensive each because they're a research prototype and you know the key is to figure
out what we want to figure out a new deal between hardware and software and then yes the hardware
guys can come in and figure out how to do this beautiful but we have to know what we want first
so that's it there's a the t2 tile project has bi-weekly videos on youtube there's also a t2
demos which just shows examples of the stuff running and you know we've got a new programming
language called ulam which is a procedural language for coding up transition rules for these
things we also have a spatial programming language called splat where you actually can make these
little these little diagrams you know little ascii pictures saying this 2d pattern goes to that 2d
pattern and so forth and that you know it's very simple but it made stuff possible it made stuff
work like that i've been trying to get to work forever now i'm just going to show you this one
and then i'm gonna i guess i'll stop because my 15 minutes are up one of the big problems with
asynchronous cellular automata is how do you move a big thing how do you move something that's bigger
than you can move all at once if it's synchronous you kind of imagine going chunk in one step but
when it's asynchronous you can't you have to somehow break it down and that's what this example was
doing it's the little blue guys that go through they create swap lines that come up and pass through
the rectangle and each time they pass through the matrix the matrix moves one step in the
opposite direction that's what a swap line does so a swap line is designed so that it
never gets more than 45 degrees down the line so it's a limited amount of synchronization
the passing of the line is a certain degree of synchronization so that's just one example
of learn by doing this is another example i'll just let this run i guess and we'll end
this is taking a plate a grid of sites that communally say let's create a common spatial
origin let's create a zero zero and a 2020 or whatever it is there's no overall grid coordinates
in the underlying architecture there's no zero zero because it's indefinitely scalable there's
no beginning everything just thinks it's the center of the universe and it goes from there
but that doesn't mean we can set up our own private little one and once we do that we
can do all kinds of things with it so this is more stuff with plates oh and i'll just jump
to this last one if i can right there it is this is an incredibly lame neural network kind of
encoded in a movable feast machine written in ulam and here it is actually running so the the
two blocks that you see on the upper side are crossbar matrices that connect inbound inbound
wires and outbound wires and they each have a weight at the connection and then down so it's
actually doing a a simple function optimization where the one on the upper left represents the
function the one on the upper right represents the knowledge that the algorithm is gaining and
then it actually had a little a little data readout on the screen to produce human output
so that's it i will stop there and
it's going incredibly slow but hopefully some folks will be inspired you know step step 11 is
you know we we have to make it happen we have to get organized and so forth and
this is not going to be running excel in a year this is a long-term fundamental research project
to kind of go for a mulligan to kind of do a do-over instead of having determinism at the
bottom we have determinism at the top instead of having data center software reliability at the
top we have it at the bottom and so on thanks for listening thank you david i from the chat
i see this was an extremely inspiring presentation for a lot of people okay i'll switch to yosha
so our final presenter today is dr yosha bach yosha bach is a cognitive scientist and AI researcher
with a focus on computational models of cognition and neuro symbolic AI he has taught and worked in
AI research at humboldt university of berlin the institute for cognitive science in osna brook
the mit media lab the harvard program for evolutionary dynamics and is currently a
principal AI researchers a researcher at intel labs california yosha the floor is now yours
thank you so the machine that builds the machine is a very interesting topic when we think about
the brain because our mind is something that is not just designed as a technological system
from the outside in but as biological and social systems are from the inside out
if we look at this difference now when we design a system in our lab we start from a
deterministic environment and we take a substrate into this environment that is not structured yet
in the way in which we want it to be structured but we can fully control it and we extend our
determinism into this new part of the universe to basically extend our deterministic world
into this particular thing so we are coming from the outside in a technological design
and if you look at a biological system you do not have this deterministic environment to start
this instead you have an indeterministic environment and you start out with some seat
that needs to colonize the environment to branch out to subdue it to turn it into something
that the seat knows how to deal with and then gradually turn its own structure and then you
go by on a simple organic growth you look at organismic growth where you already know the
structure around you because you have created it so you are part of something that had a shared
destiny at some point and so now you have known units around you this which you can collaborate
and organize and so you are colonizing the outside internally you are organizing from the ground up
from local units inside out and we can ask ourselves what an organism is does an organism
actually exist right we sometimes think of organisms as things but the organism is a
virtual thing it's a function that describes the coherent pattern and the activity of many cells
right so the individual cells are all serving that function and by making them coherent
due to evolutionary pressure and the design constraints that are built into the cells as a
result of that you see a coherent pattern emerging and this coherent pattern that we see emerging
that is the causal structure that we call the organism and the organism like every other thing
that exists to exist is to be implemented is implemented to some extent but it's not implemented
in the way in which a computer chip is implemented but the degree of approximation is much more vague
and it's the organism exists to the degree that the patterns in the interaction of the
cells in the organism are coherent so in some sense we see a pattern of this organization
a software that emerges over this information processing that looks as if there is a coherent
agent that is inhabiting this thing and traditionally the word for this
emergent operating system for an autonomous robot in nature is called spirit and so in this sense
the emergent agency that we see in organisms is actually what was called spirits by the previous
civilization and these spirits also happen to be in our own minds and they also happen to
emerge in groups of people in nation states and ecosystems and so on and these spirits are
virtual machines that possess agency that is they play a controlling role by being able to model
the future and their own place in the universe to some degree and they are approximately implemented
and so in this sense the spirit is a very high level of an organization that is required to
see the emergence of such a spirit and when we look at the hierarchy of causal systems at the
lowest level we may have something like our automata like the game of life and this automata
they can already be curing complete it's not that they are limited in any way if you give them some
memory and so on they can implement arbitrarily complex structure if you set them up in the right
way but you need to do this from the outside where some kind of design process the only
automaton that might be able to do this without it with a random starting state is our universe
itself that might be a big automaton at its bottom level and it just happened to inhabit a region in
it that has interesting enough complexity to contain us if you look at a mechanism that is
slightly more complicated than causal that an automaton that's usually a stateful thing and it
is entwined with a substrate here I used as an example the famous machines by
sorry my brain is blanking out
sorry Tanya you know his name
Theo Janssen Theo Janssen Strandbeest and he has been building these amazing machines that are
usually driven by wind power and they're completely mechanical things that are
fully coupled with the environment that don't have an existence that is in the sense independent
of the environment and if you look at feedback systems you can have open loop systems that are
coupled for instance in oscillators you and in synthesizers you produce interesting patterns
that are the result of some static coupling and if you make this coupling dynamic for instance
in the regulator for a steam engine you can have a cybernetic control system and the controller
in a cybernetic system is built by having a system that cares about the target value and
wants to minimize the distance to the target value and if you extend this controller with
computation you can get an agent and to have this decoupling of this ability to model the future
you need to have a system that is a computer a Turing machine in some sense is a mechanism that
is disentangling itself decoupling a causal structure from the underlying dynamic of the
universe the interesting thing about our computers is that they do the same thing regardless of what
the environment is doing they work the same way whether you are carrying them to america and new
york or whether the temperature is a few degrees higher or lower or whether your climb the mountain
or go down or whether the wind is blowing or not and the same kind of computer also exists
inside of our scouts it's a slightly different one but this principle of the computer is that
enables an arbitrary causal structure and you need to have this arbitrary causal structure to
be able to make models of the future right because you want to look at different futures
regardless of what the universe is doing right now and the simple system that we know in nature
that is in the sense Turing complete and has the powers of function approximation
and self organization to achieve that is the cell so the cell basically is able to perform
computations that are decoupled from its immediate substrate and that enable the cell to make models
that predict the future so the cell can regulate against future disturbances and keep itself stable
against these disturbances so that's why the cell as such a complex system is able to exist
so the cell is an agent and an agent is basically a controller combined with an internal setpoint
generator and the ability to model the future so the agent is not just acting like a thermostat
on the next frame tries to optimize the state of the next frame but it's integrating the expected
setpoint deviations over the future and tries to minimize them and if the modeling capacity is
sufficient then this agent is able to model different branches of the universe and the effect
that its decisions will have on these branches and as a result you basically get beliefs desires
and intentions all emerging from a simple controller that is able to model the future
so this is basically a minimal concept of agency and agents can start to collaborate with each other
and as groups for agents and groups agents they typically have individual motivation
and a reputation system among the agents that makes sure that their actions are harmonious and
beneficial to the members of the group and a slightly different extension of the group agent
is a state building agent a state building agent is one that scales beyond a reputation system
it means that the individuals do not have to know each other individually to have to
maintain a model of their reputation and that transaction and synchronize this reputation
system somehow like a tribe does a state is fundamentally different from the tribe because
the members of the state become interchangeable they have functional roles now and these state
building agents can grow very large but the size of the state building agents depends on the size
of the effective colonial structure that it can maintain so basically logistics chain to build
such a colony of units such as synchronized the state needs to have a way to impose administration
on its substrate and extract more like entropy from the substrate than the administration costs
and this limits the size of the design of a state building system especially once you
have such a state building system and evolution it's going to compete the similar systems for
the same leg entropy right so you are basically the set of principles that has outcompeted all
other systems from extracting that entropy from your volume of space and to do this you need to impose
coordinated patterns of organization onto your volume of space and this because you're
competing with others limits the size that you can have and there are very few organisms that
have cracked the code and have become infinitely scaling state building agents right most state
building systems have a limited size their design is limited by the stable logistics chain that they
can use to impose their colony onto the environment and this here for instance is the pando forest
it's ash trees in Utah it's one of the largest organisms that we have on earth all these trees
are the same tree they're not just genetic clones for each other but their wounds are connected
this is basically one big tree that can grow as large as it wants it's very old and it didn't
mutate very much since it's gross right so it needs to be evolutionary stable so it doesn't drift
another example for an infinitely scaling state building agent is lindy pizzeria humina it's a
brazilian ant that has spread around the world and all members of this ant of these ant colonies
will not attack each other they will all treat each other as part of the same cohesive colony
with the exception of a few drifted colonies for instance in in the u.s. when they get in touch
with the other colonies they will attack each other so they had some kind of genetic drift
after the colony was established that makes them appear to be strangers to each other but
this species has cracked the problem of becoming infinitely scaling state there's no limit to the
size of this colony apparently and if you look at the design constraints for such systems the
mechanical component needs to have an outside in design by some external agent so it is not going
to exist by itself and it's not able to adapt by itself and then you build a controller controller
gets resilience that can be larger than the mechanical component because it's able to adapt
its states to slightly changing environmental circumstances and maintain an attractor state
by itself via dynamic control and if your controller is able to model the future via
decoupled computation then it's able to integrate future reward and is able to not just adapt itself
to the environment but it's also able to adapt the environment to itself and in a group agent you
can do this on the next level so you basically build an agent that is composed of multiple sub-agents
and each of these sub-agents has its individual motivation and the reputation system to coordinate
the group and in a state building agent you change this reputation system or extend it via
a hierarchy of governments and this thing needs an immune system so the individuals are submitting
to this governance and are not building their own government that is competing with the main
government and you will have limited autonomy of the sub-agents so there will be set up in such a
way that they per default most of them will want to submit to the state building group
rather than doing their own thing and you can see this in humans via basically a domesticated
species of the hominids and as a result you're not just tribal homo sapiens is state building
because most of the individuals in our species are willing to submit to the group before they do
their own thing and if you go to an infinitely scalable state building agent you can do at some
level less than you can do in these other groups because you need to be static you cannot have
an evolutionary drift you cannot adapt to the environment beyond the mechanisms that are
built into the system because if you were to drift then this infinite scale would break and you
would no longer be consistent so if you think of hierarchical governance as a principle we have
a trade of there between adaptivity and coherence in the system the more adaptive it is the harder
it is to maintain coherence and the individual agents here are incentivized to defect from the
system very often and you might have to limit this by having an agent that imposes an offset
to the payoff matrix to the individuals and this is what you call a government and the need
for a government comes not from political constraints or from the desire to exploit people
or something else just game theoretic thing that you can derive from first principles
and the purpose of this government is to integrate the total reward which can happen from bottom up
and to top down the credit assignment to make sure that the individual behavior is adjusted
in such a way that the national equilibrium of the individual agents become compatible
with the common good and this is something that also needs to happen in some sense in our own
brain the neurons are autonomous reinforcement learners and the interaction between the neurons
needs to be coordinated into a coherent structure and Jerry Ailman has suggested that the organization
that happens in our own mind is something that evolves in every individual in some kind of what
he calls evolution he calls neural Darwinism and so maybe the top down process that is harmonizing
about bottom up perception is something like a governance a colonizing agent so our brain
is not just playing free jazz which it does to some extent but it also plays a coordinated
symphony it is serving coherent goals it is has an emergent coherent agent that is forming inside
the organization of the cells it makes our organism more efficient by giving it a coordinated spirit
so how is this relevant to AI current measure learning representations all have an outside
in design and organisms the representations are different the organisms are coupled to
the environments with the features are not static they are functions that basically are operators
on your current mental representation to give you the next state and they're tuned in such a way
that they track the sensory patterns and the features are kept stable and coordinated
via individual controllers so every feature is probably some control structure that maintains
its stability and its coordination with the environment and the entire thing goes beyond
jazz by having some kind of emergent governance that harmonizes it and instantiates individual
features and resolves them and they are no longer necessary destroys the attractor states
this some governance ones that the level of the scene that you currently use to interpret the world
and you have multiple systems of interacting agency in there visit the scene agent that is
trying to predict how the world continues you also have a self agent that is driven by the
motivation of our organism and you have an attention agent that is figuring out which features
to select and harmonize and to instantiate and dissolve at any given moment and in this way
organisms can have an essentialized course of structure but the centralized course of structure
is not like a CPU and a computer rather it's a it's more like the centralized course of structure
in a society of people that emerges as a result of an evolution that makes the society more efficient
and better at competing with other societies so this is very end for today thank you Yosha
right so now we are to the discussion part of the session um let me see what's what we have
in the chat for questions so um first of all uh please feel free if if any of the panelists
has comments about each other's presentations uh please feel free to voice them um and in terms
of questions so first question is from uh Thomas McGee and uh it is not um it was posted I believe
during Yuri's presentation but it may have been to anyone um what are some examples of
multi-stable and metastable neural attractor dynamics would the slow fluctuation of externally
oriented delta theta nom dominated oscillations and internally oriented alpha beta oscillations
be an example of an endogenous multi-stable attractor dynamic in the brain also curious
about some examples of neural heteroclinic cycles well it's a charged question that there are
many components to this uh one of the most beautiful things in in in brain evolution
about scales is brain rhythms now what you would like to know in general about scaling is that
what do you want to preserve and what do you what are you allowed to sacrifice so brain rhythms
are extremely useful on this because they are pretty much the same in every single brain in at
least in the mammals from the mouse to the human and the mechanisms are the same the pharmacological
sensitivity is the same the second interesting thing is that they form a just just to finish this
line which means that the most important thing for the brain is to keep timing preserved and
the reason why timing is so important is because we control muscles and the muscles are the same in
all species and the speed of the muscle hasn't changed in evolution at all so other creatures
have pretty much the same speed so that's probably one of the evolutionary pressures that allowed or
of course to keep timing the same and then you sacrifice a lot you sacrifice a structure you
put a lot of of lines that is axons in a larger brain that are much more much faster conducting
because you have to deliver the information in the same time to a more distant target so then the
calibers of the axons grow and so on and these are beautifully demonstrated by comparisons of the
fibers in the copper scolosum and in the in the retina in the the the optic tract and so on now
these oscillations or rhythms that this questioner asked about form a beautiful hierarchical system
the hierarchies organization is simple which is called phase amplitude coupling which means that the
lower oscillations phase modulate the amplitude or the magnitude of the faster one and the phase
of the fast one modulates the amplitude of the even faster one and so on and so on and so on so
the consequence of all this is that when you have a short period of time and you've got a short
period of an oscillator or short waveform then only events can occur locally when you have more
time and then you have a slow oscillator that it engages all the other ones in a larger neural
space the consequence of this very different from me I probably had this is if I if I understood it
right from from from Dave he alluded to this that that we try to believe a stuff to distant
architectures rather than just the neighbors now this is what the brain does in both ways
namely that most of the organizational pattern is local but the large oscillation is allowing that
local computation is broadcasted locally globally a little bit and the global
computations that is the global oscillations constraints what goes on in any local situation
so this allows this hierarchical system allows you to have a brain syntax to package information
in short chunks and longer chunks so you asked about various various names but for the audience
it doesn't matter let's just call the faster ones gamma oscillations which are about the
20 30 millisecond this could be the content of this is a bunch of neurons fighting together
with the one and only purpose is to discharge a postsynaptic target neuron this could be called a
neuronal ladder now a theta and an alpha oscillation can concatenate several of these slots the gamma
oscillations to a neuronal word and the neuronal word can be combined into a longer segment
so this is the way I think it was Christoph who already mentioned that you know without a
generative rule a syntactical rule you cannot really grow the information content infinitely
but if you have such a syntactical rule such as the brain oscillatory hierarchy then it allows
the brain to generate infinite number of sequences from limited number of elements so this is a
complicated answer to the brain rhythms if you I just didn't furthermore I had a previous book but
that's a short answer. Gary if I can follow up on that is it the case so you're saying these brain
rhythms are extremely conserved across man million species at least and does that mean that the size
of the brain doesn't affect the rate of a given class of oscillation elephants are going no faster
no slower even though they have much more distance in just raw centimeters to cover I mean and why
the hell would that be I mean why because they just stretch the axons out that makes hardly any
difference in the propagation time so I think the idea of physical systems was discussed a couple
of times here now physical systems are different from theoretical creations with unlimited speed
and so on in order to keep the if you look at my mark here it has color and all sorts of features
as you know it has been studied and from Mars we've studied about the blinding issue all these
things have to come together but they have to come together somewhere in a small brain and a large
brain in the same time in order to perceive it and they don't understand why same time why couldn't
it be a little longer in the big brain because we are well not because but this is the speculation
I'm interacting with another species and another species and another species and another species
and all of this if there would be a tremendous you know order of magnitude advantage then in
speed for example I would be that I would think the the short cycles I could expect to be preserved
or forced chemically or something like that but it's the long ones that I would expect could have
more variation so this is the interesting kick brains do this for a goal and we can talk about
the goal a little bit later because this if you are interested in what is preserved in the brain
throughout evolution then my answer is timing and the brain oscillation it's not because the brains
cannot do something else breathing which is also an oscillation a very regular thing is organized
by by about a few thousand neurons that can have several orders of magnitude different in
rhythm you know the ways and the hardware so they are very very different so if you want you can do
it but all the other oscillation that I use for cognition and controlling the body seems to be
preserved everyone thank you and as I mentioned briefly that there is there are beautiful full
anatomical data showing that the the connection between this part of my brain the this part of
the brain is about 100 times smaller in a smaller brain and the conduction velocity is
10 times more in my brain because it's needed that you get there at the same time
cancels out the size the cost is enormous because you have to put myelin and energetically it's so
costly to maintain to deliver electricity from one place to another but this is what brains do
oh that's the same in in digital manufactured computers the more metal you have to run the
more energy you pay the more laters you pay the more area you pay it costs a ton if you want to
crank this clock the same speed on a bigger chip it's a physical system the brain is just like
your chips in a sense in that sense thank you and question two to dirty if you look at the
organization of the neocortex how much of that do you think is the result of deliberate
circuitry building and how much of it is just a stochastic substrate so you point out that the
complexity doesn't very much change to relearning but it's not that the brain starts out with no
structure or the neocortex starts out with no structure after the initial setup of course
and then it forms all this intricate structure after interacting with the environment it
tweaks the structure but the complexity at which a child perceives the world is probably not that
much different from the complexity at which an adult perceives the world even though the
functions are being learned are slightly different but how much of that is basically reflected
via the circuitry and how much is the circuitry just a result of of the learning of for instance
RNA based memory that is stored in the activation pattern or propensity of the individual cells
well the propensity of the individual cells seems to be preserved throughout much of lifetime
so the firing rate of a neurons is almost like a fingerprint that you know you can perturb it
you can do lots of things that it do the same now you take a cortical unit a cortical module it's
called the column and then you can grow it and then many people are very much interested in how
these different columns compute something differently in the visual system versus a thinking
system such as the prefrontal cortex but if you look at the connectivity of these two systems
they are not very different so the commonality is much stronger so much so that experiments have
been done 20 years ago when either a newborn or a prenatal animal is taken out and you take
a piece of tissue from here and you put it here and you change it there will be a relatively
normal brain because this system can tolerate that kind of discrepancy now when you look at
a small brain a large brain and you say how many different types of neurons there are there
then today or these days you know people celebrate if they find one neuron that in the human brain
or in a primate brain that looks a little bit different or genetically looks different than
in the brain of a mouse because the component diversity is relatively limited throughout
the mammalian evolution now having said that the neocortex is a modular system it can just grow
because you can add element and then you need the agent that you talked about the controller
that brings this together that may be the thalamus that allows all these things to be
modulated together work together but there is this different type of organization called the
hippocampus which is a single giant cortical module it is the same structure there is no
modularity in it it just grows from the tree shrew to the whale and it gets larger and larger
because it is quote-unquote designed as a random graph that you would like to go from anywhere to
anywhere else in just two steps and that may be an interesting thing we know why and I don't have a
good answer nobody does so why do we have this this external loops why does the neocortex cannot
solve the problem of the of the what the hippocampus can do but what I learned today is that even in
computer science and everywhere architecture is the primary thing that determines form
defines function and the brain is not an exception from this in fact it's I think the prime example
thank you Yuri so so we have a question from uh Wini Schroll to uh to Christoph and Yuri
looking at your insights is the current architectural paradigm for artificial neural
networks still stuck in an architecture ignoring the endless loop with environment
paradigm of real organisms so despite despite the deep learning advances will we continue
getting more stuck this question has a plus script saying some alternatives like cellular
automata still totally missed the feature of being massively looped or massively parallel in my
opinion also a dead end street and I answer to that I take it as asking is deep learning
the end of the story so to speak and and can that be continued indefinitely by just
enlarging the system or is enlarging the the training sets in my opinion here is that deep
learning is stuck the main problem being that it's uh I priori assumptions it's uh it's fundamental
data model is not tuned to our environment it may be tuned to some particular application
fields but as far as we are and after animal type human type intelligence
deep learning doesn't have the right data architecture that is the reason for it
being very poor in generalizing you know if you show a new kind of object to a three-year-old
child the child gets it after the inspection of a single sample of that object and recognize it
it in under massive changes in color in exact shape and so on and so what deep learning is
poor in is its feet forward architecture which is forced on it by the necessity to
backpropagate the error this is a very poor data format and as I have tried to point out
self-organized networks which differ from what we have today in deep learning structures
fundamentally by having cycles of of connectivity you know lateral connections between
within a layer speaking about a layered system so I think the
enormous efficiency with it with which animals learn or humans learn is something which is
beyond reach of the deep learning paradigm.
Christoph I have a question about conmogoral complexity if you think of physics the conmogoral
complexity of the universe might be very low in the sense that it could be a fractal which has a
simple generator function but the complexity of the particle universe is extremely high
so if we tried to describe the detailed fine-grained structure of the universe around us
we would need an enormous amount of code because we cannot compress it very well
because we don't have access to the underlying function and our position in the fractal
but the description that we are making of the world with Newtonian physics and basically the game
engine that our mind inhabits again has a much much lower complexity so there is basically an
emergent causal structure that we use to predict the world that fascinatingly works quite well
and that can be described efficiently in what you describe as a gigabyte of code probably a lot
less if you write the code down more efficiently than we do and now an interesting question is what
is the actual conmogoral complexity of our mind right the complexity of building a brain by setting
up a self-organization process between the cells is probably relatively low it's not the entire
gigabyte of genetic information but probably more in the order of kilobytes or megabytes
that are required to basically form out the brain as in the self-organization process
but what is the conmogoral complexity of the emergent system if you were to design the brain
as an engineering project from the outside in is this going to be similar to the Newtonian
world where you'll have a relatively efficient structure could we come up with classical AI
architecture to describe the brain efficiently or do you have to deal with the fact that the
effective structure of the brain is going to be very complicated so you will need to have a
self-organization to understand it well my argument was of course that the brain is of low
conmogoral complexity because it can be built with so little genetic information as you said
some people claim or have computed that the 3.3 billion
nuclear bases can be compressed to something like 50 mega mega bit so the complexity is very low
and in order to build the brain you need a process of self-organization that's
as we know starts with a single fertilized cell and goes through divisions and goes
through a sequence of attractor states that's the way the brain is built now our way of building
outside in completely ignore such constraints as are implicit in the organic growth from one
state to the next we can sort of when when putting together blueprint we can we have the full
the full universe of potential patterns we can can throw on onto our blueprint and the only
constraint that we are observing is the design ideas we have in mind so I think of course you can
by by knowing the the exact the procedures of self-organization the the mechanism of self-organization
you can let them play in your computer that you use for the design and get the final result and
then that impose that final result outside in on on a piece of hardware but I find it pretty
against the nature of things to do that so I think complex complex brains artificial brains
will be built inside out and if only they are constructed on digital computers
as a present time I'm simulating all my systems of course on the digital computer what can I do
even on the digital computer you would rely on an organic growth process
generating the final structure as a sequence of intermediate states so I think you are stuck
with self-organization by the way the reason why I wanted to have Dave on this panel is I thought
that it would be interesting to see if there is an interaction between the ways in which
he is designing computers by their self-organizing principles and the way in which we think in
neuroscience and cognitive science about self-organization for information processing
may comment on that he made it very clear that reliability in our digital computers
is solely on the on the hardware level very meticulous by forcing the signals
to decide either for one or for zero with you know these these self-interacting loops driving
the signals to saturation and building on that very brittle as you put it software
now this has two flaws number one the software needs to be designed outside in there is no way
the computer prefers more functional strategies the software prefers more functional structures
less functional structures by itself so all the functional structures must be brought from
the outside in and number two the unreliability he talks about so if on the software level
you have something that is built on redundancy multiple pathways built on attractor dynamics
you can work with you can live with underlying hardware neuromorphic hardware for instance
which is analog which is prone to to a noise noise that is bridled in by these if you if you
want to refer to that as such by the software level bridled in by the by what we now have as
software so I'm completely in tune with David Attlee I love his way of looking at them thank
you Christoph I mean you know this was such a big aha for me because I was raised as a computer
scientist I was raised to be all about efficiency all about correctness and and then to realize
that that was all just purchased on this phenomenal act of redundancy at the amplifier
digital signal level and that you know we were just sort of cruising on that ever since
and yeah so the question is is how can you build bottom up in terms of software
and the idea all that I come up with is that we build simple agents and then we build more complex
agents at bigger slower and more complex agents by combining collaborations of smaller simple ones
and you know exactly how to do that depends on what the actual hardware you're trying to deal with
if you're trying to deal with analog neuromorphic stuff that has one set of affordances that you
now have to figure out how to work with and if you're working with you know I work with you
know stuff that's a little bit more traditional like cellular automata except you know fat best
effort only and asynchronous only and so forth but there's clear set of problems like control of
space and how to reduce variation around space so that you can now do something more specific
and if I could take one one minute I could show a little demo that I wanted to show
because it kind of shows the idea maybe so you know one approach is to just make everything big
and rigid right so so here is a block of wall so to speak and the idea is well but you know
instead we want to do something more adaptive more reactive so this is a a simple cell membrane
that's kind of knocking around and oops and I think I may have just killed it let's start a new one
so much for robustness there you know if god is going to mess it up you know it's not really his
fault but the point is is that you know the existing stuff that we have tries to be rigid
and it counts on the the underlying hardware remaining rigid and so forth okay there's our
rigid thing and but one of the things that we do because there's this terrible problem you know if
you try to be robust but there actually is nothing challenging the robustness the robustness looks
like waste so there's this inherent tendency to start chipping away at the redundancy because if
there's no actual problems then it doesn't matter you can get away with it so it can happen in natural
evolutionary processes as well so one of the things that we do in what we build is we build stuff into
deliberately challenge the system so one of the things we've got is an element called drag it stands
for dynamic regulator and what it does is it just wanders around and randomly erases stuff that it's
next to every so often not all the time and every so often it just creates a new sort of food particle
that can be used for anything so I'm going to flood the world with drag right now and so you
know what we see happen is the the rigid structure gets eaten up right but the
the cell cell I want to call it a cell membrane it's not a real cell membrane obviously this is so
abstracted away it actually does active transport to bring the little food particles inside and it
grows um so this is my suggestion an example uh you know a thought experiment well it's implemented
not exactly a thought experiment of how you can actually start building up that you build first
you build small fast structures then you build bigger slower structures out of multiple units of
these things and we just try to keep going up and at each stage of the operation we're going to have
data sheets saying you know this thing is good for this it'll work at this it'll do badly at that
if you go outside these parameters behaviors it's your fault and so on just like real systems
always have data sheets but computer science never did and it was again because of that same
damn determinism that the hardware guarantee was supposedly providing us
what I really like about your work is that you don't try to imitate brains but there is
beautiful work about spiking neural networks but when you spiked if you can set arbitrary messages
and so you come under the self organization from a completely different angle and I wonder
have you thought about learning systems in this way could you build structure that is learning
new functions how would a meta learning system look like because you have to design eventually
the meta learning right the the last example that I showed this the function optimizer
as a simple example that was actually implementing the psi algorithm that I did my dissertation on
in 1987 and and here it is coming back and one thing that was interesting to me when I was
implementing it in the movable feast machine in this architecture is that it was really hard to do
a bipartite graph where everything was supposed to connect to everything by equally length units
and I ended up not doing it I ended up doing a crossbar switch and putting you know weight
matrix weights at each intersection but then since it's all asynchronous that means that the stuff
that's close to the crotch where they meet is much faster and it's a lot like a georgi's picture
where he showed the simple brain and then the bigger brains wrapped around it with the bigger
loops the slower loops that just fell out in the psi algorithm in the psi implementation that I did
on the movable feast because once again we still had space there's no random access memory you can't
just pretend everything is next to everything so yeah I think so I think it's going to impact
the structure of learning systems in a fundamental way and it's going to be a pain because right
now you can just throw around matrices you can tensor them up and just do the deep learning
things the way people are doing and they're having great fun if I was younger I would totally be doing
that but you know I did my version of it in the 80s and I moved on like that but all of that all
put together is still under the same as Kristoff was saying outside in where you pick the architecture
I've got 10 layers and a concentrator and a convolutional layer and then the transform
attentional thing that's all done by the human and then it's fixed and I want to have
something that's underneath all of that that says you know we can we can do these things
but then we can reprogram them by sending down new software rather than saying we have to throw
out the machine and build a new one or maybe that's the brain goal is to put a lot of effort into
making the system resistant to catastrophic interference and that's the primary goal probably
your brain and my brain never experiences catastrophic interference showed up you know
a car accident or something like that. I like a lot of statements you had Dave my favorite one
was this we have to know what we want first which is an interesting statement because
this is exactly what the AI is about it has to have a goal now on the other hand you your mind
is very fascinated about self-organization and there are two interesting things here you know one
is that it just grows and we don't know what the end product will be the other one is a goal
now the funny thing and this is I think what most of the people don't understand out there
the difference between evolution and and intelligent design is that evolution can be
explained best with a goal but that's just a convenience and of course evolution doesn't
be tremendously tremendously misleading sometimes convenience but virtually irresistible
because it and and we think that says something to Kristoff's point about
low order structure in the environment so that there is some specific thing to want it's not
just like every possible environmental input is equally likely there is structure there that our
brain is trying to latch on to and once it finds it that feels like a goal I want to get better at
doing that and then then we go off to the races then we can do deep learning once we've got
something that says you know I want this this is a good mapping then boom go hill climb and be married
I like that and you know there's a whole big field it's called decision making
but but it's it is the natural you know intelligent design kind of of it sounds like it yeah
St. Augustine's definition but in the real brain decisions are made post hoc
most of the decisions that I made in my life I justified and it looks like decision
after the fact rather than yeah the dig I make is that intelligence intelligence likes to think
it's the captain but really it's the historian there's a there is an excellent question from
Kevin to all of the panelists so what are the panel panels thoughts on artificially creating
the phenomenal aspects of our existence for example consciousness for example there is a what it is
like to recall an episodic memory while basal ganglier learning and memory can operate outside of
awareness connecting to the ideas of chunking and attractors slash complexity rhythms of the brain
and hardware software considerations would we need anything different to go from artificial
intelligence to artificial consciousness and qualia potentially metabolic or biochemical
universities or perhaps artificial conscious computing can already be accomplished without
the bits of info at the molecular level like for an artificial hippocampus medial temporal lobe
system to create what it is like to encode and recall an episodic memory wow can I give a shot
go ahead you know to me at least the state of consciousness in my brain is one where a large
number of modalities like seeing and hearing and wanting and feeling and emotion and the aims I
I'm after at the present time where all these modalities are in sync with each other they speak
of the same thing they understand each other they one responds to the other in a useful way
like when you drive your car a signal coming in into your peripheral vision immediately lets
your your arms turn the steering wheel or your your foot hit the the brake so the phenomenon
of consciousness is one of of integration of all subsystems into one coherent state and I see
that as a an example of of different fragments connectivity fragments in the different modalities
being activated activated by activating the participating neurons of course activated
such that they all fit together into one brain spanning coherent network a network that if it
was given time would just recreate a stabilize itself by the exchange of signals that's how I see
the the generation of conscious states just to add to that you know the organizer is the
brain rhythms the system of brain rhythms they are the ones that bring all this together so
probably that's why it is so important and of course you can see the evolution of brain
rhythms and you can study it your questions the question is more complex I don't think anybody
can give a one-centus explanation about qualia but I can give you an explanation about the
role of the hippocampus for example so I take out my hippocampus and I will probably still know I'm
Yuri Buzhaki I can do a lot of things except that I will be missing my past I will be missing
what is called the no tetic consciousness that is I don't know whether I was an agent of a
episode or not I don't remember anything about my life as being a participant of this and this is
done entirely by one system the side loop of the hippocampus now what kind of consciousness is this
it's a good question because you always say you are awake fine you know your name and you
know that you are distinct from others but I don't know who I am in terms of my history so I'm just
a zombie that lives in the environment and responds according to the socially agreed norms this is
the kind of thing that I think AI can do not so long from now but the feeling of it or being you
and putting you as the first person experienced it this is the big question is that when a AI system
can be saying that I am the viewer I'm the first person experienced rather than the third person
describer of the events out there a bit more optimistic than you Yuri basically our model
of reality is a model of what the world is like right and our model of the self is a model of what
our interaction with the world is like and the model is written for us and then informs our future
behavior so basically it's the historian that is helping the emergent captain that makes a decision
based on the model contents and as a result this story is continued with the consideration that the
emergent captain is making right the entire system is virtual the captain is virtual the the agent
that lives inside of the world that we observe as being us is a virtual construct that is getting
causal power because it would be very useful to know what it would be like for the brain
if such a person existed and coordinated the behavior of the organism right it's a spirit
that is being conjured by the interaction of the cell and the family experience that we have this
feeling of what it's like and the content of what it's like is a model of what it is like to attend
to our model of reality and the purpose of modeling this control so the purpose of our
modeling phenomenon experience in our own mind and being able to access it and reflect on it
is to control the attention that we are paying and the way in which we are coordinating our
inner reality so the issue is that we have to grasp that the consciousness is not physical
it's not something that exists at the level of neurons or physics it is entirely virtual it's
a story and we live inside of that story and the story is being accessed by this loom that
weaves the story to continue the weaving and the contents of the weaving when we reflect on it that
is the reflection that we have that we experience as our inner phenomenology yeah consciousness is
not in one brain no the word consciousness means joint knowledge knowledge of yours and mine
and in russian it's called sasnanya this is for for tatiana which also means you know
knowledge mirroring from you without you i have no idea who i am if i'm the only person in my
own niche and i'm surrounded only by uh alligators i i would have a very interesting
opinion about myself certainly very different than living in new york
interesting uh you know you could interpret consciousness also by saying that the different
parts of your brain know together um as the first thing that's exactly the first view
because now you are you looking at yourself which but you're looking at yourself is your past
experience which is yeah yeah i was i wonder yuri why you think that this particular function of
knowing your own history of of being conscious of your own uh self in as you just said in a social
setting couldn't be modeled in artificial intelligence why would that be a barrier
i don't think there are limits because i there are no limits in in in our world right
i just say this is the most difficult thing to do okay looking at the kind of consciousness
which is just mirroring that aha i know that i'm separate it's a relatively easy one because
the the way how i would approach it as a biologist to say what how can i study these things in an
animal and when i say first person second or third person view then i can study an animal
of a low organization such as a mouse because in every animal the most important distinction is
the self from everything else you know there are boundaries and and so on this is this is a
biological thing that has to be internalized very early on in evolution because that's an important
thing and so this is the egocentric world and then then the allocentric kind of thing that comes much
later because that requires that you generate something that is transferable to the odd organism
which is one of your species you know this is the socialness when it comes up so all these
complicated things such as socialists and individualists can come down to the ego versus
aloe i mean as a as an engineer i i approach consciousness with how can i build it or what
would it take to make a crappy little substitute for it and say maybe it's something like this
and and i think there i can get a little bit i mostly i don't talk about this because i think
the appropriate level of implementation is so much lower than it and consciousness is something
that is kind of architectural and structural that is going to seem much less mysterious once we
earn our way up to that level of architecture but i do have a thought about it and you know
one of the things is is okay so we're we're willing to buy Dave's pitch that we have to
have more redundancy in software software is going to have to start taking over some of the
reliability work which we had said reliability is a hard hard work problem for the first 70 years
and so what that redundancy look like and i think the best example of or the most obvious
wonderful example is in software is unit tests that having tests for code is a redundant representation
the the format of the test and the procedural code that it's testing are getting at similar
dynamics but they get it in a completely different way one does it the other one checks to see if
it was done and so that you know it used to be in computer science when i was young tests were
like oh because you're too stupid to prove it's correct you know but now we live in a different
world where if you don't have tests then you're essentially negligent so that is a kind of software
redundancy right there that is you know you can bite it you can eat it people love it because
it's good and so to cover go dot dot dot way past anything that i can actually cover with an
implementation right now the sense of qualia the sense of consciousness the the guts of it
is going to be that we have these redundant representations one sort of procedural thing
that is we're doing that's actually running our sequencing control what we do move the hand do
this and the other one the historian that folks have been referring to that is describing what
we've done and we're going to get a kind of matching between those two representations
that's going to be like the test going green and that ultimately is going to turn out to be the
contents of conscious experience that that green loop when the test is passed we now have told the
story that's my engineer story thank you dave so one last question from the audience i'm sorry
we couldn't get through everyone's question so this one is from Paul Cassidy to everyone
which thinkers theories and concepts are you currently finding most fascinating and stimulating
these can be either directly related to the discussion topics or not highly creative and
interesting people are the best to get recommendations off in my experience
thinkers theories concepts most fascinating and stimulating geez you know the funny thing is for
all the engineering and science i try to do i really don't have that much time for non-friction
so you know i see i feel like i learned a lot much more about the world from fiction you know i
don't know how to say it so all i can say is at the moment i'm reading walk away by cori doctoro
and i'm finding it fun you know two authors who are often cited these days in circles that discuss
consciousness are julio tononi and bernard bars and both of them actually talk in different ways
about coherence of the state brain-spanning coherence of the state in tononi the the basic
idea is the space of all possible states of neurons in the brain is reduced by connection
so if if you cut the brain in half then the two halves are free to to to to think to to create
states they wouldn't be able to to to to create in the presence of the influence from the other
half so that is the kind of you know he talks about of course entropy and such things whereas
bernard bars thinks consciousness comes to comes into existence by there being a central blackboard
a kind of exchange medium in the middle in the virtual middle of the brain to which
all the different agents all the different submodalities can put stuff and from which they
can read stuff so again a kind of a means of creating order of creating a coherence in the
whole thing in in many of the discussions i've seen these are referred to as the main theories
whether you like it or not so christoff what do you think of integrated information
tononi stuff to you to buy in yeah yeah i i agreed with his basic idea but i mean you cannot make a
whole career out of out of this idea with a five function you cannot measure it you cannot compute
it you cannot deduce anything from it it's a nice thought i share the thoughts but so what
yeah i don't know i find too narrow the the different modalities my brain cannot speak
the same language they cannot communicate in the same language on the blackboard so they speak
different pairs of languages and so that i find that too narrow yeah to me it seems it's metaphorical
at best and even if it's a metaphor i don't know if it's a good one but it's well it seems popular
i mean just like the mark how blanket stuff seems popular but it seems i don't know i have trouble
buying it thank you i'm an active reader i'm an active reader i read a lot but i cannot make a
short list of whom i would recommend because every single time i find some great idea what
fascinates me most is that how far i have to go back in history to find the same idea
you always do so i my my favorite books are always old yeah okay i remembered you mentioned
in the during the prep session you mentioned the uh prepared unprepared counter counter prepared
concepts who was that by selling month i can send you the reference right away
so now for example you know that one is a extraordinary person when we talk about you
know in my book inside out i go back in time and i realize that you know i maybe i have to go all
the way to plateau because that's was they ought to be this side out but then seligman and many
others the brellan and brellan that we discussed at the before the meeting they are great thinkers
you know ideas come by every 50 years you know small editions come by every day
so the brain cycles do continue to lower herds very low indeed of the most interesting current
authors uh ted chiang i think and uh greg egan i think greg egan is probably the most interesting
philosopher of mine who's currently alive um greg and this last name is egan egan i certainly
will pitch permutation city to anybody yes closer yes as books to read
yes it's uh also very beautiful um mathematically inspired short stories he's
he's a very mathematically inclined and physically uh physicist inclined person who
plays a lot with his ideas in his mind and it's not uh story driven the things that he writes the
stories are vehicles to explore ideas and mental fractals it's quite beautiful and intricate
but i do agree with viewers uh statement that most of the good stuff is actually quite old
i learned a lot by reading kan and um i also um besides that i never found them that exciting
i grew up with him and now i realize he's very good he just was not exciting because he was just
the intellectual ground zero where i grew up it was just so normal but it's still very good stuff
excellent thank you yosha so uh with this we wrap up um we would like to thank intel labs for
allowing us to host this event and uh we would like to thank all of the presenters for participating
and for delivering these amazing presentations and a lively discussion afterwards the uh meeting
has been recorded and will be posted on our youtube channel the link can be found in the chat
and the chat log with all the references uh will also be posted on our website so don't worry you
don't need to copy paste anything in a rush it will be there um with this thank you everyone it was
great meeting you all thank you the audience for participating and enjoy the rest of your day
thanks to all our guests it was amazing and thank you tanya for having with the organization
and doing the moderation today thanks everyone thank you thank you nice meeting you guys
bye bye absolutely it was great
