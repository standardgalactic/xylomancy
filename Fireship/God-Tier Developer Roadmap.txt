You've likely seen videos on YouTube telling you the number one programming language to learn right now if you want to be rich.
That's not what we're doing today.
Instead, we're going to travel to the deepest, darkest depths of the software engineering field
to discover the programming languages that are loved, hated, beautiful, ugly, compiled, interpreted, useful, weird, and everything in between.
If you make it to the end, you'll have a roadmap for everything you need to know to land a job as a junior developer in 2023.
Or it might just make you extremely depressed because this iceberg is just the tip of the iceberg of what you actually need to learn.
Choose any language and you'll find another iceberg within this iceberg that goes on forever like a Mandelbrot set,
which ironically you can represent in code with any one of the languages we're about to look at.
Before we get started, there's quite a few programming icebergs out there.
But this one ranks languages based on where I think you might encounter them as a beginner learning how to code from scratch.
Each level has its own theme, so let's get right into it, with languages that are designed to make programming as easy as possible.
If you know absolutely nothing about programming, the best place to start in my opinion is Scratch.
It was developed at MIT, like some other languages on this list, but instead of typing out code,
you drag and drop these blocks together like Lego bricks to represent things like variables, control flow, and operators.
It makes the thinking process behind programming much more accessible, and you might be surprised at what you can actually build with it.
Long before Scratch, though, we had BASIC, or Beginner's All-Purpose Symbolic Instruction Code, which came out of Dartmouth in 1964.
At the time, FORTRAN was all the rage, but it wasn't beginner-friendly.
BASIC provides a bunch of basic commands, like print, go-to, and for, and was included in most personal computers,
which made it the go-to option for people learning to code for the next 50 years.
Now moving on to the next tier, we have the extremely popular, dynamic, high-level languages.
The language most people start with today is Python, primarily because of its minimal syntax.
It doesn't require curly braces, semicolons, and stuff like that, and instead uses indentation to represent different blocks of code.
The other popular, high-level language is JavaScript.
Syntactically, it's pretty ugly, but it's a requirement if you want to do web development, and almost every developer will have to touch it at some point in their career.
Any application that can be written in JavaScript will eventually be written in JavaScript.
Now, after learning one of these languages, you'll be able to build pretty much anything you can imagine,
and you could have an entire career as a software engineer without going any further down the iceberg.
But you don't want to be on your deathbed wondering if you should have tried out PHP.
On this next tier, we have languages that are extremely popular, but a little more specialized.
Programmers like to get things done from the terminal, and there are scripting languages like Bash and PowerShell
that allow you to interact with your computer programmatically.
Instead of typing out the same commands over and over again, write a Bash script to make it reproducible.
Now, if you get into web development, you'll also need to learn HTML and CSS,
which when combined together, arguably form a Turing-complete programming language.
They're not used for programming in the traditional sense, but rather to define the structure and style of a website.
And if I were to say HTML is not a programming language, I would be immediately canceled by the tech community.
In addition, most apps need a database, and the most common language for working with databases is structured query language.
You can call it SQL, SQL, or SQL.
It is Turing-complete, although not used for regular programming, but rather to read and write data in a relational database.
Now, Python is great and all, but there are many other dynamic languages that might be a better fit for certain projects.
Like PHP made it easy to build server-side web apps in the 90s, and is still very popular today.
Lua is easier and faster than Python, and is embedded into many engines like Roblox and World of Warcraft.
Ruby is an easy-to-learn object-oriented language, also commonly used to build web apps with the Rails framework.
If you work in data science, you'll come across R, which is used for statistics and data viz,
or Julia, a more modern option, also used for scientific computing.
The one thing all these languages have in common is a dynamic type system.
However, as you build more complex software, you may realize that you need a more rigid framework,
and one way to accomplish that is with a static type system.
This tier makes up the bulk of production code out in the world.
First up, we have Java, which kind of revolutionized programming with a Java virtual machine.
It compiles to bytecode that runs on the JVM, and that allows developers to target any computer architecture from a single codebase.
Syntactically, it's an absolute dumpster fire for beginners.
I made an entire video about why people hate Java, but having explicit types in your code can make it much easier to understand and refactor.
And modern IDEs like IntelliJ will pretty much make the code write itself.
Java is legendary, but it was followed up by Microsoft with C-Sharp.
It's similar to Java in many ways, but gets a lot more love from its users.
It's used to build games with Unity as well as web and desktop apps with the .NET framework.
Another well-loved tool from Microsoft is TypeScript.
It takes JavaScript and adds a type system on top of it, making it much easier to work with on large complex projects.
If you're building a mobile app today, you'll likely be working with Kotlin for Android, Swift for iOS, or Dart with the Flutter framework.
These languages are all statically typed, but they go about it in a more modern, concise way with features like type inference that minimize boilerplate code.
Next up, we have Go, which is a high-performance language developed at Google, to build low-level systems.
It was designed as a replacement for C, and Ken Thompson, one of the original creators of C, helped design it.
The syntax is nice and concise, making it approachable to beginners, and it has a garbage collector, which means unlike C, developers don't need to worry about manual memory management.
Okay, so at this point, we've reached the level of the iceberg where most people are afraid to go any deeper.
Things are going to get weird.
What happens is that many developers get jaded with these big, heavy object-oriented languages and go searching for a better way.
At this level, we have functional languages, the most famous of which is Haskell.
Instead of classes, inheritance, and all kinds of crazy design patterns, the only abstraction you really need is the function.
It was inspired by the Miranda language and is named after the mathematician Haskell Curry.
Most importantly, variables are immutable and functions have no side effects.
Surprisingly, you can build almost anything with these limitations, although most production code out there is not functional.
Most of us run into problems when trying to figure out what a monad is, which in layman's terms is just a monoid in the category of end-functors.
Haskell is great, but Microsoft developed a functional sister language to see sharp called F-sharp.
Unlike Haskell, which is purely functional, F-sharp is also imperative and object-oriented, making it more approachable to developers coming from higher up in the iceberg.
Now, if you hate Java, a good alternative is Scala.
Like F-sharp, it supports both object-oriented and functional programming, but it runs on the JVM.
It's statically typed, but there's another JVM language called Clojure that is both functional and dynamic.
This makes it more well-suited for getting things done quickly with the trade-off of type safety.
Other popular functional languages include OCaml, which is used extensively at Facebook, and Elixir, which has a very nice ruby-like syntax,
and is capable of building high-performance, real-time web apps.
There's also Elm, which is a purely functional language that compiles to JavaScript, which can build front-end UIs with zero runtime errors,
but now it's time to go one level deeper to the heart of the iceberg.
These languages are absolute chads.
They're low-level systems languages that can manually manage and optimize memory and are used to build things like operating system kernels and compilers
that make all the other soy-based languages possible, the most legendary of which is C.
It was used to build the Windows, Mac, and Linux operating system kernels, and its curly-brace syntax inspired many other languages on this list.
Surprisingly, it's not all that hard to learn and has a relatively small set of keywords to memorize.
However, being able to use it effectively requires extensive knowledge of algorithms and computer architecture.
For example, C doesn't have hash maps or dictionaries, so you'll have to learn how to code up that data structure on your own.
C was the perfect programming language when it came out in 1969, but it only supported procedural programming and eventually developers wanted more.
C++ was originally a superset of C designed to extend it with object-oriented programming patterns, like classes and inheritance.
Unlike C, it's extremely hard to learn and provides many opportunities to not only shoot yourself in the foot, but blow your entire leg off.
This is a reference to manual memory management with pointers, which got that name because they're just as dangerous as pointing a gun at someone.
Despite its learning curve, it's an extremely prolific language used to build highly optimized software like game engines, compilers, and so on.
C and C++ are still extremely relevant today, but the modern Chad tends to prefer Rust for low-level programming.
It doesn't have a garbage collector, but unlike C and C++, it uses a technique called borrow checking instead of pointers for memory management.
This makes it much easier to write memory-safe programs and consistently ranks as the most loved language in the world.
The languages on this tier are extremely popular, but now we descend further into the modern languages that you probably haven't heard of.
First up, we have V, which is a high-performance systems language that feels very similar to Go, but unlike Go, it doesn't use a garbage collector.
And unlike Rust, it doesn't do borrow checking, but it can still create memory-safe applications with its own auto-free innovation where the compiler basically cleans everything up.
I have no idea how it works, but it looks cool.
Another modern replacement for C is Zig.
It's designed to simplify low-level programming by eliminating features like macros and metaprogramming and is very explicit when it comes to memory management.
And it can cross-compile C and C++ just like Clang.
Zig is not to be confused with Nim.
Another high-performance language that's very expressive like Python, but is statically typed, and interestingly, it has a tunable garbage collector that can be turned off altogether to enable manual memory management.
Recently, Google announced Carbon, designed to be a successor to C++.
What makes it special is that it can fully interop with a legacy C++ codebase.
Another low-level specialty language is Solidity.
It's a statically typed object-oriented language, but is designed for implementing smart contracts, especially on the Ethereum blockchain.
Then we've got Hack from Facebook, which is designed to interop with PHP.
The original website was built with PHP, but they needed a language with better performance and a type system to scale it up to the monstrosity that it is today.
There are many other good modern languages at this point in the iceberg, like Crystal, Hack, and Faro, just to name a few.
But now it's time to go down to the next level, where we look at languages that are still either widely used or historically important, but not something you would likely choose to program in.
Fortran was the first high-level programming language, and was by far the most popular language for many years until C came around.
Not long after Fortran, Lisp was invented in 1958.
It pioneered many ideas we take for granted in computer science today, like dynamic typing, higher-order functions, recursion, and repel.
It inspired many other languages like racket, scheme, closure, and to a certain extent, JavaScript.
Another highly influential language that came out this year was Algorithmic Language.
It's a big, complex language and never got as popular as Fortran, but its type system and use of expressions had a major influence on the development of C and C++.
The following year, in 1959, Kobal was born.
If you want to make money in the 2020s, learn Kobal, because over 40% of banking systems still use it, with over 200 billion lines of code in production today.
In 1962, APL first appeared, which stands for A Programming Language.
It implements linear algebra directly into the language with a multi-dimensional array or matrix being the central data type.
This leads to extremely terse code that resembles mathematical notation and makes heavy use of the Greek alphabet.
In 1970, Pascal was invented and took the programming world by storm.
It's a procedural language with a familiar syntax and also had very fast compile times.
It eventually became the most popular language in the early 1980s before the rise of C a few years later.
There are many other important languages from this time period, like Simula, the first object-oriented language that went on to inspire Smalltalk,
which itself inspired many other object-oriented languages like Python, Java, and Ruby.
Then there's Erlang, a concurrent functional programming language that basically powered the entire telecom industry and is still in use today.
There's Ada, a general purpose language named after Ada Lovelace, who's generally considered the world's first computer programmer.
It was extremely popular in the 1980s and is still used today by the Department of Defense to blow people up.
In addition, we should mention Prologue, the language that pioneered logic programming and meta-language,
which pioneered the polymorphic type system used by other statically-typed functional languages like Haskell.
There are many other historical languages we could talk about, but now it's time to descend into the realm of the esoteric,
where we find rare and bizarre languages that feel more like works of art than engineering tools.
The first known esoteric language came out in 1972 and was called Intercal, which stands for compiler language with no pronounceable acronym.
It was designed as a parody to make fun of the languages of the day, like Algol and Fortran.
It has an entire paradoxical reference manual that makes no sense and has an interesting choice of keywords like please and mingle.
Please doesn't actually do anything, but it makes you a more polite programmer.
Next up, we have brainf**k.
Brainf**k is most well-known for being extremely minimal.
Urban Mueller created brainf**k in college and it works by initializing an array,
then gives you a pointer and eight different characters to manipulate memory in that array.
This results in a codebase that will f**k your brain up.
It inspired another language called male bulge, or maybe it's Malbulgia,
which is named after the eighth circle of hell in the Divine Comedy or Dante's Inferno.
If you thought brainf**k was difficult, this language takes things to a whole other level.
It makes programming so difficult that I can't even summarize how it works in a single sentence.
If that's a little too dark, a far more fun language is Chef, which is stack-based
and is designed to make your code look like a cooking recipe.
Instead of concise keywords, it uses sentences like put ingredient into mixing bowl to push a value onto the stack.
Put these commands together to create a hello world souffle, then specify how many it serves to write it to the standard output.
That's pretty cool, but it may seem kind of silly to an intellectual.
The Shakespeare programming language will make your code look like a Shakespearean play.
It provides the low-level control of assembly with the verbosity of 16th century poetry.
But if words aren't really your thing, then a good language choice would be piet,
which is named after piet Mondrian.
It's also stack-based, but you write code utilizing patterns of 20 different colors on a bitmap image.
The end result is a code base that looks like abstract art.
Now, if you're a crazy cat lady, you're really going to love this next language, LOL code,
which provides a developer experience similar to an LOL cat meme.
You open a program by saying hi, then end it by saying k thanks bye.
Loops can be performed with I'm in your or broken out of with I'm out of your.
That's nice and easy to understand, but it would be even better if it included emojis.
Emoji code is a language where the syntax is entirely based on emojis.
Modern developers like to use so many emojis in their documentation
that this language would just streamline the entire process.
It's a fully-featured object-oriented language
where you can define code blocks with grapes and watermelons,
classes with rabbits, and generics with shells and eggplants.
Another language that's not necessarily esoteric is C minus minus.
It's designed as a portable assembly language that borrows heavily from C,
but omits many of its features.
The ultimate dialect of C, though, is Holy C,
which was created by Terry A. Davis and used to build Temple OS.
An operating system written under the direction of God.
Holy C is actually really cool because it works like C,
but it's just in time compiled on the operating system,
which means you can use it like a scripting language
that can interact directly with the operating system kernel.
And that brings us to the final tier,
the absolute lowest level you can go with your learning as a software engineer.
Assembly is a language of which there are many variations
that correspond directly to the architecture on the CPU.
Different CPU architectures like x86 and ARM
require different machine code instructions.
Assembly allows you to represent this code with simple commands
that manipulate values on the CPU's registers.
Now, if that looks too easy, the next level down is machine code.
At this point, we're looking at ones and zeros, or raw binary,
usually represented in hexadecimal format.
To code at this level,
you'll need to have intimate knowledge of the computer's architecture
and also be able to count in binary.
But if we go beyond machine code,
now we're looking at billions of transistors on a CPU.
A single transistor represents one bit, like a one or zero,
by controlling the amount of electricity that flows through a piece of silicon.
Now, in order to do anything useful,
the transistors need to be organized into logic gates,
like not, and, or, exclusive or, and so on.
Ultimately, it's these very simple chunks of logic
that perform the miracle of taking some electricity as an input
that can produce some other electricity as an output
and do it billions of times per second all over the world
so you can play video games with your friend in Vietnam.
If that was too easy,
then you may want to look into the field of quantum electrodynamics.
You fully understand how these particles behave in the electromagnetic quantum vacuum.
You can then use your skills to build a next-gen, blazingly fast quantum computer
and become the richest person in history.
At this point in the iceberg, there's only one place left to go,
the scariest place of all, yourself.
Once you know everything,
the question becomes,
what is knowledge?
Epistemology is the theory of knowledge
and philosophers still don't have a good answer to this day.
Reality only exists within my own mind.
For all I know,
the entire external world and all the knowledge I've acquired
are just illusions and projections from my own ego.
Maybe there's a god-like being
that controls all the sensations and knowledge received by my mind,
or perhaps my real body isn't a vat of goo
and I'm already living in Zuckerberg's Metaverse.
Or maybe I never came out of that ayahuasca trip I took ten years ago.
The only thing I really know is that I know nothing.
Thanks for watching and I will see you in the next one.
