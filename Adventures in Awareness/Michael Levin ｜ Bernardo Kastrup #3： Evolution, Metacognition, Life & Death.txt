Tonight is, for the most part, a dialogue between Michael and Bernardo on topics that
will include evolution, platonic realm, metacognition, boundaries of self, potentially life and death,
some new research that Michael has to talk about.
And then if there's time, oftentimes there's less time for Q&A in the sessions where we
have a guest, then we'll do Q&A for sure.
And then if there isn't time this week, then we obviously have Bernardo back for another,
I think, three weeks before we have another guest.
So, and Michael, you do quite a lot of, are there other formats where people can follow
your work with this Q&A opportunity if someone's not in a kind of institution?
Yeah, the closest is the blog.
So people will often either comment on specific blog posts or just email me questions.
If they're good questions, I will eventually post the answers on the blog.
So I'll do, I've got one scheduled, one set of Q&A scheduled for, I think, next week
from some stuff people sent me.
So, yeah, yeah, you can always, like a live Q&A or one that people write in?
For now, it's been writing, I am actually going to schedule a live one.
That is something that I want to do.
So I'm just figuring out some other logistics, but I will, I will do that.
Cool.
Feel free to send us the details and we'll send it out to this community as well.
I'm sure people from here will join.
And also, yeah, just to tell everyone that I've been following this blog.
I'm not trained in science, didn't even do biology at high school.
And I'm still able to follow the core ideas.
And you write in such a fashion that someone without scientific training can follow.
So I really appreciate that.
Well, thanks. That's, that's great.
Yeah, that's, that was what I hope.
That's great.
Yeah, and I'm learning a lot.
And sometimes I use a bit of chatGPT to fill in some gaps.
I'm a little late.
Sorry about that.
Cool.
Welcome.
Maybe nervous there for a second.
Have I ever let you down?
Not yet.
Cool.
Great.
So welcome.
How are you doing, Bernardo?
Say it again.
How are you doing?
I'm okay.
Had a busy day so far.
I'm still a bit out of it.
I have to take three deep breaths and be here.
I'm going to get there.
So potentially you can relax and enjoy for the first few minutes.
I was discussing with Michael earlier that maybe we could start on some of your
thoughts, Michael, on evolution.
You mentioned a couple of papers or new research that you might want to mention.
Does that feel good for you?
If you kind of discuss a little bit.
Thoughts and evolution potentially into the platonic realm.
Sure.
Yeah, that's, that's fine.
Okay, cool.
Okay.
Well, let's see.
So in somewhat random, random order, and there's a couple of, a couple of interesting
things that have come out of our lab recently.
One has to do with this notion of hyper embryos.
And what we were looking at is horizontal information transfer between embryogenesis.
Normally, normally you get this idea that you've got an embryo and the reason that
that embryo is able to complete its journey from being a single cell to being a complex
organism is because of its genome and the maternal proteins that are in the egg.
And so it's kind of vertical, right?
It's all this stuff that's handed down by the mother.
And so one of the interesting things that we discovered, and this was, this was led
by a PhD student in my group, Angela Tong.
And what we found is something really interesting that when you challenge a
collection of embryos with some kind of the teratogen, the teratogen is anything that
tends to disrupt their ability to complete development normally.
So this could be a drug.
It could be a genetic change.
It could be a vibration.
It could be all kinds of things.
So it turns out that when you challenge them with something like this, it turns out that
large groups of embryos do much better at resisting it than small groups.
And when we studied it, we found out that not only is there kind of like this this this
group effect, but also it is not sufficient to have a group that's made up of some
individuals that never got challenged in the first place.
And what the reason that the reason this is important is this, our initial very
simple model for what's going on, why would large groups of embryos develop
better than small groups?
Initially, you might think that, well, what's happening is that if everybody's
getting affected by some kind of perturbation, then by the sort of by the kind
of group collective intelligence idea that everybody has some gaps in their
knowledge of how to make an embryo, but everybody's gaps are in a different place.
And so as long as they all exchange information, then everybody can have all
the information they need, right?
That's a very simple way to think about it.
It's the way they used to do this thing where people would guess the number of jelly
beans in a jar in a store, right?
And no individual person was ever close, but the group actually, if you average
the group, they were always, you know, spot on.
So it's like the wisdom of the crowd kind of thing.
So initially we thought that was it.
But if that was it, then what you could do is you could make a large group that's
composed of a bunch of embryos that were exposed to the stressor and then a
bunch of embryos that were never exposed.
And those would have all the information they need.
And that should be even better, right?
Because they could then instruct all the others because they're not stressed
out, they would have all the, all the information.
Turns out that doesn't actually work.
It, the only individuals that can help the group do better is ones that have
been exposed to the stressor themselves.
It's kind of this weird thing.
Like Mark Solm told me once that in psychoanalysis, you know, in order to do
psychoanalysis, you have to have been yourself, psychoanalyzed, right?
It's this kind of like participatory thing.
So it's, it's, it's kind of interesting that, that you can only help if you've
already seen that stressor.
And then we use some tools to actually see the embryos communicate with each
other.
It's pretty wild.
You can actually see waves of, of, of information that were born by ATP and
calcium signaling and some other things that are, that sort of propagate across
that, across the collective.
And it has a couple of implications.
One implication it has is that, lots of prior studies that look at the toxicity
or of various compounds, but didn't actually look at, well, how many embryos
did we expose at one time, right?
All these studies use different numbers of, you know, tzibberfish and tadpoles and
so on.
All of those numbers are actually not correct.
What you're getting is not an assessment of how dangerous is that compound, what
you're getting is an assessment after it's been corrected for by the group.
So what you're not seeing the raw effect, you're seeing the, whatever effect is
left over after the group has done its, its repair, repair functions.
And, and so, and so this is, this is, this is very important because what it
suggests is that the information that's needed to be, to have very stable development
is not just vertical.
It's not just something that every embryo has everything they need and all of that.
It's actually a kind of a group construction project.
And not only functionally does the group do better than the large group do better
than the small group or individuals.
We looked at gene expression and we asked what novel genes do large groups express
that small groups and individuals don't express.
And there's a huge collection of new genes that they turn on, which suggests
that this idea that normally in developmental biology, what you're
studying is the way individual cells help each other and cooperate and compete.
And then, and then you get this nice, nice embryo as a result, you can take
that one level higher and say that, okay, so that's embryogenesis, but there's
a kind of hyper embryo, which is the large group, which has its own dynamics,
which you can actually complete the journey better.
And we can see the communication between its parts, between the embryos, and
it has its own transcriptome.
The large, this, this hyper embryo actually has its own set of gene expressions
that, that it's, that otherwise its parts wouldn't have.
So it's, it's a really interesting example.
You know, we study a lot the collective intelligence of individual cells and
how it scales up to be this, this amazing morphogenetic system that can create
anatomies and repair them and so on.
But I guess it goes one step further.
It's actually the individuals are talking to each other too.
And you can imagine from that, you can imagine some therapeutic applications
because what if you could, what if you could fake the effect, right?
So what if in the therapeutic context, once, once we understand what it is that
they're saying to each other, we could possibly, we could possibly impose that
artificially in therapeutic context, whatever the, whatever the signals,
you know, whatever the signals are.
So we're in the process of trying to understand what, what, what, what the
communication is like, what are they saying to each other really?
It's quite a puzzle because the information that you need to actually
create a complex embryo is, there's a lot of information.
It's unlikely that all of that information can be propagated by something as
simple as a signal, a single, let's say a level of ATP or something, whatever
the, whatever the molecules are going to end up being.
So they must be modulated somehow.
It's really interesting to ask how are they actually communicating and what
are they, what are they actually saying to each other?
So, yeah.
And then, and then just this notion of, you know, the fact that, yes, you've
got individual genomes that do their, their job within individual embryos,
but, but the magic of morphogenesis and that collective intelligence doesn't
stop at the border of the individual.
It actually is able to use the computational power of the large collective.
So that's, you know, that's, that's, that's one of the things that we did recently.
Anybody, any questions or comments about that?
Someone asked, horizontal gene expression, like in mycelium.
Just someone just been reading entangled lives.
Yeah.
Yeah.
I mean, yes and no, right?
Yes, in the sense that what the genes that one embryo express are going to
affect the genes that, that, that others in the group express, but we don't
think we haven't the fixed, you know, concis, conclusively ruled out, but we
don't think it's that it's literally propagating the material.
Like it's, like, we don't think it's propagating transcription factors or
anything like that.
I think what's happening in this, this issue will come up again when we talk
about some, some new thoughts we had on memory, that what it's doing is
basically compressing a large amount of information into a very narrow
communications channel.
So something that can be easily encoded by small molecules that are propagating.
And then the recipient embryos have to sort of reinflate it or reinterpret
it for their own, for their own context.
I have a feeling that's what's going on.
But yeah, in effect, what you're seeing is, is horizontal transfer of
information that ends up controlling gene expression.
So just a super naive question.
So you've got an embryo that will do something specific on its own, and
then it behaves differently if it's surrounded by lots of other embryos.
So with a human, I'll just be like, okay, well, human can count.
We're like, great, there's lots of people around me.
You know, I'll copy what they're doing.
But is it just passively receiving it from the human?
Because presumably you don't think they're metacognitively counting how
many embryos around them.
Does the question make sense?
Yes, yes, yes, it does.
I don't have any evidence that they're aware that they're counting for sure.
I'm not claiming that.
But I think that what's happening is, and we actually, in the paper, I mean,
you know, if anybody's interested in the details of the computational stuff,
we actually have in the paper, a model of cellulose.
We actually have in the paper, a model of cellular automata acting this way.
That is a noisy cellular automata where each one has a problem
following a specific set of rules.
But there's a large collective and they get to communicate and eventually
you get pretty robust communication in the group.
So no, I don't think they're explicitly counting, but I think by virtue of the
mechanisms that couple them together, you in effect get something that is quite
sensitive to the number of individuals in your cohort.
And now at any point, obviously, Bernardo, just feel free to comment or
speculate if something Mike was saying sparks an interest.
And is what you just said related to that blog that you put that was talking about a paper
around the surprising emergent behavior of algorithms?
The algorithms, well, I mean, I do think that all of these things are connected in interesting
ways. The algorithms were a different paper. So what we did there, if people want to talk
about that, what we did there was, you know, one of the things about biology is that
when you look at systems, no matter how simple you think it is, you know, even if it's some kind of a
you know, a microbe or something, there's always more mechanism, there's always more
different components and different amazing things that you didn't know were there.
And so that that makes it kind of hard to really study emergent surprising outcomes,
because someone could say, well, there's probably a mechanism specifically for that,
you haven't found it yet, right? So what we wanted to do was to
really come up with a system that is extremely minimal, extremely transparent,
where there was no place to hide where it was obvious what all the parts were,
and then use all the tools of the frameworks we've been developing
to ask, okay, is there some kind of emergent
proto cognitive capacity here? And what we chose were very simple things called sorting algorithms.
So for anybody who doesn't do computer science in the audience, what these are are very simple
sets of steps. There's usually the whole algorithm is usually six or seven lines of code. It's very
simple. And what it's designed to do is to take an array of numbers that are jumbled up. So it's
an array of integers, let's say 100 of them, and they're jumbled up in random order. And there's
an algorithm which is a set of steps that will, if you follow it consistently, what it will eventually
do is sort the whole list into let's say ascending or descending order. These are things that computer
sciences have been studying for decades, every computer science student starts out, you know,
learning these things. And the thing about them is that they are extremely, they're simple, they're
short, they're transparent, you can see all the parts. There is no more mechanism to be discovered
and they're completely deterministic. And people think they know what these things do, right? So
you think, you know, we've studied them. And so what we wanted to do was to ask
the question of what surprising behaviors could be hiding, even in something as simple as this.
You know, and it's important because oftentimes, for example, people who do AI and things like
that, you know, somebody said to me recently, there's no emergent behavior in language models.
I know how they're built. I know what all the parts are. And I think this is a very dangerous
attitude. And so we wanted to kind of study this very simple system. And so what we did there was
we visualized the process of a couple of interesting twists. One is that we visualized
the process of sorting these numbers as a walk through through what we call sortedness space.
So they start out in a region of that space where it completely jumbled, but everybody
eventually gets to this place over here where everybody's in order. And they have to sort of
during the sorting, that string sort of makes its way to that spot. And what we did was we said,
okay, instead of having one sort of omniscient algorithm that gets to move around all the pieces,
which is normally what happens, there's an algorithm that moves around all the parts,
what we did was we put the algorithm inside the cells themselves. This again will be important
when we later talk about the memories, because what we basically did made was self sorting arrays.
So what we said is each number, it on its own has the ability to look to its left and to its right
and decide how happy it is about where it is. And if it's not happy, so if I'm a five, I want the
four to my left and the six to my right. And if I don't see that, I want to move somewhere else
where I'm going to be happier. That's it. There is no global control. And so
what we found when you do that, a couple of interesting things happen. First thing that
happens is that it still works. So when you do this and you have this like a self sorting data
where you're erasing a little bit the distinction between the algorithm and the data, because
now the data itself has a little bit of action to it. What happens is, yeah, they still sort,
but now you can do two interesting things. One thing you can do is you can make some
broken cells. So you can ask, what happens if some of the cells are broken? They can be broken in
one of two ways. Either they refuse to move when they are asked to move, or they're completely
broken in that they don't even try to move. They're not just broken for others, but they won't swap
with others, but also they don't initiate. So they're just completely frozen in place.
Normally in these algorithms, you assume that the hardware is reliable. That is, if the algorithm
says swap the four and the seven, they swap and you never even go back to check or did it,
or was it swapped or not? You normally don't check. This again will come up as important.
The importance of unreliable hardware I think in biology and cognition is really critical.
So we made this kind of unreliable hardware example where they're sorting and eventually you get to
some numbers that will not move. They're frozen, and that turns out to be a barrier in their journey
towards being sorted. It's like the definition of intelligence I like, which is the ability to
get your goals met despite all kinds of novel circumstances, perturbations, the ability to
basically to navigate your space and get your goals met. So these algorithms, just to be clear,
there is no code in there about what happens if the number doesn't move. How am I doing? Did the
number move? Nothing like that in there. The algorithm stays exactly the same. But what does
it do when you do interrupt its journey with these barriers that cannot be passed? William
James had this notion of navigating barriers and so on. And there's a concept of delayed
gratification. The deal with delayed gratification is that when you come to a barrier, if you're a
magnet and there's two magnets and they try to come together, you put a piece of wood between them,
the magnets all they're ever going to do is stay there stuck between the wood. The magnet is never
going to go around to get to its goal because it has no delayed gratification. It would have
to go further from its goal in order to get to where it's going. Magnets don't do that. But
some animals do, some autonomous vehicles do and so on. What do these algorithms do? So it turns
out that without any special code for it, what the algorithms will do if you actually track the
sorting. So here it moves along, moves along, it's the sorting everything. It meets the barrier.
When it meets the barrier, it actually goes around and in order to go around, the array
actually gets less sorted over time. It has a degree of delayed gratification. The whole thing
gets worse for a little while until it moves all the other numbers around that broken cell and then
things improve. So it has the ability to temporarily get further away from its goal and it only does
this when it encounters a broken cell. But it has this really primitive but already a tiny
capacity for delayed gratification that is completely emergent. It is nowhere in the algorithm
for it to do that. We had no idea this was going to do that. And so just a couple things and I'd
love to hear what Bernard has to say about it. One thing is this little bit of delayed gratification
and then there was another thing that we found. Because we've now put the algorithm inside the
cells themselves, that lets you do something weird. It lets you create a chimeric array where
some of the cells are following one sorting algorithm. Let's say bubble sort. The other ones
are following a different algorithm. Let's say selection sort or something. So it's like a
chimeric. We make this in the lab all the time. We'll make a frog allotle which has a bunch of
frog embryonic cells with some axolotl embryonic cells and each of them are following different
algorithms. You put them together and you ask what does this collective make? When different parts
are constructing things under different rules, what's going to be the outcome? So we can make
these chimeric strings. We can make these algorithms where the different cells are following different
rules. And then we found something really wild which is this, that imagine that you assign,
we called it, actually this was Adam Goldstein came up with this idea. He called it the algotype,
genotype, phenotype. So this is the algotype. The algotype is the algorithm that any cell happens
to be following. At the beginning, so you've got your array of 100 numbers and it's random. The
numbers are randomly distributed and they are randomly assigned to algotypes. There's two
different algorithms randomly assigned. When you do this, let's just ask what's the probability
that when I look at my neighbor, my neighbor is the same algotype as me. At the beginning,
it's 50% because they're random. So your neighbor has a 50% shot of being the same type of cell as
you are. At the end, after all the sorting is done, same thing. It's also going to be 50% because
the algorithm doesn't care about algotype at all. There is nothing in the algorithm that says what
algorithm am I? What algorithm is my neighbor? There's nothing in there about that. At the end,
everybody's got to get sorted according to their integer value, which means the algotypes again
are shuffled and random. So 50% at the beginning, 50% at the end. But what happens in the middle?
If you track what happens in the middle, what happens in the middle is that we call it the
clustering, this idea of this measure of what's the probability that I like to hang out with
my buddies. There's the same type of things as I am, the same algorithm. It actually goes like
this. So in the middle, it goes up and then it comes down again. It's this amazing
emergent tendency for these guys to cluster during their journey. To me, it almost reflects
like the existential condition of life in the universe. Eventually, the physics of the world,
you have to obey the physics of the world and eventually they're going to pull you apart.
But in the meantime, even though it's not prescribed by the rules that you're following,
you get to do something new and interesting and maintain a pattern at a high level. You get to
make these clusters, these temporary emergent patterns of like-minded data that are sitting
there. Eventually, they're going to get pulled apart. But in the meantime, they're there. We did
some other things. Like we said, what happens if we relieve the pressure a little bit of getting
pulled apart? Give them a little more opportunity to do what they really want, which is to cluster.
And the way you can do that is you can allow duplicate numbers. You can say, okay, we'll have
10 fives and 10 sixes and 10 sevens. And that way, you can sort of have your cake and eat it too. You
can be a bunch of fives in the right place. But the first few fives can be one algotype and the
next few can be in there. And if you do that, they cluster even more. So you can see that the
pressure to cluster is quite significant. They just get pulled apart at the end. So I'll just stop
here. But the point of that whole journey is to just start to look at these extremely simple,
transparent deterministic systems and already find interesting capabilities. And now, I mean,
there's some practical stuff to be done here too, because they're doing this clustering for
free, basically, right? We're not, you know, it doesn't require any additional computational power.
So if that happened to be something useful, or if we coupled it to something useful,
you could imagine getting some more squeezing some more, some more juice out of a process
that's already happening anyway. So I'll stop here and see what I see what Bernardo has to say.
Is it okay Bernardo to just quickly see if a simple example will help anyone that
because I've read it. So I think I'm following you, Michael. But it is a simple illustration of
this is normally a sorting, let's say I've got a classroom full of school full of children,
and I want them all lined up in terms of height. And normally the teacher would stand there,
okay, you stand there, you stand there, you stand there and kind of sorts it from a bird's eye view.
And what you've done is told each child, if the one on the right of you is you taller than you,
swap sides, or for the shorter than you go further that way. And so you've given instructions
to each child to move. Is that close to what you've? Yeah, that's close. And so to following that
analogy, you've told them to sort by height, and eventually they do sort by height. But what you
notice is that halfway through, they also seem to be clustering by eye color. So for some reason,
they're also hanging out together by some other property that your instructions to them do not
reference at all. So there's some other property that they seem to, that they
seem to want to group by. And then eventually, of course, they'll sort out by height, and there's
no necessary relationship between height and eye color. So eventually it'll go away. But in the
meantime, you notice that, hey, there are these groups of similarly eye colored individuals.
Great. And also, each child can only see the one right next to them. Is that how it's set up?
There's a few different, I mean, we use the few different versions of this with different ability,
different radius that they can see and so on. All right. Sorry about it. Go for it.
I'll invite you. I love your work, Michael, but here I depart from you. So I'll invite you to sort
of come into my thought line on this. You, of course, know Conway's Game of Life cellular
automaton. There's an array of very simple cells. And each cell obeys only essentially one rule.
Um, if there are two or three of my neighbors who are alive, then I either stay alive or I become
alive. Otherwise, either I stay dead or I die. That's it. That's all there is. Each cell counts how
many neighbors are alive and decides whether it's alive or dead in the next cycle. That's all there
is to it. And then if you let that thing play out and you see the patterns that the living cells,
the cells that are alive, the patterns they form, we see amazing things. We see cannons firing
projectiles with, we see systems that seem to be swallowing up other systems and growing as they
do that. That's why it's called the Game of Life because we see all these patterns. But would you
concur with me that, ontically, there is only that simple rule. Everything else is an epistemic
projection of us. Yeah, so that's a super interesting and important point. So I do agree that
everything that we just mentioned, the gliders, the beehives, all of this other stuff, it is
absolutely a pattern noticed by an observer, in this case us. But my point is going to be that
I think the same thing is true of many agents in biology. In other words, I think that observing
a temporary physiological object, which is what I think gliders are, right? There are patterns
that move through an excitable medium. I think that in many ways, these kinds of things, this is
exactly what, that's a reasonable way to look at life forms, to look at stress patterns moving
through tissues, to look at genomic information propagating through a lineage agent. I agree with
you, but I think it's actually important. And Randy Beard did this cool paper called the cognitive
domain of a glider in the game of life. He literally tried to take the perspective of the
glider and say, what do you see if you're a glider from the perspective of the glider?
And I think it's a projection of other cognitive systems, and I think that's a great
way to look at a lot of things in biology actually. I don't have a problem with that. I think complexity
science has been showing us very, very compellingly that things that we consider to be very complex,
in fact, aren't complex at all, at all, ontically. The complexity is our own projection of our own
cognitive modes onto the behavior of that thing. That thing is probably just playing out very
simple roles like the game of life. I completely agree with that. As you know, I am an extreme
reductionist. It's just that I don't try to reduce the big to the small. I try to reduce
the complex to the simple, and I think that's the correct way to reduce things. But the title of your
paper, in the title of your paper, you start by saying what do algorithms want? So instead of
saying, look, these high level functions that we seem to see, they may not be there at all. They may
be our own epistemic projections. The title of your paper suggests that you're doing the opposite.
You're imbuing a system made of very simple rules with the kind of cognitive modes that only complex
organisms have, like a delayed reward. Well, why do I delay my reward? Because I know if I have an
inner model that gives me a projection of the future state. But that's not what your numbers are
doing. They do not have an inner model that allows us to anticipate a possible future state to
deliberately delay their reward. The delayed reward thing is purely an epistemic projection
of ours. It's not in the system, but it is in me because I have the model. I experience it. I can
anticipate future states and deliberately delay reward for that. So yeah, that's where I get
slightly uncomfortable because you present this not as eliminating the notion that there are these
higher level cognitive things going on. You present it as if you were imbuing things that
are very simple and mechanic with these higher level cognitive functions. So it's just like
criticism. I do it open-heartedly, Michael. Yeah, no, it's great. This is exactly the
conversation to have. And I think these are valid points. And here's my view on it, a couple
things. First of all, this idea of epistemic projections, I think, yes, I agree with you.
And I think that it's everywhere. In other words, when you look at, so let's look at an embryo.
Basically, for all of these scenarios, I think there are multiple perspectives,
multiple points of view that an observer could take. And you could absolutely take the bottom
perspective, so to speak, and say, okay, look, in the game of life, there are no gliders,
there are no bhebs. All there is is individual fixed cells. Nothing moves. There are individual
fixed cells. It matters, though. What's interesting to me is that these different perspectives,
it's often argued that these different perspectives are a philosophical
choice. They're all as good as each other, and you can look at it from the bottom,
you can look at it some other way. I think it actually makes a huge difference, because
I'm sure you've seen somebody made a touring machine in the game of life using the gliders as
signal pulses. So if you don't believe in gliders, if all you do is, if all you believe in is the
low-level rules that govern each cell, you can absolutely explain any events in the world.
In fact, you can predict forward what's going to happen in that world. You can roll it forward
as much as you want. What you're not going to do is build a touring machine out of gliders.
You can make predictions from a system that's already set up. If somebody makes a starting
position, you can certainly say everything that's going to happen about that. But I think that level
of description limits the generative insight that you have into what can happen, and it becomes
really important in the biology that we study. For example, as you said, there are simple rules.
We look at an embryo. We look at an embryonic blastoderm. There are 50,000 cells,
and somebody will say, there is no embryo here. There are just individual chemical reactions.
They're following the rules. There is no embryo here, and certainly there isn't any
goal state. What I would say is this. You can have that view, but what you're going to miss there
is the fact that all of the cells in that embryo, the reason that what we're counting, when we say
one embryo, what we're counting is the commitment of all of those cells to a particular target in
that anatomical space that they are all going to reach. The reason that I call it a goal and a
target is because, functionally, if you try to deviate them from that target, you can move things
around. You can put barriers. You can do all this stuff. They will find clever ways to still get
there. Now, I'm not saying that this is a metacognitive goal the way that humans have goals, and that you
can reason about your goals. You can set new goals. I'm not claiming that. There's a continuum,
of course. There's a very basic, there's a very basal version of this. But I think that perspectives
that look at the system and acknowledge that, okay, there's a perspective in which none of this
is happening. There's another perspective in which that is happening. It leads you to new
experiments. I mean, many of the things that we've done, we've only been able to do precisely because
we take seriously the idea that, yes, this is a system that in some way has the ability to correct
towards a specific outcome. And so with respect to these algorithms, I mean, you're right in that,
by the way, the paper itself, if you look at the paper itself was not titled, what do they want,
right? The paper had a very much more sort of conventional time. The blog post is titled that
because that's where I sort of say what I think. But talking to Carl Friston about it, we really
talked about testing. And this is an empirical question. I don't know if this happens or not.
But one of the ways you can look at as to why they cluster is the tendency to minimize uncertainty.
So your neighbor, the least uncertain neighbor is the one that's just like you, right? So possibly
you can use the active inference framework to describe why it is that they have a pressure to
cluster together with other beings that are like them. And that's, this comes up in biology too.
So these are all experiments that we can do. But I would say that I think we're both right in the
sense that there is absolutely a perspective to be taken here in which there are only low level
rules. But there are other perspectives on this, which may be useful in terms of finding new
discoveries, making new things. And then I guess my final thing is that I think everything is a
perspective of some agent, you know, everything, not just not not just, you know, some some things,
but all of it, everything. I concur with you that it is operationally useful to think at
different levels of abstraction. So if you're going to build a computer, if you're going to
build a Turing machine with the Conways game game of life, that it's very useful to operate
at a higher level of abstraction, where you're dealing with higher level components, otherwise
you would just be overwhelmed with detail. That is operationally useful. But at the end of the day,
it's a cultural game, right? I mean, I am on the record very publicly saying that you are doing
the most important work in the world right now. And people have come to me and say, oh, look,
Michael thinks algorithms want stuff. Algorithms have will. So AI is sentient. And you are saying,
you know, on a crusade saying that we have no reason to think that AI is sentient. And
where does that come from? It comes from this epistemic projection of word usage,
how we talk about things. You started your discussion today talking about, you know,
AI people saying, you know, there is nothing to this large language models that we don't
understand. I am one of those people who say that I understand the mechanics of that I know what is
there and what is not. So the fight we are fighting is to prevent these operationally useful
levels of abstractions. In other words, this convenient fantasies which are very, very convenient
and should be used, we are trying to prevent people from understanding these epistemic thing
as if it were an actual ontic property of the world out there. Because that's what Black Mirror
does. That's what the eight o'clock news does. That's what the very suspicious characters on the
internet and on YouTube are doing. There is money to be made out of this. And yeah, and then,
anyway, I have a slight issue with this, but I do understand your point that it is operationally
useful. But I think we should try to stress that there is a distinction between epistemic
convenient fictions and ontic things about the world that when we say that we are using an
epistemic convenient fiction here, we don't mean by it that the algorithm has a will, that it has
the phenomenal state of wanting to get some teleological phenomenal state. We don't necessarily
mean that. Yeah, I mean, so I'll kind of emphasize the part that we completely agree on.
My point about the language models was not that I think that they have, and I don't use the word
sentience much myself, but the kind of sentience that people often attribute to them. I mean,
I don't think they have it. But I think the kind of the fundamental thing where
that drives our viewpoints here is that are the difference in our viewpoints is that I don't
really believe in a binary distinction between yes, they have it or no, they don't have it,
I think it's a deep spectrum. And I think that what's really interesting and important about the
universe is that it's full of what I really think is sort of competing and acting in the
universe is perspectives, frames of reference. And I think very simple systems can have a
perspective. I think it makes sense. It could be extremely tiny. I don't like the binary
trying to classify systems that, okay, this really has an inner point of view, and this absolutely
does not. I think it's a continuum. And I think the question is how much utility do you get from
taking the perspective of some other system? And some of them are truly minimal. These things
that we're talking about now, I don't think they're metacognitive. I don't think they're anything
like a human. But I do think that there's a sense of a nano, a sense of a kind of
a nano goal-directedness that we can have. And the problem is that if we don't believe that's
true, then we're going to have a real difficulty saying why it is that humans or whatever else
did you want to extend it to, why they have it too. Because we all start life as a single cell.
And somehow, you have to get to the point where you start out as a little blob of chemistry and
physics. And eventually, you end up with whatever it is that you and I have real metacognitive
wants and goals and things like that. And I'm not saying there isn't a difference between those two
cases. There certainly is. But the hard part is explaining that smooth transition. And this is,
yeah, this is what we work on. Is it okay, Bernardo, before you respond? And I would love
for you to respond. If one or both of you could state as in simple terms as possible what it is
you're debating. So as many people as possible can follow. Because I'm pretty sure I understand,
but I don't think I'd be able to articulate it. It's basically what is a thing?
Well, what is an emergent property? I think that that is the discussion. When you talk about
emergency in a weak manner, so not strong emergency, not consciousness out of non-consciousness,
just emergence like the shape of sun dunes or the crystal structure of a snowflake,
emergence in that sense in which a system starts with very simple properties, but it seems to develop
some very complex properties or some complex behaviors later on. The question is, are emergent
behaviors a thing, a non-tic thing in the world out there? Does something actually emerge in the
world? Or is it just us that project the modes of our cognition and what's happening? And what's
happening is just simple stuff. There is nothing complex emerging. It's just the play out of simple
rules in an iterative way, and we project something to it. And Michael, we both agreed that there
isn't something on tick going on out there, if I understood Michael, but Michael says it's useful
in our own language, in our own thinking, in our own inner discourse to pretend that there is,
because it allows us to think in a higher level of abstraction, which is much easier than to
continue to operate on first principles all the way along. It's like somebody asking me to design
a risk processor starting from the PN junctions. It's not useful. I need to think in terms of
gates or at least transistors, you know, are there transistors in a chip? No, there are only PN and
NP junctions. That's all there is to it. Doped silicon and metal. That's all there is to it. But
it's useful for me to do my work, to talk of transistors, to talk of gates, to talk of chips,
and interconnect networks. And if I understood, Michael, that's where he's coming from. But he
also thinks that we shouldn't go too strong in this radical division between emergence, being
purely epistemic, not being out there in the world, and what is really out there in the world,
because he thinks the idea of points of view may be a sort of, not a binary one, because if it
were binary, we would have difficulty in starting from a zygote, a single cell embryo. Can you even
call that an embryo? I think we can. To us who do have a point of view. So how do you explain
that transition? I think it was Michael's last point. Is this fair enough, Michael?
I think it's reasonable. Well, the second part is straight on. The first part, I want to be a
little more radical than this. So let's play it out and see how it goes. How about this? I 100%
agree with you that all of these things, and by the way, it's not just emergence. I'm not particularly
impressed by the emergent complexity per se. I'm interested in emergent goal-directedness,
which is different than just complexity. But I fully agree with you that all of those things are
painted on to the world by us. They are things that we see in the world. Here's the move I want
to make. When you say us, I think it's everything. I think that us is not just us, me and you. I
think that every agent in the world, and at some point we can talk about where that bottoms out,
but I think certainly what happens in biology is systems that try to understand other systems
because they need to hack them. In order to hack them, you don't want to always try to think of
them as the lowest level of a bunch of emergent complex chemical soups that are going to happen.
If these other systems have any kind of goal-directedness, and I don't mean human purpose,
the kind of things you study in cybernetics and everything in between, all of these other
high-level features, you will paint it on to the world because this is how you are going to
relate to the world. You do not have, as an agent in this universe, you don't have the luxury of
being a Laplacian demon and sort of having an unbiased view of the whole world from the particles
up. You have to coarse-grain it and sense-making in a way that makes sense to you, and inevitably
you're going to tell agential stories about agents doing things. I think this is universal,
and I think that the universe is basically a giant set of competing and cooperating perspectives,
and it isn't just us. When we say us, it's everything. It has some degree of
inner perspective on the outside world, and if you're a rock, that inner perspective is infinitesimal.
We can argue about whether it's zero, but anything above that is going to, and life is very good at
scaling up these perspectives and detecting agency and so on, is going to have these kind
of perspectives. That's my move. I think that we really need to get much better at taking the
perspective of other things that are not at all like us, and I think this has also, of course,
social implications and whatever. I think we have a really hard time looking at the world
from the perspective of other things, and I've been spending actually a lot of time the last
few weeks really thinking about this and thinking of tools to help us take the perspective of other
systems. I'll try to amplify the problem you described, and I will recognize, well, at least
I will try to convince you that I understand the problem, and then I'll try to articulate why,
based on my own views, the problem isn't there. The problem you see is we start as a single cell
zygote, which is very simple. Well, relatively speaking, because zygote, the biochemical machinery
of that thing is unpathomable. Nobody has figured out, nobody has a model of that down to first
principles, but okay, relatively simple, and then it becomes us, and we do have a point of view.
Now, the same problem is playing out in physics. The measurement problem says that physical things
only have existence in relation to an observing system, but what constitutes an observing system?
Well, anything constitutes an observing system, so anything may have a point of view.
I think both attempts to solve this problem are based on the following intuition.
When it all starts, there is no point of view, and then suddenly there is a point of view,
and this discontinuity is a problem. There is only two ways to solve it.
Either everything has a point of view from the get go, or you didn't start without a point of view.
That's one possibility.
It's the assumption that the zygote does not have a point of view, and a point of view then
develops with growth that leads to the problem. It is the assumption that
any physical system is analogous to any other physical system, as far as the measurement
problem is concerned, that forces us to say anything is an observer, because we don't have
a well-behaved objective criterion to say, no, no, this is a valid observing system, and that is not.
Or this is a thing, and that is not. It's a projection. It's an arbitrary way of us carving
out the world. It is not a thing. Or to say, zygote doesn't have a point of view, but a grown human has.
Under my own view, zygote already has a point of view, because a point of view is what arises
from dissociation. If there is a dissociative process, that dissociation creates a point of view.
It creates the observer, so to say, which is distinct from the world, and therefore can observe,
because it is dissociated from the world. Otherwise, it's just the world.
Then in philosophy, this question goes deeper. It's not only what has a point of view, which
under analytic idealism is only living things, as zygote is living. It developed a point of view,
the moment of accundation. But in philosophy, it goes deeper. What constitutes a thing?
Is a painting hanging from your wall a thing? Is your table a thing? If so, are each of the four
feet of the table four things? But isn't the table then just one thing? Or is it five things?
Is it the top of the table and the four feet? There is difficulty in even determining what
a thing is, let alone what properties it has. Can it observe? Does it have a point of view?
Does it have a will of itself? I mean, even before we get to that, asking whether a table
has a point of view, whether a table has volition, we have to ask, is the table a thing?
Or are we just projecting the epistemic structure of our language onto the ontology of the world?
Not everything we have a distinct word for is a thing. This is a fist. We have a word for it.
Boom! It has disappeared. Where is the fist? The laws of conservation of energy have just been
violated because something has disappeared without releasing energy. How is that possible?
You run into this kind of problems. The moment we are not careful about paying attention about
mistaking the structure of language for the ontological structure of the world,
which is very prone to doing because we are surrounded by language. We live in a world of
language. So to me, what you are trying to do, and you are probably a pioneer in this in biology,
but you are not a pioneer of this in science in general because physics has been struggling with
this for a while. Philosophy has been struggling with this for a while. The difficulty you are
having is that you do not have a clear objective criterion to determine what is a thing as far
as a certain definition of thinness is concerned. And because you do not have that, then everything
has to be a thing. Therefore, everything has to have a point of view in potential. Or not,
if it is too simple like this I got, then it does not have one. But we do. So what magic happens in
the middle? To me, the precundation, the moment zero, t zero of life is what determines a thing.
Why do I say that? Is it arbitrary? No, it is because unlike the question of whether the feet
of a table are real things for which there is no ontological criteria, all criteria are epistemic.
They are based on convenience. If that thing breaks, I need to have a word to refer to it so I can
repair and put another foot on my table. But there is one exception to this. If you avoid
applying epistemic criteria to carving out the world into things, there are no things.
There is no car. If you say, well, a car is everything that is needed for the thing to move.
Well, it needs the air for the combustion. Without the air, it doesn't move. It needs the road for
the tires to grip. Without the road, it doesn't move. It needs gravity to pull it to the road.
Without gravity, it doesn't move. So if you follow that criteria, this kind of criterion,
functionality criteria, which is how it's called in philosophy, then the whole universe is a thing.
There is even a naming philosophy for the blob theory, whatever. But there is one exception to
this. There is one thing for which we have objective criteria to say, these are things.
And that's life. Because if you stick a needle on the arm of my chair, I don't feel it. But if you
stick it on my arm, I do feel it. So there is a clear boundary between what I do register and what
I don't register. That boundary determines me as a real thing, not as just a sort of an arbitrary
collection of pixels on the screen of perception that we give a name to. It's like saying, take
the Mona Lisa and group all the pixels or all the infinitesimal dots of pigment that are around yellow
given a certain tolerance. And you call that a thing. That's what we do, this kind of arbitrary
grouping of the pixels of reality. But when it comes to life, it's not. And we know that first
hand, we know where the limits of our thinness are, you know, should the wall, nothing happens,
should the head of something very dramatic happens in my inner life. So to me, that zygote
already has a point of view, because that's what life is. Life is when life is formed,
what we call the rise of life is the rise of a point of view, because it's the image of a
dissociative process. And then adult human is that zygote still, it's not another system that zygote
didn't get together with trillions of other cells that pile up on top of each other to form us.
That's not the history of us. That zygote underwent mitosis, cell division. And here we are already
passing a sort of metaphysical judgment by talking about cell division. What's happening,
if you look at it neutrally, that zygote is inner complexifying. It's creating inner structure.
And because it only knows how to be a cell, that's how it started, then that inner structure is a
sort of an iterative, self-similar fractal complexification. It creates structure by adding
more of the only thing it knows how to be. So that's why it started with a point of view and has
a point of view. Now it's the same thing. I am the zygote that was in the womb of my mother.
It's just that that zygote, complexified, created inner structure fractally by repeating the template,
the only template it knew how to be. This wouldn't be correct if the way human beings came to being
were by a trillion cells crawling and piling on top of each other to form us. It doesn't happen like
this. Sorry, I was passionate about this. My admiration for you forces me to be more polite.
I hope you didn't take it as an attack. It's not, but this is something I feel passionate about.
Of course. No, no, this is great. And Amir, you can tell us when it's time to move on to a different
topic because I think we could talk about this for a really long time. But I mean, I would just say
I would say a couple things. I agree with you that the zygote already has a perspective. I agree with
that. I also think that this business of whether something is a thing or not, I don't like the
binary framing of it. I don't think we need a binary classification. I think what's more interesting than
that are the ability of various perspectives to recognize persistent patterns. Somebody with a
very long, let's say a cognitive lifespan of millions of years would look at each of us as a
temporary metabolic blip. It's a pattern. It's like a wave that showed up and it's gone. There's
no permanence in anything in our bodies. And the other thing I would say is that the time
zero of the fertilization event, I really don't take it as seriously as you do because I
visualize what's happening there. So what's happening there is that you have an unfertilized
oocyte. We can see how it got there. So the steps, what you have is a bunch of nurse cells
that basically create a new cell and they shove it full of useful materials that it's going to
have later on and there it is. So it starts out as a bunch of chemical processes and then
at some point the sperm shows up. I mean, it's cool and all, but you can duplicate that with
a poke of a needle actually in many organisms. You can do it without the sperm. You can just
sort of poke them with a needle and they undergo parthenogenesis and they start to,
you know, various things. Some calcium comes in and the membrane becomes impermeable to new
sperm and then some more chemical reactions happen. I'm just not sure there's anything
fundamentally profound that happens at fertilization per se. And I think we could,
I can imagine in not too far future, all of those early processes being done exactly,
as you said before, by an aggregation kind of phenomenon. We could replace those
nurse cells with little microfluidic pumps that create the thing and kick-started with a needle
and so on. I think the whole thing is much more continuous and it's about a transit. What I see
when I look at biology and when I look at the world, what I see is a constant transformation,
meaning growing and shrinking and a reshuffling of perspectives. I see cognitive light cones that
can be very large. They can be very small. They're all looking at each other. They're all making
estimates about where the other beings are and what the, you know, sort of cognitive capacity
of these beings are. And, you know, I'm just not seeing any binary categories for us or for
thingness or for anything else. I think there are just perspectives. I'll briefly comment on this.
I think we are sort of beginning to converge or at least identifying where we don't agree,
but very briefly, just to prevent a misunderstanding. I don't think factumdation
is the rise of a point of view from no point of view. Factumdation is two points of view
creating a third. So it's from points of view to a different point of view. So it's not a
fundamental transition. You're not creating something that's fundamentally new. It already
started with two previous points of view, but those two previous points of views mixed in a
certain way and outcomes a different point of view. What I think is, what I think is trickier,
and maybe you agree with me, is that it's a biogenesis. It's the rise of life from non-life.
It's when you truly create a point of view from things that were not a point of view.
That is a little trickier. Otherwise, we would have done it already. You would have done it already.
Craig Venter would have done it already, but all he managed to do was to
synthesize DNA and implant it on a sort of empty shell that was alive. It started from life.
So there seems to be something, you know, if you ask me, do I think we will artificially
be able to induce a biogenesis? I think we will. I don't see any fundamental reason for us not to
be able to do that, because obviously it has happened at least once in the universe. So if it
has happened, it can happen. And if it can happen, you know, maybe it would take the monkeys another
500 years, but I don't see any fundamental reason why the monkeys won't be able to do that. But it
is on a different level and level of complexity than fecundation, I think. Otherwise, we would have
done it already. What do we say, Amir? Should we more of that or go on to something else?
I mean, someone put in the comments, I think it's such an important topic. It's my favorite one.
I don't want to bias the whole group, but several people put little emoticons on that.
So this is kind of fundamental to who we are and what we are conscious of. I don't think there's a
more important topic that people put in the chat and everyone who thinks, no, we really need to
discuss this, put lots of emoticons on it. And then we'll see, okay, there's something that people
feel we urgently need to discuss. The only thing I'm nervous about in terms of the group is I'm
following it, but mainly thanks to having, you know, watched a lot of your stuff, Michael, and
also being invested in this for a little bit. So I just wonder if it was like a short recap,
if that's possible, and then the kind of chatty bt version of like, okay,
some of this debate in a paragraph in simple terms, I don't know if that's possible for you.
Yeah, yeah, that's going to be tough. I think it's because we're talking about a number of
really, really deep issues here. I mean, one thing I think that we're discussing is whether
there are binary categories for some of the interesting things that we talk about, for example,
living or not living. Now, this may be crazy for biologists to say, but I don't actually believe
that's a distinction. So I think it's a spectrum. I don't believe that, you know,
you can say something is life or not life. I think what you can say is,
to what degree is something good at scaling the cognitive light cone of its parts? I think we
call things alive, where the system itself has a larger and a more interesting cognitive light
cone than all of its parts have, you know, so rocks don't do that, right? So little particles
have a very tiny, I don't think it's zero, but I think it's extremely tiny cognitive light cone,
and the rock has exactly the same. But living things are actually very good at scaling these
perspectives and climbing up that cognitive hierarchy. But to me, it's a continuum. And I
think that, you know, I think that the creation of life from scratch as the biogenesis that Bernardo
was talking about, I think we are, as you say, I think we're going to get there. I don't think
there are, I think it's a technological issue that's stopping us now. It's not a knowledge issue.
It's not a kind of a, you know, a fundamental thing. But anyway, I think we're talking about
that, whether there are these binary categories. And I think we're also talking about whether
there are objective facts about, you know, what a thing is, or whether something is an agent or
is not. And so whether that's the case, or whether everything is a matter of a perspective from some
kind of system, you know, is it super helpful to take the perspective of a table? I think not.
I think you don't end up with much. But I do think that there are systems that we can build that
might be biological, that might be technological, that might be hybrid. So we make hybrots, which
have a little bit of biology, but otherwise they're basically an engineered system. And to really
understand, to relate to that system, to understand what it's doing, what it's capable of,
at some cases, to have ethical relationships with it. I think you do need to take its perspective,
not as a technique or a, you know, a bit of fakery that you indulge in to help the science go,
but actually fundamentally, you know, I really do believe that all kinds of things have perspectives
that we currently do not recognize. I don't think we're very good at recognizing the
perspective of unconventional systems that are not like us. And I think they're real in the
sense that anything is real. And I mean, I share, you know, basic, you know, kind of these idealist,
you know, kind of basic ideas with Bernardo, but I think there are way more perspectives in
the universe than we think, you know. Do you associate life with Varela and Autopoiesis?
I think it's, so what I think is Autopoiesis is very important for is the creation of a mind,
not life. I think cognitive, I'm much more interested in the cognitive
kind of distinctions than life or not life. I don't think, I think we can absolutely make things
that would engage in some degree of Autopoiesis that some people wouldn't call alive, I guess.
I don't even know, I don't have a good definition for life. You could, you know,
you could bring on Sarah Walker or somebody who really thinks about life, per se,
and she would have a different opinion, I think. I don't spend much time thinking about life at
all. But I do think that Autopoiesis is a critical component of making a mind with a
significant inner perspective. If you're not Autopoietic, you're going to have an extremely small
inner perspective. When you say that non-living things may have perspectives,
do you mean that there is something that is like to be them, that they are conscious
in their own right, in their own, given the boundaries of their own system?
So this is, you know, the what's it like to be is an interesting question, because look,
if you say, let's go back to the kind of original, you know, what's it like to be a bat, right?
So what are we really asking there? If you ask that question, what's it like to be some kind of a
system? If you, what I think you're really talking about is a relationship between two things. In
other words, if I really knew what it was like to be a bat, there would just be one more bat. Okay,
I wouldn't be finding out what it's like to be a bat. If I really, really knew everything about
what it was to be a bat, I would just be a bat. And that's it. There'd be one more bat and I
wouldn't learn a darn thing. There'd be a bat. So what we're really talking about is some kind of a,
I view it as some kind of a control knob, where what you're really saying is I'm going to retain
some features of myself, but I'm going to twist this knob a little bit so that some other things
are going to change. I'll become more bat like. And then I'm going to know what it's like, to some
extent, to be like this other creature. I don't, you know, if you go all the way, then you then
you're just whatever it is. So, so I think it's a I think that question is actually much harder than
a lot of people make it out to be. But, but yes, I do think that some things that currently people
would not classify as living. And I don't know. I mean, people, like if you look at a textbook
that kids use, they use all kinds of criteria, you know, what has to be subject to the laws of
evolution, and it has to have metabolism and you know, some other stuff, right? So there may be
some criteria like that. Yeah, I think that I think that there can be and probably are both here
and outer, you know, sort of wider in the universe, things that would fail those criteria,
and that do have a useful inner perspective from which to see the universe. Do you think viruses
have a conscious perspective? So, so I reject the the do they or don't they kind of thing, right?
Because I will not try to put it in a category, I will simply ask the question,
if you try to view the world from the perspective of a virus, what do you see? And I think you see
very little. I don't think you see zero, but I think you see very little. And so and so that's
what we're talking about. I think all of this is about what is the what is the cognitive
Lycone and this is by the way an experimental, I mean, people people said this about about cells
and tissues, they say, oh, that's zero. And I'm saying, no, you need to do experiments. And if
you do experiments, you might find that there actually is a very useful inner perspective
that you can try to at least get your head around you, you're never going to be it,
you're never going to be that system, but you're going to at least try. So,
you know, yes, do I think they have some degree of inner perspective? Yes. Is it
significant? I think it's extremely small. If you look at integrated information theory,
they are flexible about what where the boundaries are, I mean, flexible, the theory implies where
the boundaries are, but that doesn't necessarily line up with life, at least not in principle,
not a priori, maybe in practice, it may line up with life. And as far as we know, it does,
but not not a priori. But the theory does say, even if we don't know where the boundaries are,
because we don't have the instrumentation to make the measurements that are needed for us to derive
that conclusion, there are boundaries, because of the exclusion principle in it. So,
whatever, whatever states become part of a complex, their perspective becomes
subsumed in the perspective of the entire complex. In other words, the states that form a complex
do not have a perspective of their own. That's the integrated information part of the theory.
Do you disagree with that? Do you think it's, there aren't such criteria for determining what
is subsumed and what is not? What I don't, well, a couple of things. Again, I don't believe that
there are objective criteria for any of this. I think all of these criteria are from the
perspective of some observer, which in the case of significant systems like living systems,
is the system itself. What I don't like, I mean, the one thing I don't like about it is
that exclusion axiom, right? I mean, it's basically something that's just sort of added on
with my understanding of it anyways, that it's just added on. I don't like it because
I do think that even in the human organism, there are multiple, there are multiple selves,
multiple perspectives of different degrees of sophistication. I mean, it's awesome that we
have these left hemispheres that can talk to each other verbally and make claims about how
conscious they are and how they don't think the liver is conscious. And, you know, I mean,
after all, I don't feel the liver being conscious, right? And that's great. But
that's because I think that's because, and I don't say much about consciousness usually,
but just this kind of role with it here. I think that's because we have a very hard time
taking the perspective of other beings in other problem spaces. So I do think that, for example,
the liver, let's just take that. I think the liver is an intelligent agent that navigates
physiological state space. It's a space that we have a very hard time visualizing. Our sense
organs did not train us to navigate that, to see that space. We're bad at recognizing things that
work at other timescales and other spaces. And I think that if we did, if we were better at directly,
just imagine like, here's how you might engineer a being that could do this. Imagine a human that
was born with an innate sense of their blood chemistry, right? The way that you feel and see
and whatever, you also had some receptors for, I don't know, 20 different parameters of your
blood chemistry and you could feel it directly. I think if we had that, if we were that kind of
creature, I think we had no problem recognizing that our liver is an agent with some degree of
intelligence navigating that space, dealing with all kinds of stuff that happens, not just because
it's complex. It's not an issue of complexity. It's an issue of problem solving. It's an issue of
having preferences. Your liver absolutely has preferences about which kinds of blood chemistry
likes better than others and how it feels about certain things you drink and stuff like that.
And I think that if we were better at recognizing these things, we would A, be able to notice it.
B, we would be able to communicate with it better. I mean, this is our research program now,
is literally trying to communicate with these things, not micromanage them, not force them,
but to improve the biomedicine of drug use and regeneration and so on. When I say drug, I mean
pharmacology, to use these things as a way of getting buy-in from the tissues, I mean literally
getting the tissues to not fight back and not to cause all these issues with all these different
reasons that drugs fail and so on, but to actually communicate with that primitive intelligence.
And of course, we don't feel it to be conscious because we don't feel each other to be conscious
either, right? Anyway, that's my take on it.
The IIT is consistent with what you said. IIT does not say that there is only one complex
in a living creature. What it says is that whatever is part of a complex, then the only
point of view is that of the complex. The subparts do not have their own point of view. Their own
point of view becomes subsumed in the global point of view of the complex, but there are many
complexities in a living being, and one of them could entail the liver. This is completely
consistent with IIT and even with analytic idealism because the liver is part of a living body,
so to me it's perfectly okay to talk about the multiple complexities that form us.
There is even a lot of empirical evidence for this, that there has been this back and forth
about what happens to consciousness when you sever the corpus callosum. Initially they said,
well, consciousness splits in two and then they talk to the patient and the patient said nothing
changed and then they decided, okay, it didn't split in two, but now with modern experiments
we are seeing that in fact they have split in two. It's just that each consciousness of the two
does not notice a difference because it's dissociated from the other and doesn't know about
the presence of the other, but people behave as two. You can ask people two different questions
and depending on whether the answer comes verbally or from writing, the answer is different
because it's the left hemisphere controlling language and if you're writing with your left
hand then it's the right hemisphere controlling that and the answers are different, which is
amazing, amazing. If you confront people with this they will confabulate a completely implausible
story for why they did that and they will insist that, oh, nothing changed, I am still me.
So all of this is consistent. IIT does not contradict what you said. I would even,
if I may make a suggestion, Michael, I think a collaboration between you and Julia could lead
to some very interesting things. Yeah, I agree. Yeah, Julia and I have talked about these kind
of things. We are using some of those techniques to look for, not really phi, but various surrogate
metrics of phi in the various things. Like for example, in the scenario where we do have cells
that come together to become a xenobot or we have other kinds of systems where cells come
together, like to literally watch. Can we look at by tracking calcium signaling and other things?
Can we actually watch the integration happening? Yeah, I agree with you. I think that's super
interesting. There's another thing here that I think might end up being very relevant to this,
which is something else that I've been thinking about a lot recently, having to do with memory
and the way that, and this is related to this issue of perspectives, and one way,
so let's just go back to the basic example that I bring up a lot, which is you got a caterpillar,
you train the caterpillar to eat some leaves on a particular color disk and it remembers
and so on, and then that caterpillar becomes a butterfly. So in the process of becoming a butterfly,
basically most of its brain is dissolved, most of the connections are broken, it rebuilds a new
brain, now you got this butterfly and the butterfly still recalls the original information.
So one thing that you might think about is, wow, where is the information stored during
this process? And that's an interesting question, but there's actually a much more
interesting issue here, which is that keeping information still, meaning recording it and
making sure it doesn't change, is a minor part of this, the more major part of this,
is the fact that the butterfly and the caterpillar are completely different architectures. So first
of all, the butterfly does not eat what the caterpillar eats, so the butterfly doesn't care
about the leaves at all. And what you actually have to do, the caterpillar lives in the two-dimensional
world, it crawls around, the butterfly lives in this three-dimensional world. So what you really
have here is the ability for information to get remapped in a way that in your new life,
as literally, I mean this is going to sound crazy, but literally, this is all literally true,
in your new life as a higher dimensional being, what you're going to remember is not the details
of the things you learned before, but the salient meaning, the part of that, the lessons that you
learned that are actually relevant to your new life, and they're going to get remapped onto a
completely different set of muscles and different behavioral repertoires in a butterfly than existed
in the caterpillar. So this issue of remapping information and the importance of, from the
perspective of, right, so you've got, I mean of course it's going to have some kind of
medium, some kind of engram that holds the information, what you have to ask is then
from the perspective of whom, what does that information mean? So from the perspective of
the caterpillar, it might mean, you know, crawl in a certain way and get yourself some leaves
from a perspective of the butterfly, it means, oh no, flap your wings a different way and you're
going to get some nectar, but they're reinterpreting this information from different perspectives.
And I think once you start thinking about this importance of remapping information to new
contexts, some very interesting things happen. For example, if we think about the evolutionary
lineage as a whole organism, right, so I don't know, some 50 million years of alligators or
something, so like the whole lineage, what you know for a fact, if you're that lineage,
what you know for a fact is that everything is going to change, your body is going to
change because there will be mutations, your cells are going to change because there will be
different chemical properties in your environment. If you try to take the information you learned
in your past too seriously, if you're sort of over-train on those priors, you know it's going
to be poorly applicable in the future. What I think evolution does, I think it fundamentally
makes, because everything is change and everything is guaranteed to be different,
what I think it fundamentally does is mechanisms that are perspectives that are trying to extract
salience from my current situation, from whatever you were inherited, whatever you inherited from
the previous times. This is why biology is so incredibly interoperable that we can, you know,
we can take the cells out and put them, you know, we can, I didn't even get to talk about
antherobots yet, which is this whole new thing that we published recently. You can take the
cells out, combine them with some kind of weird nanomaterial that they've never seen before and
always something useful and something coherent happens. And it's because I think fundamentally
life and evolution have bought into the assumption that things are not going to be the same,
that you're going to have to reinterpret and remap what you have from a different perspective.
And you can think about this as, you know, we're not butterfly caterpillars, but we kind of have
this too, you know, when we were children, we had certain memories and certain things were very
important and other things were less important. And then, you know, puberty kicks in and all kinds
of stuff happens, your brain is remodeled by the hormones and whatever. And you have to now,
you know, you still have those memories, they make some sort of sense to you. And in fact,
each memory recall we know now is not a non-destructive read, right? Every instance of
recall actually modifies the memory a little bit. And so this, so I think this is just really
important, the ability of, I think that's another thing that's special, right? So auto-poesis is one,
but the other thing that's special about what things that we call living is that they're just
very good at compressing down the complex states of an organism at time t, compressing it down to
an arrow, you know, kind of almost like the, you know, the middle, the middle node of an auto
encoder or something, right? You shrunk it down, and then you're going to reinflate it, but you
might reinflate it onto a completely different context. You're not going to be the same as you
were before, right? And none of us are the same. And you can see that in evolution, where you
shrink it down, every generation shrinks it down to an egg, reinflates down to an egg, reinflates.
And we can, communication is that way too, right? So I have a complicated brain state here. If I give
you a matrix of all my neuronal states at this time, there's nothing you can do with it because
your brain is somewhat of a different structure, even if we're the same species, you can't map it
exactly. But language gives us a nice narrow interface, right? Where I can take all of that,
I can squeeze it down to a message, I give you the message, you're going to reinflate it in your own
cognitive system, however you can. It may end up the same as how I sent or it may not,
but you will preserve the salience, right? You're going to squeeze the salience out of it.
And so that's what I think is really important about memory as message passing between
temporal slices of beings and that having a perspective from which you interpret your
engrams, your environment, everything else. Yeah, I think that's really key.
I can't remember what we agreed, Michael, you staying two and a half hours or two hours or
how much time do we have you for? I got another half hour, no problem.
So I think this crowd, especially in me, would be interested in your thoughts on,
you've hinted at a platonic realm, it's speculative, it has some utility in explaining
some things in evolution, if I've understood you correctly.
You comfortable in bringing the conversation in that direction for a bit?
Sure, yeah. And this is, just to be clear, this is right at the edge of
things that I feel certain about. So I'm just going to say some stuff that I've been thinking
and I have no idea if this is going to, in the end, be useful or mature properly or what.
So just some thoughts. The way I got into it was through the creation of the various
synthetic kinds of life forms that we make. So we make xenobots. The more recent thing I'll
just tell you about is amphibots. So when we made, so xenobots are self-assembling
little proto-organisms that come together when we scrape some skin cells off of early frog embryos,
they can come together and have all kinds of interesting behaviors and so on. And there's
a bunch of new stuff that isn't published yet about new genes that these guys express,
that frog embryos don't express and so on. But one of the things that you might think,
when you see that and you say, well, amphibians, we know amphibians are plastic. We know that
embryos are very plastic. Maybe this is a frog embryonic thing. Maybe this is just
specific to frog embryos. And so what we wanted to do was to get as far away from that as possible.
And so what's far away from from embryonic frogs? Well, that would be adult humans.
And so this is this is a project by PhD students who just defended Gizem Gomushkaya in my group.
And what we did was we took tracheal epithelial cells from adult human patients. So no embryonic,
you know, no human embryos, but adult patients, they donate these tracheal epithelial cells.
And what we found was a protocol in which these cells are given a second life. They basically
they basically grow into, again, a kind of self-multi little organism. If I had, well,
you can see this on there's a blog post about it. You can see the little video, this thing running
around. And and so they have a again, they have a they have a different different morphology than
the normal humans or human embryos, they have different gene expression. They have the ability,
they have some interesting abilities. One thing that we found is that when they, when they encounter
a scratch in a bunch of human peripheral neurons, they will actually heal that scratch. This is
not in patients yet. This is in a petri dish. But if you make a damage to a to a lawn of neurons,
the the antherbots, we can can sit down there and over about four days, they sort of knit the two
sides together and repair the damage. Who would have thought that your tracheal cells, which
normally sit there quietly for decades in your in your lung epithelium, have the ability to run
around and heal neural wounds when given the opportunity, right? So so so you get these emergent
novel novel capabilities, novel structures, and we're just scratching the surface still. We don't
know, I think, even even a tiny bit of what they can do. But if you once you start thinking about
where do these competencies come from, typically speaking, if you look at any kind of an animal
or plant, you say, okay, so why does it have certain certain shapes and certain behaviors?
The typical answer is, well, evolution, of course, eons of selection. So it was selected,
you know, the frog is the frog, the frog genome knows how to make frogs, because that is what
they were selected for a success in a in a froggy environment. But but here you get to and
certainly our data are not the only ones there are other other data like this, you get to a scenario
where you've got these things. Well, there was no history of antherbots. There was never selective
pressure for your tracheal epithelial cells to be able to run around on their own and heal neural
wounds. There was there was there were no no xenobots, you know, xenobots are able to construct
other xenobots by running around and collecting together loose skin cells that we give them,
you know, as we call a cinematic cell for application. There's never been any xenobots,
there's never been selection to know no other animal on earth as far as anybody knows reproduces
like this. Where do these capacities come from? So you can start to think that maybe what's happening
and obviously, I'm not the first person to think this. So a lot of a lot of classic philosophy
thought about this this idea that there is there's some sort of latent space or a platonic space
in which certain kinds of I don't even know what to call them. I'm not going to call them objects,
but but certain kind of things hang out there. And these these things become instantiated,
they become implemented in the real world when physical machines show up that are
good embodiments for them. So for example, when when evolution discovers different
ion channels that are voltage sensitive, that immediately gives you a voltage gated current
conductance, which is basically a transistor. So now you now you can you can make use of all the
rules of logic gates and the truth tables and all these kinds of things that and you get that for
free, you don't need to evolve all the all the states of a truth table for for for ands and ores,
you've you've you've immediately got you got this for free by by inventing this little thing.
And there's lots of things like that that you can find that that will make use of the laws of
adhesion and and you know, other other laws of mathematics and computation and and mechanics,
biomechanics and other things. So if you if you think about evolution as basically searching
the space of pointers into this platonic space, then it becomes reasonable to have a research
program of looking around to see what the structure of that space is. And so so people do that,
like, for example, you can download this thing called the map of mathematics, right, and it's
and it's just like visualization of different types of different types of types of mathematics and
how they sort of connect together and and so on. So you could imagine that that these things that
we make, so the xenobots, anthropots, all the all the kind of synthetic constructs, what they
really are, are little periscopes, they're little little ways to to kind of stick a probe up into
this space and and look around and see what do we normally pull down in a normal embryo.
And a normal embryo uses tons of these kind of, you know, what physicists call free free lunches,
like lots of lots of these these amazing effects that they make use of that they don't have to
evolve from scratch. But around them, there are sets of sets of halos of other things that they
could use if the situation was a little bit different. And and by by doing these perturbational
experiments, by by pushing the the embryo into into scenarios that are different from what it
normally does, you get to explore the the space, you get to explore the all the stuff that's around
it in latent space, and you find, oh, actually, they can do this and this and this and and we can
even, you know, we can start to think about what else is out there as a as a tool for engineering
and for discovery. So so that's, you know, that's the kind of and and so that's step step one,
I guess, is just to is just to realize that that a lot of what evolution does is search
through the space of of pointers into this into this reservoir of these these amazing
capabilities. And then, and then the other thing the other thing you can you can ask and this is,
you know, it gets progressively weirder and then I don't know, this is just this project is just
beginning, but you can actually also ask the question of what are the the the contents of
that space, what is it doing on its own, when it's not being instantiated here in the physical
world? In other words, the traditional, at least my understanding of the of the traditional
conception is that these things are time these these forms are timeless, they just sort of
sit there and they don't change and they're permanent and they are how they are.
I'm not sure of that. We I now have this this kind of multi layer model where
we can start to imagine some, I don't want to call it chemistry, but but but some some rules
for ways that these things can actually interact with each other and some dynamics that can go on
and I have some ideas based on the work of Patrick Grimm and turning logic sentences into into
visualizable dynamical systems, how you can think about what the interaction laws and what the
chemistry might be of these kinds of concepts aside from from the time when they're actually
pulled down into a physical machine in the in the physical world. So that's the I don't know if
this makes any sense, but you know, that's the that's the stuff that I've been thinking about.
I find this fascinating. Michael Roger Penrose is well known for talking about this platonic realm
as well. So for three decades now, I think he is people who wants to put him down and say Roger
is not even a dualist, he's a trialist, because he's saying there is the physical stuff, there is
the mental stuff, and then there is the platonic stuff. My own perspective and I wanted to sort
of run that by you and get your thoughts on it is that we don't need a separate thing if we say
okay, all of existence is a play in a field of mentation, a field of subjectivity. Then that
field exists and to be to exist is to have properties. In other words, that field is what
it is and not something else that it conceivably could have been. It is not that it is what it
is and therefore it does what it does. It has properties, it has intrinsic inherent dispositions,
preferred ways of behaving, preferred templates of behavior, so to say, and to to to abuse the
language from depth psychology could call these templates archetypes, which is the name Jung
came up with. In other words, if this is all one field of mentation, then it has to use a physical
metaphor. It has its preferred frequencies of oscillation, it has harmonics, it has resonant
frequencies, because it is what it is and to be is to have properties and it has the properties it
has and not others. Could these sort of intrinsic inherent resonant frequencies, these archetypal
templates account for what you're talking about without our having to postulate a separate platonic
realm? Yeah, yeah, super. So on the one hand, I mean, I agree with you in that I don't think it's
fundamentally like really in the end of all things, I don't think it's a separate realm. So I agree
with you that these are all components of one bit fundamental field. But I think for the time being,
I think that's a useful frame to think of this because it leads to specific questions about
how do we explore it, how do we map it, the things like that, right? But the frequencies
and the vibrations, I'm really glad you brought that up because that's an interesting example
of actually what we're doing and how we're studying it. One thing that you might think
that hangs out in this platonic realm, one thing that might hang out there are logical
statements, right? Just pieces of basic logic, right? So let's take the Liar Paradox,
the self-referential sentence that says this sentence is false. So one interesting thing
about that is there's this philosopher Patrick Grimm, if anybody doesn't know, he's really good.
And he had this work in the 90s, which is very interesting, where he points out the following.
If you look at that sentence, it's a paradox only if you insist on a static unchanging
truth value. So if you want a truth value, you can't and it's a paradox and okay, what do we do?
But if you're willing to say that what it actually is, is a dynamical system where you
actually look at it and you say, okay, this statement is false. Okay, so it's false and you
say, oh, wait a minute, but that might mean it's true. So as you as a mind, as a perspective looks
on this thing, what you actually see is an oscillation. You see a true false, true false,
true false. So now something interesting happens and Grimm showed how you can take either one
dimensional or two dimensional. So you can do things like he'll say, sentence A, I am as true
as sentence B is false and then sentence B says, I am twice as true as sentence A, right? And you
plot those true and you get this like crazy thing and then it's chaotic and sometimes they settle
down. Sometimes they don't settle down. You can imagine dynamical systems that you can make
all kinds of. So now what you've got is something interesting. So there's a layer of this space
consisting of logical statements. Some of them are like rocks. They have a constant truth value.
Pi is more than three bang. That just sits there. It doesn't do anything. It's completely static,
pretty boring. And so that kind of hangs out. But then you've got this other thing that's like a
it's like a simple oscillator, right? It's like a simple, the basic
layer paradox is just sitting there and it's oscillating. True false, true false, true false.
That's what it's doing. So this is what led me to this idea that it may not actually be these like
forms that are locked in stone and don't do anything. Some of them look like they have a
dynamics to it. Then you can imagine multiple sentences that are interacting with each other
and they have a really complex and you can plot them in different ways. You can either plot them
as a function of time, in which case they vibrate and they have different frequencies,
as you just said, and they do all these things. Or you can plot them in a slightly higher dimensional
space and then you just get this shape, right? You get this shape that you can use. Okay,
this set of logical claims makes this crazy complicated looking shape and Grimm actually
like plots some of these out. It's pretty cool. So just one last thing. And so we're building,
I have one of the folks in my lab and I are making an actual visualizer for these things so that you
start with some logical statements and then you actually see what they look like.
You can now comes the part where you can actually instantiate a chemistry to it because what you
can say is, okay, here's a set of statements that refer to a few different things. Let's say,
you know, ABC, here's a set of statements that refer to C, D and E. Well, they have something in
common. That would be the C. And that means that you can imagine like atoms with a free, you know,
with a free of a hole in their orbital, they can actually come together because you can,
they can combine. If it was ABC and DEF, then, you know, noble gases, right? They don't combine
at all. They don't interact with each other. They sort of slide right by, but sets of sentences that
do refer to things in common. Now you can look at their interactions. And you can say, well,
when they do come together, what happens? So this thing has a shape. This thing has a shape. When
they come together, what's the shape? So it turns out that, and this is just like a tiny corner of
that space. We're just looking at something super like simple and basic, which is just like these
logical sentences. Of course, if that space exists at all, there's going to be like huge
amount of things in there that we don't know how to deal with. But just that alone,
we can start to, and then you can ask some things like this. For example, what's the
frequency of the oscillator? There isn't a time component here. Well, there isn't an external
time component here. What there is is the frame rate of whatever cognitive system is picking up
that liar paradox. So the lie paradox is hanging out there. When you have a system that can
follow it through at a rate of one per second, for example, well, then that's the frequency at
that time. If you're much faster than that, well, then you get a faster feeling. So it's not intrinsic.
It's again, from the perspective of whichever mind is now in resonance with this thing. So all
this is all super early. I don't know if any of this is going to go anywhere. So take it all with
a grain of salt. But I do very much like that you immediately went to the kind of vibration stuff,
because I think that's a good way to start thinking about it. And there's also, if any of you have
seen, and I don't remember the link at the top of my head, but Richard Watson, who's an evolutionary
biologist and computer scientist that I do a lot of collaborations with, he has an amazing set of
videos on YouTube. It's about six hours total called Songs of Mind and Life. And it digs very deep
into this, not the Platonic space stuff, but this notion of the intersection between cognition
and vibration and things like that. And so if anybody's interested in that, definitely check
it out. It's just amazing. It is fascinating that you're going in this direction. I didn't know
that. I'm very happy to learn it. Just a brief comment. I'm not just to add to your plate,
things that you can think about. The liar paradox, you can make it more complex because you can
split it. You can say the fall, the next sentence is false. While the next sentence is the previous
sentence is true. And then you sort of have an extended liar paradox. So you can, you can extend
this and depending on how you model it, this can give you extra degrees of freedom. Another is a
quick sales pitch for a philosopher from my country that never got proper recognition. His name is
Loutzen Brauer. He lived in the late 19th, early 20th century. And his realization was that the
five axioms of Aristotelian logic are just that. Well, not his realization. We know that from a
Griffith's Trilemma, Munchhausen's Trilemma, logic cannot be used to validate logic without
running into circular ease. And in other words, the axioms of logic are arbitrary. The only thing
they have going for them is that we think they are self evidently true. And when we apply them
empirically, most of the time they work, not always quantum mechanics comes in here and tells us
that it's not always the case. But Brauer, he figured that the law of excluded middle,
which is one of the five axioms, it's the axiom that says every statement is either true or false,
not both and not neither. And he decided to get rid of this axiom and see if we could construct a
coherent logic, operationally applicable and coherent, internally consistent logic without
that axiom. And lo and behold, we can. And in some application, it's much more reasonable than
Aristotelian logic. He called it intuitionist logic. And that gives you just a quick example
of one case in which it's very compelling that it's a better logic in mathematics and therefore by
implication in physics and the other natural sciences. You can because of the log of excluded
middle, you can prove that something exists by proving that it cannot not exist. And that allows
you to prove that something exists without ever being able to conceive of an example of it.
An example, a simple example of that which you have just proven that it exists. And under
intuitionist logic, this doesn't work because you don't have the law of excluded middle. So to prove
that something exists, you have to produce one example. And that is much more empirically intuitive,
right? Because how can you prove that something exists if you can't even give me or conceive
of an example to tell me what it is that you're that you have proven to exist? And you can't even
say that you can't even tell me that. So you wouldn't get the oscillations from that. Because
to get the oscillations, you don't have fixed truth values, but you're still using the law of
excluded middle. But you could get some other quite interesting dynamics. And some people
have speculated about whether something like this, intuitionist logic, would be a better path for us
to make sense of the so-called high strangeness phenomena, some psychological phenomena that
are weirder than dreams. And yet people report it. So it's a it's a phenomenal reality and stuff
that people experience. So how is their mind operating to produce high strangeness phenomena?
Or how is the mind of nature operating to produce high strangeness phenomena? And the hypothesis
I raised was it is not using the law of excluded middle. That's monkey logic. It's not nature's
logic. Anyway, just wanted to put it out there. Lauten Brauer is the name of the guy that should
be as well known as Spinoza. But unfortunately, he isn't. He had some other weird thinking about
social issues that maybe is the reason that he would never be popular in the world today. But
he had some very interesting ideas. Yeah, super cool. Thanks. That's great. I was aware of
intuitionism, but I didn't connect it to this to this grim stuff. So that's that's very good.
I just wrote his name on the chat. So people because people will not know how to write down
lights and but I just I just put it there. That's very good. That's very good. Well, you know,
one is I'll definitely think about that. That's excellent. And you know, another thing we started
to think about is is enabling. I mean, this is some steps down, but enabling some of the again,
I'm really I'm really interested in this this notion of as William James once said that
thoughts are the thinker, you know, and this idea of active data and and and sort of erasing
the distinction between passive data that and and in the context of this thing we were just
talking about, you could imagine that some of the sentences contain elements that actually
modify the sentences. So you could imagine, right, a self referential kind of thing where
there are certain atoms that actually go and cut out pieces from another sentence or alter
edits in some sort of string rewriting rules or something like that, right? So you can imagine
but but but the other thing about that is to go back to because I think I forgot to mention
this in the in the business about memories. If if the job if if if what the the system wants to do
is remap and grams and other pieces of information that it got from its past self or from whoever
into the new context, you could imagine that the the n grams themselves might be active.
In other words, they don't have to be completely passive, they could also there might be some
advantages to them to be picked up and nourished, you know, maybe they're just passive molecules,
but maybe they're maybe they're not molecules, maybe they're vibration cycles, or maybe they
write some kind of some kind of oscillation patterns that actually can be fed by appropriate
resonance with with the cognitive system that they're going into. And so maybe they can actually
increase the likelihood that they get picked up and reproduced or or something by by dynamics
that they do right so so they don't have to be passive entirely. So I'm also also kind of
fooling around with some with some models like that of of of memories as self reproducing patterns
that have their own little tiny agendas and maybe it's as dumb as as persist, you know,
that may be the simplest thing. But maybe it's something else, maybe it's more than persist,
maybe it's, you know, kind of like individual neurons like to have a job, you know, they like
to connect to circuits where they're actually going to going to do something. And so maybe these
things too, maybe, you know, maybe their primary driver is to be to be remapped and in the new
in their new context and not be wiped out, which kind of gets to this kind of basic philosophical
thing, which is, you know, the some things called bait baitsons paradox, this idea that if you're
a species, right, you have a choice. If you don't change with the environment, you're going to die
out, right, you're going to you're going to be go extinct. But if you do change, well, you're also
kind of gone because you're not the same anymore. Right. So what do you do? And I think that yes,
that's the case for that. That's a dilemma that that is is a problem for evolutionary lineages,
either way, you're not going to persist as that same thing. But it's also, I think, a problem
for any kind of cognitive agent, because if you really are intent on not changing and persisting
as you are, then you can't learn, you can't modify yourself, you can't improve, you can't, you know,
you can't make any changes in light of further experience, you know that the most profound
experiences are going to change you in some way, you're just not, whether it's, you know, the
mechanics of metamorphosis or puberty or whether it's learning, and you're just not going to be
the same. And so committing to this idea that whatever persists, it's not going to be a thing,
it's going to be a pattern. And then then then then it makes sense, then you can be an evolutionary
lineage that changes over time. And then you can be a human way or any other kind of creature
where your cells and the molecules in your brain go in and out and changes come, but you are still
the same, not because you're the same thing, but because you have an extended cognitive history
that ties it all together. So yeah. Amir, just a quick point. I wanted to ask Mike was simple,
he has no question about an earlier topic before he leaves. So if I have 30 seconds in mind to
the end, it's a quick question just for me to understand that. Do you want to do it now?
It's a different, it's the earlier topic about things. We can do it quickly, Mike. It's just
from my understanding and maybe the understanding of the people here. When you said we have to be
open from multiple points of views, I'll talk about points of view as things. If there are things,
then a thing has its point of view. If we don't have any criteria for telling what is a valid thing
and what is not, then we have an exponential explosion of the combinations of permutations
of the states of nature. All of these combinations and permutations can be things and they partly
overlap. So we would have an exponential explosion of things and points of view.
Is that what you are open to? Or do you think there actually is a criterion for telling what is a
thing and what is not? It's just that we don't know what it is and it may not be the same thing as life.
I think there is a criterion, but I think that criterion is different forever. So I apologize
in advance. This is not going to be satisfying, but this is what I think. I think that the criterion
is from the perspective of each agent. In other words, I think that the universe is
probably infinite, but certainly a hyper astronomical number of perspectives and of
beings and from the perspective of each one of those beings, a different set of things are things
and a different set are not things. So yes, they are absolutely and the criterion is again from the
perspective of each observer. The criterion from the perspective of that observer is does it help
sense making? Does it give me a greater purchase on the world, both in practical terms, but also
internally, right in my own sense making. However humble or primitive that might be for simple
agents. So you can ask any, if provided you know how to communicate with it. So we do okay left
hemisphere to left hemisphere. We're working on ways to ask your liver questions like quite literally
we're asking, we're now trying to develop some technology to communicate with various other
very unconventional agents. And from those kind of agents, you will get a different
set of what do I consider to be things. So your liver will have all kinds of comments about
persistent physiological states as things. And we will look at those and say, no, that's that
that's I don't care about that. That's not a thing. IIT also takes this perspective that the
criteria is based on the perspective of the thing. It's the first person perspective of the thing.
But IIT would say, the criteria is to maximize integrated information, whatever partitioning
maximizes information integration, that determines what are the things. And but what you're saying
is is to maximize sense making. That's where you depart from IIT. Instead of maximizing integrated
information, you maximize sense making, there should be a way to formalize this.
I really think you and Julia would make an exquisite pair.
Yeah, yeah, it's it's been a while actually, we used to we used to meet up at the at some
Templeton meetings that they used to have at the Arizona at the ASU. So it's been a while
since I've seen him. So I will I will talk to him again, I think. But no, you're right. And I think
that I you know, the fi and things like that are a pretty good. I mean, I call it sense making.
But of course, I don't have a formula that you can that you can calculate. IIT is almost a formula
you can calculate. And certainly, there are surrogate metrics that you actually can calculate.
So that so it has that benefit of it. But I am really interested in and this is where some of the
experimental stuff kind of leads into, you know, like bigger, bigger issues.
I'm really interested in what an explanation is. And the idea that what we are looking for as
beings, not just as scientists, but as beings, we are looking for a better understanding of the
world, not just looking backwards, as far as explaining what just happened, not looking
downwards, as far as figuring out the particles or the components of whatever just happened,
but actually looking forwards. In other words, I think a good explanation is a story about the
world that helps you do the next good thing. In other words, it's something that it's looking
forward. It's it's increasing insight, not not not a not a dissection of what the hell just
happened. But as as living agents, we have to live forward, we don't live backward,
the way that third person descriptions of science can do, we have to decide what we do next.
And these things are very complex. And and as beings, what I like from explanations are
something that raises my sense making of the world such that I see, well, given that now I can do
this or now I should do this. And I think that is when I talk about sense making, that's what I
mean. I mean, that agents that have to actively engage with the world. And I don't mean the
three dimensional world. I mean, whatever world they live in, it might be a physiological state
space, it might be anatomical, whatever world they actually live in. The fact that they have to
engage with it is what makes them an observer. And this is like, you know, you mentioned like,
well, maybe photographic film is an observer, what kind of but a really tiny one, because the
photographic film is not going to do anything different, based on what it sees on the film,
at least the standard film doesn't do that. Right. Whereas, whereas things that I would call a
significant agent is something that takes observations. And then the observations matter
because it tries to fit them together into a compressed representation of that helps it
to know, well, what the hell do I do? You know, now after that. And right. And so and so that's
why that's why I think that agents see things and they see other agents. Because if you don't do that,
it does not help you understand the world you're living in. And as a practical matter,
you'll be dead in no time as a as a biological agent, if you don't understand what what you're
dealing with. There is work in physics, in foundations of physics, that dovetails very well
with your thoughts here. Marcus Miller from the Austrian Academy of Sciences,
the way he frames physics is to ask the question, what will I see next? In other words, can I predict
the states of the world? And all of physics can be rewritten in terms of this question,
what will I see next, as opposed to under the assumption that there is a fixed world out there
which experiments telling us, well, if there is such a world, it's not physical. Unless you
entertain all kinds of fantasies about, you know, multiverses and super determinism, hidden variables.
But if you could relate, what will I see next to what should I do next, because what you would
do next must be informed by your ability to predict the world, what the world will do next.
There is a way to mathematically formalize this. Marcus has done it. Actually,
essential foundation, we just got a researcher, we are funding a researcher at the University of
Tri in Switzerland to do research on the so-called physics of first person perspective.
Yeah, yeah. You don't need to start from scratch here.
Yep. No, that's really great. And the other, and I wonder if they talk to each other, I don't know,
but Carl Friston and Chris Fields and Mark Solms and these guys that I work with,
they also work on exactly this, so active inference and basically predicting your
own next sensory states and how that, you know, they call it, I think it's Carl's term,
the physics of sentience and the sentience of physics, right? So like this is, you know,
so I don't know, Amir, you guys might want to see if they can show up at some point
that's some really interesting stuff. So hopefully they're talking to Miller and it's all
kind of one thing, but yes, I completely agree with you, predicting what you are going to experience
next is a really fruitful kind of frame for this. I sent Marcus Carl's paper published on
the IEEE, one of the IEEE journals in 2013 or 14 about active inference,
but I didn't hear from Marcus back. The thing, I mean, I love the work of Carl Friston,
by the way, but it's amazing how much resistance there is to it because people say, well, I can't
understand it anyway, so why will I even try? Why will I even bother? Carl is not doing himself a
favor by his writing style. Yeah, well, I mean, he's an amazing genius and, you know,
I sure as heck don't understand all the math behind it, but I think the very simple,
so there's one kind of slice of this, which is just surprise minimization. Just alone,
this idea of surprise minimization is really powerful and you can apply it to all kinds of
scenarios as Carl has done from ecosystems to psychiatry to whatever. We had a project
recently that it isn't published yet, but another grad student in my lab,
Franz Quichling, he's looking at surprise and yeast, sorry, not yeast, algae, algae. So believe it
or not, algae can be surprised and the reason that algae can be surprised is because they form
expectations of what's going to happen next and you can subvert those expectations and then they
get stressed out and they're surprised. So this kind of thing and then, you know, Chris and Chris
Fields and then Carl can take it sort of much further down and look at symmetrical interactions
between the system and its environment and who's learning about whom and, you know, it turns out
like both are learning about both, right? Michael, if you're, I mean, sorry, I'm taking too much of
your time, but here we may converge because if you go for this, if you go for active inference,
surprise minimization, which goes back to information theory, you will get Markov blankets,
which means that you will get life. So it may, your criterion for determining what things are
may actually be life if you pursue that consistently because, you know, Markov blankets, you get
cell membranes, active inference, you have inner models, you know, the inner states can only
communicate with external states or the other way around by proxy through the states of the
Markov blanket. This is life. Actually, Carl wrote the paper saying that this is life.
Yeah, which I'm 100% on board with that part is completely fine. I just think that if we
take it seriously, I think we're going to be able to include in that umbrella with that exact same
framework a bunch of stuff that any reasonable biologist is going to say, well, I don't know what
this is, but it isn't life. And I'm okay. I mean, I think what the move that you're making and I would
be perfectly comfortable with it is to say, guys, you get the wrong definition of life. This is what
should be life, right? So I'm okay with that. But at that point, you know, it's, I don't know,
the vocabulary. I'm kind of, yeah, less, less tied to it. Fantastic. Beautiful. Thank you. So yeah,
felt like a super amazing dialogue, which points seem to be in opposite direction and then
end up converging very naturally, which is very beautiful to see. I just want to say
very quickly before you go, Michael, because I mentioned it last time, Douglas Harding.
But again, just another weird coincidence because he'd written this book on having no head,
which you, which was the same title, he wrote that in 1961. And it has the same title as a
paper, I think you co-authored. He also wrote a book called The Science of the First Person
in 1974. So it felt like there's someone back there writing the titles of all these kind of
new ideas from a very different perspective. He was kind of an architect and a mystic and a
philosopher. Anyway, maybe we'll bring someone along that, that kind of followed that work.
Just, I know we're over time for you, Michael. So just huge gratitude one more time. It's always
fascinating. Thank you so much. Yeah, it's just brilliant. And I hope you'll come back one day.
And then you've mentioned several other people that would be worth speaking to as well. So
sure, you know, I absolutely will. Thank you. Thank you so much. Yeah. And thank you,
Bernardo. It was awesome to discuss all this with you, of course. Yeah.
Oh, just to say quickly, everyone, we're staying on the call for a little while,
Bernardo, because sometimes what happened last time when you left, a lot of people left not
realize it. And then we're like, oh, we didn't realize it. So yeah, carry on, Michael. We'll
be here continuing for a little bit. But Michael, carry on with what you're saying.
Cool. Yeah. No, sorry. I just, yeah, I was just thanking you and thanking Bernardo,
because it's a fascinating conversation, as always. I've taken a bunch of notes on some of
the stuff you said. So very interesting. So yes, I look forward to more at any point.
Sure. Exciting. Thank you so much. Take care, Michael. Thanks, everybody. Appreciate it.
