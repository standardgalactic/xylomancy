There was a period of time on 9-11 when nobody knew what was going on.
A plane had hit the World Trade Center.
Everybody on the news was talking about it.
There were rumors that other planes had been hijacked, that there was some kind of major
attack, but nobody knew for sure.
There were all kinds of crazy rumors swirling around, but in that moment, it was just as
likely that this was just a horrible accident.
Just a thing that went wrong and nothing more than that.
And then the second tower was hit.
That was the moment that all the confusion went away and we all collectively realized
at the exact same time, oh, we're living in a different world now.
I think we're kind of having that moment right now with AI.
For the last 10 years or so, we have been hearing about how this technology is going
to change the world.
It's going to take all of our jobs, leave society unrecognizable.
There's just been this background anxiety about it, what AI could do, but for the most
part, it was just like an abstract thing that we couldn't really see or imagine.
But some recent advancements have made this abstract thing a lot more clear.
AIs that can generate articles, music, images, video, and code, meaning they could create
more AIs.
There are even people using AIs to build and run businesses, all by themselves, making
thousands of dollars a day.
At the very least, these are the new tools that in five years or so, you're going to
be at a disadvantage if you don't know how to use them.
And at the very most, we're seeing just the tip of the iceberg of a technology that will
radically reshape our society in ways that we can't possibly comprehend.
What we're seeing right now is AI's second tower moment.
Whichever way this goes, we're in a different world now.
All right, so this is a video about what's going on with AI right now.
And the thing is, what's going on with AI right now is it's changing extremely fast.
Like there are entire channels dedicated to following this stuff, that post multiple
times a week, and they're struggling to keep up.
So the idea that this video is going to be timely is just laughable.
Yeah, things have happened since you started watching this video that already makes this
video obsolete.
And that's kind of the whole point.
For years, we've been hearing about the idea of the singularity, you know, the moment
that AI outpaces us and the unimaginable becomes real.
I covered it a few times early on in this channel, and I've been making the argument
actually, for the most part, that when you step back and you scale things back and look
at the big picture, we're in the singularity.
We've been in it for a couple hundred years.
Yeah, I kind of got away from the idea that the singularity was this, you know, one single
event, just one moment when everything changed all at once, you know.
I started seeing it as an era of history that began maybe with the birth of the Industrial
Revolution, when we learned how to harness energy, or maybe even the invention of the
printing press, and we learned how to pass information on through space and time.
You know, like everything just kind of hockey sticks after that.
What's been happening lately is starting to feel like the classic version of the singularity,
you know.
Like we're just rolling downhill and about to cross the event horizon of this thing,
where there's no going back.
Hyperbole much, Joe?
I don't know.
I mean, not if you listen to the hype around it.
Judging on the hype that you've been hearing about AI, this could go in two very different
ways.
On one hand, AI could solve all of our problems, cure cancer, create new methods of propulsion
and clean energy.
All the issues we're currently dealing with that we fear will destroy us someday, AI could
be an unimaginably powerful tool to solve those problems.
This is one possible outcome.
But then there's the other outcome, where in an inconceivably short time AI becomes smarter
than us, it becomes an intelligence we can't possibly fathom, leading to the extinction
of the human race.
And to me anyway, no discussion of AI is possible without talking about both the good and the
bad.
That's what I'm going to try to do here.
And it's difficult.
I'm trying really hard, guys.
Honestly, I have had to restart this video like four or five different times, because
every time I thought that I was done, I would find some article or see some video that kind
of threw my entire point out the window, and I would have to start all over again.
There's just so many takes on this subject, and it's not that any of them are wrong, actually
the problem is that a lot of them are right.
They're probably all right.
In fact, one of them got into eugenics.
I didn't see that coming.
I mean, nobody even knows exactly how these things work, even the experts that have been
working on this for decades, so like, how am I supposed to add anything to this conversation?
Like what can I possibly say that hasn't already been said?
And if I'm being honest, I haven't even really been keeping up with this.
There's like a 50,000 AI apps out there, and I haven't been able to mess with any of them,
because I'm always just trying to get the next video out.
So not only am I trying to make an informative video out of this thing, I've got to get
caught up on a technology that I've been falling way behind on, like I couldn't feel
more older and out of touch.
And the biggest irony of all is that I'm sitting here struggling really hard to write a script
about a technology whose core value is that it can write the script for me.
Maybe I should just pick up where my last AI video left off.
When was the last time I made a video about AI?
My last video on AI was in 2016.
Wow.
Oh, there's a little baby YouTuber back then.
Okay, so yeah, the last video was talking about the three different levels of AI, so
why don't we just do a quick refresher on that?
All right, so yeah, big picture.
When we talk about AI, there's three different levels.
There's artificial narrow intelligence, artificial general intelligence, and artificial super
intelligence.
Narrow AI is what we've been dealing with for a long time now.
This has taken the form of chatbots to spell check, image processing that helps with photography,
astronomy, medical diagnostics, and so on.
Voice recognition is a kind of AI.
Virtual assistance like Siri and Alexa.
There's all kinds of AI in gaming, aviation, search engines.
The list goes on.
AI's help make our jobs easier and our lives more efficient in a million different ways.
It's also manipulated our society in ways we're just now beginning to come to grips
with.
All the polarization, isolation, depression that we've been seeing by social media, these
are products of algorithms that are themselves a kind of AI.
I know some of the biggest algorithm experts at YouTube, and I can tell you they're just
trying to figure it out like the rest of us, only they have millions of channels worth
of data to deal with versus a few channels.
Yeah, the algorithm is basically like an alien life form.
Nobody really knows how it works.
It's a black box that nobody can see inside of or understand, much less control.
This is the point that will come up later.
Yeah, all of these AIs are amazing and powerful, but they're all examples of, again, narrow
AI.
They're built and trained to do one specific thing, and they do that one specific thing
better than any person could, but that's all they can do.
And we're already seeing this bifurcation of scenarios, you know, simultaneously incredible
and amazing, but also tearing apart the fabric of society.
Artificial general intelligence is AI that can do all the things that narrow AI can do,
but for everything.
It's a generalist, much more like a human being.
I want to make sure that I'm clear here.
I'm not talking about consciousness or sentience at this point.
This isn't an artificial life form.
We're not talking about giving it personhood or rights or anything.
In fact, the consciousness thing, it doesn't even play into this conversation right now.
I think it's better to just kind of set that aside.
That muddies waters that are already pretty muddy.
A general AI is just AI that can have the same capacities as a human brain.
It can analyze images, but it can also make music.
It can problem solve and strategize.
It can deceive and manipulate.
Here's the thing about artificial general intelligence, though.
When it does happen, you'll probably miss it.
Because if an AI has the same capacity that we have, well, one of the capacities that
we have is that we can make an AI smarter.
So if an AI that's as smart as we are can create a smarter AI, that by definition is
artificial superintelligence.
This is what futurists have been saying for a long time now, that pretty much the instant
we reach artificial general intelligence, we will reach artificial superintelligence.
AI that's smarter than a human.
Smarter than all humans combined for that matter.
And this is where things really split into a couple of different directions.
On one hand, we could see a utopia where every disease has a cure, aging can be reversed,
resources perfectly allocated for all, the climate and equilibrium, economic recessions,
forever eradicated, all our wants and needs fulfilled, so we can spend our limitless lives
and pursue knowledge and happiness.
Or in an effort to get rid of all conflict, it suppresses us all into an authoritarian
surveillance state devoid of free will, with all of our wants and needs doled out according
to its all-powerful insistence on order, creating a techno-slave state.
Or it could decide that the common denominator in all the world's problems is humanity itself
and wipes us out the face of the earth, replacing us with robots and machines that live on for
a billion years, eventually spreading to distant stars and eradicating all potential life in
the universe from existence.
I may have gone too dark with that one.
There is of course another option, which is that all of this is just hype, just way overblown
hype by companies who invested billions of dollars into this and now need to sell the
product they made.
In fact, there's an argument to be made that this is just another gold rush.
AI is the new crypto.
And there definitely is a gold rush of sorts going on with all these new AI tools suddenly
being integrated in everything with a keyboard, some of which are awesome, yeah, but some
of which just don't make any bloody sense.
But really, this isn't anything new.
Companies have been using AI as a catch-all buzzword for the last decade.
It's just like this thing that they say to convince you to buy their product and say
that their product is better because it has AI in it.
Everything from cars to HVAC units to washing machines, coffee makers.
Tech investors need to beware.
40% of companies in Europe, and now claimed to be AI startups have actually, if you can
believe this, little or no connection with artificial intelligence at all.
Now, in these cases, the AI is usually just like an algorithm that allows a device to
self-adjust or optimize according to the situation.
And they've got their merits, you know, as the kind of narrow AI I was just talking about.
But it is also just marketing.
So yeah, on one hand, AI is nothing new.
It's been used to sell us on products for a long time.
What we're dealing with right now, though, is something different.
This is generative AI.
Not to be confused with general AI that I was talking about a second ago.
Generative AI, though, it's exactly what it sounds like.
It's AI that generates something that didn't exist before.
And this does feel like it just kind of popped up out of nowhere in the last couple of years.
But again, it's really just a culmination of a lot of things we've been getting used
to for a while now.
We kind of started seeing the first sparks of this back in 2015 when videos like this
from Google's Deep Dream Project started kind of making their way around the internet.
But AI would basically start off with a picture, and then it would find patterns in that picture
and the alignment of pixels and whatnot that it would recognize as other images, kind of
like us seeing faces or shapes in the clouds.
It would then pull from a set of images and insert them into the image, leading to these
mind-bidding visuals of animals and faces reminiscent of a heroic dose of mushrooms.
Or so I've heard.
Following that, the research continued into training AI models to recognize objects and
images.
That's pretty much what all those captures were all about, finding the stoplights and
the cars in the images.
You've been training AI models this whole time, and didn't even know it.
It also started to see tools in Photoshop like content-aware fill and scale that will
intelligently replace objects and add extra photo to the photo based on the space around
it.
That got fully integrated into Photoshop in 2019.
I actually use this all the time on my thumbnails.
And then there's the AI video and image filters that started on Snapchat, and then on TikTok,
and then there was a trend of AI-generated avatars and social media through apps like
Lenza.
I'm leaving a lot out, but the point is that all of these little AI tools and toys have
been around for years and becoming more and more popular.
Now, at the same time that all this was happening, there were AI's that were learning natural
language patterns.
The first auto-correct features and word processors went back as far as 2003, but it became especially
useful with the advent of smartphones.
Predictive text and phones and search engines soon followed, voice recognition paired with
natural language models led to Siri in 2011, Alexa in 2014.
And then in 2021, OpenAI announced Dali, which put the image and text features together
and had the ability to create entirely new images based off of text prompts.
All that labeling of objects and text recognition at all kind of came together so that if you
entered the word camel, it knows what a camel is and it can search its massive image archive
and it creates something that resembles a camel.
The first Dali was kind of under the radar though.
It was kind of just made for research purposes.
It was Dali 2 that came out last year in 2022.
That's what gave public access to this technology for the first time.
Mid Journey came out about the same time and people kind of lost their minds.
For the first time, literally anybody could just enter some words and do a prompt and
get a pretty good quality image out of it.
And yet anybody who's been following this even a little bit can attest to how quickly
this AI art has evolved.
And then by the time we got used to all that, here comes ChatGPT.
ChatGPT.
ChatGPT.
ChatGPT.
ChatGPT.
ChatGPT.
ChatGPT.
ChatGPT.
ChatGPT.
ChatGPT.
Okay, so ChatGPT, in case you don't already know, it works off what's called a large language
model or LLM.
LLMs are neural networks.
A neural network is a computer system that basically works like a brain.
Since a brain has billions of connections between neurons, LLMs have billions of connections
between mathematical functions that act like neurons.
I don't want to go too deep in how all this works, but I'll just quote a tweet from
Peter Yang, a creator of Economy SO, who said this quote.
Imagine that you have a library with a huge collection of books.
You want to learn everything you can from these books, such as how to write a good essay
and how to speak a foreign language.
How can you do that?
An LLM is a program that can generate text based off the books in your library.
So it does kind of work just like predictive text on your phone.
If your phone has a library of your past text, it can kind of figure out what the most
likely next word is going to be.
So I'll say if you start to type your street address, it's learn that from watching your
text and it auto-completes it.
Only an LLM has millions upon millions of books and articles to draw from, and then
they kind of weigh what they read in terms of importance.
To be clear, this is a massive oversimplification, but you get the idea.
The process of feeding an LLM gobs of text is called pre-training.
When programmers want LLMs to get better at specific tasks, they can feed the LLM more
focus text.
This is called fine-tuning.
But it's not really interested in giving the right answer.
It's programmed to give the most likely answer.
And a lot of times that answer's right.
A lot of times it's not.
For example, when I asked chatGbt to give me five facts about the YouTuber Joe Scott,
this is what I got.
Joe Scott is an American science communicator and YouTuber who creates videos about science,
space, and technology.
He's been creating content on YouTube since 2014 and has over 1.5 million subscribers.
Accurate.
Before becoming a full-time YouTuber, Joe worked as an engineer and consultant in the aerospace
industry.
He has a degree in aerospace engineering and a master's degree in systems engineering.
This is not true.
Joe is known for his informative and well-researched videos, which cover a wide range of scientific
topics from black holes in space exploration to artificial intelligence and genetics.
Well done, chatGbt.
In addition to his main channel, he has a second channel called Answers with Joe, where
he explores interesting questions that provide answers.
That's...
Second channel's called TMI, so swing and a miss.
Joe is an advocate for science education and outreach.
Sure, that's true.
He has spoken at events such as TEDx and collaborated with organizations such as NASA
and the Planetary Society to help promote science, literacy, and interest in space exploration.
I wish that were true.
So yeah, out of five questions, two of them were completely bloody wrong, and one of them
was kind of half wrong.
So also when I was messing around, I asked it to give me directions to the closest roller
skating rink to where I live in East Dallas, and it pointed me to a nice little skating
rink at the corner of Gus Thomason and Ferguson, but when I looked it up on Google, it's actually
way up in Plano, about 10 miles away.
So yeah, when people ask me if I use chatGbt to write my scripts for me, my answer is not
just no, but hell no.
In fact, the first time I ever really tried to do that, I was doing a video on smart cities.
I tried to save a little time and asked it to write a few paragraphs about the planned
city of Tulosa, Arizona, and it gave me this.
Tulosa is a bustling metropolis located in the heart of the country, with a population
of over 2 million people.
It's one of the largest cities in the nation, and a major center of commerce, culture, and
entertainment.
This city is home to a diverse array of people, with a rich mix of cultures, religions, and
backgrounds making it a vibrant and exciting place to live and visit.
Tulosa is a cultural hotspot with numerous museums, galleries, and theaters showcasing
the best in art, music, and performance, and it's home to many renowned musical and
theater productions, as well as countless festivals and events that take place throughout
the year.
Yeah, um, this city does not exist.
It's literally just computer renderings right now.
Now I will say I've used it to help create video titles for my videos, and it's been
pretty helpful with that.
And also, while I was testing it out, I thought I would try seeing if it could help me brainstorm
some ideas about a character that doesn't really exist.
Say I'm writing a book, and I made up this character about a farmer who's about to go
bankrupt.
The prompt I gave it was, I'm writing a story featuring a character that's a farmer trying
to keep the family farm from going bankrupt.
He's a tough man struggling to keep himself together for his family.
What are some quirky characteristics I could give him?
And it gave me these options of superstitious.
If a farmer could have a collection of unusual, lucky charms or rituals that he believes will
bring good fortune to the farm, talks to animals, collects unusual items, expert whistler,
green thumb for unconventional plants, fear of modern technology, expert storyteller,
proclivity for inventing gadgets.
This is pretty good.
Like that's seriously helpful.
I could actually use that.
Oh, and I also asked it to recite the to be or not to be speech in the style of Snoop
Dogg.
I was kind of hoping to see a to be or not to bizzle, but I didn't get that.
But I did, again, a matter of seconds, it created a whole rap verse that's honestly pretty
impressive.
Okay, now I am not a power user of chat GPT.
There's a million videos out there with great advice on how to create the best prompts to
get what you want.
I'll just direct you to some of those down in the description.
By the way, my prediction is that the word prompts is the word of the year for 2023.
Get used to that word.
You're going to be hearing it a lot.
Yeah, in my experience anyway, it works really well as a kind of springboard or brainstorming
partner, less well as a source of accurate information.
Yeah, ironically, the computer program is better at creative thought than accurate information,
which is fine, except, you know, Microsoft put it into being a search engine, a thing
people use to find accurate information.
And this is a problem.
As bombastic as the prognostications around AI have been to me anyway, this is a much more
immediate threat.
The way AI could accelerate the already massive problem of misinformation online.
You know, I keep hearing about people using this as a shortcut to creating content online,
which is fine.
Like I just said, there's some really helpful use cases for that, but you have to fact check
it.
And frankly, a lot of people aren't going to do that because for many people, whether
or not it's accurate, it doesn't matter.
It's just about giving people something to click on.
Combine this with the rapid advancement of the image generating apps that are already
damn near photorealistic, and we are truly entering a post-truth age when literally any
content can be faked, any image can be faked, any voice can be faked.
I haven't even gotten to that one yet.
And pretty soon nobody's going to know what to believe anymore.
So they'll just believe whatever they want to believe, only increasing the fragmentation
and distrust in our society, which has pretty got off all already.
Now the AI bros are quick to point out that this is the worst AI will ever be, that it
will only get better from here.
But on the other hand, it'll only get better from here.
Now there are other LLMs being developed like Lambda from Meta and Bard from Google that
have not been released to the public.
Google especially is being extremely cautious about releasing Bard because, you know, their
entire reputation is based on their accuracy.
Some will say that Microsoft was actually being really risky putting chat GBT into Bing
so early, but let's be honest, nobody was using Bing, so they really had nothing to lose.
But this does put pressure on Google to counter with their own search assistant.
And now we've got an AI arms race.
I guess, you know, maybe the upside is that there's only a handful of these LLMs right
now because they take literally billions of dollars to train them.
Only that's not true anymore.
Late last year, researchers at Stanford announced a powerful LLM called Alpaca that could be
pre-trained for as little as $600.
They did it to create an LLM that academic institutions can test without needing billions
of dollars of funding.
According to their paper, it worked about as well as Meta's Lambda AI model.
It didn't stay up long though.
They took it down on March 20th because they were concerned about hallucinations.
That's what they call it when computers tell confident lies.
You know, like chat GBT does about half the time.
But the point had been made.
The price of LLMs is going down from billions of dollars to hundreds of dollars, and pretty
soon people will be making these in their garages.
And since GBT-4, which hasn't been fully released to the public just yet, it has the ability
to write code, so now you have the ability for AI to write more AI and improve it.
Anybody else feeling like this is kind of spiraling out of control?
It's no wonder that over a thousand tech insiders signed a letter in March to put a pause on
AI development beyond GBT-4.
It's from the Future of Life Institute, which is controversial in its own way, and there's
a heated debate around their intentions, which is a rabbit hole.
I'm just going to have to leave out of this video.
But even with the generative AI that's out right now, we've seen a flurry of app creation
using it.
Literally every other day, there's a new crazy world-changing app that makes the news.
Some of it's been the same AI marketing I was talking about before that's nothing new,
but some of it's just bonkers.
Apps like mixo.io that create websites in minutes, jasper.ai that writes marketing and
SEO copy for the web, luca.com that creates AI-generated logos, tome.app that writes and creates presentations
with Dolly and ChatGBT, quillbot.com that paraphrases AI paragraphs so it can pass an AI detector,
yikes.
There's runway.ml, it's a video editor and image processor, Nvidia has an app that lets
you draw simple landscape and it'll just fill in the rest they call that Canva, Nvidia also
has a broadcasting app that will basically make your eyes look like it's going in the
direction of the camera.
There's 11labs.io that does voice cloning, sounddraw.io that makes music, there's agent
GPT that lets you build an AI agent that can do anything you can ask it to do, and there's
futuretools.io which is an AI search engine for AI tools.
By the way, that is just, that's just a sample.
There are hundreds of these out there and there are other channels that have reviewed
literally hundreds of these apps.
Again, I'll just point you to those, there's going to be a link downstairs.
Okay, so when it comes to these new AI tools, my personal theory is that they're just that,
they're tools.
You know, you still need to know what you're doing to get the kind of results that people
are talking about here.
You know, it's like Photoshop.
Just because you have Photoshop doesn't mean that you can do the same thing as a professional
designer can do.
I can attest to this, I suck at Photoshop.
Actually, there's a great meme that's going around that anybody who's worked in a creative
field will understand.
It says, to replace creatives with AI, clients will need to be able to accurately describe
what they're looking for.
We're safe.
I'm sorry.
As somebody who's worked in that field, I can tell you that made me laugh quite a bit
when I first saw it.
But anyway, to test my theory, I actually dug in to about 10 or so of these apps and I made
a whole separate video of it where I go through some of these apps and I try to figure out
if I can make them work as a total noob in the way that the demos of these apps say they
can.
And I'm uploading this along with this video to Nebula.
Because I've just seen a ton of these videos talking about these crazy things that these
apps can do, but I've never actually seen anybody actually use them outside of those
product demos.
So yeah, I gave it a try myself.
Some were garbage, but some I really think I might be using from now on.
And trust me, if a tech adult like me can do cool things with them, then they must be
pretty powerful.
So if you're on Nebula, you can watch it right after this video.
If you're not on Nebula, well, here's why you should sign up for it.
Nebula is the premium streaming service that I help start along with some of my friends
who just happen to be some of the best educational YouTubers in the world.
And I am completely unbiased in that statement.
On Nebula, you can watch our videos ad-free and earlier than everywhere else.
And you can also see Nebula-exclusive videos that you can't find anywhere else, including
Real Engineering's Logistics of D-Day series, Real Science's unbelievably good series called
Becoming Human.
And for those with a morbid curiosity, you can find my Mysteries of the Human Body series
and my ongoing Forgotten Atrocities series.
And something I don't talk about nearly enough is Nebula classes.
This is like some of those other online learning platforms that you may have heard of, but
these classes are run by educational YouTubers, just going full on educational.
You can learn how to produce videos like Volksgeist, how to produce music like Adam Neely, and
how to sue like a lawyer with legal legal.
And there's new ones added all the time.
And the reason why we made this platform is because YouTube can be a lot.
You know, with the ever-changing algorithm, the AI once again, we're always chasing the
content that will work here, and we're always having to be more click-biddy and sensational.
I know you guys hate that, but Nebula is a place where we can just let our hair down
and make the content that we care about.
So if you've ever thought about supporting a YouTuber, this is easily the biggest bang
for your buck.
Because not only are you supporting hundreds of content creators with that one subscription,
you get tons of content in return.
And if you sign up for the link below, you get that for 40% off the annual plan, which
comes out to a little bit over 250 a month.
Which is probably worth it just so you don't have to hear ad reads like this.
So click the link down in the description below to check it out and watch me test out some
of these AI apps, which I can tell you, if you were to test all these apps out yourself,
it would cost way more than your Nebula subscription.
You've already saved money.
Alright, so to kind of wrap this thing up, I want to kind of talk about some of the issues
that really need to be mentioned because so much of this topic gets overwhelmed by the
existential dread stuff, and while I know that's kind of my thing, there are some right here
right now problems that are far more immediate threats.
Obviously there's issues of jobs being lost to AI, and yeah, this is something to be concerned
about.
But there's also a bit of a debate around this, because one could also make the argument
that these new tools could help employees be more productive and more creative.
Yeah, there's another line that tech bros tend to say, which is your job isn't going
to be replaced by AI, it's going to be replaced by somebody else using AI.
And there's a couple of things that I can point to as perfect examples of that.
So Corridor crew did this all AI animation called Rock, Paper, Scissors, which is incredible.
And also a TikTok creator called Ghostwriter977 made a lot of news recently because he made
a song called Heart on My Sleeve that used Drake's voice in the song, but it was AI generated.
And it was so good that it got taken down by Drake's people.
And the point there is that, yeah, these guys were able to do amazing things, but these
are extremely talented people.
I mean, you can look at Corridor crew's YouTube page, I mean, they make insane stuff all the
time.
This is just a new tool they've been able to use.
I mean, going back to Photoshop, when it came out, I remember a lot of people were
worried that it was going to put photographers and illustrators out of business, but most
professionals just kind of adapted to it and just started using it and made better stuff
than they'd ever made before in their lives.
I personally do know a few artists that are actually embracing Dolly in mid-journey.
Mostly it's just kind of jumping off points to kind of spark new ideas.
And as a writer, as I showed a minute ago with some of the brainstorming ideas, like
this is a really quick and easy way to push through writer's blog.
I do worry a bit that this could kind of become an Uroboros like a snake eating its own tail
because if people use these AIs to create online content and then the AI pulls from
that online content to make new content, it just becomes an endless cycle.
There is also the whole debate around the fact that AI is using other people's work
as part of that large language model and stuff, all of which is copyrighted material
and a lot of people are up in arms about that, and I think understandably so.
But also at the same time, again, playing devil's advocate, it's not completely copying
it.
It's kind of using it as an inspiration, which we all do that, don't we?
It's like it also just made the news recently that Ed Sheeran had been sued for possibly
copying the core progression from the song Let's Get It On, but a lot of pop songs use
the same core progressions.
In fact, there were songs before Let's Get It On that used that same core progression,
which is why Ed Sheeran won his lawsuit.
So this is an ongoing debate around art that started long before AI, it'll be going on
long after, but AI does make it a bit more complicated.
Now the pessimist in me does worry that the money people see AI as a cheap or even free
content creator, and that it'll squeeze creative jobs out of existence.
But the optimist in me thinks that humans working with AI could unleash even more mind
bending ideas and that eventually the cream will rise to the top, just like all the tools
from the past did.
Now in fact, as I'm recording this, we'll see if this is still going on when the video
comes out, the WGA is striking in Hollywood.
Part of that is about streaming services and not getting paid well for the streaming services,
but a big part of the argument, a big part of why they're striking right now has to
do with AI.
And I want to just point out a thread that Justine Bateman shared on Twitter, where she
was talking about some of the big issues and things that we can expect to be happening
in the near future with AI for some of the things that they're trying to get ahead of.
She starts by pointing out that she is actually a coder and she has a computer science degree,
so she does know a bit of what she's talking about here.
She points out that AI written scripts and digitally scanned actors already exist.
And actually Bruce Willis made news for signing over his AI rights to his likeness.
This kind of started happening when he was diagnosed with aphasia and couldn't really
perform anymore.
He sold his AI rights so that people could continue to make movies with him in the distant
future.
She points out that in that case, your digital image can be triple and quadruple booked,
so an actor could actually be working multiple projects at the same time.
She suggested in the future that films could be customized for the viewer, meaning people
could just special order a movie if they wanted to.
She uses the example of I want to film about a panda in a unicorn who saved the world in
a rocket ship and put Bill Murray in it, so you could be watching whatever streaming service
they might offer something where you could just give a text prompt and it will just create
a movie as you wanted to see it.
Which Bill Murray with a panda in a unicorn saving the world in a rocket ship just sounds
like a Wes Anderson movie.
Which actually I'm pretty sure that Wes Anderson at this point is just an AI that's been pre-trained
on Wes Anderson movies.
She points out the possibility of people getting themselves scanned and putting themselves
into films so like you could put your own face on Darth Vader.
She said you could train an AI program on a series and then just create a whole new
season of that series.
And that brings up some really interesting possibilities but my big question is, is that
something people want?
I mean, would you want to see that?
Like there are already programs like Nothing Forever, which is a never ending AI generated
Seinfeld episode.
I mean, who isn't crazy these days?
This is terrible, but it will get better.
And actually the Nothing Forever thing, it's streaming on Twitch, they took it down because
it started using homophobic slurs.
So there's that.
Yeah, you know, computers doing all the creative stuff while people keep working in factories
for lower and lower paying jobs is not the future I was hoping for.
Now as for administrative and legal jobs and whatnot that's under threat by AI, that I
don't think is anything new.
I don't mean to minimize that as a threat.
It definitely is to a lot of people, but that's a trend that's been going on for quite some
time now.
And again, I think the more familiar you are with these tools, the safer your job is going
to be, but there are a lot of takes on that subject.
Now one area of AI that did put me on my heels is that of AI and warfare.
I talked a little bit about AI in my episode on the future of war, but that's a debate
that's only getting bigger and more confusing.
AI gets used in a lot of ways by the military from image processing to logistics, but what
about AI is having the power to decide if a person lives or dies?
Like just the fact that, you know, drones were conducting strikes controlled by an operator
hundreds of miles away, like that was iffy at the time when that started being a thing.
But now the debate is whether or not an AI should be allowed to make that decision.
But even bigger than that, way bigger than that is that increasingly there's been talk
about giving AI the ability to launch nuclear weapons.
I think I need a lighting change.
So back in the 80s, the Soviets instituted a dead hand mechanism on their nuclear arsenal.
This was in the event that, you know, decision makers might get wiped out in a nuclear strike
on Moscow.
It would automatically trigger all their nukes to fire at the U.S.
Now you could say this was kind of an early algorithm or automation of the nuclear arsenal.
And similarly, the U.S. has contingencies in place in the event of a first strike scenario,
but that time horizon on first strike has gotten smaller and smaller over the years.
First ICBMs could reach the U.S. in about 30 minutes.
The nuclear submarines cut that time in half.
Today we're seeing the birth of hypersonic missiles that could cut that in half yet again.
So now in a nuclear scenario, military leaders may have less than seven minutes to make a
decision and retaliate.
And that's led many to consider handing those decisions over to AI to save precious seconds.
So when we talk about an AI arms race, this is the ultimate version of that.
We could see a day in the very near future where the U.S., China, and Russia all had
their nuclear arsenals controlled by AI.
AI that we don't fully understand or control with the ability to wipe out all life on Earth.
Anyway, just something to think about.
Ultimately, I think what we're dealing with here really is just an amplifier.
It's a highly evolving set of tools that can make production more productive,
create is more creative, bad actors into worse actors,
scammers more successful, and weapons more deadly.
It's the Wild West right now.
And we really don't know where this goes.
And I can hear all the comments already of people saying,
you forgot about this, you forgot about that.
Yeah, there's a lot that I left out of this video because it's just too much.
This is already way too long of a video.
And writing this kind of broke my brain.
The whole thing just gives me like a grandma migraine headache.
Like not here or here so much, but like right here.
So any one of the topics that I brought up here and any of the things that I left out
for that matter could be entire videos of their own.
So yeah, if this video does well and you guys want to see a video on any of those topics,
let me know, maybe I'll do them.
And also, there's a ton of videos and creators doing great work on this topic.
Again, I'm going to put links down in the description so you guys can go check it out.
I encourage you to do so because we got to stay on top of this.
The genie's out of the bottle.
But I think I'll leave things off with a quote from Jeffrey Hinton,
who's often called the godfather of AI.
He's been working on AI in neural nets since the 80s.
And he was working with Google until recently.
He actually, he left Google so that he could speak freely about the subject.
He recently said this in an interview with CBS.
This is the biggest technological advancement since,
is this another industrial revolution?
What is this?
How should people think of it?
I think it's comparable in scale with the industrial revolution or electricity.
Electricity, yeah.
Or maybe the wheel.
Or maybe the wheel.
Yeah, that was earlier.
Yeah, okay.
So buckle up.
Yeah.
All right, thanks a lot for watching.
Go check out that other video over on Nebula if you want to get your brain
melted just a little bit yourself.
But I want to take a minute to quickly thank all the Patreon supporters
and answer files on the member side.
I got some new people I got a shout out real quick.
We got Joe Ape, Adam Russo, Edward McPhail, Brett Messenger.
Welcome back, Brett.
Ryan Jay, Norman Barton, Josh Deruse, Don Hyman, Stephen Hager, Bruce Danton,
Nicholas Altieri, and Jan McCall.
Or Jan McCall, I'm not sure which one that is.
But thank you guys so much.
If you would like to join them, get early access to videos and access
to exclusive livestreams, just click the little join button down below.
Please do like and share this video if you liked it.
And by the way, share your opinions on this topic.
My god, it's such a big topic.
And again, there's so much that I left out of this.
Talk about it down below.
But if this is your first time watching, maybe click on this video right here.
Google thinks you might like that one because they've been watching AI and all
that.
You can look down on the sidebar if you're watching on your browser.
Any of the thumbnails that have my little logo on them, give them a click.
And if you enjoy them, I do invite you to subscribe.
I'll come back with videos every Monday.
All right, I am putting this video to bed.
Thank god.
Thank you guys for watching.
Please go out there and have an eye opening rest of the week.
Stay safe, and I'll see you next Monday.
Love you guys.
Take care.
