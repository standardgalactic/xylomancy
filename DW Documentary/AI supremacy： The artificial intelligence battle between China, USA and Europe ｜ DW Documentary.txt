After many, many years later, maybe we will look back, we recognize that, oh, that's the
moment when everything changed.
In five years, AI is going to literally be in everything we do.
As humans, we have to, first of all, understand that this is going to happen.
Many technologists try to solve human problems using technology when actually what we need
are human solutions.
The deeper question is, what does it mean to be human?
What are the things I'll still be proud of?
I find this moment extremely profound because it really forces us as a humanity to think
through exactly what consciousness is, what makes humans human.
There's a whole lot at stake here, careers, unbelievable amounts of money, and who gets to shape the future.
It's already begun.
A global race for supremacy in the age of artificial intelligence.
China, the United States, and the European Union are vying for economic growth, political influence, and power.
So are the big tech companies, and startups are hot on their heels.
For those who lose, there'll be no second chances.
Jonas Andrewles founded one of the most influential European AI companies.
With his help, the European Union could catch up with the world's AI leaders, become independent from the US and China,
secure a prosperous future.
This is a watershed moment for Europe, the last roll of the dice.
If Europe wants to decide how to use technology in accordance with European values, then it has to be able to build that technology itself.
Thomas Wolff co-founded Huggingface, a major open-source AI platform.
He wants to stop one of the most powerful technologies in human history from ending up in the hands of a few corporations.
What we need is a multitude of players, not just one that owns AI.
We don't want a future where such a fundamental technology is in the hands of a single company.
There are plenty of films where that's the mark of a dystopia, one company that controls everything.
Han Chao is a Chinese AI entrepreneur.
He wants his company, Gina AI, to be successful on both the Western and Chinese markets.
So what role do Chinese AI companies play in this global race?
And how is the Chinese Communist Party using them to achieve its political goals?
Chai GPT or GPT-4, it basically serves as a brain.
And this brain cannot be made in the US, right?
So this is some worry that the Chinese government has.
The culture of each country, how each government runs this country will eventually be reflected into the brain.
It is absolutely clear that at the highest levels of leadership in the United States and in China,
artificial intelligence is viewed as foundational to the future of economic and military power.
We've created an economic and financial system that's based on the assumption that everything's going to keep running smoothly.
We get cheap gas from Russia, the Americans look after us, so we don't need to spend money on arms.
China is always friendly.
We've gotten comfortable.
And now we have to break out of that comfort and say, we can go on the political offensive again.
We can compete.
We can create competitive conditions here.
We can make sure that the cool companies we have can also grow and play a role in the global market.
That's already been made clear.
At the end of 2023, German Vice-Chancellor Robert Harbeck made significant progress towards these geopolitical goals.
Aleph Alfa, a German AI company, raised around half a billion euros from investors.
It was one of the largest rounds of European financing for artificial intelligence technology,
and it was a signal that the European Union can produce elite players in the field of AI.
Aleph Alfa's founder and CEO is Jonas Andrewles.
He's given priority to investment from German industry, SAP, Bosch and the Schwarz Group,
which owns supermarket retailers Liedl and Kauffland.
I was an amateur radio enthusiast.
I soldered radios together and built my own antennas.
Early on, my father had computers at home, so I was able to start programming and playing around with them at a very young age.
When we started out, the term generative AI didn't exist.
Hardly anyone had heard of open AI.
We were very technical.
We managed to create category-defining innovations.
We were just nerds, researchers.
And there were times when I felt like I wasn't coping with the amount of work and the challenges.
Every night, I could answer emails until I was so tired, I fell off the couch.
And there were still things I was neglecting, which I didn't want to neglect.
In spring 2023, the European AI landscape was a lonely place.
With his start-up, Alfa, Jonas and Andrewles had built the only generative AI that could compete at an international level.
He'd acquired the expertise from his work as a high-ranking AI researcher at Apple.
Suddenly, he'd become one of Europe's great hopes in the global AI race.
Right now, we simply can't cope with the onslaught of potential customers and partners.
Most of the German stock index companies have been in touch.
Lots of medium-sized companies.
There are briefings, press engagements, events, an unbelievable amount of stuff.
It's like the Cambrian explosion right now.
An incredible amount of new and creative things are emerging.
We're the only Europeans in the world that can do this.
It was an exciting development.
We also had things like open AI, and maybe ours were even cooler.
What is missing and what I think deserves more attention in the EU is why there are not more domestic companies that actually grow and scale.
A lot of company leaders, start-up innovators, end up going to the US, and the access to capital is really one of the main challenges.
If you look at what we did, it's enabling technology.
What I need for that is a carefully selected, effective team of brilliant researchers.
Then I need money.
More money than you normally get as a German start-up.
These days, we're talking about billions.
And then you need partners to help you.
The kind of help that money can't buy.
Open AI doesn't just get 10 billion from Microsoft.
It also gets incredible support in integrating its technology into all Microsoft products and platforms.
At the time, Aleph Alpha had 60 employees at various locations.
Most were at the company's headquarters in Heidelberg in southwest Germany.
Unlike open AI, Androulas wasn't gearing his AI towards private users, but rather industry and the public sector.
But they tend to be sluggish and not easy to win over.
That posed a challenge for Jonas Androulas.
He needed pilot projects to prove his technology works.
You stand here and you're greeted by a virtual person.
Hello, may I help you? Where do you want to go?
Then I can use the screen.
We have to keep moving in this direction.
That's not good. That's my job.
I know it is, but we're very happy to still have you.
She'll probably be taking her well-earned retirement soon.
It's become a standard question.
I ask if you'd like to stay on a little longer because I need you
and because there aren't enough skilled workers coming in.
It's a big issue.
That's important for us.
Solidarity.
And of course the main topic is innovation.
Heidelberg is one of the first municipalities in the world
to introduce an AI citizen assistant using a language model
provided by Aleph Alpha.
We have a partner, a customer, with whom we can look at these new technologies.
They also act as a testimonial for us because anyone can go and try it out.
That's a huge advantage because a lot of our customers
don't want to be named right now.
They don't want people to know exactly what they're doing,
so it's great to have a pilot customer with a bit of vision and courage.
The hope is that in the long term,
AI will improve public administration and speed up services.
I just enter a question.
Motor vehicle traffic on the B-37, which is a busy road.
Then I get it to search.
Of course, that's a very general question.
The question now is what point in time,
whether we're talking daily or annually.
Of course, the AI has to work out what the user actually wants.
The B-37s closed between 7 a.m. and 6 p.m.
Now I can ask, how do I apply for child benefit?
That wasn't the right answer.
It can't find anything now.
The messages that we get back from the public
and from tests we do ourselves
get passed on to ALEF Alpha
to figure out what needs to change
to make the inputs more accurate.
It's always about the accuracy of the inputs.
The technology is still in the test phase and not yet reliable.
2023 was a delicate time for ALEF Alpha.
Jonas and Drullis needed fresh money from investors.
Meanwhile, Microsoft and OpenAI were gaining more of an advantage.
In fact, a race starts today and we're going to move.
We're going to move fast.
And for us, every day, we want to bring out new things.
On March 14th, 2023, OpenAI released chat GPT-4,
the most powerful artificial intelligence to date.
At the same time, it greatly reduced costs for users.
For Jonas and Drullis and his team,
it was a threat to their business model.
I'd like to poem about fly fishing from the perspective of a fish.
And it goes on for hours.
It's huge.
Oh, wow.
In the depths where shadows weave and play,
in this cool, clear waters where I stay,
I am the fish beneath the silver stream,
where life's a dream, or so it seems,
a wily being, sleek and sly,
with ancient instincts to live and die.
Yeah, it goes on.
Yeah, well.
Yeah.
They see the ends of my heart.
I went to an apartment with a number of colleagues
and we watched on a big projector screen
the announcement of GPT-4.
Someone had a chat GPT-4 account,
so they could use GPT-4 and we could play with it.
And we were, like, very impressed
and surprised by how good it was.
It's not upsetting when someone comes out
with a great piece of technology
because we're researchers and building technology
and that's how it is.
You know, when you're a violinist
and you go and you watch an amazing solo
by an incredible violinist,
you don't feel, oh, you know, I should,
I'll give up.
You know, it's inspiring.
I was a little stressed out.
I was in the middle of conversations
with potential investors, business partners
and I knew that in every conversation
I was going into, somebody would say,
but GPT-4.
I would have wanted to build GPT-4 myself.
Two years ago, get 200 million,
be the first model at that level of capabilities
out of Heidelberg, out of Europe.
It caused a lot of frustration on the team
and I saw that, that's painful to see.
In fact, comparing OpenAI with ALEF Alpha was absurd.
OpenAI was almost half owned by tech giant Microsoft,
which had pumped over 10 billion dollars into the company.
Jonas Androulis had raised just 28 million euros.
Still, he wanted to take them on.
We're all under enormous pressure.
We're fighting for survival.
We've created something world-class with a lot less money.
We're basically at the forefront on the highest level.
But we all know that there's now a wave
of Microsoft money rolling towards us
and we can't do anything to stop it.
It's very easy to speak in French or English?
It might be difficult to make really French
without English words everywhere.
Because, yeah.
While Jonas Androulis was filling the heat
from industry top dogs, Microsoft,
he was trying to find a solution
to the problem.
Jonas Androulis was filling the heat
from industry top dogs, Microsoft and OpenAI.
Thomas Wolfe was more relaxed.
He co-founded Huggingface,
which has 200 employees and offices
in Paris, New York and Amsterdam.
The company has built a successful platform
where programmers and companies can share AI models
and further develop them.
The philosophy, the mission and the values that we push
are actually very European by some way.
Being careful about the data,
trying to build something responsible
and not just go fast and break it.
There are definitely Anglo-American values
in chat GPT.
We wondered whether we could set up a project
to analyze and document that.
For example, with benchmarks
that could show whether a model has Anglo-American,
French or German values.
It would be interesting to do a comparative study
between chat GPT and Bloom Chat, wouldn't it?
If you ask a question in different languages,
how different are the answers,
depending on the kind of question?
Is the approach more American or European?
That would be an interesting study.
When I talk about pluralism of values,
I mean that every population in the world
has its own value system.
We have a lot of different nationalities here
and we have to ask ourselves,
what are our values?
What's important to us?
Optimistic space.
Optimistic parks in Europe,
like new start-ups.
Germany, Aleph Alpha is already a big player.
In the UK, stability is obviously a very visible player.
Here in Europe, in France,
Mistral is a new player in Finland.
So in almost every European country,
I see at least one or two start-ups
with this ambition to become
and to build something big.
As idealistic as Thomas and his team
from hugging face appear,
there is also criticism.
Open source or not, the end result is
that a small elite of tech professionals
is determining what our future looks like
and what risks we're exposed to.
All the business people I meet say,
we need education.
Society has to educate itself.
We only create the systems,
but you can design those systems in different ways.
For example, you can make it
so that a person can understand what's going on,
at least a little.
This could be one of the obligations
we impose on the industry.
These machines have processed all cultural knowledge
and are created by mathematicians
who don't know anything about culture.
That's a bit of an exaggeration, of course,
but we have to find ways of explaining this to people
who aren't interested in the math.
They just use the machines as tools.
They need to understand where the limits are,
in which situations the machine will or won't work,
just like with GPS devices,
where we recognize when they give us the wrong route.
Isn't it great that such a huge research field is opening up?
I find it fascinating.
But there's also a huge gulf opening up.
Who's actually responsible in the end?
Because as a developer or researcher,
you have a certain responsibility.
It's not about restricting research,
but when there are applications
that are harmful to society,
we have to be aware of that.
There is a huge potential for manipulation.
Just think of the influence of chat GPT on elections.
I think there needs to be an antidote.
More education.
That's a good topic for the upcoming elections.
What education do we need to stop us being manipulated?
That's a big question.
What happens when people start asking AI who they should vote for?
Because the AI will give them an answer, as it always does.
Who decides how it answers?
Who should decide that?
Unfortunately, I have no answer to that.
Generative AI is developing at breathtaking speed
and tech giants are battling it out in the ring.
That's spurring development even more.
There's a massive new market up for grabs.
Leading AI experts worry that big tech,
in its eagerness to compete,
is creating technologies beyond our control.
I think we've made a mistake
when my Swedish countryman Carl von Linneus
branded our species as Homo sapiens,
because sapiens means the thinking Homo,
the smart one, right?
We're not going to be the smartest anymore.
Maybe we should re-brand ourselves the Homo sentience,
the feeling human.
We can feel curiosity, meaning, purpose, love.
That is what really makes us unique.
We should ask how can we keep control over the machines
so that we can use them as tools to build a world
where we can really have human flourishing
with positive experiences.
In 2014, when I founded the Future Life Institute,
it was quite taboo to even talk about AI safety at all,
because that would imply that it wasn't totally safe.
And a lot of AI researchers thought
that it would be bad for funding
and that only weird people worried about this.
It was very much like coming out of the closet moment
for people to sign this letter and say,
oh, you too are worried?
I think we should slow down a little bit.
Oh, I didn't know that.
And then it suddenly became socially acceptable.
Max Tegmark and his Future of Life Institute
published an open letter,
warning that artificial intelligence
posed an existential danger to humanity.
Civilization itself could be under threat.
The letter was signed by hundreds of AI researchers
and tech industry leaders,
including Tesla boss and ex-owner Elon Musk,
Apple co-founder Steve Wozniak,
and touring award winner Joshua Bengio.
And it's been quite shocking that we've had
a lot of people who have been involved in AI research
in the last few years.
The award winner Joshua Bengio.
And it's been quite shocking that once we put this letter out
and kind of a who's who of AI researchers signed it,
the conversation really exploded.
My worst fears are that we cause significant,
we, the field, the technology, the industry,
cause significant harm to the world.
I think that could happen in a lot of different ways.
It's why we started the company.
I think if this technology goes wrong,
it can go quite wrong.
And we want to be vocal about that.
We want to work with the government.
I think he was serious about that.
I think that's kind of,
so he was talking about this existential risks.
And I also believe there are existential risks.
There are also a whole spectrum of other risks.
And I know of some, I talked to him a couple of times about this.
He very much recognizes them as well.
On the one hand, of course, these warnings
about the major power of this new technology
also amplify the significance of the products
that these people are building.
So it could also have an indirect marketing effect, right?
Like look at the incredible things that we're building.
But also let's make sure that nothing goes wrong.
And for that, they look to the politicians.
The net effect of that could be that
if heaven forbid something goes wrong,
they could say, well, we warned you,
but the politicians did not act,
or they did not act in time.
So I'm looking at a paper here entitled
Large Language Models Trained on Media Diets
Can Predict Public Opinion.
This is just posted about a month ago.
This work was done at MIT and then also at Google.
The conclusion is that large language models
can indeed predict public opinion.
I want to think about this in the context of elections.
Should we be concerned about models
that can, large language models,
that can predict survey opinion
and then can help organizations into these fine-tuned strategies
to elicit behaviors from voters?
Should we be worried about this for our elections?
Yeah.
Thank you, Senator Holly, for the question.
It's one of my areas of greatest concern.
The more general ability of these models
to manipulate, to persuade,
to provide sort of one-on-one interactive disinformation.
I'm nervous about it.
I think people are able to adapt quite quickly
when Photoshop came onto the scene a long time ago.
For a while, people were really quite fooled
by Photoshopped images,
and then pretty quickly developed an understanding
that images might be Photoshopped.
This will be like that, but on steroids.
And the interactivity,
the ability to really model, predict humans well
as you talked about, I think is going to require
a combination of companies doing the right thing,
regulation, and public education.
2024 is a crucial election year,
not only in the United States, but worldwide.
There will be European Parliament elections.
There will be elections in India.
I mean, it's a large amount of people in the world
will actually go to the polls.
And while we're living in this big experiment
where it's very hard for independent researchers,
journalists, civil society organizations
to probe these models,
that we may only find out, you know,
what the harms and malign uses
as a weapon against democracy were when it is too late.
Shortly after Sam Altman appeared before the U.S. Senate,
he co-signed a statement
along with a number of high-ranking executives
from Google, Microsoft, and other tech companies.
The fact that it was the companies who themselves
were asking for this type of regulation,
and it was the leading researchers who were asking
for the government to get involved,
that really was the turning point in the conversation.
To understand the effect that generative AI was having
behind the scenes of global politics at the time,
you have to travel north to a small Swedish city called Luleå,
around 150 kilometers south of the Arctic Circle.
When people say that artificial intelligence
is going to be like the next industrial revolution,
I think they're underestimating its impact.
It's not just going to be a new technology like the steam engine.
It's like building a new species.
A species that's much smarter than us.
President Biden himself was having meetings
on artificial intelligence, in some cases,
as often as three times per week.
And I will tell you that not very many things
get on the president's calendar for three times a week.
May 31st, 2023.
The sirens and motorcades descending on this Swedish coastal city
gave a sense of how much was at stake.
Leaders came here to discuss nothing less
than how humanity should react to the arrival of this new,
albeit artificial, form of intelligence.
What role should politicians play?
Democracy needs to show that we are as fast as technology.
You saw the first letter on asking for a course of six months.
You saw yesterday a number of very, very insightful people
signing up to say you need to do something for the very existential risks.
And then you have the non-existential risks as well.
Why is it important for the European Union to have a common policy
with the US concerning AI
and shouldn't other parts of the globe be included in the conversation?
Europe is important, but this is bigger than Europe.
The US is important, but it is bigger than the US.
But if the two of us take the lead with close friends,
I think we can push something that will make us all much more comfortable
with the fact that generative AI is now in the world
and is developing at amazing speeds.
Music
Jonas Androulis was also invited to the top-level meeting in Sweden
to represent the views of European AI startups
and call for fair competition.
Of course, there are other AI companies in Europe,
but we're the one that's keeping pace the most with the global leaders.
I assume that's the reason why we're here,
not because we're so charming.
Music
How do you feel about that?
We can raise more capital.
Two weeks ago, I was at the SAP Sapphire Conference
and Christian Klein, on his opening keynote,
he said, our key partners for generative AI are
Alif, Alfa, Google and Microsoft.
Then I'll have events coming up with HPE and Antonio Neri.
What do you think about our colleagues on the other end here,
from Anthropic and the latest statements, etc.?
Obviously, the statements on safety.
Yeah, like yesterday and so on.
Long-term, it is possible to conceive catastrophic events.
I've had Brussels and Berlin and they basically are scared.
Music
We will start with Jonas Androulis, the founder and CEO of Alif, Alfa.
The floor is yours and thank you very much for being with us today.
All right, thanks for having me.
I think we're all a little bit dizzy.
The speed of change, like everybody I know that is in AI,
is kind of stressed out.
With this technology, we're only even just stretching the surface.
I fear that knowledge work is an important part of what is happening in Europe.
So this is an opportunity for us to build new empires, to build new value,
but it's also a risk that we're losing a substantial pillar that we're standing on.
Thinking about how we can make this a fair playing field,
because I think it's in everybody's interest that Europe will contribute
to a safer future in AI.
Music
While the US and EU were trying to come up with a common strategy,
on the other side of the world in China,
an artificial intelligence ecosystem was emerging with its own set of rules.
AI is a key part of China's efforts to become a global power.
I always remember my mom and my dad pushed me to this Olympic school
in order to get specialized in mathematics and also English school.
It's like an extra work besides this regular schoolwork.
So basically you have to take the lessons on Saturday, on weekend.
It makes me a quick learner and my mom is correct.
So in order to keep progress, in order to keep pushing yourself,
you have to keep learning.
And I always tell my employees also to keep learning,
to keep up this fast pace in AI.
Music
My father was a professor in computer science,
so I'm very lucky to get in touch with AI in the very early days.
Back in 2009, I was trying to build some AI models, very simple AI models.
Nowadays, if you look from today's large language model perspective,
that model is like a very simple, simple, like a small ant.
Music
Han Shao has worked in both the East and the West.
He's held positions at the Chinese tech giant Tencent
and German online retailer Zalando.
Three years ago, he founded his own company.
Gina is an AI startup with offices in Shenzhen and Beijing.
But its headquarters are in Berlin.
Oh, where do we have another interview here? Why?
Yes, for the website.
For the website?
We have the internship program with interns
and now we want to add also like employees experience,
so people can see how it is to work at Gina.
Not only from an intern perspective.
Yes, I see, I see.
Music
So, Kaleem, of course, from India.
Isabella from South Africa.
Aladdin from Tunisia.
Jackman from Malaysia.
Michelle finally from Germany.
Music
I have a limited amount of wires, right?
And so I can only power one monitor.
And so like sometimes I really need to like show people the architecture
and like also show people the results of the model.
And so it's nice that I have like this second screen where I can draw on it as well.
So like it basically becomes touchscreen.
Music
So this is basically showing the progress of training the model.
It's kind of like stock market, right?
I see this model performs relatively good
because you can see it's increasing over time.
But sometimes it's not very successful.
For example, this one, this model start very high.
But then the progress kind of stopped.
That is wasting our time, it's wasting GPU resources, energy and so on, right?
Music
Han Shao and his team are working on optimizing AI models for specific applications.
For example, linking text, video and images.
Their goal is to make communication between humans and machines
more intuitive and natural.
Music
A lot of people may recognize this.
This guy, this is a kind of grandparent meme, right?
So it's very popular on social media, right?
So if you upload this picture to the algorithm, it will generate a story.
You can generate comedy, erotic, fantasy, horror, all this kind of story.
So we just keep it default and then we just do.
It wasn't supposed to be like this.
I was meant for more.
He whispered to the room, his words echoing into silence.
I am more than the lonely man I've become, more than these disappointments.
Suddenly, his eyes glinted, a revelation forming within his mind.
Perhaps, it is time I showed the world that again.
With strengthened resolve, Arthur placed the coffee down,
marking an end to his solitary reflection and the beginning of a new chapter.
So basically this is what you can do when you push multimodal AI into an extreme, right?
So you can see from a single image, you are able to generate not only a text description,
but an emotional audio story.
Eventually, Chinese companies will be in the leading position in this generative AI.
Two months ago, I was participating in this World AI Congress in Shanghai.
And during that conference, there were 30 large language models released on one day.
Some from big companies like Tencent Alibaba, Baidu,
some also from like a middle-sized companies from different industries even, right?
For example, from Bank.
This Chinese company are usually very good at learning from U.S. companies, right?
So they kind of copycat what U.S. companies are doing and then make it even better.
I don't doubt that one day, you will see one of the top models
in the benchmark in the leaderboard actually from China.
The question of which companies will dominate the age of artificial intelligence
has real geopolitical consequences.
China is using the expertise of its tech companies to expand its power.
Western nations, meanwhile, are trying to counter this.
My name is Jeffrey Kane.
I was a long-time journalist and foreign correspondent in China.
I wrote a book called The Perfect Police State,
and I was an advisor to the U.S. Congress, to the House of Representatives,
on sanctions and Chinese politics.
From what I have seen around the world in China and elsewhere,
I am deeply concerned that we do not know how to manage AI yet.
We do not know what's coming.
We do not know how to rein in this technology
and put it to the good use of our democracy.
China has been leading in bringing technology under state control
and, in fact, using it as an instrument for state power,
whether it is for internal control and censorship, a grip on society,
or whether it is their global ambition to have digital infrastructure
around the world and to work with countries, for example,
I think, about the African continent.
It is, of course, a vision that is at direct odds with that of democratic societies.
In 2017, China's national strategy for artificial intelligence,
and this is a public document,
set out the explicit goal of dominating global AI technology.
And so I think the United States has explicitly set the goal
that we are not going to assist China in rising
as an AI-enabled authoritarian superpower.
Ironically, in the past, it's been large U.S. companies
that have undermined their government's policies
in order to gain access to the massive Chinese market,
foremost among them, Microsoft.
Microsoft is the most pivotal and important western company
operating in China that has helped the Chinese government
develop its AI dystopia.
Microsoft set up an office in China called Microsoft Research Asia.
This was a gesture from Bill Gates back in the 1990s
because he wanted to guarantee stronger market access to China.
This laboratory has gone on to train the who's who lists
the superstars of the Chinese artificial intelligence world.
Many of the key people in this laboratory have gone on
to found companies such as MakeV, SenseTime,
or either found them or they've taken on very senior roles in them.
That was like the incubator of the modern Chinese internet or AI industry.
A lot of great people, great researchers, startup founders
actually come from Microsoft Research.
And those talents are now becoming kind of the very big influencers,
opinion leaders, and really like entrepreneurs in China.
Microsoft helped build China's tech elite.
This in turn has been used by the Chinese government
to create a gigantic surveillance state that operates with the help of AI.
Like in China, in Beijing, and Shenzhen,
you can find the most CCTV camera in the world.
And to be honest, like general public get used to it.
So they don't see this as intrusion to their own privacy
or having a software that analyze their behavior
because the kind of narrative there was to protect them,
to make the society more secure,
to protect from terrorists and so on.
So in general, the public over the last 10 years
has already accepted the fact that there are surveillance everywhere.
And now, not only you have an option of listening to all the information
that people exchange in society,
now you also have the cognitive capacity to process all of this.
So that's a scary, scary future.
Unfortunately, it's definitely not an impossible one.
Right now we have like over 500 city brands across the country.
That means one city is just like Shanghai.
They have a lot of big data analysis center.
They're collecting all this data from different areas.
And they have the machine, they have the algorithm,
like centralized it and do the computation analysis
and making all these decisions.
The Chinese government has used all forms of AI so far.
They see AI as an extremely powerful tool
that they can use for the military, for national security,
for state surveillance, police work,
also the management of cities, traffic.
They have been selling these same technologies all over the world,
especially to authoritarian governments
with the promise of total surveillance
and a nation free of crime, free of dissidents.
It's a brave new world
because we have not yet found a solution to this in the West.
China is forging ahead.
The US is pursuing its own interests.
And the EU?
It's striving for independence.
If Europeans don't play a part
in shaping this future technology,
then it will be American or Chinese AI
that will penetrate our lives to an unprecedented extent.
It will know us as well as our closest friends and relatives.
It will communicate with us around the clock
and influence our thoughts and actions.
To prevent this, the EU needs companies
that can not only program
but also build their own hardware infrastructure.
The EU needs companies that can not only program
but also build their own hardware infrastructure.
To keep highly sensitive data safe.
The most important resource for the future of generative AI
is GPU power.
In other words, computing power.
In the future it will be as essential as electricity
and water have been for developments
that have taken place in the past.
There's already a saying in Silicon Valley,
the GPU poor.
The people with fewer graphics cards.
Training high-end AI language models
requires thousands of high-performance graphics cards,
which is also why supplies are scarce.
That's another reason why many smaller players
ally themselves with large tech companies.
A lot of the deals in the field of generative AI
in recent months have come at the cost of independence.
Many companies have partnered with large corporations
by accepting restrictions on things like hardware selection,
cloud selection, integration.
We absolutely didn't want to do that.
Early on, Jonas Androulos recognized the value
of having one's own hardware.
He built a data center for his company in Germany.
For that reason, Alif Alpha is becoming increasingly
strategically important for politicians.
The media talks about you as Germany's
answer to chat GPT. Is that right?
That's wrong. You could say Germany's answer to open AI.
But chat GPT is a product aimed at the consumer.
It's really intended to help school kids do their homework,
or to write a poem for grandma's birthday and things like that.
That's not our target group at all.
We want to go where the most complex and complex
processes are. For example, in the financial industry,
in administration, in security, in healthcare.
That's where we want to build systems that assist
and support people.
We are in a government ministry here,
and public administration could benefit enormously from AI.
We have an incredible number of processes
that could be systematized and carried out.
So the focus of my work here was a bit like asking
how the public sector could act as a mainstay consumer.
Generating work, if you can put it like that,
which would create demand for German and European
AI technology.
I mean, it's an AI company that targets the public sector,
and we are the public sector.
So we only have to see that we generate opportunities
for these technologies to be tested, be it through customer
experience, funding decisions, or even permits.
We talk a lot about regulation and that kind of thing,
but if we continue to be dependent on foreign countries
and commercial enterprises for this essential technology,
then in the future things could potentially end up
like they did with energy, like with gas recently,
where we wanted to say certain things, but we couldn't,
because otherwise it would have gotten cold and dark around here.
The data center that so far ensured
Aleph Alpha's independence comes from US company
Hewlett Packard Enterprise.
Hewlett Packard Enterprise is one of the biggest players
when it comes to setting up computer infrastructure.
They build data centers.
They set up internal server rooms.
A lot of the high quality infrastructure
in which the modern world runs comes from HPE.
Andrew Lewis secured a strategic partnership with HPE,
giving him access to hardware
without tying him to the company exclusively.
He also hoped it would help him gain a foothold
in the US market.
He finalized the deal in Las Vegas with HPE CEO Antonio Neri.
Welcome to HPE Discover 2023.
This event is special because of this
our annual opportunity to reunite
in the global community of customers and partners.
We're announcing a major joint project with HPE today.
There will be a press release going out simultaneously.
It will be a big joint market venture.
That's the important thing.
Not that I'm going to go on a stage,
but that we're now taking a joint step
with a major partner.
Am I nervous? Maybe a little.
We've been working towards this for months.
I'm sure it'll go well.
What is the competitive advantage of your model eventually?
So, I mean, we're building our model.
We have an independent tech stack,
so we're not relying on any external dependencies.
We've recently solved explainability in a new way,
so you can not only see positive and confirming sources,
but also disagreeing sources.
You share with me an example.
Yes, exactly, right, from your own kind of speech.
So, I think this is...
They are analysts here, so be careful.
Well...
Americans move fast.
They're willing to take risks,
but of course this partnership also has to benefit HPE,
and any partnership can come to an end at any time.
You're a little patient.
Jonas and Droolers wanted to avoid becoming dependent
on a large corporation,
as with OpenAI and Microsoft.
But that strategy brought with it a major risk.
If his technology doesn't keep up with the competition,
he'll be out of the race.
We'll have more money soon.
Yeah, exactly.
I'm hoping that yesterday helped a little bit with that.
Oh, yeah, it certainly didn't hurt.
And I've got some kind of immediate feedback
after the show from investors on my cell phone.
And of course I want to put this money to work.
I think if we can get your help,
if we could get your help to really say,
okay, these are the application use cases,
I think we can get that list from you.
And then we can turn around and look at,
okay, one, how do we package it?
Two, can we use it internally?
I think that would be great.
And then obviously three,
how do we make sure we line up the services offer?
Thanks again for the partnership.
Great to see you.
Thanks a lot.
I think what always attracted us to the relationship was,
Alaphalfa's mission was to enable enterprise application use cases
for LLMs and multimodal models.
And most of the customers in the valley
or most of the companies in Silicon Valley
were much more consumer oriented.
So this concept of a single tenant LLM
that can be trained with your data for your application
really fits our core customer base.
For all their friendliness,
Andrewlis knew the Americans wanted to see concrete results.
He had to deliver and fast.
I will show you anger.
I have a smile for you.
Are you happy with the trade fair so far?
I am very satisfied.
Many people come by and want to talk to me.
What's been most interesting?
The most interesting conversation
was possible because of the communication
between humans and robots.
The AI race is also a competition for attention.
It's about catching the eye of investors
waiting on panels, being noticed, being quoted.
We've already heard from a few masterminds on this topic today
and there are still a few more to come.
With you, we'll be asking to what extent
the AI itself will drive innovation?
This one's niche technology is now the subject of massive hype.
Jonas Andrewlis is suddenly in the spotlight.
His AI is being tested and evaluated,
not always favourably.
News magazine did cite accused Alaph Alpha
of allowing its AI to be provoked into making racist
and chauvinistic statements.
Andrewlis pointed out that his basic technology
has deliberately not been restricted.
That's just low-hanging fruit for journalists.
I took a screenshot.
The model used a bad word.
Every time I fine-tune the model or tune the instructions,
that diminishes it in certain areas.
It loses capabilities in exchange
for me making it more pleasant or safer.
And those might be the exact capabilities
that I need in an industrial context for automating processes.
We want the embedding technology to become a well-known brand,
just like the iPhone.
That's the most important thing.
Don't forget to subscribe to our channel
for more videos like this.
We want to think about whether it makes sense or not.
We want to become a company like OpenAI,
the top provider in the embedding world.
What is the best way to push the team to focus on this product?
We have a team with different cultural backgrounds,
and sometimes it's very hard to organize everybody
to concentrate on one thing.
This is also because the AI is developing so fast
and a lot of hypes are here and there.
People want to try this out, try that out.
So I just talk to my CEO and make sure that all the senior engineers,
senior leaders are kind of on the same page.
For me as a CEO,
my primary job is actually killing the fun,
killing the fun part by killing all this distraction
to make sure that people concentrate on the single mission
to make this company successful.
We are kind of a developer-driven company,
and most of our customers or users are actually developers,
software engineers.
So for example, right now there is a talentus sitting there,
and their engineering team is also our customer.
The biggest challenge is the competition in AI is just too intense.
Investors are not stupid,
like most of the investors,
especially when it comes to later on,
investors have a very strict evaluation about this company.
So the companies that we are competing with,
such as Hackingface from France,
and Coher from the US,
so those companies are not like those guys who previously worked at Google,
or graduated from MIT, Stanford,
so they are very smart people.
Most of the investors will look at us as not as a small company,
but they will evaluate us with more,
not based on the hype,
but based on the performance of the company.
So that means we have to show two things,
either the hyper growth of the user,
so we need to grow the user base super fast,
or we show them a solid revenue.
Summer 2023.
Thomas Wolff has managed to make time for a family vacation in Brittany, France.
As Chief Scientific Officer,
he's primarily responsible for research and development at Hackingface,
a job that allows him to take a break from time to time.
What are you up to today? Anything special?
We're practicing ceiling with the trapeze.
Didn't you do that yesterday?
Yes, today we'll do something else.
We'll do the same.
Meanwhile, Thomas' business partner, Clemente DeLong, is in the spotlight.
He's the CEO of Hackingface, the public face of the company.
Tech industry heavyweights like Google, Amazon, NVIDIA and AMD
have invested $235 million into Hackingface.
The open development platform for AI models has become a billion-dollar business.
The company gained even more prestige
when Mark Zuckerberg's Meta used Hackingface
to publish its high-end language model, Lama 2.
It's a model that was recently published by Facebook, or Meta.
It's similar to ChatGBT, an open source competitor.
The difference is that it's free.
You can just install it on your computer
You don't have to access it through the ChatGBT interface or pay for it.
It's like a set of Lego.
Everything is open. Everything is freely accessible.
You can also buy it pre-built.
If someone builds an open source model for you,
it's like they're building Lego for you.
A beautiful sports car made from Lego.
And then it's yours.
You can open up the hood and look inside.
The greatest advantage of open source, its free accessibility,
is also its greatest weakness.
What if a model was developed further by criminals,
terrorists, or other bad actors, and used to cause harm?
Any security mechanisms built into a language model
can easily be removed.
Seeing a large scale of technology,
that's a big question we're asking ourselves at Hugging Face.
In the beginning, our aim was to make this technology
as widely accessible as possible.
We thought it would help lots of developers,
but there are two sides to the technology.
There are some people who can access it
who really shouldn't be able to.
There was a guy I met last year who had an AI
designed to develop medicines, molecules that are good for your health.
Just as an experiment, he put in a minus sign
and trained it to look for molecules that were bad for your health.
Within four hours, it discovered thousands of chemical weapons,
including VX, the most powerful nerve gas
that we here in the US have developed.
Of course, you shouldn't open source things like that.
It's just crazy.
I'm a scientist. I love open source.
It's undeniable if you think about the pace of progress,
how do you make sure that there is the most progress?
Open source is your friend.
Having said that, I just cannot completely ignore all the dangers.
And of course, the only argument I have seen so far
from supporters of open sourcing,
everything is saying, well, we will figure it out.
It's easy to comment from the sidelines
to simply warn that it's all dangerous.
It's more difficult to actively get involved,
to try to create something positive, something good.
It won't necessarily be successful.
There'll be mistakes and then fresh attempts,
but I'm going to try.
It's risky, but we'll follow the path we think is right.
MUSIC
MIT is one of the most renowned tech universities in the world.
It has close ties to industry.
The research carried out here has the potential to change the world.
Needless to say, MIT is at the forefront of artificial intelligence.
In addition to his work with the Future of Life Institute,
Max Tegmark is a professor here.
The topic of AI security is part of his day-to-day.
So we want to ramp up the effort and pace at which we do things.
And it's also very inspiring whenever I go to Silicon Valley
and meet with various companies,
how quickly they do things compared to what we do in universities.
So I thought it'd be fun to...
Now we're lucky to have a whole bunch of talented people here,
so we can wrap up.
Tegmark and his fellow campaigners want to keep a close eye
on the tech startups from Silicon Valley,
uncover risks and use scientific methodology to show people
just how little time we have left to counteract the pull of the tech industry.
So even working very hard on finishing our paper,
we had a very, very long conversation about it yesterday.
I thought the very last part of what we talked about
might be kind of fun for the whole group.
Yeah, I completely agree.
Do you want to draw that table?
Yeah, sure.
Maybe they can contribute to good quotes for it?
So we basically, as you know,
modeled the conflict between the movement to replace human livelihoods
and maybe replace humans, period,
versus the movement to resist this and to preserve the status quo.
So this doesn't just come...
It's not just something Peter pulled out of a hat.
It just actually comes from the math.
So if you're naive, like,
oh, we have AI that can do everything a human can do but better,
my life will still be good.
So we call that naivete.
So if a lot of people believe this,
then they will not invest personal sacrifices and personal costs
to greater unite and for the movement to be in a better position
to resist as a team.
There's companies and open-source developers
that are working day and night with the goal of, you know,
taking people's income streams by creating AI models that are better
than them at their job and their capabilities.
So once you lose your income streams and your leverage,
like, it's too late.
Your options are more limited.
The biggest danger is that we'll look back in 20 years
and realize that we've automated everything
because it was so easy and because it worked
and the AI behaved correctly in 99% of cases
and suddenly we no longer have control
over something that's crucial for society.
The process has already begun.
Until now, it's been the intellectual and creative abilities
of humans that have set us apart from other creatures and machines.
But what if those qualities are now being taken away?
My name is Dr. Inongo Lumumba-Casango,
a.k.a. Samus.
I'm a rapper, I'm a producer,
and I'm an assistant professor at Brown University
and the Music Department.
Initially, I wasn't sort of tapped into all of the discussions
that were happening around AI.
Of course, peripherally, I was sort of listening,
watching, reading.
But I really started to tap into these conversations
when I noticed what was happening
at the intersection of hip-hop and AI.
And that's when I realized, whoa, this thing is moving really quickly.
I mean, last year, we were talking about a sort of AI-generated rapper,
and this year, we're talking about rappers like Drake
and artists like The Weeknd having their voices
actually sort of cloned using AI technologies.
And so the speed at which this has become
sort of an immediate challenge for working artists
is very alarming.
Ultimately, it's the logic of capitalism.
And as a human creator, what you can do is
try not to be left behind.
As a Chinese, we always feel that technology,
if you use it in a smarter way,
it can push you, uplift you yourself
to become a smarter, greater creator.
Machine and AI could do the job faster, cheaper,
and they don't have strike,
and they don't resist any ridiculous demand
from the clients or from the bosses.
And I can see that Chinese companies are already using it
to replace human labors.
So I think this is a very critical moment right now
for the creators around the world.
So this is something happening,
and it's gonna be big in the next three to five years.
So for folks like myself who, you know,
I've been able to build a life for myself,
but I would definitely not say that I'm in the sort of,
like, top tier of the music industry.
There's a way that I think we're able to skirt under the radar
and continue doing work as we're doing it,
because it's so much about experimentation,
it's so much about trying out weird things,
and AI is so much about averaging.
It's the people who are invested in playing
in that space of the anomaly
and playing with the unexpected
who will sort of continue to thrive.
The impact of artificial intelligence
on our society is far-reaching and complex.
How can we regulate a technology
that's developing so quickly
and whose potential is almost impossible to gauge?
The United States is struggling.
Here in Washington, the tech industry's influence is huge,
and governing majorities are fragile.
The fact of the matter is that the U.S. government moves slowly.
It is a democracy.
That slowness is built into the system.
The U.S. government is not supposed to be efficient
and not supposed to be able to tackle problems quickly,
because a government that is too efficient
can use that against its own citizens, too.
I think that we've now reached a state in our society
that many philosophers and writers
in the 20th century warned about,
which is the inability to govern technology
due to the increasing pace of change.
Well, I certainly would not bet against democracies,
but it will be a really tough adjustment period.
The first major piece of legislation
aimed at regulating artificial intelligence
on a far-reaching scale came from the EU,
the AI Act.
I definitely kind of really admire European Union
for being essentially the leader in this space.
They took on this kind of regulation very seriously
before anyone else really fought seriously over that.
Jonas Androulas has come to Brussels.
Together with other startup founders,
he wants to let politicians know
that strong regulation could put smaller European players
at a disadvantage compared to the competition
in the U.S. and China.
I think it's always a bit difficult.
Meetings like this are always a bit difficult
because you say your piece
and you never really know what reaction you're going to get.
A few new people will listen,
and of course it's clear that cooperation
within Europe and with Europe is important,
but it's always hard to say how much we can achieve here and now.
I could just talk.
Do you have documents?
I could just talk.
I've prepared something.
It's your session.
You can decide where you want to sit.
So good afternoon to all of you.
I'm pleased to welcome you to the European Parliament.
To this meeting,
an important meeting at the right time.
Something that will happen,
and we already see basically a few steps down the road,
is like the cloud,
like the hyperscalers have done with cloud compute,
there will be an infrastructure for general intelligence,
that all the value creation, all the apps,
all the new innovations in the world will build upon.
And for us, there will be no second chance.
If we cannot move fast,
then we won't be able to try again in 12 months.
Thanks a lot.
APPLAUSE
Androulos has repeated his message over and over again,
whether on international stages, to German politicians,
or here at the European Parliament.
Over the course of a year,
networking and lobbying has become second nature to him.
So I started my career as an investment banker
and management consultant,
wearing a suit and 38 degree weather with no air conditioning.
MUSIC
I don't think I'd make a good politician.
I realize that in my days at Apple.
What's the probability of success?
Is it worth investing this time?
Is it worth fighting this battle?
I think so. I think it's a battle worth fighting.
But I also have moments when I think that doing something else
would be pretty nice.
MUSIC
Shortly after his meeting with the European Parliament,
it passed the AI Act.
Ten or even five years down the line,
it is this governance structure that will give Europe
the ability to deal with the rapid evolution of AI
and to reap the most benefits from it.
And we have worked first and foremost
to ensure our citizens' rights and freedoms
are not just respected,
but protected and strengthened.
We don't want mass surveillance.
We don't want social scoring.
We don't want predictive policing in the European Union.
Full stop.
MUSIC
My name is Dragosh Derake.
I'm a member of the European Parliament,
representing the Renew Group,
a member of the European Parliament.
I'm a judge by profession.
I was also a member of government in Romania,
Minister of Digitalization,
Minister of Interior,
prior to coming to Parliament.
AI will play very much into the power balance.
Why? Because it drives our economies,
but not only.
It becomes also a geopolitical factor,
both in terms of how warfare is going to look like,
but also how this technology
will play into many of the processes
that will keep
one part of the world or the other competitive.
And therefore,
also the way you write the standards
and how those standards become
globally accepted standards
is very important in that power balance
that I mentioned earlier.
So we're going to see very soon also,
I think, a competition or possible clash
in terms of global standards.
And that is why we have to take measures
to protect
our interests and also to make sure
that again, our understanding
of the role of technology
is one that is shared by as many
on the global stage as possible.
In renegotiations,
Germany, France and Italy lobbied again
to soften the rules of the AI Act
to protect domestic players
like Aleph Alpha from heavy regulation.
But in the end, the European Parliament
prevailed.
In terms of regulation,
we're the economy that's leading the way.
And there's a concern that that
will take too much creativity out of the market.
So in Europe,
we're better at regulation
than at putting technology on the market,
unfortunately.
The truth is, it's ultimately going to be good
for the tech industry as well
to be regulated, level playing field.
Even seatbelts in cars
were viciously opposed
by the auto industry at first.
But then when we got the law
saying all cars have to have seatbelts,
they started to sell much more cars.
Hanzhao has travelled to Shenzhen.
In order to keep his team
on the same page,
the CEO has to visit
the various company offices regularly.
So you see that there's red letters
on the building,
that is basically our office.
But we are now that big,
we are just one small room
inside that big building.
He wants to take his company
Gina to the next level.
That will require all
his employees to pull together
as much as possible.
I'll just put this down.
I brought some waffles.
Try them, they're delicious.
I told them,
you have to eat now
and make a happy face to the camera.
When I work at Germany,
people are greeting each other
like telling jokes,
talk random stuff,
football match yesterday,
all these kind of things.
It's more introvert.
The office is more introvert.
It's just like different working cultures.
Both of them are pretty productive
under my weep, right?
I always think that
a sequence of small success
will make the team stronger
and makes the team more confident
on building things.
Because larger success means larger hope.
A larger hope
could mean larger disappointment.
Here in the start-up,
everything moves very quickly.
Then we become a little bit stressed,
we become a little bit nervous
because we could lose
the advantages against the other competitors,
against the market and so on.
It's not about what we did,
it's about
how people perceive us
on what we did.
Meanwhile, in Germany,
there is also a team
working on releasing a new
large language models.
Yesterday, the leaders told me
that this model can be ready
on Monday, but it has been postponed
for many times.
I have to see how it goes.
In the evening,
Han Xiao has another meeting
with a potential investor.
On the way, he calls his technical director
to ask whether the launch
of the new language model
is going as planned.
Hey, Wan Nan,
your embedding platform
has to get into the global best model list.
This company won't succeed
unless everyone does their best.
If you don't get into the top 10,
it'll be much more difficult.
Who uses a platform
that's not in the top 10?
You need to think more
about these practical things.
Is the LinkedIn post done?
The Twitter post?
There needs to be a strategy here.
Okay, that's it.
Bye.
We want to get into
the top 10 model.
A leaderboard.
Our models get into the top 10,
but the team
just told me,
the German team just told me
they probably cannot get into the top 10.
That's why I get a little bit
intense
on my
conversation, because I said
this is something that we promised
to ourselves.
In this world, it's a very, very
attention-based world.
If you cannot get into the top 10,
it's just like
even if you get into
number 11,
nobody cares.
That's why I'm telling the team
that it's not
about engineering only.
You also have to think about
the whole company, like the marketing sales.
It all depends on the number 10,
the top 10 models
that are in this leaderboard.
Okay.
Yes.
Hello.
Hi, Grace.
Grace Liu works for
a Chinese investment bank.
The two first met a couple of years ago
during the start-up phase
of Han Chao's company.
You're just starting to bring
to people, right?
Multimodal AI.
We're working on two things right now.
One is prompt technology
and the other is embedding technology.
This year will be quite
a challenge for you.
We've made a new software with prompt perfect
aimed at developers.
We've already got 200,000
registered users.
That means there's a lot of demand.
I don't think I can jump
to my conclusion yet,
but Han mentioned something
very interesting to me about his
new development and two new products.
Actually, the most important thing is
the CEO, him or herself,
right?
And whether he is a good
entrepreneur, not only a scientist
or a good developer.
Meetings like this one put opportunities
on the table for Han Chao's company,
both in China and in the West.
And there's good news
about his important project.
The new developer tool performs just
as well as the equivalent technology
from OpenAI.
By the end of 2023,
Jonas Andrewles
has plenty to celebrate.
He's completed a major round of financing.
The company prevailed
and convinced enough investors
to raise half a billion dollars.
That's money Andrewles
is going to need.
Because competitor OpenAI
is already triggering a new phase
in the race for AI dominance.
We did a lot of things
that smart people told me
four years ago
they would be impossible.
Build deep tech AIR&D
out of Germany?
Impossible.
Fund this with mostly European capital?
Impossible.
Build our own data center?
Impossible.
Contribute category defining research?
Impossible.
And now we are entering into a new era
and we are super happy to have you all with us.
And thanks for being here
and help us make this the best party
that Heidelberg has ever seen.
Thanks.
And for Thomas Wolff,
quiet holidays may soon be a thing of the past.
Hugging face is now
valued at 4.5 billion dollars.
Thanks to successful start-ups
and the AI Act,
the EU at least has a seat
at the table alongside the US
and China.
For now, for humanity at large
the question remains
what kind of world are we building right now
for ourselves
and for our children?
I was holding my little baby Leo
who just turned 9 months old
and looking into his eyes
and thinking right now
his language abilities
are much worse than
chat's GPT-4
and he's never going to catch up with AI
ever.
I have two kids that are in middle school
and I'm thinking exactly about that
what I should teach them about
so they are prepared for the AI
in future.
How do we teach our kids to kind of
build something like
unique and individual?
The machine is our supplement.
It's our brothers or sisters
so I think that's
how I feel.
Even in these pivotal moments
in these complex times
people always find a way
they're creative and resourceful
my son is already learning to code
he's really interested in AI
he wants to understand things
and create things using AI
our children will probably create
a world that's completely different
from ours but I'm not worried
at the end of the day
I'm an optimist.
you
