Given a particular matrix if you want to compute its trace, you will be basically adding up the
diagonal entries. But this is quite an out-of-brake approach in thinking about trace. Can we visualize
what's really happening when we add these diagonal entries? The visualization will also
explain many properties of trace you might have seen. There is one particular property that I'm
saving for the end of the video series, which is traceAB equals traceBA. However, in the majority
of cases where one of A or B is invertible, we can derive it using one of the other properties.
But in any case, let's start the visualization. At the end of the previous video, we have described
a matrix as a vector field. Let's expand on that a little bit. If you are given a matrix A,
then the vector field would be constructed by attaching every point with position vector x
by the vector ax. A little note on the illustration on screen here. Technically,
if this illustration really describes ax, then the vector field would look very messy because
some of the vectors would be too long. So the usual thing to do is to standardize the lengths of the
vectors, which will still give you the direction. And if you really need the length, then add colors
to indicate how long the vectors should have been. In particular, these two vectors are the
important ones, because they are the vectors attached to the points 1, 0, and 0, 1 respectively.
The vector attached to 1, 0 would be the first column of A,
while the vector attached to 0, 1 would be the second column of A. With this visualization
of matrices, the intuition for trace is just one sentence. The trace of A is the divergence
of this vector field created by the matrix A. We are going to see what divergence is.
Now I am aware that this has been talked about on YouTube, but I want to be more quantitative,
so bear with me if you already knew the visual intuition of divergence.
Given a particular vector field, we can define divergence at a point, say this red dot.
We now consider a very small region around this dot, and write down the area of this small region.
The next thing is to let every point in this small region evolve together along the vector field.
As you see, the area of this region changes. For divergence, we are interested in thinking about
how quickly the area changes initially, per area, as the area of the initial region shrinks to 0.
In this case, let's look at how the area evolves again. We can see that it initially decreases,
and in fact keeps decreasing along the way, so because the area change is negative,
we have the divergence at this red dot to also be negative. However, one reminder is that this
rate of area change is per area. In this case, if we compare the final area with the initial area,
we can record a change of negative 0.148 during the evolution. Now, if we quadruple the initial
area and, again, play the same game and let this area evolve under the flow of the vector field,
and this time, we record a change of negative 0.595 in area. If we compare this change to the
previous area change, this is exactly a factor of 4 accounting for rounding errors in my computer
simulation. So, in our intuition of divergence, the per area part is very important. So that's
the divergence part, but why is this related to the trace of the matrix generating the vector field?
Actually, the first question that comes up would be that the divergence is a local property. This
means that if we consider another point on the vector field, the divergence could be different,
so why does this statement seem like the divergence is the same everywhere? Well,
it's because it is, but just in this specific case, where everything is generated by the matrix A.
To see why the divergence is the same everywhere, let's first denote this point with its position
vector x and any point within our small region around x to be x plus d for small displacements
d from x. Now, the vectors attached to those two points are ax and ax plus d respectively.
This means that the initial displacement between these two points is d, and after a very short
time epsilon, the displacement is increased by epsilon times ad. Here, ad is the difference
in their velocities or the rate where they drift apart. However, notice that there is
absolutely no x here. This result does not depend on x. So, if we have this exact shape
of the small region, let's illustrate it with just three points, each with displacements di
from the point we try to compute the divergence of. After a short epsilon period of time,
the displacements are changed to di plus epsilon adi. But these are independent of our position.
So, even if we have this initial region elsewhere, we will still have the exact same shape
after time epsilon. The change in area is the same everywhere. Because the divergence is the
area change per area, divergence is the same everywhere in this case. This also means we can
choose a convenient region to see how its area changes, and this region doesn't have to be
infinitesimal either. This is because if we chop any normal region into very small ones,
then from our intuition of divergence, each small region ui has its area changed from ai
to ai times 1 plus epsilon times divergence after time epsilon. Most importantly, we know now that
divergence is the same across all these regions. So, for the entire region u, which has its area
being the sum of these small regions, would also scale by the same factor of 1 plus epsilon times
divergence. Since we can basically choose any region to see how the area evolves, a convenient
choice is the unit square containing points 1, 0 and 0, 1, as the initial area would automatically
be 1, so we focus on the rate of area change. If we suppose that A is the square matrix A, B,
C, D, then as said before, the vector attached to 1, 0 would be the first column A, C,
and the vector attached to 0, 1 would be the second column B, D. Let's focus on the point 1, 0,
and its attached vector A, C. Here, its vertical component doesn't really matter here, because
it doesn't change the area of the region. The base and height of the parallelogram have not
changed. So, the vertical component doesn't matter, but what about the horizontal component?
This time, it matters. The area has changed. The rate of change here is given by precisely
the horizontal component of the attached vector, which is A. You can run a very similar argument
on the other point 0, 1 here. This time, the horizontal component does not matter, because again,
the area wouldn't change in that case, and the vertical component provides the change in area.
In this case, the vertical component is D. So, all together, the rate of change in area would be
A plus D, which is exactly the sum of the diagonal entries of the matrix A. So, we have demonstrated
that trace is really the divergence of the vector field. Now, if you are not convinced by these
horizontal component or vertical component arguments, all we are doing is computing the
determinant of this slightly different matrix. The first column is where the point 1, 0 moves to
after time epsilon with this velocity A, C. Similarly, the second column is where the point
0, 1 moves to after time epsilon with the velocity B, D. If you actually compute this determinant,
then we see that this is really the rate of change of the area. That is also the trace.
Anyway, the fact that trace is just the divergence of the vector field is very useful for understanding
the many properties of trace, and these properties one by one would be the focus of the video from
this point onwards. Let's first start with why trace is the sum of eigenvalues. When visualizing
matrices this way with vector fields, if the position vector x is an eigenvector of A, then the
vector attached to it, which is Ax, would face the same or opposite direction as the position vector.
In fact, once you are on this line, you will stay on this line, because the position and
velocity vectors are both on this line. In the case where there are two such lines, where the
position vector and the velocity vector attached are on the same line, then to investigate the
divergence of the vector field and hence the trace, one convenient choice of region is a
parallelogram aligned with these two lines. Let's label the two lines by their eigenvalues lambda
1 and lambda 2 respectively, and let's say the side lengths of the parallelogram are A and B.
Focus on this corner of the parallelogram. The length of the vector attached to it should be
lambda 1A. That's because on this line, every position vector satisfies Ax equals lambda 1x.
Since the position vector has length A in our notation, the vector attached to it should be
with length lambda 1A. So after a very short time epsilon, we should have an extra length of epsilon
lambda 1A along this line. Using the same argument on the other corner of the parallelogram,
the extra length on the other line would be epsilon lambda 2B after time epsilon.
In this illustration, lambda 2 is negative, so the so-called extra length is actually length
lost. So after a short time epsilon, the length along this lambda 2 line would be B times 1 plus
epsilon lambda 2, and similarly the length along the lambda 1 line would be A times 1 plus epsilon
lambda 1. The new area is the product of the side lengths and sine theta, where theta is the
angle between these two lines. Compare this with the old area, which is AB sine theta. If we now
compute the divergence of this vector field, which is the rate of area change per area, then we would
have this expression, which is new area minus the old area over the time period of epsilon,
divided by the initial area, which is AB sine theta. If you really compute this, we would have
lambda 1 plus lambda 2 plus a small bit involving epsilon. However, as epsilon tends to zero,
then the epsilon bit does not contribute, and we are left with the sum of eigenvalues,
so the trace is the sum of the eigenvalues in this illustration. So this is the first property
of trace. The next property has something to do with the exponential of matrices, which I have
described in the previous video as well. Essentially, given a vector field created by the matrix A,
the flow of this point with position vector x along the vector field is precisely given
by e to the ta applied to x, where t is the time elapsed when you flow along the field.
The determinant of a matrix is the scale factor of this unit square under the matrix
transformation. Applying the matrix e to the ta to this square is equivalent to letting the region
flow along the vector field, so the area of whatever we end up with is the determinant
of the matrix exponential. And we actually know how the areas evolve along this vector flow.
Let's denote the area of this region as s of t, which depends on time elapsed along the vector field.
The trace of A is the rate of area change per area, with the rate of change in area being
the derivative of s, and the area being s of t itself. By rearranging this formula, we obtain a
differential equation in s. Note that the trace of A does not depend on t, it is a constant,
so the determinant s of t can be solved as e to the t times trace of A. This neatly explains
why the determinant of the exponential matrix is the exponential of trace.
Now let's go to the property that the trace is independent of basis vectors.
Given the matrix A, as usual we consider the vector field generated. This time,
we apply a linear transformation q to the whole picture. In general, where the vectors emanate
from would change, and the vectors attached would also change. More specifically, what had been x is
now transformed to qx, and what used to be ax is now qax. This one needs a bit of explanation. Initially,
the attached vector to the point x is going from point x to x plus ax. So when we apply the
transformation q on the whole picture, then the attached vector goes from qx to qx plus qax. So
this attached vector is qax. Now let's call this new position vector y. Then in terms of y, the
attached vector is qaq inverse y if q is invertible. So for any position vector y, the attached vector
is qaq inverse y, which suggests that this is actually the vector field of another matrix,
qaq inverse. Now the trace is the rate of change in area per area, but in applying q to the whole
thing, all areas scale by the determinant of q, and this factor of determinant cancels when we
consider the quotient. So in other words, the trace of a equals the trace of qaq inverse. Or if you
want to go for the usual change of basis formula p inverse ap, simply substitute the matrix q as p
inverse. Using this relation, we are able to derive another famous property of trace,
which starts from rewriting trace of ab. If b is invertible, then we can simply add in
b inverse b, and the expression stays the same. However, written like this, we can use the property
we just derived, and then we can obtain it is the trace of ba. Now this property of trace
is perhaps more well known, but we have done a bit of algebra to get here. There is a better way,
but we will need to introduce the concept of lee bracket, a story for another time.
So we can obtain this property of trace by transforming the whole plane by p inverse,
and the final property we will see is this perhaps less famous formula. This formula
is known as Jacobi's formula for a matrix a that depends on time t. Well technically,
this is only true if a of t in this formula is invertible, because there is a inverse in the
formula. A more general formula involves the adjoint matrix, which is defined even if a is not
invertible. But for the purpose of visualization, we are going to assume a is invertible and try to
understand this formula first. First off, what does the left hand side really mean? The determinant
can refer to the area of a parallelogram described by a of t acting on the two basis vectors.
This area will change because a itself evolves with time. In fact, these points would also change
as a changes. The rate at which these corners move is exactly a prime of t acting on the basis
vectors. If we can somehow make this into a whole vector field generated by the matrix m,
then we know how the area evolves. Specifically, we know that the trace of m is the rate of area
change per area. In this case, the rate of area change is the derivative of determinant of a,
and the area is, of course, just the determinant of a itself. So, if we rearrange this,
then we have something that really looks like the Coby formula. The problem now is what is m?
What is the matrix m that generates this vector field? Now, particularly at the points a of t
acting on the basis vectors, we know what the vectors attached should be. To go from the position
vectors to the attached vectors, we can simply apply a prime a inverse on the position vectors.
So, the matrix m we are looking for is a prime a inverse. If we go back to what we have obtained
previously about derivative of determinant, we simply substitute the matrix m to be a prime a
inverse. This is almost the same as Jacobi's formula, just that the matrix in the trace
has the other order in multiplication, a inverse before a prime here. Don't worry,
there are two approaches here. Either use the property we discovered that trace a b equals
trace b a for a or b being invertible, or similar to how we dealt with the previous property,
we just apply a inverse to the whole picture. In that case, the corners of the parallelogram
go back to the standard places 1 0 and 0 1, but the vectors attached to these places
are a inverse a prime acting on the basis vectors. This is because previously they were just a prime
acting on them, but we have applied a inverse to the whole picture. This means that the matrix
generating the vector field would be a inverse a prime, and the matrix m to be put into the formula
that we derived previously would be a inverse a prime. And this is exactly the Jacobi's formula
where the matrices in the trace are in the right order, a inverse a prime. So this is the Jacobi's
formula derived in the case when a is invertible. We are able to derive and understand many properties
of trace visually by thinking of trace as divergence or the rate of area change per area
when the area evolves along the vector field. As always, thanks for the patrons and please like,
subscribe, comment so that more people can watch it. See you next time.
