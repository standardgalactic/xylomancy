Hey there, how's it going everybody? In this video, we're going to be learning how to run
code in parallel using the multi-processing module. Now, if you'd also like to learn about
running code concurrently using the threading module, then I did recently put out a video on
that as well, so I'll be sure to leave a link to that video in the description section below.
Now, if you don't know the difference between threading and multi-processing,
then you should have a grasp on the difference between those once we're finished.
Now, I would like to mention that we do have a sponsor for this video and that is brilliant.org.
So, I really want to thank Brilliant for sponsoring the video and it would be great if
you all could go and check them out using the link in the description section below
and support the sponsors. And I'll talk more about their services in just a bit.
So, with that said, let's go ahead and get started. Okay, so first, why would we want
to use multi-processing? So, basically, we want to use multi-processing whenever it's going to
significantly speed up our program. Now, the speed up comes from different tasks running in parallel.
Now, in this video, we're going to start off with a basic example of where we learn how to run some
simple sleep methods in parallel, but then we'll finish up with a real-world example where we do
some image processing on a directory of high-resolution images. I want to show that real-world
example because, personally, when I watch tutorials that only show how it works on basic examples,
then I always feel like I don't really walk away with any useful knowledge. So, we'll use the
sleep method to get a good idea of how to use multi-processing, and then we'll be sure to go
over the more complicated real-world example of image processing. So, let's go ahead and get started.
So, I have a starting script open here, and if you'd like to follow along, then I'll be sure to have
a link to this code in the description section below. And, like I said, we'll start with a very
simple example to see how this works and then build up with more realistic examples. So, let me go
over the script that I currently have open here. So, first, I'm importing time, and I'm just using
time to measure how long it takes the script to run. And that's also what this is here. This is just
a start time for our script. And then we have a function here called do something. And all this
is doing is printing that we are sleeping for one second. Then we actually sleep a second using that
time module. And then we are printing out that we are done sleeping. And then we are actually
executing that function. So, it should do all of this. And then we are calculating the finish time
and printing out that our script is finished. Okay, so if I run the code that we have right now,
we can see that it said that it was sleeping for one second, done sleeping, and that we finished
in about one second. And that sounds about right since we were running our do something function
one time, and that sleeps for one second. And if we were to run that function twice,
then our program will likely take two seconds. So, let's go ahead and see that. So, right below,
do something here. I'm going to run this again. And if I run that, then we can see that now that
it printed out that it was sleeping for one second twice, and that it took about two seconds. So,
we can see that each time we run this do something function, it's adding about one second to our
script. So, our script is just waiting around sleeping for a second. And once that's done,
it moves on to run that next function and sits around waiting for another second. And then at
that point, we're basically done and our script finishes. Now, I created a quick graphic to try
to represent what this looks like. So, let me bring that up here in my browser real quick.
And this is actually the second graphic. We'll go over that in just a second. Okay, so this is
basically what it looks like for our script to be executed right now. So, we are running a function.
In this case, it's that do something function. And then this is just coming up here and waiting
and executing for one second. And once that one second is over, then we come back and we execute
this another function. And it's that same function again. So, then it comes up here and executes
this sleep for one second again. And when that one second is done, then we can come down here
and print that our script is done. And running everything in order like this is called running
it synchronously. Now, if you have some tasks that don't need to be run synchronously, then we can
use the multi processing module to split these tasks up onto other CPUs and run them at the same
time. Now, if you watch my last video on threading, then I mentioned that tasks were going to either
be IO bound or CPU bound. So, CPU bound tasks are things that are crunching a lot of numbers and
using the CPU. And IO bound tasks are things that are waiting for input and output operations
to be completed. And they're not really using the CPU all that much. So, some other examples of
IO bound tasks include file system operations and network operations like downloading stuff online.
Now, in that threading video, I mentioned that we wouldn't get much of a speed up when using
threading on CPU bound tasks, because those threads are still only running one process. But with
multi processing, we're going to actually spread the work out on the multiple processors on our
machine and run those tasks on at the same time. So, we can use this with both IO bound tasks and
CPU bound tasks. So, it really just depends on what we're doing and your computer's hardware that
will determine if it's better to use threading or multi processing. But with that said, let's
look at what it looks like to run something in parallel using multi processing. And I've got
another graphic put together of what this would look like. So, in this example, we can see that we
still have our two tasks. But now we're just breaking these up onto two different processes.
And unlike with threading, where we were running these concurrently, and I said that running concurrently
doesn't necessarily mean that they're running at the same time. With multi processes, these actually
are running at the same time on different processes. So, we can see here that once we kick off our
multiple processes and we spread out our tasks onto those processes, then we can just run each of
these functions one time. And then both of these will sleep for a second. And then once they're
both done, we'll come down here and print that they're done. Okay, so now that we've talked about
multi processing and what it looks like to run code in parallel. Now, let's see how to actually do
this with our current script. So first, let's import the multi processing module. So this is in
the standard library. So we don't need to install anything. So up here at the top, I'm just going
to say import multi processing. Now I'm going to show an older way of how to do multi processing
first so that we can get a good idea of what's going on. But if it seems confusing at first,
then definitely stick around. Because I'm also going to show some newer ways of doing multi
processing using pools that allow us to add this to our program with just a few lines of code.
Okay, so first, instead of running the do something function twice in a row like we have here,
let's instead turn both of these into processes. So to do this, I'm just going to create two processes.
And for both of these, we can just say P one is equal to multi processing dot process. And now we
are going to pass in a target. And the target is the function that we want to run. So if I want to
run this do something function, then I can pass in do something. Now we want to pass in the actual
function and not the return value of the function. So we don't want to execute the function with
parentheses like this. We just want to pass it in with no parentheses. Okay, so now that will
be one process. And now if I do a P two is equal to multi processing dot process with a target
of do something, then that will be our second process. Okay, so at this point, we've created
two process objects, but we're not actually running that code. So if I run this right now,
then we can see that it says that it finished immediately, but nothing from our function printed
out. So our functions act didn't actually run. So in order to get our processes to run, we need
to use the start method on each one. So down here below our P two, I'm going to say P one dot start
to start that first process, and P two dot start to start that second process. Okay, so now that
will actually run our processes, but it might not do exactly what we think it'll do. So if we run this,
then we can see that now it runs the functions. But it said that our script was finished in zero
seconds. And then it said that we were sleeping for one second twice because we ran that function
twice. And then it said that it was done sleeping. Now our entire script didn't actually complete
in zero seconds. It actually took around one second. But the reason that it says that it completed
in zero seconds is because after it started both of these processes here, while those processes
were sleeping, our script continued running and came down here and calculated out the finish
time and printed out that our script was finished in zero seconds. And then it kicked off these
processes. Now actually, I think that I just said that it started sleeping first before it printed
out that we were finished. But these processes take a little bit longer to spin up than threads.
So it actually didn't even start our processes first, it actually came down here and printed that
we were finished before the sleep statements even first got executed. So it printed that
before it said we were sleeping. And then after a second, we were done. So basically what this
is doing is it's kicking off our processes. But then it's going down here and running the
rest of our script before our process is finished. Now what if we wanted our processes to finish
before we calculated the finish time and before we printed out that our script is finished.
So in order to do this, we can use the join method. So to do this right below start,
I'm going to say P one dot join and P two dot join. So when we run that join method,
it means that the process will finish before moving on in the script. So now if we run this,
then we can see that both processes started at almost the same time. And then they both printed
that they were done sleeping after one second. And then our script continued on to print that our
script had finished in about one second. Now if using multiprocessing seems a bit complicated
right now, then definitely stick around until the end of the video, because we're going to see an
easier way of how to do what we're doing here. But I think it's important to understand what
this is doing so far, even if we use other methods where we don't actually manually call these start
methods and join methods. Okay, so right now, we're not really getting that big of a speed up.
Now so our code ran in two seconds before. And now it's running in one second. But that's because
our function doesn't take too long. And we're only running it twice. But what if we wanted to run our
function 10 times? Well, if we were to run our code synchronously, then we can take a guess that it
would take 10 seconds since our since one would have to finish before the other and we'd be running
10 in a row. But if we ran this with multiple processes, then it should be significantly
faster. So let's see an example of this. Now instead of manually creating 10 different processes,
let's instead create and start these in a loop. So to do this, I can come up here and I'm going
to copy this whole part here. And now I'm just going to override all the code that we have here so
far. And I'm going to say four underscore in range of 10. And we'll say p is equal to
multi processing dot process with a target set to the do something function. And now let's also
start that process here within our loop. Now if you're unfamiliar with the underscore in Python,
basically, that's just a throw away variable name. It's just saying that we're not actually using
the integer from this range in the loop. So we just have something as a throw away variable there.
So we're starting all these processes here within our loop. But we can't do a p dot join within the
loop, because it would run join on the process before looping through and creating and starting
the next process in the loop. So it would basically be the same as running it synchronously. So we need
a way that we can start all of these processes in one loop, and then loop through those processes
again, and run the join method on them, so that they all finish before the end of our script.
So to do this, let's just append each process to a list. So above our for loop here, I'm just going
to create a list called processes and set that to an empty list. And then below p dot start,
I'm going to say processes dot append, and I will append each process to our processes list. And now
here below our for loop, I'm going to say for process in processes, let's do a process dot
join. Okay, so just one more time here, we are looping over a range of 10. So we're going to do
this loop 10 times here. And each time through the loop, we are creating a new process with this
target of do something. And we are starting that process. And then we are appending that process
to a processes list. So then after that loop is complete, and all of our processes have been
started, we're coming through and looping over all those processes, and we are joining them. And
again, when we join a process, when we run the join method, it means that it is going to wait
until that finishes before continuing on to the rest of the script. So it'll finish before it
comes down here and calculates the finish time and prints that our script is finished. So we're
running this do something function 10 times, and it sleeps for one second every time. But since
we're using multiple processes, it'll just run all of these in parallel at the same time. So instead
of it taking 10 seconds, let's save this and run this and see how long it actually takes. So we can
see that even running the function 10 times, we're still finishing this in about one second. Now that
might seem a little strange, because I don't actually have 10 cores on this machine. But your
computer has ways of switching off between cores, when one of them isn't too busy. So even though we
had more processes than we do cores, it's still finished in about a second. So that's pretty good.
Okay, so now let's look at how we can pass in arguments into our function. So right now, we're
running a function that doesn't accept any arguments. But let's add a couple of arguments
real quick. So right now, we're just sleeping for one second. So let's add an argument that
specifies how long to sleep. So up here, we will accept an argument. And I'm just going to pass in
an argument of seconds. And let's also change that we are going to sleep for that number
of seconds. And let me also put a parentheses s there as well. Now this needs to be an f string,
since we're now using this variable here within our string. Now I want to sleep for
that number of seconds. Okay, so with that small change, our do something function now accepts
an argument of seconds, and then it'll print out that we're sleeping for that number of seconds,
and then it will actually sleep for that number of seconds. So let's pass in seconds as an argument
to this function. And we need to pass that in as a list of arguments to our process. So I'll say
down here, where we are saying that our target is that do something function, we can also pass
in an argument of arcs. And we'll pass that in as a list of arguments. So I'll do 1.5. So now,
instead of sleeping for one second ever for 10 different times, now it's going to sleep for
1.5 seconds for 10 different times. Now, unlike with threads, in order to pass arguments to a
multi processing process, the arguments must be able to be serialized using pickle. Now if you
don't know what that means, basically serializing something with pickle means that we're converting
Python objects into a format that can be deconstructed and reconstructed in another Python script. So
now we should expect our function to take 1.5 seconds instead. So if I save this and run it,
then we can see that now our script is finishing in about 1.5 seconds. Okay, so I said before that
I was going to show you the older way of doing multi processing. And then I'd show you what I
believe is a faster, easier way of doing this. And I still wanted to show you the manual way of
creating these processes, because I think this can still be useful depending on what you're doing.
And also, I think it's better to learn this manual way first to understand a bit better what's going
on in the background. But in Python 3.2, they added something called a process pull executor.
And in a lot of cases, this will be an easier and more efficient way to run multiple processes.
And it also allows us to easily switch over to using multiple threads instead of processes
as well, depending on the problem that we're trying to solve. So let's replace what we currently
have and instead use this process pull executor. Now this actually isn't in the multi processing
module. It's in the concurrent futures module instead. So up here at the top, let's instead
import concurrent dot futures. And I actually don't think I need multi processing anymore.
So I'm just going to say import concurrent dot futures. Now I'm going to leave everything else
that I have here for now, so that we can see the difference between these. Now when we use this
process pull executor, it's usually best to use this with a context manager. So above our processes
list here, I'm going to do the same thing that we already have. But just with our concurrent futures
module instead. So I'm going to say with concurrent dot futures dot process pull executor, and make
sure you get those capitalizations in the right place. And then we will say, whoops, we'll say as
executor. And now within our or with our executor here, there are a couple of different methods
that we can use. Now if we want to execute the function once at a time, then we can use the
submit method. So the submit method schedules a function to be executed and returns a future
object. So let's add this in and then I'll explain this a bit more. So I'm going to say f one is
equal to executor dot submit. And I will submit that do something function. And let's also pass in
an argument of one. So again, the submit method schedules a function to be executed and returns
a future object. So a future object basically encapsulates the execution of our function
and allows us to check on it after it's been scheduled. So we can check that it's running or
if it's done, and also check the result. So if we grab the result, then it'll give us the return
value of the function. Now right now, we're just printing out values. But let me add in a return
value so that we can grab that. So instead of just printing that we are done sleeping up here,
instead, I'm going to return that string. So I'm going to say return done sleeping instead of just
printing that out. Okay, so now that's returning that string. So if we still want to print that
out, then we'll need to print that return value. So let's grab that by using the result method
on that future object. So I'm going to say print, and we will print out f one dot result.
Now if we run the return method, then this will wait until the function completes. Okay,
so let's comment out what we had before and run our code. So I'm going to comment out this processes
list here, and our previous starts and joins. And instead, we're just going to use this process
pull executor. Okay, so if I run this, then we can see that that still works. And that's a lot
less code than we had down here that's commented out. But we're still not running this multiple
times yet like we were down here. So if we wanted to run this multiple times, then we could just
run submit multiple times. So I could say, let me go above our result here, I'm going to add in
another execution of this do something function. So I'm going to call this f two is equal to
executor dot submit, do something with one second. And then I will also print out the
f two result. So if I run this, then we can see that it's the same thing, it kicks both of these
off at the same time. And we finished in about one second. And if we wanted to run this 10 times,
like we did below, then we likely wouldn't want to run submit 10 different times. So we could use
a loop like we did before. So instead of running one at a time, I'm going to use a loop. And we
could use a regular loop like we did below. But I'm going to go ahead and use a list comprehension
to create these instead. So we could say, I'm just going to copy this executor dot submit part.
And I'm just going to overwrite all of this other stuff right now. And I'm going to say results
are equal to, then I will start a list comprehension here and say executor dot submit,
do something for one second for underscore range 10. Now, if you're not familiar with list
comprehensions, like we have here, then I do have a separate video on that as well. So I'll
put a link to that in the description section below if you've never seen this type of code before.
And if you're not comfortable using list comprehensions, then you can always use a regular
loop like we did down here below. Okay, so now we've created a list comprehension that's running
our submit method with this do something function and an argument of one second 10 different times.
Now, in order to get these results, we can actually use another function from the concurrent
futures module called as completed. And this will give us an iterator that we can loop over
that will yield the results of our processes as they're completed. So I think this is really
useful. And it's one of the good things about using these processing pull executors. So to use
this, we can say just for f in concurrent, oops, sorry about my typing there, concurrent dot futures
dot as underscore completed. And now we want to pass in this list of results, which is a list of
futures objects. And now within this list, let's print out f dot result. So if we run this,
oops, and it looks like I have some invalid syntax here. Oh, I forgot to say, I should have said for
underscore in range of 10. Some of you probably saw that as I was typing it out. Okay, so now,
if I run this, then we can see that we slept for one second. Now it's still ran 10 different times.
But if we scroll down to the bottom, then we can see how much time it took. So we can see here
that it actually took three seconds this time. Now, the reason behind that is that our pool may
have made a decision based on our hardware, not to a lot as many processes. So that's why it might
take longer. But even though it took longer in our simple little example here, I still you like to
use these processing pull executors most of the time, because I trust it to a lot the processes
a lot more than I trust myself. So I pass that off to the process pull executor to do and to
make that decision for me. Now to prove that these results are actually coming in as they're
completed, let me actually pass in a different range of seconds for our processes to sleep.
And those should print out in the order that they complete. So I'm going to create a list of
seconds to sleep. And I'll make that sleep from five seconds all the way down to one second.
So above our results here, I'm going to make a list of seconds. And I will just make a list of five,
four, three, two, one. And I'll also print out the seconds in the return statement of our do
something function, so that we can tell which ones are finishing and in what order. So again,
I'm going to make this an f string by putting an F right there. And I'm just going to pass that in
to so we can see which seconds is actually done sleeping. So now let me also change our list
comprehension here, so that we are running our do something function with each of these seconds
in this seconds list. So I'm going to say executor dot submit, do something. And I want to
do that for whatever second. So four sec in our seconds list. Okay, so now if I run this,
then we can see that it actually started our five second process first, and then our four,
then our three, then our two, then our one. But it finished these in the order that they came in.
And the lower number seconds are towards the top. Now I'm not sure why the one second process
took so much longer than the two and the three second processes, I guess it just got hung up on
something. But the four and the five second processes were down here at the bottom. Actually,
let me run that one more time. And oh, okay, so that's why it's because our one second process
was down here. And since I have four cores on my machine, it started these four processes here
first. And it didn't start the one second process until this two was finished right here. So that's
why that took a little bit longer. But since we are using this as completed method, this actually
did print our result out our results in the order that they completed. So this two second one finished
first, and then this three, then one, then four, then five. And we can see here down at the bottom
that our script is still finishing in about five seconds. So that's pretty good. Okay, so with this
submit method right now, it's submitting each function once at a time. But in order to run
submit on an entire list, then we need to do a loop or a comprehension like we did here. But if
you're familiar with the built in MAT method, then there is actually something similar that we can
do with processes where we can use the map method to run our function over a list of values. So if
you're familiar with the built in MAT method, then this is very similar, except it uses processes
instead. So it runs the function every time or with every item of the interval that we pass in.
So let's say that I want to map our function to our list of seconds. So to do this, I am just going
to overwrite our list comprehension here. And I'm not going to be using this as completed anymore
either. So I'm also going to get rid of that. So now in order to do this, we can simply say
executor dot map. And now we will map our do something function. And we will map our list
of seconds. So again, what this map method does, if you're not familiar with the built
in Python map method and what it does, basically map will run this do something function with every
item of this list with every item of whatever iterable you pass in. So that is what map does.
Now, when we were using the submit method, it returned future objects. But when we use map,
it just returns the results. Now, it is going to run those processes in parallel. But instead of
returning the results as they're completed, like we saw before, map is going to return the results
in the in the order that they were started. So to loop over these results, we can simply just
do a for loop. So I'm going to say for result in results. And then I will just print out our
result. Well, make sure that I'm printing out the result and not that results list. Okay,
so now if I run this, then we can see that all of our processes kicked off at pretty much the same
time. Except for that one second when it looked like it got outside of the pool like it did before.
But they actually didn't all complete at the same time. But when you loop over your results using
map like we did here, then it returns the results and the order that they were started. So since
we slept for five seconds first, then we waited for that one to finish before printing out the
other results. But it still didn't slow us down. We can see that our entire script still finished
in five seconds here. But it looks like our five seconds was done sleeping first, and then our
four, then three, then two, then one, it actually didn't finish in that order. But it printed out
in that order because, again, it prints out the ones that in the order that they were started and
not in the order that they were finished. Now, another thing to point out here is that if our
function raises an exception, it won't actually raise that exception while running the process.
The exception will be raised when its value is retrieved from the results iterator. So if you
need to handle any exceptions, then you can do that here within the iterator if you'd like. And if
you'd like to learn more about handling exceptions, then I do have a more in-depth video if you'd like
to learn more about that. So I'll be sure to leave a link to that video in the description section
below for anyone who's interested. Now, even if we don't grab our results within the context
manager, it's still going to automatically join all of those processes and let them finish after
the context manager ends. So if I comment out where we are printing out our results, let me also get
rid of our old way of doing this here so that we can see our code below our processes here.
So now, I'm commenting out where we're printing those results. And if I run this,
then we can see that it still didn't move on to our finish time here until it returned the results
from our processes. So anytime you're using a context manager like this, it's going to automatically
join those processes, and they're going to complete before that context manager finishes.
Okay, so now that we've looked at a basic example of using sleep, now let's take a look at a more
real world example of where using multiple processes would be useful. So I've got another
script open here where I'm not using multiple processes at the moment. So let me open this up
and let's go over what this is doing. And again, I'll have a link to this code in the
description section below for anyone who wants to follow along. So in our last video on threading,
I showed how we could use threads to go out and download some high resolution photos from
unsplash. Now if you don't know what unsplash is, it's a website that has some really nice photos
available for anyone to use. Now downloading images is something that is IO bound, since we're
waiting for the images to download. So for this multi processing example, we want something that
is more CPU bound. So in this script, I'm doing some image processing on the images that we downloaded
in the threading video. And I'll have these images available in the description section below as well,
in case anyone didn't follow along with that threading video. So let me go over this script
to show you how someone might do this image processing normally. So I'm using the pillow
library here, which if you don't know what the pillow library is, it's a image library for Python
that makes image processing easy. I also have a video on pillow if you'd like to learn more about
image processing. But I have a list here of image names. And these are all of the images or all of
the image names that we downloaded in the last video using threading. So I am starting a counter
here so that we can measure how long our script took. I am setting a size of 1200 pixels. And that
is what we are going to resize these high resolution photos to. Okay, and now what I am
doing is I am looping over all of those image names. So with one image at a time, I am opening
that image. And then I am running running this image filter. And we're just doing a Gaussian blur
on that image. And then I am doing an image thumbnail and setting it to this 1200 pixel
size. And then we are saving that image into a processed folder with that the image name. And
then we are printing out that that image was processed. Now I do have a processed folder
here within my directory. If you don't, you'll probably get an error. And I also have all of
these photos here within my directory. If you don't have those, then you're also going to get
an error. So you want to have all of those photos in order for this code to work. Then after that's
done, I am printing out the time that it took. And then I am printing out that our script is
finished. Okay, so this is processing 15 high resolution photos. So if I run this now, then
let's see how long this takes. So I'm running this, we can see that it is just going through
synchronously and running these one at a time. And then we will print out the final time once this
is done. Now I think that my processing here, I think that this still might be more IO bound
than CPU bound. Because opening the image and saving this here is going to be more of an IO bound
thing. I don't know how much is actually getting CPU bound here using this filter. But if we were
doing some more computations, then this would be more CPU bound. And we can even test this in a
second. But anyways, we can see that our script finished in 22 seconds. So that's how long it
took to do this image processing here on 15 of these high resolution photos. Now when we're
processing a lot of items like this, this is actually a great candidate to use multi processing,
because this can be one of those CPU bound operations that's spending a lot of time processing
each image. And it's not moving on to the next image until the previous one finishes. And if we
use multiple processes, then it can actually go ahead and move on to the to process another image
while the previous one is finishing. And even if this is IO bound, unlike threading, CPU or
multi processing is actually going to be beneficial for IO bound processes as well. So now let's see
how we can change this code so that it's using multiple processes instead. So first, let's think
about what we're doing here. So we're looping over our list of images and processing each one at a
time. So if we remember from our previous examples, then this would probably be a good candidate for
the processing pull map method, where we can pass in a function and a list and have that function run
with every value in that list. But first, we'll have to create a function that will process a
single image. So to do that, if we think about this, we can basically just replace our for loop
because our for loop is processing a single image from our images list. So instead, we can just
change this one line here and just turn this into a process image function. And we will just accept
this image name as the argument. And now that we have that function that processes a single image,
then we can create a process pull and map our list of images using that function. So first,
let's import the concurrent futures module so that we can use that. So up here at the top,
I'm going to import concurrent dot futures. And now down here below our function, we can
do this by saying with concurrent dot futures dot process pull executor as executor. And now,
within our context manager, we can just say executor dot map. And we want to map this process
image function. And we want to pass in the list of these image names. Now, just in case that was
confusing, let me go over exactly what we did again, in order to change our previous script
in order to use multiprocessing. So we were using a for loop here. But instead, we changed this to
a function that processes one image at a time. And now we're using our processing pull executor,
like we saw before, within a context manager, we're running executor dot map. And we are passing in
that function that we created. And then we're passing in our list of image names. And again,
what map does is it runs this process image function with every item in this image names list.
And just with those small changes, this will actually use multiple processes to process those
images and run these in parallel, instead of running these synchronously. So if I run this,
whoops, and I made another mistake here, you guys probably saw that one also. But I needed to put
a colon there. Okay, hopefully that's my only mistake. Okay, so if I run this, then we can see
now these are processing faster. And I'm going to open up my activity monitor here, and scroll down
to the P's. And we can see here that we have multiple Python processes running here. So we can
actually see these in our activity monitor. And now that this script is finished, then we can see
most of those go away. The only one that's still here is probably just one that is open here in
my sublime text. So we could see all of those kick off in our activity monitor. And we could see that
they were all returning faster. That's because they were running in parallel. And now instead of
taking 22 seconds like it did before, now it finished in seven seconds, so more than a third
of the time. So that's a pretty significant speed up there. And this would be even more
significant if we were processing even more images. So the speed ups can be pretty drastic
depending on what you're doing. Now, again, you might want to experiment when using multiple
threads or processes for specific tasks, depending on what you're doing and what kind of hardware
you're running. One might be drastically different than the other. And it's hard to tell exactly what
you should be using without some benchmarks. But again, a good rule of thumb is that you want to
use threads for things that are IO bound. And you'll want to use processes for things that are CPU
bound. But you may actually see significant speed ups using threads with this example, since this
is reading and writing to disk, which is an IO bound operation. Now one nice thing about using
the concurrent futures library like this is that switching between threads and processes
is just as simple as changing this process pull executor and just using a thread pull
executor instead. And you can do that vice versa to change from threads to processes with your
programs. So if I change this to a thread pull executor, let me see if I'm right about a lot
of this being IO bound here. If I run this, then we'll see how long this takes us to finish this
script using threads instead of multiple processes. And that was actually faster. So that was 7.2
seconds. So even though I tried to put together an example that was doing a lot of processing on
the CPU, it looks like most of this is IO bound from opening and saving these files and not CPU
bound, but from doing some image processing here with these Gaussian blurs and these resizes and
things like that. But that's okay. That's why you want to always experiment. And, you know, if you
try it with a process pull, then maybe try it once with threads and see if you get a better
execution. And also, whenever you add in even more items, maybe processes will start to become
more performant than threads. So it really just depends on what you're doing. Now before we finish
up here, I'd like to mention the sponsor of this video. And that is brilliant.org. So when we're
talking about threading and multi processing, these topics are especially useful in the field of
data science. And the data science field is growing at a very rapid pace. If you'd like to learn more
about programming and data science, then I would definitely recommend checking out brilliant.org.
So brilliant is a problem solving website that helps you understand underlying concepts by actively
working through guided lessons. And they've recently added some brand new interactive content that
makes solving puzzles and challenges even more fun and hands on. And if you'd like to learn more
about data science and programming with Python, then I would recommend checking out their new
probability course that covers everything from the basics to real world applications and also
fun things like casino games. They even use Python in their statistics courses and will quiz you on
how to correctly analyze the data within the language. So their guided lessons will challenge
you. But you also have the ability to get hints or even solutions if you need them. It's really
tailored towards understanding the material. They even have a coding environment built into their
website so that you can run code directly in the browser. And that is a great compliment to
watching my tutorials, because you can apply what you've learned in their active problem
solving environment. And that helps to solidify that knowledge. So to support my channel and
learn more about Brilliant, you can go to brilliant.org forward slash CMS to sign up for free. And
also the first 200 people that go to that link will get 20% off the annual premium subscription.
And you can find that link in the description section below. And again, that is brilliant.org
forward slash CMS. Okay, so I think that's going to do it for this video. I hope you feel like you
got a good idea of how to use the multiprocessing module and how we can use these to speed up our
scripts. Now I hope you also feel like you got a good overview of threads and processes and when
you should use those. But like I said, if you're unsure, then there's no hurt in simply trying
both on a subset of your data to see what gives you the most speed up. Now there are some more
advanced topics that we could cover in future videos, such as race conditions, locks and things
like that. But we'll save that for a future video if anyone is interested. But if anyone has any
questions about what will be covered in this video, then feel free to ask in the comment section
below and I'll do my best to answer those. And if you enjoy these tutorials and would like to
support them, then there are several ways you can do that. The easiest way is to simply like the video
and give it a thumbs up. And also it's a huge help to share these videos with anyone who you think
would find them useful. And if you have the means you can contribute to Patreon and there's a link
to that page in the description section below. Be sure to subscribe for future videos. And thank you
all for watching.
you
