Welcome back to Awakening from the Meaning Crisis. This is episode 26. Last time we took a look at
what's happening in Germany in the period post-Hegel, post-Marx, post-Nietzsche, and we took
a look at the rise of the pseudo-religious ideologies and the various other cultural undercurrents
and threads and processes of transformation that were gathered together in Germany and
then exacerbated and ignited, if you'll allow me a volatile metaphor, by Germany's terrific
defeat and the terror that was World War I and the impact this had on Germany and how all
of this, all of these features that we saw at work in Germany and in the Meaning Crisis get
spun in Hitler's autodidactic myopia into a Gnostic nightmare, a titanic pseudo-religious ideology,
and how the two great pseudo-religious ideologies of Nazism and Marxism, at least the Stalinist version
in the Soviet Union, come to titanic blows in the Eastern Front at the Battle of Kursk.
And then I pointed out that this and then the ideological battle, political ideological battles
of the Cold War thereafter, have left us deeply traumatized. We place no faith in pseudo-religious
ideologies, utopian visions to solve the Meaning Crisis. At least many of us don't.
We do not see ourselves as capable of the nostalgic return to religion, somehow pretending that all
of this history, all this science, can be ignored in a kind of fundamentalism. And please note that I'm
not equating all religion with fundamentalism. Instead, we find ourselves in the middle, in between these,
and we're trapped. We can't go back, and we can't do a secular alternative to religion. And yet we need
something that will systematically create psychotechnologies that transform consciousness, cognition,
character, and culture in a way that religions have, if we're going to address the Meaning Crisis, and in fact,
the meta-crisis that we're confronting right now in the world today. And so we're caught in this
situation, and we pursue either various radicalisms, and I critiqued the idea that the Meaning Crisis should
be understood, or we should attempt to solve it by the clash, or through the clash, by means of the clash of
political ideologies, that that is to fundamentally misframe it. Because if you remember,
Kierkegaard, and Marx, and Schopenhauer, all in their different ways, and in ways that we can criticize, are
nevertheless pointing to the fact that the participatory and perspectival knowing that is so crucial to
responding to and losses of meaning and regenerating meaning has been ignored by Hegel.
So we can't do this politically. It doesn't mean that politics is irrelevant, but it means that framing and
formulating the problem at the political level is to radically misframe it and misformulate it.
And then I propose to you that instead we turn to an alternative way of trying to reformulate the problem,
that we try and get a scientific understanding, as best we can, of the meaning machinery,
this machinery that we perspectively participate within. We don't just simply, I'll often say meaning-making,
but as I'll argue, we don't just, we don't make meaning the way the Romantics said.
Nor either do we just receive meaning from the world, the way the empiricists and the Enlightenment argued.
We're going to see that it's neither one of those. That's another dichotomy that we have to transcend.
But nevertheless, let's look at this machinery, the machinery of meaning realization.
What are the cognitive processes at work within it?
And I propose that we do that from a scientific worldview precisely because, at least from a scientific point of view,
precisely because we need that to complement the historical analysis,
and because the scientific worldview is part of the problem of the meaning crisis itself.
So, I propose we take a look at the science of cognition, and that means that we take a look at cognitive science.
I am a cognitive scientist, professionally, but as I said from the very beginning of this series,
I'm offering you a particular interpretation of how to do cognitive science.
Not everybody in cognitive science would agree with me,
but I think it is a viable and respectable version of cognitive science that can be argued for.
What is that idea? It's the idea that cognitive science is born out of a particular way in which the scientific study of mind has unfolded,
and as I indicated last time, it's a way that has actually contributed significantly to a version of the meaning crisis
that is deeply personal, deeply in the very guts of our minds and bodies.
And this has to do with the idea that this term has now become equivocal, and we'll come back to that in a minute.
Because we actually are talking about different things, or at least different levels of the reality of mind,
with different disciplines, different disciplines that use different vocabularies, different theoretical styles of argumentation,
different means of measuring phenomena, different ways of gathering evidence.
So, we have the brain that's being talked about by the neuroscientists.
You know, talk about patterns of neural activity using fMRIs, etc. We talked about that.
And then we have a totally different level at which we're understanding intelligence, the mind, in terms of information processing,
especially when we're in the project not of measuring brains, but of trying to make machines that are instances of mind.
Not just simulations, but bonafide instances.
And this is the project of artificial general intelligence, projects like machine learning, etc.
And of course, they talk about different things.
They don't talk about neurons.
They might talk about neural networks, but those aren't the same thing, importantly.
They'll talk about algorithms, heuristics, you know, all that sort of stuff.
Very, and they don't, you know, use fMRIs.
They actually make machines and processes.
Different ontology, different methodology, etc.
Then we, of course, we have understanding mind as behavior, and that's psychology.
And here we talk about things like working memory and problem solving, decision making.
And we do experimentation on human beings and statistical analysis.
Again, different ontology, different theoretical vocabulary, different methods of studying the phenomena,
different ways of presenting evidence.
And we noted throughout that there are attempts to create hybrids between the various disciplines.
So these are the levels of reality here.
And these are the disciplines here.
Because above this, as we said, we have language because of the tremendously important and special role that language plays with respect to being a medium for mind,
and being a way of communicating mind.
And, of course, here we have linguistics.
And we might get psycholinguistics to try and bridge between them, right?
But nevertheless, in linguistics, we're talking about things like, you know, sentence structures and rules of transformation,
and gathering different kinds of evidence, etc.
And then the networking of minds and brains together through language and behavior as culture,
and that's studied by anthropology, and that has a very different method.
This really emphasizes the perspectival and the participatory.
So you do participant observation, you write ethnographies, right?
And, of course, that helps to give one of the advantages of science.
It helps to formulate, you know, and specialize people so they can get much more precise analysis.
And so this is a good thing.
I'm not trying to, in any way, despise this.
But it is problematic in that it carries with it, first of all, it fragments us.
This term, mind, has now become equivocal.
What are we talking about when we're talking about our mind and related constructs like our self?
So let's remember what equivocation is.
Equivocation is when you fall into confusion precisely because you do not keep track of the meaning of your terms.
So here's one of my favorites, right?
So nothing is better than long life and happiness.
Kind of something that you get in Star Trek, right?
Great.
And then I can say to you, a peanut butter and jelly sandwich is better than nothing.
Ergo, a peanut butter and jelly sandwich is better than long life and happiness.
So you know what you should do?
You should eat a peanut butter and jelly sandwich and then commit suicide.
Now that's ridiculous.
And that's the whole point.
This should not convince you to eat a peanut butter and jelly sandwich and commit suicide.
It's designed to convince you of the, the, the ridiculousness of this argument.
Now why is the argument ridiculous?
Because I'm used, the argument hinges on the, this, right?
And that because I'm using the same term, it sounds like I can make the inference.
But of course, although I'm using the same word, I'm not meaning the same thing.
This means no thing from the set of things that makes life worth living is better than long life and happiness.
This means no thing from the set of things you should eat.
And those are not equivalent sets.
There's not equivalent reference.
If you don't keep track of what your words mean, that's why we, we, I'm always so careful to try and give you, like, the meaning of things and the history of the meaning of a term.
If you don't get sensitive to the meaning of terms, you'll fall into equivocation.
Which is a disastrous way to try and reason about anything.
Okay, so what's the point of that?
Well, the term mind isn't univocal.
It can be, what am I talking about?
Am I talking about this?
Am I talking about this?
Am I talking about this?
Am I talking about this?
Am I talking about this?
Am I talking about how this and this?
Am I talking about this?
We don't know.
And the degree to which I'm equivocal, without realizing it, is the degree to which my thinking
about my mind, and therefore myself, is ridiculous.
If you aren't clear about what this word means, how you're using this concept, you will be bullshitting yourself through equivocation.
I also pointed out that one of the consequences of this is fragmentation.
What do I mean by that?
Well, there's an ignorance in this.
And again, I'm not disparaging science.
And again, I am not disparaging these science.
I love these sciences.
I've got education in them.
And I value them.
That is not what is happening here.
But, one of the things that is missing, that we are ignorant of in this model, is this.
These various levels of reality causally impact and constrain each other in very important ways.
These individual disciplines don't capture that.
That's why there's this constant temptation and need to create the hybrids, like psycholinguistics.
So, how are we going to study, therefore, the relationship between the levels?
We have to get the disciplines to hybridize, or beyond that, to talk to each other, to integrate together in some fashion.
If we're going to deal with that ignorance.
And that has to be an astute practice.
We can't just integrate by equivocating.
No integration through equivocation.
Because that's just bullshitting.
So, what we have to do, is we have to have a philosophically astute integration.
We need philosophy, precisely because philosophy is the discipline that has us take conceptual care
to try and articulate the meaning of our terms.
To try and bridge, because that's what philosophy does.
It tries to bridge between these different vocabularies, these different ontologies, these different methodologies.
That's what philosophy does.
Philosophy isn't about sitting around in cafes, smoking cigarettes, and saying vaguely obscure things.
Now, the discipline that tries to come up with a philosophically astute integration between these disciplines,
so that we can avoid equivocation, and deal with fragmentation, and overcome the ignorance of the causal relationship between the levels, that's cognitive science.
That's what cognitive science is.
That's what people mean when they say cognitive science is an interdisciplinary science.
Now, I hope you see that cognitive science is already directly confronting and addressing one of the ways in which the meaning crisis is inhabiting us,
in terms of the way the scientific worldview, again, I'm not denigrating it, but the way in which the scientific worldview is fragmenting us,
and causing us to fall into ignorance about who and what we are, and to equivocate and bullshit ourselves about who and what we are.
Cognitive science is placed to address that by its very nature.
And, of course, it is the science that is going to talk about this meaning generation process,
because all of these are about that in some important way.
They're all about how mind makes sense.
Now, I want to argue that there are different ways in which you can understand how you practice cognitive science,
how you try and create these bridges between the disciplines.
And I'm not presenting them in a neutral fashion.
I'm telling you that right from the beginning.
I think one of these ways is the best way.
A way, nevertheless, in which people use this term.
They'll often not capitalize it, and they'll pluralize it.
They'll talk about the cognitive sciences.
And then, all that is, is just generic nominalism.
Cognitive science, or the cognitive sciences, is just a name for the genus that each one of these disciplines belong to.
Anthropology is one of the cognitive sciences.
Machine learning is one of the cognitive sciences.
Neuroscience is one of the cognitive sciences.
Generic nominalism is useless, given the concerns I've articulated for you.
It's not going to address the equivocation.
It is not going to address the fragmentation.
It is not going to give us any purchase on addressing the ignorance between the different levels of reality.
So I believe we should, although this is often used this way,
we should reject this, at least as the sole meaning of what cognitive science is doing.
The next thing people do, is they will have this term, sort of, cognitive science.
And they understand it as a kind of interdisciplinary eclecticism.
What I do, like, I'm, you know, to do cognitive sciences, let's say I'll be one of,
I'll be a member of one of the core disciplines, let's say I'm a neuroscientist.
And what I do is, I'm a neuroscientist, but I, I, I read a bit about psychology,
or perhaps linguistics, and then I pick some ideas that are interesting from the other disciplines.
And, you know, and I use them.
And sometimes I, I'll tell some of my linguists or psychological friends
some of the things I'm doing in neuroscience, and some of those ideas might interest them.
And, of course, that's good and people are free to do this.
And the model for this, right, is, you know, kind of like, I mean this as an analogy,
you know, what we have in interfaith dialogue.
See, the, the whole point about interfaith dialogue is, you know, the, the Christians and the Buddhists talk,
and, you know, I find something interesting, let's say I'm a Buddhist in Christianity,
and the Christians find something interesting, me and we talk, but we're not trying to radically transform each other.
There's no sense in which there's going to be a really significant transfer, a transformative transfer of insight between us.
And we're certainly not trying to make something above and beyond Buddhism and Christianity.
It's not like after we do the interfaith dialogue we're going to have come up with a new religion.
Now, I use that metaphor precisely because I think it's helpful, right, for understanding.
Now, the goal of interfaith dialogue is to, you know, enhance mutual understanding and build tolerance and respect, reduce violence.
And these are all noble endeavors, so I'm not, I'm not disparaging this.
But notice the problem here.
Notice it's not really capturing why people feel so strongly, you know, drawn towards creating things like psycholinguistics
that bridge between them, the, the different disciplines.
See, the problem with this is it's both, it's either too weak or too strong.
This can very quickly just become, there's no significant bridging between the disciplines.
There's some interest, there's some creation of mutual respect, but it's not the case that we're really capturing significant,
theoretically important relationship between the different levels by having strong transformative insights passing between the disciplines.
Right?
So this will tend to degenerate.
Or people will realize they need something stronger.
They will realize that there is something to this attempt to create the linking disciplines.
And that's the third, and I think therefore best, vision of cognitive science.
That's the vision of cognitive science as synoptic integration.
Synoptic integration is not saying that all the disciplines are saying the same thing.
It's not saying that.
But it's not simple eclecticism of, well, they're all saying different things, but let's get them all to be friendly and like each other
and they can have some sort of peripheral influence on each other.
Synoptic integration is saying, no, we need to build something, right, between the disciplines that addresses the equivocation,
deals with the fragmentation, and fills in the ignorance.
Tells us about how the levels are all, are actually causally interacting and constraining each other.
That's synoptic integration.
So what you want to do, right, is you need to say, they're not saying the same thing,
but they're not just saying different things either.
You have to create this bridging vocabulary that integrates across the disciplines.
Now, that's a tricky thing to do.
But we've talked a long time ago about the fact that our brains actually,
since the Upper Paleolithic transition, we've been training them and developing them and enculturating them
to get very good at bridging between domains.
Even the word bridge exemplifies what I'm referring to, namely metaphor.
We use metaphor as a way of bridging between domains.
I am not about to make the argument that science is metaphor.
That is not what's happening here.
But I'm trying to use metaphor as a way of saying that there is already a cognitive ability in us
that we can exact and make use of in cognitive science.
Look, look at how a metaphor works.
If I say to you, and Sam is a human being, if I say to you Sam is a pig, right,
notice what you have to do in order to make this work.
So it looks like I'm creating an identity claim, Sam is a pig.
But of course, what makes it a metaphor is it's not an identity claim.
I can't use this as a way of telling you that Sam has pink skin and he lives on a farm
and he's going to be eaten by other human beings someday.
That's not what I mean.
I mean something like he's gluttonous or he's, you know, sexually selfish or something like that.
Right?
So notice what I have to do.
I have to keep the two different while also saying how they're importantly the same.
Now why am I doing that?
Because that difference, right, that difference gets me outside of my, here's my framing of Sam.
And the difference gets me outside of my framing of Sam.
And I look through this.
I look through, if you'll allow me, you know, the framing of something as a pig.
And I use this to look and see something in Sam, a way in which they're identical.
So I step back through the difference, but I step, I look through into the identity.
And I see things in Sam through my pig lenses, if you'll allow the metaphor.
And I allow, it allows me to see and understand Sam in a different way.
It alters what I consider salient in Sam.
It restructures.
And so metaphor has this duality about it.
And what you want to do is you want to, you want to create a, a, a, a, a metaphor that
balances these in an appropriate way.
When a metaphor, when a metaphor balances these, these, these two well, we talk about
a metaphor being apt.
So, notice if I make the identity relation too strong, if I emphasize this side too much,
and I say bees are hornets, you don't think, oh, wow, what a great metaphor that is.
That's such a wonderful metaphor.
In fact, that's a really crappy metaphor.
Right?
This doesn't give me enough distance.
I can't step back enough and have an insight into this.
This provokes no insight.
There's no insightful transformation of my understanding of bees.
This is too close.
But if I, if I emphasize the difference too much, something like, you know, arguments are
chairs.
Well, you know, arguments are chairs because they're both human-made structures and we use
them on a day-to-day basis.
This is a very crappy metaphor precisely because, you know, the difference is too great.
I've stepped back so much.
If you'll allow me, I'm, I'm losing sight of this and it's not clear.
It's vague.
How, what am I supposed to see about arguments through this distant lens of chairs?
Apt is when I get an appropriate balance of that.
So, what I'm looking for, I'm writing cognitive science, is I'm looking for theoretical constructs,
proposed theoretical entities, that get this apt balance, that allow me to keep the differences
between the disciplines, but, you know, but also see from and through those distances relevant identities,
that allow me, right, to look from neuroscience into artificial intelligence in an insightful way.
Or look from, I step back from, right, behavior in psychology, I go, I step into linguistics,
and then I look at psychology.
I keep that distance, I don't identify them, but I also try and see, ah, but what is the,
what can I see in psychology through the lens of linguistics?
Now, of course, the thing about cognitive science is it's not trying to create single aptness, right,
it's not trying to create a one, this is one way, I've just bridged between two domains.
Cognitive science is trying to create constructs that are multi-apt, that bridge between multiple domains,
multiple disciplines.
And that multi-aptness is really important.
So I'm trying to create constructs with multi-aptness.
They get this balance between identity and difference that affords and provokes insightful transformation
of the theorizing from one discipline to another.
And I start to create an overarching integration.
Now this brings up an important idea about, well, what's constraining me?
How do I, like, what's, how do I judge if I'm doing this well or badly?
Well, this has to do, I think, with this notion that is very much the notion that we use when
we're considering how to create new constructs, new ideas, theoretical entities that will bridge
between domains, create lines of inquiries.
This is plausibility.
Now there's two meanings to this word.
One is just a synonym for high probability, and that's not the one I mean.
There's a different meaning, originally really brought to the fore by Rescher's work, but a lot of other people.
There's work being done now, some good work in psychology being done on plausibility.
I'm doing some work with Leonardo Ferraro, Jun Sung Kim, on plausibility.
And this other sense of plausibility isn't a synonym for high probability.
It's a, it's, it's a synonym not for rational, but for reasonable.
The sense, making good sense.
And of course, man, that's so relevant to us, right?
Making good sense.
Deserving to be taken seriously.
Right?
This is what plausible means.
It's reasonable.
It makes good sense.
It should be taken seriously.
And when we look at, sort of, ideas that we're using to make sense of the world,
and again, this is building on a lot of people's work.
I can't refer to them all, all the people I'm trying to draw together.
Of course, people make judgments of plausibility all over the place, and they bullshit themselves in this,
in all kinds of ways.
I'll talk about that.
So I'm talking about here, not a descriptive theory of what people do when they're saying something's plausible.
I'm talking about a normative theory about what do they do when they're doing it well.
What are they doing when they're doing it well?
So part of the argument is this.
People, of course, really like ideas that are multi-act, right?
Here is my idea, my thesis, my proposal, some model, whatever kind of construct I'm using,
and it's multi-act in that, you know, I can use it and it can bridge to this domain and this domain.
I can go into these many different domains.
I can do this insightful connecting and transfer.
I think this is a much better way, this notion of multi-actness, right?
And being able to go into many different domains and help us find, formulate, and solve problems.
I think this is a much better understanding of what scientists are trying to invoke when they say a theory is elegant, right?
Than just talking about simplicity, precisely because of the way we have no canonical way of trying to work out what scientists are meaning when they talk about simplicity.
Whereas it's clear that they do seek constructs that do this.
Now here's a problem.
Is that good enough?
Is that good enough to make a construct plausible?
Now, see, the problem with that is if it's just on its own, right, we're lacking something.
We're lacking another thing that we want.
And this is a point actually made by Rusher, and it comes out in some of the psychology of plausibility.
You see, we also want that these constructs are produced in a certain way.
Not just that they're, this is how they're used, but this is how they're produced, right?
This is their forward orientation, this is their backward orientation.
We want a construct that has been produced by many convergent, right, independent lines of investigation.
Now let me show you just a concrete example of this, right?
And you can see it even in young kids.
You prefer information that integrates, think about integration, across multiple senses, right?
So, you prefer information that is not just something you can see, but also you can simultaneously hear.
That's why seeing and hearing me right now is better than just seeing me or just hearing me.
Now why is that the case?
Well, you see, if I'm getting all of my information just through one channel, there's a very good chance that this thing is being produced by bias, by distortion in that channel.
But, if I'm getting the same thing produced by, from multiple independent channels, right, there's a very good chance that it's not being produced by the bias or distortion in any one of these.
There's a chance that, there's a very good chance that the relative biases and distortions cancel each other out.
So, by doing convergence, I get bias reduction.
And man, does that matter, eh, for overcoming the way in which we bullshit ourselves with salience.
So, convergence gives me bias reduction, what Rescher calls trustworthiness.
Now, trustworthiness isn't truth. It's not certainty.
This, by the way, is why science likes numbers.
Scientists like numbers not because we're fascists or because we don't appreciate the artistic beauty and blah, blah, blah, blah, blah.
We like numbers because they give us this. Look. You can see three. You can hear three. You can touch three.
Numbers afford convergence and they boost trustworthiness. They help to reduce bias.
And remember, I've tried to argue that the scientific method of experimentation is a method, right, in which we are trying, methods of, sorry, the scientific method of experimentation and observation are methods, psychotechnologies in which we're trying to reduce bias.
Reduce the way in which we're deceiving how we're coming up with our constructs.
Now, think about this. If you had just elegance, this multi-aptness, you can bridge to many different areas and link lots of stuff together, but it wasn't produced in a trustworthy manner, what would you have?
You would have conspiracy theories. That's exactly what conspiracy theories do. They're a form of bullshitting because they are, they're very, look, if you will just accept that the British royal family are,
lizard, reptilian aliens from another dimension, you can explain so much of their political and social and interpersonal behavior.
Just give me this idea. Just give me this and look at what I can do. Look at all the different disparate facts I can link and integrate together.
I can give you this synoptic integration. And you should be saying, yeah, but it's all bullshit.
It's bullshit because we find this. We want this. So it's very salient. But it's bullshit precisely because we've lost this. We don't trust the construct.
What about the opposite? So the conspiracy theory is far-fetched because it gives us lots of this but very, very little convergence.
What about this? Where I've got tremendous convergence. Surely we'd like this. And there's just, there's very little insight, integration.
What's that? Well, if you read scientific journals, you'll see people, and even beyond philosophical journals, people rejecting this.
This is, this up here, this is the conspiracy theory and it's far-fetched. But you know what this is? This is triviality.
And we reject things. Now, to accuse something of being trivial is to not say it's false.
It's to say that it has no transformative power. It makes no difference. It causes no insight. It affords no integration.
So this tells, this tells us something. And notice, notice, notice, notice ways in which we can equivocate on these, right?
Between, we can equivocate between this, right? Between these two. So Daniel Dennett talks about this.
This is a way in which, one way in which we bullshit ourselves. He calls it the deepity. A deepity. Okay?
So, people do this. They'll say, they'll say things like, love is only a four-letter word.
And, and you, everybody says this and, oh, it's very profound and you take another drink of your alcohol or whatever.
Alright? Now, notice what's going on here. On one level, this is a triviality. Of course love is a four-letter word.
I've got many different independent memories, different uses. Everybody's using the word love this way.
Right? Love is a four-letter word. Right?
Now, at that level, it's trivial. But then, it's supposed to, I'm supposed to equivocate between this as a word.
I'm equivocating between this as a word and this as a concept for a thing that I care about.
Because love as a thing has tremendous elegance. It goes into so much of my life.
But notice what's happened here. I'm not actually giving you any information or analysis about love as a thing or a concept.
I'm pretending to give you multi-aptness, when in fact, all I'm doing is giving you triviality.
Sorry, triviality.
I equivocate.
As I say, love is just a four-letter word.
It's bullshit.
It's bullshit that makes use of, abuses, and this is powerful ways in which we bullshit ourselves with these deepities,
these things that sound deep and are not deep at all.
Because what we're doing is equivocating.
We start with something that's undeniably trivial.
And then we're equivocating with something that looks like it's elegant and multi-apt.
And we bullshit ourselves.
We do the reverse.
We say something that looks like it's really multi-apt and really controversial and is going to change everything.
And then we're challenged.
We're challenged.
Oh, no, but great criticism.
Oh, no, no.
I never meant that.
I only meant this trivial thing that nobody would possibly object to.
Right?
This is the Martin Bailey strategy, right?
Where you present and it looks radical and controversial and then when you criticize, you withdraw.
No, I was just saying this.
It looks like I'm doing, but no, just this.
But then I pretend that I didn't actually change my position.
They're the same thing.
And that is again how we bullshit ourselves.
So notice how we can abuse this machinery and bullshit ourselves.
Now the fact that we can abuse it tells us how we can improve it.
How it's supposed to be used.
Because if we acknowledge that these are abuse, that this is abuse, that, right, the deepity is an abuse.
If we acknowledge, right, that the Martin Bailey strategy of avoiding criticism is an abuse.
If we admit that we don't want far-fetchedness and triviality, we can put this all together into a normative account of what good plausibility is.
We have high convergence matched by high elegance.
And I'll talk a little bit later when we do some more cognitive science.
We want something more about this in terms of relevance realization and other things, but we'll come back to that.
But when I get a balance between convergence and elegance,
then I get something that's highly plausible.
So I'm making a construct that is trustworthy and powerful.
And it's affording me getting a new pattern of intelligibility.
This is how I make integrative new patterns of intelligibility in the world.
And so this is what you're trying to do in cognitive science.
You're always trying to create these constructs that are high in plausibility.
When I get something that is extremely trustworthy, that is balanced with powerful multi-appness,
then I think that's what we mean when we say something is profound.
It's the exact opposite of the deepity, the triviality, the conspiracy, the Martin Bailey bullshit.
It's profound.
Now being profound doesn't mean it's true.
Being profound means it's very reasonable and it should be taken very seriously.
I'm going to now try and exemplify this with you.
I should mention before I go that this idea of the balance between this and this,
I got this from Elijah Milgram's really, really brilliant work on practical induction.
Practical induction is not induction about how you change your belief.
Practical induction is how you change your desires, how you change what you care for.
It's deeply relevant to that Socratic project of having a rationality of what you care about.
Okay.
So what I want to do is, first of all, draw this together in this definition.
Okay.
So cognitive science, right, it's the discipline that it's trying to bring about synoptic integration.
And I'm going to say it's trying to bring about profound synoptic integration.
It's trying to create these constructs that bridge, don't reduce, bridge between the disciplines.
Profound synoptic integration, profound synoptic integration that addresses equivocation,
fragmentation, and ignorance.
The ignorance of the causal relationship between the levels of reality that we designate by the term line.
That's what cognitive science is trying to do.
And of course, as I've tried to show you throughout, it is deeply relevant to the meaning crisis,
because it deals with this issue of fragmentation, the confusion we have about ourselves,
how we're sort of pulled apart.
It deals with, as you've just seen, the meaning-making machinery.
And it deals with, again, as you've just seen, our propensity for bullshitting ourselves and deceiving ourselves.
Now what I want to do is I want to do the cognitive science of meaning-making.
Again, I'm not totally happy with this term, because it sounds too romantic in my ears.
Right?
I'd also want to say meaning-seeking, but that sounds too empiricist in my ears, like meaning's just out there to be seen and experienced.
Right?
So, I'm going to try a new metaphor.
Because it also goes with something else I've been saying from the beginning.
And this is inspired by the way we talk about the cultivation of wisdom, and it's inspired by Heidegger's use of this metaphor, meaning cultivation.
Because what I'm going to try and argue, and also you've seen this in the history, is meaning isn't something we're imposing willfully on the world.
That's a mistake from our history.
Meaning isn't something we just find in the world.
That's to ignore the scientific revolution.
Meaning is something between us and the world, like the way you cultivate a plant.
You're doing stuff with the plant, but you're also allowing the plant to unfold.
You're cultivating with the world meaning between you and the world.
So, as much as possible, I'm going to try and switch this.
I will fall into habit because this is the language that we inherited from the cognitive revolution in psychology about talking about meaning-making and making sense.
And where the emphasis is on us making, even though, as I'm going to show you, third generation cognitive science is much more talking this way than the romantic notion that we impose or make meaning or we simply sense it or find it in the world.
Okay, I want to start doing the cognitive science of this.
I want to take a look at the science of cognition.
And I want to try and exemplify what I showed you, what I argued for.
I want to try and exemplify synoptic integration and the creation of a plausible construct.
So, the faculty in us that is supposed to be our core cognitive capacity, our core capacity for meaning cultivation and being able to adaptively respond to the world.
And this goes all the way back, right, to the Greek heritage.
This is the notion of intelligence.
Intelligence is the capacity that makes you a cognitive agent.
At least an agent whose cognition is working with meaning as opposed to a living thing, right, that is, in some sense, like a plant responding.
Maybe in a very sophisticated fashion, but it's just responding in this complex fashion to its environment.
Intelligence means you are, in some sense, a cognitive agent.
Okay.
So.
What is it that we should…
How should we frame this?
We're going to try and get a purchase on this, right?
So, a good way of trying to understand this is the way we try to test for intelligence is being a general problem solver.
And this goes back both within the psychometric to people like Binet and Simon who are trying to measure intelligence and people like Newell and Simon, two different people by the way, that are trying to create artificial intelligence.
artificial intelligence, artifactual intelligence, right, not fake intelligence, right?
Both of them point to this idea that when we're trying to measure or make intelligence, we're trying to measure you as a general problem solver, or we're trying to make a machine that is a general problem solver.
Now, what does that mean?
Okay.
So, here's a machine that's not a general problem solver.
This is good for solving this problem, holding water.
And we've talked about this in such a way that I can use it.
It solves a bunch of other problems maybe, but not very many.
Not very many.
It's very limited in its problem-solving capacity.
Now, unlike that cup, you are capable of solving a wide variety of problems in a wide variety of domains.
You are a general problem solver.
You can worry about God and how to get a drink, how to go swimming, right, how to build a houseboat.
The number of domains in which you can operate is vast, and within each one of those domains, there are many different kinds of problems you can solve.
You are a general problem solver.
And that's why when we measure intelligence, we give you a wide variety of different kinds of tests to see if you can solve a wide variety of problems across multiple domains.
That's why I test to see if you're a general problem solver.
And what Newell and Simon were exactly trying to make, they in fact called it, we can't use this term now because it now means global positioning,
but they called it the GPS, the general problem solver.
The first project to make artificial intelligence, not just computational machines, but artificial intelligence was the, right, this project of trying to make the general problem solver.
Okay, so you're a general problem solver.
Okay, great.
That makes sense, right?
Now, what I need to do is a couple things to be, I got to be very careful here, right, and because people get very, of course this is, we'll come back to that, this is such a politically laden term,
precisely because we aren't clear about what we're talking about, we're equivocating all over the place, and we're ignorant of how this term is applied to different levels of reality,
and yet, nevertheless, we bullshut ourselves by finding it salient and rushing into speech and action without the clarity that is needed.
We'll see, for example, that this is not a synonym for being rational, being intelligent.
And what you ultimately should care about is not how intelligent you are, but how rational you can become.
So, let's take care here.
We're meaning some capacity you have for solving your problems and learning.
And so we want to keep intelligence separate from knowledge.
Of course, having knowledge enables you to do things, right?
And in that sense, in a broad sense of adaptivity, it makes you more adaptive to your environment.
You can do lots of things, even if those things are make claims that other people value for their truth.
But if you, if you think of the, if you make these synonymous, then you can't use this to explain this.
You can't say, the reason why Susan was able to acquire such knowledge is because she's intelligence.
Because if intelligent means possessing knowledge, then all you're saying is Susan possesses knowledge because Susan possesses knowledge.
Which is non-explanatory.
Right?
So, what we want to ask is, what is it to solve a problem?
Don't focus on the product, having the answer, getting the knowledge.
Right?
Focus on the process.
The process.
And this is going to be a hallmark, we've talked about this before.
The hallmark of rationality is valuing the process, not just being fixated on the product, especially the belief, the conclusion.
Right?
So, what, we've got to analyze the process.
What is it to solve a problem?
And this is where the work of Newell and Simon was just so deeply influential.
It's been influential in psychology, computer science, economics.
It's just seminal and important work.
Now, as I first try to describe it to you, it's going to strike you as, you know, somewhat trivial.
But, let's go very carefully on what we're going to do.
Right?
We're going to try and analyze a problem down into four basic features.
And we'll end today's episode with that.
And at that point, it won't seem like we've got that profound construct that we're looking for.
And then, I'll need you to wait to next time.
But, Newell and Simon basically said, what is it to have a problem?
A problem is when there's a difference between the state you're in, which they called your initial state, and the state you want to be in.
This is your goal state.
So, I have a problem when there's a significant difference between those.
For example, I'm thirsty.
Right?
And I don't want to be thirsty.
And those aren't the same thing.
Things have to change in the world and in me for the difference between the initial state and the goal state to go away.
So, part of what I have to do when I solve a problem is the system has to be able to represent, we'll have to come back to how we're going to use that term, the initial state and the goal state.
And then, there are actions, operations I can perform that will change the state I'm initially in to some other state.
So, for example, part of the problem I had was I'm over here and the glass is over here.
So, one of the things I can do, one of the things I can do is I can walk towards the glass.
Right?
The cup.
Right?
Of course, another thing I can do is I can raise my hand.
Now, you say, well, don't raise your hand.
That's stupid.
Well, wait.
There's going to come a point though when I do need to raise my hand.
So, I'm going to need that operation.
Okay?
So, I think you're starting to see things.
And then, what I do is from here, perhaps I can do two other operations.
Right?
From here, maybe three.
From here, maybe only one.
And so on and so forth.
Right?
I'm not going to draw it all out.
Right?
So, so far I've got, right, three things that I'm analyzing problem solving into.
Initial state, a goal state, and operators that can transform one state into another state.
There's one other thing I have.
I have what are called path constraints.
You see, I'm a general problem solver.
I don't want to find just any solution.
One of the ways I can make lunch for myself is to burn down my house.
It will cook my food.
That is not a good solution.
Not because it doesn't achieve the goal I want in this situation of cooking my food,
but it really reduces me as a general problem solver.
I don't want to solve this problem to the detriment of my ability to solve multiple other problems.
Or I will lose my intelligence.
I will lose my capacity as a general problem solver.
So what I have to do is the following.
Solving a problem is this.
It's to have a sequence of operations, a sequence of operations that will transform the initial state
into the goal state while obeying the path constraints.
Preserving me as a general problem solver.
That's what it is to solve a problem.
And this, this is called the problem space, or sometimes called the search space.
Now, what this analysis does for you is it explicates the problem space.
And this is where all of the powerful insight of Newell and Simon's work comes out.
Because once we start to pay attention to properties of this search space,
we can see how profound this idea actually turns out to be.
And that's what we'll do in our next session together.
Thank you very much for your time and attention.
