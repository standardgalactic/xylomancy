It's a great pleasure for us to host Nassim Talib to Dartmouth, Nassim as you probably
know by now has been a pretty influential thinker for the last three decades, but particularly
since he published the Black Swan, which I looked it up, Nassim is cited by a hundred
thousand people in various publications.
I looked in Google Scholar, you should know this, it's good for your career.
Nassim came of age in Lebanon during the Civil War that only in retrospect seemed predictable.
Little wonder he spent his remarkable career teaching us about how to manage risk.
His profession he once told me is probability, but his vocation is showing how the unpredictable
is increasingly probable.
He taught us to be irritated by economists, officials, journalists, and executives who
take averages from empirical data and suppose that our tomorrows are likely to be pretty
much the same as our yesterdays.
He taught us about fat tales, fat tales there.
Fat tales, events that seem statistically remote, but contribute most to outcomes by
precipitating chain reactions say, viruses that spread software that goes viral.
He taught us about the dangers of connectivity that enable exponential growth.
He taught us about the dangers of connectivity that expose us to malicious or compromised
nodes in the network whose threats once could be isolated but now move and spread instantaneously.
He taught us about how fragile connected systems are and how fragile connected systems are
and how seriously we have to take antifragile measures that make us more robust even at the
cost of some illusory notion of efficiency, about the importance of storerooms and cash
reserves and many supply chains and circuit breakers and separation of powers.
He taught us, a former options trader that he was, about how to hedge against even profit
from our inevitable reversals.
He taught us about how in an uncertain world our choices actually become easier because
they focus us on doing what we must avoid, which is reckless behavior while increasing
our flexibility.
He taught us finally about how to contain our incipient recklessness, how we need to
insist that all have skin in the game, face moral hazards, suffer the consequence of our
action.
He taught us as only he can about Hammurabi code.
Now we are confronting a world in which network effects are being put on steroids.
Nodes are able to process unimaginable amounts of data and turn them into what can seem like
human creations.
AIs, large language models may not be as capable as humans but we seem nevertheless to be meeting
them halfway.
Nassim has made clear to me that he does not consider himself an expert on AI, yet I can't
think of anyone who is better qualified to talk with us about the dangers we may face
from technologies we just barely understand in networks that we do understand largely
thanks to him.
With great pleasure, Nassim Taler.
I'm very honored, but he gave me ... Professor Abishai gave me way too much credit, but
I think that it's been shorter because what I think I contributed to mostly is fragility,
is mapping fragility to accelerate a nonlinear response, why they must be come together.
Something else is pretty much other people's ideas largely my grandmother, but this mapping,
so that's sort of ... but I'm very honored also to be here because I've read him before
he read me.
Also you guys have a wonderful set up here, wonderful campus, very well positioned shielded
from New Yorkers and stuff like that, valley, so the entry points are scarce, so this is
a wonderful campus and I'm honored to be the first time in that great institution.
Nassim, let's start with some of the basics.
I feel like most of us intuitively understand the dangers of connectivity, but I think that
you've given it a kind of precision, you've given that danger a kind of precision and
I'd like to hear you talk about it because before we talk about AI, I think it makes
sense for everyone to understand what you considered to be the dangers of networks before
AI became a serious problem.
Let me give a very simple metaphor, a story I gave a Black Swan, so I'll be repeating
myself with that story, but it illustrates both fat tails and connectivity.
Let's assume that you're in the 19th century and you're an opera singer, you're an opera
singer in Boston or in Naples, you're protected, you have a job because the great opera singers
in Milan at the Scala which is very small and there are great opera singers at the Metropolitan,
they can't compete with you because they're over there and you're here, so you have some
kind of protection, therefore the income of opera singers is going to be similar to the
dentist, some dentists make a lot of money, some make less money, but the greatest dentist
doesn't make much more than the average because of course you can't scale it, you can fill
up the Scala, you know, you can do more than that.
And then, from Carrion, okay, discovered that there's such a thing as television and such
a thing as Deutsche Grammophon where you can store your voice, what happened?
Hundred years later, a few opera singers, about ten of them made 90% of the money and
the remaining opera singers worked, Starbucks was not the same at the time, but most of
the occupation was Starbucks, so that gives you an idea about connectivity, what did it
do in the economic world, okay, is that someone dead, like Pavarotti, can compete, okay, or
as a state can actually get the income away from a young opera singer in Boston, so this
is pretty much, so this is connectivity for you and then you can generalize to biological
things like COVID and in the Black Swan I say that the pandemic would not be a Black
Swan because of connectivity, now connectivity is a very good thing, but it has side effects
and if you don't know the side effects, alright, don't get too much into something, so these
are the side effects of connectivity is that you have a winner take all effect, so if you
take income of athletes, 1950, the top athlete versus the average, two, three times which
people found excessive at the time, top athletes, today it's 50 million euros versus say 35,000
euros, I'm very bad at numbers, so I can do algebra, but I can't do division, so this
is like 50 million by 35,000 and then you get an idea of the inequalities that we have
in that field, okay, so the current environment produces these things, the Harry Potter effect
that 100 authors worldwide can live off, numbers of the four or five years ago, can live off
of their income as authors and then the rest, again now they have Starbucks, there are other
things, there are university programs, where they teach people to write or end up teaching
other people to write or stuff like that, so this is the winner thing, so the rare event
actually accounts for the greatest impact on the entire thing, if you average it out
you miss that, you miss that.
You miss that because it's driven by the tales, by the rare event, by the extreme, there are
two environments, one I call mediocrity, if I take the weight of the people here, we put
them on a scale, I'm sure in darkness, the engineering department know how to build robust
scales, no, and then we add to our sample the largest person you can find on a planet,
the largest human being, it's not going to change the average much, all of us here, I
don't know how many we have here, let's say a couple of hundred, nothing, it's not going
to make an impact on the average, but if you take the net worth and add Elon Musk, okay
it was 200 billion dollars, so you realize that there are some domains Elon Musk would
change the average and it would be a high percentage of the total, so this is the effect
of fat tales and you got to figure out which domains produce fat tales and which domains
don't, so we have a tableau, in the blacks one I did that years ago, by saying this is
the domain of socioeconomic life, it's driven by fat tales, your weight is not driven by
fat tales, there's no meal you can have that will represent 98% of your annual consumption,
you can try, I mean you die I think after the first 2% or something like that, you die
after the first 5000 calories, so you can't reach, but you can lose all your money in
a minute, so we have this domain and the other domain.
Right, so go back to the epidemic, because that's interesting, you said the epidemic
was actually not a black swan event, even though the particular virus might be considered
a rare fat tale event, yeah, not having an epidemic is actually the rare event, not having
had an epidemic, but let's look at connectivity and the reasoning I had the black swan as
follows, if I have an island, an island would have many more species per square meter than
a continent, okay, so what does it tell you, it tells you that the continent has more inequality,
right, a few species dominate the numbers, and if you'd open up all the islands to one
another, you're going to have that, so we're going to have a winner take all of the biological
field, so whatever virus you have would travel, so the reasoning of the black swan with that
there's such thing, I don't know if you've heard of Air France, in France they fly to
New York, Paris, and at the time they rotated because they were not stopping Gabon during
Ebola, there are other things like, so there's Air France, the British Air, the American
Airlines, everybody has those, okay, so the great plague, I don't want to call it great,
but it was the plague, all right, it was a bad plague, it took, I think there's some
villages in the Lake District, in England, that reached 340 years after Constantinople,
okay, and they never reached the Americas, and Oceania, okay, so you realize now you
can have the same effect with a meeting like this one, where you have people from many
countries, or particularly if you have conventions, and people fly in, and they can distribute
to the Philippines, Mongolia, South Western China, Argentina, within a week you'll have
a worldwide pandemic, so that was the reasoning in the black swan, and no pandemic was taking
place, and we haven't had anything of significance since the Spanish flu, so I mean we had many
bad things, but so the black swan for me was the absence of such a thing as COVID.
Right, so the irony here is that most people will think of the existence of this virus
as a rare statistical event, but because of connectivity, and the way in which you describe
connectivity, the ability of that virus to spread is so baked into the network, and there's
no place to hide, and there's no place to hide that we should not think of pandemics
as rare events, we should assume that they're going to be predictable, they're rare, improbable,
but the probability of their spread is very predictable.
But I was enraged during the pandemic at practically every single group of different political groups,
in the beginning when we were waiting, we were a group of people in a nearby arm myself,
waiting for the pandemic to emerge, to go back people, to reduce connectivity, you don't
need all these things, all you need is reduced connectivity, and the Ottomans know how to
do it. The Ottomans in Habsburg had something called lasaretos, quarantines. I grew up in
Beirut, there was a quarantine, the Quarantina, had an Italian name, that was people, vessels
would come in and put you for 40 days. Actually, quarantine was about seven to 11 days, depending
on where you came from, they had formulas. And the minute they hear a rumor of a pandemic
or the Quarantina, so you had quarantines, we don't need quarantines if you have testing.
So it took us 13 months, from the inception of the COVID, to have testing at the U.S.
border. And particularly, I don't know if you've been to JFK when planes come from all these
places, and it looks like, I mean, the being in a subway car, everybody's contaminating
everybody. So for 13 months, people didn't get the simple measures. So in the beginning,
we started fighting for what we called, exactly, the coupling systems, by putting fences around
the system. So instead of lock-in, lock-in in your house, we locked out. So the second
thing is we had to fight people in psychology departments, finding it irrational for us
to worry about a pandemic that killed 5,000 people worldwide, when cancer was killing
5,000 people every day or something. So you can explain to them the following reasoning.
There's a fellow called Dr. Phil, who went on television and said, at the time, COVID
killed 3,000 Americans. He said, 3,000 Americans have drowned in the swimming pool. So, you
know, we don't shut down swimming pools because people drown in them. Why do we shut down
because of COVID? So, you know, the response is, if I drowned in my swimming pool, also
I was at the neighbor who was going to drown in her swimming pool, and that probably increased.
Sorry, that probably has not increased. Whereas if I die of COVID, my neighbor is going to
die of COVID has increased. So you got to look at the multiplicative effect of these things
and forget about standard statistics. Again, mediocre standard is what people learn in
business pool and statistic to classes. You're completely useless on a bell curve. The bell
curve works very, very well if you do astronomy. If you do medicine, it works, but it doesn't
work in socioeconomic thing. It doesn't work for pandemics. So we had to fight, and nobody
was taken as seriously until we started producing papers in like nature physics, because physicists
understood the mass immediately, and then people start taking us seriously. And then
you interviewed us. I remember also when we talked about it, I read that paper at the
time, and one of the things you said in the paper as a kind of decoupling or quarantine
was if everybody just wore a mask immediately. Exactly. Even if you don't understand how
it works, wear a mask. And the masks were masks also, they didn't get the non-linearity,
that the first part of it is complicated to explain the following. If I reduce viral
load by 10%, I may reduce infection probably by 90% or risk of death by more than that.
And the second thing, they couldn't figure out that if I wear a mask, and I reduce my
viral load by 10%, and you were wearing a mask, that you're looking at the joint effect
of both masks, not just one. So there have been a lot of papers on masks that we actually
debunked a lot of them. But besides that, you don't need a paper. I mean, just understand
that what you've got to do is wearing a mask while you're going to have a little CO2 or
something. It's not a big deal. People are not going to see your teeth. It's fine. Draw
a smile on your mask. So we had to fight for masks. But the problem is that in the beginning,
the establishment, intellectual establishment, using pseudo statistics, what I call the Pinker
statistics, named after Stephen Pinker in my books. So bad statistics are called na√Øve
empiricism. They were against measures to fight COVID. And then it switched. The Trumpist
became against the measures. And the other ones, because the Trumpists were against the
measures, the other ones said, okay, let's take measures. But in the beginning, it's not
like the polarization flipped at some point during that story.
So let's talk about fragility in this context, because that seems to me a critical insight
that you've advanced. If you have networks that are susceptible to the catastrophic network
effects that ensue, and that you have exponential spread, you then have, you know, you have
a kind of fragile system, which considers itself safe as long as it's just doing averaging,
but is not at all safe if you take into account the catastrophic effects of tail events.
And also the acceleration effects. And the acceleration effects.
Let me explain sort of like what happens in a system. So let me go back to non-linearity.
I can talk about it. It's not too complicated.
Yeah, go ahead.
So non-linearity.
As long as you don't talk about convex and concave.
Okay, so if you jump, say you jump four meters, you're going to be harmed a lot more than
four times if you jump one meter. You agree? All right. And if you definitely, if you jump
ten meters a lot more than ten times one meter, because if you jump ten meters, definitely
there's an obituary in the darkness. So there's what we call acceleration. I notice that in
finance as a trader, if the market is down one percent, say you make a hundred thousand,
the market is down ten percent, you make 20 million from acceleration payoff. So that's
what we call, let me use the word negative convexity or convexity, concavity or whatever,
or positive convexity in some cases. So there must be, then I've noticed that everything
in nature has to have those accelerated, those response. Okay. And there's an argument which
is complicated. But let's say, so in other words, if you jump four times one meter, okay,
it's a lot better than jumping zero, zero, zero, zero than four meters. You agree? All
right. So let's apply that to demand. Okay. A fragile system in demand. And there was
a part of our conversation way before people were aware of the supply chain. If you consume
a hundred one year, say toilet paper, whatever it is, okay, and then a hundred the next year,
the average is a hundred, it's not going to stress the system in the same way that if
you produce zero one year or demand zero one year, and then two hundred the next year,
that happens, demand, you have hyperinflation, you have a deflation, then hyperinflation.
All right. So that's exactly what happened with demand for anything, for bicycle parts
to whatever, demand one to zero, and then jump, okay. And of course, also there's stuff
like Peloton, demand one to a hundred, and then one to zero. So it was a lot worse than
50 and 50. So the unevenly distributed stuff, if you're fragile, you want a distribution
to be steady when you're fragile, when you're out here. You want the market to go down one
percent one day, and then one percent the other day, it's a lot better than zero and
then two percent. I think that the effect is it squares or whatever. So it's the same
thing actually in price impact in the markets. If you want to buy ten units, say ten billion
dollars of whatever, the stocks, if you buy them all now, you're definitely going to have
financial problems. You've got to move prices. But if you buy over ten days, no impact, okay.
Because ten times, you know, it's a hundred times the price change because it's in squares.
Ten times is a lot, like a hundred times one. So that's the example of non-linearity that
has to be present. And I think that's the only idea I've ever had. Everything else comes
from reading a lot of books, talking to grandmothers, and grandfathers, and uncle. So this idea
that our world, you've got to realize where the fragilities are, and it's very simple
once you understand where the vulnerabilities are based on non-linearity. So this is, and
then the idea is-
So for business school students, I just want to be, for business school students, the clearest
example of this are the efficiencies of just in time manufacturing, stuff like that. So
fragility is, in a way, a function of an illusory understanding of efficiency, right?
Yeah, the word efficiencies actually makes no sense, because I'm okay. So let me give
you a little bit of my background. I was a regular MBA person, then became a trader.
Then, after being a trader, I decided to become a mathematician. People do things backwards.
And then after that, so I did practice, and then I did a theory. Usually people do the
reverse. They study, then they, okay. So to me, a lot of things that make sense, because
I was a trader, trading complex instruments. So I did things backwards, and then I reversed
their sequence, going from practice to theory, theory to practice. You see, you do it differently.
And so that was the thing. They realized that a lot of the stuff we teach in some departments
is excellent. A lot of stuff that's very bad, because it doesn't match the nuances of reality,
okay? Like mediocre standard, extreme standard. You can't talk about probability in the same
way, with a multiplicative process, and a process like drowning in a swimming pool, or falling
from a ladder, or having a heart attack. Okay? So there are different classes of risk. So
this is sort of like my background. So come into it. So if you have for, so our, our,
we actually talked about this, because I was, for my sins, technology editor at the Harvard
Business Review back in 1986, 87, when just in time manufacturing, we felt we had to
compete with Japan at the time. And, you know, just in time manufacturing entailed our, you
know, doing away with storerooms, and having good relationships with one supplier who would
deliver just in time to your factory. So you wouldn't need a storeroom. And why have a
lot of cash reserves, because you want the money to be working for you. And it was all
under the rubric of lean manufacturing. And it was a kind of efficiency idea, which was
great, and terrifically cost effective. Yes. As long as there was no disruption. Exactly.
And, and now we learned in COVID, what did we learn? Yeah, but, but actually even before
that, the notion of efficiency to me was, is something that exists in textbooks, but doesn't
exist in research. Let's take a very simple example, mergers. They say, okay, we're going
to have a bigger firm, it's going to be more efficient on ground that you will have fewer
people in personnel department, and smaller number of cafeteria people per capita, whatever
it is, and a fewer number of trucks or whatever. Okay, so they look at the number, they say
it's going to be more efficient. But obviously it doesn't work because companies, you know,
large companies don't survive. Okay. And here in instant, you know, thought experiment,
two companies come together. Okay, they should have huge advantage that they don't have. And
papers have been since 1978 documenting the absence of gains from mergers. This is something
that's leaking somewhere. Then I figured it out when I started doing modeling on acceleration.
I realized that, you know, there's such a thing as an animal called elephant, you know,
a mammal, or a very cute and so on. There's an equivalent animal built almost the same
way, called what? A mouse. Okay. Now, why is it that we have 8 million mice in New York
that more than we ever had elephants, why? Because a mouse, I don't know, I'm not suggesting
please don't accuse me of whatever, but if you throw a mouse out of the window, it will
laugh at you. But if an elephant falls by one meter, breaks a leg, it's gone. Okay. And
one meter is tiny for an elephant. Okay. So you realize the same thing applies to corporations
because if they're squeezed into needing something, so we look at a few case studies of
corporations that had a squeeze that cost them a lot more than if they were small. And
effectively, that explains the first efficiency coming from size called economies of scale
turns out to be completely S. They're dystochastic, this economy is a scale. So there's an optimal
size. And then we look at other stuff like efficiency of supply chain. Visibly, if you're
going to be squeezed into paying up, you've got to count that in your model. Eventually
you're going to pay up. Everything's efficient. But let's say you have no chips. You're going
to go begging for chips, no? Because your whole process is stopped. You have all these
employees, you've got to feed. Okay. You have all these things, all these things to deliver.
Every day costs you a lot. So you're going to pay up for whatever you don't have. And guess
what? You know, it's going to be taken out of... So there's an equilibrium. And the
equilibrium is probably some economy of scale, not too much. Some supply chain optimization,
not too much. There's constraints as high. And then when I started looking mathematically
at optimization models, I realized that they only made sense under a set of assumptions
that completely get destroyed if you vary one variable. Okay. So I mean, and I looked at
the first thing I looked at is Ricardo model of comparative advantage. That if you assume,
you know, the original Ricardian model, Ricardian model that one country produced cloth, the
other one produced wine. But let's... But it assumed that the price of both is constant.
But what if the price is not constant? So yeah. So what if you have a problem with
Philoxera that happened after Ricardo destroying your wine crop? Okay. So all these are not
part of the model. So I think the analogy I gave you is that if I drive 500 miles an
hour in New York City, I say at 2 a.m., it's not going to be faster than 20 miles per
hour. Actually, it's not going to be faster than one mile per hour because you're guaranteed
to die. At 500 miles per hour, you're pretty much guaranteed to die. So there exists.
And then the other thing I discussed in the black swan is why is it that nature, if it
was efficient to have, you know, less stuff like, you know, why does nature give two kidneys?
And I'm sure students at Dartmouth tend to have in general two kidneys, but you don't
need two kidneys. You need only one kidney. And an economist would say, not even one.
You just go to dialysis. You're carrying all this weight for nothing. Well, there's
no storm and you're pressed out of the, this is the other gene pool, right?
So that's the perfect segue to talk about what steps you can take to be antifragile,
that is to say what things that you do to be robust, because I think that's really the
portray into the question of AI. We are able to counter the dangers of fragility. How?
Okay. Let me not be very gloomy by saying that number one, I like AI.
No, we're not in with AI yet. I'm just talking in the current situation.
The current situation of connectivity actually is doing good things. Let me put a good thing,
a good word for connectivity. Yeah, okay. Let me before. In 1973, for those of you who
were driving a large car, you know, you know what happened. In 1973, there was an Arab
oil embargo. You remember that, of course. And then the American cars in 1973, I don't
have seen pictures, they could pretty much have this conference in a car. All right,
they were very large. Okay. So it was, they were like gas guzzlers, nobody, I mean gas
was free and cars got bigger. And then there's such a thing as Las Vegas where cars were
okay. So you had room. So cars were huge. Okay. And 1973 came. Now what happened after
1973, compact cars started to show up everywhere. Okay. And the cars tried and the demand for
oil dropped to the point that the state of Texas was nearly bankrupt, but definitely
the Soviet or bankrupt. Okay. So it took like from 1973 to the early 80s for the adaptation
to take place. Okay. So that's in the 70s. Now there is, I think the Nobel Prize of, I don't
know if there's no such thing yet for the Nobel Prize for environmental studies. It should be
given to Vladimir Putin because by cutting the gas, it took Germany six months to adapt.
Okay. So he helped the cause of environmentalism because what took, what took six or seven years
of, you know, reduction in demand and adaptation and stuff like that happened in six months
because of the Russians. He thought that it's going to be, you know, like the Arab embargo
and everybody's going to suffer and the Germans are going to come to their knees to beg for
mercy and give us natural gas. We need you, you know. So God save Russia. It didn't work
because they adapted very quickly. So our world can adapt much faster than you think.
And I remember posting something on Twitter right before I bought a Tesla. All right.
I made a mistake in my life. So I posted that, that how, you know, this is great.
We have like convexity, a source of energy, free energy, you know, and stuff.
Electricity is free. And I got all these insulting things including the letter from the chief
investment officer of a major firm, how I should be ashamed of saying something like that.
And sure enough, we have much more, many more electric vehicles and much more solar power
as growing. Right. So you're coming at this on a slant. I mean, what you're saying,
what I hear you saying is that by stressing the system, you're proving the adaptability
of people within these networks and that there are certain stresses.
But that's happening faster than in the past.
That came with, you know, got good things, got bad things and now we got good things as well.
I agree. But I'm trying to set up your own insights with regard to how you create a more
robust system in advance of this kind of stress. In other words, you spoke about breakers and
storerooms and cash reserves and the things. I mean, even, I mean, one way to understand it
is like the separation of powers in the United States. The biggest danger that the founders
understood was that of a tyrant. And somehow they made something that appears less efficient.
They made it like the American government operates less efficiently than you imagine it
being able to. But the reason for doing that is because of all the breakers in a way that
they've put in to avoid the big catastrophe, which would be a tyrant. So there are ways
in which you can create a more robust system, a more robust system when you take the all-in
cost of putting in these breakers rather than just looking at the immediate inefficiency.
They are definitely, I mean, I gave a metaphor that's very easy. Years ago, they say they
had two twin sisters and they have an identical business, same revenue base, but one of them
makes $4 share, the other one makes $1 share. The one that makes $4 share doesn't pay for
insurance, doesn't have any stuff like that. And the stock market is going to love her,
but she's going to go bankrupt, who is probably one, eventually. If you look at mortality rate,
it's just like medicine. So you have an average expected life expectancy of maybe six or seven
years for these firms. But security analysts won't pick it up. The other sister makes $1
share, but she can survive, provided that her board or something doesn't try to fire her
to hire someone like the other sister. So the thing is, we don't have to go through time
series and data to figure it out. You can just look at inventory of the firms. You know what
can blow up a firm. You pretty much know what is it, debt, operational leverage, central
thing, figure out on the list. Each firm has its vulnerability. You don't do that. Why?
Because it costs money. Real owners of companies. This is why we have a survival of family-owned
companies, intergenerational, for hundreds of years in Japan and Europe, even here, because
they have skin in the game. Whereas an employee has this asymmetry. You see, you want to accumulate
as many bonuses and then send a postcard saying, I'm enjoying my retirement on a golf course.
By the way, I'm sorry about your bankruptcy. So that's the Jack Welch trade. I was going
after Jack Welch when he was like a sacrosanct. It was like going after Aquinas or someone,
you know, in circles. The guy is stuffing the company with what I call short optionality,
these things that explode. Incidentally, let me confess one thing. I made my money, retired from it,
betting on blow-ups of companies that have hidden risk. Like Fannie Mae. I wrote in the
Black Swan, Fannie Mae is sitting on a barrel of dynamite and everybody laughed at me, but
I had the last laugh because we made tons of money from the bankruptcy, from its insolvency
and then, of course, later on as funding. So I don't hide that we have skin in the game
in the sense that we bet on tail events that are not...
But you're implying that the people who ran Fannie Mae didn't.
They had no idea.
They were making their bonuses and they didn't necessarily lose anything.
No, I didn't know. They said they had 15, they counted the New York Times. I said the New York
Times as they're sitting on dynamite. When I saw their P&L, accelerating losses, providing
things, I said they're going to go bankrupt. I told the New York Times, I told the fellow
who turned to be COVID denier, Berenson, who ended with me. He showed me secret reports,
I told him they're going to go bankrupt. He said, they said public, he said, of course,
shout it. You know, I can tell a doorman, I'm going to tell people in the street, they're
going to go bust. They eventually went bust, but they countered. This is nonsense. This
guy doesn't know what he's talking about. We have 15 mathematicians. Of course, I countered,
but they didn't publish the New York Times, that it can have 15 mathematicians, 115 mathematicians,
1500 mathematicians, 15 billion mathematicians. It won't make a difference. You're still
going to go bankrupt. And sure enough, they almost went bust without the tax payer, without
the generosity of you and us tax payers. So we have a, it's not just Tiny May. Tiny
May was, to me, a model of firms like that are going to blow up. So we can express the
bank with other firms, that was that. And that was the banking crisis 2007. And that's
what people noticed me. But the blacks one was written right then. So now let's look
at the same analysis and apply it to who's going to blow up. So it's very simple. You
take a firm, you see how many suppliers they have. What odds are that in 2003, they had
18 suppliers for a product. But the accountants, over time, made them get one supplier in New
Haunt, or converge, all right, like a very large firm that I know had 15 suppliers and
now one in New Haunt. Okay, but of course they deserve what happened to them. Okay. But
because it was cheaper, but things are not cheap. But there's a middle way. What's the
halfway is, if you need supplies, make sure that all your suppliers are not in the same
basket. Okay, so. Right. All right. Diversify, it's one-on-one diversification. Okay. So.
And skin in the game. And skin in the game, of course, if you lose the other, you know,
so there's a lot of things you can do. But then, as a society as a whole, I think the
job of the government is to protect us from tail events. That's my definition of government
that sort of, some people think the government, like in the EU, should meddle with how much
energy your vacuum cleaner uses. I think that otherwise the government is there for
pandemics and things like that. Okay. That we have a reserve for oil, but we didn't have
one for chips. Right. Right. We have a, so we have to identify. Our vaccines. We didn't
have a reserve for vaccines. Oh, we didn't have, we weren't planning for this event.
That's right. And the only place, the only intelligent person, because from 2013 on,
Yanid Baryam and I went, talk to the people, tell them, listen, the pandemic is coming,
are you ready? The person, the only place where these people had a game plan that was
very precise, Singapore. And guess what? And the person retired, so it wasn't as good as
when he was there, fill something, right? He was head of civil service in Singapore.
And he had, he knew, he said, yes. And then this is what we're doing for this. And he
taught us basically, you know, we learned more from him than, than, than our argument.
So, so there are some places, but not, not the job of the government is to have contingency
plan in case of pandemic. And we know we're going to get that big one. I mean, COVID was
very bad. But it was more like a dress rehearsal for the real one. Think about it. The
antibiotic resistant strain that once it's out, you know, plus with aging of the population,
they will transmit. So, so there are things that will, you know, that, that, that, that
you've got to consider. The problem is epidemiologists, I hope I'm not offending too many
people, but epidemiologists, their models were using Gaussians who were not using, you
know, power law fails. When we wrote that the nature of physics, the physicists got it
right away. They say, how come they're not using it? So yes, there's a published article
and people were shocked, it's a completely different culture.
Well, now that, now that you've frightened me with the idea of a universal pandemic of
antibiotic resistant bacteria, I feel like I'm somehow scanting the problem by turning
to AI, which seems by comparison, by comparison, rather hypothetical event. But I do, before
we get to questions, which I hope to in like within five minutes, I just want you to try
to apply what you mean by anti fragility to a network where nodes in the network suddenly
are on steroids because of AI. Like, how can we apply this?
Let me, let me go back to COVID in a way, in a way we were lucky, COVID was a bad thing
that killed 20 some million people were very bad. But it's sort of like it was, it taught us
all right. So just assume that the big one came before COVID. Okay. So and the Internet saved us
with COVID. Just assume if we didn't have as a sequence yet COVID than the Internet versus Internet
and COVID. Okay. So, so we were, but now we're more prepared for the next one. So we don't
have a lot of selling to do, say, okay, you test at the border, you close the border, you do this,
you do this, you do this. We know the game plan. And probably for generations going to hold.
The, and, and the zoom, you know, which I mean, I'm sure you fed up with it. Okay, I am fed up with it.
He made me teach a class on zoom. For me, going to a dentist is better than teaching class on zoom.
But nevertheless, I mean, it allows us to function. So the, the, so we have things.
So antifragile, there's, there's, there's systems that have this property that without stressors,
they get weaker. That's what I noticed. Doctors call it hormesis. And I figured out the modeling of it
comes from convexity. Once you define fragility, you have the reverse of fragility. And it's the same
equation. It's a minus sign because the minus one is concave, the other is convex. So something,
so you tell yourself it's a system is antifragile, then it needs to be stressed. Okay.
Otherwise it dies. And natural systems don't get information via the New York Times.
How they get via stressors. So if you go, if you have a Mediterranean skin, I think you qualify
a Mediterranean skin, you go in the sun. All right. What happens? You tan. Okay. Why do you tan?
Your body gets a signal that this is the intensity. So it's protection for 10% more intensity.
I'm sure you have a gym here. No, you have a gym in darkness. There's a gym. You go to the gym,
you lift the 100 pounds. What happens to your body? It prepares for 110 pounds. It upregulates.
So there are a lot of things. And now it tells us that what is the converse of it? The bad news is that
if something needs stressors and doesn't get stressors, what happened to it? It weakens. You see?
So just assume that if you spend six months in bed, no stressors, no germs, nothing, no classes,
no Starbucks, no bad coffee, nothing, or you're in bed for six months. And then you get out of bed.
First of all, your bones would be weaker. And of course, you're going to first germ.
And if you're in a completely germ-free room, what's going to happen to you is probably not going to survive.
So there is this idea that you need stressors up to a point. You need some stressors.
And things upregulate. And I learned that. One thing is maybe sort of I'm trying to explain
why I'm not a good speaker. I don't want to be a good speaker. Because if you speak like this,
you have to make an effort to understand me or people. You'll remember more when I'm talking about you upregulate.
So now this sort of like...
Okay, but I still want to make it easier on them. Just a second. So apply this to AI.
I mean, we normally think... I mean, people have talked about this. You wouldn't be in the room, I suppose,
unless you were concerned to some extent with AI. Well, no, you'd be in the room to see nothing anyway.
But with AI, we have these nodes in networks that have these capabilities.
And you spoke about the various capabilities of AI at lunch today, which I want you to share with me.
But what can we do if government's responsibility is to protect us from tail events?
Yeah, I'm not worried about AI and let me start more.
I'm more worried about the pandemic and I'm vastly more worried on my list about debt.
And I don't know if you own real estate, but we had because of bad policy for the reserve zero interest rate,
we have a bubble and they're not able to manage it, keep raising a lot of debt in the system.
So to me, these are the big problems. AI is not a problem for several reasons.
Number one, I happen to have my big job is happen to do statistical modeling.
And we've been doing neural net forever. Neural net and finance and always failed.
And also with people, what do you mean by AI?
The different things, the machine learning, the LLM, which strategy PT is, and we'll focus on that in a minute.
And then we have robotics. Robotics, do you have a thermostat in your car?
As you put 68 degrees, if it's higher, it shuts off.
So we've had that forever, for a long time.
So it's not like we're just making it more advanced, but people were not afraid of thermostat.
And now suddenly the thing robots are going to take over the world.
So we've got other things to worry about before, but let me talk about chat GPT as a trader.
I learned one thing as an option trader.
And I had a saying, if you have any reason to buy a stock or an option to buy an option, don't buy it.
Why? This was already in the price.
Now, let me explain what chat GPT does, basically.
It takes all the conversation and gives you the most likely, maybe not that precise conversation,
but the most likely one that resembles it.
And the first thing I did was try to trick it, because during the day I do nothing except bicycling now
and a little bit of math in the morning, and then the rest of the time I get time to kill.
So let's strip chat GPT.
So you go to the obvious point that what does chat GPT?
It's just verbalistic, it takes words.
So you can trip it by either making it say two things that are contradictory because of verbalism,
but that's complicated.
So I did that, of course, and say, oh, I got a home run.
So let's see why chat GPT cannot run anything.
Let me tell you why.
It's a great clerk.
It cannot run.
The clerk doesn't run.
It assists.
Let me explain the thing.
The first thing is there was a...
At the Congress of Berlin, there was a bit of a war on one part in Greece and Western power.
The other one was the Ottoman Empire.
And there was a fellow called Konstantin Karateodoris, who was representing one power.
So I asked chat GPT what was the function of Konstantin Karateodoris at the Congress of Berlin,
where they had to sign a peace agreement between Greece and Western countries versus the Ottoman Empire.
Of course, it's because his name was Greek and he was an ethnic Greek that he represented Greece.
Who did he represent?
The Ottoman Empire.
Karateodori Pasha.
So you knew immediately what does it do.
It doesn't know the answer, but it gives you the most likely answer.
And that's exactly what's going to bankrupt you because that's already in the price.
I tripped it.
Another one was my village, the Battle of Amun.
My village is a Byzantine village in Lebanon.
So there was a battle that happened, according to the record, some century after the Arab invasion.
So there was a battle between the Byzantine army and the Maronite Christian sect that was pushed up the mountain.
So we asked chat GPT what happened at the Battle of Amun.
And it told you it's between the Islamic invaders and the thing because it's most likely.
So when you take the corners, how are you going to make money?
You're not going to make money with an existing idea.
That makes sense, you're not going to make money because it made sense.
A lot of people tried, they failed, and you don't hear about it because people don't talk a lot about their failure.
So that was the idea.
If you look at chat GPT, it cannot come up with a theory of relativity because it's not part of discourse.
It would actually dismiss it.
You see?
So that's why I'm not worried about it.
And you can't run anything, you're just an assistant.
It's excellent if you want to write a condolences letter.
It's always very complicated.
I have friends who are Muslims, friends who are Jewish, friends who are Catholic,
and then I have to make sure I use the right wording.
You don't say Advitam Eternam to eternal life to a Jewish condolences letter.
I learned from chat GPT, so you write one.
You see, let his memory be eternal.
So for example, chat GPT is great for that because it gives you the most likely thing that people say.
But if you want to progress, you don't progress by saying the obvious.
You don't progress, you progress only with the corner.
So I can't resist asking you, is it possible then that the great, even call it black swan, danger of chat GPT,
if what you're saying is true, that it's always sort of giving you sort of the most likely average response?
Exactly.
The mediocre, the most mediocre.
The most mediocre assistant you can ever have.
Right.
So think about it.
That's how it's by design because it reflects.
Right.
But if we become more and more and more pleased to have this assistant,
is the difficulty and maybe the danger that we are going to meet them halfway and ourselves become mediocre?
I mean, that's the thing that kind of bothers me.
I think, okay.
So we are becoming, I agree with this.
This is what I was going to talk about at lunch.
But let me come in with one word.
Have you heard of the, there's a Flaubert's dictionary of received ideas?
Yeah.
As a parody, what people would say, that's a received idea.
Usually, you know the crowd is wrong.
So it's pretty much like the dictionary of received ideas.
But let me, what happened, that I am, I have a problem.
I didn't know I was good in math because I have a, I can't count as a track very well.
I can't divide.
So I have, I have, I had a 12C, luckily.
And I became a trader with a 12C.
I became adapted.
So what happened that I'm still my 12C calculator, which incidentally I have now my iPhone 12C.
So I can't compute a tip in a restaurant without it.
All right.
So the, but it frees you up to do other things.
So become more mediocre at driving.
I used to get lost driving home.
Now, definitely without Google Maps, I get lost, you know, going around the corner.
All right.
So I'm a worse driver than in the past.
Sailors are worse navigators than they were in the town of Columbus when he has three ships
and how he can follow one another, especially at night.
All right.
And communicate.
All right.
So there were much better sailors than today, but you free up that time.
I become very mediocre.
All right.
In, in saying that I'm mediocre in what I use that machine and I'm going to be better
than other things.
Okay.
So, so this is, this is where technology can free you up to do other things.
And, but people think that chat GPT will replace people.
I think what it will do is what I learned from, from my translators.
You know that translators lie.
All right.
One of the lies is I don't, I don't use Google translate.
Never heard of it.
I don't know what it is.
So I know some translators used to translate two, three books a year in 2000 when I had
my first book translated.
And now the same translators translate seven or eight books.
How this is.
So, so Google translate is not replacing translators, but translators are using it for efficiency
to, you know, for the first cut and stuff like that.
And then of course they make sure that you text doesn't look like Google translate by,
by changing words here and there or so.
But the, so this is pretty much what will happen with when people say that in imaging
we're going to change GPT, not change GPT, that, that pattern recognition will replace
radiologists.
It probably will have fewer radiologists.
Okay.
Because they can process maybe a hundred, you know, x-rays a day versus 10.
Okay.
And, and this is where it's very useful.
Right.
There are parts of the world that don't have radiologists at all and that will, you know,
it's part of the world.
Yeah.
Because you'd have one radiologist service a lot more.
So we'll bring down the cost of medicine or make it more efficient, but it will free
up medicine to the other things, you know, like focus on headaches, for example, or maybe
curing bad humor.
Right.
That's to me is whatever I'll think that are more important.
I mean, very important, but, but completely neglected.
So if you freeze you up, like driving Google Maps, feed me up to compose maybe, you know,
other things and became worse now at composing spontaneously a condolences letter.
But I know now I have a format for, you know, what's for the optimal format.
This is for Shiite.
This is for Maronite.
This is for Greek Orthodox.
This is for, for religious Jew.
This is for secular Jew.
So I have the format.
So you see what, what, so I'm worse writer for condolences letter, but probably I have
more time to write aphorism on Twitter.
All right.
So I'll have to remember this when I write my thank you letter to you.
Okay.
We should, we should actually go to audience for questions.
Yes, sir.
Just wait for the microphone.
Someone is going to deliver a microphone to you.
I'm curious if you would comment on how you perceive the possible outcomes given the increasing
US debt and our inability to service it.
We have, I think that we're conscious of it.
I mean this country is very adaptable.
Nobody would have thought that would have 5% interest rates, 7.7% mortgages today.
Yeah.
And then we went from 2% to 7.7% mortgages.
So some countries are very adaptable.
It's the most adaptable probably country on the planet.
So there's one thing about debt that happened.
We have had some inflation that reduced debt in a way.
All right.
And then also there's a Lebanese expression.
It got a bit big before it gets smaller.
You got to get bigger before it gets smaller.
So in other words, now we realize what's going on with each problem of Congress.
And some people are realizing that the thing cannot last long and you can't keep borrowing.
The government has to have some kind of model for, to reduce that.
But there's a positive thing I would say is that the government has, because of the zero interest rate policy, has accumulated debt.
But there's a lot of, you know, that swelling of assets.
That's a lot of profits for the government because you know there's such a thing as income tax, capital gains tax.
So government has accumulated assets that people are not noticing during the bubble.
So overall I'd say that people are conscious of the problem now.
And I'm glad people are fighting in Congress.
Because on one hand you have a tension between, it's like optimization under no constraint.
So you optimize social justice.
You'd like to, but you need to have constraints.
Like you have a wallet, you know, you have a watch in your wallet.
And you can't borrow forever.
And so people are conscious of it.
And once you have the solution, it would be probably easier.
Plus we got, I think AI would do something which is increase productivity in some domains.
As we are noticing, the Google Scholar translator productivity.
So a lot of things will come that, but so it's not, we're not Japan yet.
And other countries will suffer more before we suffer.
I had a question about AI and regulation.
A number of AI innovators are going to Congress and asking for regulation,
which looks a lot like Stigler's insight that firms demand regulation to raise barriers to entry.
And of course, highly regulated firms are the most profitable firms.
Would you agree that what's happening is a Stiglerian thing where they're trying to raise barriers to entry
or is there some noble intent there?
Those clamoring for regulation are those the most threatened by AI.
I mean, I was an arbitrage trader and you know what regulation means
because you give me a country where they have a lot of regulations.
You hire three lawyers.
Okay, one lawyer is in Japan.
Japan was the most regulated financial market.
You hire a lawyer in Japan, one in London and one in New York.
Okay, and then the regulation, what does it do?
It causes arbitrage because there's some, you can't short stocks in Japan.
So you can make tons of money, whatever you have regulation,
you can load tons of money finding ways to reproduce the same product built in another way.
Like for example, you can't go short stocks in Japan.
So you buy the index.
Okay, you buy all the stocks, but you can short the index.
You have a flat book and someone wants to short a stock.
You short the stock at a huge fee.
You know, you remove one stock from your loan.
So you have met a synthetic short, for example.
So this is an elementary trade, but they're more complicated trades.
So regulations are, I'm for skin in the game, not regulations.
I'm for tort because you can't game tort.
You cause a problem, you pay for it.
Regulations usually allow, I had a fight with this guy.
He's at Princeton.
He was last chair of the Fed, trying to sell.
No, no, no.
Another fellow.
There's a fellow.
I was in Davos the only time.
Sorry.
I'm blind there.
I was in Davos.
And the fellow say, oh, it's incredible this.
How can we protect ourselves?
You know, the world I'm talking about.
An American citizen said, you make me go bust.
How can I get cash?
I'm in Switzerland.
Stuff like that.
Oh, no, I got protection.
What is it?
So, you know, FDIC insurance, they insure you for per account,
not per individual.
So you give them $20 million and they open up, I don't know,
it's 25 accounts or 50 accounts, something for you.
And then, therefore, I told them that this is unethical,
you know, because basically rich people can benefit.
He said, no, we got a lot of former regulators in our staff.
Then I started the crusade against regulation because I
realized that regulation allow regulators to later on sell
their services because they know the inside.
I mean, some regulations are necessary, but it's like
speed limits.
Some are necessary.
But torts are vastly more powerful because it can't be
game.
And torts, and that's the left-wing concept that started
with Ralph Nader.
And so, you're actually dedicated the book to Ralph Nader.
Torts are vastly more robust than regulations.
So I think with AI, you can use a tort system.
You say, you're responsible.
But basically, the regulations, people calling for regulation
with AI either don't understand anything, or they are
afraid of it because it hurts their business.
But think about it.
If we slow down AI growth in this country and the Chinese
develop AI, what happens?
We're going to have to learn Mandarin now as first language
because basically you're invaded, all right?
So you have to realize that there is a, you know, you can't
really stop research on grounds that it hurts Elon Musk's
business, okay?
Oh, it's helping Elon Musk.
Sorry?
It's helping Elon Musk, but he's got...
He wanted to regulate it first.
You scared him.
Maybe he woke up one day, thought it was bad for him.
Right.
But he also has one of the most robust AI networks going
with the self-driving cars and the neural networks.
Yeah, but this is not working.
Self-driving is not working.
There are problems.
Oh boy.
This is where...
There are some mathematical things that this...
Even if every individual car is self-driving, you see the
problem is you have to make them all.
Right.
All cars on the road got to follow the same protocol.
Right.
You know, when you see flocks of birds, they all follow the
same protocol.
Right.
So you got to...
Instead of doing it bottom-up, you got to do it top-down
for the cars.
So this is why I doubt that it's going to go very far,
except for using some things, you know, you know,
temporarily, you know, you can't have a self-driving car as
easily as you think.
If all the cars were self-driving, okay, you need to
have one unified protocol.
Right.
And to get that, you know, I think maybe your great,
great, great, great grandchildren may do something
similar of the sort.
So we have to get rid of human beings and to have
self-driving cars again.
Yes.
Wait for the mic.
Thanks.
First off, thanks so much for coming up to Hanover.
One thing that you've spoken out against before is like
reading newspapers.
I'd love to hear you expand a little bit on that.
And I guess as a follow-up, like how you suggest
staying informed.
Okay.
So the problem of information is that the anecdote is
very salient.
What?
The anecdote is very salient.
Yeah.
So when you read newspapers, you're focusing on
anecdotes.
And early on, as it relies as a trader, all these people
are talking about things that don't connect to the
importance of the events.
You see, like all these analysis, they make no sense.
All right.
So the, so I realized also that the newspaper should be
a thousand pages long on some days and one page long
on other days.
Right.
The coordinates to statistical significance.
So what happened?
Right.
Yeah.
They're the same length.
So I stopped reading papers when I became a trader.
And it's very easy because it freed up time to do other
things.
And other people reading the papers were out of business
anyway.
So, so that's the idea of the anecdote.
You see anecdotes.
You don't see them in context.
Okay.
And the same thing with the news.
But you develop tricks to only read about large deviations.
Large deviations are more, more explainable with
something.
But the market, they tell you, oh, the market went up
10 points, tiny, based on conversations with this and
this.
And as I showed in the black swan, they said, one market
up on September capture.
And then later in the afternoon went down.
Long market down on.
So down capture.
I mean, they look at.
So pretty much wasting your time.
And I had this algorithm.
If you only cure the newspapers, spend some time
reading the previous year's newspapers.
And then you realize how silly it was to read that
newspaper.
You know.
So how much time you wasted.
And then you can pre-up your time to read other stuff like
articles by Professor Abishai, for example.
Even in New York, I said, at that time, I said, don't
read that.
If you're going to read the newspaper, read the weekly
one.
And now I think you should really read the yearly
newspaper.
But the news get to you organically.
If there's something going on, then you know to look
for the news.
You're not being supplied with the news.
Yes.
Sorry.
Hi.
So the first thing you said about AI is that you're not
worried because we've had these sorts of things for a
long time, like the thermostat automatically adjusts.
But it sort of reminds me of Dr. Phil's anecdote of the
swimming pool.
And the thing which worries me about AI is the possibility
of recursive self-improvement.
And I think that this is a good example of an accelerating
tail event where for a long time, things seem stable and
normal.
But once you pass a threshold where AIs can recursively
self-improve, things can get out of hand very quickly.
And they are something worth worrying about even though
we've had swimming pools for a long time.
Yeah.
We can worry about, I mean, there are things to worry
about, like recursive self-improvement where it starts
learning from itself.
And then the size, you know, you need to have a lot of
things going wrong for it to start learning from
itself and then spontaneously and then running the
world.
I think the reverse actually is happening with AI.
The language model does that progressively.
It's actually the reverse is that it's progressive self
degradation.
And let me tell you how it happens is that you know when
you use chat GDP, it's calibrated to some information
up, say, the 2021.
And now you use it and you populate the web with
information based on what you got from chat GDP.
And then guess what chat GDP is learning from itself.
So it's more likely.
So the counter to that is I'm more worried about a
self-licking lollipop.
But basically it's, it is recursive in the opposite
direction.
It's self degradation.
It's like the, so this is what I'd be worried about
was a lot of AI models.
So you put that so much better than I did.
Does that satisfy you?
I'm not sure.
I mean, it's definitely a concern AI is training on
their own data.
But I think that within these labs like open AI, the
thing that they understand the most is AI engineering.
The very first thing that they're testing these models
trying to get them to do is to help them with their work.
So I do think that there is still a capacity for
recursive self improvement.
Yeah.
So you'd have evolution.
You'd have some system of self-improve at the expense
of others and stuff like that.
I mean, this, this, we have bigger problems ahead of
time, namely a pandemic.
We have things how to handle a pandemic debt.
We have the fact that zero interest rates destroyed
financial knowledge for half a generation, 15 years,
16 years, generation of trainees in finance.
So we have some sort of lady has a question.
Yeah.
Kids on TikTok too.
Yes.
Go ahead.
I usually, you know, when you allocate, of course you
have ladies, but then also if you don't think people who
don't have hair.
Hi.
Thanks.
Wow.
When you say that.
Thanks for coming here to Dartmouth.
During the Arab Spring, I kind of realized that that was
maybe the last time we could ever trust video footage from
a scene where things were really happening and now it's
really, really here.
AI can create videos, not only pictures, but live videos
from a single photograph.
I think it's going to make everybody a lot more skeptical,
which may be a good thing, but what do you think about that?
Okay.
So this is a great thing because I wanted to discuss it
today and at lunch, I told you what I was going to say.
The people have the feeling that this information is something
new that came from social media.
Okay.
But you got to realize the French Revolution, you know, the
story of the stories of Marie Antoinette.
There were a complete smirk campaign with all fake news and
they're produced in London and called Libelles.
Actually, the word Libell I think is generated from that
where people would be, and they could sue anyone in London
because they had freedom in London and harming the French
was a good thing.
Of course, they would print it in London, these pamphlets,
and crossing, crossed on Fisherman's boats, right,
and then supplying all kind of fake news.
So we have a long history of fake news and how we handle
fake news in the past.
And of course, there's a counter to fake news which is,
you know, the fact, I mean, I, for example, like to bust stuff
and we have a mechanism to bust stuff.
Even Twitter has it.
It tells you that this is not true.
And during COVID, people are producing all kind of fake
statistical tricks that it's easier to bust now than in the
past.
And you know the protocol of stages of science, right?
That's the fake news, right?
The produce at a time that the protocol of stages of design
was the pamphlet produced during the Tsarist era.
Actually, the Russians were experts at it.
They had the produced en masse, you know,
they produced the protocol of stages of design,
saying that the Jews wanted to take over the world.
Exactly the same language you hear now about Soros
and a bunch of people, the World Economic Forum,
trying to program you with vaccines so they can, you know,
own the world.
Well, for us, fake news is the book of Luke, you know.
So anyway, so we have had fake news about historically.
I mean, there's even fake news in the Talmud.
All that.
I don't know about Jesus being the son of a Roman soldier
called Pantera.
Oh, yes.
Yeah, Pantera.
That's right.
So Yahushua bin Pantera.
That was it.
So there's a lot of fake news.
So historically, so thanks for your questions.
It's a great question.
Can we trust stuff on the web?
And I think that we have an antidote we didn't have in the
past.
You cannot believe how many people in Egypt believe in today
in the protocol of Satan's design.
Whereas if you put the fake news on Twitter,
you're going to have people countering it.
And these people develop authority naturally because they
spend their time countering it.
I never expected that thanks to COVID,
I reached millions of subscribers on Twitter.
And during COVID, the fellow called me up and said,
listen, I'm going to tell you one thing.
I don't like your style.
I think you're arrogant and rude.
OK.
But I'm going to tell you one thing.
The New York Times, they're boring, polite,
boring, and so on.
And people know that if you attack the fake news,
OK, it will have more impact.
I still said, I don't like your style.
I've confirmed, but I need you.
So he likes my style, visibly.
So I play a role, for example, against fake news.
And I tell you, there's this nonsense that you need,
against PS, you need a thousand times more effort
to remove the SN to put it in.
It's not true.
You can, like, we don't, I don't believe,
the things correct themselves very quickly.
Last question.
Yes, sir.
How do you get more skin in the game
for civil servants, politicians, and CEOs?
OK.
Politicians should never.
Do you want to add to that?
Yes.
I told the educational institutions
where there's no stock options or things like that.
OK.
The first thing, skin in the game, OK, for politicians,
but first of all, you should have limited,
you should have decentralization.
That's some of the problem.
Because if you give more municipal power,
people live in a community.
So they already have more naturalistic skin in the game.
That's how Switzerland works.
And then term limits.
OK.
So term limits, definitely.
So nobody, you know, they also remove some wedge
between people who become professional politicians
versus normal human being.
And so this is how we can work.
And also, I think polarization, it's not popular to believe
that polarization is good because I like politicians
to hate one another.
Because then the cast, they can't become a cast that runs us
by having fake, like in Lebanon.
In Lebanon, they love one another secretly.
So they became a cast, you know, and then they start,
like in Congress, they give themselves perks, for example.
But if they hate one another, you know,
these things become more difficult.
We're talking, and I, about the idea of collaboration
doesn't work as well as competition
and adversarial collaboration.
So this is where, you know, I think polarization is helping.
But for politicians, the only thing to do is term limit.
And then the second question for educational universities,
I think we have a problem with student debt.
And basically, you know, I'm a professor,
and I say openly in the institution that there are a lot of,
the real estate developers made a lot of money.
So student debt should not be the responsibility of society,
but those who made money from it.
So institution, if you make it accountable for student debt
after a while somehow, then they would probably make,
there'd be a chain, the real culprits are,
you know, the culprits are real estate developers.
That's where the large money went there,
and the large money went on a fat administration
with multiplication of administrative positions,
like someone responsible for winter entertainment,
someone responsible for improving your life.
Like, I get this email from the well-being program at NYU.
What the hell do I need the well-being program from NYU?
Buy it from the market.
So you realize when there's money, they spend it.
So it would make it more efficient,
because the cost of education, when you look at Germany,
the cost of education is something like one order of magnitude less
to produce the same than the United States.
You want the word of the difference.
The difference is partly real estate, partly administration,
not so much faculty.
By the way, if you're afraid of faculty liking each other,
don't worry.
Thank you, Nassim.
It's always such a pleasure to hear you
to think about what you think about,
and such a pleasure that you drove all the way up to Dartmouth.
I mean, the leaves are great, but still.
I mean, I'm really very grateful.
We're all very grateful that you came.
This is a great campus, and don't tell anybody
it was a great retirement place.
I know, I know.
Thank you.
Thank you.
So thanks.
