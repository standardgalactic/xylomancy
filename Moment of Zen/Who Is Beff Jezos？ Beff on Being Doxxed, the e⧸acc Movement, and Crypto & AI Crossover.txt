Hey everyone, today on Moment of Zen, we chat with Beth Jayzos, the co-founder of the EAC
movement, or Effective Accelerationism, who was doxxed on Friday night by Forbes reporters.
We'll link to some articles about it below.
Up ahead, we get the inside story from Beth, whose real name is Guillaume Verdome.
We also discuss anonymity, the media, and the role of journalism in our society.
Also joining the conversation is Bayes Lord, Beth's EAC co-founder, who remains anonymous,
and Nathan LeBenz, who hosts the Cognitive Revolution podcast.
Quick disclaimer, and then we'll get to the show.
I'm an investor in XTropic, the stealth AI hardware startup that Guillaume founded.
Here's Moment of Zen with Beth.
Yo, yo.
What do we got going on here, Steve Jobs?
Well, you know, I got to switch up the look, keep the commenters chirping.
Yeah.
Yeah.
A lot of people hop in.
So, Somali Pirate to, you know, Confident Design Partner, I don't know, like what's going
on here.
Yeah, exactly.
Just testing it out.
Did you get a better webcam, too?
No.
Oh, okay.
But, but I'm going to.
Is the Binance topic like a five-minute topic?
I mean, I can give an update on it if you want.
Yeah.
Well, I mean, it's a little bit old news at this point, but we had a major settlement
that Binance, the CEO of Binance CZ, who, you know, kind of kicked off the SBF issue
and is big of a name in crypto.
I mean, it's CZ, SBF, and Brian Armstrong were the three big names during the last cycle.
And SBF has now been convicted.
And CZ, there were always kind of rumors that there was like a big DOJ investigation.
Then there was an SEC suit that happened this year.
But in terms of the real criminal stuff, that had always been swirling and a lot of allegations
around sanctions.
And remember, sanctions are a U.S. tool because the world is run on dollars.
So the U.S. can basically say, hey, you can't send dollars or anything, crypto, to these
specific countries or individuals, and the allegations were that Binance was facilitating
that.
Now, I actually don't even know the details specifically, whether or not they did, to
what extent.
But what came out was, and the settlement was CZ is stepping back as CEO.
And I think the record finds for sanctions have been as a result of violating sanctions
with Iran.
I want to say it was like BNP Paribas, which is a French bank, paid something like $8 billion,
or maybe it was HSBC, I forget.
And then I think another big set of fines, HSBC might have been the drug cartels, but
basically it's like Iran, which is a geopolitical issue, and the drug cartels, if you do money
laundering, you pay major fines, and there's criminal liability.
So the settlement was, he steps back, Binance can still exist, which I'm actually surprised.
I think he's paying something on the order of like a $50 million fine.
And the thing I didn't quite get in the first day of the news, but then it turned out later
kind of seemed to bubble up is he's still in the U.S., I think, and actually may have
to do some jail time, which is like a pretty big deal.
Because he's voluntarily given it up.
So you know, if he's willing to step back, pay $4 billion fine, $50 million personally,
and potentially do jail time in the U.S., that means they were going to throw a huge amount
of the whole book at him.
But what's interesting is the SEC is not done with their case, which I think is a civil case.
So that will still be another big hit on Binance, if they have to settle it.
Obviously, you don't have the founder anymore.
If he has to do jail time, it can't even be, you know, indirectly influencing.
And then I would imagine the European Union and every other jurisdiction that's kind of
within the global U.S. sphere is going to say, well, we don't want to look like we were not
tough on these guys.
And so these guys are going to be paying a lot of money.
So I'm curious to see if they end up existing, you know, five years from now.
I mean, five years in crypto is a long time, but basically Binance popped up during the
call it 2017 era when there was another exchange called PoloniEx, which was actually based in
the U.S., but they were only serving international customers in theory, that they knocked PoloniEx
off the top spot and never kind of looked back, and SBF was gunning to try to be the
next Binance.
So what's left in the wake of this is, you know, Coinbase, which I think got a lot of
ridicule from, you know, the mid-wit, thin Twitter, like Buko Capital and all these like
kind of a non-accounts that are too afraid to put their name next to an account so that
they like to make fun of, you know, entrepreneurs on the sidelines when obviously everything
corrected last year, they were all like Coinbase is not, you know, like a real business.
I mean, Buko Capital was calling Coinbase a cancer as of last week because crypto prices
are pumping.
But Coinbase actually is the only one that's been following the law and didn't have a crazy
risk program.
So FTX disappears, Binance disappears, Gemini basically was doing a bunch of shady stuff
and blew up as a result of that.
What was the other one?
BlockFi, right?
Like there's a pretty famous meme.
I like pump, but pump kind of was like pumping them and it's like to the moon and like this
and obviously that was fraudulent.
And so it turns out like Coinbase is the only one that was legit.
And yes, like that's been the MO of the company the whole time.
And so finally with the government cleaning up the space, it's like now Coinbase is sitting,
you know, Coinbase, Bitcoin just crossed 40,000 and Coinbase is basically the only exchange
with like meaningful fiat rails and customer base.
I mean, there are overseas exchanges that will take place in Binance, but it's a huge
vindication, I think for Brian Armstrong, who's taken a lot of arrows for a lot of different
things.
I'm also happy about the share price personally.
Yeah, totally.
You're heavily incentivized.
Yeah, let's be clear.
I'm extremely biased here, but what I would say is like, if you want me to give you like
the counterpoint, I do think Binance pushed the industry forward.
Modulo put the illegal stuff off the side.
They never had a major hack, which is usually how a lot of these exchanges go down.
And to the degree that I understand it as a result of the DOJ, it wasn't misappropriating
customer funds, right?
So now the SEC may come and say something different, but big difference between SPF, which was
actual fraud, right?
Like he was taking customer funds, which you're not supposed to touch and was using it to
pay Tom Brady and donate to political campaigns.
So I think Binance was an honest actor as it relates to customers.
I think they just seems like they were a little fast and loose with the international sanctions
regime.
Perfect timing, fast and loose with the international sanctions regime and Antonio hops on to the
call.
Who sanctions?
What regime?
Yeah, that's actually a good one.
We know a few people who would like to argue that US sanctions are not valid, but the reality
is if you live in a dollar denominated world, you got to pay attention to those sanctions
because you can go to jail if you violate them.
We were talking about Binance.
Aha.
Where is the man of the hour?
He's having trouble getting in.
I've never seen this issue before.
Maybe he's using some like futuristic quantum web browser that doesn't have support for
lowly riverside web RTC.
Or Emily Baker White put some weird malware that she used to like sample his voice to
out him and it's still like on the machine.
Did they add him on our podcast?
Are you sure that this wasn't actually MBS in collaboration with Forbes?
Right?
Hey, Beth, how are you?
You guys, you guys know the reference, right?
Um, no, what?
MBS?
It's still not confirmed and I think it's probably fake, but it's also maybe real.
Bezos' marriage got broken up as a result of MBS sending spyware in WhatsApp to Jeff.
And the text messages in question were, hi, Jeff, how are you?
This is MBS.
Well, it was probably good for him and bad for American cities everywhere, but yeah,
exactly got divorced.
I don't know.
Lauren Sanchez, she's pretty happy, right?
And she's now on the, on the front of the yacht that they just finished.
Because sailing in front of you is such a blue collar thing, right?
What is, he's not sailing.
He's motoring.
Motoring is totally different.
Doesn't he have a sailboat?
Doesn't, isn't it a big sailing yacht?
I don't know.
The deck photos I've seen are clearly a large motor yacht type thing.
Someone, we should put it in the YouTube comments, the pictures of Jeff Bezos,
but my understanding is that there are sales, but it could be.
You guys, you guys have the most interesting guests on the, on the podcast.
The one time I can't make it.
Oh, don't worry.
Oh, Dominic Cummings.
Yeah.
Yeah.
He sounded super pumped to like, rejigger San Francisco, I have to say, which was
interesting.
Yeah.
I don't know.
I think, I think saving SF is kind of cope.
You think it's unsavable?
I mean, are you running there?
Sir.
Hey everyone.
Welcome to face Twitter.
Phase doxxed world.
Well, hello world.
I see the, I think the Eigen function in your quantum computer has clapped into the state
in which you can join the Riverside and some other worlds you were in fact still struggling,
but Schrodinger's, Schrodinger's Riverside episode.
Yeah.
Yeah.
Yeah.
We need to, we need to upgrade the quantum computers to, to use this wonderful app.
Speaking of which, what is that, that menacing blinking box behind you over your right shoulder?
That's just, don't worry about that.
You know, just don't worry about that.
Yeah.
No, I'm, I'm in EAC HQ or Extropic HQ.
I've got our banner in the back and of course I've got some diet, Dr Pepper and some ketones
back there.
Very memetic.
But are we, I guess we're recording right now.
We're recording.
We're launching it.
Okay.
Wonderful.
Eric doesn't read you your Miranda rights.
You just go right into it.
It's like a cold.
Okay.
Got it.
Let's go.
Yeah.
Well, super happy to be here.
It definitely feels weird.
It definitely feels very weird.
You know, it's been kind of a compartmentalized part of my life.
You know, felt like a video game on my phone, more or less, right?
Like having an alternative Twitter and having a very professional life day to day, you would
never guess that I'm back from just like day to day interactions, frankly.
And now the two have kind of bled into one another and they are one.
And so I'm still pricing that in mentally, frankly.
So it's been an interesting couple of days.
A lot of inbound more DMs I can ever count.
And yeah, I mean, it's been a very surprising reaction.
Well, I guess not that surprising.
I guess like, you know, tech Twitter kind of kind of hates the establishment media at
this point and, you know, came to my defense, which, which felt felt quite good.
But, you know, I'm happy to go into any part of it, you know, how it went down.
You know, the why I started Beth anonymity and anything, the startup.
Let me know how you want to structure this.
This. Yeah.
So can we start with the sorted details of how they figured it out and what voice they
sampled and how that whole sorted tail played out?
Yeah.
I mean, there was a couple instances where there's reporters that, you know, think they
have my docs and I'm just like, you know, you can't, you can't dox people, you know,
I do not want you to do this.
And usually that kind of kills the story to some extent, but, you know, it's kind of been,
you know, I've gone, I've been in the SF social scene in person.
I know a bunch of investors, for example, they, some of them know some of them have
correlated the two.
But obviously I spent a bunch of time in Twitter spaces.
I have some online lectures from my days in grad school and quantum computing.
And really that's basically what they've, what they've correlated.
They, they, they use some, I don't know, I call it CIA technology as a joke, but, you
know, they use some government grade technology to identify my voice.
You know, just because I have a 50 K follower account that speaks truth to power.
I guess, I guess it tells you that, you know, we're doing something right and that some
people in the establishment, you know, want to have leverage over the leader of the grassroots
movement that, you know, is for freedom and, and, and against top down control, which is
very scary because that's what they like.
Right.
So.
Hey, we'll continue our interview in a moment after a word from our sponsors.
Real quick, what's the easiest choice you can make?
Taking the window instead of the middle seat, outsourcing business tasks that you absolutely
hate.
What about selling with Shopify?
Shopify is the global commerce platform that helps you sell at every stage of your business.
Shopify powers 10% of all e-commerce in the U.S.
And Shopify is the global force behind Allbirds, Rothy's and Brooklyn and millions of other
entrepreneurs of every size across 175 countries.
Whether you're selling security systems or marketing memory modules, Shopify helps you
sell everywhere from their all-in-one e-commerce platform to their in-person POS system.
Wherever and whatever you're selling, Shopify's got you covered.
I've used it in the past at the companies I've founded.
And when we launch Merch here at Turpentine, Shopify will be our go-to.
Shopify helps turn browsers into buyers with the internet's best converting checkout up
to 36% better compared to other leading commerce platforms.
And Shopify helps you sell more with less effort thanks to Shopify magic, your AI powered
All-Star.
With Shopify magic, whip up captivating content that converts from blog posts to product descriptions.
Generate instant FAQ answers.
Pick the perfect email send time.
Plus, Shopify magic is free for every Shopify seller.
Businesses that grow grow with Shopify.
Sign up for a $1 per month trial period at Shopify.com slash Moment of Zen.
Go to Shopify.com slash Moment of Zen now to grow your business no matter what stage you're in.
Shopify.com slash Moment of Zen.
You spoke truth to power and now they're going to try to speak power to truth, so to speak.
But I'm curious, someone must have, they must have been tipped off because they didn't do an all against all voice sample.
They started after this pairwise interaction, right?
Because there was nothing online that would have suggested it.
And then they confirmed it via that, I imagine.
Yeah.
So they must have like asked around, you know, I mean, it's kind of like a, people know other people's docs is right?
There's kind of Twitter parties in person and people go by their alternative name.
So they know your face and eventually they correlate things.
But there's kind of a, yeah, there's an unwritten rule of like, you don't like talk to reporters.
You don't share people's docs with other consent.
I'm sure some people, you know, broke that rule.
But, you know, I don't know what drove them to really break the story now.
I think there were some latent variables there.
But yeah, essentially, I think it was on Thursday.
I get a text from some of my investors.
They identified some of my investors.
So this podcast is going to drop after we announced the round.
So I'll just mention investors.
But yes, so some of our big investors get a text like, hey, I think this, you know, over this first reporter, I think it was Conrad has started correlating your identity with Beth.
They didn't correlate all the company because we had a, you know, I had a company change the name.
Now we're extropic.
They hadn't correlated everything perfectly.
But then the censor fused across reporters internally.
So they didn't have enough to ship it on Thursday.
But then on Friday, a different reporter, Emily joined force, the filings, the track name changes.
They went to my personal Facebook to, you know, to identify a photo I shared like on my friend, you know, friends only Instagram of the party, you know, when we were on stage with Grimes and stuff like that.
And they correlated everything.
Right. And so they just had me in this sort of checkmate, like we have this, this, this, this, this, this talk to us, we're going to ship it.
And I was like, all right, I got to get in front of this, right?
Again, you know, I've been doing this deep tech startup for nearly a year and a half.
And, you know, as the bio says, I come from Google X, you know, we're taught to be very secretive about what we do because in deep tech, that's kind of the, the MO.
And, you know, we want to be secretive for longer.
But for all sorts of reasons, including national security interest reasons, right, like our technology is pretty out there.
And it kind of forced our hand, right, like it correlated all identities.
And also, it also kind of doxed the fact that I had founded the startup because I was kind of, I hadn't identified that on my main account.
So for me, it was kind of a moment of panic, because, you know, I want to do what's right for my company, right?
I've been working really hard on this company.
We were planning announcements in a couple months from now.
And now we have to rush everything, right?
Which is, which is not great.
But what I end up doing, getting on the phone, getting in from the story, I already knew exactly like that's the thing with reporters, like, they're so low entropy, they are all in the same typical subspace of stories.
You can predict exactly what they're going to write just from the prior that they're trying to get you.
And so I just disarmed every typical attack they would try to do on EAC trying to have second or third order guilt by association to some idea that's a derivative and another idea and neutralize that essentially entirely.
I see we have Bayes Lord joining.
There you go.
What's up?
What's up, Bayes?
Can you guys hear me?
What's up?
Yeah, yeah, yeah, we can.
Awesome.
Oh, we have Nathan as well.
Oh, let's get.
All right.
Here we go.
What's up?
What's up guys?
What's up?
What's up?
Yeah, good to see you.
Good to see you.
I guess now with real names in my case.
So yeah.
So yeah, it's been an interesting, you know, I guess 48 hours dealing with this.
I think overall, I mean, we can get into why I was an on for various reasons.
But overall, it seems like it was positive to the point that where some are like have a conspiracy theory that this was planted.
But anyway, I had that theory, Guillaume.
I thought I thought we're all getting conned and you're actually dropping this because that's the question.
Do you think you would raise on a higher or lower valuation now than you did this round?
I would bet the valuation grow up actually.
Definitely higher.
Yeah, exactly.
Right.
But I mean, I didn't, I want to raise around, you know, raise around just uncorrelated.
I didn't necessarily initially disclose to my investors.
I didn't want that to be part of the price or anything like that.
I didn't know where it would go.
Right.
I didn't want to correlate the two identities.
It was really like orthogonal.
And now my hand was forced to correlate the two and own it.
And so I got in front of it.
And of course, I'm going to harness any hand and dealt.
I'm just, that's what you're supposed to do.
Right.
And now, now we've harnessed it, you know, pretty well.
I would say we'll see how it plays out, of course.
And now there's this conspiracy that it was planted.
But, you know, in my case, again, I just wanted to control the narrative.
I knew the story is going to be really bad if I didn't get on the phone and, you know, I actually, I wanted to stall them.
I want to give them enough content so that we had a couple more hours.
We adjusted our website to have a pseudo launch the day of.
So, you know, shout out to the team for being so adaptive.
And, and, you know, as of, as of the moment of airing this podcast, we'll probably have announced the round on for, for extrapics.
So we rushed that over the weekend.
So yeah, definitely not plant.
But at the same time, it was always sort of a trap, right?
In game theory, you want to make it like you want to make sure that like the incentive was to not dox me, right?
For most people, because they knew that if they did dox me, now I could go on these podcasts with my real face with my credentials.
I could talk to potentially politicians and I have credentials that have some, some firepower and now more of a problem.
So they kind of messed up.
It's their fault, really.
It was a trap to some extent, but, you know, I tried my best to, you know, stay in on, but, you know, again, voice identification technology.
I'm not going to use a voice changer on Twitter spaces like every day.
Are you kidding me?
Like I'm not going to do that.
And I would imagine maybe the first podcast we did, they use that voice and correlated it with my YouTube lectures.
But it's probably how they got me.
Yep.
Can I still call you, Beth?
Sure, that's easier.
Gil or Beth, Gil is like the Americanized version of Guillaume, very French, French Canadian.
So you got me.
Super simple question.
Did the reporter journalist, whatever I'm going to call this person, did they give you a rationale why they thought it was a moral imperative to dox you?
I think there was the keyword that was like set off alarm bells for me was public interest.
And, you know, I had just crossed 50k followers.
And, you know, because the, because the law is you can't dox people unless you're a public figure.
Right.
And I guess I crossed into, I guess there's a threshold, right?
So is it 50k?
Apparently it's 50k flat, right?
But to me, it's like, okay, if they think they, you know, if they think it's of public interest and they're going to go with it, they're probably going to go with it.
And so I'm kind of screwed here.
I got to make, you know, I got to make a move.
So wait, is that, is that the journal group chat decides when you become public interest?
Or do we like, like, I'm very curious like how they rational, like, because to me that if you want to be anonymous, you should be able to be anonymous and doxing you.
What gives them the right?
Because, because if I was to go put the, I don't know, the address of that reporter online, and maybe now we're arguing over whether or not an address is too far.
Like what point is too far?
And then who gets to decide?
That's my question.
And I don't think anyone has given an answer outside of I'm a journalist, so I have a special badge.
You used to have blue checks now that don't.
And then they get to decide who can be a non versus not.
But if you were to do it to them, that's, that's harassment, right?
Right.
Well, I mean, to me, I was, you know, mostly focused eyes on the ball, you know, I have to my prime responsibilities to my company.
And I was just concerned, like, hey, we're, you know, getting announced, we have to announce and get our stuff together, you know, without preparation, without heads up, only a few hours.
So, you know, it seems like we were, it really seems like we planned this, but we truly didn't.
So, but I'm just glad we adapted given the circumstances.
But yeah, overall, I think like, I mean, this was clearly wrong, what they did.
And, you know, I, you know, there's not that much to have leverage over me.
It's like, okay, cool. I used to, you know, work in quantum computing and then have, you know, a normal ish background.
But, you know, maybe some other people that are trying to speak truth to power and have their voices heard and want to use anonymity as a tool to speak truth to power.
You know, because there's a sort of power asymmetry, so you kind of equalize that when you're an on.
They can't, they can't do that anymore, right, if they fear getting doxxed.
And so it's kind of like, they want to make an example out of me, right.
And I mean, I think there was, I think there was a congresswoman at a conference, a defense conference that explicitly named out EAC as a sort of dangerous movement that needs to be suppressed with AI.
That's the tweet. I'm not sure if it's correct. I have still have to watch that clip.
But to me, that sounds very dystopian.
Like our whole movement is about freedom of information, freedom of speech, freedom of thought, freedom of compute.
It's very simple. And the fact that that was deemed dangerous enough or I don't know, like to want to suppress and provide the public leverage over me.
I don't know. That's a huge red flag for me.
I think that we were becoming a voice that was going to be a problem for the executive order.
And there are very special interests behind that executive order.
And they wanted to, you know, send me a warning shot, I guess that is my theory.
But one thing I couldn't understand, and maybe, Beth, I just haven't read all your tweets, I couldn't understand.
You obviously have a very distinguished academic background.
In fact, I was reading your quantum tensor flow paper on the way in ages ago.
I worked in like experimental quantum computing like 15 years ago back when it was like a total infancy.
And I knew a lot of the theorists back then, like Michael Nielsen and I actually dated you.
Back in the early days of computing, but obviously wasn't really smart enough to continue.
But in any case, I was reading it with a lot of pleasure.
And it's odd that they would consider this a bad thing.
It's obviously given a lot of intellectual credibility to EAC movement.
Like your background is pretty good, right?
Like it's pretty distinguished.
Like you've done a lot, right?
And I, you know, a lot of co-authors.
And it's like, that's why I thought the conspiracy, and I don't really believe it to be clear.
But I thought maybe he actually like actually provoked Forbes to do this because this is like a brilliant thing.
Like you bring actually so much positive social capital to the movement.
You come off as like this edgy, you know, poster who kind of had, you know, was pulling the world's tail.
It's like, what's the downside to this?
Like, I don't understand. Yeah.
Yeah, for me, I can let you know why I was anonymous.
I mean, originally I was at Google X working on some pretty secretive technologies.
I had access to, you know, the top of the food chain there.
So I, you know, I couldn't necessarily tweet anything like political and stuff like that.
My tweets were watched, which is normal.
But, you know, I wanted to have just a separate account where I can really let myself self go kind of like offload.
Thoughts and also I reached a point in quantum computing where I was respected enough that people would cheer me on or they approve of my ideas or whatever.
Oh, so smart, whatever.
And that was kind of like kind of annoying me that like, do they like my ideas or do they just want a job or something?
And I just wanted to put my ideas in the arena, right?
It's like, I just wanted people to value my ideas for their own, not look at credentials, not like weigh my opinions.
Dependent on status.
I just wanted my ideas to be evaluated on their own.
And to me, like growing a movement and having ideas resonate from scratch uncorrelated from my original identity.
Like, I mean, of course that felt like, you know, it felt like New Game Plus as we say in video games, right?
You restart the video game from scratch, but you have kind of all your intellect and memory and your gear, but you're trying to rank up again.
So I started from scratch and account with like no followers and grew it to 50K before.
Now, there's a stat boost from the status signals of credentials.
I personally very much hate credentialism.
I think I would have been an entrepreneur five years earlier if it wasn't for credentialism, especially in deep tech.
I got very frustrated when I tried to do a startup at 25 and, you know, I would get like, who are you?
And, you know, I just went through big tech, the gauntlet of grad school and big tech to prove myself and prove to others that I can do things so that I can raise the capital to realize the visions I had.
And so, you know, I've always, I think base is on the same page here, you know, we always wanted sort of like EAs is all about like gatekeeping, gaslighting, status signaling, at least to us from our perspective.
And, you know, IAC was about kind of bottom up.
Everybody has access to opportunity to build no gatekeeping, no sort of status signaling.
It's all about building, right?
And we want to maintain that.
And I think that, like, I was afraid that if I, you know, used any sort of credits that would dissuade people, you know, from participating or feeling like they can participate because the thing is everybody starts somewhere.
And I was once, you know, that kid that was really smart, had a lot of ambition, but didn't have the credits.
I was just straight out of school and nobody gave me a chance.
And I want, you know, the next, you know, genius to be able to, you know, start building their dreams right away.
And I just personally very much hate gatekeeping, even though nowadays I've gone through the gauntlet, I've paid my dues.
Now a lot of doors are open for me.
But, you know, I'm just trying to kind of pay it forward in a way that, you know, my younger self would be appreciative.
So really that's why I was anonymous.
I just wanted to get, you know, get my ideas evaluated in the arena in an uncorrelated fashion from my credentials.
Hey, we'll continue our interview in a moment after a word from our sponsors.
Compliance doesn't have to be complicated.
In fact, with Vanta, it can be super simple.
Trusted by over 5,000 fast-growing companies like Chili Piper, Patch, Gusto, and Juniper,
Vanta automates the pricey time-consuming process of prepping for SOC2, ISO 2701, HIPAA, and more.
With Vanta, you can save up to 400 hours and 85% of costs.
Vanta scales with your business, helping you successfully enter new markets, land bigger deals, and earn customer loyalty.
And bonus, our moment of Zen listeners get $1,000 off Vanta.
Just go to Vanta.com slash Zen.
That's V-A-N-T-A dot com slash Z-E-N.
I have a quick question on bootstrapping your account, if you're willing to share.
You know, I know a bunch of people who are like, I wish I could do it in a non-account, but I feel like just getting it from zero to something is just such a, you know,
especially if they have already an audience on their main, but they feel like as their main grows, they can say less and less and they have to kind of stay within whatever box.
And so I'm curious, how long did you kind of toil away at this new persona before you felt like you were starting to make some traction?
I think like I had a first account, I got it to 6K, and then it got banned on old Twitter, pre-Elon Twitter, where I got locked out for saying COVID came from a lab, you know, which turned out to be true, right?
So the old regime got def 1.0.
And so I had to restart my account.
Basically, yeah, 18 months ago, start from scratch, those demoralizing, but I knew the recipe.
There's a formula, right?
You go on Teapot, which is much higher engagement, just the people are just more online, and you reply to the big accounts, you try to get them to reply, maybe save something provocative.
And then, you know, you can just do Twitter Spaces and, you know, people follow each other on Twitter Spaces because you have a meaningful conversation of like one hour or something, and then you follow each other.
And so you could bootstrap, get to 100, 500, a thousand, and so on from there.
Yeah, I mean, for me, it was really discovering a community, discovering people like Bayes Lord, you know, that I really resonated with intellectually and can have like meaningful conversations.
At the time I was working for Big Tech remotely from Canada, I was extremely bored.
I was like starved to have a sort of tech community to have like good intellectual discussions.
So like Twitter Spaces and this part of Twitter, as it's called, was sort of ideal.
It was like, oh my God, I found my people.
And, you know, nowadays it's kind of condensating and physically in the physical world and SF primarily.
But, you know, to me, it was kind of seeking a sense of community.
And, you know, it's late night, you're in a Twitter space, you're talking about the meaning of life.
Where do we come from? Where are we going? You know, it's like 4am or something after a long day of work.
And you just have these sort of like fireside, you know, it feels very primally correct.
I don't know, it's like you just tell stories and you communicate verbally and that's really how it started.
I'm at Bayes and we'd have these late night Twitter Spaces about the meaning of it all and where it's all going.
And at some point people were like, man, these are really good.
Someone should note these down. Someone noted down that became the first yak blog post.
And then Bayes, Lord and I, you know, a couple months later, we're like, okay, we should make a longer one,
a bit more serious, a bit more technical.
And that became sort of the big one that went really viral.
And the rest has just been compounding memes on Twitter.
Personally, I've been very active on Twitter.
I would have very strong technical opinions about quantum computing.
Frankly, I would be, I would call out a lot of bullshit.
I think, I think there's opportunities to do great work in quantum computing, but you know, my policy was radical candor.
So that's how I built a following, right?
So it's already kind of a firebrand in quantum computing.
So it's already had that muscle kind of pre-trained.
And then I carried that over to kind of like, I guess, AI at large or yak isn't just about AI.
It's about all sorts of stuff.
But, you know, I think it really helped grow the movement in the early days just by the Twitter grind, you know,
for me, I use Twitter as a sort of a dopamine hit.
Some people use various stimulants.
But, you know, I just, I'm very straight-laced.
I just drink Diet Coke if I feel fancy.
It's Diet Dr. Pethper, not sponsored.
And, you know, use Twitter.
And that's it.
Those are my drugs of choice, if you will.
But, you know, to me, it's just like I have like random fleeting ideas.
I like to note them down and then go back to the task I was doing.
And frankly, it was kind of just feeding my Twitter addiction and felt like a fun video game.
And, you know, the followers were rising.
But at the same time, like I found a sense of community.
I found some friendships, made all sorts of great connections.
And, you know, to some extent, you know, you could say like, you know,
yak at this point is almost like a form of spirituality for some.
We can go into that.
I think we have in the past podcast, but yeah, that's where we are.
Where we are with yak.
That's how that was this trajectory.
Should we get base to jump in here?
What's what's the schedule like today?
Yeah.
The, well, I mean, base just did a podcast this morning.
That will also be after this one.
Okay.
But the what's next for for yak?
Where do you see it going from from here?
Yeah.
Well, now that I guess I am docs, right?
One thing that was kind of stopping any sort of like organizations
or incorporations of any kind of any sort of org or institute was that,
you know, we're like going to register with our real names somewhere.
These institutions and that would have docs us.
So now we have that opportunity.
Will we take that opportunity?
TBD.
But personally, I mean, I think, I think right now there's sort of a lack of
theory and educational material for people to understand complex systems
and self adapting systems like capitalism.
And our whole thesis is that bottom up bottom up self adaptation is superior
to top down control.
It's very easy to convince a crowd like put me in charge.
I will do this action.
It will have this impact.
It's much harder to convince a crowd of like, Hey, if we all act in these
microscopic exchange laws, the emergent behaviors that like we have a highly
functioning society, right?
And the more sort of research you create there, the better and more educational
material.
So we might start a research institution there and fund some grants.
I would love to fund some open source hackers.
Obviously we believe in open source software for AI.
We think that open source software is a hedge against the oligopolization of AI.
Right.
There's a couple of players right now that obviously now that they're in the
lead, they have all sorts of interests in closing down AI, outlawing open
source models.
So, you know, sort of like ensuring freedom of compute is something we might
create orgs to sponsor hackers, but also potentially, you know, have some
influence in Washington.
Right.
Those are some next step.
Obviously, like growing the movement on Twitter, that's going to keep going,
also known as X.
And, you know, overall, yes, you know, it gives it gives people an attack
vector now that I am doxxed.
Right.
That is unfortunate.
But I do very strongly believe in what we talk about in EAC and, you know, I am
willing to go all the way, whatever it takes, right, to defend these ideas.
And I won't let sort of this, this sort of pressure or reputational pressure
affect me.
I think I'm quite robust against such attacks.
And if they want to come after me, then, you know, bring it, I guess.
Yeah.
Can I ask one question, Eric?
Sure.
Please.
Yeah.
So, I mean, you mentioned one thing, that I found, that I found sort of, sorry, I'm
a Franco file.
I'm going to use your full French name.
Yeah, that's good.
And, and also mentioned, and also mentioned completely out of context.
Sorry.
That's one of the running gags on the podcast.
You mentioned one thing about the open source.
So it's funny.
So Dan and I come from the crypto world, whereas, you know, decentralization is like this
religious mantra that I think is often overexpressed, actually.
And in fact, I think Dan, I think you quoted it in Farcaster, right, of like sufficiently
decentralized, right?
Which is almost like, you know, sufficiently a trinity or something.
It's enough of a certain theological concept, but no further.
But I always found AI and this, I'm very much seeing that works on the outside to be clear.
It's like, I'm kind of a tourist, but it always seems to me the actually to be totally
centralizing.
And I think the high jinx, you saw it open AI with literally the little junior high school
drama between three people somehow wrecking the cutting edge of AI is something that could
like literally couldn't happen in crypto for a bunch of reasons.
I mean, you might cite the example of SPF, but then Dan would instantly throw a fit and
say, but that was actually a centralized exchange on that decentralized exchange, which is true
actually.
Right.
And in the fullest decentralized version, like speaking of anonymity, like, so I work
in a crypto company, we've had an non employee that I didn't know who they were, and I would
just pay them.
Right.
And we've, we have, we work with the non founders of a protocol and they never turn their
video on.
I don't know who these people are.
And yet we still do business with them and transact.
Right.
So that's, yeah, yeah, yeah.
And it's not even that weird.
And then, then I've met them also in person.
Like it's a similar thing.
Like you mentioned earlier how like, you know, it's really weird that these journalists are
such losers.
I did this tweet interviews up.
It's like, these people are losers.
Right.
Like they never actually go to the parties where you meet, you know, Beth or who, like
I know a bunch of Twitter and I think we all do.
Right.
And you meet them in person, you know, they introduce themselves.
This isn't a big secret.
It's almost like that meme or like the losers in the corner and saying, Hey, do you know
like Yoma's Beth and like everyone dances like, dude, we know, shut the fuck up.
Like, yeah, it's like, it's like, it's like such a loser thing to say.
Right.
Um, but don't you think like AI goes the other way.
Right.
Like just as an example, like I'm, I was using chat, GBT today.
Okay.
I'm pro AI.
My best friend is an AI.
Right.
But, you know, the fact that open AI instantly does a deal with Microsoft and instantly
bakes itself into like literally the most octopus like corporation in human history.
It's a little weird.
Right.
It's a little bit like pinning to the other side of the spectrum instantly.
So I'm just curious if, if you feel that, that, that binarization of it is valid and
feel free to say that I'm full of shit, um, or like if there is another open AI vision
that you're sort of stretching towards that maybe is a little bit more decentralized, um,
and not so naturally sort of centrifugal to, you know, I think that, um, you know, self
organizing systems tend to organize themselves in hierarchies, right?
So it's sort of like, um, you know, you can imagine a tree or a sort of fractal, right?
Uh, sort of structure.
You have, uh, you know, your cells for, uh, your body and then, you know, you have groups
of humans form, uh, a family and then a corporation and then, uh, city and then a nation and so
on.
Right.
So there's a hierarchical structure to organization and there's this hierarchical structure to
sort of, uh, control, right?
There's, there's some control system at the head of your body.
It's called your brain.
There's control system at the head of the family and at the head of the corporation nation
and so on.
You know, it's all about, uh, the balance between, you know, it's, it's all about engineering
fault tolerance to corruption, right?
If you have a one to all connection in, in terms of control, you have a control system
that affects all the nodes in the system.
That node has a fault.
The whole system has a problem just like open AI.
You can decapitate the leadership, you know, not, not physically, uh, but you know, uh,
and suddenly you're in control of the organization.
And now everyone that had, that were using their APIs have a problem, right?
Cause they have an ideal log that didn't, they didn't vote for in control of, you know,
a product that they depend on, right?
And so decentralization is about sort of, uh, uh, diffusing, uh, obviously having decentralized,
uh, loci or plural locus of control, uh, so that, you know, you have fault tolerance to
corruption of, of these control nodes, um, of course, like having a fully greedy algorithm
where everything's disordered is not optimal, right?
So it's all a balance between the two.
It's a balance between centralization and decentralization.
That is what is like fundamentally optimal.
The reason we're fighting for decentralization is because we think, you know, right now there's
a tendency towards over centralization of AI and we're very worried about that.
And so we need to push things in the opposite, uh, direction at the moment.
I think that fundamentally right now there's a lot of alpha and just scraping the whole
internet centralizing it and having centralized training.
I think at some point that alpha will be saturated, right?
Most companies will have a model that compresses basically most of the data that's on the internet.
Uh, and then you're going to have AI that seeks to capture data from the real world.
And for that, you have to be central decentralized.
You got to, and you want to have the intelligence perhaps at the edge.
We're not there yet.
There's still alpha from like centralizing data and, and soaking it all in and, and having
one big model that, that compresses it all because intelligence is more or less compression.
Um, but I think over time we're going to see decentralization in the form of sort of
like, first of all, you're going to have personal assistant, you know, like humane,
like tab or, I don't know, these are going to be all sorts of AR assistants.
I'm sure, uh, at first like you're going to have, you know, the, the intelligence is
going to be in the cloud, but the data acquisition is going to be on the edge.
But eventually people are going to want their own compute, uh, that, that they own in control.
I would imagine, uh, and, you know, maybe there's compute in the robot directly, right?
It's not, there's no need for a connection to network.
Um, I think that's going to be sort of the, the decentralize a decentralizing effect,
right there.
Uh, and, and you know, you can have federated learning over a fleet.
I think people are working on this obviously right now in order to train the biggest one
model to rule them all, uh, the centralized approach, centralized compute and centralization
of data is, has a huge advantage.
I think a big problem as well is that right now the centralized approaches, they scraped
the whole internet, uh, which includes your data and then they rent it back to you, right?
Bit by bit.
And I think the future is about, uh, crediting people for the data that contribute to AI systems
and sort of distributed ownership, right?
I mean, they're, they're starting to do this with sort of GPTs, uh, open AI, but you know,
it's just, it's just an early start, but I, I, I do think there's sort of, uh, I think
there, there's going to be a very interesting way of a startups right now, uh, like from
crypto migrating to being infrastructure to line incentives for AI.
Um, we're not a crypto company, by the way, uh, just, just, just, you know, people thought
we were going to launch a coin.
Uh, we're not a crypto company at the moment.
I have nothing against crypto.
I love it personally.
Um, but you know, I, I, I think that, um, crypto being sort of the value exchange network and,
and programmable incentives for kind of collaboration in AI, right?
To, to, to have sort of decentralized, uh, research labs.
I think, I think that's going to be a very potent application of crypto.
And it's just something I fundamentally want to encourage because I think that if
we have a future where there's only a few companies that are like government that
have the government mandated monopoly or oligopoly to serve AI models, then you have
a sort of like single point where a few people get to control the cultural priors
of these LLMs, what they're allowed to say.
So it's an information supply chain attack because people won't ask each other,
what is the truth?
They're going to start asking the LLM, what is the truth?
And if, if you, if you change what it says, then you're controlling people's
sources of information and you're controlling people.
So it's cyber genetic control of the population through this information
supply chain attack by proxy, by, by, uh, you know, saying that, oh, well, we're
responsible, we should be put in control of what these LLMs are allowed to say.
Right.
Um, so we definitely want to fight against that.
And one solution is to erode their market power by having alternative solutions
that are just as good or nearing the same, same level.
Of course, that's not going to happen if we don't leverage sort of, uh, capital
as a capitalist like technologies for value, for incentive alignment.
Right.
Um, and, uh, yeah, very bullish on this space.
Again, not personally involved at the moment.
Uh, I, we're building a hardware company, uh, for AI.
That's fun, fundamentally new.
We can get into that at some point today.
Um, but, uh, yeah, overall, very, very worried about the over centralization
of AI started making my voice heard online.
Um, and I think, uh, you know, uh, there was an event where I got to interact
with the chair of the FTC, maybe that got noticed.
Maybe that got me in trouble.
I don't know, uh, but, you know, there are ways that our voices is being
heard in, in Washington.
Uh, and, you know, our point is that, uh, this sort of, uh, fear mongering, uh,
and, and doom is really sort of, uh, a very nice cover for very subversive
regularly regulatory capture by the incumbents, right?
Like, oh, AI is dangerous, put us in control.
We're the only ones who are responsible.
Uh, you know, you're not allowed to have more compute than we do.
You're not allowed to have open source models that would, you know,
erode our market power and our pricing power, uh, because they're dual to use.
They're dangerous.
Uh, that's all, that's all bullshit, right?
They, they, they cooked, uh, they cooked, uh, those, those proposed, uh,
regulations, uh, for their own advantage, right?
Um, and so we got, yeah, we got a fight.
I mean, they're going to push, they're going to try to push these
regulations through, um, and so that's why we're not, we're not stopping the
fight and I don't think, I don't think my docs is stopping anything in terms
of like making our voices heard.
In fact, it might accelerate things.
I mean, I'd love to deepen into the crypto, AI overlap, Guillaume thing
that you hit on, but if we want to move on to the regular, cause I, you know,
again, I'm seeing the AI world from the outside and obviously I, I use it
and I've been watching, you know, some of Carpathian's videos and stuff.
But like what you just said, right, this business of paying data owners
for their trading sets, like fortunately we do have a public ledger of ownership
that's natively financialized with an underlying value model that does this
very well.
And in fact, some people are even working on blockchain attribution solutions
that figure out where this thing came from because this other person used it
and it's worth X amount.
So I've often thought about like, if there is some sort of crypto, AI
collision, which I think is inevitable, like, but like, just to shoot that, the
idea down just for one second, like, will it, like, why wouldn't you say pay
Reddit for its data, like literally in a direct deal rather than all this like
crypto craziness, like, will it ever be like, this is like the, like the classic,
not to say this is a bad idea again, but the classic bad ad tech idea from web
two was like, oh, pay users for their data.
Well, Brave does that.
And it turns out that data is worth $3 a year, right?
And Brave is a great product and lots of people use it.
I use it, but they don't use it because of the $3, right?
They use it for a bunch of other reasons.
And the data that you actually own that you express with your browser just isn't
worth enough.
So even if you could get things down to like literally the micro ETH, like what
I care that I'm getting paid because the model is getting trained, trained on my
sub stack, and even you could figure out, like literally, what is the actual value
per query that my data contributed to?
And I'm sure the incrementality that is super hard to figure out, but you, you
guys would know better than I would, but even assuming you could figure it out,
that's going to be literally worth like 30 cents a year.
So would it even make sense to, to wire all that together?
Well, um, yeah, I mean, I, I've had some various ideas in this space.
I guess I could just broadcast them, uh, YOLO.
Um, um, essentially, I think, I think you can price the value of data according
to, um, how much information gain, uh, the, the system gets from your data.
Um, and there's some very specific mathematics for that.
And that can give you a share of, uh, a model's future profits, right?
So similar to how, you know, eukaryotic cells, you know, own a fractional ownership
of the success of the greater organism, right?
Through DNA, and that's better than prokaryotic cells, like bacteria.
I think that the future is people owning fractions of, of a model, right?
According to what they contributed to it.
Uh, and I just realized that, you know, um, there might be 10 different tokens
now that spawn using this idea, but, um, I don't know, for me, it's like, I have
more ideas than, uh, I can act upon, uh, in, in one last time.
So I just rather broadcast them.
And, you know, this is something Bayes and I have been talking, you know, we,
we considered, uh, doing something in this space, but you know, I think, uh, at
the moment we have, uh, our hands full with, uh, changing the entire AI hardware
software stack from scratch beyond the transistor, right?
Which is a significant undertaking.
So, um, but yeah, uh, I, I'm, I'm really, I think, I think there's really going to be
some, something interesting that comes out, um, and hopefully it can erode away the power
from sort of the centralized players.
Um, and not, not that like, you know, they're necessarily nefarious, but you know,
every, every meta-organisms control systems act in the meta-organisms best interests,
right?
It's like the real politic, right?
And I think that's the thing about YAC that is that we, like we, we cut through the
bullshit, right?
It's like every agent and subsystem is going to act in its own best interest.
It's going to do whatever it needs to do in order to, uh, secure resources or utility
towards its own growth, right?
An acquisition of resources, period.
That's just how everything works in nature.
That's just reality.
Uh, and it's like, okay, now that we have this reality, how do we create the, the system
that harnesses this to create a sort of emergent altruism where we reach greater
prosperity, find new optima of the techno capital machine that, uh, you know,
allows us to support more humans on earth and to scale civilization to the stars, right?
And so, um, anyways, I, I, I got, uh, into my typical like Twitter space, um, uh, ramble
there, but, um, yeah, I, I, I do think that, uh, again, super huge opportunities in the
interface of AI, uh, and crypto, and that's partly why, uh, you know, there's kind of
been a, a sort of, uh, an informal sort of handshake between crypto and, and EAC, uh,
you know, um, uh, uh, Brian Armstrong, um, uh, you know, they put out an ad for Coinbase.
It was basically an EAC ad, uh, frankly, uh, really we're kind of fighting the, the decels
and the, the centralizers, right? The incumbents, those that seek, um, in, in, to, to control
everything and to cause inflation, to secretly tax you. And they're scared of sort of bottom
up decentralized revolutions that, that they don't control, that, uh, causes, uh, deflationary,
uh, pressure, right? Um, and so, uh, you know, there, there is interests in deceleration.
There, there are kind of, uh, uh, interests of the control systems that are kind of greedy
at the cost of what they're controlling. And it's kind of, uh, we're kind of the, the,
the autoimmune response, if you will, to the, the control systems, right? Uh, and, uh, you know,
we're, we're causing a bit of inflammation to the brain now, uh, or the, the brain of whatever
this, this whole thing is. Uh, and, uh, it seems like, uh, you know, they tried to apply, uh,
Forbes anti-inflammatory pill, if you will. Um, so, yeah. You know, you know what EAC reminds
me of? I have, have you read, uh, John Perry Barlow's, uh, cyberspace essay from back in the day,
uh, like in the nineties, way before your time, probably. Okay. But I, you have, based on, um,
uh, do you, do you remember it fondly? I remember reading it when I was young and getting into
the internet and I find it was the most amazing thing. Uh, I think I was only shown it like, uh,
two months ago, but very based and definitely has like five, five overlap. And at the time,
right, like the internet was forming as like cyberspace, which now seems almost cliche or
cringe almost was like this edgy space that you would meet. And he has this line in which he,
he basically addresses it to the weary giants of flesh and steel, i.e. the industrial giants to
which the internet represented an alternative. And I think a lot of EAC reminds me of that same
rebellion, of course, except the weary giants of flesh and steel are actually silicon now. It's
actually the old internet that has gotten kind of old and boomerish to which this is a rebellion.
Part of the reason why I'm in crypto, I came from the sort of fang world and working in all that
world. And I felt that that was all slowing down and becoming the man actually. And crypto was
like the only thing that reminded me of the early web two days in which it was like, like, if,
if you don't have people coming after you and getting severely pissed off because you're building
something, you're building shit. I mean, to be, or something that's like not important, right?
Like, if you read the story of Uber, like literally every taxi commission, people in
Paris were kicking the shit out of Uber drivers, you know, all of Spain shut down Airbnb. Like,
you know, if you don't have major governments pissed off at what you're doing, you're actually
not building anything particularly important, right? And there wasn't a lot, there isn't a lot,
in my opinion, an internet consumer outside of some of the things we discussed that meet that.
So anyway, it just reminds me of that vibe of the cyberspace vibe. And I think, obviously,
I think we need more of that. So it's cool. We're definitely the most cyberpunk. Yeah, yeah, yeah.
Movement out there. Hence the, hence the Arasaka tower vibes here. And, you know, we had the
party with with Grimes for the, you know, after the open AI dev day. And the point was,
you know, keep AI open, right? And, you know, it's got to feel like a bit of a rebellion
because it kind of is, right? And then you have the engineers from these, these big players,
they come to the party and they're like, man, this is freaking cool. I kind of want to join
the rebellion. I don't want to work for the empire. What the hell, how do I join, right?
And so that's how it starts. So we'll try to keep that going in many ways. But yeah, I mean,
it's definitely, it definitely very, it feels like we are in the cyberpunk future. It's kind of been
surreal how we've gotten here, frankly. And yeah, no, I'm just grateful to be here at this point
in history, frankly. It's an exciting time. To quote the Steve Jobs line, why join the navy
when you can be a pirate, which is something you used to be able to say about Apple. But I don't
think that's the case anymore. And I have a little bit of experience there. That's the thing, right?
What is, what is the sort of mind virus that infects organizations, that decelerates everything,
adds way too much process, way too much bureaucracy. And then it grows kind of like a cancer,
it's kind of like middle management kind of grows and eventually takes over from the founders. And
now it's kind of like this, you know, borg of some kind that, you know, these core, these huge
corporations, you know, have decisions by committee for everything, there's tons of process, it's just
very hard to get anything done. And really, the answer to that is disruption. Or you got to have
a free market, you got to have free market competition. And if an incumbent is too slowly
gets disrupted by a startup, we saw that with opening AI, right? Frankly, I don't,
yeah, I can't say too much about Google. But, you know, clearly, there was a sort of slowdown
and its speed and the talent eventually saw that and sort of migrated to startups, right?
At least for AI. And then now they're getting disrupted and they're kind of in trouble.
So, you know, but if they remove that mechanism where bottom up challengers
can dethrone and compete with incumbents, if they remove that ability, then we don't have
this kind of self correcting mechanism and we'll just live with kind of monopolies that are
not shipping great product and then everybody, the consumer suffers. And we don't want that,
right? And so to me, it's kind of like, you know, you have sort of like the doomers pushing for
centralization and control. And then you have the, you know, EAC pro freedom folks that are more
about antitrust, right? Like it's about monopolization. And so I think there's an interesting
political landscape shaping now, I think, you know, seems like some Democrats are more on the side of
like AI safety so far. And allegedly, Trump has said he would cancel the Biden executive order on AI.
You know, EAC is not partisan per se, but we're kind of like, we have an issue that we care about,
which is the freedom to compute the freedom to do, to advance technology. And so yeah, I,
you know, I don't know if you guys want to get into, you know, 2024 discussions, but
oh, we never talk about politics here, never, never, never, never. I'm totally joking. We do it
all the fucking time. Well, go ahead. Go ahead. Go ahead. Oh, yeah. No, just on the question of
like, well, what, what, why a big tech so bad, right? Like, I think part of it, I won't really
re-litigate the whole thing. The episode we recorded earlier today and the piece that Nadia and I
put together, like talks about some of what I think about this, but I do think part of the
issue here is just simply like, do you have actual improvements that you can build?
Onto things in the world, onto systems in the world. And I think like there was kind of this,
this like growing lack of capacity to actually do things that were, you know,
sufficiently ambitious. And then also like when you have like the effect of a bunch of capital
accruing, companies naturally end up becoming kind of inward facing, navel gazing, people are
like incrementalists, and it's just kind of like locally optimal for people to kind of be a little
bit lazy, you know, L plus one until you, until you retire, you know, you, you know,
you know, people are obsessed with doing fire and they want to like ride around in a van or
whatever, instead of like build, build cool shit. And yeah, I think part of the shift here is just
that we have a bunch of new technologies coming online and new capacity with AI especially.
And yeah, people just see that it's time to try to dissipate that alpha and do the work.
There's real work to do.
By the way, have you given me the betting odds of like which fan company came out or
came out with the biggest open source dedication to AI? And it being Facebook, I don't know if
I would have bet on my former employer, to be honest. I mean, I don't know if you agree with
that characterization, but it makes a lot of sense.
These Frenchmen are so based.
Yeah, yeah, all the AI Frenchmen, they're all for pro freedom. But I mean, look, every agent
acts in its own about, you know, self-interest. I think that, you know, if you're number three or
four, right, I think right now the leaders are really open AI, anthropic, I would say. I think
that's not a controversial statement. You know, if you're kind of competing for number three or
four, like I think the point is you want to kind of equalize the playing field and kind of ban
together to try to beat, you know, the top two, right? And so I think that's the thing about
open source is it kind of groups everyone together to collaborate on iterating on the open source
architecture and tooling and products to compete in a road away the market leverage of the top
players, which, you know, they're eating, I don't know, 90% of API calls, if not more, if you
include anthropic, frankly. And so, you know, I think, yeah, I don't know, it just makes sense
from a fundamental standpoint, you know, Facebook has a lot of data and they have a
lot of compute, they have a lot of great researchers. And, you know, I'm really happy
they're contributing to open source, but hopefully they don't stop. But at the same time,
you know, it does cost them a lot. It does cost them a lot. And it's kind of like,
they're giving to the community this value. At the same time, people are open sourcing models,
they're not open sourcing the training code, right? So it's not fully open source AI, right?
So they still have their mode of like how to train these things. And we saw, you know,
couple engineers that did llama left and then started Mistral because they have that sort of
artisanal know how of how to train these beasts. And then they raised hundreds of millions right
out of the gate. So it's very valuable knowledge. So they're still keeping some alpha there,
which is good. That makes a lot of sense. But, you know, I do think that
it's kind of like communist AI to some extent to have like just open source everything,
everything's free, like data costs money, compute costs money, engineers that are talented cost money
more and more, in fact. And until we have a sort of proper, like, decentralized
slash centralized system of incentive alignment, I think, frankly, with through crypto rails,
I don't I think it's gonna be tough for open source to really compete with the big centralized
players, right? Just like how much capital is being injected in API calls towards the top players,
you know, pills and comparison to the rest. But, you know, if there's actual capital flow,
like that gets reinvested, then improving open source models, beyond just scrolling on Instagram,
then then I think that's, I think that has a shot. So you think so you think crypto is actually
critical to survival of open source models? That's interesting. You think that's yeah,
yeah, I haven't been very public about that. But it's kind of a thesis I've formed over over time.
I mean, I don't know if it's necessarily crypto, like, I would say like crypto like,
like thinking, right, you could just use like stripe if you want, you know, but
some sort of way for people to collaborate on models and pulling data compute and capital
to train these things, right, and know how. Right. Well, if I could interject,
the greatest accumulation of GPU that is not in a data center was the Ethereum network until
they moved to proof of stake. Right. And that was a crypto economic system that worked pretty damn
well. Maybe Bitcoiners would tell you different, although they have their own set of compute,
a little less useful for AI. But I do think like we don't have to imagine it. It's not science fiction,
like it did exist. Like that's actually what Nvidia's stock price was originally bumped up on
was crypto before obviously AI is taking it to new heights. So I would imagine a world where
everyone's gaming PC and maybe you just don't get to the level of compute that you can with the,
you know, eight H series in data centers. But if you were to take every, you know, GPU around the
world and then be able to kind of do something like SETI at home in a kind of decentralized manner,
maybe, maybe you do actually have this kind of, you can't go drone strike the data center because,
you know, I am the data center, come and come and take my GPU. Right.
Yeah, I think that is the dream. I think that at least right now in the way we're doing these
big models, you need, you know, paralyzed high bandwidth multi GPUs.
It's very hard to shard the models without a significant slowdown over the network, right? And
if an alternative is like a thousand times slower or more pricey than, than the centralized
incumbent, like in the free market, like people want to support decentralization. But if the
product is not like competitive with the centralized player, like at the end of the day,
people pay for what works and has the right cost benefit analysis. But I think that, you know,
there's getting, there's going to have to be sort of algorithmic breakthroughs. But you can imagine
where people instead of having just a gaming PC, they have maybe, you know, bigger boxes that have
beefier GPUs and they can run maybe a whole single node. Yeah, like this is what George is working
George Hots is working on kind of the hardware infrastructure for that, right?
Selling beefy GPU, GPU boxes of several GPUs. I don't know if he's
this is like a petaflop, a petaflop at home. Is that the idea?
Right, right, right. And that seems like an attractive kind of like node to run potentially
a future protocol. I would encourage a lot of people to do the research here. I think there
just needs to be a lot more players in this space. And I think that AI people, you know,
are going to have to talk to the crypto people. And there's going to be kind of going to be a
moment there where there's going to be, there's going to have to be bridges built there in terms
of the language. But, you know, I'm, I'm, I'm optimistic. I don't know, that's my prediction.
I think the merging of crypto and AI, you know, this kind of anti centralization
of the movement is going to kind of combine forces with crypto. Again, I don't own anything
in any protocol right now. So not talking my book, just like my prediction, but
yeah, no, I think it's exciting. Personally, I'm really worried about, you know, okay, cool,
like, great, we've decentralized the algorithms and the sort of like
distillation process of AI, like distilling data into neural weights, right? That is the
software process that we're talking about. That's what OpenAI does. That's what Anthropic does.
Great. Maybe we figured out how to decentralize that. You're still buying your GPUs
from the same supply chain that is down to, you know, NVIDIA, TSMC, ASML, right? ASML is,
for those not familiar, you know, the, the, the machines that do the extreme ultraviolet
lithography. So the most advanced process nodes to, to, to, to create the GPUs used with NVIDIA.
NVIDIA doesn't build their own GPUs. They, you know, work with TSMC, which is in Taiwan.
And, you know, that's where they're built. And so again, you know, I'm just thinking about
fault tolerance of the system. And right now our supply chain for AI hardware is absolutely
not fault tolerant and might be co-opted by totalitarian leaders from, you know, the CCP,
right? And might cause a major global conflict because of that. So, you know, what, what, what
I'm working on is sort of like decentralizing the AI supply chain by fundamentally changing the
substrate on which we run generative AI completely, right? Beyond transistor-based compute, beyond
digital compute. And when, once you have this fork in the tech tree, there's all sorts of
opportunities that pop up for far more energy efficiency, for far more speed, and eventually
far more density. And that's what we're going after. So we're still kind of in the, we're still
living our values. It's just we're going after the, the much harder problem of hardware engineering
and production is really expensive right now. Model production is very expensive for all the
reasons that you listed. And I think that crypto probably crypto cross AI has a lot of potential
in your term with like the, the one to end part of this, right? Where you're diffusing the capabilities
of the model in the same way that, you know, you see open source already doing without crypto.
I think like in general, yeah, like the, yeah, this is like a thing, a broad thing that we've
talked about a lot, right? Which is like, there is so much work to do to put intelligence into
like every corner of the world where it's needed. And you just like the idea that you're going to
do that with a few thousand people, a couple of centralized companies is probably wrong.
And I think like, yeah, you can do this with APIs. But a lot of times you need more privacy than that
for your data. Maybe you don't have internet connection. There are a number of like constraints
that come up in the real world that, or you don't want to have these, you know, centralized APIs.
And I think, yeah, there's, there's kind of a natural balance there. Nathan brought up this
paper, I think, this, this DeepMind paper, right, which is they, they recently came out with some
innovation and doing, you know, kind of like distributed training, some kind of federated
learning scheme. I think it's probably worth emphasizing the main problem here right now,
which is just the, the, the network latency, as, as Guillaume said, I don't think anyone
has figured this out. As far as I know, nobody, nobody has solved this problem, making it cost
effective. And I think it's probably worth underscoring that, yeah, right. So if it takes,
let's say like a hundred days to train a frontier model, if you are off by a factor of two or five
or 10, and you're distributed scheme, that's pretty much kills it. Like it's a really long
horizon. By the time you finish, you will already be not state of the art anymore. Right. And so,
yeah, this is really problematic. I think it's also just about the, the, the DeepMind paper.
It's like using data parallelism, which a lot of people have figured out, I think BitTensor
figured this out, but yeah, you also need model parallelism. You need to shard the model over,
no, it's just, yeah. But you're, you're screwed, right? If you can't fit the whole model in one
computer that you can, you know, plug into a wall outlet and not have to have a home nuclear power
plant, like it's really hard to do model parallelism or it's hard, it's impossible to do data
parallelism. And if you're doing for a big enough model, and if you're doing a model parallelism
over the network, you're also screwed from the, you know, interconnect. And so, you know, kind of,
like, solve, like creating the hardware substrate that's going to allow for decentralized AI,
we have to solve from first principles, how to increase the density of intelligence in space,
in terms of space, time and energy from the first principles of physics. And that's sort of like
what we're, what we're building, what we're trying to enable. So, you know, like,
that's why, that's why I think, like, if there are decentralized crypto protocols of all sorts,
if we have the best AI hardware that has the highest density and runs most energy efficiently,
obviously it's, it's in our, you know, we will have a lot of customers, right? Similarly,
we could be the Nvidia for Ethereum in that case, right? We don't, again, we don't have a crypto
protocol. But I think that that's, that's a very hard problem. You need to assemble a team that's
basically like a Manhattan project like team. And, you know, we came from Google X, Google Quantum,
AWS Quantum, you know, all sorts of institutions, IBM, you know, Google Meta, etc. And we assembled
quite the team and, you know, we're going after like the hardest problem in AI right now,
which is like, how do you embed AI into the physical processes of the world the most efficiently,
right? So, you got to really understand the duality between physics and AI, right? And that's
what we're, that's what we're after. And so, it's kind of like, to me, that seems like,
you know, okay, I would love for there to be a protocol that is competitive right now, but
we need to solve for the density of compute first. Look, maybe George builds crazy boxes that are
water-cooled and you use like two plugs in your house, and maybe that's just enough to run certain
models. That's great. I think we need to go much further. I think there's orders, there's still
orders of magnitude to go in terms of energy efficiency and density for AI, for compute,
especially for AI, right? And that's what we're solving.
What is this? I just wanted to say thanks for coming on the podcast, but you guys continue
the conversation. Thanks so much. Cheers. Guillaume, I have to ask, what is the hardware,
though? I mean, are you going to bring quantum computers to market doing AI? I mean, I have
to ask you about that. It's not quantum computing. It's definitely not quantum computing. Okay. Yeah,
we all got jaded by quantum computing being kind of like nuclear fusion. You know, the timelines
are very long. You know, fundamentally, a quantum computer, you have to cool it to absolute zero
ideally. That's obviously physically impossible. And so, what you have to do is this process called
quantum error correction, right? So, you have to identify faults from, you know, the universe
jiggling and screwing up your computer, the computer's operation, and you got to identify
faults and filter them out. So, you're pumping entropy. So, it's basically a fridge, right?
But this sort of algorithm that is your fridge occupies like 99.9999, you know, well,
not that many nines, but quite a few nines of your computation, right? Overall. And to me,
that seems very inefficient. And, you know, a lot of us were kind of full stack architects or
engineers, the software, the hardware, and the compilers for quantum computing. And we'd look
at the roadmaps, we'd look how long it would take, and we kind of got depressed to some extent.
And so, a lot of us were like, actually, you know, maybe there's ways to use this noise instead of
it being a hindrance. And so, you know, we set out to do a different type of physics-based computing
that is not quantum mechanical that is specifically focused on general VI, right?
And for now, we kind of got our hand forced with this whole doxing situation. So, you know,
we're going to be still nebulous about what exactly it is we're doing. But, you know, we have quite a
few scientific publications in preparation, right? So, but yeah, overall, you know, we think there's
a different path forward, a fundamentally new way to compute. It's going to be like
quantum computing, but a new type of physics-based computing. And ultimately, we learned a lot from
quantum computing in terms of how to program, how to have programmable matter, how to have,
how to integrate, you know, these sort of physical systems into a deep learning program.
You know, that's what we pioneered with, you know, the software I did at Google,
with my CTO now, Trevor, we did TensorFlow Quantum, right? And so, now it's about how to
really have programmable matter and figure out the tidus embedding of AI in the physical world,
which is exactly what the doomers fear most. And so, you know, as a joke, we kind of say
Bayes, for example, is one of our principal FOOM engineers. And we just announced that today,
that Bayes is part of the team. And, you know, ultimately, I think that there is no path forward
where, you know, the ultimate form of AI isn't built. And I think that, you know, we could talk
about like human augmentation and sort of the transhumanist path forward. I'm very bullish on
that. And I would love to, you know, find ways to fund more efforts and sort of like human machine
collaboration and augmentation. But yeah, overall, like, you know, the EAC thesis has always been
like, hey, you know, I don't think like banning GPUs is going to do much, the tech tree is going to
mutate around whatever your restrictions are, and is going to adapt similar to a virus kind of
mutating the technical capital machine just finds a way it's kind of a system that's almost alive,
right? You know, it's always like, and it's entropy seeking, it's exploring all sorts of
configurations, and it finds one that allows it to grow. And, you know, might as well build it
and try to make it technology that's, you know, helping humanity scale, right? Our goal with
EAC and really with the technologies we're building at our company is to enable sort of AI,
the ability to perceive, predict, and control our world, you know, at all scales, including the
nanoscale, such that we can, you know, tackle the real problems that are in the way for us to scale
to Kardashev type one, which is a scale of civilization in terms of its energetic expenditure.
You know, it's kind of like, to us, it's like the ultimate denomination of like societal progress
is like the Kardashev scale, because every other measure like GDP, or like it's based on dollars,
you know, you can like fudge the numbers, right? It's not anchored in like physical reality.
And similarly, sort of our cultural thesis is that, you know, you should evaluate your actions in
terms of like, how do you think it's going to contribute to the growth of civilization down the
line, rather than sort of like subjective measures of utility, like hedons, right,
hedonism, like how much pleasure is this giving people on average, which leads to kind of spurious
optima, like, you know, wireheading, or TikTok, and whatnot. So yeah.
You've got me in total suspense though, if it's non-transistor based computing,
you've got me thinking what the hell it could be. I'm guessing.
Yeah, yeah, yeah. I mean, we're, you know, we're working on it. We still have to remain somewhat
secretive. And I guess there's going to be a lot of interest now. Again, we want to be in stealth
until we had more to say, more to release. But for now, we're keeping things pretty close to the
chest. But I think there's certain discoveries that you make that, you know, like, okay, I don't
think I'm going to be able to unsee this. And if I saw it, someone else will see it.
We should just move as fast as possible to bring this forth.
And for us, it's like, okay, how do we make this the most impactful to the advancement of mankind?
Like, let's tackle the actually hard, the hardest problems that most people don't dare to tackle.
And, you know, it takes some, take some courage there. It takes some
fanaticism to some extent. I think to me, the fact that we have this framework of EAC,
it's a really powerful motivator, right? It's like, what am I contributing to, right? Like,
we're kind of in a, well, you know, I went through a sort of whole phase of, you know,
a group Catholic, and then I was a, not a Reddit atheist, but I was a typical atheist,
studied math and undergrad, and then went through a Nillist phase. But then I think like,
understanding that the whole system is seeks growth and entropy production. And, and that's
kind of the way things are. And that process is what created life civilization. And the technologies
we enjoy, like, okay, we want to contribute to that. So, so having the knowledge that you're
contributing to something greater than yourself gives you that sort of like, infinite dopamine
well, to grind through the long nights to skip the holiday dinners to just file more IP, right?
Like, and put in the hours. And, you know, I think like scaling, you know,
everybody has their own cultural religious framework that provides utility to them for us,
you know, for the EAC community, I think, I think it has had utility for a lot of people to get out
of this sort of Nillistic rut that they were in that, you know, the world was going to collapse,
there's only doom and gloom, everything's going to get worse, put us in charge, we're going to
fix it, maybe, oh, we didn't fix it. It's because you get it didn't give us enough power. And like,
we're just like, you know, it's kind of like, well, you can make parallels to SF politics,
I'm an SF right now. How's that? How's that? By the way, oh, it's, it's night city. I love it here.
You know, it's, it's truly night city. I like to say our office is in our soccer tower. So,
we went with the sort of cyberpunk vibe. It's very much like a night city of the video game,
right? No, but you see the sort of like, if you let the D cells in charge and you let the movie
play out, this is what you get, right? You know, you get, and D cells are kind of,
like they have much more power if they're attached or in control of something that's very
prosperous, right, and generating a lot of value, like similar to big tech, right? You know, there's
money printers and then these sort of folks that seek power kind of take over, but you know,
they can, they can cause a lot of damage. And I think, I think there's a, there's a cultural
turning point and hopefully, you know, it doesn't matter if you're Republican or Democrat, like
having people that are anti tech progress, anti tech first solutions and, you know,
sheathing themselves and under the cover of virtue to gain more power and doing things out of
self interest and, and, and larping that it's for the good of, of many, you know, I think people
have had enough of that and are ready for a change. And, you know, of course, like as technologists,
like we propose technological solutions, but ultimately, like, like we believe in the power
of technology, we believe in people having agency and not accepting that this is just how the way
things are, you got to accept how they are, things are just going to get worse, you know, screw your
dreams kid, just accept it and give up, right? And it's like, no, fuck you, we're not, we're gonna,
we're gonna make the better future happen. We have agency we can build, get the heck out of our way.
You know, we're gonna make the better future we want. And you need a sort of like, fuck you
optimism, right? And that's, that's EAC in a nutshell. And hopefully it keeps growing, because,
you know, we think that's what's, that's what the world needs in many ways. And, you know, hopefully
we can accelerate SF and then we can accelerate the rest of the world. So can ask you one follow-up
and then Nathan, I know you want to jump in and I want to give you time to jump in. But, but I did
want to follow on one question that you mentioned, you mentioned race Catholic, I was also raised
Catholic. I eventually converted to Judaism and kind of rejected this, this sort of default
secular majority of society. That's a whole another story you've done a bunch of episodes on. I do
think, you know, it's one of my pet theories that religion never goes away. It only gets, it's almost
like, you know, energy or momentum only gets sort of transformed. And you guys sort of worse, worse
crappier versions of it. The reality is you can't actually, you can't actually navigate the world
without a sense of metaphysics of some form. And in fact, if you don't have an explicit metaphysics,
you can't even do empiricism well, because then you have to change reality to sort of suit metaphysical
ends. I mean, the site, the COVID example in which they denied the lab origin hypothesis because
it serves some metaphysical end. And so they stopped being able to do empiricism as well as
they could have. They could have, you know, and then that whole COVID story, if there wasn't actually
a way to have a conversation about, do we save the kids and screw the old people or vice versa?
Like you couldn't have that conversation. So instead it was about the science, but really it
was a moral conversation that nobody could have, because we weren't all morally or even religiously
on the same page. That's a whole separate conversation. But I do think it's interesting,
and I do think it's one of the things that's a little bit lacking in tech. I mean, you see these
homespun religions like, I would say Burning Man is a little bit culty. Startups are obviously a
little culty. And I'm not saying this is a bad thing, by the way. It's just, yeah, I know it's
a good thing, but it's a little incomplete, right? In the sense that like, well, it doesn't quite
tell me how to raise my kids or who I should marry. I don't know if, and I know I'm putting you on the
spot a little bit to like, give me the gospel, bro. But like what, you know, yeah, what would be, and
direct me to a set of writing if there is one, but like, what would be the E at gospel or like
that? You know, what is the true, the good and the beautiful in this world, other than obviously
building for building sake, which I think we all get. What is the bigger picture? Yeah. So at a
high level, right? Yeah, because all about figuring out whatever sort of cultural framework yields
the maximal expected growth and scope and scale of civilization. And we don't want to be prescriptive.
All we're giving is a loss function. And you can have your own hyper parameter settings. You're
like, okay, I have a cultural heuristic. I think this is an optimum of this sort of loss function.
This is how I want to, you know, do things within my tribe here. It's essentially a sort of like,
think of like a very thin framework from which you can have like subcultures, right? And, you know,
the idea is to have sort of culture be more or less like, like code, like on GitHub, you can kind
of have a base framework, and then you can add kind of commandments or add things you believe,
or you can diff it, right? You can make forks, and you can kind of keep track. And so we've seen,
for example, you know, Vitalik forked yak and made some changes, right? And then he's like,
this is what I believe, right? So really, you know, yak is sort of a meta cultural framework. We don't
prescribe, we don't prescribe too much, we try to prescribe the minimum. But to us, it's very clear
that the the engine that keeps progress going, maintaining the sanctity of its sort of momentum
and, you know, maintaining malleability, adaptability, and so on, is it's crucial to maintain freedoms
and maintain entropy in the system and accept variants rather than constraining things, crushing
entropy, crushing variants, because that leads to crystallization, and sort of like catastrophic
failure. And so, you know, at a very meta level, we try to maintain variants in most parameters,
but it's not like all variants, no restraint, because that that just doesn't work, right? It's
kind of like running a system at very high temperature, it's just pure disorder. So it's
kind of always about finding the optimum balance between order and disorder, so between entropy
seeking behavior, and novelty seeking, and sort of constraint and conservatism. And so we don't
have any one particular prescription of how to live your life, but some people like to make forks
and have more particular prescriptions. And to us, it seems, at least my personal thesis on how
cultures get kind of mimetically post-selected for, it's like whichever culture either confers
its adherence and a better ability to grow, or if a culture is more sort of viral, then it's
going to be more likely to exist, that's just like by probability theory. And so, you know, to us,
it's like, okay, if we have this sort of metacultural framework, people have all sorts of forks, and
all these mimetic forks with different parameter settings can compete in a sort of cultural
setting. But we should explore the space of cultures and heuristics of how to live your
life. So for example, another friend of ours is Brian Johnson, and he has his own life heuristics,
and he's trying to create his own cultural framework, and he has much more prescriptive
ways to live your life. And he thinks we should, you know, life spans should be much longer than
what it is, and you should have longevity as a priority. And so, I'm all for this sort of
renaissance of exploring all sorts of neo-religions, neo-cultural frameworks for how to live your
life. I think it's much needed because otherwise sort of parasitic mind viruses, like the ones we've
seen do all sorts of damage recently, including the diesel class of mind viruses. That's a whole
category. Yeah, they come in and they kind of like, like you said, kind of fill in this gap
in people's hearts, if you will. So I think we're on the same page, and I think, you know, much more,
you know, Lindy religions, right, like in a sense like that have been around for a long time, like
they're very robust, right? It's like a code base that has been through hell, you know, and back,
and like it's just, it's very robust, right? It's been robustified over a long time,
and by the proof that it's lasted a long time, it's a good heuristic. So, you know, that's great.
But I think like some people want kind of, you know, modern variants, right, and they want to
contribute to shaping new subcultures. And so we encourage people to form subcultures. So really,
we're kind of like only setting the hyper hyper parameters of the whole thing, and, and people
can set like more finer grain fine tunings of how they want to live their lives. So there's no one
way to go about it. But, you know, we do talk a lot about building, because we think that obviously,
fundamentally, like technology, building technology is a very high leverage way to use your time on
earth to impact the future scope and scale of civilization, right? And so, you know, encouraging
one another and helping one another in building technologies that have a positive impact, like
we think that's a good heuristic that should be in most, you know, forks. And so, so we encourage
that. Some people think that's the only message, but it's not, right? It came from kind of a higher
level thinking, but yeah, cool. Well, you're in, I think you're in the right city for exploring
religions. I mean, the way I see San Francisco, it's really, it's a Petri dish for literally
exploring every weird ass thing that society wants to do, whether it be autonomous vehicles,
whatever weird computation you're cooking up with, not having rule of law, for example, psychedelic
drugs, whatever, bring it, we're going to, it's going to be cooked up here and then from here
expand and diffuse whether we like it or not to the rest of the world. But I want to let Nathan,
and I know he's probably been biting his tongue this entire time. And I think I'm the last host
left standing. And so, I'm going to invite Nathan to go ahead and comment and provide maybe the other
side of it if he wants to. Well, how much time do you guys have is my first question, because I am,
I have a lot of questions and I would, if you have the time for it, I might kind of fork this
episode and just kind of take it in a whole different and kind of more from very sort of
naive questions direction. My show is all about AI and it reaches a pretty diverse set of people
that are all pretty obsessed with AI, I think. I don't really actually know too much about them
other than that they go pretty deep with me on a lot of AI topics. And so, the way I was thinking
about approaching, so we could do this now, we did it another time, but I mean, I'm up late.
Now is a pretty bad time. I have to have a 6am round announcement to craft. It's going to be a
long night for me. So, I was happy to do this podcast. It's very timely for us, but I'd be
happy to hop on your show. I mean, you could re-watch the recording, write down your questions,
and we can just go into it. And I would love to do that actually. So, cool. Yeah, I've got a list
all cooked up, but I'm happy to do it whenever is convenient for you, although it is timely now.
I mean, I think part of the reason why Eric had a mixed crew is to have there be
the other take of it. So, I don't know if there's one question or if it makes sense at all.
We have nothing against it seeding another show, by the way. That's perfectly fine.
Or we can bail on. I also want to be respectful of Guillaume's time because it sounds like he's
in a, and again, thanks for making the time for the podcast. Yeah, we're going to do it.
Yeah. I mean, my angle on the whole thing is, I describe myself as an AI scout,
and I'm getting more and more, putting more and more emphasis on, let's really try to figure out
what is today, what exists, what can be done with it, if we are going to extrapolate,
can we extrapolate, first of all, in a high confidence way into the short term,
and then use those discussions as kind of the foundation for figuring out what we should do
about the bigger picture questions, where I think inherently there's a lot more uncertainty.
And one thing I haven't really heard from you guys, and I've pieced a little bit of it together
from Twitter, but I don't have a great sense of like, what are your near term expectations?
Do you think we are headed for AGI in the next couple of years? Metaculous has it at just over
two years. The leaders of Anthropic, for example, say that the leading developers in 2526 timeframe
may create such a lead that no one will ever catch them. Are you in that same headspace of
thinking that we're going to see pretty radical transformation on just a few year timescale
is my very first question? Yeah. First of all, I don't like the term AGI that much. I think it's
human level AI or human like AI. I think like calling AGI general intelligence, like human
like AI that was distilled from human generated data, I think that's like very anthropocentric.
And I think I work in physics based AI, inspired by physics. And to understand the physical world,
I've done so for 10 plus years now. I think that intelligence is a much more general concept than
just human like intelligence. And frankly, I'm not scared of FOOM because again, I've worked on AI
for engineering matter, drugs, simulations, biology, all sorts of stuff. It's much harder than people
think. I do think it is disruptive for our economy based knowledge economy of human like white color
intelligence. I think there's still going to be a 10 year gap for physical intelligence, robotics.
I think our motor intelligence is much harder. It takes many more parameters. It took billions
of years to evolve, rather than I guess like, I don't know, 100 million for the neocortex.
Probably got those numbers wrong, but it's ballpark. But yeah, essentially, I think
I think there might be a disruption to our economy. But I do think that people will adapt.
People will learn to augment themselves out of self interest, right? And it's like, where will the
system go? Every corporation is going to do what's in their best self interest. They're going to maybe
be 80% AI, 20% human. And each human is going to be augmented and control a fleet of AIs, right,
that are doing its bidding. And that's okay. Maybe the human employees become the control systems
for a fleet of AI that do most of the work, right? Maybe they become more kind of like
the capital allocators or the executives of companies that are mostly AI for the execution
layer, right? Maybe that's the future. I think we're heading towards interesting times, but I
don't think there's going to be cataclysmic effect. I don't think it's going to end humanity. I think
we're going to adapt and the system will adapt. And this sort of EAC is all about the main, like
it's a faith and sort of worship of this adaptation of the Homo Techno Capital Mimetic
Machine, the whole thing, right? Like memes, technology, capital humans, it's all coupled,
it's all adapting, it's always shifting. The only constant is that it's always changing,
and it should be always changing, and it seeks to grow, right? And so we have a faith that the
system will adapt. It might be abrupt. And so personally, I'd rather augment humans in orthogonal
directions to human-like intelligence rather than try to replace human-like intelligence.
Obviously in an economy that's already shaped to take in human intellectual labor
and do all sorts of produce products, like having human-like AI is what's going to grow the fastest,
so that's what's being built first. But I'm already pricing an AGI personally, and the technologies
we're building hardware and software all assume there's probably going to be a human-level AI
within two to three to five years, right? And that's been priced in for me, mentally.
And it's like, now what? What's the next thing, right? And to us, it's like,
we're going to seek to grok and perceive, predict, and control matter at the nanoscale, right? And
then we're going to, you know, we're going to seek to, again, increase the density of intelligence
in terms of the substrate that's what we're working on. And so, yeah, I think, yeah, like,
I think it's coming. I don't think it's going to be cataclysmic, but I think that
people should start preparing and start integrating their business processes,
integrating their personal life and their personal workflow with AI, right? There's going to be the
class of sort of the tech forward people that embrace AI and sort of do well, right? They
integrate with it and those that refuse to use it that don't do so well, right? But the important
thing is that if people get to own a piece of the system in which they're contributing,
at least they own a piece of the future as it grows. Whereas if they, there's only centralized
players from which you, you, you have to pay rent constantly. And maybe they'll give you a
sprinkle of UBI at the end. That seems pretty dystopian to me. So that's the future we're trying
to prevent. I don't think the disruption can be stopped at this point. It's, it's coming. And
the only question is like, who's going to own the future? I think it's a lot more questions than
that actually, but I'm going to have to hop to, but I think you have needs to go. Can I ask you
one last question? It literally is a 30 second thing, by the way. One of my employees, he was
digging up some of your old videos. He, he saw that you had a 405 pound bench PR. Is that actually
true? Yeah, he was very impressed by that. Yeah, yeah. I mean, I was, I played, I played college
ball, college football. I have a friend who's a doctor in the NFL, played with a great friend.
And yeah, I mean, I just kept lifting after football. And, you know, to me, it's just been
like, I was a mathematician and I was a power lifter. And to me, it's just like engineering
signals in order to have neural adaptation. And it's all one in the same. And so, yeah, I mean,
you know, the best Jesus character, it's all about mind and body. And, you know, I, I do
like to cultivate strength and, you know, push, push myself to the, to the limits to some extent.
And yeah, that, that is a, I'll just post the video if you want. I'll tweet it.
Well, he found it. I have no idea how he found it on Vimeo, but I'm impressed because, you know, a
lot of this transhumanism business is very agnostic and kind of denying the physical, but you're
actually embracing it. And that's also other conversation. Thanks for making time. I'm going
to have to hop off. I assume everything will upload when we all hop off. I'm not sure what
Erica's never disappeared before. So I literally have no idea what's going to happen.
All right, to be continued, guys. And yeah, definitely to be continued. And one of these
days I want to talk crypto and AI with you when you're over the whole hump of fundraising and
all that stuff. Because I've been thinking about this whole thing for a long time. And I'm very,
yeah, I'm impressed. Okay, cool. Awesome. All right. See you guys. Cheers.
