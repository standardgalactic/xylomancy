So, this is one of the most interesting conversations I've had all year, and it's with former
PokerPro and scientist Liv Bere.
So Liv has a YouTube channel where she makes films about game theory, complexity, physics,
a lot of other really interesting topics, and we covered a lot of ground in this conversation,
including what she learned about intuition and logic playing poker.
Everyone in the world tells you, oh no, trust your gut when it's got a really strong feeling,
it knows, it knows something that you don't.
And it's like, well, this is clearly not true, because it's often wrong, and it seems to
be largely, am I having a good day or a bad day?
If I'm having a good day, my intuitions tend to be more optimistic, if I'm having a bad
day, my intuition is pessimistic, so I can't trust it that much.
We also talked about game theory and why it's such a useful tool for sense making.
It's just the mathematics of these competitive situations, effectively, looking to see what
optimal strategies are, suboptimal strategies, and the phenomena that arise out of them.
And we delved into a concept popularized by Scott Alexander called Molok, which took the
conversation in a really interesting direction.
And what he really did for the first time was he related Molok to game theory, and talked
about how it seems to be this sort of the force, so again, if there's this force of
something that's driving the emergence and complexity, there seems to be this opposing
force, which is a force of destruction that sort of uses competition for ill.
Molok is the god of unhealthy competition, of negative sum gains, so competitive interactions
that make the world worse off for their existence, as opposed to being neutral or better.
Liv is also one of the speakers at our free state of sense making event on the 25th and
26th of September, so you can sign up for that down in the show notes, and I hope you
enjoy the film.
So Liv, welcome to Rebel Wisdom.
Thanks for coming.
Thanks for having me.
So you're a former pro poker player, and you also have an interest in game theory, which
is something that we've covered on the channel and something we're always wanting to learn
a little bit more about.
But the first question I wanted to ask you is, can we play our way out of all the sort
of game theory traps we find ourselves in, by which I mean the broken information landscape,
institutional corruption, culture wars, polarization, obviously the list goes on, or are we just
completely fucked?
I mean, that's the quadrillion dollar question, right?
I certainly don't know the answer to that.
I sincerely hope that there is a way out of it.
I don't see what it is, in all honesty.
It's something that consumes my thoughts on pretty much a daily basis.
But there's something in me, call it dumb optimism, call it the belief.
If there's these sort of dangerous forces of sort of semi-entropic forces trying to
break down complexity, the complexity that is civilization in one direction, it almost
seems like there's some kind of force pro complexity trying to hold everything together
and keep this weird world that we're in going, keeping things interesting.
So yeah, I mean, I don't know what the answer is.
All I know is that we are in an unbelievably critical time of the past decade and certainly
the coming decade.
It's definitely, we're definitely in the most interesting time in human history.
Okay, sure, I might be biased, seeing as I'm here, and we like to be the kings of our
own stories.
But yeah, shit's getting real.
Which leads me to a question I wanted to ask you about.
A lot of the people we've had on the channel, like Daniel Spaktenberger or Jamie Weill or
Jordan Hall, who've talked about existential risk in particular, seem to be quite pessimistic.
And then there's other people who have a kind of, there's a meme called Dumer Optimism,
where there's a sense of, yes, we're screwed, but within that we have some kind of hope
and a kind of optimism in spite of that.
And then we have people like, there's lots of different sort of tribes, like Extinction,
so our deep adaptation, which is a big influence on, for example, Extinction Rebellion, which
is this sort of environmental version of we're all screwed, it's already done.
We need to go live in cabins and we need to be, it's all, I think it has kind of a religious
quality to it almost.
Yeah, I'm curious about how optimistic or pessimistic you are about the current state
of affairs.
It depends what day you're asking me.
Right now, I'm in a more pessimistic mood, simply because I read this article by Kaifuli
yesterday, talking about the next generation of warfare that we're entering into with these,
you know, with autonomous weapons and particularly AI driven ones.
It's not inconceivable within a few years that for $1,000 you can, and a little bit
of know-how basically build an entirely anonymous drone that can take out whoever you want,
and it will not be able to be traced back to you.
And that's just the beginning.
And you read that and you're just like, I don't see how we will ever make it.
So right now I'm in a pessimistic mood, but after the weekend I did a little Burning Man
ceremony and just felt the magic a little bit and I was like, no, we're going to make
it.
And it's weird, it's like a, I mean, you could almost say, is it like a sort of left brain,
right brain thing, you know, logically I don't see a way out of it, but there's like some
intuition in me that feels like we're going to make it.
But then sometimes my intuitions are just like, no, like also, like I don't see a solution.
So I don't know.
And I guess perhaps the thing to do in the face of that, you know, this constant uncertainty
and this oscillation between the two extremes is to, you know, which state of mind would
I rather live in more?
Given that I don't know which one's the right one and I seem to be able to go into both,
I might as well invest in what I can in myself to control, you know, am I more likely to
wake up in an optimistic mood or a pessimistic mood?
And I can control that to an extent by, by, you know, taking care of my information diet.
What do I read?
How much time do I spend on Twitter?
You know, definitely the pessimism is correlated to the amount, you know, my, what my, my phone
tells me I've been looking at Twitter, you know, how many minutes per day?
You know, part of the thing I hate about, you know, you go on to Netflix or whatever
right now, it's just the amount of dystopian art out there to utopian art is like a hundred
to one.
Probably worse even.
There's just, there's just so little utopian programming, films, books.
And part of the reason I think is because it's just much easier to imagine a dystopia.
You know, one of the reasons why utopia doesn't exist is because it's incredibly hard to build.
So again, if you have a more optimistic society, then it gives people the space to dream up
and think of more positive things and it gets the ball rolling in the right direction.
Yeah, I like that.
There's a bunch of stuff in there I'd love to pick up on the, the choice to be optimistic.
You know, I think that is a very interesting thing in the times we live in.
And it doesn't surprise me that it's actually something I've written about before the fascination
we have with dystopia.
I think is in, I think there's lots of reasons for it, but I think in part I've described
it as, I've described the world we're living in sort of culturally as like a noir story,
like a noir detective story where you have the detective going through the, often like
encountering different institutions like the church and okay, it turns out the priest is
in on it and corrupt and, and like corrupt to the core and then the judges are corrupt
and the police are corrupt and everyone's corrupt except for the detective usually plays
this kind of chivalric role of, of the kind of broken but all like roughly all together
pure of soul, pure of soul somewhere in there, right?
And they're like,
Light in the darkness.
Yes, light in the darkness, but they're sort of like hitting the whiskey because like just
to be the light in the darkness is so much and I think, I think there's something in
that as a kind of as an image and there are, and also just kind of, you know, we're recording
this not long after the 20th anniversary of 9-11 and the, the sheer shaking foundational
shaking impact of things like 9-11 and the financial crash and many other things that
have happened since then in terms of institutional trust.
I think we, we have this sense of being in or moving towards a dystopia.
But I'm very interested as well in something you were just talking about in the, the optimism
within that, right?
The, the kind of, and even so there is this kind of, there is this hope.
So I wanted to talk a little bit about game theory because this kind of points towards
a critique I have of game theory, but I thought it'd be cool to, to just kind of get a bit
of a definition of, of what game theory is before in case anyone's not really familiar
with it.
All game theory is, is a branch of economics basically, which typically deals with competitive
systems and it looks at the strategic, you know, it, it describes people or, or decision
makers within it as agents typically, just so that it's not human centric, you know,
AIs could be decision makers or whatever, mice, rats and so on.
And it's just the mathematics of these competitive situations effectively looking, looking to
see what optimal strategies are, suboptimal strategies and the phenomena that arise out
of them.
You have an interesting position in this because you're a former pro poker player and so, you
know, one could argue, maybe this is wrong, correct me, but it is that you were sort of
having to apply game theory under tremendous pressure with high stakes.
But I'm curious about on the table, how much of that is game theory and how much of it
is, obviously experience and then intuition, which is another thing I'd love to talk about.
But, you know, the critique of game theory is often just like with, with modern economics
is that it relies on, on actors being rational, I know not all game theory does, but this
idea of rational actors looking after their self interest, you know, it turns out we're
not really rational actors, but I still think it has a lot of value.
How applicable was it to, to your poker career?
So I think we need to step back a bit in terms of like describing what's going on at the
poker table.
So you will have, obviously seven or eight other people around the table and your job
is to basically sift through all the different forms of information that you're receiving
in order to figure out what the optimal decision is and you've got multiple decision points.
And there's a broad range of information that you're receiving, like from, you know, the,
the amount that the person bets, the, the cards that you have relating to the cards
on the, on the table, the, the, the demeanor of the, of the person, you know, like the,
you know, about their past experience, how much they've played, but then now their face
is doing something funny that you've never noticed before or they're breathing heavier
or something like that, something they say.
So there's this, there's a lot of qualitative and quantitative information coming in.
And where game theory comes in really, right in, in this, in, in the case of poker, typically
game theory applies to the strictly quantitative stuff.
So, you know, the, there, there will be certain probabilities with which other cards will
come out and you, you know, the sort of odds that the, that are being offered to you based
upon your bet and so on.
And what that means based upon that information, effectively in a vacuum, the quanta, the quantifiable
information is that there will be these mathematically optimal solutions to, to these different situations,
which are, because there's so many possible situations, they're very hard to calculate.
It doesn't, it sounds like, oh, so you just need to remember the math, not, but what game
theory will do is basically suggest that there are certain strategies that you will want
to employ in certain situations based upon this quantified information.
But then of course there's this, this like nebula of other stuff coming in, like, well,
yeah, but they were breathing funny, which they weren't doing before.
How do you quantify that and so on.
And in terms of how much of that nebula sort of applies to your overall decision making,
I hate to, to put, like, try and put a percentage on it, but it's by and large, like, 90% of
the quantified stuff and then the, the, the, the, like, these sort of fuzzy things around
the edge will count for 10% of your decision.
A lot of people, so when I first started playing poker back in 2005, no one really understood
game theory.
No one understood the mechanics of how the game worked.
And the best players in the world were basically these, like, they were typically older, kind
of like hustler types who had just spent decades in casinos, just seeing the gamut of human
behavior and developing really strong intuitions about, about people.
And so often they'd make these, these, these strange plays that would turn out to be correct.
And they wouldn't even be able to explain to you why they did it.
It was purely this sort of automatic unconscious intuitive process going on, which, and their,
and their intuitions were basically better than everyone else's.
But then when online poker appeared and we started getting like data analysis software
and this kind of stuff, you, now all of a sudden we had data that pros could look at
and use to analyze where they were going wrong, you know, where are the leaks in their game.
And this kind of, you know, it lifted the lid, lifted the veil on what's going on in
poker.
And now people to realize that, okay, there's mathematical solutions to this.
And what it meant was that the game basically went through a sort of scientific revolution
away from this pure artistry of just feeling and having a vibe of someone to, to going,
well, actually look, this is the mathematical optimal solution.
I'll stick to this until I get such strong overwhelming evidence from something else
that I might override it.
And in, and that, you know, in some ways I hate this, but in reality, like you cannot
be a top professional these days without having that mathematical foundation.
You just, no one's intuitions will be able to surpass knowing if you're playing as someone
who's playing a game theory optimal style, even though in some ways it's kind of robotic,
you just can't beat it by pure intuition alone.
Of course, you know, if someone is now playing not quite perfectly, now you can have these
other like these, these other like fuzzy skills, you can bring in these fuzzy skills to figure
out how the, how to exploit their mistakes.
But yeah, the very long-winded way of answering basically, it's, it's by and large a very
mathematical game over 80, 90%.
That's really interesting.
Fascinating.
I really like that.
I got a nice image there of the various sort of data points that are happening, many of
them at the same time, which is a bit like, I mean, that's, you know, trying to make sense
of something online is a little bit like that as well.
Yeah.
And, and it's interesting with like the particular, so the game of poker, I think can, we can
look at also life in general through that lens in a lot of ways.
Like we, like I also have this kind of yearning for being purely intuitive, right?
But I also am aware that intuition really does lead us to stray a lot of the time, right?
Especially when we're trying to make sense of complexity.
Something John Vervecchi, we've had on the channel a lot talks about in cognitive science
turns, you know, how do we, how do we make sure the frame that we're looking at everything
through?
Like he uses the example of like the glasses we're wearing, how do we know that that frame
is accurate?
And of course it's never 100% accurate, but practices and techniques that help us take
the frame off and go, oh yeah, shit, that's a crack, that's smudged, that I'm seeing everything
wonky, clean it a little bit, put it back on.
And that process of continuously regenerating our frames, I think is kind of more important
than ever.
At the same time, there is something, well, I would use the term kind of like transcendent
or magic about the power of, of intuition, right?
And so when we're looking at something like, well, actually to rewind a bit, I mean, I
see this come up in culture a lot, I'm sure, you know, this has been a real trend of people
trusting their own intuition over, say, the opinion of experts, that happens a lot now.
And there is good reason why we don't necessarily trust experts, you know, I mean, I read an
article recently, which was, you know, making the point about America had access to the
absolute best experts in international relations, counterinsurgency, etc. for 20 years, when
and yet the pull out of Afghanistan was a complete catastrophe, right?
Unlimited budget, almost unlimited expert credentialed experts, a few experiments have
been done where an educated, so there's a caveat to this, really someone who's decently
educated on a topic, trying to predict the future based on that information, it gets
about the scores is roughly in line with a credentialed expert.
So I'll put in the show notes, probably the article that was from actually read it this
morning, I think it raises an interesting question, though, right?
So we need to be able to have some way of not getting completely deluded by our feelings
and our intuition, which it which it tends to do.
And every time I notice it's happened to myself, I'm like, Oh, that's a bit embarrassing.
I really shouldn't have been so certain.
But it keeps happening, obviously, because we're human.
And then at the same time, we need to know how to trust it in some way.
I think so I'm curious to hear your journey with this, I know you were kind of at one
point sort of anti intuition, then you've gone kind of in a bit of a journey with it.
Yeah, I mean, I started out, you know, prior to poker, my decision making process was just
a delightful mix of deep overconfidence and emotionality, just I was a highly emotional,
you know, it was 20 year old girl who thought that she was the bee's knees and everything
and hadn't learned about life yet.
And then poker came along and didn't always, you know, the great thing about poker is that
it's like got these like quite tight feedback loops where, well, just tight enough so that
you will eventually realize that you're clearly not doing something right because you're losing
money, but loose enough where you can still be deluded for a while about your relative
skill level, you know, because there is this luck factor.
And so part of the hardest thing is figuring out when, you know, when things are going
wrong, is it because you're making bad decisions? Or is it because luck is not on your side?
Because it can be both or a mixture of the two. So, you know, you've got your system
one, which is like the classic like intuition, this unconscious process, and then system
two, as I call it, what Kahneman calls it, which is like this, the voice in your head,
you know, what's 471 plus 86, that'll be your system two at work.
And so then I was like, OK, so really what poker is about is about this linear system
two stuff, this thinking things through like solving a math problem, and which it by and
large is. And then I would sometimes try and, you know, I'd be playing, and I would, you
know, facing a big, you know, big, difficult decision. Someone's put me all in on the river,
I'm facing my tournament life, you know, heart's pumping in my ears, and my gut will
be saying, oh, a fold, fold, fold, they've got it this time. And the maths will be saying,
cool, no, you've got to call, you've got, you know, your hand is statistically good enough
to do so. And I would, for a while, I would be like, well, my, my, no, my gut is so strong,
I'm going to just listen to that. And on, well, I don't know whether it's more often
or not, but on a sufficient number of occasions, my gut was completely wrong. I was like, huh,
this is interesting, because everyone's been telling me, you know, but everyone in the
world tells you, oh, no, trust your gut. When it's got a really strong feeling, it knows,
it knows something that you don't. And it's like, well, this is clearly not true, because
it's often wrong. There's bias, and it seems to be largely, by and large, you know, am I
having a good day or a bad day? If I'm having a good day, my, my intuitions tend to, to be
more optimistic. If I'm having a bad day, my intuition is pessimistic. So I can't trust
it that much. And, you know, that was sort of then I did my TED talk a few years after
that, where, and I still stand by the contents of it. Basically, I, I, I shit on intuition
a little bit saying, you know, if you Google it, the internet tells you that it's, it's
this perfect source of knowledge. You should never second guess it, always trust it and
so on. And I think that's actually very dangerous advice, because there are some things your
intuition is really good for, and some things it's terrible for. And the main, you know,
going into the details of what all those things are, the main thing is basically, if it's
something that, if it's a decision you've made many, many, many times, then your intuition
is going to be pretty good. Which is why our intuitions are all from quite good around,
like social things. You know, you meet someone and you get like a weird vibe off them and
you don't quite know why. You know, you've met a lot of people. By the time you're in
your 30s, you've met a lot of people. Chances are your intuition is fairly good and you
should listen to it. But if it's, you know, if you've started a new job and you're solving
difficult problems that you haven't quite figured out how to do the logic for yet, relying
on your intuition isn't a good idea either, because ultimately it needs some data and
experience to be based off. As far as we know, it's not this purely magical thing. It might
be sometimes, but we'll get to that. So yeah, so then I sort of went into this like a deep
skepticism of using intuition. Certainly, you know, and certainly was, my message was
don't over-elow on it. Be very careful because it can be biased. But then more recently,
funnily enough, after a conversation with Daniel Schmaxenberger, who, who is managers
to like anyone who has ever met him, he just like shakes people's brains up. One of the
things he said to me, we hadn't had much of a conversation, but he pulled me aside. He's
like, you need to get in touch with your feminine side a bit more. And I was like, what, what
does that mean? And I was initially like annoyed me because I was like, what, because I, and I
had historically sort of associated femininity a little bit with weakness. I'd always, you know,
I've always kind of been attracted to typically male pursuits, you know, physics, heavy metal,
poker, you know, it's, it's all very predictable to the point where I then started to associate
feminine things with weakness and so on. But it was just that I didn't quite understand what
femininity is. And what it kind of, you know, if, if masculinity is kind of like this outward
seeking, looking for some strict type ways of defining and viewing the world, femininity is
this more sort of passive, inward facing, reflective form of thinking, a form of wisdom.
It's just like another form of wisdom. And that's what I think he was getting at. Basically,
he's like, play around with your feminine side and it will enable you to start listening to
your intuition a bit more and respecting it. And he was absolutely right. And since I started
doing that, I don't know, life, life just became a bit easier. And just just, I don't know, I just
felt like more of a whole person. It's, it's hard to, it's hard to describe. It sounds a bit weird,
but it was kind of cool. I really like that explanation of when intuition is useful and
when it isn't, right? It reminds me of, so there's something I've been quite influenced by as a
work of a guy called William Duggan at Columbia Business School. And he talks about strategic
intuition. And strategic intuition is basically our, so he uses it, he talks about creativity
and innovation through it, but has these four different stages of how we come to new ideas
and how we kind of get new insights. And the first one is examples from history. So you've
done, like you said, you have lots of experience in the thing. It might not even just be in that
thing, you have a whole database in your brain of, let you use the example of social interactions. So
that we have all these different kind of social interactions there and are unconscious in the
library of our memory. But then we also have loads of other things connected to that, loads of
different frames, we have lots of different, so let's say kind of horizontal connections. So it
might be, okay, I also know about this person's culture, or I also know about the cultural
context of where we are, or I'm having this interaction with someone at a roller skating rink.
Well, I know how people are at roller skates, so all these different things are going on.
And of all that information, then unconscious, so the second stage of this innovation process is
presence of mind. So you don't try and find the answer, which goes into that receptivity you're
kind of talking about. It's, okay, well, I'm just going to be awake and aware and allow my unconscious
to do its thing. And then the third stage is the eureka moment, which he calls a koudouille,
which is a strike of the eye in French, which I don't exactly know where they got that phrase from.
But it's a kind of, and we've all had that experience of something hits you like a ton of
bricks, and it often happens when you're not trying to solve the problem. You were taking a
shower, you're walking the dog, whatever it might be. And then the fourth stage is the resolution
to carry it through. It's something I used to do with companies and was on the kind of campaign
to get rid of brainstorming, because brainstorming is really awful for that creative innovation
process. Because what brainstorming is really good for is going, here's many ideas, let's,
as a group, hone down the ideas to one. What is terrible for is here's a blank space, make ideas,
because that's not how the process works, according to Duggan, and he goes into the kind of neuroscience
of it. But one example he uses in that is of a fireman going into a burning building and having
this intense feeling of get out, get everyone out. And this is a real life example, and I think
there's quite a lot of them. He goes in, doesn't know why, that can't see anything in particular,
that's telling him this is incredibly dangerous, but has seen so many fires that somewhere is
intuition is like, something's off, get out, obviously get out the building, the whole thing
collapses like five seconds later. That's what you're talking about, it sounds like you have the
intuition. Well, well, I mean, usually when people report this kind of thing, they can't quite
identify what it was. But there will be some element in all of the complexity of the environment
that is connecting with a preexisting element, which is, oh, that time where that happened,
and this I also noticed that slight offness to the smell or whatever it might be that you
can't consciously notice. So in those moments, that kind of screaming intuition. But if I walked
into a burning building, I'd probably have that screaming intuition the whole time.
Just get out, get out. So, yeah, I really quite like that example. So one of the aspects of game
theory that we've talked about on the channel before, but I don't understand that well,
so I'm going to ask you about it, is multipolar traps seems very relevant to the times you live
in life. So what is a multipolar trap? Yeah, a multipolar trap is basically, it's another word
for race to the bottom type scenarios, which involve typically coordination problems. So
a group of people who are in a system where there's some level of competition,
you know, they're competing for thing X. And in order to get more of X, it typically means that
they have to trade off some kind of values. And inevitably, that trade off will keep happening
more and more because there's individual incentives on each person to do that. And it results in
everyone ending up in a worse state than they would be before. So an example that is very fresh to
mine, because I've just made a video on it, is these new face filters that I don't know if you've
seen or if you spend any time on Instagram, don't. But if you do go on there, particularly for women,
but men as well, there's this just these unbelievably good AI driven filters that you can,
you know, you put your photo in and you press it, and it will just make your face slightly more
optimal. And it's often quite subtle. I mean, there's ones that are very clear and
blatant, but they're the most dangerous ones are these really subtle ones where
if I was to just show it to you and you hadn't really met me before or you didn't know me,
you would have no idea that it's there. But for the user, you see it, you know, you can do it
before and after of what your natural face looks like. And then with this thing, it makes you
absolutely hate your face. Like, like it's astonishing. And you can apply this to like
Angelina Jolie, you name it, the most beautiful people on earth, and it will make them look like
trash, by comparison, because you know, we're such relative creatures, right? We always just like
we're always comparing. And these things are super cheap. They're completely ubiquitous. And, you
know, I've done all right in the looks department, and I'm like a fairly well established, you know,
mentally, you know, chicken her like mid late 30s. And they're messing me up hard. Like I like to
the point I now I've used them on my pictures to try it out, like I'm like, how do I ever not
use this all the time. So what the hell it's doing to teenagers is just like, I can't imagine,
because I mean, like, they're having to compare their faces to the best person, you know, like the
Hollywood version of themselves. And so the way this relates to like a multipolar trap is
individually, even if someone knows that this is bad for them to use this, and they know it's
bad for like, their followers to, you know, to be posting these pictures, because it makes their
followers feel worse about themselves. If you're trying to make it as an influencer on Instagram,
how do you do that? Well, you, you, you want to post the best pictures of yourself possible,
like typically beauty and sex cells, ultimately. So individually, everyone is incentivized to
actually use one of these, these, these apps. And then even if, and even if people get together
and say like, this is bullshit, we shouldn't, we shouldn't be doing it, you know, it's bad,
it's bad for us and for everyone else. Ultimately, it's still such a competitive rat race, that
there's such a pressure on everyone to quietly go and use one, particularly as no one can really
tell if you're using it. And then people will suspect that others are using it anyway. So then
they're like, well, I might as well. And then basically everything falls back down again. So
it's impossible to get like a, a rely, you know, a, a, a solid packed going where no one uses
these things because of these incentive pressures. So it's turning beauty, because beauty was kind
of historically considered to be something that correlated with health, right? That's kind of
how it originally emerged back in, you know, presumably in prehistoric times, females wanted
to mate with males that showed signs of evolutionary fitness for their environment.
But then there are points like, like with peacock feathers and so on where sexual selection and,
and like what's good for your environment, you know, for your survival can like decouple and
diverge. And then you stop optimizing for this like secondary trait. And, you know, so basically
where beauty can get decoupled from health. And that's, to me, these, these apps are like the
ultimate example of that because you're like, we know they're unhealthy for us mentally. Like
there, there's tons of studies out there which are showing this just actually really, really bad
for teenagers in particular. And yet we, because they make us look so good, we can't stop using them.
So yeah, that's like a multipolar trap where you just can't get everyone to agree to not use them.
Yeah, that's a great and terrifying example, isn't it? It's quite, yeah.
I mean, it's a very mild example actually, you know, in the grand scheme of multipolar traps,
there are much, much more dangerous ones, you know, like AI arms races and so on.
But it's like a nice little example because I think it's also a good example because it's
something that a lot of people who aren't typically exposed to these kind of ideas
can relate to. Another thing that we're kind of skirting around is the topic of complexity.
And you have a background in physics as well. And the kind of complexity theory,
what doesn't necessarily come from physics, but I think it's kind of a physics. Yeah, I mean,
they're like brothers and sisters. They're not the home of complexity theory. So
why are you interested in it? What is it about complexity theory you find useful?
I mean, it's just, I mean, it's kind of the study of what is right, because,
I mean, whether or not you believe in aliens, like the Earth, what's going on on Earth right now
is just so, from a computational standpoint, it's probably the most complex thing within our,
certainly within our pocket of the universe, in my opinion, and probably the observable universe.
And it's this weird, you know, it's kind of poetic in that like complexity to describe
something that is hard to describe. And it's by, even by that, we struggle to even come to a
definition of what complexity is. So like, that's why I just find it so fascinating, because we just,
it's like really like the cutting edge. So it's very much a frontier of knowledge.
You know, just like we, there's certain things in fundamental physics we haven't figured out.
We really haven't, we just don't have like a solid theory of complexity yet as a civilization.
We're getting there. And it, I think will be, again, this is an intuition, but I feel like
understanding complexity is kind of essential, or at least having a firm grasp on it is essential
for us to make it through. You know, we are in a more complex stage of civilization than ever
before. And it's only getting more complex. And to an extent, we want it to get more complex,
because, you know, if we do blow ourselves up, that's a permanent reduction and curtailment
of complexity in the universe, which, as I mentioned to you before, I think is very bad.
And so, yeah, I just think it's, I just think it's an absolutely fascinating topic. And every
time I speak to someone about it, I always learn something new. That's the interesting thing as
well. You speak to not even necessarily experts, just asking people to define it. It's like, wow,
I didn't think of that before, which is usually a sign that it's a really important topic.
Yeah. And what are some of the elements, I mean, maybe useful if we talk a little bit about the
elements of a complex system compared to, well, one useful way as well as is the
difference between complex and complicated. Yes. Maybe we could start there and then we
can talk a little bit about what happens in complex systems. So a nice definition of
complex versus complicated. Complicated is the opposite of simple. So something that has,
you know, many, many different bits and so on, and is, you know, many, many sort of constituent
parts. Whereas complex is the opposite of independent. So the main way a complex system
differs from a complicated one is that a complex one is sort of, it has this level of sort of
self-referentialism, and it has these feedback loops and so on. And also it evolves over time.
So a complicated system has lots of different parts, but is otherwise static in time by and large.
And so it's, you know, if you were trying to simulate it, you could actually simulate it quite
easily and also explain it. Whereas a complex system, because there's sort of so many more like
levels of dimensionality to it, which are like changing and feeding back into one another,
and it's sort of like these sweet spots between all these different dimensions of things,
is very, very hard to describe and also predict, which is sort of relates to this idea of emergence
as well, because a complex system is basically something that has emerged from something of
lower complexity. And this process of emergence is often like kind of a black box. We don't
understand how and why it happens. You know, like no one could have predicted the internet,
even in like probably like 1890, which, you know, in the grand scheme of the timeline of
humanity is nothing. But it was this unbelievably complex thing that came out of an already complex
system, and yet it would have been impossible to predict. And so, yeah, that's the main difference
to me. Yeah, that's a great explanation. I haven't heard that one before. The image that came to me
was a complicated system, it's like a grandfather clock, and a complex system is the Amazon Rain
Forest. Yeah, and I just got this image of a grandfather clock sitting in the Amazon Rain
Forest as this kind of juxtaposition, but just how incredibly different they are.
You know, it's really recent that I've become more interested in complexity,
and part of it, part of what's really exciting me about it, as I'm on this kind of,
what I feel like will be a very long journey of understanding, is that the sort of enlightenment
project that began perhaps in the 1700s all the way up until now, I would argue, was we can look
at the world and figure out how it's like a grandfather clock, given enough time. And then,
as science has progressed, we've been like, okay, actually, maybe our model was wrong, maybe the
universe isn't like a grandfather clock, maybe it's a complex system, which I think is pretty much
the truth that we've kind of arrived at. But what I'm seeing as I kind of delve into this is just how
important complexity is as a framing for so many different things. So many of the things we've
talked about on Rebel Wisdom as well, like, you know, trying to make sense of the information
landscape, trying to look at the culture wars and figure out, okay, how the hell do we come into some
sense of coherence with one another? How do we revive the common so we can actually have new
type of conversation? All of those are complex problems, because they're all feeding back on
each other. And then there's this, this hope of emergence, because we don't know, like you said,
we don't know what's going to emerge from the interaction of all those different parts.
My sense is that something like a new religion of sorts could emerge, which would completely flip,
would be the next thing that completely flips our entire way of working and communicating with
each other, because we cannot coordinate right now. And the thing that has helped us coordinate has
been that in the past, right? So I mean, yeah, a really appealing meme. Exactly. Something that
is, and I think we have no, I don't think it would look anything like the religions that have come
before. And I've argued that it's sort of brewing as we speak online, and then breaching, I call it
the age of breach, because things are brewing online, and then breaching into consensus reality.
And so far, it's been quite nascent, like the, like GameStop, or the capital riots, where it's
like, Oh, God, that looks like a new thing. And then it's like, well, it all collapsed, but
who knows? There's like a boundary between this, like, this, this, whatever is underneath there,
and then what's in our world. And that boundary is becoming more and more looped in some way.
Definitely. That's what you described. It's like a larger surface area or something. And, you know,
things will pop through. And then, yeah, no, I mean, I mean, the religion topic is a whole other
thing. I, I buy and large agree that not only will we likely see some kind of new religion,
and it's almost seems like people want to need that. But I think we should have something. And
my main problem I've had with all the past religions is just they've been, they're just
really unfun. They just buy not all of them, but by and large, they're about no sex, no drinking,
or whatever, like just they're the antithesis of partying. And again, like, there are some good
pockets within some of them. And I think those are the ones that, you know, have flourished for a
while and so on. But clearly, it seems to be some some part of the human spirit, we want to worship,
we want to think of something bigger than us. That to me is some evidence that there might be
something bigger than us. And but regardless, like, why, you know, why not play into that? Why not use
that? But at least, I mean, I've been thinking about this for a little while, I think there's,
there's value in actually brainstorming collectively, what would we want if we were to
design a religion, what would it look like? I think it's worth, certainly the viewers of
Rebel Wisdom, and people thinking about like, just spending some time to write down five things
that they would like about religion or something like that. And then we hive mind it and see what
comes. Yeah, I'll join right now. Straight up. Before it even gets developed. Yeah. Yeah, that
it's a very it's an interesting one. It touches on something we've talked about as well, which is
this sort of this strange relationship we now have with with rationality and reason and our
understanding of of what that is. And our conception of ourselves as rational actors when
we're we're sort of anything but and yet we do have this capacity to take a step back and be
reasonable. I'm fascinated by that dynamic in particular and how it's how it's showing up
culturally, you know, this sense of on every side of the political, let's say every tribe in the
political spectrum, there seems to be this sense of, I feel like this, therefore, this is truth,
whether it's in sort of successor ideology of progressives right now, or whether it's in the
the kind of rabid certainty of, you know, some people on the right about their own views.
There's a sense of feeling an emotion overtaking our sense making. And I think
often religion has been the necessary place to pour that energy with other people as well. Yeah.
And so I think without it, we're, I mean, we've talked about this a lot. We're totally adrift.
Yes. Yeah. Yeah. So yeah, I'm I'm curious. And I think it'll be weird as hell, whatever,
whatever emerges will be weird. Yeah. Yeah. So you actually when we were talking before
before this discussion, you actually introduced me to a concept I hadn't heard of before,
which comes from, well, Scott Alexander popularized it, but it comes from an Alan
Ginsburg poem originally. And before that is it, I think, a believer Sumerian God,
Canaanite God called Moloch, right? Yes. And I got quite excited when I came
across this and I'll talk about why in a bit. First, we should talk about what exactly it is.
It relates to complexity. And there's this other concept called Moloch. And yeah, what is it?
Yes, I mean, you summarized where it's where it came from quite well. It was originally the
is either the Canaanites or the Coffinogens, I don't know, but it was a God of war,
that they supposedly sacrificed their children to by putting them into an oven and burning them
so that Moloch would be happy and they'd win the war. So really, that was dark as it gets.
And then it became more popular when when Alan Ginsburg wrote this amazing poem called,
it's actually called Howl, talking about this thing that sounds sort of analogous to capitalism,
making people mad. And then Scott Alexander really nailed it. But he wrote this
unbelievable blog called Meditations on Moloch, which was the first time I've seen he basically
he's trying to analyze what Alan Ginsburg is talking about this this sort of mechanistic thing.
And what he really did for the first time was he he related Moloch to game theory and
talked about how it seems to be this sort of the force. So again, if there's this force
of something that's driving the emergence and complexity, there seems to be this opposing
force, which is a force of destruction that sort of uses competition for ill. And, you know,
the way the way I'm terming it, I'm doing a video series on this. And I'm terming it as basically
Moloch is the God of of unhealthy competition of negative sum games. So competitive interactions
that make the world worse off for their existence, as opposed to being neutral or better, because
games can be good or bad, you know. And and so Moloch is kind of like this personification of
that. But in reality, what it is is just this diet, this like dumb, blind force of like,
evolution and economics, where basically you'll have these
systems where individuals are incentivized to do sort of the selfish thing, kind of like a
prison as dilemma, like a multi person prison as dilemma, where they, everyone is individually
incentivized to do the thing that will give them a short term gain. But if everyone does that,
then everyone overall ends up worse off. So from basically from a God's eye view, everyone should
do the cooperative thing. But in reality, because it's so hard to get so many people to coordinate,
there's no way of enforcing it, then everyone ends up in a bad place. And that's, you know,
it's called a multipolar trap, or a Moloch trap, as I like to call it. So yeah, that's kind of an
abstract concept. But for simplicity, think of it as like the god of unhealthy when competition
goes wrong. Very cool. Yeah, that's a really cool explanation. And I like in that essay that he
points out, it just takes one person to be a dickhead for in many of those multipolar traps,
everyone's cooperating except for one person and that can then in the really bad ones.
In the worst designed ones, like a good example would be like, you're at a stadium at a football
game, and you're in a block and everyone's sitting down at the start of the game. But then the team
comes on and someone at the very front gets excited and just wants a slightly slightly better angle
so they stand up and it makes the person behind them stand up and then the next person ends on.
And everyone has to stand up now. And they're just stuck there, like you basically the system is
like fallen into this lower state where, yes, sure, you could like quit the game by being like,
I refuse to stand, I'm going to sit down, but now you don't get to see. So either way, you're like,
you don't have a better strategy than the current one, which is now standing up. But if you could
poll everybody, they would much rather everyone be sitting and you know, have the same view,
effectively. So yeah, that's just one example of where like a poorly designed system,
due to competitive dynamics can have this like cascading effect where everyone ends up
in this annoying situation where they'd rather not be.
Yeah, and I think what's I really love the concept because I think one of the things that's useful
about it is that in the various circles who are interested in changing the world in some way,
changing the system, finding ways to create a better system, which is something I really also kind
of, you know, identify with and I really care about a lot. There is often very little, it's
often very meta, it's often like, it gets very zoomed out and doesn't necessarily look at the
forces acting against sometimes it does sometimes it doesn't right. And there's something about
the concept. So I got really excited when you started when you introduced me to the concept
because I looked at the you described it a bit, I read this got Alexander essay and then I for me,
there was a lot of crossover with a model I'm really familiar with from from mysticism from
the Gnostic Gospels. So the early Christians, well, arguably they weren't really that Christian,
but some of them were a little bit more kind of Hellenistic mystery traditions. So we're talking
kind of maybe the third century, you know, second and third century. And they had this incredibly
sophisticated model of I would say a model of human psychology of the human psyche. And they had a
creation myth in which the earth is a living goddess. And the God of the Old Testament Yahweh
is this kind of this false God, which is just pure ego, right? And he kind of he gets created
by mistake by her. It's kind of complex why but he's they describe him as like an abortion,
like he's so she is a goddess and has the all the kind of divine creativity of a goddess,
right? She's tapped into the sort of universal source of emergence, let's call it. And he comes
along and he says, well, I'm the God of everything there is. And she's like, no, you're not because
you're not you're not you're almost like a cracked reflection. You're not even real really. And this
interesting because the neuroscience of our egos has been argued that the the narrating eye are
our egos looking out for our own ends is a kind of conglomeration of many different aspects of our
brain. And we kind of cobble together a self from our essence. And so in a way, yeah, yeah, exactly.
Yeah. And that's exactly a lower complexity self. And in a way, it's real, but it's not real at the
same time. So you have this dynamic there. And then they argued that when we so human beings
have that divine intentionality and that divine creativity. And also, though, we are very easily
deluded by Yahweh and very easily deluded by the Archons, his sort of weird, super weird cosmology
they had, but like this kind of mechanistic, self replicating almost like machine angels,
right, really out there. So so for the Gnostics, their argument was like, look, we see Yahweh or
we say see Moloch and you know, it's very similar. In the systems that we're part of, we see it in
the Romans, we see it in the tax collectors, we see it in the way that people replace the kind of
hierarchies of nature, the natural hierarchies with fake human made hierarchies of society.
And so they were sort of outsiders. And their argument was you have to tap into the deeper
spiritual wisdom inside yourself, the Gnosis, in order to kind of liberate, they were like,
quite, you know, into like liberating yourself kind of quite psychedelic as well. And Carl Jung
was a huge, like fan of the Gnostics, right, the two of the codices are called the young codices,
because he bought them basically, he found them after they were discovered, the scrolls were
discovered in a cave in the 1950s by two Egyptian farmers. Crazy. That's a crazy cool story. Yeah.
And then the final bit of it for me, the synchronicity was that there's a there's a book on Jung
by Peter Kingsley is a classical scholar called it's kind of he's also kind of a mystic,
which is called catafalc. And he talks a lot in that book about this biblical this kind of
mystical tradition that he argues Jung was very familiar with, which is about prophecy. And the
prophecy, a part of knowing who the prophet was was that they howled, right, which is the name of
the Ginsburg poem. So I was like, Oh, very cool. There's a lot of there's a lot of crossovers
like everywhere. Yeah. And what what I love about that is like, for me, I look at it like, I think
they were and Jung thought they were incredibly sophisticated mappers of the conscious of human
consciousness. But there's also some aspect to it, which can't be quite explained for me, which is
that there is this, it does seem there is this entropic force that humans create that we create
from our own, I don't know what what what your take on it is, is it do we create it from our own
bad incentives that are built into us or I don't think I don't think humans in particular
create it. I think it's just, I mean, again, depending on sort of the mood of the day, like it
almost feels like it's just like there are these two opposing types of forces going on within the
universe, like deeply metaphysical forces, where, you know, it's not that it is entropy, but it's
like it uses entropy to its advantage. It's basically a thing trying to I don't know, but like
Mike is like the way the way I envision it, it's just like, you know, that feeling where you are
playing something, and you want to win so badly. And I know that's because I had this like pathologic
I was pathologically competitive as a kid. And it's like eyes on the prize, but to this like,
all consuming extent, and you can't see anything else, you can't see the externalities of what
you do. And all you care about is this like, like optimizing for this one narrow reward.
And the byproduct of that is that if you like play that out to its logical conclusion, it means
that you will turn basically the everything into the universe into this one thing. So the ultimate
instantiation of that is actually like the paperclip maximizer, right, which is why when you
mentioned the Gnostics talking about this like mechanization of all these many, many things
of like the same thing. Could you describe what that is in case that someone isn't familiar?
Yeah, so the paperclip maximizer is this this thought experiment, I think by Eliezer Yudkowski
of like a way in a super intelligent AI could go wrong, whereby it's super intelligent in that
it's unbelievably good at getting whatever it wants done done. But it's stupid into the extent that
it was basically programmed to do this one narrow thing, which in this instance, you wanted to make
paperclips. I just wanted my AI to make some more paperclips better than what I can currently do.
I'm a paperclip maker. But because it's so unbelievably good, it turns everything from,
you know, the factory it's in, it figures out how to pull the constituent parts of the atoms, the blood,
you know, the hematolobin in your blood, the iron extracts it and, you know, dismantle everything
until it can tie all the entire universe, anything it can in the universe into paperclips. Why? Because
basically it was so laser focused eyes on the prize winning the goal of making as many paperclips
that you end up dismantling the universe into this very low complexity state. So it's effectively
like kind of a, you know, it's analogous a little bit to, you know, the heat death of the universe,
because what is that? It's actually a very low complexity state, where basically it's just like,
how would you describe it? Well, it's just homogenous gray soup, you know, that's all it is.
The universe started out very low complexity in that it was kind of like this singularity of
matter and energy. But, you know, if we're talking in terms of Korma-Garov complexity, which is like
basically how many, how many bits of code do you need to describe a thing? It started at the
universe started out pretty simple. And then time started and things started unfolding. And
suddenly we, you know, we've started seeing hydrogen and helium. And that would coalesce
into stars, which, you know, created greater, heavier elements. And all this beautiful complexity
started emerging, patternicity. There's like dance between order and disorder, you know,
with like a bit of hierarchy, but a bit of anarchy and so on that creates this like,
highly complex dynamic system that's very hard to describe, like you to write the piece of code
to describe the universe, you basically have to just create the universe. That's what a highly
complex system is. And, but at some point, the stars will die out and so on, all this sort of
free energy that is used to create all this complexity will start dissipating. And then it'll
slowly, as far as we know, turn into this gray soup, which is low complexity. So it'll do this,
entropy will do this over time. And so, yeah, so this like this gray soup is kind of analogous
to, in my opinion, like what a paperclip maximizer would do. It's not a very, basically, it's
permanently curtailing, you know, there's no more complexity to arise. The universe has reached
this steady state. And that is, you know, it seems like a tragedy on enormous potential, because
at least up until now, it seems like the universe is trying to emerge into greater and greater
states of complexity. So I hate to boil it down to like good and evil terms. But to me, good is
that which creates, you know, allows for greater emergence and complexity to appear, and thereby
utility, you know, useful information that we can process and do and make wonderful things with.
And evil is that which does the opposite. In other words, like, turns things into this like
low diversity, low, like high, you know, like very basic situation, whether it's, you know,
a cloud of hydrogen, which in the mountain, the Howell poem, he and Ginsburg describes Moloch as
Moloch, who is a cloud of sexist hydrogen. So it's like this, yeah, it's like this kind of a
force of entropy, but slightly different, because entropy is actually just kind of neutral. Entropy
is just like time effectively. Whereas Moloch is a thing that turns everything into this like one
Moloch focus is sacrificing everything in order to win this one thing, hence the like child
sacrifice. Brilliant. Yeah, it's so I think it's a really, really excited to introduce this model
into kind of, you know, into the channel and like our thinking in general, because I think there's
there's something I don't quite know what, and I think this is the journey you're on, right?
Like there's something in it, right? There's something in it. Also the kind of thing I'm trying
to figure out right now. And I mean, a lot of this again is like a sort of an offshoot from
conversations with Daniel Schmacktenburger, Forest Landry as well. But I don't think so like
Moloch is tied to the competition, right? But competition gone wrong. But competition can
also be an enormous force for good. Because actually, like, we're you know, the capitalistic
model has risen the world to what it is right now, like we would not be living the cushy life with
our, you know, nice cameras in this cool room and so on, without the a lot of the luxuries that
capitalism has provided. And in its best form, capitalism is, you know, it's like a positive
sum game, it's using competition in order to like drive progress faster than it would without,
and creating these these novel things that arguably wouldn't exist without it.
So it seems to be that there's like some kind of optimal amount of competition, like zero sum type
competition that we would want within the universe, but kind of just like encapsulated in little
pockets, you know, constrained in certain ways, whereby Moloch can't get his dirty claws into
it and like turn it, turn the whole, you know, twist it into something bad. And again, like we,
because a lot of, you know, a lot of people are like, no, we just need pure, pure cooperation,
pure cooperation is all we ever want. No, no competition whatsoever. But that's a lower
complexity state than a universe that has mostly competition, as I mostly cooperation,
with little pockets of competition, driving, driving it forward, but in just like,
delicately constrained ways. So I'm trying to, it is very much just a working, you know,
a thing I'm just playing with, but there seems like there's something to that.
It's like a higher order level of complexity where you're using games in a beneficial way
without letting them get too out of control. Yeah, it's very interesting. I mean, what comes
up for me is something around intention and values, right, on the individual level, because
so to use that Gnostic model again, another aspect of it was that the issue is the ego
disconnected from the self in Jungian terms. So we all have an ego, we need one, that's great.
I consider myself very competitive, like, but there's also a question of priorities. And
would I be competitive at the expense of, say, someone else's well being, or would I
decide to be competitive instead of loving my wife, right? If it was the tradeoff, which one of
those priority, which one of those are hiring my value system? So there's something about that
going on, I think, which then applies right back to the game theory examples, because
in Scott Alexander's essay, you know, he ends each of those examples with like,
but from a God's eye view, if we all cooperated, better outcomes for everyone.
And what I find interesting about, yeah, so that Gnostic model saw the ego disconnected
from the self as unable to create anything truly novel, because all it can do is replicate. And
what it does, so we have that God and we have Mother Earth Gaia, or Sophia, they called her.
So that sound of divine creativity that each human has. But when the ego is disconnected from
the self, it can't do anything except mimic that divine creativity. So and what it ends up doing
is creating like a Disneyland reality that looks real, but isn't real. Nothing is authentic.
Everything is skin deep. Think of kind of reality TV, for example. There's so many
aspects of our culture. I read a great essay, which I'll put in the show notes about Solar
Punk and the author talked about, we've run out of authentic things to frack from our culture.
So now we're fracking our own future, you know, fracking our idea of the future just to get some
like, so it's that extractive thing. And then I guess it also goes to the idea of sociopathy
and psychopathy and Machiavellianism, which is this kind of dark triad in psychology.
And, you know, I've heard Daniel Schmackenberg and many others in this space talking about
that being a major problem when you're trying to create cohesion and cooperation is like the
sociopath problem, because a sociopath or a narcissist looks like they care about other
people, but they do not care at all. They don't have empathy, but they're mimicking empathy.
And it is insanely destructive, because how do we cooperate when that's in the mix?
Yeah, I don't even know if this is that they don't have empathy. I think often psychopaths do
have empathy, they because empathy is just being able to put yourself and like, you know, like
feel what someone else is feeling. And a truly powerful psychopath is someone who would be able
to actually really feel what you're feeling, but then just not actually give a shit about what
happens to you. And like, they're doing something that will be ultimately self serving at the
expense of you. But yeah, that's probably a good distinction to make. And an unsolved problem,
I think, in terms of, okay, we want to find new ways to cooperate, we want to find new ways to kind
of build a sustainable future. How do we deal with that problem? I mean, it's a really on the game
theory level is fascinating. I'm just on the kind of like being a human being level. It's such a
big question. I mean, yeah, it's about building robust systems whereby a few defectors, you know,
people playing this multi person prisoners dilemma, where the system can sustain,
you know, having a few people do it, because I think it's going to be next to impossible to
ever have everyone working purely cooperatively, purely like, and I'm speaking from really a
personal level here, because I was on a game show, which was the prisons dilemma, to an extent,
and it was, you know, it was a one time one. And I did the, you know, I defected, I did the selfish
thing by, you know, doing the clearly dominant strategy in terms of winning money, which was
my goal on the thing. I went in, I was like, I need to win money. So I did the, I did the selfish
thing. But man, like, I'm still getting hate messages from that today, like 14 years later.
What was the game show? It's called Gone Balls. It's on YouTube. I hate it.
Okay.
Did you win?
I won. Yeah. I mean, I played it, I played the game perfectly from a, if you're optimizing for
the value of winning money. But that's again, it's this bigger question of like, what are the
externalities to this? Overall, you know, I, I was doing the sort of the, yeah, I was doing the
strategically, I picked the game theory optimal solution within the definitions of the game.
But outside of that, there's other externalities about the value of cooperation, the value of
not looking someone in the eye and saying, yeah, I'm going to split this with you. And then
actually stealing it, you know, and, um, and it taught, yeah, it taught me like a really
important lesson of thinking about the externalities of whatever it is we do. And so, but what we need
really is to build a system that is robust enough, complex enough, but in the right way, where it
minimizes, where the amount of externalities anyone individual can do, negative externalities
anyone individual can do are contained and constrained. And I don't know how we do that,
but we have to find a way. Yeah, so it's a really good point. I think an example I've used before is
the, how the US constitution was made, because they did a quite good job, obviously not perfect,
but quite good job of thinking, yeah, really great at the time of creating an anti-fragile
system with that in mind, because they were focused on how do you prevent tyranny. And the
process whereby they went through it was, you know, in part the federalist papers were just
writing to each other constantly being like, well, what if someone does this? It's like, oh,
shit, yeah, what if someone does that? Yeah, stress testing. Yeah, stress testing constantly. And I
think, I mean, that's probably a good place for us all to start is just to kind of,
yeah, start having that conversation, which I think a lot of people already having and start
to kind of stress testing. And now we have the luxury of being able to actually make models
and play them out. Like, we can, you know, there's like, I think, you know, game designers, etc.
A lot of people out there who can go, okay, well, let's let's put it in a simulation and see what
happens, you know, that's really exciting to me. Yeah, no, I mean, that's exactly as they're,
though, the blessing and curse of technology is that technology is particularly exponential ones
are making Moloch's life much easier to, to destroy the universe. But at the same time,
we're also building technologies that enable cooperation better coordinate, you know,
the ability to coordinate with one another. You know, like a simple internet forum,
it's just such a valuable thing that like just never existed before. You know, it's not only
because it's a way of sharing information across multiple minds across time, not just in the moment,
but also storing it so that new people can come in and retroactively go back and learn and then
like, and now add something new and so on. So when we were prepping this interview, you mentioned
like quite a few different things you're doing, which sound very exciting. And I think our viewers
will be quite interested in. So and you also have a YouTube channel, which I think is where
they're going to be coming. Yes. And as a reminder, you're appearing and our state of sense making
free event at the end of September. So people can check you out there, but we'll put your YouTube
info below in the show notes and maybe you could tell us a little bit about like what's coming up,
like what you're working on. Yeah, I've been down the rabbit hole on this like Moloch concept and
to an extent complexity. So yeah, making a series, trying to pick apart what Moloch is and also
bring it to life. I do some acting in it for the first time, which is weird. I dress up. It's a
whole thing. But a lot of it relates very tightly to what we've talked about today. So yeah, people
enjoyed this, then they should take it out. Yeah, I'm really looking forward to that. So yeah,
subscribe to live. We'll put the your different social handles down the show notes. And thank you
so much for coming on. Our ability to make sense of the world is breaking down. We're making more
and more consequential choices with worse and worse sense making to inform those choices,
which is kind of running increasingly fast through the woods, increasingly blind. Over the last two
years, rebel wisdom has interviewed some of the world's top thinkers. Now we've brought them together
for an eight week online course, Sense Making 101 with Daniel Schmacktenburger,
Diane Musho-Hamilton, John Vivecchi, and more. Improve your sense making, develop your sovereignty,
and join a wider community looking to do the same.
