I want to ask Sam some questions myself,
and then after that we'll open it up
to a broader set of people so everyone can have some time.
You know, Sam, just before we start,
I want everyone to understand your story,
because you have such an interesting background
in the tech ecosystem, you know,
help us walk us through from graduating stand,
we're not graduating, joining Stanford,
dropping out, running Y Combinator,
running a different startup before that,
and now running OpenAI and a number of things.
Just help us understand how you came
to where you are right now.
Yeah, so I started at Stanford where we met,
and I was already in love with computer science,
but I really fell in love with it once I got there.
I actually went to study AI,
but at the time AI was really not working at all.
In fact, very memorably, one of my professors said,
the only sure way to have a bad career in AI
is to work on neural networks.
We've decided those don't work.
And so I got kind of discouraged,
and I started a company.
That was a great experience.
The company didn't work out that well,
but I kind of like learned about startups
and thought they were a very powerful force
and something I was very excited about.
So I then ran YC for a while,
and while I was doing that,
got newly excited about the idea of startups
that take on hard technical challenges.
And I sort of thought it was curious to me
more people weren't doing that.
It seemed like a really valuable opportunity.
With some other people started OpenAI
as one of those examples and many other things,
which have gone on to be pretty exciting,
but really fell in love with OpenAI.
Once it seemed clear that we were really gonna
have a chance at making true general purpose AI,
like a system that could do what a human can do
and contribute new knowledge to society,
I got really excited and wanted to go work on that.
And so stop being an investor and now I do that.
Amazing.
So first of all, what is OpenAI?
Is it just chat GPT?
Are they the same thing?
Are they different?
Just help us understand what the company does.
We are a company that is doing research and deployment
to try to figure out how to build AGI
and how to responsibly deploy that
into the world for maximum benefit.
So this is unlike other technologies.
Well, other technologies are like this too,
but this is a strong case of a technology down on the one hand
is the most exciting, most promising, coolest thing.
I think that humanity will have yet built.
We can cure all disease.
We can give everybody a great education,
better healthcare, massively increased productivity,
huge scientific discovery, all of these wonderful things.
And we wanna make sure that people get that benefit.
That benefit is distributed equitably.
And on the other hand, there are the obvious concerns
about the power of this technology
used in a negative direction.
And so we wanna be a force to help manage those risks
so that we all get to enjoy the benefits.
Chat GPT is definitely what we're best known for.
So I guess there's sort of synonymous at this point,
but OpenAI is really about this quest for AGI.
So help us understand,
I mean, all of us have played with it, right?
We have poems getting written by it.
We've all asked it fun trivia questions,
tell her in answers,
but help us understand you,
without a doubt have a better understanding
of how it's getting used all around the world
and all sorts of different industries, vocations, reasons.
Talk to us a little bit about
some of the most interesting things that you've seen.
Like for example, what's the most surprising use case
of some of the technologies that you guys have built
that you've seen recently?
So the main thing I would say that's interesting about it
is its generality.
There's a lot of other systems
that can go do this thing well or that thing well
or this thing.
And in many cases, better than Chat GPT.
Some not, like there's not probably not a AI
that can write a better poem or whatever,
but other categories,
you could find something that's maybe better.
But the fact that this one system is truly general purpose
and can do so many things,
means that people are integrating it into their workflow
as a very powerful tool.
And so the same thing that can help you write computer code,
one of the areas that we've seen the biggest impact
is what coders are using this for,
doubling and tripling their productivity.
You know, there was a paper that just came out
that when Italy temporarily banned Chat GPT,
developer productivity like fell in half
on like a fairly big study.
And, but it can do that.
It can also help you find information.
It can help you write a poem.
It can help you summarize documents.
It can translate things.
And people are using this,
which we hoped would happen as this sort of super assistant
that just makes them more and more productive.
And it's that generality
that I think is the coolest part.
So with so much ability that maybe even you guys
haven't even thought about how people are using it
when you developed it and launched it,
I'm sure you've seen a lot of interesting use cases
right here out of India itself.
Can you tell us something or just give us an example
of something you've seen that's really inspired you
that you've seen come out of the Indian market?
So India has been a country
that has really truly embraced Chat GPT.
In a way, maybe you can tell me why
I'm sort of curious.
I'm hoping to learn while I'm here.
We're very delighted,
but there has been a lot of early adoption
and real enthusiasm from the users.
One of the very earliest things,
like in the first weeks of launching Chat GPT,
we heard about a farmer in India
who wasn't able to access government services
and via like Chat GPT hooked up to WhatsApp
in some sort of complicated way, was then able to.
And that was like, that was like one of the early things
where we're like, huh, we did not think
that was gonna happen.
And just to expand on it,
so what I've understood about OpenAI is Chat GPT
is one implementation of the things you've built,
but you have capabilities to real-time translate,
to transcribe audio into text.
And are you seeing people use these in combination
in ways that are surprising?
Well, we recently launched an iPhone app
that has speech recognition in it,
which is that's hooking up to our models together
and people love that.
But the main point that I would like to get across
is none of the current systems really matter.
Like we're gonna look back at GPT-4 and you know,
I don't know if any of you have like
picked up an original iPhone in recent years,
but it's like, wow, I cannot believe
we were excited about this.
Each pixel is like that big,
you know, it just feels like this
like incredibly antiquated thing.
The curve here is gonna be much, much steeper.
And what the systems are gonna be capable of
in the not-distant future, we think,
is gonna be very dramatically different.
So this is like a system that,
I don't even know what the right,
this is like the old first like grayscale Nokia phone
that looked like a little candy bar.
And the iPhone 14 is coming.
So what I would say is it's a mistake
to get too focused on the current systems,
their limitations, their capabilities,
the impact they're having.
The thing that matters here is we are
on an exponential curve, truly.
Two big miracles, I think, in the field.
Number one, we have an algorithm
that can genuinely, truly like no tricks learn.
And number two, it gets predictably better with scale.
And that, we're gonna look back, I think,
on those two realizations as a turning point
in human history when you put them together.
But what it means is that the rate of progress
in the coming years, the capabilities
are going to be significant.
So it's totally cool that chat GBT can write that poem.
When a future system can like cure all disease
or help us address climate change
or radically improve education,
or make us all like 10 or 100 times more productive
at what we do, that's quite impactful.
It's amazing.
Now, let's flip to the other side of this
because there's no doubt there's incredible power
in this technology and with that comes challenges.
I wanna play a clip, maybe you guys can put on a clip
of something I recently heard Sam speak somewhere
and we can talk about it a bit.
Could you play the clip, please?
Hi, my name is Sam and I'm happy to be here today.
Thank you all for joining.
I also wanted to say that the gentleman on stage
with me is incredibly good looking.
And I also want to say that you should be very careful
with videos generated with artificial intelligence
technology.
Okay, so you didn't say that recently.
Clearly that was just a ploy here,
but, and thank you by the way, I was very...
Totally agree with that part.
But nonetheless, I think it raises a real question, right?
When, you know, this video, if you look closely,
you can see the lips aren't perfectly synced,
but like you said, this stuff is only gonna get better
and exponentially better.
Fundamental questions are on authenticity.
What's real and what's fake?
How do we handle that?
Yeah, so that was like deeply in the Uncanny Valley.
It's very strange to watch,
but we're not that far away from something
that looks perfect.
And there's a lot of fear right now about the impact
this is gonna have on elections and on our society
and how we ever trust media that we see.
I have some fear there, but I think we're actually gonna,
when it comes to like a video like that,
I think as a society we're gonna rise to the occasion.
We're gonna learn very quickly that we don't trust videos
unless we trust the sort of provenance.
We'll have techniques like watermarking detectors.
More than that, I suspect at some point,
if people are saying something really important,
they'll cryptographically sign it.
And, you know, web browsers or phones or whatever,
we'll build in some ability to say,
okay, this is authentic.
But that part we can all adapt to.
Like we did this with Photoshop.
There was a period of time where people thought
if you see an image, it's gotta be real.
We learned, we're like, okay, you know,
that thing is Photoshopped, it happened quickly.
Videos like that, society will build antibodies quickly.
But there's a related thing that I think
is getting discussed less,
which is not the ability to generate mass media like that,
but customized one-on-one interactive persuasion.
And I think people are gonna be able to create AIs
that are very good at this.
So it won't just be like, you know,
I'm watching a video of you,
but it'll be like I'm chatting with you back and forth,
and it's like the most interesting,
compelling conversation that I've ever had
that's like affecting me in ways that I don't know about.
And that's a new thing that's different
than just generated media.
Again, I think we'll find a way
to build societal antibodies to it,
but I don't think it's discussed as much
and it's gonna be a challenge.
I also wanna talk about jobs,
because the natural fear is AI is gonna make us redundant,
particularly in markets like India,
where we have so much of a workforce,
and a lot of it is oftentimes doing somewhat rote work.
Should we be worried about this?
I mean, does this affect societal disruption
on employment and capitalism
and all the things in how we've been running?
I mean, to some extent, yes,
every technological revolution leads to job change,
and this will be no exception.
I guess three thoughts.
Number one, job change itself is fine.
If you kind of look at the history of this,
in two generations, we can kind of adapt
to any amount of labor market change,
and there's new jobs,
and the new jobs are usually better,
and that's gonna happen here too.
Some jobs will go away.
There will be new better jobs.
They're difficult to imagine as we sit here
and dream about the future's gonna look like.
The thing that might be different about this
is the speed with which it could happen.
And I think it will require a change
to the socioeconomic contract
and the way governments think about this
if it happens at a very fast pace.
The second thing is it's not going
the way people predicted so far,
and I don't think it will in the future.
So the current systems are actually not very good at all
at doing whole jobs.
They're very good at doing tasks,
and so the nature of the job,
if you're, say, a computer programmer,
to stick with that example,
shifts to you kind of like manage a team
of extremely, extremely junior developers
that can only do one, one minute task at a time.
And then they'll do 10 minute tasks,
and then they'll do an hour task.
But you'll still have to think of like,
how is this all gonna fit together?
What do I wanna build?
And maybe eventually it learns that too.
But this idea that instead of replacing jobs,
it's making people dramatically more efficient,
and there is such a demand overhang in most places.
If we can overnight make the world create
three X more software,
because we make every software developer
three times more efficient,
that is not nearly enough.
That does not nearly fulfill the demand
the world has for software,
and I think we'll see that in many other places.
So another example of this is that the consensus,
not the consensus,
the like absolute belief of experts
around the world 10 years ago,
first AI is gonna come replace the physical labor jobs,
so truck drivers, farmers, factory workers, real trouble,
then it'll come for the sort of easier kinds
of cognitive labor,
then maybe eventually like computer programmers,
even a mathematician,
and then way in the future or maybe never,
because maybe it's like magical and human,
the creative jobs.
And of course we can look now and say it appears
like it's going exactly the other direction.
But that was like really non-obvious certainly to us.
We started thinking we were gonna build robots,
and it's still in some deep sense to me,
seems like it should be much easier to make robots
than it is to make GPT-4.
But here we are.
I think with other job impacts,
it's just gonna be surprising,
but I think the world will get way wealthier,
we'll have a productivity boom,
and we will find a lot of new things to do.
You talked about robots,
and we've talked about sort of the real practical,
likely disruption that we're gonna see because of AI,
but we also have to talk about that 1% extinction risk,
or that robots are gonna come and take over our lives.
How do you think about that?
I mean, you have actually been probably more so
than the average person cautious about this.
And for us, we kind of think of it as sci-fi,
kind of like in the realm of not really realistic,
but interesting to talk about.
But I think you would say it's something real
that we have to think about.
How do we understand it?
I wanna be super clear.
I don't think current systems are dangerous.
I don't think there's any way that GPT-4
causes an existential risk to the world.
But people are very bad at thinking about exponential curves.
And GPT-10 may be a extremely different thing.
Given the importance of getting this right,
even if it's a 1% chance,
I think putting a lot of effort into thinking,
studying how we align an AGI,
how we design safe systems at this kind of scale
is super important.
And starting that early is really good.
I think we can totally manage through it.
I think we're developing techniques to mitigate it.
This is really why we started the company.
This was like our initial focus
and still is our most important focus.
But yeah, we need to address this.
So is there a power switch in the back of your office
that nobody knows about where you can just pull?
It's like that thing in Jurassic Park, that giant.
Yeah, it has to be big and dramatic,
but you pull this big thing
and it shuts down all the systems if we need it.
Exactly, exactly like that.
Okay, good, good.
I'm glad.
I feel better now.
Okay, and it works even if you're traveling, right?
I mean, yeah, okay.
Anyways, so let's talk about regulation
because again, I think what's really unusual is
this company is a few years old,
but really for the consumer,
it's like less than a year old because of chat GPT.
And yet here you are, traveling the world,
meeting leaders globally to talk about
the importance of regulation.
And not only are you doing that,
you are probably one of the most vocal people
saying we need it.
And not one of those,
we'll regulate ourselves, leave us alone type of things.
You are saying governments need to step up,
understand this and get involved.
This is very weird.
This is not like how most startups operate.
What's going on?
Well, again, we started the company
because we were nervous about AGI risk
before people even talked about AGI.
And now I think part of the reason we deploy systems
is so that people confront the technology, feel it,
understand the risks, the benefits.
And now a lot of other people are also very excited
but sharing the concern.
I think this is a special moment
where the globe can come together
and kind of get this right.
And we certainly would like to try to do that.
So let's talk a little bit more about AI in India
because it's so unique for us.
And there's so many interesting use cases
that are very India specific.
One of the obvious questions we think a lot about
are languages.
India has one of the largest depths of languages,
hundreds of languages in the country.
Now AI is by and large trained on what's publicly available,
what's available on most of the internet,
which is inevitably gonna be mostly English,
probably a lot more Western focused
in terms of just the sheer quantity of stuff
that goes into training.
How do you think about biases?
How do you think about inclusivity?
How do you think about multi-lingual countries like India
and making a product that's relevant,
that's useful, not just for all of us fancy people
sitting in Bombay and Delhi,
but for everyone in the mass of the country?
Yeah, it's super important to us.
We had a big step forward from GPT 3.5 to 4
at non-English languages.
So GPT 4 is pretty good at say the top 20 languages
and okay, it may be the top 100.
We will be able to push this much further.
It's challenging for us for very small languages
spoken by only a few tens of thousands
or hundreds of thousands of people, that's difficult.
But the systems are fundamentally gonna be very good
at this, I think, and it's important for us to do.
Now, as you were saying, it's not just the language,
it's also the history, the culture, the values,
and we want the entire world represented in here.
There will be some areas where the world's got to agree
on like here, the sort of global bounds of the system.
But mostly, if you wanna use it in the US or in India,
that can be under a different legal framework
and then in different parts of the culture in each place,
it'll be very different.
And I think that should all be represented in there.
We recently launched a new program to give out grants
for people that want to run experiments
of the ways we can do this, the way we can collect this,
but we really, really want to.
You know, India has been particularly unique
and successful globally at building a lot
of the underlying technology stacks
to support new innovation in digital with India stack,
UPI, Aadhaar, things like this.
Do you think India should build its own LLM, AGI, AI engine?
You know, in some sense, should we think of this
a little bit like nuclear technology
where every country should be building
its own capabilities and a little bit more nationalist
in the way we think about this?
I mean, how do you think, as a country,
we should think about AI as something in a sovereign sense?
First of all, it's super impressive
to see what India has done, I think,
in a way that really no other country has
with these sort of saying we're gonna do national technology
really well and make it a really like a national asset.
In terms of AI strategy, I think there's a lot of things
that can work.
I think this question of sort of AI sovereignty,
none of us have an answer to yet,
feels like it's gonna be at least somewhat important.
But the main thing that I think is important
is figuring out how to integrate these technologies
into other services.
And that is an area that I think governments
are behind on and don't have the answers to yet.
But I think hopefully we all start to use LLMs
to make government services way better,
both from how do I enroll in this program
to how do I get better healthcare?
But if you're in the Indian government,
should you be like, we need to set up a team
of crack engineers to build our own open AI?
I mean, is there a concern for us to say,
are we depending on, for fundamental infrastructure,
are we depending on something
that's not owned by our country?
Yeah, I think it is good to have certainly
some sort of AI research effort.
What exactly that should do?
Should that be training ground up LLMs?
Should that be pursuing new research directions?
Should that be focused on fine tuning open source projects?
I think there's a lot of options there,
and I don't yet have conviction on the right answer,
but some nationally funded AI effort feels like a good idea.
One of the things that I think is so interesting
is that open AI straddles this line
of being a non-profit and a for-profit.
And I don't know if I fully understand it.
I don't know if many people do.
I know you've raised money from investors
and Microsoft is definitely one of your shareholders.
When we think about it,
do we think of open AI as something
that's here for society to do societal good?
Is it here to make money for its shareholders?
Is it both? What happens if those conflict?
How do we think about that?
If they conflict, we're definitely here for the societal good.
That's super clear,
and that's why we put up with all this complication
in our structure.
Can you help us understand what exactly does it look like?
So there's a non-profit that has a board
that governs this thing that we call a cap profit,
where our investors can make a certain return.
But if we ever need to make a decision
that is in favor of societal good,
but not in favor of our shareholders,
we're set up to do that.
And one of the most controversial things I heard
was that you don't own equity in open AI.
Why is that?
What's going on?
I mean, it started just as sort of this quirk of our structure
where we needed non-conflicted people on the board
who didn't have equity, a certain number of them,
certain percentage.
And then I kind of just never got,
I forget about it until it comes up
and something like this,
but I don't think it's like a particularly noteworthy thing.
Like I made a ton of money early in my career.
I actively invest, so I expect to make a ton more.
I get far more value from,
even like personally, selfishly speaking,
I get far more value from all of the other sort of benefits
that come from running open AI,
a very interesting life than I would for more money.
But most of all, I just believe that this is gonna be
the most important project of our time
and I'm super grateful to work on it.
If you need me to like send you reminders to keep up on it,
I'm happy to do that, just let me know.
So look, a lot of people have flown in here
from all around the country to come hear you
and while understanding all this theory about AI is cool,
help us do our jobs better.
I wanted to put you in a couple of roles and tell me,
okay, you are now the CEO of a hospital in India.
What should you do?
And not theoretical, go hire a couple of people,
help me do my job better, be my AI for a second here.
One of the things that we have heard from a lot of doctors
is that they're using chat GPT with GPT for
to help come up with new ideas for tricky cases.
So input the symptoms, maybe the test results,
say I can't figure this out,
what are some ideas for the differential diagnosis?
And in many cases, getting great results back.
Awesome, now let's say you're running a bank,
what do you do?
This is like rapid fire,
like we're all taking notes to do our jobs better here.
Like a sort of traditional bank branch on the street,
that kind of bank, not like an investment operation.
Yeah, like a traditional bank that issues credit cards
and checking accounts and all that stuff.
I think I would try to just like,
on a very brief little side journey of my career,
I once like helped build a mobile banking app.
On the side?
No, no, it was like, yeah, whatever.
I still think the consumer experience of banking
is terrible and a lot of it could be replaced
by chatting with an LLM.
That's interesting.
Let's say you're running a university, you're a chancellor.
I mean, we've all seen how chat GPT
can definitely affect the education experience.
Now let's say you're running a university.
Yeah, that one I think is pretty clear.
I would just like go redesign the education experience.
I would have the equivalent of like personalized tutoring,
interactive textbooks.
I would integrate it into like all parts
of the learning process.
Now just totally theoretically,
let's say you're running like a large news media company.
Real tough.
In like a market like India, like just as an example,
what would you do?
And let me just get my pen real quick,
but yeah, what would you do?
Just tell me.
One of the things that, you know,
there's been a lot of controversy about whether
this is going to be good or bad
for the publishing industry and news in particular.
One of the things that we've heard from journalists
and reporters who are actually using the product
is that it helps them do the boring parts of their jobs
better and they get to spend more time reporting,
talking to sources, thinking of ideas.
And so I think I would just like encourage everyone
to just start using it.
And now let's say you are the ministry in India
responsible for overseeing technology, AI, et cetera.
You know, what would you do in that situation?
Like what would you be doing today as a regulator?
I would say, you know, we have the G20 coming up.
India can play like a huge role here
in global conversation about what this sort of
international regulatory thing might look like
and we are gonna really focus on that
between now and September and make sure we prioritize that.
Can you tell us something that you haven't told
other people about what's coming from open AI?
Like maybe just some insider information
that we could use in some form or curve.
You know, we kind of tell people what we're working on.
Like it's gonna get smarter, it's gonna get multimodal.
We're gonna try to like teach it to generate new ideas,
come up and help us like discover more new science.
We're going to reduce hallucinations.
We're gonna give users like more control
so no one feels like it's biased
or at least it's biased in the way you want it to be biased.
We don't have like a lot of secret plans here.
I think always as a company to our strength and weakness,
we just sort of say what we think
and what we're gonna try to do.
It's amazing.
Now, one of the most amazing things about you, Sam,
is that you are running what is going to be
one of the most impactful companies in history.
Whenever people say impactful, they leave out
whether it's gonna be a good or a bad impact.
That is a very purposeful leave out
because we don't know, right?
But you're gonna shape the world with this.
We know that.
And this isn't your only job, as I understand,
or maybe it's not your only purpose.
It's my only like operating.
It's the only thing that I'm like in the trenches for.
So can you tell us what else you're doing
that's like exciting you or motivating you
outside of an open AI, your side hustlers,
if we put it that way?
I think we're gonna get nuclear fusion to work
in the next few years and importantly,
not just as a scientific demonstration,
but as incredibly cheap energy and at global scale.
So I think other than AI, if you could do one thing
that would like really help the world get richer,
increase the quality of life, it's very cheap energy.
I think there's like a huge historical correlation there.
And I think we've all like lost sight
of the appropriate ambition level here
of how much of an impact we could make.
But if we can get fusion to work
and if we can make enough of it for the world,
then if it can like cut the energy cost 10x plus,
that's pretty great.
I'll pick that one.
So your side gig is nuclear fusion?
I don't, I'm an investor and sort of like helper of that one.
It's amazing.
So just so I understand you're revolutionizing
artificial intelligence and energy.
Not you, specifically you, but these are like.
I think those are the two, my basic model of the world
is that the cost of intelligence and the cost of energy
are kind of what compounded everything else.
And if we want a radically better future,
those are the two things we should focus on
trying to like make abundant.
It's incredible.
So my last question for you is,
what is the most exciting thing that you are seeing
globally in your own company?
Like what is the thing that outside of everything
we are all talking about and seeing that excites you
about where open AI or even not just AI in general,
what's the most exciting thing ahead?
I mean, I think it's this generation
of new scientific progress.
If these systems can really contribute
additional understanding of the world,
better technology, better science,
that is like the sustainable way
that the world actually gets better
and that the quality of life increases.
We're not there yet.
It might be soon, it might take a while,
but I believe we are gonna get there.
And that will, I think we all underestimate that.
It's amazing.
Sam, thank you so much.
Thank you.
To be clear, Sam asked me to talk less
and to open it up for you all to ask more.
