Welcome back to Demystify Sci, where today we are exploring how to achieve the impossible.
For this conversation, we have with us Jim Keller, who is a microprocessor engineer who's
worked at places like AMD, Apple, Tesla, and currently is working on a next generation of AI
compatible chips that are going to be a competitor with Nvidia for all the stuff that they're doing
for artificial intelligence, and also has this wild idea for a startup, which is already in
progress for being able to create a semiconductor fab that is tabletop size. He's also got the idea
of being able to 3D print a car for $5,000, and so this is a guy who's worked for his entire life
at these enormous organizations that are able to achieve things that across the board people say
are not possible. And so we wanted to start with him to figure out what does that actually look
like? What are the things that go into making a successful company? What are the pieces of
culture that are internal to the company versus the pieces of culture that are internal to the
humans within that company? And how do they play together in order to let people achieve
what seems on paper absolutely not going to happen?
Which is very improbable as a perspective considering he's actually so cynical about
the lifespan of institutions and of these companies. He recognizes there's a cyclic nature
to the boom and bust of the production in all of these different organizations.
And so he's pulled out these really fascinating trends for what it means for a company to reach
that pinnacle and why they can't stay there. And the same thing can be applied to our scientific
institutions, our government, and we go into all of this. So it's a really, really refreshing,
inspiring perspective that I don't think we've seen on this show so far.
And honestly, it's also just really cool to sit down with somebody who has worked on the chips
that have been in the technology that I've used my entire life and to discover that he's thinking
about physics and science and human nature and the fractal arc of reality in this way that actually
gives him the ability to come up with ideas that other people just seem to not have access to.
So we get into all of that. It's a really good conversation. Hopefully we'll be able to have
him back to talk about some other stuff because he's been in contact with these titans of the last
50 years, Elon Musk, Steve Jobs, and just has a wealth of experience in the world
that I think would be really interesting to talk more about. But in the meantime,
I want you to consider coming over to our Patreon. So we are a Patreon-sponsored podcast. We take no
ads, we have no commercial sponsors, and we really, really, really want to keep it that way
because that aligns with the way that we see the world functioning. We make something that is useful
to people and the people who like it support us and let us keep doing it. And so if you've watched
a couple episodes of the podcast and you enjoy it, then consider coming over to patreon.com
slash dmstify.ci and joining us for just a couple dollars a month. A fistful of dollars if you like.
Indeed. However, many dollars fit into the fistful that you would like to take, happy to accept.
You can put different denominations in a fist, it turns out.
That's true. And also, something else that you can really do is if you're watching the podcast on
YouTube, leave a comment. If you're watching it on Spotify or any of the podcast stores,
perhaps rate the podcast. These are all things that help us boost ourselves algorithmically,
and they don't cost you anything except for a few minutes of your time.
And it helps us get better guests too, which is ultimately going to serve you guys. So
do it. All right. Hopefully, you will follow through.
Hopefully, we will see you soon. And for now, enjoy the conversation with Jim Keller.
I came across a quote that I think is an unfortunate article about you where they said
that you're really a fan of the Steve Jobs aphorism, which is that once you know what to do,
you shouldn't work on anything else. And I wonder about that in context of institutional longevity,
because it's really easy for an institution to continuously come up with a new thing to do and
keep trying to work on something different. And so in addition to knowing what to do and then
working exclusively on it, do you think that there has to be a sense of an expiration date?
Yes, probably definitely. So this is a, yeah, this is a really complicated question. And then
I was part of, you know, the demise of digital equipment, which was a great company.
And we went from growing and everybody there was excited. A friend of mine's wife said,
what do they put in the water? All you guys do is work or talk about work. It's really fun.
And then I've talked about this in a couple, like financial analyst seminars recently that
like when I joined digital, they were very proud of building low cost open computers.
And they were winning against IBM. And then IBM, and people said nobody went broke by in IBM,
home digital was building this lower cost, more open computer that people could buy and do stuff
with. And 10 years later, and only took 10 years, they're competing against sun and silicon graphics,
who are building lower cost, easier to use computers. And the digital sales guys, some of
the same people, I suspect, you know, poo pooed the sun systems as toys and cheap and little
and non professional. And, you know, digital went through like a literal collapse.
Their best revenue year was on falling sales rising prices. And then they just lost the market.
And it was also interestingly enough, we were going bankrupt at the same time we were building
the world's fastest computers. We were building a new generation of product that was demonstratively
be better than anything we'd ever made, better than son by a lot, and went bankrupt at the same time.
And so it seems impossible on some of them. Yeah, yeah, it's a miracle. But there was all
kinds of things. So, so you have to, you know, I tell people, sometimes ask me, like, how do you
manage a team? And how do you do something? And people simultaneously, let's say, underthink it
and underdo it. Like, people will read one management book, a frequent question I get is,
which book should I read? Because I say I read lots of books. I mostly say all of them. And,
you know, I've been trolling some of my internet friends by releasing lists of five books, but
they're, they're relatively randomly arranged, you know, book on management, a book on science
fiction and the book on, I really like Katie Byron Katie's book, loving what is, you know, and,
you know, so, but now, as a book on management, that's not obvious, but it's a great book on
management. Same with the five love languages, which is, I think, a marital book.
And, but it's complicated, you need lots of different frameworks to figure things out. So,
so there's a great example that the company could literally
revert almost everything that made it successful, then go bankrupt while building a great new product.
And mostly, I think that made it successful. Yeah. Yeah, so we're building alpha computers,
which had 64 bit addressing, and it was one of the better, better ones of the early 64 bit
computers. And one of its charms was we could adjust very large memories from some server
applications. That was important. But the memory group at digital had been making lots of money
for years and they'd been raising prices. They literally created an industry around
digital making plug in memories that were cheaper. When company EMC became very large and successful.
So as digital brought alpha to market, the memory guys were raising money,
raising memory prices, and we didn't sell any memory. So, so that one of the virtues of the
computer was addressing more memory and memory prices are so high, that our customers
were buying memory from a competitor. Like, like in the world of like, how dumb could it be?
And as engineers, we knew this was happening. And the memory group was working with us to
make it harder to plug in memory and engineering team made it easier to plug in memory.
And there's no intermediary that could be like, Hey, we're working against each other.
Well, so, so this is where you get it. So Ken Olson was the founder and he was still there,
mostly, although he was replaced with Bob Palmer. So Ken have this kind of do the right thing attitude
and, and, you know, let people go off and do their thing. But the problem is the memory business
was a business and the server business was a business. And the memory business made more money
by actually lowering the server business substantially. And that's where, you know,
the uncoordinated action kill them because usually, you know, you, you would think somebody would say,
Hey, this doesn't make any sense. We're killing our business by not doing something.
But it's really hard and mostly not companies when they're non founder run,
you know, run the ground at some point, because a founder is optimized for the longevity of their
baby. And non founders frequently optimized for their own personal income.
So how many people were digital equipment at that point?
The peak was 110,000.
That is enormous.
Yeah. Yeah. Yeah. Back in the day, it was a Arctic cap was 14 billion.
I worked on a computer. We, you know, back to 800, we sold $5 billion worth of
computers at a half a million a piece. It was, it was really amazing.
So I like, like I said, so you need a couple things. So there's the life cycle story, which is
you know, in human beings to the zero to 20 year, you're a kid learning stuff. And then 20 to 40,
you find your place in the world. And then 40 to 60, you should, that's a mobile, exploit your
expertise. And then 60 to, you know, death, you enjoy a retirement or your enlightenment.
Or if you're a sociopath, you might continue to operate at some high level of manipulating
reality, right? And so companies go through those cycles. And a lot of companies fail long run
because they just get old. And some companies get restarted, like, you know, both Apple and
Microsoft were essentially rebooted, you know, Apple by the founder and Microsoft by
Satya Nardella, which is, which is amazing. Like, nobody saw that coming because that company had
seemed to have gotten into the, you know, they had cash cow products and they were soaking the
customers for it. So it's very hard to reboot a company substantially, once you pass a certain
point. But anyway, it's a framework. And there's another framework, which is organizations tend
towards order. And the order slowly like a startup is very chaotic. And a friend of mine drew this
graph of, you know, the x axis is chaos at the origin and then order. And then the y axis is
productivity. So for a while, as you increase organizational procedures and process, you get
more productive, but at some point you get less productive. And the trick isn't figuring out
where you should be on the curve, you should be at the top. It's like, you know, you curve, right?
The trick is staying there. Because once you start organizing for productivity,
more order always seems like the right answer. And then a lot of companies, the people who are
very good at organizing things, sort of outmaneuver politically, the people are good at inventing
things. And if there's nobody going, wait a minute, we need a new product. So it's very
difficult to escape that trap. And does the size of the company influence that as well?
Well, yes and no, you know, like there's many companies who go through, you know, never get
very big, but still become bureaucratic. But it probably gets harder to avoid it as you get bigger.
Like, you know, a lot of the big tech companies that we think are, you know, great,
are famously bureaucratic, you know, like Google and Facebook. And then there's some
companies that are famously not like Amazon's run as a whole bunch of small silos that,
you know, compete with each other. And I'm not sure what the current lay of the land is at
Microsoft. Apple under Steve Jobs was mostly small teams and he didn't trust big teams.
But since he passed away, the company has become unbelievably large and successful and all the
teams are huge. What was the secret to these reboots that actually worked out?
Well, Steve Jobs was a very strong belief in product. So we, I had a friend who worked for him
at the time and he said, we have 10 business groups and they're all losing money. The company's
losing money, but on paper, all the groups are making money. And that's because they were doing
transfer costs, you know, bureaucratic shenanigans. Like, I'll make something for you and sell it to
you as I have a profit, but then you sell it to somebody, you know, so it was just a mess.
And there's too many competing products. And if you have product A and product B,
the marketing guy will say, make a product between them. And, you know, you'll have a
better product line, better coverage. So Steve Jobs, he canceled apparently all the business
units, he canceled the products, he canceled, fired most of the managers and he created the
same as 2x2 Matrix, which was consumer pro mobile desktop. He said, we're going to make four products
and everybody wants one of those. Like if you're a professional and you sit at your desk, you want
a desktop pro computer. If you're, you know, working, but you travel, you want a professional mobile
computer. That was the MacBook Pro, the Mac Pro. And then the iMac was the famous translucent,
you know, fun computer for the house. And so, so he created those and then he said,
we'll make each one of them the best we possibly can, which means we won't get all the customers
because there'll be gaps and holes. But you could trust us that if you buy iMac, you'll be very happy.
And, and then when I was going really well, then they did the iPhone. And then he really believed
in the iPads. I was there during the, I guess the third iPhone chip in the start of the iPad.
And then he really believed in TV and he told us he'd cracked TV. But he passed away before he
built the product. And I don't know what he cracked because it wasn't the Apple TV product,
he didn't like that very much. But he was very focused on the next thing. And then he, Steve famously
said, like, so, so technology is often what I call a cascade, instead of cascading dimension
return curves, you go up and it plateaus, and then there's a new invention, you go up into plateaus.
So we went from rotary phones to button phones to touchscreen phones. And each one of them,
when it first started, so the first, you know, touchscreen phones weren't as good as the buttons.
Right. So black, blackberry users laughed at the touchscreen phone people. So the screen was
bigger, but your touch wasn't accurate. It was slow sometime. I had friends that would prove to me
they could type faster on blackberry than a touchscreen phone. And yet the blackberry died
because they were married to the old technology. So Steve's point was when you go from one
technology to the next one, you always go down that up. Right. You're, you're jumped.
You're, you're by definition jumping from a highly refined endpoint to an unrefined starting point.
That depends on when you jump, right? Because the people who had
And that's the thing. As he said, any idiot can show you could wait until it starts to be refined.
Now you're behind. So the wind, if you wait for other people to do it, you could have a business
strategy of being a fast follower. That's actually a business term. But if you always wait, you'll
always be second. And when people create new markets, it's amazing. The digital and phones to,
I mean, Apple and phones, we did 64 bits before anybody else. We did high resolution displays
before anybody else. We did great cameras before anybody else. We did thin phones before anybody
else. And each time it took a couple years for people to catch up. So yeah, it's a, it's a funny
thing. So was this, this was the reboot strategy? Yeah. So this was after like Steve's got thrown
out of digital out of Apple, partly because he couldn't work with people and partly he made a big
back on the big bed on the Lisa and then the factory for the Lisa and the original Macintosh
and it didn't go well. And he was famously hard to work with. And so when he came back,
Apple bought next. And next was Steve's company with a new operating system.
So like Apple at some point needed to do operating system they bought next. And then
for a bunch of reasons, I wasn't there. He maneuvered his way into back into being CEO and then
you know, launched into a famous reboot of Apple, which, which by the way is relatively
unprecedented. He said that Microsoft managed to do it as well. What was the story there?
And that's not a non-founder. Yeah. So Microsoft, everything was Windows. They had Windows,
you know, Windows phones, Windows PCs, Windows mouse. And the world was sort of shifting away
from Windows and Windows had a lot of problems. Like it was going mobile and they tried to build
something called .NET, but everything they did was proprietary early and the company was suffering.
And Satya pivoted the company to being data first, essentially. He got rid of all the Windows groups.
We have, I suspect they actually let go a lot of people, including senior management.
So Microsoft built this beautiful tablet computer. I know people who made it,
but the group that did Office Suite wouldn't port their software to it.
Right. And nobody could tell them to port. Like they ran a business and they said,
doesn't make any business sense for us to port the software. So under Satya, that all changed.
What's that? Because it would be packaged with the tablet when it was sold. And so it wasn't going
to make money. No. So, so this is where you, so you guys have probably read Shakespeare, right?
Some, not the time. It's good to read Shakespeare. Right. So Shakespeare is always the drama between
the king, the ministers, you know, the poor bastards and the hero.
Right. And so big companies, when they become bureaucratic, you know, if they're run by somebody
who then has some number of people running organizations, let's call them the conniving
ministers, right? And they are, let's say, buying for favor from the king and benefits
by mostly messing with each other. And the king isn't king because he's stronger than all of them.
He's stronger because he plays them against each other and they play against each other.
But at some point there's, let's say, a real problem, like windows is going down or the
Macintosh is broken. And then the drama is, is how does it play out? Because the king can't trust
the hero because the hero will replace them. The poor bastards are all rooting for that.
And the ministers are trying to get the hero on their side because then they can win.
And it's very difficult in a lot of companies for anybody to,
unless there's a really strong founder and a really strong culture.
The picture that you're painting makes it seem almost miraculous that anything gets done.
Oh yeah, that's actually true.
Now, I read this funny, here's a funny one. So there was a study about the differential
growth between China and Vietnam. This was 20, 25 years ago. And they basically said there was a
10% difference in corruption between the two countries. I forget the exact numbers.
And as a result, China was growing at 10% year over year and Vietnam was growing at zero.
And the corruption number was big, like 50%.
Which was what were corrupt?
According to this study, I don't know if that, you know, it's true. But, you know,
people look at spectacular growths and think, wow, that's amazing. Like, they must be all
working really hard and doing really good things. But it could be they're producing 4%
you know, real benefit year over year, but compound growth of 4% actually over,
you know, 10 years is a lot. Right. And then in our big economy today with all the companies,
like there's lots of strategies. So new technologies are mostly exploited by new companies.
Like when Google was growing fast, some big companies had search engines, but they were all
terrible. And Google grew and, you know, for a while, for a long time, they professed, you know,
they do no evil and everything was the good of humanity. But the way they made money is
serving ads. And then what happens is they get really good at it. And the more ads they serve,
you know, the more money they make, and the more they get you to look at them, the better
and then they go back to the people who want to pay for ads. And they say we can manipulate
the results to give you better responses. And now you have their company mission,
which is to make all the data available to everybody, but their business says we're going
to make a lot of money. Their advertisers, you know, would like, you know, differential
benefits and the consumers have options. Right. So that's a complicated thing.
And then you could cast that as a Shakespeare play and assign the, you know, the villains and
heroes as you want. But it's really complicated. And this happens all the time, like every company
goes through these cycles. Do you have any insight into the day that Google dropped its do no evil
slogan? Yeah, long after that was true.
You know, so then there's, well, companies go through this cognitive dissonance phase,
you know, they have a corporate vision about who they are and what they want to be. And then
they have a bottom line to attend to, and then the business practices that accomplish that.
And then I'm sure some engineers said, Hey, we can't do X, Y and Z because of our vision. And
it was like, Yeah, well, we haven't been doing that for years. And, you know, it's, it's, it's
complicated. You know, most people at Google want to do the right thing. And most businesses want to,
you know, be, you know, let's say as moral as they can be. And then the market
kind of does this interesting thing, which is as companies become monopolies and start like
squeezing their customers, essentially, you know, it's easy to cut your R and D and, you know,
spend more on sales and make more money. But then there's a competitive thing.
Like the US car industry, there was the big three, and they were all playing the same game
and gaming each other. And when Toyota showed up, they laughed, it was a shitty little car,
and Toyota made a better and better car. And all of a sudden, they're on the back foot,
you know, trying to catch up with Toyota, like you saw that happen, they actually went, some
problem went bankrupt. And then the government bailed them out because there's, you know,
like the layers of complexity is they're so high, it's amazing. Like,
there can be chains, depending on that at some point. Yeah, yeah, there's the politicians and
the unions and the jobs and the states and the distributed manufacturers and,
but they all going through these cycles of their internal growth of technology cycles of
competitive cycles. Yeah, it's quite amazing.
Hey, folks, quick interruption. I really need you to come over and check out our Patreon page.
You can give as little as a couple of dollars a month, or you can give us a fistful of dollars.
The point is this program is entirely supported by people like you who are enjoying this program,
not many sponsors, not many ads, we want to keep it that way. So please consider coming over
and checking out how you can just give the tiniest amount to support this project into the future.
Thank you. I'll see you there.
So do you think that you can tell when an organization is starting to get to the place
of decline early? Or do you think that it's always something that you can only really tell
once the decline is fulfilled and then you look back and kind of match things?
Like, is there a predictable time length, even? Is there a time scale? Is it size dependent?
I'm not even thinking necessarily about time scale, that would be interesting. I'm thinking
more about it. In terms of things that happen, like patterns that you start to see emerging
and people starting to behave in certain ways. Like you're talking about the drill equipment where
you have the the branch that's dealing with memory and the branch that's dealing with servers
completely operating at odds with each other that serves as this harbinger of chaos to come
unless somebody can come in and, you know, make the vessels behave. So in retrospect,
it's way easier. Somebody said, you know, the past debanker, you know, they were going to
bankruptcy and they said it happened slowly at first and then all at once. And that's often,
so digital went through this rising revenue on falling unit sales. That's a really good sign.
You see companies, I worked at a company that was basically capitalizing cost. So if you build a
product and you have to buy a component to put in that product, that's an expense. But if you build
a factory to build that component, that's capital, right? And so for financial accounting reasons,
capital is deductible and gives us a good thing. Capital is an asset versus expensive are a problem.
And so as companies get bigger and mature, they get, let's say, sophisticated economic
tools and some of those are really good, because we have complicated tax rules and international
business rules and reporting roles and you have to know what they all are and you have to play the
game. Otherwise, you won't report making any money. But you know, the nominal timeline looks
something like the life cycle of a human being, which I said is 20 years, 20 years, 20 years,
20 years. But some of that has accelerated like the lots of startups go through five to 10 years
of figure finding the real place in the world and then ramping. Some companies ramp really quick,
like Google probably would be wandering around for five years. Like they were making real progress
and lots of people like them, but they weren't making any money. And then they ramped pretty hard
for over 10 years and 15. They still make lots of money to a lot of the AI companies right now,
right? Like OpenAI and Anthropic, their ramps are super big. Yeah, that's a, so there's another
phenomenon. So independent of the business cycle, there's kind of hype cycles. AI is
as a strong hype cycle partly because there's a lot of revenue and market cap based on it.
So there's a little FOMO going there, which is, you know, let's, let's get involved and do something.
How much of that can you tell how much of it is hype and how much of it is real? Because I mean,
you obviously can't really trust the representatives of a company to tell you accurately
what's happening or what will happen. Promise is these massively intelligent,
general intelligence machines that will one day outshine humans and everybody's pointing to the
exponential curve and like, we're, it's going to continue forever, but anybody who looks at
exponential curves also knows that sometimes they're logarithmic and they just stable it.
Yeah, yeah. Yeah, they're, they're escars, not exponentials. Yeah, it's pretty hard to say. So
the, in the internet boom, there was a whole bunch of companies who clearly had to achieve some network
effect to be successful. So two good examples, one early was PayPal. So they were paying their
customers to recommend them to other people. So they spent hundreds of millions of dollars in
customer acquisition with actually no plan to make any money. But they got big enough and they
started to make money. And then there was other companies who said, Hey, we're going to do the
same thing webband and there was a pet company that was doing online stuff. So they were paying,
they spent billions of dollars in customer acquisition and then didn't keep any of them.
And just burn the money law. And Uber was the same way. Uber spent billions of dollars in
customer acquisition. And, you know, Uber used to be a really good deal compared to a taxi young
price. Like the convenience is a huge win, but the price was also better. But when they slowly
started working on making money, when they had acquired enough customers that the argument of
customer acquisition was kind of dumb, they started raising prices. And now it's not obvious that
they're cheaper than taxis. They're more convenient. And we got used to them. And then they're,
you know, 10 years of spending money to get customers, you know, they put a lot of taxi
companies out of business. But, you know, it's, it's not always obvious which way it's going to go.
You know, there was a lot more webvans than there was PayPal's.
But these are, you know, business cycles, which are really interesting. The internal dynamics. So,
humans are, you know, when we, when you build organizations, humans are very good in groups
of five to 10. Because that's essentially a family group. And we're very good in groups of like a
hop to 100 or so. Because that's like a tribal group, like we can map them really well. But when
you want to grow past 100, suddenly you need a whole different level of infrastructure.
Because now you have one group working on something to deliver with another group where
they don't know anybody. And, and this is another one of those dynamics when, when you have a
strong vision and you're growing fast, and there's too much to do, you know, sometimes those
organizations grow naturally, sometimes you really have to work on it. But then when a company slows
down and you have all these little groups of people who don't know each other very well,
and they're exchanging, you know, work for a boss or some reward, that stuff can get
gained pretty hard. And then companies become bureaucratic. And then there's the famous line
about bureaucracies. Like, bureaucracies are inevitable with human beings, apparently. And,
you know, it's, it's not whether you want one or not, it's how you manage it.
Because at some point the bureaucracy will, like somebody said, you know, imagine that
bureaucracy is always run by your worst enemy. And, and for a lot of companies, that's actually
what ultimately does them in. So you have business cycle dynamics, which is really interesting. And
then you have this organizational dynamic. And that's been studied pretty widely, you know, like
there's a, there's one line that which is 20% of the people do 80% of the work, which is fairly
common. And then there's another one, which is the output of an organization is the square root
of the number of people, which has, you know, been studied and they're stated behind that.
And then you might say, well, then we should keep the group as a whole bunch of small teams.
Some people do that, but sometimes that's impossible. Like you're doing something really big
and hard and you actually have to figure out, like, well, a thousand people isn't as efficient as a
hundred people. You can get a lot more done with a thousand people than a hundred.
And is it just the challenge with technology and large projects is that you can't break a project
down into small enough chunks that you can get people to work in these small groups? Like,
I'm thinking for, you know, really, no, that's actually that you put your finger right on it.
Like one of the fundamental things is humans aren't very smart. And we're not getting any
smarter. So we don't solve harder problems because we're smarter period. Well, I've been
working in engineering for 40 years. I don't see any evidence that anybody's any smarter.
Some of the tools we have are really good. Do you see other people are dumber?
No, not really. Okay, that's good. That's really no.
I'm sure the answer is going to be yes, but that's good. I have an aunt who's very smart and very
well read and she was complaining about young people. So I found this letter and I read it to
her and she said, that's just it. People don't read enough anymore. They don't write. They don't
do this. They don't do that. And I said that was written by Ben Franklin. It's such a great,
you can probably go Ben Franklin's letter about, you know, the inadequacies of young people.
So when you think that, that mostly just tells you your age.
So all human beings around 50 years old or so start to suspect that 20 year olds aren't very
smart. I've always been an old soul some early at that arrival. So you might. Yeah. So if you're
early, it really depends on where you go. Like we hired college kids at Tesla. They were so smart
and hardworking and ready to go. And then I'm, you know, and I talked to friends at another
big company and they're the people they hired for college to be honest, weren't very good.
But that's because the students were selecting based on the company. You know, the super smart
ones wanted to go test their metal at a place where they knew they'd be stressed. And the students
that were sort of average and wanted to go along the get along and get a good paycheck.
We're picking a company that was literally easy to work for and do nothing.
And I mean, I'm just thinking I was looking at that's a really funny drawing
hand drawing diagrams for, I think it was like rocket propulsion systems before they had computers.
And so it's this photograph of this gigantic piece of paper. And there's like five engineers
that are hand writing the calculations and drawing trajectories. And I look at that. And
to me, it seems objectively like a harder thing to do than if you have a computer that can do
the same thing for you. And so it's like, if the computers are picking up the slack,
then you wouldn't be able to notice the difference. But if you were to take the computers away,
would we still be able to perform at that same level? And that's, that's the part where I'm not
100% sure. It really depends. So you could probably coast way, way further knowing a whole
bunch of programs and tools. But the Tesla rocket engines are way better than the ones they built
in the 70s. They're just way better. And you know, they produce them for 10x less money,
10x less hours, they're reusable, they're more efficient. Like everything about them is better.
They're not even close. Modern cars are so good. Geez. I was in the Hyundai factory recently.
The time to go from, basically, what comes into the factory is these rolls of steel.
And they're random millimetres thick, depending on the parts. And four hours later, there's a car.
All stamping is done. They have a machine that rolls it, cuts it, stamps it, knocks it out.
They basically take every part and scan it with laser beams and they, you can mark them up and
correct them and tweak them. And then the robots will put the pieces together and spot weld them
all together. The damn things are near perfect. Amp machines are great, by the way. So they've
been using stamping machines forever. Like a stamping machine is literally a car of a shape
and a hard surface and then put a big weight behind it and drop it on a piece of flat sheet metal.
And sheet metal. Also the number one cause of workplace accidents.
Yeah, the modern stamping machines are all operated by robots. They don't let people near them.
Yeah, stamping machines are tough. I gotta tell you about Donut Factory and they're always losing
fingers over there. It's the worst. Yeah, yeah, stamping Donut. That's amazing.
You gotta cut them somewhere. Well, and then when you build a factory with robots and you're
at cause the robots are so strong and they move so fast that they'll take people apart.
So then the, all the factories are like built with this is the people's zone and this is the
robots on the pretty soon robots will be smart enough not to whack people. Like all the robots
we'll see. But at that point, anyway, it's like the robot containment zone as well.
What's that? I said, but at that point when they're smart enough, they can escape the robot
containment zone as well. So that's, that's a very large sort there.
Didn't you work at Tesla on some of the, the first, were you freaked out about these possibilities
when you were working on that system? Yeah, so I, I ran the hardware,
the, yeah, the autopilot chip hardware team. So we built a hardware three,
it's called the hardware three chip and started the hardware four chip.
And then also started Dojo, that Tesla super computer. And then for a while, the, the autopilot
software team reported to me, but that was sort of, you know, a random thing because Andre
Carpathi mostly worked for Elon and some of the software team worked for me and some of them
worked for Andre and we missed around. So that's a different question. That's a different question.
Am I freaked out that robots or super intelligent computers will impact humanity?
No, just the, these Tesla's, these self-driving cars, right? It seems like whenever you introduce a
new technology, somebody's going to have to figure out what's wrong with it. Like airplanes are
an example, right? They're, when they first build these jetliners, they're falling out of the sky
all the time. But now they're some of the safest ways to travel on the planet. And I, I remember
there was a few, maybe actually, I don't remember one really bad incident with a Tesla car mistaking
an intersection, a truck pulling out for an intersection, an intersection for white or gray
sky or something like that. There's been a couple of problems. No, we reviewed all the,
all the fadles and many of the serious accidents every week, clearly. Okay. So, so you're familiar
with the trolley problem, I presume? Yeah, which is you have, you have a switch and then on one
track, there's one person tied to the tracks on the other side, there's five people tied to the
tracks, you pull the switch. Yeah. Yeah. So Elon deeply believed you pulled the switch.
Right. Kill less people. So, so he said, oh, he said to publicly, yeah, we're going to make
cars safer. The only way to do that is autonomous driving and really good, you know, autonomous
driving software and computers. And, but, but as it develops, some people will die because of
defects in that software, but less people will die. I think. And then he also backed up that
commitment by making Tesla, like Tesla had some of the brush crash analysis software in the world.
And then the way they built Tesla's with the battery pack and the floor and the crush frames
in the front and the back of the car, and made it really safe. And so they were one of the first
to five star, you know, crash certification, which is actually mostly a real thing, by the way,
like some certifications that I'm skeptical of, but the crash safety people are really good.
And then the side impact crash and then, and then there's a really wild graph, which, you know, the
fatalities versus speed graph. So over 40 miles an hour, you mostly die and under 40 miles an hour,
you mostly don't. And so the mission was a, the raise the speed where you mostly don't die
and be lower the speed of the car to really fast in the event of a detection of an accident.
Right. Oh, go ahead. So, so yeah, so was it, was it daunting building a safety product?
Yes, definitely. Did we analyze it a lot and worry about it? Oh, yeah. So one of the guys who
worked for me, there was a radar product we had that mistook a truck for a sign and rejected.
So the problem was radar, it's a relatively low resolution and a small object with a right geometry
can look like a very big object. And so the radar's problem is false positives. So they reject
lots of false positives and it rejected the truck and the person dies.
And then when we took the software apart, we figured out why, like the filters,
the software using work very good. We rewrote the software so that we would detect that truck
properly and some other situations where the radar was not doing that good.
How safe are they at this point? These self driving software is compared to the average driver?
I don't know. I don't, I see Waymo and Waymo driving around San Francisco with no people
in the cars and I think they're relatively good. They overkill it really high on sensors and compute.
Tesla, Tesla's are not there yet. I have the newest version of self driving software. It's
pretty good. I really like it, but I wouldn't let it, you know, drive to work.
You wouldn't take a nap in the backseat? No, I definitely would not take a nap,
but it's, it's coming along. And then like Elon's belief is it's going to go in every
single car. So it can't cost 50 grand. So the Waymo solution is really expensive.
It has many, many sensors and lots and lots of computers and looks like a fighter jet or
something. It's got the cost of processors is going to go down to the degree that
the Waymo system isn't $50,000 anymore in like 10 years. Yeah, yeah, 10 years maybe.
Yeah. So there's like two schools. So this is again, one of those, you know, technology trends.
So sometimes you say, well, I'll build a computer or system big enough to do what I want and then
I'll cost reduce it over time. And then the other is I'll build the solution and the size that I want.
Right. And then work to make it, you know, the functionality fit the budget.
Right. If you look at computer technology over a long enough span of time, it definitely started
with we'll build it enormously expensive and enormously large, and then we'll scale it down.
Is it just that we've gotten to be sufficiently geared out that we can start working on
technological problems from the standpoint of now I have enough components that are
small enough and advanced enough that I can build small from the get go.
Yeah. Well, so yeah, there's a there's a funny trend line. So like every 10 years, we went from
mainframe, the mini computer, the workstation, the PC, the mobile. So that was, you know, every 10
years is about 100 times more computing. So on the transistors per year, about 10 x every five years,
it's pretty solid graph. And then what happened is,
like, like a PC wasn't 100 times faster than a mini computer, it was more like 10 times faster.
It traded some of the transistor, you know, performance, or just having less of them in
a different form factor. So, so if you look if you look at the trends of how many transistors
you have versus how many transistors were in the new cheaper product,
like the transistor count grew faster than, you know, so the budget was slowly going down,
which modulated the transistor improvement. The problem is AI, the AI you really want is like
a million times more than we have. In terms of driving or just in general? What's that?
In terms of self driving technology or just in general? Yeah, for a lot of things. Okay. Like,
like, like if you look at the, you know, the the operations in a phone chip, like phone chips are
20 bucks, right? And, you know, Nvidia's new GPU is 25,000. Right. And some of that's marked up
because of, you know, their market position and some of it's it's a lot of transistors and a lot
of heat and performance. So AI was an interesting step function, like when you went from work
stations to PCs to, you know, mobile, like, like the first PCs were obviously inadequate compared
to work stations. But the transistor count quickly, you know, sped them up. And then the original
phones were inadequate compared to PCs. But so then there's two funny things there. One is
whenever you start with a big software on a big computer, the software never gets simpler.
So when they went from work station to software to PC software, the mobile software,
each time they were rewritten, like PC software is written from scratch and borrowed very little
from work station or your software, right? Now, at some point, the PC got fast enough to run
work station software. But there was an evolutionary bottleneck that caused our big rewrite.
And then same thing happened with mobile devices, like the original mobile operating systems were
very lean compared to PC operating systems, that caused a really big cleanup. So the problem with
the Waymo approach that once they write all that software with all those computers and everything,
the odds of them, you know, making a 10x simpler by rewriting is kind of low. They're sort of stuck
at a higher cost basis. So I'm a little skeptical of the build it big enough to do the job and make
it cheap later, or hope that, or hope that that happens. Did you say that in the video ship was
$25,000? Yeah. Who are the customers for that? You know, Microsoft and Google and
Bank of America and lots of people. What are they implementing it in?
Just in their own software enterprise, like in their own computation back at home base?
Oh, yeah, yeah, right now, like all the big tech companies are in an arm race and they're all calling
NVIDIA to get allocation for their new best, but they currently have the best processors by,
you know, like functionality and, you know, obvious proof points. Again, NVIDIA is slowly
becoming the IBM of the AI year, I think. And like, we'll see how that goes. Like,
is it generally, I run an AI tech company. So I have opinions about it. But, you know,
like, I want to hear about that too. But is that generally the case that the first
frontline technology is bought by these, you know, miscorporations or, like you mentioned at the
beginning, digitally you said was selling a half a million dollar computer. And I'm thinking,
who's buying that? Yeah, like a lot of people. So when digital started, they made logic boards.
So they made little boards as big with transistors on them. And they had products called like AND gate
and OR gate and right. And then they worked themselves up to making, I forget the original
number, but, you know, they were making computers in, you know, one to 10,000 zone.
That were, you know, slower than IBMs, but, you know, 10 times cheaper. And people loved them.
And then they built the 1144, which is probably 10 to 50,000. And then the 1170,
which is a little more expensive. And then the Vax 80 and 100 or the Vax 780
was a 1 million instruction per second computer. It sold for like 100,000 to 200,000 dollars.
And they sold, you know, for the time, a lot of them. And then the Vax 80 and 100 was faster.
And the cheapest one was over like 150,000 and the high end was 5600,000 dollars.
And they sold them to banks, businesses, all kinds of people.
Was the military a customer as well?
Yeah, the military bottom, it was all over the place. But at the time, the half million,
the high end Vax computer for half a million dollars was a great deal compared to the IBM solutions.
And, you know, they were selling a lot of them, but then they were planning like a
computer after that was even more expensive. And so this is another anomaly that happens is
if you like the high end technology trends that you'll see in like forms or business review or
something shows this falling price of computer, but generally speaking, in each kind of epoch of
computing, the leaders slowly get more expensive. Like Sun started, you know, $3,000 workstation
when they went out of business, they were selling $100,000 servers. So there's a funny thing, like
it's sort of like the Ford Mustang, when the Ford Mustang came out and was 65,
was this beautiful little sports car by 72, it was just bloated, you know, because everything,
everybody's idea maybe a little bit bigger, let's put a little bit bigger engine, a little bit
bigger tire, we'll make the back seats a little bigger, we'll make it a little wider. So elbow
room and what they, you know, they killed what they loved about it. And that's a very common
phenomenon. So human beings are phenomenally good at this kind of stuff. So interesting,
though, because on some level from the consumer standpoint, the 65 Mustang might have been a
perfect car. Yes, it didn't mean anything. And you could still be selling 65 Mustangs today,
and they would be going like hotcakes because they have the aesthetics, the vibes, the feel,
whatever. And so it seems like the process of technological development in this market system
works directly against the person who just wants a thing that looks like the sweet spot that got
hit. Because I'm like, is the iPhone 15 significantly better than the iPhone 6?
No. Right? And because Shiloh is still... But so that's the division return curves. And then people,
so the designers, the marketing people are all looking for something different. Because they,
you know, somewhere in their pointy little heads are like, if we just keep making 65 Mustangs,
people will maintain them and nobody will buy a new one. But if there's a new thing you have to
have, so why do you buy a car, especially a sports car? It's partly for fun, partly transportation,
partly for status, partly for new, partly you got bored, partly who knows? It's a complicated
thing. So yeah, this is where I mean, like people underanalyze everything. So we just described,
you know, at least a dozen frameworks, right? And so just all 12 equations with 12 unknowns,
you need 12 equations. Like, you can't, you can't cherry pick a point and then
get anywhere. So if you want to make new technology, it's good to be aware of all these
different phenomena, and then you have to think about it. But you can also overthink it and be
over constrained by the whole thing. But yeah, I would, I would have loved to have much improved.
Now, some of the Mustang growth was because they started rolling in new crash standards,
which the old Mustang couldn't do. And then there was all kinds of wild emissions stuff with which
they tried to build emissions in the cars before they had to computer controls and sensors to do
it. So nowadays, you could make a Mustang that big, that's way safer because we have the crash
software and very efficient and relatively, you know, low on emissions because we have the sensors
and the computer control systems and the high pressure pumps to do fuel injection properly.
Like, it's a, you know, today we solve those problems with high end technology.
Like modern computer control motors are amazing. What's that? But like Ford's not making. That's
the thing that's really strange to me. Is that? Oh, yeah. So then the question is, why don't they
go back and make the great car with all the technology they have? I don't know.
Like it's hard to actually do it. It's really actually a really funny trend right now. It's
like reissuing, you know, the 54th Strat or something like that. And they're selling really
well actually, because they just couldn't improve. And they're literally rewinding all the coils to
spec and everything is like exactly how it was. And people are just loving it. Is it all exactly?
They're very, they're so expensive. They're high. Like they're, you know,
high end American products with, compared to some of their cheaper lines and stuff.
I think that they really do go after the original as much as possible when I can tell.
And so it's an interesting strategy. I think the problem is the safety standards on those
old Mustang searches. Like if you've ever driven an old 60s, 70s car, they're like the
suspension's horrible. They have no pickup compared to what you're used to. They're just
not actually good cars is the problem. Yeah, but you could make a car that looked and felt
like the old Mustang that actually was safe, but it would be the opposite of like a reissued fender.
You know, the reissued fender, you could make exactly the same guitar and somebody would love it.
Whereas the reissued Mustang wouldn't look like even the
the, the, the metallurgy of the steel would be completely different and it would be so much
better. This is something that's really interesting to me because I'm like, okay, so Ford, for whatever
reason, doesn't reissue the 65 Mustang. Like that's perplexing, but there are people that
may smaller car manufacturers that would be happy to reissue a 65 Mustang with all of the updates,
but they can't because of intellectual property. Like Ford, in perpetuity, owns the,
No, they don't. It's mostly, you could probably copy it. I don't, I, there's a difference to
de-copy right law and patent law on this one. I don't know what's, what's the intellectual
property. I was going to introduce a new car that's, we were talking to Warren Mosler,
he tried to do that, right? He built this car that was way better than all the competitors
and it was just impossible to bring it to market. He seemed perplexed by even what
had happened to him, but it seemed like it was really held down by a kind of old club.
It's very difficult to edge into that. Okay, so fine. Like, I think that the way that trademark
law works is that if Ford owns the trademark to the Mustang and the design of the car is
not functional, then nobody else can copy the look of the car because the only things that
aren't protected by trademark are things that are not. That are functional. Yes. Sorry. That's
a double negative. Trademark protects non-functional appearance based things. And so the look of a car
is protected by the trademark that they own over it, unless somebody can prove that the look of
the car is functional, in which case trade dress doesn't cover it. But let's think about something
that's more recent, like the iPhone, right? So Apple doesn't make iPhone 6's. So if you want an
iPhone 6, you have to get one that's old. And they're manufactured in such a way that they're
hard to repair. And so by the time that you get an iPhone 6, like none of the operating system
works on it anymore, it's very slow, like it's buggy, you can't really repair the components
easily. Is there some space to separate out the companies that generate the ideas and then the
people that implement them so that somebody who like Apple comes up with the idea for the iPhone,
then allows other people to make iPhones because they've moved on from inventing the
iPhone to inventing something else? Or is that just a complete socialist type of dream?
Well, some of this just happens over time, but it's longer time frame. So
so this is just my belief from history. 100% of the current companies will all become defunct.
Somewhere in the next 10 to 50 years. Like there's like essentially zero companies left from 100
years ago. I think General Electric is one of the few. So all the fortune one. Yeah.
There's the biggest companies during the expansion westward were all windmill manufacturing
companies. Yeah. Yeah. And then there was the oil and oil steel railroads. They were the high tech.
They were the booming startups in the mid 1800s, early to mid 1800s. And then they were the
you know, all the copies that ran ran in the United States and literally lent money to the
US government to keep the float. And you can imagine how how shifty that whole thing was.
They literally called them the robber parents, you know, but then their descendants created
all these foundations. So now people go to the Orange Foundation and Carnegie Mellon University.
You know, but those companies are 100% gone. And that cycle will repeat
inevitably. And then some of that will create space for people to make new phones and stuff.
But some of those devices, some of the devices, you know, like nobody really wants an iPhone 6
because an iPhone, you know, 12 is good enough and cheap enough and serves the need. And, you know,
the we're transitioning to like a different kind of computer in 10 years will be AI computers that
we deal with. And the question is, you know, who owns and who controls it? How do you build them?
How many companies are there? Who are the players? And it's going to be kind of wild.
I don't think it'll be many of the current big players. And some of the current funded startups
may be the ones, but some of the numbers that lead to next generation, you might not have heard
yet. So this is again, this is another one. Sorry, but I'm just curious if you think this is a
fixed law of the universe, the lifespan of these companies, because it seems like bureaucracies
can survive for a very long time. I know there's some Chinese bureaucracies that lasted almost
a thousand years. I think it's the Chow dynasty. But it doesn't seem like necessarily the organizational
structure is dated, right? It doesn't have an expiration date as much as something else about
their inability to adapt to the needs of new customers. What is that? Is it possible?
Well, I don't know if you want to, well, like the first step is understanding also like,
like, so business bureaucracies have self limits, because as companies become bureaucratic,
they don't respond to the market. They consume all their revenue for, you know, nonsense. And
they go bankrupt, right? So then there's these quasi businesses like utilities,
which are horribly run, or big companies like Ford and Chrysler, who have such big unions and
political clout, that they got bailed out by the government to cite the fact that they probably
should have been bankrupt. Now they will tell you that they paid back the loans. And I'm again,
I'm not an expert, maybe they did, maybe it was great. And, but then government bureaucracies
are a little funnier because, you know, they're not funded by their success, they're funded by
taxes. And oddly enough, the worst they do, the more they spend and the more they tax. And so they,
until it starts, it's having such a big impact that there's some either kind of internal political
blush, or in fact, they failed so badly that, you know, they lose a war, like historically big
corrupt countries, you know, didn't end well, as it were. But those cycles can be longer. And then
there's some bureaucracies, like there's some Japanese companies that are hundreds of years old.
Some of them are successful. And, but some of those are family businesses where the
families escaped, you know, then the, in the Western world, like family money only lasts like
two or three generations. You know, like, like, you know, the up and comer guy who made the money,
his, his descendants do very well if they keep growing the business. But at some point,
they start dividing it up and the children are raised in luxury and they don't try very hard. And
then some of those families, families, they go bankrupt quickly. Is that just a cultural difference
East West? Well, I suspect most rich families in Asia also go bankrupt the same way as over time.
So I'm not enough of an expert by just like, there's some famous families in Europe that are also
hundreds of years old. That's true. That's true. And, but if I remember correctly, these Japanese
companies are not like big tech companies. They're like a pub that's been run by the same family for
like a thousand years. Really? Yeah. Like some of them are. Yeah. Yeah. I just, I think that the
oldest company in that I know of continuously independent, I think it's Nintendo. What's that?
Nintendo. Yeah. I mean, yeah, yeah, Nintendo was definitely it was not a handheld game company
like 300 years ago. So yeah. So they became very famous for that. And then 1889.
What's that? Nintendo was founded in 1889. Play cards. Yeah. And was it Nokia was a rubber company?
Yeah. You know, they became famous for phones. So sometimes they transition, but you know, it's
so again, to the socialist point, I don't know, people work really hard when they see personal
benefit and and personal goals. Like most people don't work for money. I don't know anybody that
works like once you're successful in high tech, you're not working for money. You're working for
goals for interest. You know, somebody said once you have $100 million, you know, you buy a couple
houses and a ranch and a boat and a plane. And after that, like none of the really rich people
work for money. And most of them, you know, it's sort of like the money exists, but it's more
like stewardship of an asset. Like the people who have assets invested or they make decisions about
it, they're, you know, it's a complicated thing. And then the question when you have assets, who
should use them? And what does it even mean? Like, if you're a big shareholder in Tesla today, what
do you own? Well, you own the production capacity of employees, 100,000 people around the world,
making millions of cars. And you mostly don't just spend that money because if you sell your Tesla
shares to spend the money, you don't own Tesla anymore. And if you own Tesla shares, your money
goes into a factory that's making cars, you know, so it's a, you know, like what does asset ownership
mean is a complicated thing. And, you know, generally speaking, you know, there's producers in the
world and consumers and the consumers mostly don't produce anything. Seems like there's a flaw
in the design of these corporations because the arm of the corporation that's invested
in making money and selling stuff, sometimes works at odds with the department that is
innovating and coming up with new ideas. A new idea is always less profitable than an old idea
that you could just iterate and sell a little bit. Yeah, yeah. And so has anybody made it?
That's called creative tension, I think that's flaw. Creative tension?
Yeah, the creative tension between should you produce what's making money now,
or should you invest in something new? And by the way, companies go bankrupt on both rails.
So they don't make the new product and then nobody cares about them, right? You know,
blockberry, like who cares about touchscreens? That didn't work out so well. And then other
people invest in all kinds of new stuff and it doesn't work out. And you kind of look back and
you think if they just kept making comfortable shoes, they'd been fine. And so the, you know,
it's sort of like the same graph of like what percentage of humans have descendants after
10 generations? The answer is not very many. What percentage of corporations are successful
after 100 years, essentially 1% or something. But that's because we live in a very experimental
universe. Like the number of things that can go wrong is like essentially infinite. And the
percentage of things that could go right is relatively low and often very dependent on
luck in the current state. You know, so like the iPhone five years earlier had been down. As a
matter of fact, they tried it a couple of times and the technology wasn't there. But when they
finally did it, it was pretty good. And it seems like that might be what, and there's some inverse
of that, which is that when the winds shift and you have a model that works, you're kind of screwed.
Like we were talking earlier about Google being an ad serving business. At the end of the day,
the goal is to get you to look at ads and those ads are having like their money. But with generative
AI, you can go ask the same, the same question to chat with the tea or cloud or whoever it is
that you're using. And there's no mechanism for serving you ads through that. Oh, there already
is. There is. I have friends, they're doing, they're sending me screenshots of they did a search and
the search said, Oh, you might be interested in this article in the Atlantic or so the AI models
are fine tuned with their advertisers data. So don't worry about that. Even worse,
like movies and everything. So when you're watching a movie, even worse, even better, hard to say,
sounds in your perspective. So you don't have a, you know, Coca-Cola famously paid, you know,
Marvel Studios, all this money to put a Coke can on a table. Well, that only works for a certain
segment of the audience. Like some other segment, I guess, wants to see a can of,
you know, pork and beans. So all the AI generated video will, will gain the environment to
affect your perceptions. Also, like we'll be watching different movies, essentially. Yeah,
yeah, everybody will be watching different movies. Taylor to my interest, might, might
have all those federal issues. Well, tell them some, some combination of your interest and what
somebody wants you to think. Oh, it's really interesting because I'm trying to think of like
Iron Man having a can of pork and beans on his table instead of having a can of Coca-Cola. And
there's just something so strange about that. But I suppose, yeah, there's a 7.4% target market
that would have loved that pork and beans. Like it can't be, can't be cake, Coca-Cola, you know,
like bias. You have to have to be open the pork and beans experience. It's going to be really.
Okay, but so I have, I have like an overarching question about where this is all going.
Yeah, I'm curious about still about the lifespan feature. Do how much fallout is there in the
death of a company like in the bankruptcy phase? How is that devastating beyond just the people
who are working there? And is there anything like an end of life plan for companies? Or is this all
sort of surprising when it happens, even though it's completely inevitable?
Just a reminder that people pull out, which is like in case of the end, do this.
Yeah, yeah. For most companies, well, like I said, the, you know, the truism is they went bankrupt
slowly at first, but then all at once. And lots of times people are very surprised. Now,
so there's the question of what, what if anything should be done about that?
So like most companies pivoted, that used to be you work for a company for 30 years and retired
and got your pension from the company, right? And that like, now that's 100% over. All your
pensions are what's called portable pensions and earned 401ks or IRAs. And so as you work there,
you, you invest, and maybe the company is, but it's a great company and best in your
retirement fund, which you own. So that's good. And then depending on, you know,
dumb luck and everything else, that may or may not grow at the stock market. So that's, that's a
thing. Some companies get propped up because it's like too big to fail. Like, but then,
then you have the opposite effect, which is what, like, why do we prop up big banks and
financial institutions? Because it didn't make them better companies basically taught them the
valuable lesson that financial management was, you know, for babies and, and, you know,
they can get away with anything. And so those, and that's where you get into the, you know,
complex relationship between investors and companies and governments and regulators and
revolving doors between regulators and companies. And, you know, my personal view is it would be
better if companies failed more often. And, you know, you could imagine a regulation to say the
life cycle of a government organization should be more like 30 years. Because then you could go
through a 10 year growth phase and a 20 year, you know, productivity phase and then get shut down
before bureaucracy takes over 100% of your output. Because, you know, to your question was like,
have you just said what percentage of our output is wasted on our bureaucracy? And it, it, it slowly
grows. And at 100 years for most companies, it's over 100%. So the bureaucracy taxes,
you know, a minimum of a percent a year. And at certain phases that goes up faster, and then
occasionally gets reset, like Microsoft was clearly, you know, reinvented for a whole bunch of
resupply was clearly reinvented. Is that reset possible with the governments or with an academic
institution? Because these are the real big bureaucracies today, as far as I can tell. Yeah.
So universities used to be reset all the time because they were funded by
their endowments, their patrons and their students. But now they're funded by the government. So they're,
you know, so they've been detached from the market cycle at some level. Now, some, some
universities, I have a couple of friends I've been teaching for a long time, and
they get cuts every year to the professors. And while the bureaucracy continues to grow,
so they used to their budgets used to be 10% bureaucracy, 10% facilities and 80% professor
salaries. And now it's like 40% bureaucracy and 30% facilities and 20% percent professor overhead,
professor of overhead. And, you know, like it's amazing. They take half those grants, right? Half
those government grants that you say about. For this kind of grant, they get 50%. This kind of
grant, they get 60%. And then they can, and then, yeah, it's made. Don't they hope that? I mean,
can you imagine a reset that's possible in such a whole bunch of people trying to invent something
outside the current university structure? Alternative institutions. Yeah, so. Which
is an alternative government, though. Yeah. Well, now governments have gone through a really big
reset. You know, the United States government has gone through several major resets. Like the
civil war? Oh, so you guys are too young. So I have a friend who's very worried about the current
government situation. So when I was a kid, you know, they were, they were taking young men
at essentially gunpoint and sending them to Vietnam to kill people for, you know, no good reason.
And then the National Guard shot students on campus. And then the police department beat up
protesters at the Democratic National Convention on television. Like these things happen.
And the Democratic Party lost brutally for multiple
elections until Bill Clinton basically reinvented the Democratic Party.
A really big reset. Like it happened. But then they became bureaucratic just the way,
you know, the modern parties are basically in the same boat they were. And the Reagan
revolution was somewhat real. You know, the, you know, Nixon, Nixon got taken out for a bunch
of complicated reasons. And Ford was a loser. And, you know, like it was quite a turnover in the
60s and 70s. And then things have to get bad enough. And then the pendulum swing. Yeah. Yeah.
And there's lots of people who study like the 20 year cycles and 60 and 80, 100 and 200.
So we're clearly going through one of those cycles. Like it's hard to believe like who's
running for president now. The year without an election. Yeah. Yeah. And that's probably what
people will say. And then people will look back and go, well, how did they let that happen?
But when I was kid, they taught us about yellow journalism and the robber barons and
the Great Depression. And, you know, like we went through multiple cycles, like
literally since 1850, that I was taught in detail about. And, you know, like we're in another one
of those cycles, which will be in the history books. And there'll be, you know, the great deficit
and the great election, something or other, who knows what they'll call it. And
like these cycles keep happening. So, so the big difference in this, this took me a while.
I was talking to my friend because he's very anxious, you know, he's younger,
you know, 30 something. And I think everybody has this, by the way.
What's that? I think every single person listening probably has at least one current
that's in a similar position with respect to the government situation right now.
Yeah. Yeah. So it took me a lot like when, when I was going through that and watching television,
I was a young person. And, but, you know, there was a threat that I could be sent to Vietnam and
my parents were anti-war protesters. And there was literally, and they were also civil rights
activists, which is wild because my father was a Reagan Republican, but, but it was a moral statement,
not a left wing statement. And he had friends that literally got beat by police in Philadelphia. So,
like, like there was a real threat and we didn't know how it was going to go.
Like we sat around the kitchen table and my parents would pray
that we would live through this. Like that was my childhood. But we did.
Now it could be, now I have a, well, you can live through almost anything attitude,
which would be wrong. It was, you know, that was pretty threatening. And, you know, it was,
you know, there was like, when we were kids, we used to train for atomic fallout by having
under the desks. I was six years old who were, you know, we're seeing the six year old desk at
the top of the desk about this big and we would get underneath it to protect us from fallout,
which we had no idea what that was. But there was air raid sirens and, you know,
you know, running the classroom and hide under these little tiny desks.
No, it was fairly, fairly daunting.
People have lived through so many hard things. Like my mom will tell me stories of the arc of
our family in the Soviet Union. And it's just insane, right? Like Russian Jews in 1920 that are,
that are running from the Red Army that are, you know, and then like her entire branch of
the family left St. Petersburg and they went into exile in Siberia. And then they ended up joining
one of these communes and the communes, they took all your passports so you could never leave.
And so like the husband of the family was either killed or arrested. And it was this woman with
eight children, no food. She can't leave because she doesn't have any of her papers and she manages
like her dad would tell her stories that they would gather wild hemp seeds and squeeze them
for oil. And that was the only fat that they would be able to get. And yet they made it, right?
Like my parents live in California now. And the memories of everything that they went through have
kind of faded into the background and so I developed this feeling about the political shifts, which
is like, yeah, they happen, but life exists on the foreground while all of that stuff happens
sort of in some ways beyond our control. Like these are systems that run. And our task is to
figure out how to do something meaningful and worthwhile despite the fact that the background
is so insane. So this gets to the philosophical point, which is, you know, these cycles exist.
So the, you know, the Nassim Talib is like, the harder you work to keep it frozen,
the worse the end is, you know, you know, the long tail event, like in the financial world,
trying to regulate the system to avoid crashes makes the crash worse. No, may in fact put it off.
And then there's, you know, the great attention between should you crash early and often and
then deal with it all the time, but then you have smaller ones, or should you
try to build a robust financial system that, you know, avoids that. And the same with political
systems, like the United States for the most part has had a pretty dynamic political system, but
you know, the current alternative seem, you know, there's a funny phenomenon like
in a negotiation between multiple parties with the stake in the outcome, you compromise towards
the middle, but in bubbles of, you know, like-minded people, it tends to, let's say, negotiate towards
the edges, you know, I'm the most virtuous, no, I'm the most virtuous, no, you know. And so
that's an interesting dynamic, which also plays out organizationally, like when there's a proper
negotiation of the parties, something interesting happens. But when there's a, you know,
autocratic will or makes stupid decisions, or I got to describe this business group,
they were making so much money, nobody wanted to call them on it, but their decisions were
actually killing the company as a whole. And, you know, these systems happen at multiple,
like, I have a belief that these systems play out at multiple levels. So, you know, like,
how family dynamics work with a small number of people, looks a whole lot like a small
team dynamics work, which looks a whole lot like how extended family dynamics work.
And that's because we're humans. Now, if we weren't humans, say we were beings with a thousand
life cycle, and we didn't have families, and, you know, we could keep track of like a thousand
numbers in our head instead of seven. Would our dynamics play out differently? I think they'd be
a lot different. But our dynamics that we live and play out the way they do, because of our
biological, you know, grounding and our evolutionary process. And we co evolved with our culture,
which gave us mental capacities for a whole bunch of things. We co evolved with our lifespan,
which gives us, you know, let's say expectations and pretty deeply ground ideas about what to do.
And you have to understand like 10 levels of that to make any sense out of anything.
And so there's something that's really crazy that's happening right now, which I think has
been a continuous project since the invention of the first computers, which is to create a
fundamental shift in the biology of humans. Like, I don't necessarily think that the first people
who sat around and were asking how to build a computer had this in mind. But I see it as this
emergent step in evolution, where we had the dream of being able to make a machine that could think.
And the first iterations of those machines, we're only able to think in very basic ways,
according to the way that we programmed them. And then progressively, we increase the speed
with which they can think the number of complex processes that they can run. But still, you're
limited by the fact that it is, you know, garbage in garbage out. If you if you don't know how to
work the machine, you can't make it go. But as we develop tools that are intelligent, and we start
to gradually mount the computational power of computers with the computational power of humans.
And then we also start to manipulate the lifespan of humans in order to extend it.
What effect is that going to have? Because it seems like it's this project that we're
running full throttle into. And obviously, you do, right? It's we build tools. That's what humans do.
But I feel like there's something that's fundamentally different about the tool
that is the steam engine and the tool that is AI and bioengineering, combined with AI.
Yeah. Let me try to take. Yeah, there's about a couple of different ideas there. I think
it's interesting to take it apart. So starting with your last one. So we made a whole bunch of
tools which didn't really or did only slowly reengineer our biology, but they reengineered our
culture. So all over the world, human beings live in, you know, Aboriginal humans live in
tribes of 100 to 200 adults. And that's a human constant. As best I can tell, I read the number
of books about it. And so our ape relatives Gibbons are famously monogamous and orangutans
are solitary territorial with some really interesting side shows. And gorillas are a
dominant male with a harem. And chimpanzees are a dominant group of adults, you know,
three to five males and three to five females in a group of 30 to 40.
They can go from a solitary animal to a pair bonded animal to a harem animal to 30 to 40 to
100 to 200. So that's our organic basis. But with tools, you know, you know, who and who knows
which one drove it? Was it farming? Was it herding? Was it bow and arrows? Was it whatever?
We used our tools to get to engineer culture and society. And then essentially, the person that
could keep the biggest village together could win against the other villages. And then at some
point, that also caused, let's say, a massive escalation or a political abilities, because
you want to trade with that village and get rich or go to war with them and get killed.
Like there's, you know, so our tools, what we co-evolve with our tools and our culture,
right? And some cultures are way more effective than other ones that making new tools.
And but, you know, it's also a very chaotic function. And so we're making new tools,
which is going to cause some additional cultural change. And it's already doing it in some of
that good ways and bad ways. Like the internet is full of people speculating about it. But
you know, we've gone through a lot of evolution. Now, computing, computers don't think,
right? And, and there's a funny thing. So their first computers, you know, executed
sets of statements, which, you know, you could do with a pencil and paper is just, you know,
when they do a billion instructions a second, it's a little faster than, you know,
one a second. But that's a matter of quantity, right? And then, like,
so the statement kind of computer, and then we went into, you know, there was the big data
revolution and analysis, where you could run so many programs across data, you could find
signal where nobody could. And it's almost like we got into pattern recognition. So you went from
executing statements to something that seemed to do something different, like pattern recognition.
And then the early AI programs, you know, like the famous Alex net, which could recognize a cat
in a photo. Like that's kind of a wild thing. But, and it was way better than what's called
classic vision, where which attempted to find cats by correlation. They would say a cat is a
collection of pointy ears and round eyes and fuzzy hair, and cute smile or something. And then
you could have a database of when you see these parameters, these features with these ratios,
it's a cat versus these features as a dog versus a, you know, a problem or something. So, so that,
you know, the statements to think, you know, like analysis, and then recognition, and then the language
model, you know, people are very puzzled by this because they're sort of stupidly good at chit chat
and summarizing things and predicting the next word. And they do something that seems almost
amazing. Like you can think of having multiple equations like, you know, x plus y plus three z
equals five and two x plus seven y plus z squared equals seven. So those are equations. And then
you can do algebraic processes to do something with, but you can't add the word cat and dog.
Like cat plus dog doesn't mean anything. Does that make sense? But you can translate cat and dog
into a space where you could add them up. Right. And then you could query a statement against the
words. And it turns out with enough computation, you can create really called embedding. And then
there's all kinds of transformations you do on that data, where you essentially you've turned
ideas into mathematical things. And I know they're mathematical, but I can actually look inside
the computer chip and look at the register that has the bits in it that I'm adding. There's no magic
in AI computers. They're just numbers being added up. But like the representation of the word cat
and dog isn't a very good representation for manipulation, let's say. So the some modern
computers, we can do something really interesting, which is with a set of words, predict the next
good word. Or with two sets of ideas, put them together and summarize that. It's kind of amazing.
And it seems relatively intelligent. Because in fact, the current state of play is
its ability to write, summarize, analyze and talk to you is better than the average person.
But it's not clear it's thinking. Yeah, I was going to say, how do you define intelligence?
Yeah. So you know the joke, every time intelligence can do something that stops being AI.
So like, like surely it's AI when you can play chess, but then we wrote a program that clearly
wasn't intelligent play chess, but go. That's so hard, you have to be intelligent. No, that
that was just a program to like to recognize generally any object in a picture, you must
be intelligent. That was easy. That happened 10 years ago. Right. To complete this sentence,
that must be intelligence. Nope. The turning test. I talked to you for 10 minutes and I can't tell
it's not a person. That's been passed. The bar exam. That must be artificial intelligence.
Now that was easy. Like so. So we don't so so so what's happening this intelligence is being
defined by what it isn't, which is crazy. Right. And then today, people say, well, the AI models
are no smarter than the input that they be fatted. Well, human beings aren't data and intelligence.
Like Christ, the average person barely gets 100 megabytes of data and by time they can talk and
do smart things like work where I would call computation intelligent. So and that that means
some of it's trained in a way that like builds these simple spaces and representational things.
But then we can experiment experimental, right? That's yeah, yeah, we can do variations on that
and combine them over and over. But it turns out the variations that are being done.
Arch magical, their variations in the representational space,
now turns out those representational spaces have infinite variation possibilities or
very large variation possible. And we do a funny thing where we're very good at making small
variations and then filtering for some sensibility and then combining filters of those variations
for something bigger. And depending on how smart we are and what what we learned and what, you know,
let's say sense, you know, make sense of the constructs we have, you can be more or less
successful at this. Have you ever watched like Richard Feynman lectures on math?
Like you're super fun because he goes, Well, this is obvious. This is obviously the case
is hopping across the the trail like 100 yards at a time, because his ability to produce variations
were really good. And his ability to make sense out of the possibilities
were amazing and really well embedded in its thinking. Right. And I go, well, I can spend
an hour on each one of those, you know, cognitive beliefs he made, but I can do the same thing that
appears. I can describe outcome. What's that? I just I'm trying to separate out what humans do
that's different than these artificial intelligence programs. And it seems like something about our
ability to compound abstractions into new layers of abstraction, but I'm not sure the computers
that are pulling off this. I actually think they're pretty good at that side. The programs are
written yet to do the variation. That's not just noise. So if you just do noise like,
like there's I think the problem to crack is how to do variations that are interesting
without just being noise. And I don't have a good idea. Like chat GBT is, I don't know,
I've been chit chatting with it about, you know, physics and stuff. It's interesting how it puts
you together. And then you can see places where it just falls flat and other things is like, well,
that's kind of interesting. It's synthesis is me, I would say medium. So to pass the bar, because
that's mostly factual associations, they can play all the games. Those are mostly role based kind
of things. And you can see somewhere it starts to fall apart on idea synthesis. But it's not,
it's not sitting there cranking 24 seven doing variations. Like when you think about something
hard, like you guys are working on your physics problem, that's partly running as a background
program in your mind for what a year, two years, some of the years. And well, 10 years, all right,
so you have 10 years of background processing. What's a pretty well refined sense of what makes
sense in that, which may in fact be your biggest problem, you may be filtering out all the best
ideas. But that's a, that's a real problem for smart people. So it's kind of complicated. So I
don't, I think the synthesis is getting better pretty fast. And people keep saying, we see at
the current level, it's terrible, they'll never get better. And I think, well, compared to a year
ago, it's unbelievable. Like, we're on some pretty steep curves here. But this, and then this
mixture of experts thing matches my personal model of like, there's a workspace, and many,
many agents that we apply to it. And then we have many tools of variation and combination or
when we think, and they're starting to build that platform of multiple experts and a common workspace.
And then the ability to make variations and then test the variations for, say, some useful
just before we waste too much time thinking about it. Like, you don't spend very much time
thinking, well, what if I could just invert gravity? Like, that's not worth the years where
the thinking is worth like a half a second worth of thinking. But what if there's a different way
to look at, you know, these field equations, and you're good at a bunch of mathematics,
then you can test pretty fast those things. Now, the problem is there might be five more
variations of field equations that you don't know. So one of those might have been good.
So you have a filtering problem. So you may have in fact had a good idea that you filtered it out
because you didn't have an analysis, a good enough thing. Like, I had a friend who's better at me
than computer designing smarter. But I was more creative. He felt he he would run into a problem
idea, put it down, and I would kind of go, Well, this is pretty good, but it's got these three
problems. And then this is pretty good, but it's got these two problems. And then this is pretty
good, but it's got this problem. And then one day, I would go, if I take this and this and this
and put it together, and I got something that works, and I would tell them and he would go,
how do you stick that out? And I explained it to him. He says, but we rejected all this ideas.
And I said, you stop thinking about them. I didn't stop thinking about them.
That's the layer on the AI that I don't see yet, which is the ability to take
I know, but that's the steps and smash them together in a way that's unlikely, but productive.
I just explain the whole program, we can write that in 10 minutes.
That program wasn't hard to write. And I'm not even going to write as the AI programs
going to write it. I think the sensibility filters are a bigger problem than the
combining things that were pretty is pretty good synthesis as medium.
But we just started breaking that into problems.
Yeah, so I'm fairly, well, I don't think thinking is magical. I don't think it's quantum.
I think it's like we already built computers with more operations a second.
They're like biology is insanely efficient for computation compared to transistors.
But there's reasons for that. And I think we'll solve that problem, by the way.
Like, where do you think thoughts come from? Like, where do you have a thought?
You're like, I thought I just thought of something. Where does that come from inside of
the human architecture? Oh, we're, you know, like the base of, you know, what we think of
thinking is, you know, advanced planning systems. Well, I think so your brain grew in a bunch of
layers, like, you know, a sensory cortex and a motor cortex. And, you know, we sense both the
external world and ourselves. At some point, you know, low level animals got good at that.
And then they started moving around. And then they started doing basic planning, which is,
you know, run towards food and run away from teeth and, you know, all kinds of things.
And then we've been elaborating planning more and more and more. So when you're just sitting
there doing nothing, the various parts of your brain will be like sort of newling on what should
I do? What should I think? How should I get ahead? And it turns out we've elaborated that so far,
we can think, how do I plan ahead in mathematics? How do I plan ahead in art? How do I plan ahead
in engineering? How do I plan ahead in four dimensional political chaff? How do I plan ahead?
Like, we're really good at it. Just very strange how thoughts come up most unlikely
time when you talk to people who have had inventions or brilliant mathematical physicists.
And they'll, they'll just mention these strange occasions, you know, I was having dinner with
my wife talking about the opera or I was in the shower. It seems to be a very common feature that
people, you know, as a computer architect, I don't think that's odd at all. So, so the,
the voice in your head is a postdoc narrative. This part of your planning review system.
And your actual thinking is, is in many, many, many layers of computation. And not very many
of those are visible to you. Alright, so some of those layers are computing and being rejected
and computing and being rejected when you don't even know it. I have the sense I can feel myself
thinking sometimes and I can't access. And then sometimes that kind of breaks through to higher
level things where you start to label it like I'm having these thoughts and they have labels,
which are words, which I can say, or enough of it go somewhere and then you can kind of go
tell the story about your thinking.
Just the feeling of thinking before you said that sometimes you have the feeling that you're
thinking that you can't access. What does that feel like?
Oh, so there was, there was a really good book about this, which they did a whole bunch of
experiments which showed that your, your thoughts, your verbal thoughts are half
second behind your actions, which at the time shook me up. And then I thought, well, of course,
that's how it always feels. And then there's a, what's it, you know, it's advice I could give,
you know, give, I've given people, which is if you want to solve some hard problem, you have to,
you have to spend a lot of time and effort putting the problem in your head.
And, and I also noticed as a college student, I was relatively bad at learning things quickly
and getting the day on the test. And I had some friends that did that. Like, like if I took an
engineering class, I started studying day one, and I did all the problems. And I mostly didn't
study for the last week of the course before finals, because I found it was better for me to
stew on what I knew than to inject some new thoughts that would screw it all up. I've always been that
kind of person. And I trust the thinking. But yeah, it's strange when you're thinking hard
about something that it's kind of boiling around. But, but again, so my model of it is there's many
layers of it might not be true. I couldn't tell you, I haven't put any probes in. And that much
of your thinking and computation isn't visible to what you think of your current working set of
thoughts. And so the fact that occasionally things work out and get signal to some simpler
level of thinking, and then you're surprised by it isn't surprising to me, I think that's obvious.
But I know I had a friend who was very freaked out about the fact that he could never figure out
where his good ideas came from. He literally dropped out of college for a year. Because he never
knew like halfway through a course if he was going to get it. He just felt really anxious
about it all the time. And it's like, well, what did you do about it? And basically nothing. He
said, I just live with it. And I was like, well, you could spend more time meditating on that. Like,
I think you can have some more access to it. But you could also say that's part of our architecture.
That he was just freaked out that it would fail him at some point if he didn't understand.
I don't know where it comes from. So I don't know why it will happen again tomorrow.
Interesting. Yeah, it's a funny thing, but I'm not surprised about it. Because, well, like,
if you go look in neural networks, like when they first started doing like the cat recognizers,
they would see as you went through these layers of convolution, that, you know, you went from an
image to components of an image. And then, you know, essentially, you would have a layer which
would do size and variance and orientation and variance. And then associations of different
things. And sometimes in layers, you could see what it was doing. And sometimes in layers,
you couldn't. So they would pull the layer out and say, well, if I don't know what it is,
what's it doing there? And they pull it out and it wouldn't work anymore. And that's probably
because that was some computed association map that had no relevance to what you think.
Like, and there's also a thing called overfitting, which is kind of funny, where you can train
a network so good, it can only recognize what you trained it with, right? Or there's another,
when you have way more, say, parameters in the network and enough layers, you can compute the
associations in a way that they're not overfit. So it can recognize essentially more than you've
trained it with, which is not mathematically right description. But like, that's how it feels.
And then I think humans have very deep layers. Because we do, you can count, you can see them
in your brain, like cortical columns or six layers of neurons thick, with a spectacular
number of connections. And then the cortical columns talk to each other. And then they fire
each other. And then they run many, many times. Now, when you're thinking hard for 10 years,
like, the number of passes through your brain is unbelievable. And your brain is even coordinating
those passes. It's not your whole brain, you're doing all kinds of different things.
And then things beginning at this that computers don't think.
Yeah. So the computers we have today, so the AI we have today is not what I would call thinking.
But it's always to build one that does. But yeah, it's going to happen pretty soon.
Oh, so I mean, it's like, yeah, they don't think what's that distinction look like?
Well, it's, you know, it's like the read the endlessly redefined scoring test.
So Elon's version of it, but it's all the novel physics problem.
Because the high end of human thinking is solving hard novel problems. And I think that's the
differentiated from, you know, producing lots of word salad. Like, like, this is an interesting
thing. I have a friend who's a writer. I threatened him with writing all his possible books in
coppery writing them before he was he wrote them. Because he's a very good writer, but he has a style.
And, you know, and, and if he told me that 20 ideas of the book, we could, we could generate
much of the writing. Now, obviously, a really good book has a, as a mental journey to it that
solve some problem, like some, you know, your, like some people are interested in, you know,
like trip reports and, and, you know, travel dialogues and whatnot, which are predicted,
right? If you go to Thailand, and then degrees and then Iceland, and you look around, you will
see things and you can literally take a camera and point it at those places and then give that
chat GPT, which would write you a nice travel book about what happened. Like, that's not
intelligence. That's a scriby, right? But if you went there and the cultural cons, you know,
cultural differences between Thailand and Greece, if you understand something new about humanity,
that could be a really interesting book because that's a novel idea. And today chat GPT wouldn't
write that book, but you might. Right. But at some point that GPT will write that book.
So with the, the solving the novel problem, wasn't alpha fold solving a novel problem?
Right. If they basically figured out a way using AI to solve the protein folding problem,
which had, yeah, so this is a really good
boundary. So that's still a computational problem. Now, I don't maybe human culture
is a computational problem. Yeah. So there was something. So I talked to these guys that
just just just cracked me up. So when you do finite element analysis on an airplane,
imagine you have an airplane and you're blowing wind across and the wind is turbulent, of course,
the air is turbulent. And then there's, there's both an analysis of structure of temperature,
different nations, there's a whole bunch of really interesting things. And so it turns out they have
reasonable finite element analysis programs written in Fortran, which is a little rusty.
And, and they're computationally limited to analyze airflow over planes and structural
failure, all kinds of stuff. So then they were trained, they were using the Fortran programs
to train AI models. And now at one level, you want to analyze one element, you know, and it's a
billion operations of elements. You know, that's a lot. And to run that program on a variety of
elements to train an AI model that turns around and for the AI steps to do anything, it's a,
you know, it's a, it's a million trillion operation, which is a lot more than a billion.
But here was the amazing thing is when they train multiple very large AI models with these
Fortran programs, the AI models are really good at analyzing things and ignoring the things that
don't matter and sending more computation on things that did. And they analyze the whole
airplane, it was less total computational steps than the finite element analysis, which
couldn't differentiate any element. They all look the same. The Fortran program doesn't care
that AI model had a deeper level of analysis, which could do something to look at the whole plane.
Yeah. Yeah, well, it did something interesting. I don't know exactly what it did. But people
are using programs to train AI models and then getting better results. Because the AI models,
when they analyze it as sort of this log, rhythmic, or maybe linear computational bed burden for scale,
whereas the finite elements that have some kind of exponential burden for scale.
So the protein folding thing is really interesting. This was where like really small
atoms say probably have programs that can do stuff, but they scale it up and computationally
explodes. And the AI models probably don't computationally explode.
So when the AI's start thinking, do we have an ethical issue on our hands? Like,
are they alive essentially at that point? Do they have self-awareness? Is that our
real life? Yeah, I think you already have that problem. So this will make you think about what
thinking is. So AI is clearly making everybody think about what thinking is. Because we've had
10 definitions of thinking. They all fell apart because as soon as AI did it, everybody declared
it's not thinking. Because it's obviously not thinking. And now we have ethics built around
the sanctity of the human life, which has a narrow definition of embodiment in a person between
2 and 8 feet tall and 500 pounds. So we have this definitional state in a person.
And we've mostly given most of those people at various points in time some kind of ethical
standing. So now what happens when we enable a trillion AIs or else more than us? Do they
have ethical standing? Do we have ethical standing in their mind? I don't know.
It may conclude that we're paperclips or something. It's a curious phenomenon.
And this leads back to the question that... I'm just curious how we can rush towards
something like that before we figure out the answer to that problem. Are you familiar with
Ian Banks, sci-fi writer? Yeah, that was one of his... I think he's a pretty good writer.
Because he imagined the universe where there was a wide range from robots that were obviously not
very smart to humans, including some very smart humans to AIs, which were human level
intelligence to extremely past that. And he created a world where it was sort of all interesting.
And it was still a goal for the humans. Well, so 99.9% already live in that world.
Like you guys are pretty smart. You're already enough smarter than most people that you're
unintelligible to them when you actually talk seriously. 99% of people already live in the
world where they're not very smart. Like it's already a fact. We already live in the world where
there are cats and dogs and ants and mosquitoes and birds and trees and all kinds of things and
nobody wakes up in the morning like trying to stomp out all the cats. It's not a thing.
And anything any smarter than us is seriously not resource bound. This thing where the robots
destroy the earth because they need energy or something is just whack. The sun is putting
not so much energy. It's unbelievable that energy in the material around us is startling.
Like our local consumption of energy is 0.0000001% of the available energy.
So it doesn't necessarily guarantee that your ideas will take off either, right? Yeah,
there's this whole marketing charisma element to having your idea. It's to be a kind of a
beloved person, at least in the realm of scientific ideas that we play in. It's like,
you can have a great idea, but that's just the start of your battle.
I actually think that it's not...
You know, what's the battle? Like humans are very conflict oriented. So we have all these
interesting priors. Like one of our biggest problems is like humans for like a million
years of evolution, you know, whatever you believe, you know, are essentially zero sum game
because it was a zero sum game. Like if you eat all the local deer and stuff, there aren't any deer.
So now we can produce an unlimited amount of food with energy, probably.
And there's an unlimited amount of energy. So we don't live in a zero sum world.
Yeah. There's only a couple of kinds of shortages. Like there's something that's in fact rare,
and then there's another kind of shortage, which is it's new and they haven't made enough for
they're too expensive for everybody, but that's usually a transient. And then there's shortages
due to monopolies and then there's shortages due to, let's say, refreshing of production.
Right. And there's literally nothing rare. Like we can't run out of aluminum because
like aluminum is a metal. Like you use it and you melt it down. Like there's no shortage.
I just love these things. They won't have enough copper to make the solar cells.
Oh, there's so much copper in there.
It's expensive at some point, right? It ends up in landfills and you got to process it.
No, there's so much in the top 100 kilometers of the earth. It's not funny.
Oh, here's a funny story. It's like, so computers are made out of essentially three atoms.
Oxygen, silicon, aluminum, a little bit of copper.
Some gold in there as well, right?
Yeah, it's really trace. So they use like 32 elements as trace elements, but you know, by bulk,
it's so it's by bulk of silicon and oxygen. So 70% of the earth's thrust down like 100 miles
is silicon, oxygen and aluminum, which looks like a setup to me like
like carbon and hydrogen. Like these are all trace elements. There's a lot of carbon and hydrogen,
but the big hitters are for whatever reason is silicon dioxide and aluminum oxides and,
you know, all kinds of iron. But iron, like the percentage of it goes up as you go further down
on the earth because of, you know, melting or something.
But there's like so much of everything that's not funny.
Like they did, there's a couple of processes. Just look up by weight how much like copper,
magnesium, titanium is in like the ocean. Like there's really good processes they're developing.
Like just in seawater?
Yeah, just seawater.
So there's a lot.
I don't miss it. I think that the idea that AI are going to show up and they're going to destroy
the humans and the paperclip maximizer means are, I think that they're deeply informed by dystopian
science fiction. And my greater worry is that they'll will become stuck at some computed optimum.
And what I think by that is if you have an intent, if you have a super intelligence and the
super intelligence is like, this is what should be done in this circumstance. And it has the ability
to inform what you do at every circumstance. That's kind of the ultimate centrally planned economy
in some ways. The most centrally planned culture.
Okay. Well, let's, I like Elon Musk's line about very important to train these things about the
truth. And you know, one of the truths are there's endless cycles and there's endless chaos and
chaos is very important to development as is randomization and maximizing the alternative
frames. So I think that's true personally. But I think, and I have a theory that thinking and
ideas are essentially infinite. I'm not sure why there's a limit to it. And so if it was smart at
all, my guess, my preference maybe or my hope is that it goes in some interesting direction
of more, more variation, more possibilities, more explorations. And then you said like,
like humans, because of our biological grounding and our competitive like humans are
hyper competitive, even when the act like they're not that's just a good competitive strategy.
Like you, you're both very nice. That's a winning strategy with a lot of people who are going to
make friends that way. Like, but, but we're hyper, no matter what, we're hyper competitive.
We have a built in zero sum game, we're very oriented towards the world about whether it's
like one of the basis of company cycles of is it uncertain that enables exploratory behaviors
and growing that enables us to participate in growth. Is it steady state? And then we
start reacting with steady state means we're going to run out, by the way, like then you start
exploiting what you have and trying to get your share. And then there's inevitable collapse. And
then, you know, we reset. And so, so we're very aware of those states. And so AI that triggers
fears of competition and running out in scarcity is very different from technology. So like when
technology has been a lot of fun, it's when this is like the iPhone created a new possibility,
the internet was a new possibility. You know, the thing I'm not super happy about AI right now is,
you know, only large companies heavily funded, you know, big guys are doing it. And they're,
they're using the language of establishment and scarcity, which triggers people to fear it.
As opposed to the language of the PC, the iPhone, like some of those technologies literally came out
of small growing companies. And they had the energy of growth, which stimulated the people around them
to think, by the way, I just, this just occurred to me. So it's not something I was doing on.
But anyway, it seems kind of obvious that, like, if the environment says, Hey, there's only so much
of stuff and we might run out, which is the endless drama about resources, where we're
going to run out of resources, you guys somewhere and you believe we're going to run out of copper
or something, I can prove to you that we won't run out of copper or aluminum or silicon dioxide.
It's literally what the planets made out of. Like, we can't run out of materials to make chips.
Right. It's actually suspicious how much computer technology is embedded in the near part of the
earth. Like, I have a theory that this is the earth is the remnants of the previous supercomputer
that was, you know, in some sense, for a planet like this, too. I often just think about us being
of the earth and just some sort of organ that the earth has produced. Yeah, there's just enough
carbon, carbon to give the book program is biology, but computational substrate is silicon dioxide.
And there's a bunch of reasons like carbon is super good, low temperature chemistry and carbon
chains and all kinds of stuff are silicon saster. It's 300 degrees C, you know, gotta melt it
1000 degrees C. It's really sticky. You put an atom on a silicon atom, it's stuck there. It's
you can only manipulate it at high enough temperatures that you really don't want to,
whereas like carbon is fantastic, low temperature, relatively low vibrational mode, you know,
you know, chemistry. It's super good. But anyway,
That idea about the competition and the scarcity.
Yeah. So, so the, the, the, the advertising guys would like you to think there isn't enough to
stop. So FOMO and it's valuable. Like you may charge more by convincing people, there aren't
very many of them and only you have the good one. So the current, you know, marketing end of consumer
capitalism is all scarcity, you know, demonizing, like just scaring the shit out of people.
We're going to run out of oil. That's crazy. There's lots of oil. We're going to run out of
ox, what are we going to next? We're going to run out of oxygen. We're going to run out of food.
We're going to run out of carbon or aluminum. Jesus Christ, like, like there are 7%
aluminum or something. We can't run out of aluminum. But, but, but that puts you in the
mindset of fear and running out. And so the technologies that were exciting when film first
came out and airplanes came out, there was 40 airplane companies, maybe a hundred and cars,
there was a hundred car companies and PCs used to go there and there'd be 50 guys making PCs.
Right. So today, the big AI is coming out. Nvidia makes the chip and Microsoft open
AI and Google make the AI models. And it's a, there's a scarcity mindset to it and a
unobtainium something to it, which is not good for technology and good for people. We're not
running out of air. We're not running out of aluminum. We're not running out of compute. We're
not running out of, like we should be in a, in a growth mindset. And humans are very fun to be
with when you're in a growth mindset. And we're very boring and let's say not great to be with
when you're in a scarcity mindset. Scarcity mindset means if you eat that apple, I don't
get an apple and I'm going to fight you for it. Gross mindset of there's so many apples that are
falling from the trees and we're planning different kinds of trees and you talk to friends and they've
invented four kinds of apple trees last week. And you know, you can't wait to see what the next apple
is. You know, that, that's, that would be a fantastic world to be in.
What freaks people out about AI beyond just the scarcity is something that you mentioned earlier,
which is that you had product placements back in the day where everything was,
all the Marvel movies had Coca-Cola cans. And now you're going to have Marvel movies that have
a unique product based on all of the data that they've collected off of you off your cell phone
or whatever else. And that fractures reality just a little bit. And then you have all of these
subsequent fractures of reality where that shares if, if a shared reality is a limited commodity
all of the sudden, that's kind of the fundamental that that's the scariest thing at all where you
can go talk to somebody across the street and they no longer live in the same universe as you
because they have consumed video and media that has nothing to do with what you've seen.
And so that scarcity on the back of AI is kind of baked into the way that the tools are going to
be used because I can imagine more AI startups, you know, if the chip isn't $25,000 and you have
people that are interested in building stuff on the back of it, then it seems plausible that
you could get that kind of ecosystem. But that ecosystem seems to feed into a scarcity of shared
reality. And that's really interesting. Yeah. So I mean, if this cycles happened, you know,
with newspapers, with movies, with television, with the internet, where when it's in the gross
mindset, lots of people participate, we develop a sense of trust with it. Like I remember when
television broke trust in the 60s, because they were lying about the war and lying about the peace
march. And then in the 70s, there was lots of cynical TV shows. And so that, and I know that
got gained as well, but there was kind of an era of cynicism about something that had been trusted.
Walter Concrete was the news. The New York Times was the news. And these are institutions you can
trust. And Walter Concrete died. And I don't think anybody believes the New York Times anymore.
Well, you know, some writers, yeah, so that, but, but here's the thing is that healthy human beings
form relationships with things and evaluate them with should they trust them.
Right. And then periodically, like sometimes it's individuals stop trusting this.
Like, I don't know if I mentioned this, scientific American, like I used to read it a lot, but I
noticed the computer articles were lousy. But I thought it was just a computer articles, but then
I talked to a friend who was a mathematician, and he said the math articles were lousy. And then he
called up a friend who was a chemist, he said, no, the chemistry. Oh, well, so shit. You know,
I thought this was trustworthy because now it's it continued to be fun because the scientific
American was essentially entertainment at that point. But it wasn't, it wasn't a trusted source,
as it were. Now, whether they know they're a trusted source, you're not idle, like these are
complicated things. And then trusted at what level and to what impact to you. So like, like the
Marvel movies were a really interesting thing, because the original stories were really well
grounded stories, like they were good archetypal stories. But then as they tried to elaborate it
and the bean counters took over, they started just making a whole bunch of blah, blah, blah,
you know, including whatever message of the week they were into, and then nobody watches them.
They're boring and repetitive. And so there's that kind of thing happens in like the same
thing happened on the internet. You know, like, there was everybody was there, there's all these
forums and people talking, and then they got into better technology, but then they got curated, and
you know, most people don't believe that much about that. But it's, but they are the relentless
and the selfish is interesting. And I think the same thing will happen with AI, like, like people
get gained by it. But at the same point, people start to go, let's say I generated, it's probably
you know, there's marginal utility on it. And then there's been many attempts to have curated
news and internet to media, like the internet you can trust, but it's really hard because
soon as they make any money, they got bought by somebody who doesn't feel that way.
And so it's, that's, it's pretty complicated, but most humans grow up in this world.
And then humans, humans sort their lives out depending on what they need to do.
You know, people who are trying to do geopolitical operations need to have a way difference filter
for, you know, let's say, you know, shenanigans and somebody who's running a, you know, simple store.
And technologists is the same way. So
I think that there's something in there about an eternal
untrustworthiness that's been with us for a long time. Because if you go back to a model where
we're all just 100 person tribes, it's not like the tribes are living in harmony. There's probably
warfare, there's conflict. And the leader of your tribe might be telling you things about the other
tribe that aren't true, but are functional and necessary in order for you to be willing to go
on a raid or whatever. And so I think that we've, sometimes I think about this in the sense that
we've blown ourselves into a false belief that there is something outside of our direct experience
with people that can be trusted, because we want so badly for that to be the case. Because if you
think about your own personal relationships, the people that you have relationships with that
are closest to the ones that you can trust them. Right? If you have somebody that you look at and
you're like, well, I can't trust you, you're probably not going to be very good friends with
that person. And so we want to be able to generalize that outwards to systems. But then as you're
speaking, I'm sort of thinking maybe that's a false, maybe that's been an eternal false hope
where even Walter Cronkite, like he was the news, but the CIA had tons of people at all these news
organizations. Yeah, he was just reading the paper. So here's the other way to think about it is,
you know, when you start to go into a scarcity system, the, you know, everybody you deal with,
you know, has some cost benefit with, you know, if they lie to you and you catch them,
that's a cost to them. But, and if the benefit, the line is really low, they're probably not
going to. So in a, again, in this frame of in a growth mindset, where there's lots to do,
the benefit of lying is relatively low because you can, you can get what you need.
But if you're convinced that, you know, things are tough, the company has layoffs coming,
you know, a company that's growing 10% a year is pretty healthy. People generally help each other
to get the job done. There's an interesting book called Stretch, which says if, if you have about
10% more to do than you can, you stretch and if somebody offers to help you, you accept it,
you appreciate it, right? If it's 50% more, you get burned out because you can't achieve your goals.
If you have 10% less than you need to do and somebody offers to help you, you say,
stay off my turf. Because if they do your work and there's a cut coming, the boss is going to go,
well, Jim only ever does 80% and, you know, Bob over here picked up the slack. And so
the stretch of the organization sets the trust level. It's almost sad how simple it is, but it's
actually true. Once you weed out the nefarious characters, if your organization's stretched,
they are incented to cooperate. And if there's not enough to do and there's cuts coming,
they're incented to undermine each other. It's the same thing with product placement and stuff.
Like, you know, Coke is a weird thing because it's like a zero value product because, you know,
zero to make, it's entirely, you know, manufactured and sold on brand. Nobody really cares what it
tastes like. I don't think so. I sure don't. But the brand has established something and humans
have, you know, habits and stuff. So they have a positive association with the brand, the image,
the consumption, there's a flywheel of that kind of thing. So I think, yeah,
and I like being generically afraid of AI. Like, it's not helpful because he can't solve any
problem by being worried about it. I mean, some understanding of how technology impacts society,
how we use it to change our culture, what stage we're in is really interesting. And then what's
going on with the players? Like, I think that's helpful. And then there's the, you know, the odds
that humans with this technology aren't going to develop intelligence is zero. Right? Like,
we're either going to keep going up or, you know, like, we're very dynamic. You know, we accumulate
knowledge, like there's eight billion of us. We're not super good with, you know,
low stress environments, humans do really well with some stress and some restrictions and stretch,
I think, the companies, you know, with real missions, you know, do real well because people
work together to solve the mission. And like, you know, it's a very curious time because we're
developing something very new in a time when many, many people were think we're in a zero-thumb game
and possibly going down, but, and the advertising to that effect is relentless.
You know, we're running out of, like, literally everything. Now, there are certain things that
are getting worse, like our ability to build roads, that's bureaucratically captured, that's poor,
following the ability to build airplanes, they've laid off all the engineers apparently, and it's
run by, you know, the accountants, like those things actually have. So airplanes got unbelievably
reliable, and then people took it for granted, and then, you know, but that just means...
It had something to do with their growth, too, because there was a merger with the fellow
Douglas, and they laid off all these QA people, and...
Yeah, yeah, it's quite the shenanigans, you know, they financial engineered it.
Yeah, it's, you know, that's the kind of thing that was like, if I had a magic wand,
I wouldn't allow mergers of large companies, because it'd be better for them to grow or fail
by themselves and create more small companies, because I think more small things is better
than small numbers, the large things. But I don't have that magic wand, and big companies
lobby heavily for a lot of those mergers, because that's how they make money.
Like, a lot of big companies essentially never have any new ideas, they just keep buying small
companies with ideas. You know, like, Google's, what's that?
Now, like, like Google, for example, has bought a large number of companies, but they're,
there's only two money making assets are basically search and YouTube, and they bought YouTube.
Facebook famously did better, because they bought WhatsApp and Snapchat, but I always forget the
list of them, but they bought a relative, they bought companies that actually had real growth
and value and continued to grow them. But it's not clear the world would have been better off
if those companies had been separate companies.
It does seem to be this tendency towards agglomeration, like there is, there doesn't appear
to be an upper level of size, like there is for something like a cell, right?
Well, yeah, yeah, that's pretty funny. Well,
yeah, the cell, like in a company, essentially, the cell is a small team of 10 to 20 people.
So all big companies like are made out of cells, right? And so, yeah, but one company can, you
know, acquire another whole animal and then merge the cells together and, you know, they'll do it
for some reason about synergy or efficiency or something. But it may in fact be because they
don't have any new products. So they have a lot of money, but they don't have any new products.
So some companies like, like big pharmaceutical companies, they invest a lot of money in R&D,
but almost all their new products come from acquisitions. So
And I wonder if there's the same sort of cycle, like there is with the megalodons, right? So
there's megafauna. There's a period on earth where megafauna dominate, and then the conditions
change, and then all of a sudden, they're no longer the dominant biological paradigm. Do you
think that the same thing happens inside of corporate structures where there's just an
era of huge companies, and then the winds shift, and then it goes back towards smaller companies?
No, I think things just tend to get bigger. So when I was a kid, I was taught that
animals are really big either because it's really hot or because it's really cold.
You know, mammoths are big at the poles because it's cold, and dinosaurs are big because it was
hot. And I thought, actually, they probably just get bigger. And then something happens,
like a big rock falls on the earth and resets it. And then they killed all the big animals
because the infrastructure for big animals is really complicated. So my guess is companies just
get bigger, and then they occasionally fail hard. Some companies have actually failed and gone
bankrupt after they've been big. And some companies, especially with the way government
bureaucracies and companies work, they can continue to acquire companies. But there will
be some financial reset. Like during the PC boom, all the companies involved were small.
Like IBM messed around with Windows and PCs, but they gave the operating system to Microsoft,
and they had their own chip, but they decided to buy the chip from Intel. Both of those companies
were small. And then Dell and Gateway, all these companies were all small. And they were all actually
too small for the big guys to even care about. But then they grew so fast, you know, they avoided
getting acquired. Like, that's an interesting phenomena that they grew. Whereas once, you know,
Google and Facebook and some other companies got big, they had grown so fast that they grew fast
enough not to be acquired. Zuckerberg famously turned down a billion dollars for his toy startup.
But then they turned around and they bought a lot of the small companies.
They became a business model at some point. I knew lots of people that were starting startups
exclusively with the goal of getting a profit. Google. Yeah, like the network thing happened
the same way. There was like hundreds of small networking companies, and the big ones got a
certain point. And Cisco's business model was literally acquiring successful startups and
ramping their revenue. And sometimes that was real, like a small company couldn't build a billion
dollars worth of network switches, but Cisco could. They had the supply chain that manufactured
and operations to do it. So sometimes actually great value like Cisco, like I think often did,
but sometimes it just, yeah, it's hard to say. It makes somebody someone. Hardware might be
different than software. Well, so there was a long time when hardware wasn't like that. There was,
in fact, you know, 50 or 100 airplane companies and files and motor companies. And then the big
companies in the US, they outsourced. There was a period of time when Ford made everything and
they slowly outsourced the seats and the transmissions and all in the tires and the shock
absorbers and all kinds of stuff. And so there's a there's a there's a pendulum swing they call
vertical to horizontal integration. Like you make everything in the stack or do you make your
piece like PC world was what's called horizontal structure. So Microsoft made the operating
system until made the chip. Del made the computer. Somebody else distributed the thing. Somebody
else made that work. But now Apple is a vertically integrated company. They make every single thing.
So you said that one of the things that you would do if you could waver one was to prevent
large companies from buying little ones. What are the other things that you would do?
I'll govern the arc or see if they'd have time limits. You know, obviously, you know,
our represent representative should have time limits or term limits.
Like if like imagine you wanted the most independent experiments happening,
so that none of them if they failed would take out lots of people.
So people want to build new houses and they can't because of the regulation. So they go somewhere
and start a town or some town allocates a whole bunch of land, which great. So they can build
houses and new roads and the new school, new shopping center. And as everybody moves in,
they all join the town council and they fast regulation so they can't build any more houses.
Right. So they're like, you know, they're like, you know, they're like, you know,
there's no limits. Right. So the like this. And again, this is this is biological like,
like we operate from zero some games and limits to growth and in competitive nature.
So if you want to architect a world, that creates keeps creating possibility.
But by the way, I don't think it's bad. So you know, you bought your house when you're 30 years
old and you know you raise your family or you retire there and you don't want to build a new
shopping center and screw up the neighborhood like sure go ahead and do it but then you can't
complain that there's no housing in the area like like the United States is literally three
you know three three million square miles of land most of it's empty you know there's
like we could support a population of a trillion probably most of it's really barren i don't know
if you've spent a lot of time in the intermountain west but that's a harsh harsh landscape yeah it's
an energy problem but the my premise is more small independent things are better
like and one reason we met was you had some scientists on that you know i quite like
and some of whom are literally actively suppressed by the scientific community
and again i don't know if they're right or wrong at some level like i'm interested in it and i was
you know surprised you know borderline shocked you know when i first discovered that there were
scientists who couldn't get their papers published not because they seemed obviously stupid but because
they didn't go to the narrative and you know at some level you could think
well i know governments could craft and big companies get bureaucratic and stodgy and but
at least you know the scientists you know einstein surely einstein is a good guy and
and you know the people who studied his work and then you read these articles it was peter voigt
you know peter voigt he wrote the book not even wrong that's what a few hours in his office one day
actually he was the reason i even went down this path in the first place so when i was a little
kid he had one of the first blogs that was critical string theory and i was so excited to meet him
and everything but uh he just turns out to have a lot of crazy mathematical ideas too so yeah but
he also is a very strong believer in some parts of particle physics so other people are wrong and
he's very dismissive of them and so being hostile to all their i heard book lost in the maths is great
but then she's very much uh true believer in other things so you know but you run into this
interesting phenomena that even people who who seem outside the canon in some places could
still be true believers in other places and actually i have a theory i have a theory that
you can only have one out of the canon idea at a time like well if you have an idea that you're
championing unless you're like thomas golds or something you mean you're only allowed to have
one idea out of the can that's a strategy or you think that's a human nature problem i think that's
a strategy i think that people are basically like look i know this is crazy yeah i'm not crazy
because i'm buying to all of the yeah yeah i'll tell you i believe that so the yeah so
no yeah and i and i kind of get that um but i i don't know for some people i they probably have
three craze and there's probably humans have a limit you know our our computational substrate
has limits on how many non-conformist ideas we can have at a time and that's that's another
kind of problem well it's really painful right like if you if you don't have any common ground
to stand on with other people it gets really painful i think you have to surrender to some
common knowledge at some point yeah and it's it's in this surprise i i told you guys i i found this
list of you know crazy things about the sun which i thought was fun but i talked to a you know
sun scientist and he was quite mad about it and i bet you know i was i was a little taken
back because i was like man this is amazing like you know like there it is right there it's so hard
and complicated and um so the the polar morality of ideas is i think really important and and then
so the recognition of tendencies like i told you there's this you know chaos versus order
productivity graph like everybody can tell you where you should be but nobody knows how to stay
there it's like when they built the interstate highway system they invented the road system
the equipment to build the companies were created like everywhere they went they had to build new
companies to build these new roads and it was sort of like they were so excited about building
new roads they didn't have time to think like we could literally steal half this money and nowadays
it costs literally 10 times as much money per mile to build a road and they're better engineered
quote unquote and better planned and you know but the money disappears in bureaucracy and so
you know like the best thing would be a way to like really reinvent all kinds of things
so like young people everyone's like people say stuff like oh you know there's so much debt and
you're screwed all this up it's like yeah but we built all that why don't you build your own stuff
like like the current car test companies are defunct you know then elon builds a new car company
everybody's you can't build a car company you definitely can't build a rocket ship company
and you definitely can't build a new airline company he's probably got a list of a hundred
things those things you can't build like build new stuff i'm involved with atomic semi to help
pound the company and we're building a semiconductor fab that's really small and like you explain it to
people and they'll say well half that might work and half like it'll never work obviously semiconductor
companies cost 10 billion dollars where are you gonna get 10 billion dollars it was like
one of those gonna build it for 10 000 like not 10 billions and we've developed so much
scientists that so humans are uh Jordan Peterson told me this funny line just like like there's a
high incentive to get used to things so the first time you drive somewhere it takes a while right
but if you drive there 10 times you drive back and forth every day you don't even notice the
drive anymore and i've noticed even on like a hike when you walk like if you walk a hike and you
walk there and then you walk back the walk there takes twice as long as the walk back
because you've already you know because it's your your perception of time is novelty and you know
bias which is really curious but there's a couple of exceptions to this like you don't get used to
your kids well if you do you they'll die so or it could be your perception of your children is
highly influenced by important they are to you so even small deltas are novel like there might be some
like the like the nice way of saying is if you love your children they're always new
but the other way that the economy argument of it is we're not descended for people who didn't
pay attention to their children so we pay attention to them and we know there's pretty small differences
whereas you you walk down the street you don't really care very much whether your neighbor
mowed their grass or moved a car around this year an idiot right so do we have this kind of funny
so but the problem with that is we get used to everything we're used to the science we have
we're used to how they make cars you know we're used to the things like when i first went to the
tesla factory like it was all new to me right and it would really warm me out i'd spend hours there
i'd go home like you know flashing lights and moving equipment and after a year i've been there so
many times like i wouldn't i wouldn't be walking to a meeting annoyed that i couldn't park my car
i was five minutes late so i was walking fast through this factory of wonders i was walking
to a place that literally made me sleep an extra hour a day for three months because it was so
novel and new and right and now i was walking by it all annoyed that i was late like and and this
happens to everything scientists physicists you know they're so used to string theory everything
is bullshit compared but and we're so good at something like i i really love the line um
the unreasonable effectiveness of mathematics right but there's a counterline to that which
is something like like physics isn't mathematical because we know so much it's mathematical because
we know so little like it's so wild so yes so the if people had a better understanding of
you know why should there be limits to size why should there be limits to duration why
is it hard to stay on the high point of the productivity curve why do we get so used to
things that we ignore them even when they're really important why do we accept that you can't
build a better x y or z why are you condensed by advertisers who have only their own interests in
mind that we're running out of everything great scarcity you know like like these are hard things
to get out these are mental traps there's there's a lot of them and some of them are like we earned
like being a zero-sum person as a person member of a tribe after a million years of
of evolution that pretty smart strategy right now being oriented towards whether it's spring
summer or fall you know that's also pretty smart too you know like in the winter you know you fight
over the last apple in the summer you know that's great right so so but knowing these things is
important because because we build politics around them we build structures around people
build their lives around them i know people are going to spend their entire lives worried you know
it was peak oil and then peak this and peak that you know and none of it happened like literally
none of it happened make sure that's so vital and it's really interesting because it keeps coming
up it translates into your personal life too right in terms of where you put your attention
yeah yeah yeah people i had this uh like i had this mind-bending experience as an artist like as
a musical artist where i heard something uh Nigel Godridge he's a producer he worked with radio
head for many years he said something like in an interview one time just blew my mind where he was
like you need to stop trying to make it sound good and start trying to make it sound interesting
and i was like wow that's really profound because that's exactly as a musician who's been playing
an instrument for 40 years or something you're so obsessed with like optimizing your technical
ability and it's like nobody cares like literally everyone only hears technically
perfect music all day every day but it doesn't stand out because it's technically perfect it
actually blends into the background and these artists just kind of decay into fade away into
nothing and so there's just something really really interesting there about following what's
surprising and what actually grabs you as opposed to what's perfect or what's you know the best
version of what came before yeah i saw Crosby stills and Nash i guess play and they played their top
hits just exactly like they played them 30 years before which i thought was terrible and then i um
because they were such a wild band like they they did like five albums in two years that were all
knockouts and then they and then Jeff Beck did this live album that was so much better and
more interesting than his early stuff like he never stopped experimenting with a guitar he
could make it sing and dance like like some of it you can clearly hear in his earlier stuff but
that was just amazed i always liked the Jerry Garcia line when we got some what his limitations
were he said everything i learned everything i know everything i played like that like that's
an amazing thing and he was like i really like his guitar playing too but he also had a style
and then he killed himself with heroin like jesus i don't know well i wonder if that was
too if like this the drug side of things too is just some reaction to that in a build that that's
trying to get outside to get out of your own way kind of thing yeah yeah yeah it could be some of
what made him great was also what he was playing with with elucid and janet and heroin god knows
what we got that's a tough road to hoe though i think technically it was diabetes they killed him
but he apparently would live on ice cream for months at a time okay which cherry you gotta see
yeah yeah he sued him over that too that was pretty funny names are after him
they literally killed us that's right because there's a big Ben and Jerry is that the corner
of Hayden Ashbury right now oh it's oh you can't even pick it up it's like but you know that that
kind of combinational complexity and insanity is just a beautiful thing so like like he couldn't
that's that's as weird and deep as you could possibly get at some level
i mean it's been really really fun talking to you you know so much about the arc of this
technology that's shaping everything about the world right now and you're working so deeply on it and
you have a really subdued optimism about it which i really like
a dude optimism my nephew said i'm a cynical optimist
i haven't looked at too much cynicism over here i think that you call things as they are but it's
just i want to see a world where people are optimistic again yeah that's a great goal
and and humans are good at being optimistic but we are so attuned to our environment you know like
the like it sounds dumb but there's winter spring summer and fall and winter again
and you know we were very optimistic towards the length of the day and the growing of every
sentiment and you know logically pessimistic you know at the end of the year where you start to
run under here and work run out of stuff and our environment and our culture and everything that
we create influences people's attitudes and stuff and and getting like like even like like a company
culture like how do you get to a growth mindset and one reason i love working freelance is i watch
them create it because it's like we're going to save our so we're going to go to get a backup
playing it and we're going to do 10 of possible things and and we're going to work our asses off
to do it and there's so much space now that's all the space are we going to make a rocket better
well one set of people say you have to write a stupid or requirements document and outsource it
through government contractors and you know get a rocket that sucks for a lot of money and the other
one that says we're going to build a little rocket and we're going to be able to do we're
going to we're going to keep doing it every day and we're going to make the machines so they quickly
ran out of machines to make the rocket so they had to make some of the machines to make the rocket and
you know and then you know something magical happened because now they can
they land rockets that take off it looks real it never looks real like watching them take off
and land it just feels like the future we don't have flying cars but we have reusable rockets and
i feel like that's a decent we're going to build flying cars don't worry about it's coming
the be optimistic no i was in a like i was at tesla the first time they landed two rockets
next to each other and they set a big tv screen with a couple hundred people went there and
everybody's milling around and they we watched them take off and then you know the cameras
are following them up and then they separate and then they come back and then they landed
the whole place jumped up and down cheered people hugged each other's people there's grown
people crying it was so fantastic and i thought i got to be you know so great to be part of that and
here's the crazy thing we could all be part of that every day
now you have to ask yourself why aren't you part of that every day
like how many how many things have impacted you in a way that you know we're all getting
nagged by society and people are interested in you know nagging us for their advantage it's a
it's a crazy thing i think i'm less cynical because maybe i'm more accepting like the solution to
cynicism isn't to ignore it to be bitter so you figure things out and then you notice things like
humans go through lots of cycles they're often absolutely horrible that they create wonders
and people aiming at wonders are way more likely to do something good than people aiming at
you know terrible things or restrictions or the whole degrowth thing is crazy like like i know
where it comes from if you think it's november it's going to be cold for six months it's a pretty
good mindset there's i think that there's something about california like you're talking
about environment having a huge influence of mindset and california is a place that doesn't
really have winter you know it has you know like it has a sunny and it has a slightly wet period
but it's just this kind of flat experience and it was really interesting moving to a place like
new york where all of a sudden you're confronted viscerally with the fact that the seasons come
and they change and winters are always around the corner even when it's peak of summer you're
already thinking about that biting wind in the in the canyons and so i i don't think that it's
incidental i was worried about the swampy summer summer a lot more for me it's just there were
times where it would be so cold in windy in manhattan that you would round and the wind would
blow along the avenue and you would round the building and it would just literally take your
breath away it would hit you in the face and you're just like and then you reenter it and you keep going
but the optimism that california offers in this place where there's sun and there's grass and
there's ocean i think that it isn't an accident that so much of the technologies that shapes
the future is coming from california because it is a place where it's easier to be optimistic than
perhaps anywhere else in the country yeah but on the flip side then it also creates the comfort
stuff that humans are also not very good at so not like it's a we're we're a curious we're a
curious species you know and and you have to be knowledgeable about what that is
you know the when i was in intel there had been a 10 layoff which by you know silicon
valley standards and companies with troubles with nothing and like four years after it happened
they all still talked about it and and that's partly because it was viewed as unfair and
fully executed which might have been true but there was also a presumption of stability and
comfort right that had grown into the culture and and and that kind of thing could have been
you know a reset and a positive journey but it caused people to kind of double down on protecting
their turf and security and really dysregulated quite a few people and so the that seems weird but
like even big organizations need proper spiritual leadership to to navigate you know stuff like
that you know there was a need for change and reorganization but it had like almost everything
needs to be done skillfully now sometimes you can't do it skillfully because you just don't know and
you know the famous world war two study where they evaluated like the quality of decisions
based on the time contemplating the decision no they and they found there was no correlation
so there was decisions made in weeks decisions make months decision making years but the decision
making time was not correlated with the quality of the outcome and the big difference was the
faster you made decisions if it was bad you found out faster and so again this is great
attention so you need to have some framework and some like you know sensible guidance when
you're doing change on the flip side you know change needs to move at a pace such that you can
evaluate the failures of it to move on and again that's like and they're both true
and so like look how do you be you know and human beings need to be able to live in a world where
many many many things are true and then we're navigating a line along some set of these constraints
but some things okay have more positive outcomes than other ones
I mean like maintaining a clear line for how those cause and effects
folds together is also really important right because the worst outcome is to make a decision
and then to not really understand what the effect of it was so you can never evaluate if you made
the right decision yeah you see that kind of stuff happen all the time yeah yeah yeah when you want
to learn stuff and make decisions and do experiments and sometimes fail then you really have to be
willing to look at what really happened and why and some companies are going like we're going to
make more decisions and fail when we need to and then they all cover up what the failures were
assigned blame to the political parties out of power and you know it doesn't work at all
oh yeah I like companies where like like Tesla had this idea like doing the normal thing was
failure thinking a risk was good and if it worked out that's really good and if it didn't work out
if you learn something that's good as opposed to most places you judged on the outcome you know
if it worked it's good if it didn't work it's a failure and which makes a lot of sense unless
you're trying to do new things in which case doing the same thing has doomed you to not improving
I heard that culture really broke a lot of people though yeah oh yeah it's really hard on people
yeah no I saw people at Tesla like after four years a lot of people would be burned out but
I tell you they're way better engineers when they started so they kind of give questions what's your
goal to have a happy comfortable life or to have a you know population of people that can do things
pick stuff up and get to work cheerful what's that said what's your goal oh I like to do stuff
oh like I'm really curious about things like I'm curious what's gonna happen I'm curious about what
people are gonna do like currently I'm running a science project that my company about can we
achieve a high level of creative and productive output with you know independent autonomous
teams doing stuff oh like I'm into it it's fun to watch people it's it's in every possible
I think I could I could jump in there and help out what if they fail they'll learn a lot more and
then you know like we'll see what happens yeah I played the fuck around to find out video for
the whole company in all hands super fun what's that I said I don't know what that video is
I'll send you the video you'll laugh yeah it's a little walkthrough of a graph about
you know what do you have to do to find out it's uh it's pretty important all right we'll keep it
in mind well then and then some group did one of my teams did something and then the complete
message they're like well Jim you told us to do this like you played the video like what did you
expect would happen well I was hoping you did it right a couple times faster and you know figure
it out a little bit are you are you still hiring yeah yeah where you're hiring oh yeah over the last
year and a half we had some like let's say leadership voids and we did a bunch of reorganization
and smaller teams and right now we're we're mostly hiring for like skill sets we're hiring
programmers and you know like computer design is complicated there's so many different skill
sets like people don't realize how many disciplines there are like even if you're an electrical engineer
a computer engineer a programmer underneath there's a lot of differentiation um so yeah we're gonna
probably hire 50 people relatively short order and and then when you hire people it's really it
the coolest thing is everybody a hire changes your group a little bit
but you make a plan and then hire some people and then the new people change what you're doing and
why and there's new ideas and sometimes it causes a reshuffling of how the org works
um yeah 10 star it's 450 people oh so if you're hiring 50 it's like a pretty significant yeah it's
a big chunk yeah tom xx me we're close to 30 yeah it's super fun very cool well i think we should
let you go there's a lot more left on the table to talk about but i'd prefer to just have you back
then to keep rolling right now right hey great to chat i was very curious how this would go yeah
thanks jen you're a fascinating dude oh yeah you guys too keep it up i uh i enjoy your guys
content too appreciate it thank you so much have a good rest of your day all right take care
