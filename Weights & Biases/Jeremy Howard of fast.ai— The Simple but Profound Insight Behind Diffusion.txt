I've been telling everybody who will listen that I feel like we're in the middle of a
significant spike in technological capability right now.
And so if you're not doing that, you're missing out on being at the forefront of something
that's substantially changing what humans are able to do.
You're listening to Gradient Descent, a show about machine learning in the real world,
and I'm your host, Lucas B. Wald.
Jeremy Howard is the founding researcher at Fast.ai, which is a research institute dedicated
to making deep learning more accessible.
They make an incredible Python repository that people use for lots and lots of deep learning
projects, and they make an incredible set of classes that many people I know have taken
and is almost universally loved.
He was also the CEO and founder of NLITIC, the president of Kaggle, and has done a whole
bunch of diverse, amazing things in his career.
It's always super inspiring to talk to Jeremy, and this interview is no different.
I really hope you enjoy it.
You are the first person to be on this podcast two times, and I think you are the most popular
guest that we've had based on our YouTube metrics, so it's great to have you.
And I guess I wanted to start with, actually, the most memorable part of our interview for
me personally was the amount of time that you set aside every day to work on just learning
and just said undirected learning new things, which I really thought was an amazing thing
that I always aspire to do more of.
But I was curious lately, what have you been learning?
I'm spending all my spare time at the moment on generative modeling around the stable diffusion
or diffusion modeling space.
Hence the new course, I guess.
Yeah, it's a bit of a chicken and the egg thing.
It's partly the new courses because of the learning, and partly the learnings because
of the new course.
I've been telling everybody who will listen that I feel like we're in the middle of a
significant spike in technological capability right now.
And so if you're not doing that, you're missing out on being at the forefront of something
that's substantially changing what humans are able to do.
And so when there's such a technological shift, it creates all kinds of opportunities for startups
and for scientific progress and also opportunities to screw up society, which hopefully you
can figure out how to avoid and stuff like that.
So I'm very keen to do what I can to be on the forefront of that and to help others who
are interested in doing the same thing.
And when you say spike, do you mean diffusion models specifically or do you mean machine
learning more broadly?
Do you mean like this?
I mean diffusion models specifically.
Interesting.
Interesting.
Yeah, it's a simple but profound insight, which is that it's very difficult for a model to
generate something creative and aesthetic and correct from nothing or from nothing but
a prompt or a question or whatever.
And the profound insight is to say, well, given that that's hard, why don't we not ask
a model to do that directly?
But why don't we train a model to do something a little bit better than nothing?
And then to make a model that if we run it multiple times takes a thing that's a little
bit better than nothing and makes that a little bit better still and a little bit better still.
And so if you run the model multiple times, as long as it's capable of improving the previous
output each time, and it's just a case of running it lots of times.
And that's the insight behind diffusion models.
As you'd be well aware, Lucas, it's not a new insight.
It's the same basic insight that all that belongs to this class of models called boosted
models.
So boosted models are when you train a model to fix a previous model, to find its errors
and reduce them.
And so we use lots of boosted models, gradient boosting machines in particular are particularly
popular, but any model can be turned into a boosted model by training it to fix the
previous model's errors.
But yeah, we haven't really done that in generative models before.
And we now have a whole infrastructure for how to do it well.
And the interesting thing is that having started to get deep into the area of realized we're
not close at all to doing that in an optimal way.
So the fantastic results you're seeing at the moment are based on what in a year's time
or two will be considered extremely primitive approaches.
Could you say a little more about that?
Sure.
So broadly speaking, we're looking to create a function that if we apply it to an input,
it returns a better version of that input.
So for example, if we're trying to create a picture that represents a cute photo of a
teddy bear, then we want a function that takes anything that's not yet a really great
cute photo of a teddy bear and makes it something a little bit more like a cute photo of a teddy
bear than what it started with.
And furthermore, that can take the output of a previous version of running this model
and run it again to create something that's even more like a cute version of a teddy bear.
It's a little harder than it first sounds because of this problem of out of distribution inputs.
The thing is, if the result of running the model once is something that does look a little
bit more like a teddy bear, that output needs to be valid as input to running the model
again.
If it's not something the model's been trained to recognize, it's not going to do a good
job.
So the tricky way that current approaches generally do that is that they basically do the same
thing that we taught in our 2018-2019 course, which is what we call crappification, which
is to take a perfectly good image and make it crappy.
In the course, what we did was we added JPEG noise to it and reduced its resolution and
scrolled text over the top of it.
The approach that's used today is actually much more rigorous but in some ways less flexible.
It's to sprinkle Gaussian noise all over it.
So basically add or subtract random numbers from every pixel.
And the key thing is then that one step of inference, so making it slightly more like
a cute teddy bear, is basically to do your best to create a cute teddy bear and then
sprinkle a whole bunch of noise back onto the pixels, but a bit less noise than you
had before.
And so that's by definition at least going to be pretty close to being in distribution
in the sense that you train a model that learns to take pictures which have varying
amounts of noise sprinkled over them and to remove that noise.
So yeah, so you can just add a bit less noise and then you run the model again and add a
bit of noise back, a bit of less noise and then run the model again and add a bit of
noise back, a bit less noise and so forth.
So it's really neat but it's like a lot of it's done this way because of kind of theoretical
convenience I guess and it's worked really well because we can use that theoretical convenience
to figure out like what good hyperparameters are and it'll get a lot of the details working
pretty well.
But there's totally different ways you can do things and you can see like even in the
last week there's been two very significant papers that have dramatically improved the
state of the art, both of which don't run the same model each time during this boosting
phase, during this diffusion phase, but they have different models for different amounts
of noise or there are some which will have like super resolution stages so you're basically
creating something smaller than making it bigger and you have different models for those.
What we're starting to see is like a gradual move away from the stuff that's theoretically
convenient to stuff that like is more flexible, has more fatally hyperparameters to tune but
then people spending more time tuning those hyperparameters creating more complex mixture
of experts or ensembles and I think yeah there's going to be a lot more of that happening
and also the biggest piece I think will be this whole question of like well how do we
use them with humans in the loop most effectively because like you know the purpose of these
is to create stuff and currently it's like it's almost an accident that we can ask for
a photo of a particular kind of thing you know like a cute teddy bear, the models are
trained with what's called conditioning where they're conditioned on these captions but
like the captions are known to be wrong because they come from the alt tags in HTML web pages
those alt tags are very rarely accurate descriptions of pictures so the whole thing you know and
then the way the conditioning is done is kind of really got nothing to do with actually
trying to create something that will respond to prompts so the prompts themselves are a
bit of an accident and the conditioning is kind of a bit of an accident so the fact that
we can use prompts at all it's a bit of an accident and as a result it's a huge art right
now to figure out like how you know trending on art station 8k ultra realistic you know
portrait of Lucas B world looking thoughtful or whatever there's whole books you know of
like here's lots of prompts we tried and here's what the outputs looked like and then how do
you like customize that because actually you know you're trying to create a storybook about
you know Lucas B world's progress in creating a new startup and you want you know you wanted
to fit into this particular box here and you want a picture of a red button in the background
there and you know like how do you get you know the same style the same character content
like the particular composition you know it's all about this interaction between human and
machine there's so many things you know which we're just starting to understand how to do
and so in the coming years I think it will turn into a powerful tool for you know computer
assisted human creativity rather than what it is now which is more of a hand something
off to the machine and how could it's useful do you think the same approach applies across
domains or is there something about images the way it's sort of obvious how to add noise
and maybe the data set that that we have I mean certainly the way you described diffusion
you could there's a natural application that's almost any domain but I guess Gaussian noise
and text it's a little unclear to me like what that what that really means so last week
a paper showing diffusion for text came out there's already diffusion models for like
proteins there's already a fusion models for audio the audio ones are user or some of them
use a fairly hacky obvious but neat approach of using diffusion to generate spectrograms
which images and then having something like a super resolution model but it's not doing
super resolution it's doing spectrograms just to sound so yeah these things are already
starting to exist they haven't had as much resources put into them yet so they're still
not that great but yeah that's the thing Lucas this is not just images at all it'll you know
it'll be for used in medicine it'll be used in copywriting I mean you know the way we
currently do generative text models again it's kind of a happy accident so when I did
dual M fit the whole reason I created a language model was for the purpose of fine tuning it
to create a classifier you know and GPT then that took that idea and scaled it up with transformers
you know what Alec Radford was trying to do there was not generate text but trying to solve other
problems by fine tuning it there was this kind of discovery almost with GPT3 that when you take
this and you scale up far enough it actually starts generating reasonable sounding text
but the text is not necessarily correct in fact it's very often wildly incorrect and so yeah it'll
intentionally working on text generation approaches which is specifically designed for
generating text is something that there's a lot of room to improve and generally speaking the way
I see it is this is you've got a generative model that's trying to do something difficult and it's
pretty good at it or at least better than nothing it'll be better at it if you can do it in a way
that it runs multiple times during inference because you're giving it more opportunities to do its
thing so I think you know that means that these multi-step inference models you know which may
or may not be diffusion models but kind of boosted generative models are here to stay
because no matter how good your model generative model is you can always make it better if you
can find a way to write right at multiple times I guess that is a good segue to another question
I had which is I think one of the really fun things about deep learning in the early days was
it was so tangible and you had you know you have this fantastic class where you can just kind of
you know build these models and see how they work and and play with them and so I think we both
have a very similar learning approach but one thing I've personally been struggling with honestly
with these bigger models is just actually like engaging with them in a meaningful way like
you know it's it's fun to run the various like image generating models but it feels kind of daunting
I'm not sure I have the the money myself to buy the compute to like make one that really works
we actually had one person on this podcast who did it for fun Boris which is a super fun episode
and I felt really jealous of how much fun he had building it but I'm curious how you
turn that problem into something like tractable that you can actually engage with
yeah well you know I mean remember Boris is one of our alumni he's part of our fastai community
and he showed what is possible for a single tenacious person to do although I think Google
like donated like a hundred thousand dollars a computer so it wasn't totally yeah absolutely if
you can show that you're doing useful work then there's plenty of compute out there which you
can get donated to but having said that you know he what he was largely trying to do at least at
the outset was to replicate you know what open an AI had done I take a very different approach
which is I always assume that the best thing out there right now is far short of what the
best thing could be you know that in five to ten years time there'll be something better
and I always look for improving that so yeah so you should take our new course Lucas I was
loaded on which we're in the middle of because what I've been working on is exactly what you
describe which is how to train and play with the state of the art the image generative model in a
notebook on a single GPU and as with all of these things the trick is to start with an easier but
equivalent problem so I'm doing all my work just about on the fashion MNIST dataset which rather
than being 512 by 512 pixel images of literally anything in the world including artworks they're
20 at their three channel fashion MNIST is 28 by 28 single channel images of one of 10 types of
clothing now I always tell people like whether you're doing a cackle competition or a project at
work or whatever are the most important two steps are to create a rapid feedback loop where you can
iterate and test fast and to have a test which is highly correlated with the final thing you're
going to be doing so that if you have those two things you can quickly try lots of ideas and
see if they're probably going to work you know on the bigger data sash or the bigger harder problem
or whatever so it turns out fashion MNIST basically yeah I've kind of like replicated a bunch of
different approaches from the literature on fashion MNIST the relative effectiveness of
those different approaches on fashion MNIST mirrors basically exactly their relative effectiveness
on cocoa or image net or lion or whatever cool but I can train a model on a single GPU
to a point where I can see relative differences in about two minutes
wow and that means I can yeah like very rapidly try things and so I've started yeah building notebooks
where I show every single little step and also it helps a lot to use notebooks which
almost nobody working in the generative modeling field seems to be doing at the moment so what
they do is they have you know the normal approach is to you know do image net 64 pixel or you know
sci-fi 32 pixel which is still better than doing 512 by 512 lion but it still takes you know image
net 64 pixel takes many hours on an 8 GPU machine you can't do a fast iteration loop you know
so yeah in a notebook you know I can like run a single iteration of diffusion I can see what
the outputs look like because the pictures are all there in front of me you know if you're not
using this kind of approach instead you're switching back and forth between a terminal and then you
need some way of actually viewing the images and given that you're probably not sitting directly on
that 8 GPU box you're probably sshing into it so now you've got to find a way to show you those
pictures there are ways by the way of showing pictures in the terminal for example if you use
item 2 there's something called image cat if you use other terminals they probably support something
called six all six all graphics but there's you know they're not going to be as a good exploration
environment for this kind of stuff than a notebook is so yeah I think there's lots of opportunities
to you know people like you and me to play in this field I mean I know there is because I've
you know started spending time talking to some of the folks who were the primary researchers
responsible for their key components of stable diffusion and I'm already telling them things
that they hadn't thought of before by virtue of weird little experiments I've done with fashion
MNIST on my single GPU Jupiter notebook yeah that makes sense I mean a fast feedback loop
is so important I mean that's very cool I was curious broadly if you have thoughts on stable
diffusion in general I feel like you know we're sitting here in November you know 2022 and I
think they've done an amazing job of bringing awareness to to generative models I don't know
what do you what do you think of a stable diffusion I mean it's it's um it's been great for for
progress in the field really yeah I mean generally speaking I'm all about democratization and
accessibility as you know I I don't love the fact that before a stable diffusion was released
you know a small number of people in the world had access to the full generative models and then
other people could like pay for cut down versions of them use them in small quantities the thing is
accessing these things through a a web-based API is extremely limiting you know when you've
actually got the weights you can really play with both the engineering and the artistic side of
doing things that no one's done before so yeah I think that's great I think it's important
I think you know as with any of these things you release a new powerful technology out there
and a whole bunch of people are going to be using it for you know not necessarily the things that
you would have chosen to use it for so for example for stable diffusion it seems like a very large
percentage of people who are using it to generate lots and lots of images are doing it to generate
anime and specifically nearly entirely you know very young women with very few clothes on
anime pictures and I'm sure there are people out there who are taking the clothes off entirely
you know so that's I mean that happens I guess with any technology and I don't necessarily have
I mean you can't I guess you can't stop that happening but we certainly need
appropriate laws around at least you know making illegal things make sure the things that we don't
want to be legal are in fact illegal but yeah I mean there are obviously huge benefits and you're
not going to get stuff like you know protein diffusion models or you know pharmaceutical
diffusion models or you know none of those are going to develop if the technologies in the hands
of like two or three big organizations so it's certainly a very valuable step on the whole
for society to have this stuff as open as possible and to be clear it was it was all trained at
universities you know so the one the main one most of these stuff we're using now for stable
diffusion is trained in in Germany at German academic institutions using donated hardware
none I guess it's interesting though that it was I think primarily ethics and AI considerations
that you know made folks like open AI kind of restrict access to their models or at least that's
what they said do you think that you would know a priori that that was like the the wrong thing to
do were you would you actually I actually read a blog post about that back in when GPT-3 was
just like announced and not released and nearly universally the feedback at least from the AI
community was oh this is lame they're just doing it for profits and in my blog post I said like well
not necessarily you know like there are genuine things to be thinking about here
which is not to say that that means that the motivation wasn't at least partially profit driven
it might well have been like it's certainly convenient that the ethical considerations read
in this way entirely align with profit driven motives as well but like I say it doesn't necessarily
mean they're not true and I'm pretty sure it's of both reasons and if you look at the way open AI
has behaved since then they've behaved in a way that is very increasingly apparently profit driven
so I'm less generous in my interpretation now than I was then based on their continuing patterns
of behavior and I think also with the benefit of hindsight it feels a lot more like you know in the
last couple of years companies keeping models to themselves the main impact that sense of being
is to create a bigger bifurcation between have and have nots in terms of capability
requiring more researchers to pay for API access to do things a decreased amount of openness that in
fact even you know what could be argued as being kind of deceitful behavior so like for example we
now know that the open AI models that you can pay to access are actually not the same as what's
been described in their research papers and we've now had dozens of people write research papers
comparing various work to the open AI models and now we've learned that actually we're not comparing
to what we thought we were comparing at all and you know thousands of hours of
research at time being wasted and papers being published with what turns out now to actually
be totally wrong information in so yeah I'm definitely you know more enthusiastic about
the idea of being open than perhaps more confident about that than I was a couple of years ago
and I guess do you have thoughts on the language side of things like large language models like
do you do you think that for example do you think that prompt engineering is headed to be like an
important way of doing machine learning like you know you do see these models doing incredibly well
and like a wide variety of nlp tasks like better than models you know trained specifically on these
specific tasks sometimes yeah I think generative text models have both more opportunities and more
threats than generative image models um for sure like I say they're kind of the fact that they work
at all is in some ways a bit of an accident they're far far far from being optimized for
for purpose at the moment um but they're already amazingly good particularly if you
do this kind of stuff where I mean literally there are now dozens of papers just look at like what
kind of prompts happen to work on these models that we kind of accidentally made generative models
who's you know let's think step by step and whatever else um we're starting to find ways to
actually get them to do a little bit more of what we actually want them to do but so far using really
really basic things like you know this instruction tuning so you know rather than just feeding it
the entire internet let's actually fine tune it with some examples of things that are actually
correct you know that actually represent outputs that we would want for these inputs rather just
whatever somebody rando wrote on the internet 25 years ago um yeah so my worry is I'm much
well worried about misuse of text models and image models because it wouldn't be at all hard to
create a million twitter or facebook or whatever accounts and program them to work together to
impact the kind of worlds discourse in very substantial ways over time
um and nobody would know you know so we could have like you know like on on on twitter for example
some you know fairly small number of accounts um often where nobody actually knows the human
who's behind it can have very substantive effects on like what people are talking about and how do
people talk about that thing um and so imagine yeah a million of of those accounts which were
actually bots that had been trained to be more compelling than humans which which already for
years we've had bots which humans rank as more compelling than actual humans um and that they've
been trained to work together you know take alternate points of view in exactly the right way and
um this bot gradually gets convinced by that bot and whatever else like yeah it could cause a very
small number of people in the world to programmably decide how they want humanity to think about a
topic and pay to make that happen although if I if I remember right it seemed like all the fast
ai's like sort of broad mandate was to basically make a no-code interface into machine learning
so anyone could access it and it does sort of seem like prompt engineering to the extent that it
works is like a huge step in that direction is isn't it right yeah that's what I'm saying it's like
that's why I say it's like both like got more opportunities and more threats so yeah the
opportunities are vast to you know so take for example the recent thing that was released
like last week or so explainpaper.com where our students are already you know so with our course
we do you know look at a paper or two each week and so and so last week I had told told the
class's homework to re-implement the diff edit paper and so students are saying like oh I didn't
understand this paragraph so I highlighted it and explainpaper.com and here's the summary it gave
and that's a lot more clear now that I tried to understand that bit so I asked for more information
you know this is very very valuable and you know I saw somebody on twitter a couple of days ago
saying they don't really use stack overflow anymore because they created this tiny little
simple little script called ask where they type ask and then something at a prompt that's sorry at a
in the bash you know shell repel and it would feed that off to open AI GPT-3 and return that
the result and they basically use that instead of searching the internet nowadays. Wow so yeah
people are definitely using this stuff and it's going to get much much better. Do you have a clever
way like with fashion eminence and image generation to play with large language models on kind of a
bite-sized scale? Not yet no I some you know I'll get to that maybe you know another part of the
course I guess it's a definitely a great question and something to think about. Interesting okay a
question that I need to revisit because this is unexpectedly I think one of the reasons that
so many people listened to my interview with you last time you sort of made an interesting comment
that you felt like Python wasn't the future of ML and you sort of said maybe Julia is the
is the future of ML and that really seemed to like strike a chord with the internet everywhere I
think it's kind of the most discussed part of great sense of of all time so I'm just curious do
you have any more thoughts on that like I do you do you sort of still believe that like Julia is the
future you're sort of on the fence about that I mean I was I was on the fence about that last
time we spoke and totally I I would say I'm a a little less bullish than I was then because I just
I feel like the Julia ecosystem and culture you know it's so focused on these like HPC kind of
like huge compute running things on national labs machines and it's all stuff that's very
appealing to engineers it feels good but it's a it's a such a tiny audience you know and it's
not like I don't care about whether I can run something on 5000 nodes so I just want to run it
on my laptop and it's still not great for running on my laptop really and it's not great for creating
software that I can send you I can't you know if I created a little CLI tool or whatever well
it's not great for creating little CLI tools because it's so slow to start up and then how the
hell am I going to send it to you to try out it'd be like okay Lucas well install the entirety of
Julia and then run the REPL and then type this to go into package management mode and and then
okay now you've got this thing and now you can run it just like okay that's not going to happen
or you know even just deploying a website you know and it's a lot of fast and bother and
uses more resources than it should um it's still got that potential but you know I guess the other
thing that's become more clear though in the last couple of years is their grand experiment on type
dispatch it is more challenging to get that all working properly than perhaps I had realized
because it's still not really quite well working properly and I think good on them for trying to
make it work properly it's a it's a vast research project um but you know there's a lot of weird
little edge cases and trying to make that all run smoothly is incredibly challenging so I
I suspect um yeah something needs to replace Python but maybe it's something that doesn't exist yet
partly though I mean so what we're seeing instead everybody knows we have to replace Python so what
instead's been happening is we're using Python to create non-python artifacts so most obviously
Jax you know Jax uses Python or a subset of Python with a kind of a embedded DSL written as a library
which only lets you create things that can be expressible as as XLA programs and then XLA
compiles that to run fast on a GPU and that works pretty well it's very challenging though for
research or hacking or learning or whatever because because it's actually not Python that's
running at all so it's extremely difficult to like profile and debug and so forth that code
very hard to kind of run it in a you know really nicely in notebooks
so like in our little team working on diffusion models we kind of all want to use Jax
but every time we try it's always like because like everything I write it's always wrong the
first 14 times and with Python you know I I have fought it and goes at making it better
by like finding all the stupid things I did by running one line at a time and checking things
and looking at pictures with Jax I wouldn't know how to fix my broken code really it's
it's difficult but you don't think that that flexibility is like fundamentally in conflict
with making a language performant like I think it is for Python I think yeah so for Python like
that flexibility is to be able to actually run it as Python code
so like if you look at where PyTorch is going now they've got this Torch Dynamo stuff
where they're working you know they're basically you know can interface with NVFuser and you can
interface with Triton the the open AI compiler-ish thing I'm not exactly sure what you'd call it
but and so clearly PyTorch is heading the same direction as Jax which is if you want it to run
fast you'll use Torch Dynamo or whatever it ends up being called that's that's actually now you
know integrated into the PyTorch tree that's clearly where we're heading and again you end up with
you know probably you'll be using Triton so you end up a Triton's amazing super cool super
fantastic but you know you still end up with this thing that's running compiled code it's not the
same code you wrote but a version of it um again difficult more difficult to hack on this I think
you know if you look at how this works you know there's a whole world of of software that's written
in languages which are explicitly designed to work this way they're compiled languages you know
languages like C++ and Swift and Rust and they have something very nice which is they have
flags you can pass the compiler so you can pass that the D flag to run it in the debugger or you
can pass the O flag to run it you know the optimized version and so basically you get to choose
how close the code that's actually running is to the actual lines of code that you wrote
so that for debugging you can actually you know it'll run slower but it's actually running the
lines of code that you wrote and I think we want something like that something that yeah it looks
like Python it's pretty compatible with Python but you know you can still run it as Python but you
can also run it in an optimized way you know maybe something that actually takes better advantage
of these kind of type hints that we can provide yeah that's that's my guess is what's going to happen
is we'll see Python-esque languages you know we'll continue to see these Python-esque languages appear
that may begin to look less and less like pure Python and you know are designed to work better
and better with these back-end linear algebra accelerators and compilers
is there some language out there right now that that has that feel for you
no they're all they're all basically these embedded DSLs you know like tvm or like halide
um you know we have the MLIR you know project which is kind of providing the back end needed for
these kinds of things and you know chris latner has a new company which you know presumably going
to be placed better than any other to create what we need for this kind of thing um let's see is the
guy behind MLIR yeah but it feels like a a big open area to me at the moment it's interesting okay on
a totally different topic that i kind of can't believe we didn't cover last time i feel like we
must have been right in the middle of it um yeah i think guy along with many other people in the
world sort of watched you kind of advocate for wearing masks in the early days of um COVID and
you know i think you had one of the most i mean some of the most like you know high-profile
like articles on this like the second most popular article like free print print and
i'm just kind of curious um if you could sort of tell that story from your perspective and maybe
you know like what you were seeing that other people were were missing and how you're kind of
approaching that problem differently i mean it's hard for me locus because like i don't understand
why and i still don't understand why it's not reasonably obvious to everybody like what's
everybody else missing and why because like to me from my point of view well okay so like
let me go back so february 2020 you know mid-ish february 2020 like february 2020 um i i had a
course coming up at the university of san francisco that i was going to be teaching
and i had heard you know increasing chatter about this whatever chinese virus thing um
and i guess you know what i what then happened was it hit italy and there was a lot more
information in english about what was happening in italy and there was what was happening in china
so suddenly it was much more accessible to see what was going on you know particularly because a
lot of the italian doctors and whatever were actually on twitter and stuff so i could read
what was happening and that you know a whole bunch of people were saying like you know this is a
disaster you know i can't remember whether the president of the you know main italian medical
body just died of covid and you know there's not enough hospital beds and um and then i knew it
would have kind of just i think starting to get detected in new york and i thought oh well
it seems like it might be quite likely to come here what does that mean for our course you know
it's very like not at all altruistic just there is like are we still going to do our course so my
wife and i kind of started reading about it to try to figure out what should happen with the course
and as we did it we were yeah it's like very obvious that it was going to be a global pandemic
and it was going to sweep through san francisco within weeks and so like within two days i guess
i wrote an email to everybody who would register you know i think registered to the course and
put you know put out a blog post and said we're not doing the course
live we're going to do it virtually um this is well before you know our university or i think
any university had decided to do that which again i already thought was weird like i thought like okay
it's not yet here but obviously it's going to be so why are people acting as if it's not going to be
and so yeah rachel and i ended up writing a long blog post you know because we were kind of like
okay it's not just our course it's like we know we've got all these friends in san francisco who
are doing things that we're pretty sure they're going to look back on in hindsight and think that
that's a terrible idea because i put myself in my community at risk and so we said like okay here
you know we didn't know much about it so we just said look as data scientists here's what we can see
so far in the data you know it does seem to grow exponentially at least at first and you know this
is the impact it's been having in one body and here's the early impact in new york and here's like
how the math of these kinds of you know things work and so here's like not just a prediction but
almost certainty as to what's going to happen here and that got a lot of attention and we had no idea
how to avoid it ourselves but we were worried that like historically you know when there is
global pandemics it can lead to can lead to violence it can lead to societal disharmony
whatever so we we decided to get out of san francisco for a while we also it's clear that
it's going to be there's going to be a lockdown at some point because you know i mean why wouldn't
there be again none of our friends seem to believe any of this is going to happen it's really i
thought it was weird you know like it just seemed very obvious and then yeah there was a lockdown
like a week or two later we're told our daughter's school she's like oh that's probably going to be a
lockdown you know sent back this rather annoyed email about interrupting learning or something
um yeah and so the schools are closed for a year in the end in san francisco
so then we were like oh well how do we yeah how do we like
not get covid um because we probably don't want to get covid because it seems like getting
covid can be bad we started to hear from people who would like you know saying maybe there could
be longer term implications of some of these kinds of SARS viruses so i started looking into like how
it was spread and i discovered that there's all these countries around china that had avoided
getting hit by covid and particularly hong kong there's like literally a train line away from
rohan and that just seems amazing you know and that's what i discovered that like mongolia taiwan
and hong kong all had this kind of you know either universal mask policy or universal mask usage
kind of culturally and i thought oh that's weird because i thought masks are this kind of like
weird thing that i don't know for some reason you go to china town you see people wearing masks and
i was like that's weird you know i didn't have much notice of it but then i said yeah i started
learning it was this respiratory you know they're infection and um it's kind of seemed to make sense
and so i read something in the um washington post talking about how in the check republic
particularly the populace had independently decided to wear masks you know heavily driven by a kind
of a popular science youtuber um and basically yeah within like three or four days you know
the whole country had made enough masks for everybody and their president was like talking
about how proud he was and um and they're again they're like infection was going right was going
the opposite direction to other countries i thought that was interesting so yeah i kind of
read an article about that and then i talked to a guy who used to be very you know high up in the
government on the science policy side and i asked him what's going on with masks and he said like well
you know nobody thinks there's very convincing science about it so he said if you want to convince
people to wear masks then you'd need you know find some better science so i contacted basically the
18 smartest scientific researchers i knew um you know everybody from from
Max Friedman to say it to fecci and said you know not just scientific researchers and in
plain as case sociological researcher that said like you want to help me put together the evidence
so that's where our paper came from um basically everybody said yes they all agreed so suddenly
we had this huge author group so we kind of set up a slack channel and um and yeah none of us like
he had a really strong opinion going in had one of the world's best aerosol scientists he was probably
at the strongest opinion going in because this is his job and he was like well let me explain aerosols
to you and um and then what happened was there was this amazing couple of papers that actually used
this uh laser scattering light chamber thing to actually literally take videos of you know respiratory
particles suspended in the air not suspended but just they just float in the air it showed
that they float in the air for up to an hour and it showed that when somebody wears a mask
they don't appear and that was the point where I went from like curious and interested to 100
convinced because it'd be like as somebody said like I promise you Lucas if you throw this ball at
that wall it won't bounce off it will go through and then you'd be like well Jeremy I'm not sure
but I'll give it a go you throw the ball at the wall and it bounces off and you go like Jeremy
I am very sure you're wrong about your theorem and that's how it was with masks there are people
who said like our masks don't provide respiratory protection from from these airborne particles
and that here's a video of them not going through the mask so I was like okay that's
I don't need any rcts I don't like it's it's it's it's like there's a video it's a picture working
so yeah so then I kind of went all in on just trying to say to people oh look there's actually
a thing that stops the the thing that infects us so we should wear them and I found it extraordinarily
bizarre that everybody didn't just go oh look at that video of it working therefore it works
um so it's like a super frustrating experience like I don't there's nothing I enjoy about
researching masks and there's nothing I enjoy about political advocacy you know the former
is boring and the latter is stressful but when there's something that's so obviously
can like save millions of lives and also like and avoid who knows what long-term harm
it just seems absolutely ethically required to to act on that and so I you know spoke with all
kinds of like world leaders and politicians and celebrities and whatever and at every jurisdiction
it was like this like a whole new conversation you know it's like talking to people in South Africa
and so I go we don't believe in masks it's like talk to people in London we don't believe in masks
talk people in Australia we don't believe in masks talk people in Florida we don't believe in masks
and like each one I discovered this horrible thing which is um everybody decided they didn't
believe in masks until their personal jurisdiction got hit hard by COVID until the hospital started
filling up and then they would get back to me and say like oh tell me more about this masks thing
Jeremy and that was like infuriating because of course the answer is well if you had of
put in mask mandates two months ago then this wouldn't have happened and now it's too late
because masks can reduce r by a bit but not enough to reverse a full-on pandemic once it's there
so honestly it you know I got really burned out by the process like it was like in some
ways it was successful but in the end the pandemic still happened and in the end I'm still
yeah flabbergasted particularly now that like high quality medical masks so like widely available
demand is so low that factories have been shutting down you know um so yeah I've I've
never had COVID like literally nobody I know who has worn a high quality mask at all times indoors
because no none of them have got COVID you know and everybody I know who doesn't have all had COVID
and there's a point at which is kind of say like okay I I've done what I can you know you do you
do you so you continue to wear a mask indoors at of course yeah and I guess what would change
when would you stop wearing a mask indoors I mean I suspect like the same as the answer question
when I when would I stop drinking clean water I'd rather keep drinking clean water you know
it just like we we decided I mean remember it took decades even after the John Snow experiment to
for you know big cities to decide to invest in clean water infrastructure so presumably after
some number of years we will invest in clear air infrastructure so China's already done it they now
have I believe HIPAA filters and pretty much all their public building buildings and they're
putting in UV sterilization and pretty much all their public buildings so hopefully at some point
the west will do the same thing and then it'll be like okay I'm in an environment with clean air
so I don't have to like self clean the air so that'd be one option another would be again
China's ahead of us on this they have nasal vaccines which you know probably much more
effective so if we eventually get those and you know I think they can actually make a significant
dent on transmission which the injected vaccines don't make much of a big impact on transmission
so yeah there are technologies that should allow us to be able to be I think pretty safe
in indoor spaces but you don't wear masks in outdoor space that is that the
no I mean not I wouldn't that it's not exactly a hardened fast rule you know we went to a birthday
party recently for example where it was like a karaoke thing and it was outdoors but all the
kids were singing and they were tightly packed and whatever so our family wore a mask because there's
a high amount of aerosolizing activities going on with a high density of people but uh but yeah
broadly speaking I would I'm not too concerned about outdoors because the the airborne particles
disperse much more quickly I see so I guess the interesting thing about that story maybe is that
there maybe was a fairly broad scientific consensus but no one was really ready to advocate
for it that is that is that a better summary of what was happening if you got all these scientists
together and they actually all agreed with what you were saying they they didn't unfortunately
what happened was it was highly polarized by by area so the people that actually understood this
are the aerosol scientists and the aerosol science community was basically 100% all on the same page
of like okay you know talking breathing these are aerosolizing activities we have loads of
evidence that this is transmitted through aerosols we have loads of evidence that
in the in the droplet nuclei you know that are suspended in the air masks block those from
getting to your lungs like all those were pretty much understood in that community but then
the the challenge is Lucas that we haven't had a major respiratory pandemic in the west really
since the Spanish flu so none of our infectious disease community has any background in in that
so I spent a lot of time advocating you know including speaking directly to the WHO's
infection control groups of the folks that you know kind of ran the response at the WHO and
they were overwhelmingly people who had a background in infectious diseases that were
spread through contact you know the kind of stuff that hand washing helps with so they were just
coming from it from a totally different direction and had decades of experience on treating different
kinds of diseases in a different way and they were doing their best to learn and understand
but for some that was a very difficult experience and and one in particular John Connolly like
his financial stake was very high in this phomite you know transfer this like transmission is not
through the air but by contact because you know he has financial interests in that being the case
so very difficult for him to come to terms with the idea that this is a respiratory infection
through respiratory particles requiring respiratory protection so yeah that was that was a big
challenge is this worldview difference between different scientific groups and the aerosol
scientists there were actually none of them on the WHO's infection protection committee you know
infection control whatever it was so it was a I noticed when I was talking to WHO it was a total
lack of diversity every single one had the same kind of academic background on the same way of
thinking about things and they all knew each other very well and they were also they also all
saw being on being involved in the WHO as being a very strong status signal in their career so
everybody wants to be invited to those kinds of things and so you really want to like have all
the other people on the committee think you're a good nice person and so it creates this real
monoculture so that was another big part of the problem and it was all like it definitely made
me a lot more cynical than I was before to see like how the WHO works and even like our big
paper like how to get it published it took a year from being written to being published so by the
time it was published it was basically too late and the process of getting it published was
much more about politics than about science you know and it was yeah disappointing for me to discover
that systems that I had thought of as being like very much focused on rationality and data and
correctness and rigor yeah so much of it turned out to be about about politics and networks and
stuff so I guess I was probably pretty naive before all that happened I mean I guess my sense
is that people broadly believe that masks reduce the spread of COVID at this point I mean I I'm
not sure that I know like exactly to what degree it sounds like you know you're saying to like a
really massive degree but I think you I think you had a part in that or maybe just I just follow
you on Twitter and we're just watching you talk about it but I don't know it doesn't seem like
I was leading the masks are all group globally like and we were the most substantive group
doing that absolutely I mean it feels like it was successful though I mean I just
it was successful ish like I think it's I mean if you're in San Francisco it'll look more
than successful than if you're in Australia for example in Australia from time to time we've had
mask mandates and everybody wears them when they're told to the rest of the time it's strongly
recommended but nobody does but like in San Francisco I'm told like I don't know maybe 30%
of kicks at schools or some schools are wearing them like it's definitely like it's it's it's
disappearing and also like people on a lot of people maybe most people I see wearing masks at
least in Australia are wearing masks that don't work very well even though the good masks are
really easy to get and a lot of people don't realize like oh if you get a high quality
and 95 respirator you could wear that as many times as you like until the straps wear out you
know a lot of people think you can only wear it once a lot of people think it has to be fit tested
like there's a lot of people think it's like donning and doffing is some complicated thing
yeah there's all this like wrong information out there and so the number of people actually
wearing high quality masks is to me it's surprisingly low like if everybody wore one
whenever they were indoors you know particularly if we also had HEPA filters in indoor spaces I
suspect we would be done with the virus I think it would go away because how would a respiratory
virus continue to transmit when you break the flow of respiratory particles
yeah I mean even in China like every other pictures I see everybody's wearing surgical masks
just like weird to me interesting well look we're almost out of time and we always end with two
questions but you're a little bit of an unusual guess I don't know exactly how well these will fit
your world view but we like to I like to ask people if you had some extra time to research
something completely different what might it be and I feel like you are just like an unending font
of this stuff so what are some things that you're interested in that you haven't had time to look
into well I'll answer a slightly different question because like anytime I'm interested in researching
something I just do fair the most recent thing I spent a lot of time researching
is is children's education so so our daughter missed the first year of school because of COVID
in San Francisco they were closed that would have been her kind of transitional kindergarten
year as they call it in California and then we came to Australia and so she went to school regular
school for the first year here it's just straight into grade one and she enjoyed it you know she
was always happy to go and happy to stay there but it felt like she had like blossomed a lot more
during her previous year when she was doing stuff over Zoom and on apps and stuff and the year that
she was in person in the classroom which really surprised me and instead she had become much
more of a perfectionist and was becoming like much less resilient after her year at physical school
and that all seemed really weird to me because I thought that environment would be much more
healthy than the previous one so I started yeah I started investigating it really carefully and
studying a lot of academic papers about education and I was just stunned to discover that yeah there's
kind of like pretty broad consensus in parts of the academic community or some very strong data that
suggests like schools are not a particularly great place for most kids to to really blossom or at
least entirely focus on school learning and in fact tutoring kids that do tutoring get tutoring are
like in the very top highest academic performers regardless of their previous background like it
seems like all kids can be really successful given the right tutoring and that like because our daughter
was doing all this stuff with like apps and on Zoom and stuff during her first year none of that is
limited by the speed at which a teacher thinks a kid should go but instead the computer is dynamically
adjusting difficulty over time so weirdly enough our daughter did you know was basically a grade four
or grade five of math after a few months of doing these apps you know they're so much more effective
than normal teaching so we're also trying to figure out like well how do you how do you avoid
getting really bored and stuff so yeah so I did this really deep dive into into education and
discovered there's all these like fascinating different ways of of teaching and learning which
are entirely different to what's done at normal schools so eventually yeah we we decided to take
her out of school and you know instead switched to using these kind of more academically driven
approaches in a homeschooling environment which also seem to generally lead to better social
outcomes you know better mental outcomes a bit mental mental health outcomes and better learning
outcomes and so again that's kind of been interesting to me to discover this like
whole world of research that seems really important you know for humanity how to how kids
should learn and yeah it feels like again it's being largely ignored by the institutions that we
send our kids to um and so wait let me just summarize see if I got the the summary of this
basically that tutors are much more effective than schools that actually teaching kids things is that
is that what you're saying that that would be part of it I mean and and then specific then but I mean
there's like lots of so yeah that's kind of one starting point it's like yes even you know even
kids that would otherwise have been doing pretty badly at school can be in the very top performers
so like that kind of is an existence proof that pretty much all kids can be extremely successful
but then there's this also this kind of yeah interesting data point for us which is when we
kind of gave our daughter an iPad and some you know math and reading apps and somebody on the
other end of a zoom to supervise them she had a huge amount of fun and learnt dramatically more
quickly than I thought was possible and then when she actually went to school she basically
learned nothing for the whole year and ended up becoming much less resilient and then that yeah
that there are specific ways of learning that are not particularly compatible with the normal
ways we teach at school so for example we might have talked before about like Anki and repetitive
spaced learning you know so my daughter does Anki every day so like literally everything she learns
she will remember forever if she put you know she creates a card for it if she decides she wants to
know it so yeah so like it's and that's kind of quite difficult to do at a normal school
because you did all of your great levels to be doing Anki so that in grade five you're still
got cards from grade one or grade two coming back but what happens at school is like each year
so for example in Australia the year seven and year eight math curriculums are nearly entirely
a refresh of the primary school curriculum because they kind of assume the kids are going to need to
see it again because they've probably forgotten a lot of things like how would you
incorporate spaced repetitive learning some schools in England have tried to do something
like that using something they call retrieval practice and so I know there's a school called
the Makayla school which I believe had the highest results academically in the whole country
they do something like this so there's a few there's a handful of schools here and there which
are trying to use these kind of research results but they're yeah they're kind of the odd ones out
all right and I guess like finally I don't know if this one really applies to you we usually ask
because you know that my company in this interview is all about sort of like making machine learning
really work in the real world we usually ask like like kind of what's the hard part that you've
encountered in sort of like taking something from research to actually working for some purpose and
that may not exactly apply to you but you seem very good at sort of interpreting my questions in a
useful way so I pose it in its most abstract form
I mean I've um yeah I've had lots of projects that I've tried to bring into the real world
of course that's right yeah so and it's difficult you know um yeah I mean I've I
I've been doing machine learning projects for over 25 years now believe it or not
um and in the early days you know it's such a challenge because managers didn't believe in
the power of data at all and when I would try to tell them that it could be really valuable they
would always say like can you point to a role model of a company that's been successful because
of their use of data and there were none you know and that was tough yeah then Google came along
which was great you know because then I could point out this one company that was like
really working hard to use data and they've become very valuable because of it nowadays
that bit's a lot easier um but actually um unfortunately it's my answer is going to be
that I've kind of for a lot of companies I've given up on even trying because I tried to get
particularly when I was at Singularity University where all of our students were basically execs
from giant companies and we were trying to convince them to be more data focused and some of them
really took that on board and then they would like invite me to come and talk to their VP groups
and exec groups and and I saw lots of yeah big companies try to get more data driven try to use
machine learning um I didn't see any being successful and um that the issue seemed to be
that their entire management teams were people who who's that was not their area of expertise
they were not promoted because they were good at that um they would have very smart
data driven people down in their kind of business analyst levels but they would have no idea which
ones knew what they were talking about and have no way to kind of curate what they were being told
all of the promotion systems were you know based on experience and credentialing and
things other than analytical capabilities so yeah so like in in those kinds of companies
I I I eventually decided like okay maybe it's not possible for a legacy company to become a
data driven company and so nowadays I focused all of my attention on startups um created by founders
that are already data driven and you know have a good understanding of analysis and what we're
seeing is like you know increasingly the most valuable companies or particularly the most
valuable companies in America they're basically all now tech startups I mean they're not startups
anymore but they're all companies that are created by kind of engineers and data driven people um so
I'd kind of yeah I think for like data scientists interested in making an impact the best thing to
do would be to try and make sure you're at a company where that kind of work is appreciated
and understood by the executive team interesting well great to talk to you uh that was super fun
thanks for you too Lucas answer my wide range of questions yeah my pleasure it's always so
it's fire to talk to you I really appreciate it thank you if you're enjoying these interviews and
you want to learn more please click on the link to the show notes in the description where you can
find links to all the papers that are mentioned supplemental material and a transcription that
we worked really hard to produce so check it out and how is everything going at weights and biases
I always hear nothing but good things about it everybody loves it I gotta say I gotta admit
actually the other day I was like talking to my friend I think it was Tanishk about like oh what's
going on with this learning rate here I wonder if it's working properly and then he's like oh well
here's a graph of the learning rate I was like oh that was quick and great where did that come from
and he's like weights and biases he blocks it oh he's still recording put that on there I probably
should have looked at the weights and biases team here I was with like plot dots plot x equals
he's already got it pasted into the discord chat all right well that'd be my day thanks cheers
