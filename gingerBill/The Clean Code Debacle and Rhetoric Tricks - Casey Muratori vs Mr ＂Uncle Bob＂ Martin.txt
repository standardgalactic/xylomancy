Hello and welcome, I am Gingerbill and today I'll be talking about the fiasco that has
happened between Casey Muratory and Mr. Robert C. Martin.
But before that I'm going to explain why the history got here and I'm going to also explain
some stuff.
I'm not going to try and criticise clean code itself, Casey Muratory's been trying to do
this in the long discussions he's had with Mr. Robert C. Martin already, but it's one
of those things where I just want to kind of show the rhetoric tricks of Mr. Robert C.
Martin himself.
So before we get to that start off, let's begin with the thing that started it all,
which was this video that Casey made public from his thing, it's called clean code, horrible
performance, where they say 22 minutes long video, him showing the examples of what clean
code is and going into a more, let's say more like simplified code, which is more optimised
performance and showing the cost, hey, if you do it the clean code where you're going
to be 15 to 25 times slower as your performance and you want to take that hit, understand
what the costs are kind of you, and again, this is, this view has also taken our context
is blown up by mad, it's nearly half a million views so far at the moment at the time of
recording and so it's clearly gone viral across the programming world.
Unfortunately, because it went viral, a lot of the context got lost and because the context
got lost.
People just adding their own context into it without even bothering to learn it.
So the context was this comes from a series that Casey's been doing on computerhands.com
where it's a performance awareness course.
So specifically the, this is the programming course he's been doing to performance awareness
stuff.
And this is a subscribed based thing on the on the on here and has been doing many different
topics on here as I was going to learn how to performance awareness.
Specifically, this was the blog post and he made completely public for everybody showing
all the code, showing all this stuff.
So then you can see a whole video still kind of transcribed down.
And it's part of a series, it's not the beginning of the fifth series, it's quite in the middle.
So it's kind of like, oh, okay, we're not starting from a random place.
So and also when people say and talk about the context of this Casey understands this
like, look, reminder, I don't think clean code is bad just because of performance.
My recent video is about poor performance because it's part of a course on performance.
This is the context many people lost and he's been doing this for decades is saying, so
I recommend reading these tweets, I will try and provide all of the links to everything
I'm showing today in the description or the do blue do whatever you want to do down below
on YouTube.
So be here.
So yeah, hello.
Good.
So give a background.
This put up the attention of Robert, Mr. Robert C Martin, which he colloquially calls himself
Uncle Bob.
For this talk, I'm just going to call him Mr. Martin, because I just prefer saying Mr.
Martin, insert your guesses as to why.
But yeah, he is very well known for mainly three things, which is the agile manifesto
he helped develop that solid, the solid principles.
So the agile manifesto and solid principles, which again, many people know from the world
and especially that and he wrote it in his book, which is first in design principles
and design patterns, as it says on here.
And he's also in this thing known for clean code.
So clean with a capital C code with a capital C trademarked.
This is his particular thing, the capital C clean code thing.
Okay.
And this is what he kind of tries to describe.
So to get to show my biases and my background, I am the creator of the Oden Programme language
here.
And the Oden Programme language is the general purpose program language with the distinct
typing built for high performance modern systems and data order programming.
So clearly I'm showing my biases and I'm cleaning on more like case and moratorium side when
it comes to this discussion.
And also I work at DjangoFX on Emogen and Likogen and Geogen, which are all high performance
real time pieces of software like simulations, again, Emogens for fire, smoke and explosions
in real time.
So clearly I work in an industry where we really care about high performance real time
stuff.
So clearly I'm showing my biases straight away.
So people understand what's going on.
Okay.
So now you know that's on the way.
Can we explain what clean code is before we get into this?
So sure.
So there is this kind of little document I found the other day and it's been well actively
updated by looks of only eight hours ago at this time of recording.
And today's date is the March the 30th, I believe.
Yes, March the 30th.
So it's very active already.
Someone's updated.
There's probably some typos and such.
We can even see the revisions.
And yeah, it's just some, hey, just capitalizing some stuff.
That was all it was.
Now many people have seen to have liked this clearly over 5,000 stars and over a thousand
forks of this gist as well, gist or I don't know, we pronounce it on GitHub and explained
some of the began your principles or points about clean code.
Now there's many of this.
This is the thing about which is why clean code capital C thing trademarked by Mr. Martin
is very popular because there's many of these rules which no one would disagree with.
Like follow standard conventions.
Yeah, because conventions are a good thing because then you're working on the same sun.
Only break them when you need to keep it simple, stupid, you're fine, whatever.
Boy Scott rule, leave the camp round cleaner than you found it.
Always find the root cause.
Yeah, no problem like this.
Yeah, yeah, yeah.
Now some of these things, okay, some of these are not essential.
These are accidental.
Like again, follow standard conventions.
That's not a unique to clean code.
Is it?
You can do that in any philosophy out there.
It's not a unique principle to clean code itself.
But some things like, for instance, I would say more essential to clean code are prefer
polymorphism to if or else cases and separate multi-floating code.
I'm not even sure what that means.
Use dependency injection.
Follow the law of Demeter or many of the things that many of the things like here like, oh,
use small functions.
They only do one thing.
Use descriptive names.
Again, that's descriptive names.
Everyone agrees to that to a certain extent.
Prefer fewer arguments.
Have no side effects.
Also be more functional.
It means more and more rather than be like, have side effects itself, like be more imperative
relying on like, global state or modifying state or whatever.
Don't use flag arguments.
Yeah, they are like, okay, some of these people will agree with some people will disagree
with them.
But here's where the problem is with some of this is that for the most part, some of
these rules, people will agree with some of them don't.
One of the particular is like small rules for me.
I actually disagree with this particular thing.
There was a post here.
This is on Jonathan Blow's blog, old, a very old blog actually, this is 2016, but it's
actually even older than that because it's an old email response between him and John
Carmack.
So this is John Carmack explaining effectively what he preferred for the things is not the
clean code up.
This is what I wanted.
It was the wrong one.
Whoops.
Let's go to the blog post again.
And it's this one here.
Sorry.
I accidentally clicked the wrong button then.
John inline code and John Carmack in the email is explained actually he doesn't like the
separate single functions here.
It's better just have one big function and then comment them.
Now some people might say, it's a bit easier to manage looking at re-things.
It's like, yeah, for code reviews in a big corporate setting, it might be easier looking
at a single function.
But there's a few things you have to understand.
Functions have costs.
If you split these things into multiple functions, this is a one is an extra cost.
Yes, it's a minor cost when calling a function, but like that most people don't care about
that cost unless you're doing particular things like you're worried about stacks or
anything like that.
Like, okay, most things don't care.
One thing it does do is it does actually doesn't mean it's very easy to optimize for the optimizer.
And I know how compilers work because I work on them for kind of a living.
And if you have things in line, one, it's not hard to read by just using comments everywhere
or block codes or anything like that.
I think it's just as easy.
And if you've got text editors, which are use collapsible things, that's great.
That's okay.
Deal with it that way.
But then it's like, okay, but the optimizer is going to be ready.
It doesn't have to worry about trying to inline that function and then now optimize the new
inline function that's been got inliners out of another function.
So there's that.
And also you can usually start to see easy patterns as well.
Like if you were starting manually inlining things, it's not hard to read.
Yes.
Okay.
Got 10,000 lines, but most people's IDs and text editors are very easy for code folding,
code searching, code on argument is the organization.
We're not living in the eighties anymore.
Or even the seventies, to be honest, because even small talk had better options than this.
I'm not saying a big fan of small talk, but again, the tooling is the argument of small
function is more of a, hey, it's our code review practices, the big corporations, testing
practices and also maybe just tooling practices.
So that's one thing.
But it's going to recommend highly reading this article.
I really do.
From 2014 against from 2007, as it says here, highly recommend it.
But what I'm trying to get out here about the word clean code and I'm not even talking
about the actual discussion that Casey Meritoria, they're moving and having yet, because I want
to try to build up a picture here, as you can probably tell, trying to be a storyteller.
I'm not very good at it, but let's carry on with it.
Is that the concept of clean code is what I want to determine capital C, capital C on
both of them, trademarked for Mr. Martin is what I'm going to dub a pork barrel name.
So a pork barrel is a thing that American English, but it's kind of a, you have this
bill and it has a particular thing like citizen skins, government waste, but it also has all
of this things that are nothing even related to the actual name of the bill and to keep
it in American context, because I know most people watching going to be Americans.
So I'm not going to use an English example or another European example like Germans.
I'm just going to use American example of run recent one as well is the inflation reduction
act of 2022.
The name of it, the inflation reduction act.
Okay.
Now I'm trying to be, again, I'm not an American, don't really care politics, but I think most
people would agree.
This act did not reduce inflation.
In fact, it printed more money and more excess money.
That money was not being in high demand.
So it increased inflation.
In fact, it had loads of other things in there to do with, not to do with inflation, but
a really clever political rhetoric trick is to say, Oh, you don't like this bill.
We must like inflation.
You're bad.
Everyone dislikes inflation.
So you must be, I can't be against this bill.
Can you?
It's like, but this doesn't, no, no, no, it doesn't have inflation.
How dare you don't want to, like, you can do this trick.
And again, it's not a political side either, literally all political parties or politicians
you, I do this trick.
Some countries like to do, like, Oh, just get names from bills, but then they'll give
them a name anyway, like colloquial one to refer to it rather than giving it like a letter
or a number or some random numbers or something like that bill.
And they'll just say, look, no, this is what we're going to call it because technically
internally, the American ones do, but they give them a proper name and also a very long
time.
Again, this is to provide for the reconciliation pursuant to title two of the S con res 14.
I'm just reading it as it says on here.
And it's like, okay, but that's a good example from a political standpoint.
I'm just keeping it trying to keep it politically neutral.
I don't really care about our politics, but it's just one of those funny things that show,
Hey, this is a trick because Mr. Martin will actually continually do this throughout and
he will trick do a lot of pivoting and a lot of these poor barrel names.
Okay.
So let's just say this is a good example of this bad code.
Just say no.
And it's like, okay, so what's good code then?
Because then it's he phrases it in the, oh, it's clean code, obviously.
Now there was another tweet.
I tried to find, but I couldn't find it's probably been lost to the Twitter search or
it's just been deleted, whatever, but he will commonly do this.
Mr. Martin go like, Oh, the opposite of bad code is clean code with a capital C trademarked,
which is interesting because that means anything that's not clean code is a bad code.
Um, yeah, let's not get there.
But again, to be very clear, careful on this, I'm not going to criticize him.
I'm actually like in admiration of his rhetoric.
He's a politician level when it comes to rhetoric.
I mean this.
And it's like, this is really good.
Like he's really good at it.
But again, he's been doing it for nearly 50 years.
He is what 70 years old.
He's been doing this sort of job since what, um, God, even the early nineties.
So it, okay, at worst, like it's 30 years.
He's been doing this.
He's probably been doing it for 40.
Okay.
That's what he does for a living.
He's very good at this rhetoric.
So that's why I'm like, I'm kind of admiring it into a certain extent in a weird McEvely
and sense.
Um, but sure, let's carry on with this.
Shall we?
I've got some more things.
Another thing in series, um, when this whole thing happened, when he was talking about
Oh no.
Um, people don't like the code, but then he says, some people will do this.
And again, it's showing is very good.
He's very good at knowing memes.
He's not an old man.
He's an old man, but he's up to date with a lot of the stuff.
And it sounds like silly, but it's not a book or the concept.
It's a Cartesian pandering immature behavior.
The author batches everyone.
And then he just shows this claim like, Hey, I know how to play your joke.
Like, and he does.
He's not that bad.
But then there's other things.
So here's like Casey Mertore comes up with, um, and he's talking about people criticizing
and then he replies to this.
This is where kind of the start of the conversation is happening.
So Casey was, has says in this, even if true, to what extent would you tolerate the, yes,
clean code is much slower, but it's about programmer productivity for other products.
Would you want a car that went only five miles per hour because the designers could do less
work to make that car?
Now Mr. Martin replies to what the auto owners notice he does a pivot.
This is a pivot.
And also it doesn't answer the question.
He says the automated mobile industry takes advantage of every productivity tool they
can reduce their enormous manpower cost of designing and manufacturing cars.
As a result, cars have gotten exponentially better over the decades because the extra
productivity translates to better designs.
Yes.
But do you think they, for their programming, they're using clean code principles?
In fact, we know they don't, um, especially after use Mercer and stuff like that, but
afterwards here to certain other things and like, they're probably not doing clean, clean
code stuff.
Now I know the most things have started to relax, especially when it comes to like, um,
Android auto and, and like, uh, Apple car play and stuff like that.
It's, there's stuff a buggy, but that's kind of like, oh, it's your phone.
That's a different thing.
It's just we're interfacing with it and whatever.
And it's interesting.
He does this because he does it again when someone replies to it and anything here, but
he's kind of a, he knows what he's doing when he says these arguments, that's not answering
the question.
Oh, I'm going to say is that just, just watch that.
Okay.
Another thing is this is when it starts, this was the beginning of it.
I wash your thoughts and it says, oh, I've commented on this before clean code is made
for programmer performance, not algorithmic performance.
If you need the latter, then write in C or assemble and live with the high cost of development.
So few things there already pipe, programmer performance and algorithmic performance.
Okay.
So program performance, it's the, in the contrast, how do you measure that thing?
How would you know if that your approach is better than another approach?
And if you need the latter, write in C and assemble, okay, so assembly I would call this
but yeah.
And then high cost of development.
So he's already implying that writing in C is going to be a much higher cost of development
than writing in another language.
It might be, but you should only write in it because you need the performance.
And it's like, okay, what?
Look at the framing.
He knows what he's doing.
I'm not saying he's an idiot.
He's very smart.
Okay.
I'm sorry.
I'm picturing it.
I'm just trying to explain the retro tricks.
So this is another thing.
It's like the clean code replied to you later with the automobility amount.
I've got these switched around.
It doesn't matter.
People says, how do you measure readability of the code by reading it?
So obvious.
But it's like when people say measure, they usually mean a quantifiable thing rather than
a qualifying thing.
So this equality and a quantity are two distinct ontological categories.
Okay.
Or epistemological, the many different things, which is not going to philosophy too much,
but you cannot quantify a quality and never qualify a quantity in a sense.
They're different things like, Hey, I have a tape measure here.
Yeah.
I can say it's got the, I say it's quality of being good and round and green and stuff
like that.
And these aren't even very good qualities, to be honest with you, but it has quantities.
I know it's mass just by dropping it.
That's what you need to do.
That's absolutely fine.
And it matches.
I'm just trying to explain the gravity thing.
So clearly it's got mass.
And we can measure that relative to other things that weigh things.
And we know how much this is weighs.
This is probably weighs about, I don't know, eight ounces.
So 225 grams ish.
That's quite heavy actually, surprisingly, it's not even a good one, but there's kind
of the thing.
So you can actually think and you can sort of say, Oh, how, how green is where we can
measure the reflecting of it and then see how much it reflects back a certain light and
so in wavelengths and such like this, you can say all these quantities and you, these
are quantities.
Okay.
I don't want to too much.
Clearly I used to be a quantum metrologist.
I know a lot about measurements and all this stuff, but this is a clever trick by reading
it.
That is not a quantity.
And people are wanting to question, how do you measure?
We want an objective measurement, what do you mean is they want a quantity, but he goes
out by doing this.
So this was a big long twist post I've been here where Laura's Crow again, a community
anyway says people on hand made hating on Katie's videos about performance while their
company is spending double digits of percentages of their revenue on Amazon web server bills
to serve three forms and a database view.
And it's like, okay, this is great nightlight discussion, talking about this.
And then Mr. Martin says here is his analysis was correct.
His rhetoric is a bit disingenuous.
And the overall point was extraordinary narrow.
Clean code is about increasing programmer performance.
He keeps it straight this not computer performance.
What are some real life, life, non-trial view code bases support the hypothesis that strict
clean code increases program performance replies with a mean.
And he knows what he's doing.
I'm not like, this is really cool.
Like he knows what he's doing.
But yeah, so you don't have any of his tools that some says it.
So the Vittorio mode me a thing for the people I got into a discussion with him around about
this time.
And I kind of partially convinced him about like, well, you need, you've not got evidence
for why one's better than the other.
Like show why, how do you know one's better than the other?
It's kind of that question.
How do you know what measurements are using?
What quantifiable or even qualifiable things that you're showing like, can you just show
me the evidence?
And then he goes like, he knows this for a fact, he says, the problem with scientific
data is it's controlled in controlled experiments in realistic software environments or economic
and feasible.
You're asking for something you'll never get.
And yet you still decide.
So look around and ask your associates, especially your seniors, the first like, it's just the
first part of this thing here is we have no evidence for our claims, but it's okay because
your associate seniors may agree with me already.
Nice little pairing here.
It doesn't do the same thing.
Okay.
Um, that's the first thing, but then it and someone said like, they said these over the
10 lines of course, sometimes wrong seniors, I guess, and someone saying like, well, we've
got my seniors don't agree with you.
So sometimes of course your seniors were correct.
I presume they also told you that or else being your smaller, well-named functions are
better than really badly named functions is like, okay, notice the bad pairing there
already.
A well-named function is better than a badly named function agreed.
Smaller function may not be better than a long function, but notice is smaller, well-named
functions are better than really badly named functions never talked about the length of
it.
I know it's like a minor word difference, but he knows what he's doing.
Like, and also he just changed the topic and it's a pivot.
He's gone from being the scientific data to now to well, trust your the trust the authorities
of your seniors or elders or whatever, like going to authority rather than going to like
empirical data.
Nice little pivot, you know, it's exactly what he's doing.
So another one here is always remember that computers operate on F in character, one F
in character at a time.
He's trying not to swear here, no matter what lovely subroutines you might be using.
Some replies, what about someday?
Well, the context of the problem was JavaScript in a browser.
I'm like, what context?
I even tried to search through the other tweets.
There was no context.
So yeah, okay, carry on.
Another one.
Someone has recently equated clean code to overengineering.
That is of course an oxymoron.
An overengineering code is by definition not clean and makes me wonder if those who complain
so loudly have actually stood at the target of their complaints.
It's like, see the problem?
So if he's overengineered, it can't be clean code, even though I've seen many clean code
which I had classes over and engineered.
In fact, I think clean code by default is kind of open engineered.
Like it doesn't, it's assuming this could be open to change, even though it's a closed
set of problems, which I'll get onto a bit later.
So then talking about the spittorio-Romeo chat we had earlier, I was discussing with
him previously and he was kind of like, oh, well, I can make it even faster if you just
change the entire style of it and just have a raise of separate types.
And I was just like, are you being honest?
But this was the conversation I had even trying to confuse it, like to not, he was kind of
being a bit confused, but also trying to be like explaining it.
And we kind of got to a point where like, oh, okay, like, first off, you've been a bit
disingenuous here, man, with the argument, but fine.
This is not Mr. Martin anymore.
This is just me explaining like there are people who are trying not to say to defend
him, but not understanding like Casey's point in this discussion.
So again, before I'm going to read this article, I recommend reading this clean code,
horrible performance YouTube video.
Again, links are in the description for all of these links.
So don't worry, they'll be there.
So now I've done the 20 minute spiel at the beginning of this video.
Uh, let's get to the meat and potatoes of this entire thing, which is the written
down talk.
Now this is quite interesting.
And, um, this written down talk is effectively a written discussion between
Casey Moritori and Mr.
Martin, and they are both discussing with it and it's been split into different
things and I'll explain some points as I come along and so all the little tricks.
So first off, I'm just going to try and read it.
I recommend reading this again, links in the description below for everything.
So Casey starts off with, thank you for taking the time.
And he's just kind of asking questions like, so most explanations on clean code.
I've seen that you include all things I mentioned in the video, like preferring
inheritance hierarchies to if states, which remains, like I remember, if we look
back to the, the, where was the guest I found completely lost it already now.
Um, it was here, right?
Here it was here.
Yeah.
Here's the design rules.
Um, I like some, some size.
That's not Mr.
Martin's himself, but yeah, but it sounds like you were surprised to hear me say
that like all these different things he said.
And so I look and what, and Martin's going to disconnect.
I'm not, um, sure there is one.
And interestingly, just says there is no, like disconnect.
And Casey's just asking questions about this.
So Casey's asking a basic question here.
Like, look, um, we're both familiar with visual studio and clang and it would
be a reasonable that you're kind of the back and uses it every day.
I use these every day.
I use LLVM and visual studio every day.
Are you calling these a vast majority of software that require less than one
things?
And then he would go like, Oh, these are very specialized software.
The only, the only few in existence and only a few that have actually become
popular and then talks about why this case.
And like actually talks about all these different things here.
Like, okay, speed is not necessarily an issue, but you can summarize it.
But then the first trick he does, this is going to be consistent throughout
here is the nanoseconds, microseconds and milliseconds framing.
I will tell you this, so what it will do here is making sure that passing code
preserves nanoseconds can have a big effect.
Or he says, um, I assiduously counted microseconds when it mattered.
Now, because it was way beyond anything I could imagine.
And, um, so then Casey kind of questions is a case of like, it sounds like most
software that Casey actually uses and so would myself, um, would when nanoseconds
actually matter.
In other words, Visual Studio, VMGCC, Microsoft Word, PowerPoint, Excel,
Firefox, Chrome, FMPEG, there's a type of that, but TensorFlow, Linux,
Windows, Mac OS, all of these.
And, and Martin goes again, Mr.
Martin goes like, Oh, I'm not exactly, uh, rather my experience abroad and
does all the stuff and then talks about this other applications with our
modules in the millisecond range.
And he says, what's these time ranges?
It's very like he's trying to get the reader because he knows people reading
this to think about it.
Well, most problems are in that it ranges a millisecond.
So we can worry about some nanoseconds.
Most people don't have to worry about optimizing nanoseconds.
But it's like, you can have death by a thousand cuts and a thousand nanoseconds
is a microsecond, a thousand microseconds is a millisecond.
So if you do things a thousand times badly and you can, you've now gotten to
the other domain, into the other module, as he was calling this, the time module.
Okay, fine by me, not necessarily, uh, criticizing that way of thinking, but
it's a very weird framing, which, um, like even if I read here, so for example,
I'm currently working on an application in which the vast majority of modules
work well at the millisecond level, but a require a 20 to X per better performance.
My strategy has been to write the millisecond modules in closure because
while slow, which is very convenient language, the microsecond modules I wrote
in Java, which were much more faster, more convenient, far less convenient.
So it's like, okay, so if I use them all like Java, it's easier, it's much less
convenient, but I can write faster code.
Compared to closure, which is a right code quicker, but it's not going to be
as powerful and those bits, he's merchants again, because closure and Java,
both on the JVM, so they can drag these other breezily ish.
Um, but he's just talking about the other things here.
Now, one thing I found interesting is this slash here.
Um, you'll see in a minute, uh, right, and he only wrote a book and said,
oh, I wrote a book on clean code.
Don't you know, I've only focused on the millisecond side of the problem,
not the nanosecond.
It's like, well, I'm not walking about the performance of the code anymore,
but like Casey just goes town on the question.
So Bob answers a very short question milliseconds, of course.
Um, and then he answers again.
Now you might be asking, wait, why is he answered twice?
Well, he went back in history and added some code text.
He rewrote history.
Yeah, I'll say no more.
Um, but yeah, he keeps going on about this and it's very interesting.
So now here's another problem he kind of talks out about and he's talks about
the actual, he says he's now actually finished watching the video because he
didn't actually watch the video when he started discussing with you and you
watched the first bit of it and thought, I've got enough of this.
It's like, you're not going to have discussion with someone.
You've not even watched the entirety of, but you think you're confident.
You know, you can talk about it.
I'm like, interesting.
If you're that confident, it usually means you're not actually talking about,
um, the thing itself.
Yeah.
Yeah.
Um, but he says, you know, this is a nice little pattern.
I love that basic form of like some coefficient times, the length times, the
width and in those moments, it's like, I only think programs and
mathematicians, mathematicians can truly appreciate.
It's like, oh yeah, yeah, that was fine.
Isn't that lovely?
Um, and that's fine, whatever.
But Casey comes up, okay, that sounds great.
I think we've gotten to the same page because he was actually talking about
this, not this, um, because he says, oh, I've just finished watching it.
So I'm going to add this bit back in to make it.
Split it up.
Again, take it out as you wish.
Um, what I'm trying to say is above paragraphs, blah, blah, blah box and
those just like, look, Casey has read and looked a lot of it.
Like what are you talking about?
He seems like these nanoseconds need to matter.
Like everything seems to be nanoseconds modules.
Would you say it's like, all this makes no sense.
And then he, again, he replies with, well, I'm one of the signatories that the
agile manifesto who still believes to be a bit upfront of architecture,
design, okay, why bring that up?
Sure, but fine.
Um, this is the bottom line, of course, is that single factor analysis is always
suboptimal.
There's no one true way point.
I've always made several times in clean code and it's like, but they may not be
one true way, but you do kind of suggest there's a default you should go to.
And, um, there are arguments for that.
Oh, okay.
Um, so, like Casey has a lot of questions to ask already, all of this.
Again, I recommend watching this.
Now Casey says here is like, I watched a multi-part series, a six-part
section, and it's like nine hours he watched, not once in that one second of
it, of that nine hours was indicated towards performance.
And again, again, Mr.
Martin says it's fair criticism, absolutely fine, no problems.
Um, again, I'm just going to show you here.
It's like, yeah, so thank you for the nudge kind of thing.
Like, oh, next time I'll do, I'll put a nudge in towards performance.
It's like, I've been doing this for decades.
Hmm.
Okay.
So clearly you don't see, like, but like, he's kind of butchering up trying to be
polite or like, as you would, like you're trying to be a conversation.
Like I'd always be polite someone as well.
I'm trying to be nice and kind to a certain extent, maybe not always nice, but
kind, at least kind.
Um, but yeah, it's always kind of those kind of things.
And I have some reflection of the area, blah, blah, blah.
I'm just trying to go through over this again.
I says, that's fine.
Not just all the conversation.
Again, that's a lovely conversation between two people trying to be, they're
just being honest between each other, not being horrible.
Um, Casey was also showing off this video, which if I believe it's the correct
he was just kind of, they were just joking about how slow it is, right?
GitHub literally intent of just slowing down along with the paragraph God.
And they actually found after a while why this was the case.
Uh, the thing they found out was that it was the code was looking back to the
beginning of the paragraph, looking for a colon, if it found a colon and it was
near the beginning, it was going to then expand this to be a emoji.
That was what the bug, the think the slowness was.
So if you just, as Bob made his joke, like, Oh, if I just replace everything
in the spaces with the colons is instant, there's no slowdown because it's found
the colon, found it's not an emoji and it doesn't do the search anymore.
That's how slow, like even though they were talking about the complaining,
like slow codes, like, look how dumb this algorithm was in the web browser.
And it's just trying to do this.
Now, one little thing I found a bit weird, uh, he says, I created this using
going VI and I use this, um, like replacement thing because really, I'm
an old C hacker at heart.
I'm like, what does that even mean?
This is just seems like a, I'm an old C hacker at heart.
I'm like, this has, this is one, this is just, you're in, you're in like
via VI or Vim or whatever you want to stuff.
And then you've just done a reg X for text replacement and this has nothing to
do with C. I know what he's trying to say.
And I said, oh, it's just really low level.
I'm doing all this.
I'm like, what?
Sorry.
It was just me, one of those things like the, what?
Right.
Um, kind of a bit interesting here.
So then there's the, again, recommend if you want to read the links in the
box for all this.
So you don't, I'm not trying to read the actual descriptions here.
I'm just trying to go over it.
Um, so now they figured out the things, the slowness of GitHub.
They've gone, gone back pivoting up back to this, talking about the stuff
about clean code again, capital C, capital trade marked, um, and explaining all that.
And some of the weird things like, for instance, the descriptive names things,
like, I think everybody agrees with the descriptive names.
This is not clean code, exclusive to clean code tests.
This is one where, um, he's more of a test driven development.
While case is more of a, it's more of a handle that you do frame it later on.
In fact, I think Mr.
Martin rephrases this quite well that he prefers like why you should write a
test if you don't see a reason not to.
And Casey is more in the camp.
I write a test when I need a reason to kind of thing.
And they're just, they're not bad.
One's more test driven.
One's more of a, like a more of a base of regression kind of thing or like other
testing is more of a, I'll write tests when I need to, because I do have tests
in general.
It's just not a like unit tests or general tests of everything code
coverage and a lot.
It's a different thing.
Um, I'm not going to criticize that test room development because it's not
necessarily bad in certain domains, but in certain other domains, it's kind of
like, uh, not, it seems like writing more tests than the actual code, which is
not necessarily productive, but whatever or useful.
And there's many different things in here.
Yeah.
So he says, like, look, Casey's deciding tests as well.
But then again, here's the difference he writes.
So Mr.
Martin says, I appreciate tests unless there's a good reason to this and Mr.
Martin and Casey write tests when there is no good reason to, when there's a
good reason to, so it's kind of a different distinction here.
Now he actually starts quoting again from his book talking about this.
And he, and he kind of distinguishes between the operand primal and, um,
operation primal he's calling here.
So it's kind of the difference between, I'm going to call operands, uh, operands
variants in this case, because it's a variance and operations.
So they're not using the same home.
It gets a little confusing for me.
So now they're kind of talking about the different benefits of using one of these
two things and great stuff here.
But then there's one other term that he brings up in here, which is dependencies.
And he's using this in a very, not the way that most people would use the term
dependencies.
Um, so a good example of this would be, is calling it dependency inversion.
So I'm just going to read, write, I'm going to say what he's written because
it's, I'm not going to paraphrase it very well.
If I don't, um, it says here, that would be the bottom line.
If there was one other thing, okay, about dependencies, uh, the cases of switch
statements create an out, uh, outbound network of dependencies towards lower level
modules and modules in this case, he's talking about like timing and such like
that, that kind of module in this context.
Yeah.
Each case may call to out to these other modules, making the fan out of the
switch statement very high.
So he's trying to argue against switch statements and trying to say, look, if you
go for the more polymorphic approach, like the inheritance base approach where
you have like a V table with sub typing, which is what I would class as inheritance
to begin with any, it's the emergent concept of those two things joined together.
Um, he's saying that this is going to be making it the fan out of the switch
and very high, like this is going to be much bigger because who is carrying what
says any change to one of these lower level modules can force the switch
statement and his case, his switch statement, the video, he's, he's, he's usually
prefers the, uh, inheritance style.
Not always you'll get into that can force a switch statement and all higher level
modules to depend on, on that switch statement to be recompiled and deployed.
Uh, that can be a very large cost.
On the other hand, if one uses dynamic polymorphism, object oriented, instead
of a switch statement, then those compile time dependencies are inverted.
The lower level modules become sub types that depends on the high level base type.
And the source code depends is then point in the opposite direction of the control
flow.
This is dependency and version.
Um, it prevents changes at the low level modules from forcing a wave of
recompilation redeployment from sweeping through the system towards high level modules.
So this is just a really weird, confusing terminology.
He's just made up in a weird way.
I'm seeing who has made it.
I'm like, no, he kind of actually has.
Um, I tried searching for this and it's like, it's not consistent.
What people mean by that term.
And also when people talk about dependencies, they usually mean like
third party code, usually, or sometimes they talk about dependencies.
Like, Hey, what does it vary?
It'll depend on the things, like all the bits in the thing.
Like he's talking about modules, but that his concept of a module is much more
like a class than a library.
So it's kind of a more old fashioned approach before like libraries and packages
and modules were more like standardized in other languages, obviously, but whatever.
This is why I'm going to confuse because the argument he's trying to make, and
this is the thing I would personally try to understand as well is that between the,
um, the variants and the operations, the switch statement is closed to the
number of variants, but it's open to the number of operations.
Like, for instance, you can always add more operations really easily.
You just add a new function with another switch statement inside of it.
And you've now added a new operation to all of these different variants.
Yeah.
Whilst the, um, the inheritance style is much more open to is more open to
variants operations this time.
So it's a closed set of operations, but open to numerous amount of different
variants.
This is the whole point.
You have a base class and variants like subtyping from it, the whole point.
You have subtypes or whatever, and it's more open that way.
So it's a lot more useful to be doing, if that makes any sense.
Um, yeah, hopefully that's clear.
So that's kind of the argument.
Now my point, personal view is that, which is getting talking in the thing here
with the commentary search is that the most of the time you actually have a
closed set of variants and usually you want to add more operations in practice.
So because if you've got a closed set of variants, why are you pretending as if
it's completely open, which is what inheritance is for.
It allows everybody to add more variants, even if you don't have control of that
curve, you just extend to it and it's abstracted away.
But most people within their own code base, like it's not going to be used by
third party people ever.
Usually pretty much isn't.
Um, so you, in that case, it's very close set of operate.
It's close at variance you have.
And usually when you're modifying code, you actually want to add more operations.
It's kind of like a different thing.
And they're solving different problems.
You have to understand this.
It's just that the weird oddity here is their argument is actually, you know,
the, the, the inherent style approach, which has all of the operations for each
variant bundled with that variant is easier to manage.
And the, the going on about like managing all these different dependencies and
talking about how many different places you have to deal with.
In case you just correctly point out, like, Hey, it's just a different win in
different ways, like this independent scene version thing is you're just trying
to get complexity.
And then again, Mr.
Martin says, yeah, like for every program composed of O operations and T types has
complexity of O times T.
If we use O, we can cruise T with minimal disruption to increasing O and vice versa.
It's like the switch same as you have increased operations with min disruption,
but disrupts source code.
Now I don't think this is true.
I don't think the disruption is actually even equivalent because it's weird.
Um, I know we shouldn't be talking about much, but this is not really clean code
anymore, but it kind of is related to it.
It's just the, but practically, how would you know which one is more true?
The case, like in my opinion, personal experience, we've always had a closed set
of variants, like if you want to have a new one, fine, but that variant doesn't
really like, okay, we all got updated every single place.
Now I use Odin.
So my switch statements will yell at me if I'm missing a case by default.
It says, oh, you've not handled this particular operation for this particular
variant, like in this particular case, and I just need to handle it.
Okay, great.
That's just better.
I know C and C++ and summer languages don't do this by default, but Odin does.
So clearly that's just a better language can solve those problems.
It's not really a, um, or better tooling in general.
It's not really a inherent thing.
It's just a tooling problem then.
Um, but then this is where it gets a bit weird.
He starts breaking things down to source code management about runtime, source
code, dependency inversion, and just make some terms up, which are not colloquially
understood to be meant in that context.
But again, it's the write a lot of text, try and make people understand how he
thinks, and then Casey just write small amounts.
It's the, it is a very big politician thing.
Pad it out.
Very good rhetoric.
I mean, he's great at this.
This is where I'm praising him, by the way.
Um, so again, read it for yourself.
Make your own opinion.
If you disagree with me, tell me in the comments below, tell me where I'm wrong.
Please tell me where I'm mischaracterizing me.
If I'm being too harsh, if I'm not being harsh enough, it might work.
Look, I'm not even, it's fine, but he then, it is fine.
Like just, just read it.
He's talking about these different things here.
Like he's procedural stuff, which is ifs, else statements, switch statements,
whatever.
Um, and he's calling me to say, run the time depen, I run the time dependency
when actually, no, we're going to make this compile time dispensary when it's
on the type.
It's like, no, you've just switched them around.
They're both the same.
So yeah.
Hmm.
So one thing he brings up here, which I thought was interesting.
And through this bit, as well as the second part that he starts up, I'll explain
why he does that in a minute.
He brings up, I would call the canonical case for inheritance.
So the canonical case of inheritance is the data stream.
So sorry if I've been a bit rambly all day.
I'm just trying to understand it because it is weirdly flowing as well.
Like the actual thing isn't like, it's a weird discussion.
But so I apologize for that and also apologize for my rambling as well.
So hopefully that's okay.
But again, should be all clarified here.
Here he does the canonical case for inheritance, which is literally a stream,
a data stream, a file or something like that.
And explains that, oh, these have standard operations, a close set of operations
like open, close, read, write, and seek.
Again, these are the five standard functions of the Unix IO driver.
And again, these are very standard functions on all operating systems.
So they actually map really well to the inheritance style of doing things.
The very dynamic polymorphism is he's referring it to here, which is, yeah,
it's dynamic dispatch, it's subtype polymorphism with v-tables.
Yeah, that's what it is.
But he's calling it dynamic polymorphism, which is not common term,
but he's whatever, he's using his own terminology as he needs.
But it's saying like, okay, we've got a close set of operations,
but we have so many different things like files could be anything.
There could be a file, there could be a directory.
There could be a piece of hardware on your device.
There could be just a general socket.
There could be anything.
It's like, it's open to be whatever it could be.
This is literally the canonical case.
Why is the canonical case?
Because operating systems make these files an object.
They are an object.
That's what they have.
Like they're an abstracted away opaque thing with a open, like a close interface
as to what they are.
So he's trying to argue like, this is what you meant to do.
Now, there's a lovely, lovely thing here is saying like, well,
this clearly has to be a thing.
And that's what he's trying to get down this route.
He's trying to take the canonical case to show to Casey that, hey,
you need inheritance sometimes, and this is the great way.
He's completely forgot the conversation.
He's talking about clean code, which will bite him in the book later
to use an American phrase later.
But then there's one, this weird thing he does here where all of a sudden
he talks about this hypothetical compiler, which would be able to,
you could write in the, in the Oopie stage, like an inheritance style,
and then completely the compiler would magically make this
be a switch statement if necessary, which is kind of interesting.
Cause it's like, what, what benefits would you get from that?
Cause it seems to be now a textual benefit.
It's like, you're talking about, oh, it's all clumped together.
A new variant that we know the parents like, but if there's some weird
things he just says, it's just a really weird hypothetical scenario.
He just kind of goes into, and they go on for this for a little while.
And Casey's like, I don't understand what you're talking about.
Like this doesn't make no difference, even with this hypothetical case.
So Casey goes on a bit more further here, just mentoring different things
and talk, I try to get what the benefit of dependency inversion
is anyway, and to begin with.
And they go on about this like, look, you've got a clothes interface
with opaque stuff and different ways of dealing with it.
And then we talk about this payroll thing.
They do all these different things.
Like I recommend reading it, but it is going to be this.
Like this is an OOPI thing, obviously.
You've just defined it to be OOPI because it is, it's defined to be OOPI.
Sorry. Yeah.
Okay. Yada, yada, yada, yada.
But again, Casey also kind of says it could just be some functions.
There's no reason, whatever, whatever.
That's not a problem.
Where am I looking for now?
I'm sorry.
I'm just trying to skip through this because it just goes on for quite a while.
Okay.
So Casey says that we're hypothetical.
You could just not do this and have it just a union
because in the example that Casey does when he does the union,
the shapes example in the video is, is this actually a union?
It's what I would call a fat struct union or an open, open union
where it has a variant and then just open fields.
So it's kind of like a table like thing.
A fat struct is a term that Ryan Flurry kind of popularized.
And it's kind of just like, here's a table of data or the fields available.
But hey, how you can just switch on it, like all this and just do
whatever you need to do and just access the data where necessary.
And Casey is saying, look, hypothetically, you could do this.
You could just have a file type with all the data
that responds to this in this union and deal with it.
Because in practice, there's actually only a certain set of files you could have.
You could even have the general case where it's it it will be like a V table.
Sometimes it won't use a V tail, but you can always optimize off that.
And there's many different things he's discussing here and such.
And he's talking about the union case.
Now, Martin, Mr. Martin goes here and says, look,
it seems like come on, come on, come on at the agreement
on just about everything other than per individual preference.
And it's like, no, he's trying to say, look, but we don't disagree.
It's like, actually, why are you having this conversation?
If you don't disagree, you clearly do, actually.
And you'll show this later on in part two of this written document.
And he says, thank you for the union collaboration.
Now I understand what you're talking about unions, which is like.
OK, and he says, I'll quibble you a bit on the difference
between operand and operation, but I don't think the quibble is particularly important.
In the end, it's just all functions, regardless of how you spell it.
As for human issue, performance is a human issue.
The computer doesn't know how fast or slow an algorithm runs.
But I think that that toss is dead now.
And it's like, no, it isn't.
This is kind of the point.
And he goes back to his microseconds, different module things again.
And then he then goes, look, we put a break in here to write extra bit more.
Again, rewrite history and says, look, I'm going to continue us now in the second document,
which is the number two.
Because he's trying to make a break here and then reframe the entire question in the second document.
It's a pivot and a reframe at the same time.
Clever rhetoric trick.
If you want to do that in an argument, you do that all the time.
You reframe the question.
So it's not even talking about the original thing again.
And he's tried to do this.
So that's what he's done here.
So right at the beginning.
And then Casey's reframed it and put it put it into the beginning.
So he's first.
So Casey knew what he was doing.
So let's not do that, shall we?
Yeah.
So Casey wasn't stupid.
So I'm just putting it here.
He's talking about all this goes back to the payroll example with all this kind of thing.
And Casey is trying to say is like, look, this is not an open problem.
You haven't got an open set of variants.
It seems like it's an extremely well defined problem.
So why does this need to be like operant, operand, primal design?
Let's say like variant open rather than variant closed and then operation open.
It's like this seems to be both closed.
Like it's very weird.
Like what, what are you trying to have in like save developer cycles with?
Like where's this kind of thing coming from?
And then this has been moved to our two yet because he reframed it.
It's fine.
No problems.
He's talking about the programmer cycles thing.
This is the thing.
He gave this random file he added in here, which is the, oh, great.
Let's do a code golf example, shall we?
Cute surprise.
It's like the point is the program sounds waste man.
I'm trying to program cycles.
It's like, yeah, you just gave me a code golf example.
The worst case of readability possible, but it's a code golf.
That's the whole point.
People write those things to be compact and human.
Like that's what you're trying to say.
Like we're trying to make it easier on like, can you prove my belief?
Not mathematically.
Just as I'm sure that you cannot mathematically prove that your favorite
style saves more or less programmer cycles than mine.
It's like, so he's already admitting that actually you can't prove my style is
worse than your style.
And it's like, because programmer cycles, like this is a qualitative thing.
He knows he can't measure it, which is actually, I don't think that's true to be
honest with you.
It's just that no one's really bothered to do the science because programming
isn't really young discipline or it's 70 years at best really as a discipline.
So it has no evolutionary pressure on there yet to say which things are good or bad.
So people just say random things.
So it is literally just like, great.
There's not really much science in computer science.
It's rather, again, I'm glad the rest of the world calls it informatics for a reason.
I don't know why we don't.
We call it computer science, even though it's not an empirical science and it's
close to mathematics, but even then it's not really in practice, it's close to
engineering.
It's just confusing term.
Okay, confusing term.
The dynamic was a dynamic binding and other type of just type post whatever.
I don't make more than this in my day to day life.
And he's talking about this.
So it says, do we agree so far about all this?
And it's like, the case is kind of like, well, we don't just
go about certain things in the general, but like in the specific.
I'm still asking the same question about this data stream thing you're talking about.
And then Mr.
Martin brings up again the, like, hey, here's something like the read, write thing for a C.
These helper functions don't, you know, to do all the stuff.
It's like, but if you had to do it in your case, we'd have to do a switch statement
like this wouldn't we?
Don't you know?
Oh, it's like, look at all the different variations you could hypothetically do.
This is just ugly.
Don't you know it's ugly?
It's like, by the way, if you, this is, this is a kind of tangent anyway.
I've been writing the coding call library and you actually have to do this anyway.
Like if you actually have to do, let me do the read, the OS read functions,
because the console on Windows at least does not act like a normal file.
In fact, the console on Windows is a UTF-16 document.
So that means you have to write UTF-16 files.
So if you actually write a UTFT thing to it, you then you have to do a conversion
to do it onto those.
It's actually like, or you have to do this edge case.
Not just that, the console has other things in it, which are not handled the same as an
old file again.
So it's a very, you kind of have to do this.
This is how real world code is not even purely like, oh, the operating system has dealt this
properly.
It's like, no, I still have to check if it's a console specifically and then deal with it.
So it's like, I know, like this is not working.
Like, yeah, it actually looks closer to this in real life, even with the abstraction on
top of what a file is, but I digress, yeah, but yeah, it's just interesting.
And then again, many different breaks, again, different edits here, different sections,
he's breaking it up.
The VTab we use by Unix, again, most operating systems do this as well.
Things change around significantly.
The IJS can be loaded at any time.
The IO device, yeah, that's true.
That's, again, this is the details we're talking about.
We're talking about code reuse, a great example that says the cases, I apologize for trying
to be very specific, but I really want to be, actually get to the exact proposal and
it wasn't clear from what, could you actually tell me what the OS interface looks like and
how it's implemented?
You said, I guess that depends on a lot on the language and the application, but my
understanding is that we're talking about the OS side.
So again, it's the, how does the OS implement this, like the stream, the file, compared
to how we're doing it in a language is very different.
And not just that.
Again, I thought we were talking about clean code.
Why is it going down this digression?
Just you wait.
Let's get, we'll get there.
Don't worry.
Oh, okay.
We're talking about get up crap.
Okay.
Cause it just changed.
That's, I can probably guess which day this was written on as well.
Like you're saying it seems like it looks like this somewhere.
Is it actually a base class?
Is it whatever?
And now Mr. Martin says, okay, here's kind of the general interface that you'd write
in C++.
Again, he's not answering the question he's asked.
He's done another thing.
Um, the whatever kind of missed the point again.
Um, and then he's saying, look, look, if we look at the, he's trying to say this is less
likely to manage whatever, but yeah, but you've just chosen the canonical example.
And he says, look, if I do the dynamite polymorphism case, so inheritance, I create, I create this
file of three files and have to leave them with a switch case.
I've now all of this and look at all these different things I have to define and like,
and cases.
Well, hold on.
Which proponent, at least I get to write it, please look again.
Look what he's just done.
He says, well, I've just shown you how to do it and look, it's just more complicated.
I've had to write files.
Oh no.
I'm like, cases like, hold on, hold on.
Um, yeah, and it's kind of doing like this.
So it goes on and on.
We just discuss things, but it's like cases like I want to know what the operating system
again.
And it's different.
And I'm like, okay.
And then Casey's like, we're not even talking about machine cycles again.
I'm just focusing on the program.
So again, would like he's doing again.
Sorry.
I'm like paraphrasing this poorly ish, but it's kind of just like, I'm trying to show
the techniques that he's doing here that he knows he's doing it.
He isn't an idiot.
I'm trying to be very careful like this.
Mr. Martin knows exactly what he's doing.
Like he's now just made another document on here, which only he talks about.
And it's just, he's trying to suggest like, oh, this is the clean code stuff.
And then he's saying this is what clean code is.
And I've just got the summation.
And it seems to correlate with what most people think it is because I miss people.
People keep this understanding made kind of view.
And it's like, wait a minute.
So choose carefully names, not unique.
Keep function small.
Why keep classes small?
Why manage your dependencies, vague as anything, literally be careful with side effects.
Okay.
Yeah, express yourself in code where possible.
How else are you meant to express yourself in code away?
It's your programming.
Use polymorphers when the type changes fast in the operations.
This is new stuff he's added now.
You switched when operating change fast in the types.
Why?
Why?
And at what cost?
And what Harvard evidence have you got this is better?
And like you're comparing it to this and like, you sure?
Okay.
When possible create designs where things that can change fast that change fast are types.
Why?
Keep asking this question.
Here's even in his summarizations of here, he's actually saying, we'll prefer polymorphism.
So now he's in like, well, I don't see how you got to that conclusion where like I'm
against switchtimes or something.
I'll clear and prefer like default before like all this.
I'm like, you're literally saying it in here in this summarized document.
If I'm misinterpreting it, please tell me again in the comments or something.
I'm just really confused.
Like what?
Right.
So Casey comes back again and he's talking about the internals of this.
It's like, okay, find the device, then you read it and you do this.
This is how ring versions, if you understand how they work internally.
Okay, great.
There's class.
Here's the operations.
And he said, look, you can always do it this way around.
And look, I've got a different way of doing it.
It's just a union based approach now.
With all the data inside of it doing all what we need, whatever.
And that thing that's just is actually trying to show the actual things internally,
isn't it?
But yeah, it's kind of like, look, now I don't like vtables,
because obviously it's pretty much everywhere because I find them hard to control.
So I prefer this.
So he says, look, I have a, not a vtable, but just inline things itself.
It's not a table, just inline functions.
So instead of a class, you've now just got inline methods.
And this is just general handling of a thing, which is interesting.
By the way, that should be more better for performance in general,
because a vtable is usually a pointer to a structure, a function tape,
like function pointers, whilst if you're embedding the function pointers,
you've got rid of that in direction.
So you've actually got, it will be faster in general as well,
because you've got rid of the in direction.
It also has a better chance to optimize.
And even it has slightly better chance of inlining and slightly.
But yeah, that's how compilers work.
Sorry, rambling again, again.
But I'm getting off the digression.
But Casey's kind of saying like, look, we could just handle it for each of them.
We could actually have one callback, just one,
and we could directly embed it in the structure.
So it's not even in directed anymore.
And then we switch on this.
Now, this is interesting.
You could do it for every single operation.
And then look, the code's in one place for this thing.
We've now got the best of both worlds in many ways.
And why wouldn't you prefer this way, I think?
Now, interestingly, I'm just going to like slightly digression here,
going into Odin.
And this is what we actually do for the allocator.
And I've been doing this for like a decade, maybe.
Even before Odin, there is the thing.
Sorry, apologize for the digression.
This is clearly unscripted, if you didn't guess.
Here's the allocator.
So in Odin, we have a built-in concept from an allocator.
An allocator is just a little data structure with a pointer to a procedure
and a pointer to the data.
So 16 bytes, you can easily copy this around.
So it's usually not even a pointer to the allocator.
It's just the allocator itself in memory, and you just get the values.
So that's what you're doing.
So there's not an indirection again, because it has to be a pointer.
And notice, it's just in line with the function.
And not just, there's only one function you think,
but there's loads of different allocation operations.
Yes, it's one function.
You take all the arguments in, and you change the allocation mode.
It's an allocation, alloc, free, free, all, resize, query,
feed, just query in for an alloc non-zero.
Because sometimes you want to be allocated without any zeroing.
But by default, you want zeroed, because it's quite useful.
And also, it's pretty much free if you're using virtual memory.
Like allocating zeroed memory is pretty much free.
Because it has to be for security benefits.
There's no option to not get it if you ask for virtual memory.
So I'm just trying to show here that I already take advantage of this kind of
approach, and then within every single allocator, I have a switch statement,
which then pairs each operation together.
So I'm just trying to get off my digression a bit here.
So this is what case is kind of trying to say, and you could do this.
So you're not having the full on inheritance style, you just have a switch.
You could do the blend of the two, and there are benefits to this, obviously.
And you'd have all of this.
Lovely.
So in either case, but this is largely relevant because it's solely a map lookup
now, and to a specific device, and it can be used in either design.
Anyway, over the course of the development of the OS, I think the implementation
saves programmers and cycles, potentially a lot of them, compared to the one I
understand believed you favored by the clean code method.
Again, which is interesting, because the KC1 is closer to being like
subtyping to a certain scale.
There isn't subtyping, it's just like, here's the abstract thing.
We're the function pointer, deal with it.
She's kind of close to inheritance, but it's not.
Just one.
And it sounds like a minor difference.
People say, oh, it's equivalent.
It's like, but it isn't equivalent.
And in fact, it will be faster.
You can easily measure it.
It'll be easier to maintain because everything's in there.
And not just that, if you add a new operation into that, every single one
will just yell at you anyway, because you've not implemented it.
So if you've got a language that tells you that, and switch name is obviously
not necessarily C or C++, maybe modern C++, I know, I think.
That's sometimes C with the, when you have warnings all and everything,
it'll tell you which name is missing certain cases.
But yeah.
In cases, look, I don't know if it's an extract and file code,
but it was the first one you brought up, and it happened to be the contrast
of the two designs in my opinion.
So it works for me, as Casey is saying here.
Here's why I think an enum-based design deserves the programmer cycles.
In most systems, you don't know all the functions that are going to be used ahead
of time when operating costs are hard boundary, like a driver, using operation
codes instead of virtual function calls allows you to add more functions
dynamically without recompiling all our drivers.
Yeah, yeah, no.
In any modern operating system, multi-threading is a concern.
But this is especially true for an operating system.
Having the protocol be structured based with an operation code allows us to
trivly a buffer operations in things like IO rings and other intermediaries
without writing any new code.
The entire system remains identical.
Yeah, I'm just trying to do this.
And you just said, this is, by the way, it seems like almost happens in almost
all systems at OOP systems.
I see, I'm trying to get around pronunciation, say, because eventually
they need to serialize or something similar.
And so they have to write my version as well as their version, but
they don't seem to realize how much time they're waiting.
Like, yeah, this is clarifying this point.
People think this seems like the clean code will actually save time.
It's actually, no, you're now forcing another person to write the same thing again.
And you are actually wasting time.
You think you're saving things.
But again, if you want to know if you're saving time, you're making a statement
like this will save programmer cycles, like a claim, show the evidence.
And don't just say, well, your seniors may agree with me because
they were convinced by my argument.
It's like, yeah, but where's the evidence, regardless of this
like argument by authority?
It is the after a while, many people will come out the phase and
like, oh, I don't do this anyway, but some people don't.
And it's like, okay, I never really went through the OOPY phase myself.
Got a bit of a digression here.
Sorry, this is completely random today.
I know, very, very unstructured.
But I went through the modern C++ like 11 phase.
So that's what 12 years ago now, probably a bit before actually,
because it was C++ 0x for a long time.
And I remember learning all that stuff, and that was the thing I got caught.
I wasn't really necessarily the OOPY phase.
It was that phase, so I was learning all that stuff.
And it was a while, took me a few years.
And the after was like, I'm doing all this extra code, writing loads, and
I'm not getting any more productive.
In fact, it's how hard to maintain.
I'm writing literally 10 times more code than I needed.
And they kept telling people, people kept telling me, because I was kind of
trusting these people who were more, thought they were more experienced than me,
or they thought they knew more because they'd been doing it for longer.
And they were talking from positions of authority to a certain extent,
that they were going, oh, of course, of course, this is going better.
Because I'm telling you it's going to be better.
I'm like, and then I was kind of believing them.
And I was like, it doesn't seem like, I'm trusting them.
But it didn't seem to be the case.
When I just started programming back to like a normal basic C style,
with switch statements in many cases, and just like normal
standalone functions, not even using methods, I got more productive.
My code got smaller, got easier to read.
Just by not doing any of that.
And it was kind of like not using, not doing any of the stupid templates,
not doing stupid any of the ownership semantics.
I'm not saying ownership semantics is stupid.
I'm just saying, being everywhere, it was like, look, I just kind of went
to more POD data, it was a plain old data, data, kind of style, old fashioned C style.
My code just got easier to read, more maintainable, and just everything.
Like from a personal perspective, again, I cannot measure this.
And the only way I can convince people to say, here's my code,
here's this normal code, which one do you find easier to read?
And that's the only way, that's not a measuring,
that's just still like a personal preference thing in the day.
This is the problem in these discussions.
And it is just getting down to that.
It's like, one side is, there is an empirical thing to a certain extent,
which I'm going to comment right at the end.
I will get to this, don't worry.
But yeah, he talks about this thing here at any point, things, if we would like
to talk about third parties to a lot of communication with channels on the devices,
blah, blah, blah, okay, we're talking about the IO stuff, fine.
We're nearly getting the answers.
So Mr. Martin says, okay, I think I see where we're going.
So let me say, sure, looks good to me.
The bullet points you added are after the fact are all quite valid.
And the design you picked works well in this case.
In the first point, you assume that operations will increase beyond the two
original proposed, as we both agreed, as I wrote in the clean code,
which by the way, is not the same as your clean code, right, when operation
proliferate more rapidly types, which statements are better.
So there's, that line alone is, oh, another rhetoric trick.
Lovely one, in fact, in my opinion.
In the first point, you assume that operations will increase beyond the two
originally proposed, okay.
As we both agreed, I don't think KC agreed to anything.
And secondly, KC's not calling what he collies clean code.
He's trying to understand what your clean code is.
KC never says his code is clean code, because yours, Mr.
Martin says clean code with a capital C trademark to kind of think.
Yeah, so another little kind of trick he does already.
And he can't help himself really.
So when operations proliferate more rapidly types, switch statements are better.
In point two and three, you raise the specter of multi-threading.
You are, of course, correct that queuing operations is a lot easier if you
request packets of the same type of design.
No argument there.
And the last point proposed a kind of hook for unknown and
unspecified possibilities in the future.
Yeah, so what he says is like, okay, you have the general cases and
then have a hook for the unknown cases, like the open cases.
Okay, if you think those unknown cases and special are likely,
then you should have considered them earlier.
But then that raises a number of other concerns that we should not likely
address in this document.
It's like, no, no, no.
So I think I'll let that pass.
No, why?
Because if you didn't, it has to let that pass because it then kind of defeats
his point because the inheritance approach, which is preferred by clean code,
is saying that the open case is the open set of variants,
the open set of operands is the general case.
It isn't because if you've got a close set, which you know,
like pretty much always know that 99% of the time, 99.999% of the time,
is going to be going to be closed,
like pretty much is going to be that small set.
So you're optimizing for them, and then you've got this,
the unknown hook cases allow the user to add their own callbacks in there.
Fine, that's fine.
But it says, it says, unlikely consider the head of time.
So yeah, but you're assuming that those unknown cases are just as common as
the known cases and that is actually a design in the API.
Now the thing is, if you're optimizing for the general case and
then you allow a hook in, that hook is not going to be any slower than if you
design it to be always a general case than the specific cases.
That's the point he's trying to say here.
That's why he's letting it pass because it is literally just as fast to do it that way
than to design it all the way around as if it was always unknown.
As if it was always dynamic polymorphism, sorry, just say inheritance,
it's easier because technically what it is in this case.
So now where are we?
You propose a solution that uses dynamic polymorphism,
select student types, and then a switch same to select operations.
I have no problem with this.
It works well and satisfies my concerns about dependency inversion.
I'm like, but it isn't the same kind of dynamic polymorphism that you've ever
recommended to anybody.
So this isn't technically key and code.
In fact, anybody who would, a clean code advocate would read Casey's code of,
let me go back to it, this and go, that's not clean.
So this leads to the problem of clean code is whatever Mr.
Martin says it is at that moment.
It's not like anyone could actually agree on what clean code is because it changes
from time to time.
It's not a well-structured thing.
And he said, okay, that's fine.
It's like, then why don't you just call it Mr.
Martin style because it clearly doesn't work.
It's not clean.
And it clearly doesn't work the way he wants to do in every single case.
But then it's, ah, you shouldn't do it like a dogmatic.
And it's like, it's a weird trick.
He says, look, don't be dogmatic.
Don't follow these the rules.
But then it's like, well, I don't agree with it anyway.
Well, you clearly, there's some of these rules, don't you?
It's like, it's that clever trick again.
It's the port barrel naming again.
It's the rhetoric over rhetoric over again.
And I'm like, look, even if Mr.
Martin's style increased programmer cycles, the decrease of
wasted programmer cycles, like, whatever, great.
But how do you prove this is the case?
And we're getting to the end now and we're just going to do here.
So I'm just going to read the best of it.
So, so, Mr.
Martin's your proposed solution time with things, blah, blah, blah, blah.
What have you got to this?
I will say, however, that that is an ironic that after your video and
after all the stress that you have been put on saving machine cycles,
you eventually chose a design that sacrifices machine cycles to save programmer cycles.
After all, on the OS side, this is where he thinks he has won the argument.
Ready?
This is what he's tried to, he's tried to trick.
He's tried to do it because he took the canonical case of a stream.
After all, on the OS side, you've got to package all the quest packets and
it's the dynamically dispatched handler and then run the operation ID through a
switch and I think we wind up in the same place when operations
proflate more rapidly than tights.
We both use switches.
You don't.
You do not do this.
I've read your code, your public code.
You don't do this.
But he's saying he does.
Let's just pretend you believe it, okay?
When tights proflate more rapidly than operations, we both use dynamic dispatch.
We are both willing to sacrifice machine cycles to save programmer cycles.
No.
Also the way, again, how Casey structured it will be better because it's not
technically, how many levels in direction do you have before?
Like, technically here has one level of indirection, which is a function pointer.
Compared to normal inheritance, which is three levels of indirection.
Why?
You've got a pointer to the object, pointer to the V table, then a pointer to the function.
Guess which one's going to be faster?
Just have a hesitant guess.
Okay?
And not just that.
You then have to go all through this indirection compared to having one,
which is probably going to be literally cashed already.
In the cash ready to be called, no problem.
It's going to be easily predictable as well for the CPU.
It's a very different thing.
Very different operation, that is, to a generalized V table.
So no, they are not equivalent, even in performance.
One will be quicker than the other.
I'm not doing this video.
I could do it in another video if you'd like.
But like, we could prove it, one's going to be quicker.
Single indirection compared to triple indirection.
Okay, so when we are two individuals on the same eye and
the only difference being that I wear this shirt, I don't know how to pronounce that
word, whatever, with clean coat and you have one with clean coat.
I'm like, thank you for simulating the debate.
I appreciate your candor and the civility that you exercised here.
And if, if not everywhere, I've come to experience your respect, your knowledge
and blah, blah, blah, whatever.
So the first thing is, this is a really dodgy thing.
Casey, I don't even cases, well, I disagree with most of that, but if we're
ending here, I'll just finish my final responses for Gail poster poster posterity.
And that is the thing.
See how he tried to end it.
And I'm going to read through Casey.
I'm not going to comment on it now.
I'm just going to read it for the end of this video because we've already been
going on too long.
Sorry.
So I apologize for my rambling in between.
I hope it's kind of an enjoyable, if not, and I apologize again.
So I'm just going to read through this.
I'm just going to read Casey's stuff.
This is all Casey, not me.
So regarding, as I wrote in clean code, which, by the way, is not the same as your
clean code.
Well, the point is of discussion was you to elaborate on what is not the same, but
you're designed for the IO system looks exactly like my clean code example of
virtual function for every operation, one class per element in the system with no
predication.
So what are these differences that you're referring to?
Now would be the, now would be the time to explain what they are since that was
the point of the concrete example.
If these are a bad example for accelerators, it's straight in the differences.
That's fine.
But it was the first one you gave to assumed that it would be the one you want to
use regarding when operations proliferate more rapidly than types, switch
states are better.
That was not the case here.
In no way are operations proliferating more rapidly than types in the system.
Vendors will add drivers to the iOS constantly.
Perhaps a monthly or even weekly, whereas the number of operations in a
particular system tends to go up much more slowly once every few months at a
maximum, but more likely once a year for something like the aniosis subsystem.
It isn't the opposite of what you said.
This is an important distinction because what I'm demonstrating here is the
opposite of your rule.
This is showing that even in the case where types proliferate far more rapidly
than operations, as in the case of drivers in an OS, the principle doesn't work.
Enums are better in both cases, or unions in the case, specifically because you
have potentially thousands of types in the system.
All different drivers, all the vendors have ever shipped.
Adding a single operation, however rarely, can cost massive programmer cycles to
the unnecessarily work multiplication across types that V-tapes cause.
Another way to say this would be enums are more important in a system where
type proliferate rapidly, not less.
Regarding, you eventually chose a design that sacrificed machine cycles to save
programmer cycles.
I did no such thing.
The design achieves both, like why, that's why I like it.
It's drastically faster to use something like a packet based system than
something that is originally proposed design, because you do not take a ring
transition on every operation.
New OS IO APIs are not all designed this way.
This user writes data without taking in talking to the OS and a kernel thread
picks up those data rights.
Nobody ever makes a function call, except occasionally to ensure the kernel
thread hasn't gone to sleep.
This is what I mean by the bullet point.
If at some point we decide users should be able to do multi-threading
book IO ops, I am talking about the necessity that actually occurred in both
Linux and Windows of removing their frequency of ring transitions for
saving CPU cycles.
None of this is trading CPU cycles for programmer cycles.
It's achieving both.
The Linux kernel design of the IOU ring looks like my design.
That did not add to save programmer cycles.
They added it because they wanted the highest possible IO throughput.
This is an almost universal principle of modern OS design.
Anything that can be turned into data rights should be and function calls
should be minimized.
It's been true for GPUs, for NICs, and for our example, disk IO.
And then the last bullet point is regarding, and so I think we wind up in
the same place when dynamic operations proliferate more rapidly than types.
We both use switches when types proliferate more openly than
operations, we both use dynamic dispatch.
Again, I don't see how you got there.
Obviously types are proliferating more rapidly in this system.
So that is part is true.
If we didn't believe drivers are proliferating rapidly, why are we
loading them dynamically?
And I thought that was the entire point of the example.
But perhaps more importantly, we are not using dynamic dispatch here in
the way that you've been suggesting.
I said that when I proposed the design process, I would also do the
inside drivers themselves.
I would not duplicate drivers to remove if statements and switch
statements inside a driver that allowed the drive to handle multiple
similar devices.
The only reason that there are function pointers in this system is
because the problem definition required that we load the driver from a
different module, and we are not presuming a JIT or something that
can weld, wield, weld things together for us.
That introduces a mandatory cut so we cannot get rid of it because
the problem is defined to contain it.
But note that this is not the same between our two approaches.
I have a function pointer there because it's required.
And you'll note, I've minimized the number of all the way down to one.
I didn't put it in there because I think it saves program time.
In fact, I'm not really sure I want it there at all.
I haven't actually implemented this particular system in an OS, so it's
somewhat off the top of my head, but it's very impossible that if I actually
went to write this, I wouldn't include that function pointer at all.
Instead, I might just have the OS thread reading the queue, sorry, the
OS thread reading the queue, and proliferating the pre-filtering the
packets for quota permissions, then updating a shared memory access that
lets the driver know it can process the packets directly without actually implementing.
I can't say that's for sure what I would do, but it's probably something I would try.
So thanks for overstating the similarity of our approaches, but I think
that they're similar, then I guess that's just where we end up.
Thanks for taking the time to create this thread, which pushed the
GitHub emoji to check a well beyond its limits.
Sorry, I had to read all that, but yeah, that was all right.
So this is kind of the point I was trying to point out.
I said, like, case was saying this isn't what you were showing.
And the point where I say, like, Mr.
Martin thought he won the argument that you need to use this style is by using
the canonical case of requiring it, which is the canonical case is a data stream.
A canonical case of, like, you've got different operations fixed interface,
but you've got an opaque, different, what it actually variant type, whatever it is.
And then they talk about actually, how does it implement the operating system case?
It actually just shows that actually effective.
This is how you do it in Linux.
We don't know how Windows works kind of we can reverse engineer it.
But like, it's not the source code is not public, obviously,
because it's a closed sourced operating system.
But that's kind of the the issue that's going on here.
Mr. Martin thought he won by showing like, you already just did dynamic dispatch.
In case you went, you just find it to have it.
And in fact, I didn't even require multiple functions acquired one.
It's not tripling direct.
It's only single in direction.
And I just had a switch name in there because this is also how the operating
system does it and it's better for literally CPU cycles and reduced
program cycles. It's not one or the other.
So hopefully this is OK.
And I'm done now.
I was just going to do this and I was talking about this.
We've already discussed this.
What I've seen was I did a tweet on it mildly and there were some other things
I was talking about here.
I want to talk about Mr. Martin, but I didn't in the end, be honest with you.
It was more of a I'm just showing the rhetoric styles of Mr. Martin.
That was it.
So I hope you've enjoyed this.
I apologize. This is about one hour and 20 minutes long.
So thank you for putting up with all this.
I wanted to end off with this little thing here.
This is what I wanted to end for.
So we already had this in his code, but someone commented here saying, look.
I says, but there's kinds of environments, though,
the parsimony is important nowadays.
Far and few between the vast majority of software
requires less than one percent of money, but I think this is the first section we read.
What's more, processes are so cheap and available
that it is a trivial matter to add more of them to the system.
Someone replied, I should know this person, by the way, personally,
we do not consider it good engineering practice of the person wrote it.
Not the quote, good engineering practice to consume a resource
lavishly just because it happens to be cheap in the class of it on Nicholas Worth.
One of my actual programming idols out there.
And I love this quote because it's come as Viet's law of worths.
However, it's his name.
He doesn't care. It's either name by or bind value.
It doesn't matter.
And then Mr. Martin replies, that depends upon the which resource
you are talking about.
Computer cycles, computer cycles, programmer cycles.
Which should you trade against?
And again, I don't see what being that simple code is easy to write.
Our bubble source simpler.
The tricky again, it's another trick.
I was just last showing the rhetoric trick.
Simple is actually an overloaded term in programming.
And it's that it's an overloaded term in English
because simply you need to mean the opposite of complicated
or it can mean the opposite of complex.
And in the case of complex, the technical term would be simplex.
So is it simple as in not complicated or simple as in simplex?
And he has just done this on purpose
and he knows it very well by saying, well, bull sort is simplex.
But it's very expensive.
Multiply and multiply by repeat about it.
So it's simple.
Actually, that's how much actually that's how like AMD processors,
not AMD ARM processors actually work, by the way.
They don't technically implement multiplication.
x86 does, by the way, on AMD 64, sorry, I should say.
AMD 64 does an x86 in general.
It's actually one of the only is very, very refined process that does this.
But they did it.
Linear search is a simple, like, yeah, they are simplex.
They also may be simpler, faster as well, but they might not be.
Like there's a reason.
But this is the trick.
So I just want to end on that note.
So I hope you've enjoyed this.
Please remember to like that smash button
and to comment in the description below.
And again, if you want to read any of these links before,
I will post them in the description of the doobly-doo below below here.
And hopefully you've enjoyed this.
This is a very untructured ranty talking about Mr.
Martin's rhetoric style with regards to clean code, how and at the end,
effectively, he just stated exactly what most people thought clean code was stating.
And Casey went, so I was right about what clean code was.
OK, thank you.
So goodbye, everyone, and stay tuned for the next video.
