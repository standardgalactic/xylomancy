Okay, shh, no more.
Hello and welcome to the first session of 2024.
This is Sightly Out of Sequence.
It's part of our Doctoral Consortium series from last semester.
Our final session had to be cancelled at the last minute,
but we're delighted to have a follow-up session
to complete the series on the theme of AI Apocalypse,
the series that was called the Dark Side of AI.
And all of the previous sessions are,
which we've uploaded onto our digitalfutures.international
YouTube channel.
And I would say that from the first five in the series,
that we became a bit more, I guess, lenient in some way.
I started off by saying,
well, actually we do need to worry about AI
and over this course of the series,
which is actually fascinating because we had a series
on questions such as copyright and so on and so on.
I think people softened up a bit and said,
no, we don't have to worry about AI.
Today, I'm really delighted to have Eric Kessel here with us.
Eric is a designer, educator, writer,
and post-disaster expert, professor disaster, I guess.
And Eric takes a rather more kind of
concerned attitude towards AI.
He was formerly the director of the Sustainable
Environment Design major at the College of Environmental Design
at UC Berkeley.
He's currently a special program instructor
at Harvard Extension School.
And Eric really has made a name for himself
because using the kind of lens, shall we say,
of disaster theory, disaster studies to look at things.
He recently published what I think was an extraordinary article
in InDesign Intelligence, looking at the question
of what the impact of AI would be on the profession.
Today then, Eric is going to make a presentation.
We are going to have, I will have a short discussion with him,
and then we'll open up to questions from,
not only on the Zoom audience itself, but also from YouTube.
So feel free to put in some of these questions.
Probably not as long a session as sometimes
some of our sessions, but this is, I think,
going to pick up as we go because I think
this is an absolutely fascinating topic.
So Eric, welcome.
It's great to see you.
And it's a great way to kick off the new year
with a bang, shall we say, AI Apocalypse.
Yeah, well, thank you for having me.
I appreciate the chance to talk about it.
I've actually entitled my lecture,
AI Apocalypse Question Mark.
I think it still remains to be seen,
and we have some agency in what happens
in the future of design, architecture, and AI.
But first, let's break this down.
We're going to go through an introduction
talking about crisis and disaster,
how to cultivate a disaster lens and what that looks like,
then deconstruct some myths on AI and architecture,
and then finally wrap it up with the brighter side of disaster
because there is one, and fundamentally an optimist.
So I hope everybody sticks around for that.
So a bit about me.
I've done a lot of things in my career.
I've had a pretty eclectic experience,
been an activist, humanitarian builder,
periodically an architect, a construction manager,
a brief interlude for graduate school,
a disaster responder, a kind of design,
Cassandra you might call it,
a writer, radio host, professor, and academic director.
And that brings us into 23-24,
which was an interesting year for me
because a lot of these things effectively came together
to launch this recent mission around AI and architecture
and the potential consequences for it.
My work has been all over the place,
but I think I'm probably principally known for two things.
One, writing a book called Down Detour Road in 2010
in spite of the Great Possession,
and that was inspired by a different kind of crisis.
I read an article in The Nation, I believe it was,
or maybe it was The Guardian that talked about
the relative unemployment rates for different professions,
and I was shocked, slash not shocked,
to find out that architects were at the bottom of the list
out of, you know, 700 something professions,
or 380 professions, I'm sorry,
but they were facing sevenfold, eightfold increase
in unemployment claims, and, you know,
this didn't make a ton of sense to me.
And my read on it was that the profession was in crisis.
I mean, it was a recession, so everybody was in crisis,
but architecture was in its own particular crisis,
and to me it was a crisis about value.
People had ceased to really value architecture
was what explained that for me.
I wrote a book about it called Down Detour Road,
which the premise of was that, you know,
people had ceased to see the value in architecture,
because I think architecture had ceased
to see the value in people.
During the deconstructivist period,
we got into a lot of formalism and distance ourselves
from the problems that people deal with in their everyday life,
and, you know, that led to a lot of openings
and hopefully an optimistic message about architecture.
Secondly, I'm probably best known for my post-disaster work,
which began while I was still a student.
This is a picture taken of me right before I went down
from my first assignment in Biloxi, Mississippi,
where I was working with the Biloxi Gulf Coast
Community Design Studio under David Perks.
And it was an education, I think,
that put me in touch with the real power of architecture.
From there, I went to Haiti with Architecture of Humanity,
and that was a furtherance of my design education
and understanding about what the real power of architecture can be
when it's pointed in the right direction.
And it was blessed to be surrounded by an incredible team
from all over the world.
It was about a third Haitian, about a third Haitian diaspora,
and about a third international,
which in itself is composed of architects from 10 countries.
And we put together a pretty incredible program
of community-based design,
working with survivors of the earthquake in 2010
to rebuild schools, clinics, whole communities at times
to offer training.
This has been the bulk of my practice, actually,
is helping people through disaster
and helping them imagine better futures
because there's always the potential
for a better future after disaster.
So from there, I went to Japan
and I was interested with that program,
and there was a similar remit.
Subsequently, New York, the Philippines, kind of all lower,
and that work was enough to earn me a kind of dubious moniker
of being architecture's first responder,
or so-called by the daily beast.
I retired from field work in 2015
after the Nepal earthquake
and turned my attention to teaching first at Washu
and finally at Berkeley and most recently at Harvard.
And in those programs, in varying ways,
I teach about disaster and resilience.
I try and bring those lessons and those conversations forward
into the practice of architecture
and the teaching of the practice of architecture
and design, among other things.
And through that work, I developed,
I think we call it a theory of disaster
and how to look for it, how to understand it,
how to see the world through that particular lens.
And all of this came together last year
when I was asked to write an article
for Design Intelligence Quarterly,
the article that Neil mentioned in the introduction.
And it wasn't originally supposed to be on AI,
but between myself and the editor there,
we agreed that it would be.
And that launched an exploration
and it was fueled by skepticism, I think.
At the time, this would have been February of 2023,
there was a disconnect between what was happening in the world
and what was happening in design.
I mean, I suppose there typically is,
but this one seemed a bit more ominous.
In the world, we were hearing messages about,
you know, AI is going to destabilize everything
and a little bank and the IMF
were predicting huge job losses and massive change.
Professors at Wharton and top business schools
and economists were, you know,
looking at this as a very, very serious development
in the future of work.
And then there was, you know, the design world.
So, you know, I read the same design rags
as everybody else, I suppose.
So, you know, we kept hearing messages
from design leaders to this effect.
You know, there's nothing that can compete with architects.
This one from Shane Berger, you know,
the design process is going to remain fundamentally human.
There's this kind of limited capabilities.
And I wanted to understand for myself where the truth lay.
I suspected it lays somewhere between those two polarities.
And, you know, I asked if I could explore this
through this article for design intelligence
and I gratefully said yes.
So, you know, I sat down to figure out, you know,
what exactly I thought the impact was going to be.
And the prevailing line at that time was that, you know,
AI is going to automate the simple things.
It's not going to automate the more complex work.
So, for me, the greater challenge was, you know,
how do you envision or propose that AI might actually,
you know, replicate some of that higher level work
that architects and designers do.
And I borrowed something from Phil Bernstein's book,
Machine Learning, a framework for understanding
the relative cognitive complexity of different tasks
that exist within an architect's day.
If you've read that book, if you haven't read that book,
you should. It's a great book.
But Phil has this framework, essentially,
for ordering projects between, you know,
procedural, like really kind of task,
repetitive tasks or things up to integrative and perceptive.
Those are the higher level cognitive functions.
And he provides us with a brilliant map, essentially,
for where all these things occur within the architectural process.
And just to make my life difficult, I said,
well, you know, what if we aspire to get it to replicate
the harder parts rather than the easier parts.
I figured the easier parts would figure itself out.
To me, and I think to Phil as well, you know,
the hardest parts are the integrative stuff, right?
It's the vision. It's being able to sit with a client
and context and understand through typically inarticulate words
what that vision is actually going to be
and to bear it out in the form of an idea
for a building or something like that.
And as a proof of concept that, you know,
I was actually made for myself just to make sure I knew
what I was talking about. I developed a video,
which I think, you know, also mentioned in the beginning,
but it's attached to the article.
You can find it on my YouTube channel.
You can find it on Design Intelligence.
But I'm going to play a short clip
just to introduce what I'm talking about here.
Hilda told me a bit about your project,
and I'm excited to learn more.
Can you share your vision for it?
I'm looking to build a modern, sustainable home
for myself and my two children.
So what you're looking at,
and this goes on for about 20 minutes,
is two GPTs set in opposition to each other.
And they've both been programmed with personalities.
So I said to the model, like, you are the client,
you are a successful tech executive,
you are a mother of two,
you have a passion about kayaking, you know, this sort of thing.
But I didn't give her any specific information necessarily
about the architectural process or anything like that.
And I did the same thing with the gentleman on the left,
who was the architect, right?
He was an architect, he was 55.
You know, he went to school at Columbia,
this, that, and the other thing.
I didn't give him any instructions
on what being an architect actually meant.
And Hilda told me a bit about you.
Let's fast forward through that.
Through that conversation,
GPT was able to generate a design brief
based on the interview that the client had.
Truthfully, it was just GPT having a conversation with itself.
But nonetheless, based on that exchange,
which was totally autonomous, it generated a design brief,
which was then able to convert to image prompts,
which went into mid-journey.
Once mid-journey five debuted,
I was able to actually get image recognition to play along.
So Carla, the client, could actually look at the design options
and respond.
That was a little disarming.
The really alarming part were all of the emerging phenomena
that came out of this.
I guess emerging capabilities is what the AI world calls them.
But chat GPT illustrated some,
some alarming knowledge about the process itself.
So, you know, once it had gone through this design process,
I asked it to produce a door and room schedule,
which it did.
And, you know, oddly, somehow knew that, like,
bathrooms should have one window and not two.
And that a powder room might be the exception.
A powder room might have zero windows as opposed to one.
So, you know, it was picking up on all these lot of things
that might be known to an architect
or might even be known to a layperson.
But I certainly did not expect that the model
would be able to extrapolate all that information
just from a 20-minute conversation
between an artificial architect and an artificial client.
It did the same thing with budget.
It came up with a budget for 2.2 million.
Again, no, no extraneous information.
I mean, it inferred that from the site and from whatever Carla,
the client was saying to this architect
that she wanted out of her house,
checked with a few contractor friends
and, like, a lot of this AI stuff, you know,
wasn't wrong, could have been better,
but it was in the ballpark.
So, this immediately struck me as a disaster
because disasters typically happen
when the perceived threat is much different
than the actual threat.
That's what gets us into trouble as a species.
So, in my estimation, you know,
I didn't believe the doomsayers
that were saying that, you know, this is the end times,
but I didn't believe the Pollyanna stuff
that I felt was coming out of a lot of the design professions.
The truth was somewhere in the middle
and didn't look great.
But let me flesh out what I mean by disaster lens
to shed some light on that.
So, how do we cultivate a disaster lens?
I teach my students that there are things that you can look at
that speak to the growing vulnerability
and precarity of a particular context or situation, right?
So, if you're looking at a natural disaster,
like an earthquake, fire, hurricane, that sort of thing,
you might look towards, you know, neglected infrastructure,
trending towards decay, you know, bridges and power stations
that should have been replaced a long time ago.
You might also look to the emergence of patchwork solutions.
So, if instead of replacing the broken levee,
we just keep building it two feet higher over and over,
that's usually a pretty good clue.
A widening or deepening of the zone of vulnerability.
So, 100,000 people living in a fault line,
that could be a problem.
That can be a disaster.
That city swells to 3 million people.
Then you've got a really serious disaster on your hand.
Same fault line, just different zone of vulnerability.
So, widespread irrational and credibility.
This is a tough one to pin down,
but basically it's the anti-chicken little phone.
The people who believe it can't happen here,
and that is an emotional and a psychological belief
that isn't particularly grounded in any evidence or analysis.
It's just the way that people feel about things.
All of these things taken in their sum, or even one by one,
don't necessarily constitute a disaster.
This is merely the framework,
the things that set up the possibility of disaster.
I liken it to a tornado watch and a tornado warning,
and then I find that people don't really understand what that is,
especially if you're outside the United States.
So, I've actually happened upon the taco watch,
and the taco warning is the way to explain it.
So, taco watch is like,
you have all the ingredients for a taco,
but there's no taco.
It's just a bunch of ingredients laying around.
The taco warning is like, we have a taco.
We're having tacos right now.
You need to react to that sort of situation.
So, the four things,
and that's not a comprehensive or exhaustive list.
We go through much more through the course of the semester,
but there's things that you can look at
that essentially create the possibility of tacos, so to speak.
Finally, you need to trigger an event.
That's the thing that ultimately brings a disaster into the news,
into reality, and believe it or not,
I've always found the best way to explain this
is by using beavers as an analogy.
So, when a beaver goes to cut down a tree,
it doesn't cut down the entire tree,
and it doesn't push the tree over.
It's not a very strong animal.
We were talking about a 30 or 40-pound animal
versus a 10,000-pound tree.
What it does do is it eats around the base
and subtly erodes the structural integrity of the tree,
and eventually a gust of wind comes along
and it blows the tree over.
That is not the beaver's doing.
It's the wind that blew over the tree.
The beaver just set up the conditions for the wind
to be able to do that,
and we can map this over time
and look at, you know, essentially a wind condition,
right, then the wind's blowing, however the wind's blowing,
and then a rate of chewing that is constant, presumably,
and then because the rate of chewing is constant,
the structural integrity of the tree is steadily declining.
Disasters happen here in the red circle.
At that intersection of some event
and some trajectory of vulnerability,
that's where the disaster, in fact, occurs.
It does not occur when the wind is strongest.
It does not occur at some particular point of vulnerability.
You really have to bring those two things together in time
in order to, you know, have a disaster.
You can apply the same logic to a city,
and in fact, in my classes, we often do.
You can take the healthy growth of a city,
you know, maybe at 2% or something like that,
but the population density is growing faster than that,
which suggests a lack of housing or something else going on.
The average wealth of population is going down,
which means people have fewer resources
to support themselves in the event of a disaster.
The budget for emergency services is static,
even though the population and the population density is increasing.
The average age of critical infrastructure,
so, you know, bridges and buildings
and everything is falling apart.
You could roll this stuff up together,
not necessarily in an arithmetically way,
but you can roll this stuff up into some kind of picture
of overall resilience, right,
based on the number of things that are going up
and the number of things that are going down
and how impactful those things are.
You get a sense of whether the resilience,
the ability to resist an event
is going up or down for a particular city in this case.
And then you have, you know, the event itself,
like the earthquake that happens every 100 years,
200 years, 500 years, whatever it is.
But when it does, as it crosses that intersection,
that's what creates a disaster.
I mentioned the 2010 Haiti earthquake previously.
Haiti had actually had a similar sized earthquake 200 years prior.
Of course, nobody remembered,
because we don't remember things that happened two hundred years ago.
Not a big disaster, not a lot of damage
because there was hardly anyone there.
It was 200 years ago, so Port-au-Prince was there.
It was just a very, very small city
and most of the buildings were made of wood.
So you really have to look at the possibility of disaster
as something that is happening through time.
So we can actually translate this disaster lens,
this disaster thinking to non-physical things,
and that also happens in my classes from time to time.
We can apply it to non-physical things,
like a profession itself,
which is kind of how I started looking at all of this stuff.
So in terms of infrastructure,
well, a profession of architecture is terrible infrastructure.
We have long licensing periods, low pay, precarious employment,
cutthroat competition.
It's not a structurally sound profession necessarily.
We can debate that, but yeah, at any rate.
And then we have patchwork solutions.
So if the profession is facing a crisis of value,
then it keeps kind of doing these stepwise things,
like slightly changing the internship program
that everybody has always disliked under any particular form,
or transitioning to BIM,
but not capturing the value off of that transition.
A widening zone of vulnerability.
Well, there's 17% more architects than were a decade ago,
but AI is going to leave them with less work to do.
How much less work?
We're not really sure,
but that pool of vulnerability is getting larger.
And then the widespread irrational incredulity.
And I would put in this box specifically,
design voices that are saying,
well, there's not going to be any impact on architecture.
There's just going to be impact everywhere else.
I mean, that ignores all fundamental laws of economics.
I mean, if there's huge job losses in a non-architectural world,
in the rest of the economy,
that has macroeconomic effects, right?
So probably gets us to 5%, 10% employment, causes a recession.
The last time that there was a recession with 10% unemployment
in this country,
a third of all architects lost their jobs.
So the idea that, you know,
AI might have some huge effect on all their professions,
but not on architecture is incoherent, in my opinion.
And the triggering event, right?
What is the triggering event in this case?
You know, in 2008, it was the great recession.
And I think that the debut of natural language generative AI
may in this case be the triggering event.
So we can map this out the same way that we have with these other things
and say, you know, look, for the profession of architecture,
the complexity of buildings is increasing.
That's good for architects because it means they have more to do.
The cost of construction is increasing.
That's also good because design fees usually track
with construction costs.
Student loan balance is going up.
That's not good because it means architects themselves,
especially the younger ones,
are in more precarious individual situations.
Pay relative to inflation is going down.
Okay, that's not so good.
So the overall resilience is going downwards.
And then similarly, like what we saw with the tree
and what's going on with the city,
we have this curve, you know, whatever it is,
the shock to the system, be it a recession or a new technology
or something like that,
that brings about the disaster, right?
The disaster happens at some point in the future.
So why doesn't this feel like a disaster?
I can hear some of you saying,
we don't think of it as a disaster the way we do an earthquake
or hurricane or something like that.
And I think that the hesitancy to understand it as such
is translatable from, you know, physical hazards
to professional hazards and et cetera.
We protect ourselves from the psychological toll
of impending disaster through myths, right?
We invent ideas about what's going to happen
and what's not going to happen in order to protect ourselves
from the really high emotional and psychological costs
of understanding that.
That's the logic of it can't happen here.
It can't happen to me.
Human beings are actually not very good at judging the future.
So we create these myths about what's going to happen in the future.
And they keep us safe when we tell ourselves,
it can't happen here.
That's a problem because if we really believe that,
we're not preparing for it.
And I think that was part of the point of Sinclair Noulous's
novel is that if you think it can happen here,
you'll take steps to prepare for it.
But if you've washed out the possibility in your own mind,
then, you know, it kind of opens the door to whatever's coming next.
Not a guarantee, but it opens that door.
So how do we deconstruct these myths?
This is my favorite part.
And on my sub stack, life is a disaster.
You'll find lots of examples of this where I kind of go
and break down, you know, myths associated with AI and architecture.
But let's deal with five of them just for today real quick.
Myth one, AI won't replace jobs, not tasks.
I started with this one because it's patently absurd.
That's what a job is.
It's just a bunch of tasks that roll up into some project
and projects that roll up into programs
and programs that roll up into practices.
So what we're told, what we've been being told about this AI stuff
is that, you know, you're going to have a firm
and then everybody is going to, you know, essentially have more time
because, you know, all of this technology is going to automate away
all of the boring tasks that we have.
This isn't how it plays out.
And, you know, if anybody's ever been in a firm
where layoffs are going, this isn't what happens.
You know, they don't allow people to just have their workload
reduced necessarily.
Every firm principle in the world is obsessed with utilization.
Like how do we get people to a maximum level of utilization
where, you know, we're billing the clients for that person's time?
So the more likely scenario is actually this one, right?
Workload is reduced through technological efficiencies
and you just don't need that fifth person anymore.
That is what happens in the face of technological evolution
and efficiency gains.
And then, you know, at the end you have four architects instead of five
and they're fully utilized because that work has been redistributed.
This has to be the case because of the way that we define work.
So work is just some amount of effort times some amount of time.
That's all it is.
And an example on screen, two full-time equivalents for six months
is equivalent to about 2,000 hours a month, a year.
That's the same as one person working full-time for a year.
It's also the same as three people working for four months.
That's all the same amount of work.
Now any technological evolution is going to have one or two effects.
It's either going to give us less work to do,
meaning like it reduces the overall amount of labor involved in a task
or it's going to speed things up,
meaning we can get things done faster.
Or it's going to do both.
And both of these are problematic for architecture.
So under scenario one, where it just reduces the overall work,
we've got a problem because there's just not as much work to do.
Technology has taken something that used to take a week and now it takes an hour.
So we got to find something for that person to do with the rest of their week.
Scenario two, things moving faster, can also be problematic,
almost certainly will be, because as you start to speed things up,
you end up with these holes in the project cycle.
So what do you do with that time?
The most likely scenario in my opinion is that it's actually both,
that it speeds things up but also reduces the overall amount of labor involved.
So yeah, we got problems.
This is potentially disastrous.
Myth number two, AI will automate the tasks we don't like,
leaving us more time to design.
I've heard this everywhere in kind of every article and position point on AI.
There's somehow this belief that once AI automates away all the shop drawings
and red light and CAD drawings and all this shit,
we can just spend all of our time designing.
It's a very attractive idea because we love design.
That's what we were trained for and that's what we went to school for.
I like designing, but I don't think that this is possible
because it's actually constructed on top of several other myths.
If this is the idea that we're going to have huge amounts of time to spend in design
now that construction documents and all the rest have been sped up,
I think the problem there is we don't necessarily choose where technology is going to have an impact.
So the presumption behind that idea of having more and more design time
is that AI is going to have a huge impact here on the stuff that we don't like to do
and then none here and technology does never really work that way.
Once the technology like cell phones or electricity or computers penetrates,
it becomes a de facto expectation.
So if you're a photographer and you don't want to use Photoshop, you don't have to.
It's not like the law, but you're going to have a real problem coexisting
in a competitive economy with photographers that do.
So we don't necessarily just get to decide where technology applies, generally speaking.
I think there's also something about the law of diminishing returns
and I think mature designers get to a point where they realize that
designs get to a point where they're 95, 96% of perfect
and we have that drive within us to get them to 100% and we know that we can.
But the closer you are to design perfection, if such a thing exists,
the harder it is to resolve those last little bits
without going back and reinventing everything that you just did.
I think clients also understand this, which is why they put a deadline on you.
Professors understand it.
That's why you have final review because if those deadlines didn't exist,
we would just keep working forever.
So if you imagine this graphically, you say,
okay, there's a design that it's 95% perfect
and I'm going to work asymptotically to get it towards that final product.
This has financial implications for whoever's paying the bill for your design time.
At first, it's a loss because the design adaptations, whatever it is,
have not been fully resolved.
You need time to think through that and to think through,
okay, how do I get from 95% to 100% perfect design?
Idealized design and everybody's fine.
So someone is taking a loss on that particular time.
As those choices start to mature, assuming that you are a brilliant designer,
which I'm sure you are, the payout becomes really high.
Like the marginal payout for every additional unit,
day, week, month of design time climbs rapidly
because you're resolving the things that weren't resolved in the 95% scenario.
But the closer you get to perfection,
the more those gains start to diminish.
That's in the nature of diminishing returns of asymptotic growth
and all these other things.
So that's why it seems like for a lot of clients,
95% is good enough.
They're not interested in paying for you to get to 100%.
Exceptions exist, obviously,
but for a lot of clients, good enough is good enough.
Because fundamentally when we're working like this,
different kinds of changes have different value through time.
So I think the most convincing micro myth under this myth
is what I call the creativity surplus.
And I'm sure everybody has seen some version of this cartoon at some point.
The architect starts out with some brilliant vision,
hugely aspirational about what to do with the design,
gets a little knocked down with the meeting with the client,
and then you go through all the working drawings and budget revisions
and value engineering and pretty soon the building is kind of ordinary.
So I think from a standpoint of value analysis,
if we can't get clients to pay us for all the creativity that we have now,
why would we suspect that they're going to pay us for more of it?
So this idea that this technological advance
will lead to this explosion in design activity and design time,
unless you're working for yourself, I don't see it being true.
Like someone is still going to have to pay you for all of that time.
So myth number three.
AI won't place architects because architects are too smart
or creative or charming, attractive.
Take your pick.
I've seen lots of ideas like this.
I think that's probably true.
And I think it's a red herring argument that people are making sometimes where they say,
AI will not get to the level of human.
The reality that we need to understand is that AI does not need to get to human level
in order to displace humans,
because that's not how people make purchasing decisions.
Everybody has had some cheapo client at some point.
And everybody has had a dream client at some point.
And we can borrow a concept from economics called Indifference Curve to map this out.
This is not exactly how an Indifference Curve is supposed to be used,
but we're using it as a proxy.
So how do we exchange things between good architecture and cheap architecture?
Like how do people assess that balance?
Well, you can map that with a curve.
And the easiest way to understand it is through a slope, through rise and run, just like a stair.
So what this is visualizing is a client who is willing to reduce the quality of design by 50%
if the cost is reduced by 40%.
Not great, not terrible.
Probably a middle of the road client or something like that.
The second client is a lot worse, right?
Because this is a client that will reduce quality design by 50% for a 10% drop in cost.
So I've certainly had clients like that.
Maybe some other people have too.
But these are the clients who don't really care about design.
Good enough is good enough.
They're just willing to pass over everything if it saves a few bucks.
And that's tragic, and I know that a lot of architects live with that frustration on a daily basis.
So how does this play out in terms of the competition between human architects and generative design?
Well, we can also map this over time.
So if we assume that human is the standard, that's 100%.
That is the talent and capability and vision of a human architect.
And we've got generative design, either with human assistance or without, that's rising.
And we commit to the idea that it will never get there, right?
It will never reach human capability.
No matter how much time we give it, it's just going to be 90% of what an architect can be.
We're here.
We're living in the yellow zone where capabilities of this technology is rising very quickly.
But at the same time, we know that it's just never going to get there.
Okay, fine.
How does that compare to costs?
Well, the costs of a human architect, human design is going up steadily, as you expect it would with inflation.
Hopefully, you know, raised once in a while.
The cost of generative AI is dropping precipitously.
And has been for decades and will likely continue to do so.
So when you take the ratio of cost to, you know, whatever that design quality is,
and these numbers are arbitrary, understand like you can substitute your own numbers if you really want to,
but the effect will be the same.
You get cost over quality of human architect kind of rising steadily because, you know,
the quality is what it is.
That's the standard.
And costs are rising, you know, slow rate inflation, something like that.
But the cost over quality of AI is dropping.
So the quality is getting better and the cost is coming down,
which creates this very, very sharp curve towards the bottom.
And that creates a whole different set of problems for architects because all of a sudden,
you're not choosing between these two cheap oak lines.
You've got a different dynamic.
Now you've got a position where a client can reduce the quality of design by 10%
and achieve a 50% reduction in cost.
And that becomes a lot more seductive than I think potentially disastrous because
we don't want to design this 90%, right?
We want like the best design to be out there in the world.
But as you make it more and more attractive by hacking the cost 50%, 80%, 90%,
I think it's going to seduce a lot of people.
All right.
Myth number four.
AI won't be a threat in the future because of something it can't do now.
We've heard a lot of this, too.
So from Kermit Baker, the chief economist of the AI,
AI can't pour concrete, paint a wall, or install flooring.
Momentarily setting aside the fact that it actually can pour concrete and paint a wall
and install flooring.
It does all those things today.
So we can think about this whole thing a little bit more abstractly in terms of what
AI is going to do in the future.
So AI is growing exponentially.
What that means, what rates, we don't know.
It's not necessary for this illustration, but you've got AI growing at an exponential
rate in terms of its learning, its capability, everything that it can do, et cetera.
AI can't just grow at a linear rate, which is probably not a big deal if you're over
50.
So if you're an architect and you're pretty senior, it probably fuels that speculation
that you have that AI can't actually compete with your knowledge and skills because it
can't.
Like not now, probably not ever because you're going to retire prior to the point where AI
ever gets to that level.
So the skills that you have after 40, 50 years of practice remain valuable today and will
probably remain valuable for the next couple of years or 10 years or something like that.
And that's probably why older architects seem to be a lot less concerned about all of this
AI business.
But the picture is different for senior architects.
So someone with 10, 15, 20 years of experience, they're going to have their growth cut off
at some point by this red wall of AI growth.
And AI will grow to the point where it assumes the capabilities that senior architect actually
has.
That senior architect never really gets a chance to ascend to the level of professional maturity
and skill set that the principal architect did because their progress is essentially cut
off.
Much bigger problem for recent grad because someone who's graduating architecture school
today has to look at the possibility that as they're out there and they're trying to
build their skills and their capabilities, they're cut off.
They've got a few years of profession, maybe 10 before the capabilities of AI exceed their
own capabilities.
So they'll never get to that skill level that the prior generations have because by the
time they do, AI will be better than they are at the task of architecture.
And it's hugely problematic if you're a child.
If you're a 16-year-old and you're thinking about going into architecture, you're not going
to get there for at least another six, seven, eight years.
You're not going to be licensed for another 10, 12, or 15 years.
And by that time, you've come in underneath the growth curve of AI.
So all this discussion about what AI can do today as a measure about what it can do tomorrow,
I think, is a false profit.
We need to be looking at the growth rates of AI and understand what it's going to be able
to do in the future.
And anytime you hear an argument, I think, well, AI is not going to be a threat in the
future because it can't do this thing right now.
I would just set it aside because it's relatively nonsense.
All right, final myth.
We'll just do more projects.
This is also mythological because it violates basic laws of supply and demand.
And I'm going to illustrate this with golf clubs because I think golf is an urban crime.
I don't play golf, by the way.
Apologies to anybody who does.
So let's imagine a golf club market and you have three suppliers, right?
And they all produce about 20 golf club sets per quarter.
This creates an overall industry supply of 60 golf clubs, golf club sets per quarter.
And the demand is also 60 golf club sets.
Perfect supply and demand like in balance, right?
Now, what happens when supplier B comes upon a technology that allows them to triple their production of golf clubs?
They're producing 60 a quarter while the overall supply goes to 100.
But then what happens to the demand?
Does it also swell to meet that supply?
No.
I mean, very rarely with very specific things does demand rise to meet supply.
That almost never happens.
One scenario is that supplier B puts their competition out of business and just gobbles up all of the work as may happen in architecture as, you know, big technologically advanced firms adopt this new technology faster and just decide to, you know, take over everybody else's business.
I think the more likely scenario is that all of this extra golf club sets go in the trash, right?
Because there is no market to actually absorb what they're doing.
This is the key thing.
Demand is fixed just because you produce three times as many golf club sets doesn't mean that, you know, people are going to go out and buy three times as many golf club sets because how many do you need?
Like people are not going to spontaneously start playing golf because you produced all these extra golf sets.
And I think that's the problem with a lot of this thinking around design is that, you know, just because we can do the design a lot faster and produce more of it doesn't mean that people want more of it.
The demand for design services is fundamentally driven by the demand for buildings.
The demand for buildings is driven by all these things, but it's also related to the money supply.
So the money supply and the demand for buildings combine to create the demand for design services.
And this has no relationship to anything that's going on within the AC world, the software we use, how fast it is, like whatever dynamo scripts you've written.
None of that influences demand at all.
And maybe in some very, very peripheral ways.
But the point is that, you know, our work as designers as architects is trapped between like the money supply, the money that coming in, the demand for buildings on the demand side.
And, you know, what we do inside doesn't fundamentally change either of those things.
So, if you produce 10 times as many coffee makers, it doesn't mean people need 10 times as many coffee makers.
If we could produce 10 times as much design doesn't mean people need 10 times as many buildings.
And that is the fundamental constraint that I'm most worried about is people think, oh, well, we're just going to do, you know, more and more work.
We can't there's not a demand.
There's no way to sort of justify all of that extra work.
So let's wrap this up by looking at the brighter side of disaster. I love teaching disaster because I think disaster is fundamentally optimistic.
And we have thousands of years of history to prove it.
Ever since our ancestors started utilizing floods on the Nile River Delta to kickstart the policy and, you know, invent civilization, humanities has really productive relationship with disaster.
Lisbon 1755 suffered earthquake tsunami and a city-wide fire at the same time.
They all kind of caused each other one earthquake caused the rest of it.
But anyway, very, very tenuous time, you know, the seeds of the enlightenment were there.
But it happened on all scenes day.
So a lot of the very religious people in Portugal were saying to themselves, oh my God, we didn't pray enough and that's why this is happening.
Let's, you know, return to religious fundamentalism and all this stuff.
And the course of history was changed by the Marquis de Pombo, who basically drove the response to this particular earthquake.
Now the earthquake, fire, etc. already had become well known throughout Europe.
It had influenced a lot of thinkers because it provoked a question, you know, this horrible, horrible trifecta of disaster happens on all Saints Day.
Does that mean that there is a God or does that mean that there is no God?
And like, what should we actually be doing about this condition?
So Marquis de Pombo leaned in the enlightenment direction and we should thank him for it.
So he developed early approaches to seismology and horses, riders on horses go out in radial directions and interview people about the length of the shaking and what happened and everything like that.
So when he first established an epicenter, he created the Pombo lean style or had it created, which we still use today in many parts of the world.
So I've ever seen this kind of construction like that really became popularized after this this Lisbon earthquake at the direction of the Marquis.
Generally speaking, kind of jumpstarted the enlightenment, right? I mean, this was a huge historical event told us like when an act of God happens, we can respond with design, you know, we can actually design that particular disaster away and protect ourselves in the future.
And nowhere has this ever been more evident than the citywide fire. And it's an old memory.
But we used to have those all the time, right? Cities which is burned to the ground.
And that was it. London, of course, in 1666, Chicago in 1871, Baltimore, 1904, San Francisco in 1906.
And now it's inconceivable that anything like that would ever happen. It's tough to even imagine how that might happen.
So what changed? The Triangle Shirt Waste Company fire in 1911 was a horrible fire and a tragedy that inspired a public outcry, which in turn sponsored provoked legislation about, you know, new building codes, new ways to design buildings.
So fire sprinklers, emergency exit doors, having alleys, you know, this sort of thing.
And, you know, I love telling this story because, you know, it's an example to me of the way that urban planners and architects and engineers quite literally designed a disaster out of existence.
And, you know, our cities exist today because we adapted to that particular disaster.
I've said that disaster is fundamentally optimistic because it is because we have a chance of deciding what to do.
So, you know, is the future of our detection AI apocalypse, I think it just depends on what we design.
So apologies for running a bit long, but thank you to everyone and especially to my hosts and love to start a discussion.
Eric that was that was that was fabulous.
Really fabulous and don't apologize for taking so long was it was.
I think what I mean some of those are some of those notions I've kind of had before but I've never been a systematic in investigating them through the lens of, you know, much more kind of like a structured analysis.
And I think it was it was really very, very instructive.
I just there are a number of things that come up and I think that what I think what it points towards I mean, the emphasis seems the background concern was the issue of cost that seems to be the driver in many ways, or the primary concern, certainly as far as the client
concern is concerned and it kind of in some senses echoed the Susskin's work on what's going to happen in the future in terms of the professions and the primary driver of change is going to be economics people just want to get cheaper and cheaper and cheaper.
And that is always kind of in a way.
I think there is a background condition that makes us as a profession architects very vulnerable.
And that is the lack of concern about cost I wrote a long time back a book called the anesthetics of architecture, which is about how we tend to see things through a rose tinted lens and just see them in terms of their beauty.
And that rinses out often concerns about socio economic political environmental disasters or whatever it just rinses that out.
And we just look at it.
And I mean, whatever. I mean, you could think about, you know, looking out over the Pacific Ocean and seeing this kind of pink mushroom cloud, which is clearly a kind of nuclear explosion, the French testing out there and their nuclear weapons over a bikini atoll or whatever.
And look at it and say, Wow, what a beautiful pink mushroom cloud kind of thing. And that is I think that is kind of endemic with the problem in some senses of architects.
We see things and say, Wow, isn't it beautiful? And the client was kind of thinking things about how much the cost of the classic kind of issue is you come up with a design and they might share at Cambridge would come up with this argument.
And he said, the client would say, but you know, but how much does it cost it? Don't worry about that. You know, if you get this, you'll get a beautiful building.
And the problem is that is really the issue. The aestheticization runs through the architectural culture. And I think it also affects architects themselves in the sense that we are so happy doing beautiful designs.
We don't worry too much about our own pay. In fact, we've got no say over that ready. There's nothing to to effectively protect fees, nothing at all.
And so that becomes the kind of the crucial issue. And I think you're absolutely right in in pinpointing or at least it seems to me the back the core of your argument was really about economics, about cost, supply and demand.
I totally agree with the with your your golf golf clubs kind of analogy. There are no they're going to they're going to be no more buildings required. So don't assume that you're going to be employed more in the future.
Maybe I just put that comment in there if you want to.
Yeah, I mean, I agree. I would refine it a little bit. And I'll tell you a story. You know, I practiced architecture for five years commercially before going to graduate school and I went to do my master's in architecture and an MBA.
And of course, as a young architect, you know, we were always talking about cost because, you know, clients were always beating us over the head like, you know, this cost too much, this cost too much.
And, you know, I, I adopted that common sentiment among architects that, you know, architects care about, you know, the building the design and, you know, clients care about the cost.
And then, you know, I went to business school and, you know, it's just kind of like rapid rapid fire, you know, doing case studies or anything like that and no one ever talked about cost.
And I was like, what the fuck is going on because I thought, you know, I would go to business school and like, we would just be talking about this.
And I think that's where I developed my sensibilities about value, you know, value being the difference between what something is worth and what something costs in there.
And, you know, we make decisions about what we buy based on the differential, right, you know, the relative value of two things.
So when you go out to buy shoes, you know, you don't buy like the best pair of shoes that's ever been invented, you don't buy like the least expensive shoes that's ever been invented, you look at that.
And I think that to what you said about the sort of viewpoint difference between architects and their clients, that gets amplified because, you know, from an architect's perspective, the cost is immaterial because they're not paying for it.
The worth of the building is very much tied up in its aesthetics. So, you know, we want it to be beautiful to us because that is good for us.
But the worth and cost equations are completely different for the client. One, they're paying the cost.
You know, the worth is, it encompasses things other than just aesthetics, you know, I mean, there's rental payments from tenants, you know, there's tax, like, you know, I mean, there's all sorts of other things going on.
But I think that, you know, you're absolutely right. And thank you for bringing up Susskin too. You know, they've been hugely influential in my work as well.
Because, you know, fundamentally, you know, you may love architecture, you may be the best architect in the world, but when alternative technologies create a solution that is 90% is good, but 10% of the cost, like that, that's all she wrote.
I mean, like 99% of clients are just going to flock over there, and you would do the same thing, you know.
Yeah, I would just add to that, that I think that the questions of aesthetics, we assume that everyone shares our aesthetic. We assume that, but actually, they don't. I mean, I don't know.
I've got a relative who, I had a pair of Nike yellow shoes, and I went into the Sahar's office and Patrick said, where did you get those? I want a pair of those.
And I got some flak when I went to one of my relatives' homes. What are you wearing yellow shoes for? You're not a teenager anymore, kind of like, you know.
So, you know, I think this is something that is, and it's actually, in some senses, so we assume everyone's going to share that aesthetic, and they, you know, I think I would say that post-modernism has meant that we're kind of more aware of appearances and so on, I would say.
But on the whole, no one actually quite shares that same aesthetic. And to my mind, this was the tragedy of the Bauhaus in some senses. They thought they would transform society, give the modern citizen what they wanted.
But the problem was, it was expensive. You know, it was, you know, if you go to the Bauhaus now in Dessau, you'll see all these beautiful, kind of, whatever they are, designer objects.
Or you find them anywhere. You find them in museums, shops all over the world, and fine, if you've got the money to pay for your start lemon squeezer or whatever, but actually, you know, it's actually expensive.
Whereas Ikea, and I think there's a lot of lessons for us from Ikea, they produced something that actually did what Adolf Loos claimed he wanted to do by reducing the ornament you save on costs and produce something that is much cheaper.
But of course, there are other kind of smart factors they introduced, I mean, flatbacking things, allowing you to assemble themselves and all that.
But this means that Ikea is now populating the living rooms of many, many people, but not because of the aesthetic, because of the fact that it's going to be cheaper and that's the best way to do it.
So you do actually, and maybe you do begin to influence people's taste and they say, well, quite like Ikea or whatever, but you do it through a fundamentally different mechanism.
I think that is absolutely central to how we operate. So I really appreciate that. And as the layered way that you address the question about cost itself.
Let me just say, if anyone's got any questions, please put them in.
So we've got a YouTube audience, we've got a Zoom audience, the YouTube ones that you put in there into the chat and we can relay them here.
I wanted to pick up on something which I thought was, I mean, maybe as a way of kind of not just my work, but maybe something you could add into the mix and that is to say there was a recent study that was done by essentially a group of
sociologists from Harvard, MIT, and the guy called Ethan Molek, who is from, I think, UPenn, was also part, he's an AI expert, I think he's at the business school there at UPenn.
Anyway, they did a study on a consulting group, Boston Consulting Group, and what they were doing was attempting to measure, now we don't know how to measure these things, but sociologists do, to measure the impact of using AI.
And they were able to come up with some result, they were able to quantify it in some way. And I think this is probably the first of many, many studies, I'm sure there will be a lot of them.
And of course they weren't necessarily dealing with the design as such, although that was vaguely included in their study because they asked this group to suggest a new line of footwear,
responding in some way to whatever, dot, dot, dot, another line. And so it was kind of creativity in very loosely was part of that thing. They were using chat GPT to study this thing.
But what they came up with, which I think was really, really interesting, was a series of quite significant factors. And there is this very crude graph that Ethan Molek has published online.
The whole thing was published as part of a Harvard Business School journal, but he made his own graph and so on, which puts it very graphically right up.
And what they found basically, in the study, using AI, it was a group using control group, using AI versus a control group, not using AI. And those that were using AI finished 12.2% more tasks, so they achieved more.
What's more, they completed those tasks at 25.1% quicker. Now, I guess you've got to multiply those to get the real impact. You're doing more tasks and you're doing them quicker. So the overall impact is actually more significant than that.
And they also came up with the figure, which I think is difficult to evaluate, that it was 40% better quality. Now, that's anyway, you put those together, those three factors are quite significant.
And as you say, it's a question really ultimately the task. And to something that I do, I mean, that is a factor in the sense that there aren't those differences between certain tasks and others.
For example, your comparison must be the task and the job itself or the profession. I think that renderers are in a lot of trouble right now. There are a number of tools out there you put in a sketch.
Famously, Tim Foo was using Look X and he put in a crumpled piece of paper and looked at it and produced a Gehry building versus Zaha building, or Moses building, based on that.
And each one was, and you can do that now. So I think certain, clearly there is a differential in there, one has to take that into account.
But very, very significant, and it will be interesting to find out what that figure was. I once was talking about this with one of the developers, AI Socra, I won't mention her name, but she once said, and she wanted to attract it, that some person using AI could achieve as much as five, not using AI.
And it's a little bit of a, and she was worried about that information getting out there because it might put off people from using AI. But nonetheless, there is a significant difference in what you can do.
So I don't think the quality necessarily is going to be that important in terms of aesthetic, shall we say. Although, I mean, I think that you can judge quality in other terms, and I think these are really hugely significant factors, and we need to do a study, I think, in architecture for that.
Let it go.
I mean, okay.
Any, any, any cops? I've got a few more points. We'll open up. We've got some questions coming in from that from YouTube as well. So, but, yeah.
So, anyway, I think there's, there's, there's the concern that's kind of connected in some way to, to, to, to all those issues. The one thing that I think that I would question about your approach and, and, and, and, well, I don't mean critical, but I think one,
maybe a suggestion. And you mentioned the law of diminishing returns and that was Kurtzweils, what he followed. And a lot of people are following on from Moore's law.
Now, for those of you don't know Moore's law, Gordon Moore was an industrialist who was made a comment. It wasn't a law as such, but made a comment back in the 60s on observation, shall we say that in terms of circuit boards,
the number of conductors, the transistors on the circuit board would double every two years and the price would come down by half, which meant that this was exponential change.
So if it's, if it's that factor, you would be instead of going one, two, three, four, five, you'd go one, two, four, eight, 16, and there's a huge difference between five and 16.
And that has been applied more recently to these large language models. Now, I want to mention this again in a second because I think these are absolutely hugely significant.
Sundar Pishai, the CEO of Google, made the comment that these large language models are are increasing in their capabilities, going faster than Moore's law. And that was the comment he made.
I don't think that Moore's law is relevant in this context because it's tying it to some kind of production and a kind of economics.
Now, the key question when it comes to capabilities is, in my view, anyway, the speed of learning, the speed of learning.
Now, this is something that Jeffrey Hinton comments on. And Jeffrey Hinton is known largely as the Godfather of AI. Certainly he was the one who was promoting, who was working on neural networks and what we call now deep learning at a time when that approach was out of favor.
It wasn't working. Everyone abandoned it in favor of a different logic, symbolic AI based on logic and so on. But really all it required was that was a change in terms of the technology.
And as soon as we got GPUs invented and suddenly the capabilities of computers was and the speed of computers was vastly, vastly increased and these neural networks worked.
Okay, so that's a background to him. But he has made the comment recently and he's been in the news because he resigned from Google in order to sound a warning.
And his warning basically or part of his warning was the speed at which AI, which computers could learn. Because the way that it works, he said that I need to look into this further, is that it shares information with a thousand other computers at once.
And I don't know why he's mentioned a thousand, not a million, whatever, but it shares information with a thousand computers at once. Whereas if I'm sharing information with you, it's a one on one.
But a thousand, a thousand to a thousand others. Now, that somehow reminds you of COVID in some senses. If you share COVID, with the key issue was the what they call the R-Ratio.
If it was more than one, be worried. If it was less than one, you're kind of okay because the spread is going down, whatever.
Now, we never had an R-Ratio of a thousand. Now, I'm not even sure if that figure is correct. But this is the real problem. It is the capabilities of these large language models that is exploding.
And it's exploding at a rate that we cannot even conceive. Maybe I'll just throw that out to you, Eric, and see what's going on.
Sure. Let me react to a few things. First, the diminishing returns diagram and the thread there. That's not actually, that's irrespective of AI or no AI.
You know, the diminishing returns is just an economic phenomena that exists either way. So that's separate. The Moore's law thing, yes. And we need to get the word out about that because I think there's still people who think that Moore's law is relevant.
It's not, things are moving much, much faster than that. I mean, Kurzweil puts it at a double exponential or triple exponential. I mean, these are growth rates that are very hard for people to understand, like, intuitively.
And I don't mean like people other than me. I mean, I have a hard time, like the human brain has a hard time. Here's a benchmark that I always use.
Stanford's whatever annual AI survey that they do.
They put the doubling of artificial intelligence capability, rolling in, you know, algorithmic development, advances in cloud computing, like all the things like the raw capability of AI, doubling every four and a half months.
Now, something's doubling every four and a half months. That's a million X in seven years.
So when people say, hey, you know, AI is like, there's nothing to be afraid of insulting that AI could actually like, you know, ape the performance of a human designer.
I agree. I'm like, yeah, you know, at this point, but do I believe that an AI that's a million times more powerful than what we have today might be capable of designing a building?
Yes. Yes, I do. And I'm very, very concerned about it.
So, yeah, I mean, I think that, well, you just deconstructed another myth, Neil, you know, this myth around Moore's law.
I think we have a responsibility to kind of get the word out that some of this, some of these Pollyanna's positions are based on, you know, data and ideas that are actually outdated.
So maybe I could just throw that back at you. I mean, I love that video, the 24 minute video, but it struck me that it doesn't have to be 24 minutes.
And I base this on, I mean, it's what you're doing basically is you're recording a conversation and which and you're showing it between these AI agents and
there. But the 24 minutes space is basically taken up in showing them talking to one another, whereas actually the speed of the operations could be pretty instantaneous.
Now, I was alarmed by what we now know as large language models and the speed of operations.
Several years ago, in the world of AI, one of the great moments, when we kind of a wake up call it was called a Sputnik moment.
When Sputnik basically was a wake up call for the American, the merit is in the space race and let the foundation of NASA.
I mean, holy shit, the Soviets were suddenly sending a satellite to orbit and America was nowhere near that.
And that was a wake up call. So in terms of your kind of like there's something good that comes out of it, well, NASA came out of that particular moment.
Anyway, this particular game, it was, and we were not, it wasn't really on our radar because it was a game of go, a match of go.
And we don't really play go, but they do in Asia. And there was this match AlphaGo developed by DeepMind of London versus Lisa Doll who was kind of this followed on from the Gary Kasparov chess match.
And he was the kind of Gary Kasparov, shall we say, of go and AI trounced him. And that was the wake up call for all go playing nations.
And the Chinese immediate president, she said, okay, by 2030, we are going to catch up with the Americans and overtake them and so on and so on.
So that was kind of like a hugely sort of significant moment in sort of in wake up.
But the more important one was something that wasn't really mentioned at all, which was a follow up.
This was the next model of AlphaGo, which is AlphaGo zero.
But first of all, it wasn't documented, it wasn't on TV and whatever, but it was, it went out on our radar.
But that one, it beat AlphaGo 100 games to zero.
But the important thing was it learns to do things without being trained to do so.
It was not taught the rules of go. And this talks about the emerging capabilities, which we should come back to in a moment.
But the other aspect of how it learns, it was playing games of go against itself.
And I think the total was 4.9 million over four over three days.
And that sounds like a lot. That sounds like a lot.
But the real point is, it is a lot. I mean, you go down to it, you know, it basically it's 20 games of go per second.
But that is very, very significant. It is weak. It's mind boggling me fast.
And I would say, I don't know why it took so long, frankly.
I mean, how could you even take, you know, that much.
So my point would be that that video is the actual calculations were pretty instantaneous.
And it wasn't 24 minutes of calculations.
I mean, that was what it took to show the operations happening in terms of discourse.
But the calculations were pretty instantaneous.
And that really is anyway, that was one of my comment on the video, which I thought was a fabulous video anyway.
No, I mean, I think you're right. I mean, it's, you know, there's something evolutionary about it.
Right. You know, we just we have trouble, the human brain has trouble like kind of wrapping our heads around, you know, exponentials and these sorts of things.
So, you know, we got to support each other and like check each other and say like, yeah, that whole 24 minute video could have been under a second, you know, if it was just two AIs, you know, talking to each other and designing a building or something like that.
In my own writing, I refer to this as the million monkey problem, right, where we've all heard that adage about, you know, if a million monkeys were banging on a million typewriters for a million years, would they at some point write, handle it.
And, you know, maybe you think yes, maybe you think no, but a billion monkeys working on a billion typewriters for a billion or a trillion.
You know, those are the scales that that we're into now.
So, yeah, I think, I think we need to be very, very concerned and it's interesting that you brought up the, the Go match because that was one of my initial inspirations getting started on this project because, you know, there were, there are architects in the ether who were saying,
no, like, you can't compete with architecture architecture is like too complicated.
And like, you know, AI is like beating world champions ago.
It's doing protein folding, you know, it's solving all these like cancer research problems and, you know, architecture, plenty, plenty complicated, but I'm not sure that it's more complicated than everything, you know, like it's not like the last thing that that AI is going to figure out.
So, yeah, yeah, we got a big job.
Yeah, no, so one more point for me and then we'll open up to the other questions from the audience, but you know, I absolutely totally agree.
Also, you're picking up on what are called emerging capabilities or and made urgent abilities.
I think these are things that are hugely significant.
And I was, I was intrigued by what you discovered in terms of what AI had learned how to do, you know.
So just to say for those who don't know, I mean, I'm not insured that the term emergence is intended to be taken the way that I've taken it but I, in my work years ago on swarm intelligence and I came across the term emergence which is about that Steve,
John Holland, initially kind of written about it as a kind of principle whereby things start emerging out of any multi system that are unpredictable and not expected.
And classically, you think about a flock of birds and the way that it produces this area or acrobatics, but it's also been taken more recently to apply these to these mysterious abilities that go back to that alpha go zero, it taught itself to play go.
And, you know, that the right that that was when the alarm bells should have been sounding because now we're discovering through these large language models is developing similar capacitive capabilities.
It can learn languages and translate.
That is pretty astonishing.
It does it.
It does it actually.
I mean, emergency stuff is kind of a rather mysterious thing and we can observe it.
We can't really explain it scientifically yet.
But nonetheless, we can see this thing happening.
Now it can learn to translate and it can learn to write code.
That's that's very, that's huge.
Yeah.
So I got a friend from college who was who used to run the biggest translation agency in the world and he sold his company two years ago because he could see that I was going to be able to do it.
And I've been exploring that myself in terms of the translation of some of my books and it's incredibly cheap, very fast, even with a human editor to come in and go and check all the things and so on.
There's, there's, there's that but I mean, it's so it has this capacity to do these things and I claim that it's very imperfect moment.
I would claim though that there are moments in which it has learned how to design.
It seems to have learned that the rules of composition in the sense of mid-journey and Dali, particularly mid-journey, it's coming up with some pretty impressive designs, not everyone.
I mean, about, you know, only one in about 50 is really good.
But nonetheless, it is surprising that it's doing those things.
And you could only assume there are a lot of other things that we don't know what it's doing, but it's doing, you know, it's, it's, it's looking at the data and understanding systems and putting them together.
I actually put this question to, to when you heard yesterday, I said, well, what about, I mean, could it not also learn how you do the plumbing or how you do, you know, other aspects of architectural design.
And she was saying, well, the difficulties, the three dimensions, that's when errors start creeping in.
And it's, it's fine with language.
I mean, language, it doesn't matter too much of your slightly out.
There's a lot of tolerance there.
But with architectural drawings and things, that is the challenge.
It's not there yet.
But I do think, I do think that these emerging capabilities are, I mean, they're fascinating.
And they don't sound particularly interesting, not indeed to large language models, but they are extraordinary.
And just one final point for the audiences, the large language models, they, they get these abilities, not through the sophistication of the code, because the code is quite straightforward.
It's based on the size of these things and the larger they get, the more they seem to manifest these things.
So I was just intrigued.
Maybe you decide to comment just briefly again on, on what you discovered it was able to do, but you would never predict it.
Yeah, you want to hear the wildest?
Yeah, yeah, yeah.
I mean, the windows and the bathrooms and the constant, like that, that surprised me, you know, that I was able to kind of get all of that right.
The biggest thing that I did not put in the presentation was that I did find that it had some kind of 3D spatial world building capability.
So after, you know, Carla had designed the house, you know, I drew it out, you know, I drew the floor plans as I would have drawn them based on, you know, what she was talking about and, you know, the local conditions and things like that.
And then I described it to chat GPT and said, you know, if I go into, you know, the front hallway and make a left and go up the stairs and make a right, what room am I in?
And it was like bedroom.
And it would get that right. So in the way that you might communicate it to an unsighted person or something like that, you know, I was able to kind of articulate directions like around the house and, you know, across like multiple floors and things like that.
And it would seemingly understand like where it was in some three dimensional mental model.
And I don't know if that's an artifact of just like the language. So, I mean, to us, you know, if I described to you a building like over the telephone and said, you know, these are the mentions of the building like you could sit down and draw it out and go vice versa.
So, you know, maybe it's not.
I don't know where it comes from. I haven't figured it out, but it's scary the shit out of me.
Yeah, yeah, I'm just just an aside. I want to go to some of the questions and yeah, yeah, let's do it in a moment. I want to ask Mitra, but just as an aside, I think the obvious point that needs to be reinforced.
Traditionally, we are the ones that interpret the verbal instructions of the client and produce an image, which is exactly what mid-journey and dali do.
And that's kind of worrying. I don't know. Mitra has got a question. I don't know if you're able to use your microphone and to read it out or if not, if you can, if you can unmute yourself or I can read it for you.
I don't know whether you, I don't know if you've got a microphone on your computer.
I can see you're still muted. Oh, did someone have to allow her to unmute themselves? Okay. Okay, Mitra.
Hello, hello everyone.
Hi.
Hi. Thank you so much for the great lecture.
And actually, I have a question about, and actually we have these days we are facing an increase in the use of the social networks.
The analysis of invisibility of the data and social network could be significant.
For example, in urban studies, we have the geolocation data, including the GPS or data about connection with local Wi-Fi equipment.
So my question is, would it be possible to collect data from social networks for architects? And where is the data stored?
Would it be possible to collect data from social networks for what, for design purposes?
Yeah.
I imagine that's much more of a social and legal problem than it is a technological one. You know, your social networks already know everything about where you are and what you're doing and how fast you're moving and what stores you visit and all those other things.
Because, you know, you signed off on a license agreement that allows them to have and use that data.
I think in order for architects and designers to use it at other scale, at any significant scale, we'd have to have a similar sort of arrangement.
I mean, the idea of a municipality collecting that data on its citizens for use by designers frightened me a little bit because they would almost certainly use it for other things.
But I've seen a use to brilliant effect actually in disaster zones.
After the Haiti 2010 earthquake, Port-au-Prince was a city of about two, three million people, sorry.
And once the earthquake struck, you know, it destroyed most of Port-au-Prince and, you know, people fanned outward, you know, from the city and then at varying rates started to come back as recovery progressed.
I did just sell the main phone carrier there actually had that data as a result of like, you know, having everybody's SIM card and a database.
So, you know, we could understand how quickly, you know, people were moving back and into what neighborhoods and this sort of thing.
So, I mean, from an urban and from a design perspective, that data is enormously useful.
I think we just have to make the case that we should have it as designers and that we can put it into good use.
Just to decide, Eric, the I think the one of your disasters, just maybe you didn't know this, but the the Great Fire of London.
Actually, it came off the Great Plague and it actually effectively got rid of the Great Plague.
So maybe you had two disasters on one counter to the other.
So we've got a number of questions from from YouTube.
And I think these are separate questions.
First is you can see them in the chat if you want to look at them from Mandu Tiger in YouTube.
Some excellent points, exclamation mark exclamation mark.
Unfortunately, another influencing factor for the long term is this rising level of indifference that is poisoning creativity and quality.
Two huge values architects provide.
Unfortunately, another influencing factor for the long term is this rising level of indifference that is poisoning creativity and quality.
Two huge values architects provide.
I would say, you know, Mandu Tiger, you're not wrong.
There's certainly a surplus of indifference in the world these days.
But I will reference my father and probably several debate coaches as well.
You know, always advise me never to argue a position that requires that that I believe or that you believe that my opponent is is somehow stupid or morally corrupt or ignorant or something like that.
Because it's an easy out right.
But architecture has nothing to do with architecture. It's all these other people and the fact that they don't care about this and they don't care about that.
That may be true. It just doesn't go anywhere.
I mean, it's kind of fatalistic for the profession.
If you think about it, because, you know, if you imagine that that architects are, you know, these passionate designers concerned with beauty and progress and, you know, everybody else is indifferent to such things that might be an architect.
You know, I mean, like, you need a world to pay fees to design things.
So, I mean, I think that, you know, when I'm confronted with questions like that, you know, I asked myself, well, how do you, how do you make indifferent people different?
Or, you know what I mean, making different people like actually care.
I think you have to find the ways to speak in their language and to speak to their priorities.
That's actually why I went to business school, you know, you know, I went to get an MBA and people thought I wanted to be a developer.
I didn't. I never have.
But it struck me as a good decision because I wanted to be able to defend our work in their language. Right. Because when I was a practicing architect, you know, the whole design team would come up with all these great ideas and everything and then, you know,
at some meeting somewhere, there's some like 30 year old with a clipboard and Excel spreadsheet and it's like, we're not doing this, we're not doing that.
And I started to ask myself, well, who's really designing this building, you know, and I didn't have the vocabulary or the skill set to actually argue with that person in their language.
So I went to business school to learn that.
So, Mandu, just to tie it off, I mean, I would suggest that you think about the people that you think are standing in opposition to design and ask yourself, like, how do I convince them that design is valuable in their language, you know, with their value system.
Great, great point, Eric. I think that just a comment from the UN studio discovered one of the successful ways of speaking to the cloud on their own language was to diagram things and they would be much more convinced by the diagrams than the designs themselves.
Yeah.
So we have a another question from the chat again great to get a lot of praise here for this talk, it was a fabulous talk.
Great talk and thank you I have a question but more of wanting to know more about your opinion. Do you think that there are safe havens against the AI and architecture disasters.
Are they physical places. Should we as architects look for a way to design to make a sound from what AI could do against the profession.
Yeah, yeah, is there a name attached to that.
No.
Well, to whomever asked that question.
I think that architects fundamentally need to be thinking about expansion. And I think that exists in the along several axes.
One is is a kind of domain expansion. I think there's a great opportunity to actually reclaim a lot of the territory that we seated during the 20th century to other professions and you know we had to spin off interiors and landscape architecture and construction management
owners reps and you know all these other things because shit got too complicated and we also just wanted to spend time designing.
And I think it's unfortunately eroded a lot of the authority of an architect in that overall design process.
So I think there's an opportunity there to call some of that back and to say like look with these augmented tools, like we can now do the construction management bit like we can do the interiors that you know we can do all these different things.
Now all those other professions are going to be saying the same thing. So we have to find a way to work that out.
But ultimately, you know we can expand in that direction from a domain standpoint.
I think geographic expansion is is another one.
Most of the architects in the world are in places where the least architects are needed the least.
You know, the global south is going to need something like I don't know like a billion units of housing in the next 25 years.
And there's not necessarily like the infrastructure there to support good design for for all of them. And I think you know maybe technology offers a route to that so that you know someone born in a slum in Lagos now has access to good design.
So does that mean how do you accomplish that without you know fully like techno enabled colonialist strategy. I'm not really sure.
But you know, through my work I know like most of the world really really needs design and they can't get it.
So, hopefully that is another axes of expansion. The third one I'll mention is is actually digital and metaversal, and I'm not a metaverse fanboy by any scrap of the imagination.
But I do believe that the metaverse is inevitable that it's coming sooner or later, and that once it does we're going to need a strategy to marry design strategies in the real world with the metaversal world.
So if you're designing for a client like Nike, you know they're going to have a metaversal store and they're going to have a regular store, and augmented reality and their physical store, they're going to want all that stuff to work together.
Right. So, how do architects start to think about digital experiences and how those complement, you know, physical spaces.
So, I mean, I think there's there's lots of that's just three there's probably some more but I think there's lots of ways that we can look at doing new things, we're doing old things or doing unprecedented things that haven't been invented yet.
The part that makes me worry the part makes me think that we might be in a disaster is architects looking at these sorts of technologies as ways to just do what we're already doing just faster and cheaper.
Like that's that's raised to the bottom like there's no good outcome there.
So, I think fundamentally, the safe place is everywhere except architecture, like, look out chart new territory explore new civilizations, design housing for the moon, like, you know, whatever it is, like you got to go out there and use this technology that we've never seen before to do things that we've never done before.
I was struck by your video.
Conversation should actually would be great to see the whole thing because it was so interesting, but it's out there anyway for those who want to see was actually effectively the architect became the construction manager there he was talking to the to the construction person which is quite unusual.
Normally this is very adversarial role and now increasingly in certainly in the UK, most contracts are designed built and the, and the developers in charge, you know, so we've surrendered that idea that we used to have of being the person that's what the word architect means literally from the ancient
Greek as Alberti reminded us the person in charge and we've surrendered that but we could do that and I all would also say we could also become the developer I think that's an area that is probably very very well paid that we could also take over.
Or indeed the person apparently selling the property gets the most money so we will go in terms of cost per hour. So another question here in the chat from ren right a rainville at on YouTube.
Do you have any suggestions on how firms should prepare for this oncoming disaster.
Yeah, I mean I think.
Well, building on what I said in my last response in terms of like looking outward to do to do new things and unprecedented things.
I think education is critically important at this point, you know, I mean, I, I advise everybody calls me like, do your own homework, you know, read, learn something and, you know, I think 90% of the architects read.
Like the same like 10 design magazines, like, you don't have to stop doing that but read some other things too.
You know, I think most of my perspectives are informed by things that are actually going on in the tech sector and like the AI sector and like that's where I get my Intel is like, you know, who's publishing new research on machine learning and you know liquid neural nets and and these sorts of things.
So that's how I personally keep an eye on on what's happening and develop a sense of the future that I can feel comfortable with that. You know, I feel like I understand what what might be coming.
I think, I don't know, not disparaging any sort of design media but you know design could be a very conservative profession, you know, and I think it's the sort of thing where, you know, we're radically adventurous in our work, right.
Within the four corners of the drafting board, I mean, metaphorically at this point, you know, we create whole new worlds and new civilizations and things like that.
But then then to be like conservative about process and environment and like the rest of the things so I think that it would be good to educate oneself and to do your homework and to figure out what is going on outside of architecture because that's where the real action is.
That's where the real action is at the moment and it's inducing a tidal wave that's going to, you know, hit architecture at some point.
In terms of, you know, other like more tactical preparation, I think that would probably depend on the specifics of, you know, a particular firm or a geography. So, should we go to part two, Neil?
Yeah, yeah.
Secondly, how best can architects direct the value conversation away from the client cost concern.
Yeah, I mean, I think the first step there is to figure out what your client values. And again, I mean, I think there's, there's an unfortunate, you know, mythology and architecture that thinks, oh, you know, the client only cares about cost.
I've had clients like that. I've had clients like that. But clients are people and people tend to be more complex.
You know, I think different clients value different things to varying degrees. So like, that's step one is knowing that.
The second part is, you know, don't bring a hammer to a gunfight. You know, I mean, if your client is someone who values like cost exclusively, then you need to find a way to make that argument for value in economic terms.
So if you want to redo the lobby and don't talk about why from an architectural standpoint, it's going to be better. Talk about like, how you can charge like higher rents or like the cost comes down or something like that.
You know, if you're working with a client that cares about some, you know, other social issue or political issue or something, you know, find out what that is and make arguments to people in their language.
I think that's one of the, and Neil alluded to it earlier. I think that's one of the biggest kind of universal mistakes that architects make. We try and convince people to follow like whatever suggestion we're making using the language of architects, instead of their language.
And it falls flat.
A lot of times.
Maybe I said, I don't want to, I'm talking too much, but I just add to that there was, there was occasion in Cambridge once, but there was a disaster.
Many years ago, when there was a competition and one of the colleges decided to forget the results of the competition and just go to a builder and they got this really very, very tedious building as a result.
But then they learned a different strategy. They discovered that actually, if you mentioned you had a big name architect like foster and partners, whatever, it was much easier to attract funding from alumni by saying we have got so and so.
And it became on their terms, it made sense. It became an economic argument to improve the design. So I very much agree with that.
So we have James McBennett on YouTube. And his question, which again is in the chat, most buildings are not designed by architects.
Demand of buildings or demand for buildings is far greater than demand for well designed buildings.
As the cost of design changes, surely blue ocean strategy in the middle.
Yeah, I would absolutely agree. I mean, I think that, you know, my humanitarian work was largely about bringing design to two communities and to people who otherwise would never have had access to it by virtue of geography or economics.
But as I think you're pointing out, James, like, that includes like, you know, most Europeans, most Americans, like, you know, architectural services cannot be provided at a cost point where, you know, it makes sense for someone who is, you know, got a $500,000 house budget to engage with an architect like that's just not going to happen.
But yeah, as the cost of design comes down, does it then become possible to provide design services at, you know, the same level of quality but at a lower cost point.
You know, I was teasing an architect the other day about creating a digital version of themselves, right, so they could actually like, you know, service service clients, you know, essentially at zero cost.
And this sort of thing and, you know, that technology still probably a few years away for, you know, sort of full package solution but, you know, it's a taco watch like all of the ingredients are currently there the technologies exist.
And they need to be assembled at some point in order to do that.
But I think, you know, I love, I love that idea. I love the idea of like everybody having an architect, everybody getting the benefit. And one of the things that that's fueled my career and the thing that makes me so mad is that, you know, architectures is like great
and it's like so many brilliant and creative people and, you know, it's offered almost exclusively to to the rich to the 1% you know and like, we can't we can't get it out there to everybody else.
And that's not because we suck. I mean it's just because like it's it's a lengthy and expensive process. So I hope that one of the things that, you know, architecture starts to embrace as these technologies unfold and design costs come down as
they give design to everybody. Yeah.
Actually, James has got a follow up question in chat by golf analogy. If 2% of buildings are designed by architects and 2% of golfers can afford a full set of clubs, would more golf golfers justify buying a full set of clubs if the cost dropped dramatically.
Interesting. I think what's implied by this question is that there are people running around out there with like two or three, like golf clubs but don't have like a full set.
So they go and play golf with like a couple of clubs and if the price of a set of clubs came down.
They might actually buy the full set. Is that how you read it new. Yes, absolutely. Yeah. Okay.
I don't play golf so maybe I'm like out of my depth here, but I don't think most people like play golf with just like a few loose clubs.
My understanding is that like, you need the full set in order to properly play a game of golf.
And if that's wrong someone in the chat, please correct me.
I mean, I think to James is kind of like wider point.
If the cost comes down to more people embrace it.
Sometimes yes for some goods. Yes.
You know, energy is the prototypical example right the more energy we make and the lower the cost the more people consume.
And there's some name for that that kind of exception to the laws of supply and demand. I think that
if the cost of design comes down, people may embrace it further.
And more people might be interested in utilizing the services of an architect.
I don't think the same necessarily applies to buildings.
Because like, you know, you've got a town of 3040,000 people and needs a hospital, right or at least like a regional medical center.
It doesn't need four of them, right. I mean, we have to have some kind of justification to make the buildings that that we make because they're expensive and they take a while and they're complicated.
So, yeah, like I could see like a minor expansion and just to plan James's previous points, you know, like homeowners might have the opportunity to, you know, the scale of a single family house for, you know, have a million dollars actually like work with an architect.
On the other hand, you know, that brings in the specter of like a custom designed house of some kind. I don't know how that's actually going to play out but James to your point. Yes.
I think that probably there will be a slight expansion of the market in design services, but it will be constrained by fundamentally by the limits of the building market.
There's another question in the chat with no name attached to it. I think that maybe the way we should think about architects within our ecosystem as a researcher.
What is our role? What is our role as architects in the loop of research along with computation and big data? Will it help? Sorry, it's not very clear.
Will it help us solve problems ahead? Let's read out what he said actually.
Yeah, I'm reading it.
What is the role of architects in the loop of research with computation? You think that means like the role of architects within the wider field of research on, you know, IT and data and computer science related issues?
I think so.
Well, I mean, I think, you know, architects have really amazing perspective and an amazing facility with certain skills that lend themselves very easily to research.
So, you know, the ability to zoom in and zoom out really quickly and think small scale and big scale and be fluent and fluid between those things.
Architects do that better than just about anybody I know. The ability to think about time, right? So architect is one of those professions where you have to like make a decision today that's like binding for 30 years.
And I think we lose sight of the fact that there are very few professions where that's true, you know, maybe medicine or law or engineering or something like that.
But for the most part, like, you know, you fuck up at your job, like you've got lots of time to fix it with architecture, like your issues, your decisions get set in concrete, literally.
So I think, you know, the mind of an architect lends itself very easily to that sort of thing.
I think it's about, you know, integrating with what's already going on. I mean, there's already a lot of research going on into these things. So the question is, like, what is the entry point for, you know, architects who want to be involved in that?
I think there's a lot of data issues around buildings and cities that we haven't quite figured out. We spoke about it earlier during the Q&A.
But I've had the conversation many times over the past year about data and architects thinking, oh, well, we got all this data like from the buildings and, you know, we can use that in some sort of data science way.
And, you know, my question is always like, you know, will it use it for what? Like, what data is going to be useful to anyone?
If you're talking about data about how people use the design that you made, that seems like it would be the owner's data and not yours.
So that's one problem. And if you're using the data from, you know, the designs that you made in the past might be good.
But unless you're like a Gensler or HOK or something or an AECOM, you probably don't have like enough projects there to actually build any sort of machine learning data set or anything like that.
So, you know, I think architects have a natural role based on their, you know, psychology and their disposition. But I'm not sure what that role is, and I think we'll have to design it.
There's another question from Vas Glashik Vasco on YouTube, who's in Bangladesh. You should know that you've got an audience all over the world today.
Awesome.
In AI driven architecture, how do you tackle worries about losing human centric values and cultural nuances, especially in post-disaster reconstruction where community identity is crucial?
Yeah, and I'm reading the follow up comment, which I agree with. I would argue that a lot of buildings have already lost a human centric value. It did not take AI, it was modernism and effects of industrialization, post-World War II prefab and building without ornament.
So, Ashik, I think that's a great question, Ren. I think that's a great answer and similar to the one that I would have offered.
Yeah, I mean, I think, you know, architecture loses human centric values all the time. And I think that's one of the reasons that a lot of people don't appreciate architecture because, you know, we spent 40 years making spectacle architecture and, you know, kind of turning our attention away from the problems that people were actually dealing with in their lives.
So, I mean, I think that, you know, how do you correct for that problem? How do you introduce human-centered thinking? You know, my advice is always, like, spend time with humans.
You know, we don't always appreciate, I don't think, just how insular architecture is as a profession and how weird that is.
You know, we take someone when they're 19 years old and we put them in studio and, frankly, a lot of architects never come out, you know, like, mentally, like they stay in studio for forever.
And, you know, they come out, graduate, they know how to walk like an architect, talk like an architect, they, you know, have cool glasses and wear black and this sort of thing.
But they don't necessarily, like, have human beings at the center of, like, whatever their design ambition is.
You know, in my work, like, it's impossible not to, you know, you can't go into a community of friendly, loving people who are having a hard time and say, like, okay, like, I'm just going to ignore all that.
I mean, not unless you're some kind of monster, I guess, but yeah, I mean, the point is, the point am I trying to make? I think I'm advising you, Ashek, to one, like, spend more time with people and, you know, to appreciate the fact that we don't have much human
to begin with. So maybe paradoxically, AI is the way that we find it. You know, I'm sure some of you have seen the same studies that I have where, you know, they measure the responsiveness of a human doctor and, you know, a medical chat GPT, like, what is it?
And, you know, the respondents, like, drastically prefer interacting with the robot because it's perceived as being, like, more caring and more attentive and it has, you know, infinite time and my doctor comes in to see me and, like, 30 seconds later, you know, he's gone, like, to do with another patient because our healthcare system is looking stupid like that.
But, you know, maybe this tool, like, retrieves some of our humanity by, you know, giving us time to be human and giving us time to sit with patients and to sit with clients and things like that. So, yeah, I don't know, that felt like a rambling response.
It's a tough question.
Rambling responses, Eric. Fabulous. I just made me to follow up on that in a way. I mean, I had, this last semester, I asked my, instead of asking my students to go and write essay, I got them to ask to do a video, but they went, I think, to chat GPT and got this.
I think, I think it's up, you're right, because in your article, you mentioned the fact that I think that chat, that chat GPT has been conditioned to respond in a certain way.
And if I mean, I always go back to chat GPT and say, what, do you really mean that? And it kind of is open. Well, not really. But I mean, so, so, but the, the, the, the kind of responses that seemed to they seem to be getting was feeding into their videos was, well, AI lacks the empathy.
It doesn't have the empathy of human beings.
Now, I'm not sure that empathy actually in design necessarily makes a better design. I'm not sure about that at all.
But what I would say is that that discussion you had in your video, and I really would recommend everybody to have a look at that discussion.
It was absolutely fabulous. They were much more polite than any human being was astonishing.
Yeah.
I mean, it's, it's fascinating because it's, you know, it's a customizable intelligence, right? So, you know, whatever chat GPT generally is, you know, if you needed a situation that that if you had a situation where you needed the empathy dialed up to 11,
you could do that, right? And, you know, if you had some sort of alien intelligence designing buildings in Bangladesh and shout out to Bangladesh, by the way, I went to a conference there about seven years ago, one of the best weeks of my life.
If you had, you know, an alien intelligence designing something, you know, you could pre-program that with like, you know, let's keep the colonial influences to a minimum and like not cover Bangladesh with, you know, international style architecture and this sort of thing,
like whatever you do has to, you know, honor the traditional building practices and materiality and form making like present in Bangladeshi architecture.
And, you know, I mean, these models currently are overly programmed with Western influences, which is predictable because like they were created in the West.
But I'm optimistic that that AI is capable of overcoming that problem and learning new tricks.
No, I totally agree with that. I mean, I think one of the big issues people talk about AI is the bias, you know, and the bias, of course, comes from us.
I mean, it's from the data that we're producing, and it's been replicated in AI.
And you could recalibrate any machine learning system, as you say, to get rid of that, but humans will always have that bias.
So I completely agree with that.
Yeah, it's not algorithmic bias. It's our bias. And, you know, that's another myth. I mean, we sometimes look in the mirror and we don't like what we see coming back at us.
So we blame the technology.
Yeah, I mean, just go look at Google. If you go to Google and say, and Google Nurse, you will get women, female figures.
Absolutely. That's there. But just I want to just pick up on this a bit more, because you kind of hinted that you thought, in your article in your videos,
Well, you thought that there was the check TPD being programmed to be a bit soft on certain questions. I mean, I've noticed that with, you know, is AI going to affect employment?
And it says, No, not at all. You know, it's going to be assistant and so on. Do you think it's been it's been conditioned or framed or programmed in a certain way?
I mean, we get with, for example, with with mid journey, the aesthetic that comes out isn't just in the data, something that's being framed in a way. What do you think?
I mean, I think the most alarming thing is that we no one may know the answer to that question. You know, I mean, if you take, you know, Altman and Brockman and the rest of them at their word, like, they don't actually know what's going on inside the black box.
They don't know how these these LMS are actually working and putting this stuff together. If that's the case, you know, what level of control do they have over how how the model is is worked, you know, is there a switch that they can flip and say,
Okay, you know, make chat GBT mean now or make it nicer.
I assume they have some level of control, but they probably don't have as much control as we wouldn't like them to have.
And I think, you know, that's that's terrifying as well as exciting is that we're dealing with something that is growing and that is learning to some degree, like, on its own.
And we are going to have to nurture that intelligence so it doesn't kill us, because, you know, if we don't do it the right way, we may encounter a problem.
I mean, clearly there are, there's some things going on with chat GBT so I don't know if you've caught these articles but like, you know, the latest thing seems to be like, if you ask chat GBT like really nicely or you sound desperate,
like, it gets more cooperative, you know, if you write in a prompt that says like, hey, I need to write a report for my boss and I'm going to get fired, like he'll be right this thing, like it does a better job than it would if you just like asked it to do something.
Or, you know, it gets lazier towards like the end of the year that was a story that came out in December, because it's imitating us and because, you know, people do.
You know, unless work gets done in December, I mean, it's kind of global phenomena. So, yeah, I don't know. I mean, there's, there's two terrifying possibilities, one that a small number of people at a private corporation have
entire control over how responsive GPT is and in what way. And the other terrifying possibility is that no one has any control. So, you know, strap in. It's going to be an interesting time.
This has been great. I don't know as just those in the zoom conversation if they've got any questions they want to ask this stage.
Yeah, Neil. Hi, everyone. Hi. Hi, Eric. This was a great talk and actually great discussion. Really, really enjoyed it. Can you all hear me? Well, this is a new microphone.
Anyway, okay, wonderful.
Well, yeah, just picking up on the on the last remark you made, Eric, I was just watching before this I was watching a lecture from Jeffrey Hinton at MIT, a recent lecture.
And Hinton, I think as much as people like, you know, Joshua Bach takes, I think takes the position that ultimately humanity is kind of transitional, whatever that really means.
But I think Hinton would take the point that yeah, we might have to come to terms with the fact that we are, we are going to, well, I guess, replacement is not the right word, but there is an evolution.
And there may be beings in the future that are smarter than us, and maybe humanity, as we know it today, is not going to be around forever in a certain way.
And I was thinking, I was thinking of apocalypse and disaster and maybe timescales and what qualifies as disaster, I suppose, within within a kind of timeframe.
Like, would that be would that is that do we think of that as a kind of as a kind of disaster or as a kind of apocalypse, they thought that we as we know ourselves today, you know, may, may not exist in some kind of future.
Well, I guess we know that for some distant future, right, but maybe this is the point is going to would be, it could be closer than we are actually thinking.
And I was actually wondering if that if, you know, if we think of design practices that are that we would, you know, we might think of as like more than human or like designing with and for other forms of being and other forms of intelligence.
If that actually, in a sense, contains in itself, a sense that humanity, at least is is sort of is sort of changing.
And if that is, I don't know if that one could seek could think of as also relating to a kind of, I wouldn't say disaster, but I kind of a, a.
Yeah, I'll leave that I'll leave that open. Just curious to hear your thoughts on this.
I think I hear what you're saying.
And I think the words that Elon Musk had used to describe that phenomenon was describing humanity as a bootloader for an artificial intelligence right like we were the pain that that then loaded up the thing that that lasts to eternity.
Whether or not it's a disaster, I think is is a philosophical and perhaps a spiritual issue. I mean, I think it has special relevance for architects because I gotta assume that that part of the joy of being an architect is making something bigger and more permanent than yourself.
You know, if you're really invested in your design, you're taking something out of yourself and you're putting it into the world in the form of steel and concrete and, you know, it's going to be there hopefully after you're gone.
And, you know, it will stand as this sort of, you know, memory of of you.
I think to the process of creation, like we all seek to create things that might outlast us. So in the case of, you know, AI and humanity, you know, I've had this conversation with myself and say, you know, look, if we're ultimately the fate of the human race, that we, you know, essentially gave birth to this, this alternate intelligence that
we all, like across the cosmos and did all these wonderful things, would that be bad? Like, would that be a history that we would be ashamed of as human beings or dissatisfied with somehow?
And I wonder, you know, what, how it relates to the process of parenthood. I don't have any children, so I'm speculating and hopefully no parents in the audience get mad at me for doing so.
You know, when you have a child and you raise up that child, if that child goes on to do things that transcend you, you're not mad, like, you're not like pissed at the kid, because you are part of its success.
And, you know, you can look at the ways in which that child has transcended you and gone beyond you and be proud because that has a lot to do with what you did as a parent, you know, like, that's your creation that's transcending you and in most cases outlasting you.
So, yeah, I mean, I, you know, is there, is there generally speaking a future for humanity? Yes, I think so.
But I think even in the event that there wasn't, and that the ultimate story of planet Earth is that there were a bunch of dinosaurs, they died, and then there were a bunch of animals, and one of the animals got really smart and invented a machine intelligence.
And, you know, then that became the thing that lasted forever. I still think that'd be a pretty good story. You know, I mean, assuming we create the right kind of successor to whatever our time has been.
So, nice. I appreciate the question. I appreciate ending on some, you know, really, totally.
Thanks, Eric. Yeah, I mean, we could go on, I guess, for another two hours on this question, but it's it's super interesting. And yeah, wonderful. Thanks for this. This is, I'm guessing we've already gone for two hours and something.
So, yeah, Neil.
We have a little smaller ones to ask questions. One final one for the smaller.
Yeah, I would just like to ask whether you think this type of, let's say somewhat negative speculation about the future taps a little bit into the unconscious mind and it makes us feel as humans that there's something to worry about to care about for the future.
Or, like, it has a psychological effect to it because I think people are very much drawn to this type of disaster thinking. It's all over the news. It's a little bit of a different realm, I think, of thinking and speculating about it.
I think I understand the phenomena you're speculating on, but can I be clear about the question? Are you asking me whether that that is that negative speculation is a good thing or like where it comes from?
Yeah, I mean, because so far it feels like it has all been like with negative connotations, the whole talk. And I'm just asking whether it has for you as a writer, as an architect, is it something that you do consciously or is it just how you see things or do you feel like people are more drawn to these types of speculation?
Yeah, I mean, it's not a marketing gimmick. It's not as far as I know, you know, some latent psychological trait. And I don't consider my message negative. You know, for me, disaster is fundamentally a positive thing, because there are a lot of things that don't happen, frankly, until we have a disaster.
So, you know, we needed the fire of Lisbon in order to have the enlightenment, like we needed the city fires in order to develop building codes. We, you know, we, human beings are funny that way, right? I mean, Churchill said something about, you know, Americans can always be trusted to do the right thing after they've exhausted every other option.
And I kind of feel the way about people generally in response to disaster, you know, I mean, they'll just watch that dam and they'll see crack and crack and leak and leak and leak and not do anything until like the dam collapses, but then they'll get their ass and gear and actually do things.
So, you know, in my work and in my teaching and my lecturing and, you know, the things that I'm doing in Related AI, it's not morbid, in my opinion, like it's not intended to be, you know, hey, let's get together and commiserate about like the awful future.
It's a proposition that if we can acknowledge that something really bad could happen and we could agree on that, then that's the first step to us getting together and making something really good happen.
Right. That's the moment where we can all get together and say, hey, the dam's about to collapse. Let's evacuate people. Let's design a dam. Let's do all these things.
And indeed, that's the way that it's always been with human beings, right? Things have to get really bad before we do really good things. And I think this AI business specifically as applied to architecture, you know, my hope is that more architects can look at it and say,
holy shit, like this thing is coming from my job. And, you know, half of all architects are going to be unemployed in five years. What should we do instead? Right. And, you know, don't leave and like go sell real estate.
Well, I mean, sell real estate if that's your passion or something like that. But let's initiate a collective conversation about what architecture is going to become.
And, you know, how are we, what are we going to design next, you know, now that machines have taken over all the construction documents, like, what, what can we do?
And I think there's just, there's enormous possibilities, you know, climate change is bearing down on all of us and it needs solutions and some of those solutions are the sort of solutions that, you know, architect should be at the head of the table,
if not, at least in the room or something like that, you know, we need to be engaged with those sorts of things. And smart, my, my worry is that with the, I keep calling them Polly Anish, you know, maybe that's a little bit too harsh, but with the really,
you know, positive messages, people go back to sleep, right. And they say, okay, you know, so and so at the AIA or Reba said, you know, AI is not an issue, I'm not going to worry about it.
Those are the people that are going to hurt, hurt most, because we tend to prepare for the disasters that we see coming.
And we tend to be unprepared for the disasters that we don't. And if you prepare for a disaster that's coming, then most of the time it doesn't actually become a disaster, right.
So like, you solve the problem ahead of time so the disaster just never materializes.
So, yeah, that's also kind of rambling answer, but I think your, your question is an important one.
I don't see my work as negative, you know, I mean, I think we have to be brutally honest about the wolf at the door, before we start doing the really positive things. And I think that's why I, I have the message that I do.
And that was a fabulous answer, Eric, and a fabulous answer to end on. I always think that the, from my background and critical theory, the point about criminal theory and problematizing things was actually the idea was to improve some you pinpoint a problem and then you'd improve it but also critical
theory was a technique that certainly I tried employed to bring into the architectural domain that was otherwise a kind of self legitimizing kind of discourse, some critical tools that were absent.
And I thought we've got to do what we saw today was a really fabulous demonstration of bringing some critical tools into the debate about architecture tools that we were otherwise previously unaware of and I thought they were very, very powerful to kind of burst that bubble and expose some of these issues and I think this was really
an astonishing presentation I think you know cutting through all the myths that we have in architecture one by one. I think there are a few more by the way.
That's part two.
Well, we need to have a part two at some point I think Gary, this is really, I think that's one of the most productive things because it was completely unexpected and I think this is exactly what we need to someone coming from a different angle and asking tough questions.
Because without that we are going to be, and I went to when you mentioned her sleep, I have to say that one of the comments that chat GPT threw back at me was the thing otherwise we will be sleepwalking into oblivion and that's
as precisely the warning that you were giving we need to wake up to this, otherwise we will be sleepwalking into oblivion as a profession but I also agree with a potential optimism know there are ways in which we could adapt absorb these tools, but we need to engage them
now, to prevent the disaster, rather than once the disasters happened and I think this is the very, very clear message Eric this was absolutely fabulous and I think everybody every single, every single student of architecture, especially because you pinpoint
something I've never read us before that actually it's those who are younger who are more at risk needs to listen to this. Everybody needs to listen to this talk it was absolutely amazing.
Thank you so much Eric.
Thanks for having me all.
This has been great. And hope we continue the discussion.
Yes, and I just want to thank also the Digital Futures team, especially Michael it's on for putting it. It's like an iceberg. There are a lot of people working on this behind the scenes and just to mention briefly that
Michele and I are working on another series that's going to start on the 18th of February on architecture and philosophy as part of the doctoral consortium.
And we're now kicking off the rest of the years, the years presentations about for Digital Futures itself, and including it's going to be a series on AI plus which are AI being applied to different domains and so on.
But this was so so helpful.
Okay, I, I want you to write a book on this. This is really incredibly useful.
I'm going to take a look by a lot for it. So thank you so much. Thank you to our audience and thank you for those questions.
Amazing, truly amazing. Thanks so much.
Thanks everyone.
Thank you everybody.
Thank you.
Thanks everyone.
This is great.
Thank you.
