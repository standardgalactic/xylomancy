In mathematics, you want to prove things.
Usually take some known theorems and ideas and, by using logic and mathematical techniques,
show something new.
But what lies at the foundation of mathematics?
You prove new statements from statements that you already know, which themselves were proven
from other statements and so on until you reach, well, assumptions.
Stuff we don't really prove, but assume to be true.
In mathematics, we call these axioms, and they lay the foundations of what we can do.
The most widely used system of axioms is called Zermelo-Francoise theory with the axiom of
choice.
And these axioms talk specifically about sets, and the reason this is is because sets are
so foundational that it's in everything in mathematics, from numbers to functions to
algebraic structures, which can all be described by sets.
But there's a specific axiom that stands out above the rest, the axiom of choice.
We'll see what it really says about how we make choices in mathematics, as well as
the controversy that this axiom brought.
And why, even after all that, mathematicians hold fast to this axiom.
But first, we need to learn a bit of set theory.
Because usually when you ask someone what a set is, they just say a collection of mathematical
things.
You know, we can have a set of natural numbers, or real numbers.
A basis of the vector space R2 is just a set of vectors.
In fact, basically everything in mathematics, from ordered pairs to functions, relations,
equivalence classes, even numbers themselves, can be described as sets.
So this is why set theory is foundational in all of mathematics, because sets are the
building blocks.
So we need a formal set of rules to govern how sets work, or else you might run into contradictions.
For example, consider the set of all sets that does not contain itself.
Call it R.
Then is R contained in R?
Well if R is in R, then it contains itself, so it cannot be in R.
But if R is not in R, then R should now be in R.
This is called Russell's Paradox, which is formulated by Bertrand Russell in 1901 to
show that, clearly, we have to restrict on how we build and talk about sets in some way.
Before this, mathematicians worked with sets and collections in a naive sort of way, just
using assumptions they thought were self-evident.
But with Russell's Paradox, mathematicians realized the necessity to lay down the foundational
rules of what a set is, and its properties.
In 1908, Ernst Zermelo formulated a list of axioms to base the theory of sets.
Eventually, other mathematicians like Abraham Frankel and John von Neumann added some other
axioms and eventually formulated Zermelo-Frankel set theory, also known as ZF, along with the
axiom of choice, together called ZFC.
We won't go through all of ZF today because that probably requires a whole series of videos,
but this is a quick, informal description of what they say.
Two sets are equal if they have the same elements.
There exists the empty set.
There exists a set containing two already existing sets.
The union of sets is a set.
The collection of all subsets of a set is a set.
A definable sub-collection of a set is a set.
There exists an infinite set.
The image of any set under a definable function is a set, and every non-empty set contains
a member that it is disjoint with.
Now some of these you can omit in certain circumstances by following from other axioms,
but this is the general idea of ZF.
Now it's important to note that ZF, or axiom of choice, is in some god-given, infallible,
objective mathematical set of rules.
You can construct and define other axiomatic systems and assumptions, which themselves
can be useful in building upon mathematics.
But ZF and the axiom of choice is what we use historically and so far, works pretty well.
So what does ZF say about sets, and what can we build from them?
Well, first, from now on, everything in mathematics is a set.
So it's important that we construct the mathematical concepts that we're familiar with in terms
of sets.
And we do this by constructing sets with the same properties that we expect from what we're
familiar with.
For example, consider the ordered pair AB, where it's just a collection of two objects
with a strict ordering.
So AB and BA are not the same if A and B are not the same.
What's the defining property of the ordered pair?
Well, how can we say that two ordered pairs are equal?
Well, their first elements must be the same, and then their second elements must also be
the same.
So AB is equal to A'B', if and only if A is equal to A' and B is equal to B'.
Can we describe sets with such properties?
Yes, we can in fact formulate multiple constructions, but the widely accepted definition is a Kurotowski's
definition, where AB is this set.
It looks a bit wonky, but if you do the math, you'll get that this set exactly satisfies
the defining property of the ordered pair.
Now, defining ordered pairs is important because they help us construct other concepts.
For example, take the Cartesian product of two sets.
It's the set of all possible ordered pairs, AB, such that A is in A and B is in B.
For example, the Cartesian product of the natural numbers and the natural numbers is
all possible pairs of natural numbers.
Then we can define something called a relation from sets X to Y.
Formally, these are just a subset of the Cartesian product X times Y.
Then we say that some X and X is related to some Y and Y denoted like this, if X, Y is
in this subset, R of X times Y.
For example, the greater than relation of the natural numbers is a subset G of N times N.
Then 2, 1 is an element of G, but 3, 7 is not an element of G.
But what if we restrict a relation such that every X and X can be related to exactly one
Y and Y?
Well this is called a rule of assignment, but let's step back a bit.
A rule of assignment is a set of ordered pairs in X times Y where each X and X is related
or you can say mapped to a unique Y and Y.
That my friends, is just a function.
We call back in grade school how you described a function as a graph on the Cartesian plane.
The graph had to pass the vertical line test showing that each X element had to be mapped
to exactly one Y element.
Well this graph is just a representation of a set of ordered pairs.
Take the real valued function f of X equals X squared on the reels.
We can demonstrate it as a graph where each point on the graph is an ordered pair.
So this graph represents the set of ordered pairs which is just the rule of assignment
defined by the rule f of X equals X squared.
So a function is just a set, defined by this rule of assignment.
Functions are at the heart of the axiom of choice, so let's briefly go over a few properties
and definitions.
A function is defined between two sets, the domain which is the set of inputs and the
co-domain which contains the set of outputs.
In our formal definition, if we have a rule of assignment as set of ordered pairs, the
domain is a set which the first element of the ordered pair comes from, and the co-domain
is a set in which the second element of each ordered pair comes from.
Technically speaking, a function is then formally defined as a triple consisting of the rule
of assignment, the domain, and the co-domain, but for simplicity we can just talk about
the rule of assignment.
Indeed, the rule of assignment of a function maps each element of the domain to a unique
element of the co-domain.
Notice that the co-domain isn't necessarily the set of all outputs, that would be the
image of the function.
Like for f of x equals x squared, not all real numbers are outputs of this function,
in particular the negative numbers.
If a function does map to all of the co-domain, such that the range is the co-domain, the
function is called surjective or onto.
Now looking at the domain, while each element can only be mapped to one element in the co-domain,
it doesn't mean two elements of the domain might end up mapping to the same element
in the co-domain.
In our f of x equals x squared example, negative two and positive two map to the same element,
four.
But if it happens that distinct elements in the domain are mapped to distinct elements
in the co-domain, that function is called injective or one to one.
If a function is both surjective and injective, such a function is called bijective.
There's a lot more we can dig into, but I think we're ready for a formal approach
to the axiom of choice.
Take a set x, which is a collection of sets which are non-empty, meaning each element
of x is a set that contains something.
The axiom of choice says that there is a function which, for every set in x, chooses an element
inside that set.
Such a function is called a choice function of x.
When you hear like that, it seems a bit underwhelming.
But let's look at the machinery of what's going on here.
So our domain is a set of these non-empty sets.
Then our co-domain is a set of all the elements in each of these sets, since our output will
always be in one of these sets.
So the co-domain is a union of all these non-empty sets.
Just imagine that these non-empty sets in x are boxes containing some mathematical things,
and our co-domain is just a big box where you dump all the contents of these boxes into.
Then the co-domain is a set of all the possible elements we can choose from, and our choice
function chooses one for each element of x.
We call this the union set of x, which we can also denote with the big union symbol
like this.
Then we say that there is a function from x to the union set of x, such that f of x
is in x for each x in big x.
So f of x basically chooses an element in the non-empty set x.
Now the axiom of choice doesn't actually give us a way to find this function or what
this function looks like.
It just declares that for any set of non-empty sets x, such a function must exist.
So why is this axiom so important or even necessary?
It feels, well, a bit obvious.
Well that's because most of us live in a finite mindset.
If we have a finite number of sets, we can easily prove that such a choice function must
exist using a technique called induction.
You don't need an axiom to make finite choices.
In fact, even some infinite choices don't really need the axiom of choice.
Take the set of all possible subsets of the natural numbers, called the power set of the
naturals.
Then a choice function f for the power set of n chooses a natural number from each possible
subset of the naturals.
So the domain is the power set of n, and the co-domain is a set of naturals.
But we really don't need the axiom of choice to show that a choice function exists.
For example, you can easily define a choice function by just choosing the smallest element
in each subset.
By the properties of the naturals, every subset contains a smallest element.
So again, we don't need a c to show that a choice function exists.
But the universe of sets is much, much bigger than the naturals.
For example, the real numbers live in a bigger size of infinity than the naturals called
uncountable infinity.
But we can also define bigger infinities by using something called ordinals.
In essence, we can define bigger and bigger infinities by describing what are called different
order types of the same size.
It's definitely out of the scope of this video, but the point is sets can get stupidly
unfathomably large.
And so if we want to make these uncountably infinite number of choices, well, we can't
just do that using any of our zf axioms.
We need the axiom of choice to assume that we can make these infinitely many choices,
no matter how incomprehensibly large our sets can get.
And it turns out that making these choices is necessary even for the most seemingly obvious
theorems about sets.
For example, let a function f from x to y be surjective.
Remember, it means all of its co-domain is mapped by some element of the domain.
Then does this imply that there exists an injective function g from y to x, that is,
a function where two distinct elements of y are always mapped to distinct elements in
x?
Well, let's think about this.
By the surjectivity of f, each element in y is mapped by some x in x.
So simple.
Let's just let g of y be this x.
But wait, there is no guarantee that f is injective.
So there could be multiple x's in x that map to this y.
So if x1 and x2 both map to y by f, which one do we choose for our g?
Clearly, we need the axiom of choice to choose, arbitrarily, some element to map y to.
This is how we'd formally state this.
Let x sub y be the set of all elements in x such that f of x is equal to y.
So this is the set of x's from which we'd like to choose what to map y to.
Think of like we're watching The Bachelors, and this is the set of all candidates for
g of y.
Notice that x sub y is a subset of x.
Since our choice function, let's call h, wants to choose an element of this subset,
its inputs are the subsets of x, so the domain of our choice function h can be the set of
all subsets of x, that's the power set of x.
Remember, this is the set of all subsets of x, so x sub y is an element of the power
set of x.
But recall that ac requires our domain to contain only non-empty sets, so we do have
to remove the empty set which is technically a subset of x.
Okay, then its co-domain is the union set of p of x, but clearly this is just x.
I mean everything in here is just a subset of x, so you dump all of its elements into
one big collection, it's just gonna be x.
So the axiom of choice affirms that there exists a choice function h from p of x minus
zero to x.
In particular, h of x sub y will be in x sub y, meaning h of x of y is guaranteed to be
one of our bachelors.
So that's how we'll define g.
For every y and y, then g of y just be h of x sub y.
Let's show that g is injective.
If y is not equal to y prime, then x, y and x, y prime must be disjoint, meaning they
have no elements in common.
Indeed, if x was in both x, y and x, y prime, it would mean that f of x equals y and f of
x equals y prime which contradicts the rules for functions, but each element is mapped
to a unique output.
So if x, y is disjoint from x, y prime, any element in x, y is distinct from any element
in x, y prime.
So g of y equals h, x, y is not equal to g, y prime equals h, x, y prime.
So g is injective.
So that's how you apply the axiom of choice in a proof.
And the axiom of choice appears a lot in mathematics.
In fact, it is equivalent over zf to a lot of statements.
And when I say that two statements are equivalent over zf, it means that, assuming all the other
axioms of zf, the statements imply one another.
Basically, it means that the statements are the same.
They are simply different ways of stating the same innate fact.
So saying ac is equivalent to some statement means if you want this statement to be true,
you will need the axiom of choice.
So let's go over some equivalences of ac in set theory.
One of the most important equivalences of ac is Zorn's lemma.
But before we state Zorn's lemma, we need some preliminaries.
Let's say you wanted a way to compare elements of a set x, then you can define what's called
an ordering on that set.
It has to satisfy some properties.
First, it must be reflexive, meaning every element of x is related to itself.
It must also be anti-symmetric, meaning if x is related to y and y is related to x, this
means x is equal to y.
Finally, it must be transitive, meaning if x is related to y and y is related to z, then
x is related to z.
A prime example of an ordering is the greater than or equal to relation on the set of numbers
like the integers and the reals.
In fact, in general, we like to use this notation for orderings on sets, but of course there
are many more orderings than just the greater than or equal.
For example, take the set inclusion relation, given by a is a subset of p, and the power
set of some set.
This also satisfies three properties, but here's the thing.
You can choose any two numbers, and you'll always be able to compare them with greater
than or equal to, but if you choose two elements of a set containing sets, they might not be
subsets of one another, like 1, 2, 3, and 2, 3, 4 can't be compared by set inclusion.
No worries, such a set, with a relation that satisfies the three properties, but not all
elements of the set can be compared to every other element is called a partial ordering.
And if, like the integers with the greater than or equal to relation, every element can
be compared to every other element, that set is called a total ordering.
Now let's say that you have a partial ordering on some set, and you want a subset of that
set that is a total ordering induced by that same ordering on the whole set.
Then such a subset is called a chain, and a chain is a good name for them because elements
of such subsets form a chain of ordered elements.
Now in general, if you have a subset S of a partially ordered set X, you can define
what's called an upper bound of S. This is some element U of X, such that U is greater
than or equal to every element in S. Now U doesn't have to be in S, but it could, and
there could be multiple upper bounds.
For example, an upper bound of the subset 126 in the set of naturals is 7, but also
1000, or maybe 6, or basically all natural numbers greater than or equal to 6.
But not all subsets have upper bounds, like take the set of even numbers, which obviously
doesn't have an upper bound.
No natural number is greater than or equal to every even number.
Finally, let's define something called a maximal element of X. An element M of a partially
ordered set X is maximal if there is no other element of X that is greater than or equal
to M. For example, in the set 12345 with the usual greater than or equal to ordering, 5
is a maximal element.
But in the set of all natural numbers, well, there is no maximal element.
Now we can define Zorn's lemma.
Let X be a partially ordered set induced by some relation.
Suppose that for every chain C of X, C has an upper bound, then X has a maximal element.
A few questions arise pretty quickly.
First, where is the axiom of choice in this?
This was supposed to be an equivalent statement, yet it looks and feels so different.
And also, what really is this statement saying?
What is it used for?
Let's answer the second question first.
A lot of mathematical concepts that you may know are actually maximal elements in disguise.
If you know some linear algebra, think about the basis of a vector space.
You can pretty easily prove with basic linear algebra that a basis of some vector space
V is the maximal element of the set of all linearly independent subsets of V. So Zorn's
lemma can be crucial in proving the existence of some very important mathematical objects.
So how do Zorn's lemma and the axiom of choice relate?
Well, first, let's try to find AC in Zorn's lemma.
In other words, if Zorn's lemma is true, does that mean that we can find a choice function
for any set?
Answer is yes.
Take a set X of non-antisets and let A be the set of functions, F, or technically rule
of assignments, don't worry too much about the semantics, such that its domain is a subset
of X and it satisfies F of X is an X for all X in the domain of F. Well, this set A is
a partially ordered set induced by the set inclusion relation, but it turns out that
every chain in A has an upper bound.
So you can apply Zorn's and show that A has a maximal element.
Then you can show that this maximal element is exactly a choice function for X. Zorn's
lemma implies the axiom of choice.
How about the other implication?
Does AC imply Zorn's?
Yeah.
But that proof is a lot more complicated.
It requires ordinals and a technique called transfinite recursion, which uses the axiom
of replacement.
The tools required for this proof are beyond the scope of this video, but as a general
idea, you take a partially ordered set A where every chain has an upper bound.
Then you construct some subset of A by using the axiom of choice to recursively choose
what are called strict upper bounds.
These are basically elements that are strictly bigger than everything in a subset.
Basically, at each step, if your subset still has some strict upper bounds, you choose one
and add it to the subset.
We do this continuously until the subset we constructed has no more upper bounds.
This way, we want to construct a maximal element of A by taking this subset and taking its
union set.
But because we could have so many choices for such strict upper bounds, we have to use
the axiom of choice.
This kind of recursion is also not over the naturals, but instead, each step is marked
by these transfinite objects called the ordinals.
You can then use an axiom called replacement to prove that this transfinite recursion must
eventually stop, and thus, you have constructed a maximal element using AC.
So AC implies Zorns.
So that's the first important equivalent of AC, but there's another also very important
equivalent of AC called the well-ordering theorem.
Remember the ordering stuff from Zorn's lemma?
Well, let's suppose that a set X has a total ordering, meaning every element can be compared
to every other element.
Such an ordering is called well-founded if every subset of X has what's called a least
element, meaning everything in S is greater than or equal to this least element.
If a set has a total ordering and is also well-founded, we say that the set can be well-ordered.
For example, the set of naturals with the usual ordering is clearly well-ordered.
We know that the naturals in their usual ordering is a total ordering, and it's not hard to
see that every subset of the naturals must have a least element, because if not, you'd
be able to find some infinitely descending subset of the naturals which cannot happen
because, well, you'd have to eventually stop after some finite steps at zero.
But what about the integers?
Well, it sure has a total ordering under our usual ordering relation, but it's not well-founded.
Take the subset of all negative integers.
It doesn't have a least element.
But this doesn't mean the integers can't be well-ordered.
How about we define a new relation on the integers, where A is less than B, if the absolute
value of A is less than the absolute value of B.
Now, if the absolute values are equal, and let's say A is not equal to B, then this
must mean that B is negative A. So, whichever of A or B is positive, let's order first.
So such an ordering would look like this, 0, 1, minus 1, 2, minus 2, 3, minus 3, and so
on.
Then this ordering is well-founded.
You can see how our ordering relation may look a bit weird, but nonetheless, the set
can be well-ordered.
But can we do this for every set?
You can, in fact, define a pretty nice well-ordering on the rationals and, in general, any set that
is countable, meaning it has size equal or smaller than the naturals.
But when things get uncountably infinite, like the reals, it becomes difficult to find
a well-ordering.
But even so, do we know one can exist?
Well, the well-ordering theorem says that every set can be well-ordered, and it turns
out the well-ordering theorem is equivalent to the axiom of choice.
Like Zorn's Lama showing that the well-ordering theorem implies AC is a bit more easier.
If we assume the well-ordering theorem, take any set of non-empty sets x and look at the
union set of x, then the union set of x has a well-ordering.
In particular, every subset of u of x has a least element by well-foundedness.
But notice that every element x of x is a subset of the union set of x.
So we can define a choice function from x to union set of x, such that f of x is the
least element of x as a subset in ux with respect to its well-ordering.
Well, the least element of x as a subset of the union set of x is obviously in x, so we
just defined a choice function for x.
On the other hand, showing that AC implies the well-ordering theorem is again a bit
more complicated.
And again, we need stuff like transfinite recursion and ordinals to define a well-ordering.
But the idea is pretty straightforward.
For any set x, you basically use the axiom of choice to choose an element in x.
Set that as your least element, then choose another element from the remaining element
in x, and that's your next element in our order, then you just continue to do that recursively,
again with the weird transfinite recursion done over the ordinals, and again, by the
axiom of replacement, it necessitates that we must stop.
Then we have basically constructed a well-ordering on x.
Again, the details are out of the scope of this video, but hopefully you can see the
choiceness required for the well-ordering theorem.
But the equivalences of AC are not just limited to set theory.
There are a lot of equivalences to very many important statements outside of set theory.
First, every vector space has a basis.
If you took any level of linear algebra, this is a foundational statement about vector spaces.
When we are given a vector space, we automatically assume it has a basis.
It turns out that this theorem is equivalent to AC.
Second, that every ring contains a maximal ideal.
This is a statement in rank theory, and it's a pretty important statement because maximal
ideals are quite useful tools.
And like a previous example, it's a foundational theorem in algebra, which is also equivalent
to the axiom of choice.
Now these statements might seem a bit disconnected from our first formulation of the axiom of
choice about choice functions, but they are quite immediate from our other equivalent
formulation, Zorn's lemma.
Both a basis of a vector space and a maximal ideal of a ring are just maximal elements
under the set inclusion relation.
So often times an abstract algebra, the preferred form of the axiom of choice is Zorn's lemma.
Of course, the fact that these statements also imply Zorn's lemma is quite interesting.
Another important equivalent of AC is Tyknoff's theorem, which states that the product of
any collection of compact topological spaces is compact with respect to product topology.
It's considered one of the most crucial theorems of a branch of topology called point set topology.
And these are but just a few of many examples.
So clearly the axiom of choice is an indispensable theorem of mathematics.
If we have the axiom of choice, we can prove these important theorems, and if we want any
of these foundational theorems to be true, the axiom of choice must follow.
So what's the problem?
Why did I say that the axiom of choice is controversial?
Well, there are a lot of reasons for this controversy.
One comes from the philosophical consequence of accepting the arbitrary existence of these
choice functions, maximal elements, well-orderings, without any concrete way to construct or describe
these things.
We just say that they must exist, but as far as we know, we have no idea what they look
like.
Another problem occurs with certain implications of AC that seem, well, counterintuitive.
Take the Banach-Tarski paradox, which says that you can take a solid 3D unit ball, take
it apart into finally many pieces and, using only rotations and translations, assemble
the pieces to get two exact copies of the unit ball.
I mean, this sounds ridiculous, surely that contradicts all intuition of geometry and
volume.
But if AC is true, so is Banach-Tarski.
So if we want these really nice theorems of mathematics, like Taikonov's theorem, we're
going to have to accept stuff like Banach-Tarski.
So yes, the axiom of choice breaks our intuition in more ways than one, and this weirdness
has garnered some controversy throughout its history.
But over time, the majority of mathematicians have agreed to accept AC as a valid axiom
to derive the theorems.
And as weird as AC might be, it hasn't shown any contradiction so far.
Banach-Tarski, for example, is just a consequence of describing sets so weird that the concept
of volume really just falls apart.
It may break our intuition, but that's different from a contradiction.
But if anything, the axiom of choice shows the chaotic nature of mathematics.
Our theorems are not something to be taken for granted.
Our truths are often confusing and built upon a foundation, not of objectives, but of assumptions
we can only hope are strong.
But maybe that's the beauty of it.
There may be some things we can never truly know the answer to, maybe even some statements
that don't have an answer.
But we constructed our system of truths and relying only on our intuition and assumptions
and logic discovered what the universe had to offer.
Even if we know there is a limitation, that doesn't mean we can't reach new heights.
Is the axiom of choice true?
Does that question even make sense?
Are the axioms of ZFC truly free of contradictions?
We may never know, but maybe that's not the point.
Just being curious, desiring to know more, and pushing ourselves to make sure our truths
are truths, that in and of itself allows us to contemplate and debate and imagine and
discover.
Until next time.
