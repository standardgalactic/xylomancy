Monicarlo rendering can produce beautiful images like the ones shown here, but requires
calculating many expensive rays resulting in lengthy render times.
A few samples can be quickly evaluated, but the inaccuracy of this estimate appears as
noise in the final image.
One way to address this problem is to apply a denoising filter to generate a pleasing
noise-free image.
In this paper, we observe that there is a complex underlying relationship between the
input noisy data and the optimal filter parameters, and thus we propose to learn it.
In our system, the renderer outputs a set of primary features at each pixel, including
screen position, color, world position, and shading normal.
A local neighborhood of each pixel is processed to get a set of secondary features such as
feature statistics, among others.
These in turn are given to a multi-layer perceptron neural network to output a set of
filter parameters.
Finally, the filter takes these computed parameters and the noisy output of the rendering system
to generate a filtered pixel.
This process is done for all of the pixels to generate a filtered image with comparable
quality to the ground truth.
We train the network on a set of scenes containing a variety of Monicarlo effects such as depth
of field, area light sampling, motion blur, and global illumination.
The network is trained with the iterative backpropagation process.
Here is a video sequence showing how the network converges for a particular scene during training.
Here are some results generated by our system using a cross bilateral filter on a set of
test scenes not included in the training set.
Our approach can be extended to handle animated sequences by performing the filtering process
on spatiotemporal volumes.
