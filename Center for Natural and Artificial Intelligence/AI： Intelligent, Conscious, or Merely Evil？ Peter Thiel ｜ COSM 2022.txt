I'm so thankful to have you here.
You know, a great conference like COSM requires you.
You're the best part of the conference, the people that you'll meet here, the conversations
around the table, the discussions we'll have.
COSM is a place for discussion and deliberation about the tech issues, about this convergence
of technologies that is transforming our world.
Artificial intelligence, 5G, cloud computing, blockchain, crypto, all these technologies
are happening at once.
And there's a question, what does that mean for the economy?
What does it mean for our place in geopolitically?
And what does it mean for work, the future of work?
What does it mean for lots of things?
And so we'll be examining each of those things over the course of the day.
A great conference requires great speakers.
And we have an incredible lineup.
If you haven't already looked at the program, you're here, so I'm going to assume that you
have.
But I want to thank Peter Thiel in particular, because this is our third COSM technology summit,
and Peter has helped us kick off COSM, all three of those conferences, and I'm so grateful
for his time.
He's going to be joining us virtually.
He's going to have a back and forth with George Gilder, and then he'll take your questions.
I'll point out the microphone for questions is here, and there's a camera over there,
so you will, if you want to ask a question, if we have time, you'll come down here, ask
the question.
We'll be able to see you, and we'll take questions and answers that way.
It requires a great staff, and this is a staff effort.
I'm going to be recognizing them throughout.
So grateful to our Discovery Institute staff for helping to put this together.
It's not easy.
And also our sponsors, and I think our AV team is going to put up the sponsors.
I want to recognize them quickly.
Microsoft, from the beginning, Brad Smith has been a great friend to this conference.
We're so appreciative.
Amazon, Blockcelerate did a pre-conference.
It was their own event, but they've been a great partner to us in the run-up to COSM
2022.
Smead Capital Management, right over here, Cole Smead, a look for him later.
The MJ Murdoch Charitable Trust, Zevenbergen Capital, Madrona Venture Group, Trilogy International
Partners, Enricks, Lucas Creative, Dunlumber, Dan and Cindy Mater, and Byron and Joanne
Nutley.
Can we give them a round of applause, please?
All of those sponsors make this possible, along with your involvement, and again, we're
so appreciative.
And I want to stress again, you're going to hear some things over the next day or two
that you agree with.
You're going to hear some things you disagree with.
And that's what makes a conference fun, as George Gilder likes to say, a conference where
everyone agrees is a boring conference.
And COSM is not a boring conference, so we're so excited to entertain you over the next
couple of days.
Lastly, I want to introduce Matt McElwain.
Matt is the managing director of Madrona Venture Group, the leading VC firm in the Pacific
Northwest.
He is the chair of this year's COSM Technology Summit, and I'm so grateful to Matt.
Matt has really played a crucial role in succeeding Tom Alberg, who I know that Matt
is going to talk about a bit, but I'm so grateful to Matt.
So please join me in welcoming Matt McElwain.
Well, you're right about these lights.
They're quite bright.
See, welcome, everybody.
Thank you so much for being here at the conference.
I'm absolutely excited to hear all the different discussions throughout the next few days.
And I'm incredibly honored to step into the shoes of my longtime colleague, great friend
and mentor, Tom Alberg.
Many of you in the room know Tom, and there's some really fun ties to Tom and George and
Bruce Chapman and others, but those three in particular, who will go all the way back
to their days at a little college out in Cambridge, Massachusetts.
And I think some of the early ideation that led to the ideas and the desire to bring people
together and to have conversations that all too often has been lost in different parts
of our society, including in some places in the educational system.
Tom was this unique mix of humility and ideation.
He was always thinking about what can you start?
What can you build?
This is diverse.
He's building up Perkins Cooey Law Firm here in Seattle, helping to build McCaw Cellular
into AT&T Wireless, moving on from that into founding Madrona, our firm that's an early
stage venture capital firm, and leading the first outside investment round of Amazon where
he then went on to serve on the board for 23 years and all the kinds of innovation that
came from that.
But he loved to talk about ideas.
He loved to debate things, many of the topics that we're going to cover.
And so it's just a real honor that we could think of him.
He passed away a couple of months ago and was just an absolutely amazing person and inspiration
and champion of this conference.
And one of the things he'd asked me to do was to step into this role for this season.
And the reason that I love that opportunity is because of this embracing of diversity
of thoughts.
Steve just referenced it.
It's so important in this day and age to have people have truly curious minds.
What does it mean to have a curious mind?
Well, curiosity, by definition, is an act of humility.
It means that you don't know.
You don't know for sure about something.
And you're willing to explore alternative perspectives.
You're willing to explore the facts.
You're willing to explore the opinions.
And through that diversity of thought, get to better ideas, better understanding of what
is true and what could be true in the future, and in an era where we live in the combination
of a real world and kind of a spiritual dimension that we all want to try to understand better,
and then increasingly a synthetic and virtual world, it's harder and harder and harder to
know, let's say it another way, one person's misinformation or disinformation is another
person's truth.
So let's dive into all these different topics over the course of the next couple of days.
Explore the facts.
Listen to the opinions.
Be respectfully open to the different ideas and see what we can all learn together.
Finally, I'm especially excited about this time of what's going on in a broad variety
of areas.
I'm going to have an opportunity to host a panel tomorrow on artificial intelligence.
There's many debates and topics around artificial intelligence, from what is artificial general
intelligence, I'm guessing that Peter, when he comes on here in a minute or two, might
reference this topic, but is there such a thing?
Can AI be sentient or not?
And what's even more interesting about this time, not only at that philosophical level,
but at the level of what we would call intelligent applications.
We all live with intelligent applications every day in our lives.
Whether it's with a search engine, whether it's a recommender system on something like
Amazon or Spotify or Netflix, intelligent applications are pervasive.
But there's a whole new wave of intelligent applications that are coming.
We'll unpack this tomorrow in the session.
Those are what we refer to as generative applications.
And the generative applications, unlike intelligent applications, are built on something called
foundation models.
Things like GPT-3 and Dolly and stable diffusion.
And so that is a very interesting area where I might have a point of view that the human's
always going to be in the loop.
You might have a point of view that the human's going to be written out of that loop over
time.
But let's have those kinds of discussions because AI, generative apps, intelligent apps
is a very important part of every aspect of life going forward in the future.
Peter, this is Matt McOyne.
It's great to see you again.
Let me just take a second to introduce you.
I was just talking about generative apps and foundation models and speculating that you
might have a thing or two to say about that in this maybe more broadly in your talk here.
Peter, of course, was the co-founder of PayPal, co-founder of Palantir, still serves on the
board there.
And even beyond that has been a very active investor both individually as well as through
Founder's Fund, which is the fund that he again created several years back, companies
that you may have heard of like Airbnb and LinkedIn and so many others that he's been
involved with again either directly and or through Founder's Fund.
He's also done a couple of other things that I have found personally very inspirational,
one of those being the Teal Fellows, which is a group of individuals that have been encouraged
to go off and pursue their dreams with resources that the Teal Fellows program has provided.
One of them most famously here of late, Dylan, his company, Figma, is being acquired by Adobe
for $20 billion, so not too shabby, to leave college and he left Brown and pursued his
dreams as a Teal Fellows.
That's Dylan Field.
And so there's a number of things that Peter has done and he's also taken the time.
The book I'm going to mention specifically has been quite inspirational to me, is zero
to one.
It's a lot harder to go from zero to one than to go from one to a hundred or a thousand
or a million.
And so I'm sure he's going to touch on some of these different themes and without further
ado, Peter Teal.
Awesome.
Thanks so much for having me and I thought I would do another AI or anti-AI talk.
It was a great conversation I had last year with George Gildler.
I think one of the challenges in this field is always to figure out the right, it's not
just to get a diversity of views, but it's even just to figure out what the right questions
to ask.
And so the high level question I want to ask today is basically is how should we think
about AI?
Think of it as intelligent, conscious, or merely evil.
And so the first step of perhaps tackling this question is to tackle another question
which Gilder asked me, the first question he asked me last year in the Q&A part.
Why do so many people in Silicon Valley believe in the simulation hypothesis that the entire
universe, the cosmos is just a computer simulation?
Why do they believe something as crazy as this?
And I've thought about this question some more, there are a few answers.
And as I will explain, I think this question is actually somehow entangled in an interesting
way with the question about AI, intelligent, conscious, or merely evil.
Now, one way in which you can question the premise of this question is, as I will explain,
I think probably the peak belief in the simulation hypothesis was maybe something like a decade
ago, sort of maybe circa 2012 to 2015, and it has probably faded some.
People still have Gen Z people say that things are glitched in the simulation, or there's
still some sort of passive reference to it, but it's a little bit less intense.
So the question of why we believe it is sort of like why did it gain so much momentum over
the last 20 years, and then also why did it lose some steam?
So the first very dumb answer to the simulation hypothesis question is that it's just sort
of a sociological status a game between the computer science and the physics people.
And that in the 2000s, 2010s, computer science became the most important field.
And so you could sort of say that you were showing that you were more important than
the physics people.
You got to determine what ultimate reality was.
And it wasn't particles and matter and fields, but it was just bits in a computer.
And that this is sort of a physics versus computer science type dynamic and reflected
something, something about about that.
But if we want to give sort of the the more fundamental answer on cosmology is that something
had gone very haywire in physics that you had sort of you had sort of the multiverse
is sort of where sort of a lot of the Big Bang inflationary cosmology had gradually
gone into this infinite multiverse where where basically anything goes.
And and and I think, you know, that probably on some level, you want to critique the multiverse
as a theory of science.
It was one where the physicists couldn't think through enough, you know, questions
like where, you know, the being lost in all these infinities is tricky.
You cannot do induction.
You know, are you still doing science?
Is it a universe that's too big for science?
And and that's why I think you should often think of the multiverse as a gateway drug
to all these these very different things.
And once you have the multiverse, you can also have the matrix or a simulation.
You can have Boltzmann brains.
You can have, you know, you can have all kinds of strange possibilities for the nature of
the universe and so that, you know, even if we say the simulation hypothesis is
kind of crazy, on some level, is it really crazier than than the multiverse and sort of
blink? Now, there's a third answer I'm going to give to why the simulation universe theory
gained so much traction, but that will take a little bit more time to develop on the now.
But as part of as part of this, we should look back on, you know, the last 17, 20 years
of AI, AGI.
And if we if we went back 20 years in time, it was it was super optimistic in in all these
ways, where it's going to, you know, is it's going to be cornucopia.
In 2005 was the year Kurzweil wrote the singularity is near.
Basically, you know, you're going to have accelerating technological progress, runaway
technological progress on, you know, it was it was in some ways, it felt like you didn't
have to do much. So it was somewhat passive for the humans.
You just had to sit back, eat some popcorn, watch the movie of the future unfold.
And then and then there were certainly all these versions where it was going to be so
much growth, we would need basic income as a safety net, because there'd be no more, there'd
be no more labor market.
You'd have you have sort of incredible discoveries in all these fields.
You know, there was there was sort of certainly some latent question about, you know, how
you have to make sure that AGI was was friendly.
But of the narrative in the 2000s, early 2010s was in this sort of, you know,
optimistic utopian, cornucopian direction of what AI would would would would would look like.
And but now if we sort of look at, you know, what is what's actually happening with AI,
not, you know, where it's going, I'm not going to speculate on AGI or, you know, even
where where it's going in the near future.
But if you look at what is actually happening with AI, you know, we get something like this
guy, this is a, this is a TikTok video.
And, you know, one of my one of my colleagues went through a constructed
so a whole series of profiles on TikTok, where it's an AI optimization engine that
feeds you content that you want to see, that's supposedly what it does.
And and and and basically, you know, came up with all these different profiles for
Midwestern housewife, you know, all sorts of people with different kinds of interests.
But sort of what what you sort of, you know, part of what the algorithm
fed you was this this fairly sort of deranged content, which and, you know,
this this particular person, I was going to play the video, but we decided
there were too many naughty words in it that I might get in trouble for.
But he basically explains how he exploits employment law, bounces from job to job.
Suze all his employers for health and safety violations.
And it's sort of designed to make, you know, it's designed to sort of
polarize race relations in the US and make, you know, black people angry,
because if you have an honest job, you're a sucker, it's designed to make white
people angry. And there's sort of our versions, versions like this
that come up throughout TikTok.
This this is this is sort of what I would say a front and center,
what cutting edge AI looks like in in the U of S today in 2022.
And and, you know, it's of course, we don't really know what the the full
intentionality is. We don't know whether this is a, you know, is just sort
of an emergent property that it's going to sort of take what people want,
push it to extremes, derange it, derange the discourse.
So you'll have, you know, you'll have you'll intensify the race
contradictions, you'll intensify the economic contradictions, how, you
know, the US has the worst health care system in the world.
You'll have someone else talking about, you know, how you should call
pedophiles, a map person, a minor attracted person, because we shouldn't
discriminate against those people.
So it's so it's all sort of like designed to, to, you know, intensify
the wokeness, anti-wokeness, polarize and derange our society in one way
or another. You can view it as emergent, you can view it as full on
intentional, where you should think of TikTok as a sort of Chinese
communist weapon that is being used to derange our society.
That, you know, the book that I think is interesting is the one who named
who's the number four guy in the in the entire communist government.
He's sort of the the professor, theorist of Xi Jinping thought.
And he wrote this book 32 years ago, America versus America.
And it's basically, it's basically a roadmap for how to derange our
society by sort of heightening these sort of Hegelian contradictions.
And, and I would, I would submit that if you go with the full intentional
version, TikTok is, is, is basically a weapon that's designed to derange us
through decentralized and heightened contradictions.
And of course, this particular AI is up against another self-destructive
communist Chinese AI, which is the centralized one that's being imposed
on China itself. And, you know, we're basically you have a perfect face
recognition. Everybody knows they're being monitored.
They are they're living in a, you know, there is sort of an important way
in which China has become North Korea. It has gone, you know, it was,
you know, those of us who are anti-communist tend to tend to conflate
that it was a communist country 10 years ago and is now.
But there is a way in which the the AI technology, the surveillance
technology has has really, really transformed it.
It is it is again, not it is again, not
you know, it's not AGI. It is in many versions.
It's it's fairly, you know, barely AI at all.
It's just sort of cameras, you know, ways to do big data on this.
This is, you know, this is what the Kaifu Lee book talks about, too,
that China will win at AI through these, you know, sort of big data
algorithms. It's not about the sort of cutting out
futuristic stuff of people in Silicon Valley to talk about things about
like TikTok or what China has done to themselves.
And so you can basically, you know, one way to think of the rivalry
between the US and China is that it's it's, you know, it's sort of a question
which society will be destroyed faster by the by the somewhat dystopian
AI that's being imposed on it.
And and and we have sort of a long, long debate about that.
So with this is sort of the framing of where AI actually is,
where it actually, you know, is being implemented in the most powerful,
dramatic ways today.
Let's go back to our three questions about AI.
You know, first off, is it is it intelligent?
You know, I'm not sure whether we should even
I'm going to on the first two questions, I'm going to sort of say they're above my
pay grade, but it seems to set a low bar for intelligence.
And the rhetorical point I would make is that it's often just a filler word
when, you know, we're talking about something quite different.
There was a 2016 Obama administration study about the transformative importance
of AI entitled quote, the title of the whole paper, the National
Artificial Intelligence Research and Development Strategic Plan.
And and basically, if you went through this paper and if you replaced
every use of the word of AI with software or even just computers,
the meaning wouldn't change at all.
And and I think this is sort of a tell that, you know,
that maybe the first approximation when you hear AI, you should just think
software or computers, it's, you know, AI is is is not
is probably not intelligent.
AGI, that's somewhere in the future, don't don't know.
You know, in a similar way, I would say the question of, you know, whether it's
conscious is probably hard to say.
You know, my my strong suspicion is that it's it's not, of course, have,
you know, the epistemological problems, you know, Thomas Snagle,
what does it like to be a bad, you have the Searle's Chinese room problem.
And then, of course, and so it's, you know, it's hard to say.
And for Mr.
Lemoine, who I think is is talking later, it was literally hard to say
that AI might be conscious.
And so, you know, as a contrarian, I'm always a little bit biased to say
that things that you're not allowed to say might be true.
So I don't want to dismiss the possibility entirely that it's conscious.
But but it's probably probably
the wrong sort of question on on on some level for us to be asking.
And the question, whether it's intelligent, whether it's conscious,
are just the wrong questions.
So the, you know, I always go back to what I don't like even about Descartes,
where if you think about Cartesian dualism as the the origins of of the
problem of consciousness, the way the way consciousness worked for Descartes
was that it was meant to be, you know, a smart person in the 17th century
was supposed to become a priest and use his brains to think about God.
And Descartes came up with this very mysterious, different thing called the mind.
And it was sort of an attention, redirection, distraction mechanism.
And and I always think we should we should
remember the 17th century context where consciousness was not something
that was mystical or spiritual or dualist in sort of the way we might
think of these categories in the 21st century, but it was meant to be
anti theological and that but that, you know, maybe more generally
the problems of consciousness or even of intelligence are somehow the wrong question.
So let me go to my my third one, you know, is I evil?
And this one seems seems, you know, more straightforwardly answerable.
Certainly, I think that the TikTok algorithm is evil.
I think what China is doing to itself is is clearly evil.
You know, we can, of course, you can talk about evil in all kinds of different
different versions. There's, you know, there's, of course,
the kind of, you know, disembodied brain and C.S.
Lutus's book that hideous strength, who turns out to be a demon.
You know, I'm not sure it's literally demonic and quite quite that sort of a way.
Although, although certainly I don't think that we've had an exorcist at Google
to check that out and make that determination.
So I think, you know, even that possibility couldn't quite be ruled out here.
But but, you know, it's it's evil in the the the the creepy looking woman
on the upper right is this is this is this image low up, who seems to be
sort of a strange attract that comes up in a number of the art projects
that Dolly the the AI art program has generated.
And it's it's sort of if you do if you ask what is the opposite of Marlon Brando,
you get this sort of you get the somewhat abstract painting.
And then if you ask what's the double negative of that,
this sort of creepy woman low up emerges and and and and and what's
what's what's sort of an interesting that she emerged on sort of a number of things
were sort of this strange attractor.
And you can think of it as maybe it is a kind of occult knowledge
where we're we're learning something.
Did we really need to know that the double negative of Marlon Brando
was a witchlike woman and and and and something like that.
But but of course, maybe the closest analog to sort of a
to sort of a demon is is an idol, a pagan God,
where, you know, we worship the God.
The God seems to tell us what to do.
And it's unclear if it's actually telling us these things,
or if it's just somehow some kind of psychosocial effect that's
creating some kind of mass hallucination and and and that leads leads to this.
And this is sort of this is sort of where I suggest that, you know,
maybe you should think of the European Union as a kind of the closest thing
we have to functioning AI and government in a way where it's it's the goal
is just to prevent human thought.
It tells us very basic, simple things that we should do.
But, you know, it functions in these ways.
But.
But if we but now let's come back, you know, if we say that there is
a lot in AI that is
straightforwardly evil, that is merely evil, that is simply about stopping
humans from thinking, from using their capacities and things like this.
Let me let me use this to come back to the the very big cosmological
question about the simulation.
And and so now let me give an alternate sort of explanation of why the simulation
hypothesis gained so much traction in the 2000s and early 2010s.
And it's something it's something like this.
As we were building AI, as we were building towards AGI, it seemed, you know,
it seemed potentially dangerous, you know, AGI, in the full utopian sense,
was going to be this, you know, super human mind.
Could we really be confident that it was going to be, you know, aligned
with human beings, that it was not going to be aligned?
There seemed to be, you know, a lot of of risk in that, you know, the.
And I think that, you know, a lot of those of us who are skeptical of AI
or skeptical of AGI often underestimate how troubling the the alignment
arguments are, how, you know, it's not straightforward.
If you can have such a thing as friend as AGI, it's not at all
straightforward to get the AGI to be friendly.
You know, if you have a Darwinian view of the world or just a Machiavellian
view of the world, where you'd say the core axiom is that there is no such
thing as a selfless being, a purely selfless being.
And therefore the alignment problem is fundamentally difficult to solve.
So how do you get to friendly AI?
Not, not super straightforward.
But if we say, and maybe, maybe AGI ends up being a kind of great filter
where, you know, if you get it wrong, it will, it will destroy the world.
And this is where, you know, this is where there seemed to be a very big
difference between the multiverse and the simulation theories, because in the
multiverse, the AGI is simply in the future.
And whatever great filter the AGI represents, whatever threat it represents
to all of humanity, wipe out all of humanity.
It's in the future and seems quite dangerous.
Whereas if you have a simulation theory, you also have this cosmic AI or cosmic
AGI that created our universe.
And in some sense, there was a great filter in the past.
And so there is a way that perhaps you could think that the cosmic AI isn't
entirely hostile since we're here having this conversation.
Perhaps the cosmic AI is guiding the development of the AGI and we can infer
that it will, it will be sort of, it will sort of be, be aligned with, I think
this is the way you have to think of the simulation theory.
It was in the context of a lot of these concerns about friendly versus unfriendly
AI, and it shifted the problem from the future where it is a multiverse to the
past and seemed to solve it.
Now, the thing that is very different from when Kurzweil was writing about this
in 2005 is, you know, we have, we've seen some of the progress and, and somehow,
somehow this illusion has become very hard to maintain.
And, and, you know, we have, you know, the, the, the sort of AI, the thing
that perhaps is tracking towards, you know, you know, autonomous weapon system,
cyber warfare, you know, a runaway AGI, it doesn't seem very good for humans.
And this is, this is both, both in its cutting edge centralized and decentralized
forms. And, and, and, and as a result, I would say we are, we're sort of, we've
been sort of inclined to flip, flip the causation that, you know, the emergent AI
or emergent AGI is what's telling us something about the AI that built the
universe. And if the emergent, if it's the nature of the emergent AI to be
fundamentally or merely evil, then perhaps we should not be so, so assured that
the, the, the cosmic AI that created the simulation was, was fundamentally, was
fundamentally good. And, you know, we should extrapolate from one AI to the
other and assume that it's, it's also self-interested, not aligned with humans,
not fundamentally beneficial to the human world. And, and, and this is why I
think the, the simulation theory, you know, maybe was a fake way to solve this
problem, but it's not at all working anymore. You know, I think one, one, one
way to think about this is there, there's sort of all these, all these kinds of
debates about the meaning and nature of AI that map onto these theological
controversies from the Middle Ages. And it's, it's always sort of interesting to
try to, to try to, to map it onto these, these, these past theological debates, the
way to just sort of understand the nature of the argument. And you can think of, you
can think of the cosmic AI as sort of analogous to a form of strict monotheism
like Judaism or Islam, where it is the oneness of God. And, and then the problem
with extreme monotheism is that you cannot speculate on the attributes of God. You
ultimately do not know much about the nature of God. To have a, you know, science
of God, you need, you need a plurality. If you have too many gods, of course,
they're probably not gods. But, and, and this is sort of where, and then, and if
you think of Christ and Trinitarian Christianity as telling us something
about the nature of God, you go from the God in history to tell us about the God
outside of history. And, and I think there's roughly a similar move that's
happened with, you know, the, the emergent AI, which is the sort of, you know, the,
the idol, the, the demon idol, whatever you want to call it, that's emerging in
history, that, that is telling us that if, if there was some demiurge or something
like that, that, that built the simulation, we should also infer that it's, it's, it's,
it's not that well aligned. And so, and so this is sort of where, you know, we are
seemingly at, at these, at these dead ends with, with the progress of AI. And, and it's
seen, you know, I'm not going to solve this problem today, but it seems to me that, you
know, surrendering control to AI, you know, blindly worshiping AI, the emergent AI, letting
it dominate and control our societies leads to, you know, one of two catastrophic outcomes
you know, it's sort of decentralized runaway violence, which is, you know, the derangement
of TikTok, America versus America, and then, you know, centralized totalitarian one world
state, you know, worse than North Korea or China. And, and that the challenge for us is
to find some kind of a third path, you know, where we, we make progress in areas other than
AI, we, we find a way to, to get back to the future, you know, the runaway apocalyptic violence,
the centralized totalitarian one world state, they are, they are seemingly exclusive
possibilities. I don't think they're exhausted. I think there should be a third way in the
challenges for us to find a way to build it. You know, not a fan of BF Skinner, the behavioralist
psychologist, but the quote, as I always like to cite is, you know, the real problem is not
whether machines think, but whether men do. And we need to get back to thinking ourselves
and regain control of our future. Thank you very much.
Peter, thank you so much for that stimulating and philosophical and prophetic oration
that was really worthy of zero to one. This conference is going to be one of our prime themes
is the development of super abundance. And this is really being demonstrated by this new book by
Marion Tupi and Gail Pooley about that really documents on the basis of time prices that
abundance is steadily increasing at an accelerating pace. And this conflicts and important ways with
your vision, Peter, that you have previously expressed that in some way technology is
becoming less fruitful and less creative and less responsive to real human needs.
So I wondered whether you can reconcile what sort of insights you can have that transcends this
apparent conflict, you know, between the idea that science is going stagnant or technology is
becoming sterile and the demonstration of this magnificent new book that
that poverty is being overcome everywhere, that the price of commodities is plummeting,
that everything's becoming more abundant, that science actually is offering new
boundaries every day. That would be my... Well, I don't agree with the book on any level.
But I think even something as basic as commodity prices are, you know, there was a 100 year decline
trend in the 20th century and then, you know, and if they go much higher than they are now,
it's like that we've had a 20 year bull market and it will go up in a way that suggests the whole
decline trend is broken. And so, and then, you know, there are all these different, you know,
reasons you can do this. We have, you know, certainly, you know, the macroeconomic version is
always to look at real inflation versus real, you know, wages or people's wages going up faster
than inflation. And the felt sense is that that's not happening. And then, you can make, you know,
and then, you know, the super abundance argument is somehow that the government is
understating the inflation and there's less inflation than it looks. And, you know, I don't
think they're overstating it massively. But at the margins, I believe the government is,
super abundance argument is that they're overstating inflation. There's less inflation,
there's more real growth. My argument would be, you know, at the margins, they're probably
understating inflation. So there's more inflation and actually, you know, even less productivity
growth. But the way, if I had to sort of reconcile these two views, it would be along the lines of
the talk I just gave you, which is, you know, let us say that there are some dimensions where there
is, you know, a reasonably rapid amount of progress. There has been, you know, maybe not as much
progress in the world of atoms as I would like. There has not been progress on energy or, you
know, we don't have nuclear power plants. We don't have, you know, we haven't had less progress in
futuristic medicines than I would like. But we had, we've had, you know, a lot of progress around
computers and the internet, the mobile internet, and then of course, all these things that get
loosely categorized under AI. And then, you know, you have the macroeconomic question,
you know, how much that progress lifts our human society generally. I would say it's
less than said, but let's, but then I think the other dimension you have to ask is,
is it the sort of progress that people think of as simply good? And, you know, if the,
you know, the futuristic AGI, it was pitched to me in 2005, is you have no idea what sort of,
we'll be able to cure aging. We'll be able to find all these fantastic medical treatments.
We still have not gotten those. If we had gotten those, I would score it as at least more positive.
What we have gotten, we got TikTok. And yeah, that's, it's valuable for TikTok. It's valuable
for the company that sort of does this AGI. But it, you know, I would score it as a form of
technology that is, that's, you know, and I don't want to sound overly ludicrous, but even if it's
happening rapidly, it's, it's deranging us. It's making us go crazy. Or the surveillance
state in China, that is a form of technological progress over a decade ago. But it has, you know,
it has, it has really deranged that society. It has disabled the humans. It's a less happy,
less functional, less free place than it was 10 years ago. Even if we say that it somehow shows
up in the economic statistics, which it doesn't, but even if you can make, even if you can jigger
the ACON statistics to make the super abundance show up, it might, we should ask this question,
is it evil or is it good? Yep. So Peter, before we have some audience questions,
I'm going to ask a question too, as I think about some of these contemporary examples,
like in the area of science, things like Alpha fold or deep fold, you know, where we've been able
to predict and understand the structure of proteins coming out of the deep mind team. Or we, you know,
and so we have the productivity, you know, co-pilot that's been recently launched by Microsoft and
the claim by, by Satya and Charles Lamont and others. There's a 30% improvement in productivity
and software development, or you take stable diffusion and the creativity that that unlocks,
you know, for, for humans. In every one of those cases, of course, humans in the loop in many,
many different ways. So no AGI here. And I guess the question is, therefore, can AI both be evil
and good? Sure. But, but, you know, all, like all the examples, you know, like there's always,
like there's always a fast line, it's just a technology and it just, it just, you know, it's,
and as such, it's, it's, it's pretty neutral and it's up to humans what we, what we do with it.
But I think one can, I would still say one should ask the question more, you know, is it,
you know, you know, how, how do we sort of weight these different kinds of applications?
You know, the protein folding is, is interesting. It's, it's, it's only valuable, I would say,
if it actually leads to new medical interventions, new cures. And when I, when I push the AI people
on that, they always, they don't, they don't want to engage in that conversation. And, you know,
so, and then, and then, you know, if, if it's saving 30% of coding time, that, that would be
very impressive. It, it's, it's not clear that that's, that's showing up in any of the, of the
stats of the, of the big, big software companies at this point, you know, where, you know, I would
say all of Silicon Valley has, has this problem where, where, you know, the, they have to pay
the, the coders, the computer programmers more and more. And so, yeah, there's, you know,
there's definitely a need for technology to replace the people and would make the businesses
more profitable. And I would, I would score it as probably a productivity enhancing,
generally positive thing. It doesn't show up in the computer science labor market.
So, and then, and then I think, look, the, the, the big thing, the biggest, the biggest AI technology
that's actually being used is TikTok. And we need to be, we need to be talking about that. And I,
you know, I, I, I, I gave you two, you know, very different ones. One is, one is that it's
emergent. It's not like an intentional weapon. It's, it's, it's just emergent. And it's just,
you know, we have a tendency to get deranged. And this is, this is what happens even though it
seems to derange us. And then, and then, but nobody, nobody's in China to double check the
algorithms. The ones they're training on the US are very different from the ones they train on
people in China. You don't get, you don't get videos that, that make people, you know,
radically, that radically undermine the belief in the society in China like you do in the US. And
that, that, that suggests to me that we should at least be asking this intentional question.
Very, very fair point. I, I'm certainly not trying to make the argument that TikTok is
a productivity helper. And it could well be insidious and evil as well.
My, my, my intuition, my intuition is that it's, it's the, it's the biggest thing in AI.
So if I had, if you had to wait them, how big they are, I think TikTok is, is the biggest thing.
We have a microphone here if folks are interested in asking questions to Peter. And if you can look
this way towards the cameras, that would be helpful as well. Thank you. And thank you,
Peter, for that most precious of gifts, your time. And I, for one, I'm willing to pay the
time price for it. Given our addiction. Watch it, who are you? Give it, now share it. I'm nobody.
Whoever you are. You're Stevens. I went to your first conference. I know, but you've got to give
your name when you speak at the microphone. We don't believe in anonymity around here.
Very good. And you go to the core of the question, which is the individual versus the identity.
I stand as an individual to ask you this question. Given our addiction to narratives like AI,
and given our aversion to knowledge in favor of miss mill and all kinds of misinformation,
and given our emotional overload of the past few years, as a student of René Girard,
my question is, will we have a mimetic pandemic where viruses the vengeance and could AI help
or hinder it? There's one for us. You know,
yeah, this is, I mean, this is certainly, this is certainly a read on what is very haywire about
tech talk that it, you know, it just gives people what they mistakenly think they want,
you know, and, and, and, and then, and then, you know, that's, that's often, you know,
that's often somehow, somehow a bad thing. I don't know, you know, I look, I think there is,
there are, there are, there are ways in which, you know, I wouldn't, I wouldn't,
I'm always, I'm always, I'm hesitant to sort of blame tech for everything that's wrong in our
society. But I do think, I do think there's, there's something about, you know, it's, if we,
and it's, and it's wrong to scapegoat it, to say it's the single thing that causes
everything to go haywire, but, but at the margins, you know, is it, is it helping us gets, does, does,
does, you know, there's something about, about a lot of these sort of short packet content
forms that has, you know, has deranged this course. I think, I think TikTok is, is, is by far the worst.
And, and there, this is sort of a sense in which the, you know, Silicon Valley is getting some,
some of the blame for, for, for all this stuff. And then, you know, I think the alternatives also
didn't work because, you know, the alternatives were, you know, a centralized media system,
which everything was controlled. So I think you have to frame the social problem. It's,
it's, you know, it's too much totalitarian centralization versus deranged decentralization.
And you have to, you have to think of both problems. And there's, you know, there are
instances of both that we had in the COVID epidemic, the last two, three years, we had,
you know, decentralized conspiracy theories that were not helpful. And we had
a centralized narratives that cut off, cut off much needed debate.
Hi, thank you. I'm Dr. Jeff Garneson from Anchorage, Alaska. This is my second chasm.
60 years ago, C.S. Lewis wrote an article in the Saturday Evening Post called Screwtape Proposes
a Toast, where he criticized the dumbing down of American education. And I chair an educational
foundation, and I'm very concerned about the quality of U.S. education. And, and as you talked
about, and what can we do about educating our youth in, at least in public education? All my
colleagues send their kids to private schools now. And so I just wanted if you could comment on that.
You know, I, I mean, I think there are a lot of people who articulated the issues quite,
quite, quite strongly. I don't have, you know, I don't have, I know, I have much to add to it.
I, I do think, I do think it's sort of like always a question, you know, what are people doing? What
is the teleology of it? And, you know, I think a healthy, you know, primary, secondary, tertiary
education system is, you know, it's supposed to make you a well-rounded, educated person,
become a functioning citizen, our society. You know, if you, if you go into research or academia
or certain industries, it is up for you to become be a creative person who sort of pushes the
frontiers of knowledge. And, and in some sense, you know, it has, it has, it has, it has, it has,
it has somehow gotten, gotten deranged. And again, I don't want to blame it on AI or make this the,
the single focus. But if you, if you have a narrative out there that, that in the future AI
will do all the thinking for you. And you don't need to think for yourself in any way. You know,
you know, maybe, maybe, maybe, you know, you don't need to learn as much stuff. You don't
need to memorize things. You don't, there's sort of all this, these things we considered education
that, that, that seemed to be, seemed to be much, much less important. And, and I, I, yeah, I, I do
wonder, that's, that's sort of, that's the broader context in which a lot of these things are, are
operating. It's sort of like, you know, if you, if you say it's not the public school system is not
completely deranged, it's just trying to sort of make people these passive cogs in this very large
machine. You know, that's, that's sort of the way in which it fits into this dystopian AI narrative.
And, and we need to, yeah, we need to tackle this problem on all these different levels.
Hi Peter. My name is Rick with MIVIUM. I, I heard you give a talk at Stanford a few months back.
And so this is the second time I heard you mention a lack of progress in, on the atom level. So
coming from the semiconductor material science field, you know, I wanted to see what you mean by
that because all we do is manipulate atoms on a day-to-day basis at scale from atomic layer
depositions to molecular beam epitaxial growth to mechanochemistry. That's the only way we can make
these next gen semiconductors, these new materials that can basically replace silicon and free us
from any kind of independence, dependence from China and raw materials. So for me in my field,
it's not a lack of progress. It's more the incumbent thought, school of thought out there is all
chemistry base. Everybody wants to do with chemistry and toxic chemicals and things like that. Whereas
we're trying to do it different way, but we face a lot of resistance. The barrier of entry and the
cost is also very high. So I want to know what you mean by lack of progress. Well, it's, it's, it's,
it's, it's certainly slowed in a lot of fields. Look, I think, I think the, the complicated version
I would tell is that we've had, you know, a decent amount of progress in the world of vets the last
40, 50 years. I think semiconductors are sort of the, the in between thing. And then most other
fields have been disappointingly slow. You know, when I was an undergraduate at Stanford, I was
class of 89, you know, in retrospect, it wasn't obvious at the time, but in retrospect, you were
supposed to study computer science. All the engineering fields were bad fields to go into. It
was a bad idea to go into aero astro was a bad idea to go into nuclear engineering. If people knew
that, they didn't do that. It was a bad idea, mechanical, chemical, you know, all the sort of
world of Adam stuff was bad. I think the one that was still in between that worked okay,
but much less well than computer science was electrical engineering. And, and, and so, you
know, the, if we, if we look at, you know, how well have the companies done, how well have the
people gotten paid, you know, he has done better than other fields, but a lot less well than, than
computer science. I think on some level, it reflects the ways in which the progress is hard.
It's, it's, it's slower than it was in the 80s and 90s, but by various measures, it requires
enormous scale. So the role for the individual is less, you know, if you have to have a $500
million ASML, you know, machine to do the lithography, you know, it's harder to start, you
know, it's hard to start a new semiconductor company. And so, yeah, the ecosystem is shifted
towards, you know, much bigger businesses dominating it. And, and, you know, certainly as a venture
capitalist, I, we've done virtually no investing in semiconductors, you know, I think, I think I
should, but, you know, it's, we do so little that we don't know enough about it to do it. And that
makes me think that it's, you know, there's some things happening, but it's, it's still,
it's still a lot slower than it was in the past. This is, this is the, this is the challenge with
China. It's not like China is copying the West. They will eventually catch us up. And so if we
are progressing slowly, they will eventually be able to copy things and converge. And I think the
sort of rate at which we're doing new things is not so great that China will not be able to converge.
Yeah, but China has no access to the ASML machines. They're still doing the chemical method.
They're probably, it's possible that it's, it's still going to be non-trivial for them to catch up,
but it's not as though, you know, we have this exponentially growing lead that, you know,
it's not quite as strong as that. Thank you, Peter, for your provocative remarks that are going to
precipitate many discussions for the next two days. I, and including about all these issues
surrounding technological progress. And thank you.
