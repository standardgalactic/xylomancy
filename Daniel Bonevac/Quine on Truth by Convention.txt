Well, today I want to return to our discussion of the debate between Carnap and why.
Two people who's, these are closely aligned, but who nevertheless disagree about some fundamental
questions about logical truth, about conventionalism, about ontology, and about the nature of philosophy
in general.
So let's begin by going back to what we introduced right at the end of last time.
We were talking about the idea of a framework, and indeed that's something fundamental to
the thought that we introduced frameworks, linguistic frameworks ultimately, but I think
we could also refer to them as conceptual frameworks if that didn't, in some sense, make a question
that Carnap is interested in avoiding.
But in any case, we talked about some of these last time, and we focused on the distinction
between logic, mathematics, and then natural science, state physics.
We're going to talk about other frameworks today too.
But let's start with that distinction.
Quine thinks it's tempting with respect to the first two.
When he sees the logical empirosis by Carnap as in general saying about the first two, these
things are true by convention.
We adopt certain linguistic conventions, and things in logic and mathematics are true.
By virtue of the meanings of the terms, those meanings are determined by those conventions.
Physics is something that isn't a question of convention, that's something that's actually
talking about the real world.
Well, as I see it, Quine is basically saying, with respect to this idea of truth by convention,
that it makes sense only for one of these three.
Now, which is it?
Which one could we legitimately argue about?
The question of whether or not that thing is true by convention.
Logic?
Well, you'd think logic.
That is what, in a sense, Quine and Carnap are arguing about, except that, actually,
they're Quine disagrees with Carnap and thinks that the question is ultimately unintelligible.
It's not so much that he thinks, oh, Carnap thinks it is true by convention.
I think it's not.
And there's a well-defined question we can debate.
He thinks, he says, look, my objection here isn't so much to question the truth of this
point as it's set.
Yeah.
I would say physics.
Physics there, we might argue.
Somebody might say there's certain conventions that are established in physics.
Others might say, oh, it's purely an empirical question.
Actually, as we'll see there too, Quine thinks, there's a huge amount of arbitrarians.
And so that it's not clear that there's any real sense to the question of whether anything
in physics is true by convention.
Well, that leaves only one more possibility, right?
Math.
And there he thinks it is actually a legitimate question whether this is true by convention.
Now, why is there that difference?
We need to think about this sort of question.
So let's raise this issue of truth by convention.
And here, I mean, I'm going to put question mark to indicate, I mean, the question of whether
this is true by convention.
I don't really mean to say what I'm about to do is, with respect to the truth, is it
true by convention?
Or rather, does the question even make sense?
His answer is with respect to logic.
No.
And with respect to physics, no.
But with respect to mathematics, yes.
Now, why is it different?
What are his arguments in each case?
He thinks with respect to logic, for example, that we can't say anything meaningful in saying
that logic is true by convention or true by the meanings of the terms not or if.
So all and other logical symbols or other logical words.
Now, why is that true?
What's wrong with this idea of truth by convention there?
Not in the sense that it's false, but in the sense that it's just meanings.
What kind of argument does he give?
I've got to say that when I started out reading Kwan as an undergraduate, I thought he was
a breath of fresh air.
He was so clear compared to other philosophers.
But then again, I had studied mostly continental philosophy.
So in a certain sense, compared to Hegel and Sartre and Heidegger, he's a breath of fresh air.
On the other hand, I've got to say the older I get, the less I understand Kwan.
And so I don't think it's an easy question to say what are his arguments against this
position here and here and what's his argument in favor of its intelligibility with respect to math.
I used to think I got it and it was sort of there on the surface.
Now I think it's very hard to tease out what's really going on.
I guess I'm kind of confused because I thought in the two dogmas, or in his paper, whatever,
I think it's called just the two dogmas.
He talks about physical objects being the only, I can't remember if it's physical objects
or physics being the only things that we can, you know, know, study, whatever.
Right, right.
Well, we're going to end up thinking about a variety of other frameworks, as you point out.
And one of them is going to be just the framework of things.
We've talked about this issue in relation to Russell and a few other people.
Whether we should really think of the ultimate constituents of the world,
something like sense data or sensations or other perceptions, this type of thing,
or whether we can really legitimately talk about objects like people and tables and chairs
and clocks as the objects that are in the world.
So there's that question.
And we're similarly going to begin with other frameworks like the framework of propositions
and a framework of properties.
But you're right that certain of these client things are matters of...
Well, there's a sense in which you might say all of these are really questions of empirical investigation, right?
In the end, his model is that web.
It's not that there's some sort of foundation of given things,
either given by virtue of the meanings of terms or given directly in experience.
And then we construct all these other things on the basis of it.
Instead, there are certain things we're trying to explain about the appearances of the world
and we're just building these frameworks in an attempt to understand the world, period.
And so it's all sort of mixed together there.
Whereas, in a sense, for the earlier logical empiricists, there's a clear divide.
Certain things go into the foundation.
Things like logic and mathematics and maybe some things directly perceived.
And then everything else gets built on top of that.
So if you want to think of it this way, here's the older logical empiricist view.
It's this layer cake view.
Down here is sort of logic, math, sensation.
And then everything else gets constructed on top of it.
Whereas in Quine, so that's the logical empiricist picture,
then in Quine you get this picture of, well, gosh, what?
The web is probably not so good at drawing webs.
It's like a seal.
It doesn't look like a seal.
Like a tiger striped seal.
By the way, what's going on on campus today?
I walked past camels to get here.
Why are there camels?
They're camels?
Yeah, they're camels.
It's the Israel Blot Party.
Oh, okay.
Are there camels?
Right out there in front of the Martin Luther King Center.
Yeah, I had no idea what was going on.
There's all this stuff near the main building too.
People handing out t-shirts.
I don't know.
Well, never mind.
Talking about a framework of editing.
There's this framework going on at campus today.
I don't know what it is, but anyway.
Yeah, there's this sort of web of belief
that it all hangs together in a certain sense.
In trying to explain experience,
there's no one part we can isolate
exactly the contribution it's making to the whole.
Now, if we go back to this question about conventionalism,
and we look for client arguments about this.
In a sense, as I said, it's a little hard to uncover
because it goes into so much detail
and there's so much being presupposed.
But I think the core of it is something like this.
What's wrong with the idea in logic
that it is true by convention?
Or for that matter, not.
In the end, he says,
look, we could say we established these conventions about me
and then logic follows from those conventions.
Or we could say that, really,
there are just general features to the world.
Like things are self-identical.
Or, you know, gosh,
I'm trying to correspond to the law of non-contradiction.
Reality is not contradictory.
Something like that. Reality is consistent.
And in the end, he says,
there's no real difference
between those two pseudo-doctrines.
Now, why not?
Well, really, to understand this,
I think we have to go back to his paper,
Truth by Convention.
And there, there's a lot of complicated stuff going on.
But in the end, it comes down, I think, to a key move.
How would we establish conventions in logic?
Here's a really simple convention.
Universal claims imply their instances.
So we might say, here's a rule
that's going to cover the universal quantify.
In logical notation, we could put it this way.
If for all x, a holds of x,
then a holds of c.
Let's say, for any constant c,
we substitute for x.
Or, to put it in English,
we could just say, okay, everything is a.
Therefore, that is a.
And that would be true for any that.
Okay, so now, there I've tried to establish a certain convention
that partially establishes the meaning of all or everything,
or the universal quantify.
But now, Klein says, wait a minute,
I can't do that.
What's wrong with saying, hey,
I've just established a convention,
that's part of the meaning of the universal quantifier,
of all or every, in English?
What's the problem with that?
Can you rephrase that?
Yeah, sure.
He says, look, here's how Cardab
and other logical empiricists were thinking about this
and thinking of logic as true by convention.
I established certain conventions,
certain rules for my language,
and maybe I do that by having a semantics for all
or for the universal quantifier,
in a kind of formal sense.
Maybe I don't.
Maybe I just introduced some rules like this.
Maybe that establishes the meaning.
Or I could do it with and.
I could say, here's what and means.
We have ways of introducing and.
So if I have the truth of a and b,
I can then say a and b.
And if I have the truth of a and b,
then I can deduce a, or for that matter, b,
whichever I want.
And I might say those introduction and elimination rules
establish the meaning of and.
And I could introduce an introduction rule
for the universal quantifier and say,
I've given you the meaning of the universal quantifier.
I've told you under what circumstances
we can infer it from something else.
I've told you under what circumstances
we can infer something else from it.
And that's all there is to establishing the meaning.
Now Coins is waiting.
I can't really do it.
There's something wrong with saying,
in doing this, I've just established logical truth.
And why?
Let's take a very simple example of one of these.
Like, what's a good universal claim?
Truth of everything.
Gravity.
Yeah, everything exerts gravitational force.
Therefore, you exert gravitational force.
I want to say that's true just by virtue of logic.
Okay?
And why?
Because of conventions.
Specifically, this convention is what makes that true.
Now, that seems plausible enough, right?
What have I done in going from this to that?
Here I have A of X.
Here I have exerts gravitational force, right?
I substituted that to be A in both cases.
Well, what enabled me to do that?
What justified that?
Yeah.
The word everything?
The word everything, yeah.
And so you might say, well, it's just a matter of everything, right?
It appeals to the rule.
The line says, ah, yes, right.
But wait a minute.
Notice what else I did.
I actually said, aha.
This is saying this is true for every A, right?
And so I substituted exerts gravitational force in for the A in both cases.
But now, that was just a bit of, well, the very same.
Actually, in this case, yeah, the very same sort of logical.
In other words, to get from my logical convention to any actual logical truth,
I have to be willing to engage in a bit of logical reason.
So in other words, he says, I can't actually establish a convention without presupposing logic.
In order to establish a convention by doing this or by doing this for conjunction, for example,
I have to already presuppose some logic.
I have to presuppose logic that says, oh, you mean I can substitute any sentence for A
and any sentence for B and have this make sense, right?
In other words, this is true for all A and B.
And so I'm presupposing something about logic.
And I'm saying moreover, think about what I'm saying in the rule.
Ah, if you have both A and B, you can conclude A and B.
And say, wait a minute, I already have to understand A and B.
To understand what it means to have both A and B, right?
Similarly here, I said, if you've got A and B, then you can conclude A or B, whichever you choose, right?
And I could also frame it by saying, if you've got A and B, you can conclude A.
If you've got A and B, you can conclude B.
Both of those things are true.
And he said, wait, both of those things are true.
To understand your convention, I already have to understand the meaning of both, and, and, and all.
And so again, give me those things by convention.
I don't understand the conventions and how to apply them unless I already know logic.
So the central argument, as I see it, of his paper truth by convention with respect to logic,
is that the conventions, or maybe, well, stating the conventions, I think, but also applying the conventions,
presuppose logic.
And so they can't give you logic.
They can't give you the logical truths.
They can't specify the meanings of logical particles.
You don't understand them unless you already understand the conventions.
And here I've done it in terms of syntax, in terms of, you know, actually saying what the rules are,
but it wouldn't be any better if I did it in terms of meanings.
In fact, how do we usually do that?
People will say something like this.
The truth value of A and B is truth if and only if the value of A, well, actually, in this case,
it's often done to equal science, but I won't do it that way.
The value of A is true, and the value of B is truth.
And notice what I've done.
I've given you, by convention, the meaning of A.
I'm assuming, of course, you already understand.
And, right?
And it often goes this way.
The truth value of not A is equal to truth if and only if.
Well, here's one way to do it.
The truth value of A is not equal to truth.
You say, hey, I already have to understand not in order for that to make sense.
This is not a criticism of these symmetrical rules or of these syntactical rules.
It's not any objection to logic.
It's just saying, I can't understand these conventions about meaning or about use
without already knowing some logic.
You're defining the meaning of A in a background language that includes A or not,
and one that includes not.
Or here, the defining universal quantifier in a background language
where I already have to understand how to use the universal quantifier.
So I can't be getting logical truth out of these conventions.
I only can state the conventions that apply to them by already understanding logic.
Do these conventions always follow things that seem to be logically true?
It's never like a convention's established, then something follows from that.
It's the other way around, right?
That's what this is saying.
That's what's quite the same.
Right, exactly.
It's not like we established the convention and then these things follow in logic.
Rather than we have to already know the logic to even state the convention.
So what does that mean?
Well, what he thinks what it means is that here would be a simple way of concluding.
So logic isn't true by convention.
Somehow stating conventions or applying conventions and so on would already presuppose logic.
So conclusion, logic is not true by convention.
Interestingly, he doesn't really say that.
He says, I don't think it makes any sense to talk about logic as true by convention.
So it's not so much he thinks the claim is false.
He thinks it's unintelligible.
And we still have to ask why that would be true.
Yeah.
Can't you define them other ways, like the truth tables that don't seem to imply or, you know,
don't seem to presuppose anything like that?
Let's try that.
Okay, so we have A, B, and then A and B, and we're going to set up truth tables.
So I say, well, there are four possibilities here.
These might both be true, A true, B false, A false, B true, both false.
And now I'm going to say that A and B is true if and only if well both are true, otherwise false.
So I write a table like that.
And that seems to establish a convention that specifies the meaning of and.
Now, have I in any sense presupposed the meaning of and or other logical particles?
I mean, one thing I've presupposed right is the universal character of this.
You might say the schematic letters A and B already assume that I understand something about universal quantification.
But have I in any sense assumed something of the meaning of and?
Well, you wouldn't be able to write the truth values on the right side if you didn't know what and already meant.
Well, that's true.
Although, yeah, one way of looking at it is to say, where am I coming up with these?
They must already understand they have a function to do that.
Now, of course, I could say, no, no, no, I'm not doing it.
I'm doing that in a purely formal way.
In fact, I could say, given that there are two terms here, I'm just interested in defining certain connectives with two truth values.
There are 16 different truth functions.
And so I could really just be specifying all of those.
And then, once I've specified them all, like, oh, look at this one.
I'm going to call that and.
And that's my convention.
That's the convention about and.
And, you know, that might be fine.
So others, we might have to think a while to realize what on earth is, if anything, that corresponds to a natural language.
Yeah.
Yeah, I think, but in this case, it's tempting to say what quant does, because and is part of our language.
We kind of have to, you know, understand what it seems like to understand what and is to fill out the table.
But you can do something purely arbitrary with, like, three, you know, something that takes in three inputs that has no analogy in our language.
You know, what it's just some arbitrary truth table that you can define by convention.
Yeah, right.
This is really off topic.
But I can't resist telling you about one of my favorite connectors.
This is post negation.
Okay.
Suppose we have three truth values, truth, indeterminacy and false truth.
Well, a post negation.
And I don't know exactly how to write a post negation.
So I'll just say post a.
Is this?
It's true if this is false.
It's indeterminate if it's true and it's false if it's indeterminate.
So what it does is mathematically very interesting.
It just rotates all the truth values one place, right?
So it rotates it back like this one place.
And so it's super useful.
It turns out that in a many value of logic, this is a wonderful way of getting a functionally complete set of connectives.
But now, what does that mean?
I mean ordinary negation would be true if this is false and false if that's true.
Here it's indeterminate if that's true.
And if a is indeterminate, it's let's say some borderline case of vagueness, for example, this is just false.
I can't think of what that means in English.
I can't come up with any English equivalent.
And as soon as you get to either three truth values or more than two positions here,
it's very easy to come up with connectives where you say,
well, I don't know how to say that in English.
It doesn't seem to correspond to anything.
With one or with two, it's not too hard.
Usually it comes up with some English expression that captures the meaning.
But a third truth value or a third term in the collection here in that compound sentence
becomes very easy to generate.
So you could say, look, that's just arbitrary.
Don't worry about the words about this part.
That's something maybe we could just say, we arbitrarily filled out.
Maybe we arbitrarily assigned the word and to that meaning and thereby established a convention.
So I don't think this is going to be the source of the objection that the client would have.
But is there another one?
Yeah?
So that post-negation thing, I know it's about topic of the life.
Yeah.
So what, are there any institutions in the world that think that would apply?
I don't know.
What use is it?
What use is it?
Oh, what use is it?
Well, because in a many-valued logic, the way it's usually done, we introduce connectives
in a kind of intuitive way, and negation would be just true if this is false, false if that's true,
and then indeterminate like that.
So that's a typical negation in a many-valued logic.
But it turns out that when you do this in the kind of natural way,
introducing this third truth value of indeterminacy,
there are all sorts of truth functions you cannot express in that basic way.
Because what happens is you get a fixed point at indeterminacy, for example.
If all the inputs are indeterminate, the output is always indeterminate.
And so in standard many-valued logics, once you sort of hit indeterminacy, you can't get out.
And the same thing is true of determinacy.
If all the inputs are determined, the output is always determinate.
So you can't actually define a truth function that takes determinacy into indeterminacy or vice versa.
And that's a real mathematical limitation of the system.
You might think it's also a real meaning limitation,
since it seems as if we ought to be able to take indeterminate inputs and get a determinate output.
For example, if somebody says, oh, it's indeterminate that,
we ought to be able to actually then say, oh, that's true because all the inputs are indeterminate.
And so it means that in a logic as it's standardly done,
you can't express things like it is determinate whether or it is indeterminate that and so forth.
And so this is a way of letting you define all of those things.
It's a very mathematically elegant way of letting you define them.
It's also just a mysterious way.
You define them from an English sort of human point of view.
But that's why it's useful.
How do you get to that though?
How do you just change it?
How does that work?
Well, in math, you can do anything you want.
Instead of saying, you know, you can just say, well, take a logic with or and and and not to find the usual way.
And then, oh, add the post-connective and boom, you can now define anything.
You can define it as determinate whether or it is indeterminate that.
Or it's definitely true, and I mean true and not false and not indeterminate that and so forth.
And so it's really useful.
It just requires something that we can't assign a real meaning to in English.
So just going back to the original question, we have several different systems of logic.
And you've just shown another one and sometimes we define some logics in terms of other logics.
So why doesn't that show that logics can be defined conventionally
so long as the conventions are based on other logics?
Like why can't you just kind of do a circle?
Well, good question.
There are a lot of contemporary logicians who think, yeah, logic is true by convention.
And indeed, you can see it as soon as you move to some of these other logics
and you think, what convention should we establish?
In fact, just the idea that we could have more than two truth values
makes you think, ooh, what should we say that about and, about or, about not in such a logic?
And it feels, in many cases, as if you're being asked to define certain conventions,
not as if you're being asked to presuppose what we already mean or already do.
And it certainly has that feeling when you are characterizing something like quantum logic
or certain other logics for highly specific purposes.
So it is a defensible position.
But now let's get back to Klein's objection.
How would he object to it there or here?
It's not going to be on the basis of this, although that's very tempting to say,
yeah, look, it's somehow filling that in that we're establishing convention.
Here it has that feeling strongly because this isn't capturing the meaning of anything we're presupposing.
It's not like, oh, come on, we were all using the post negation all the way along, right?
No, we weren't.
But in this case, let's go back to this because it's a much simpler case and then we'll proceed back.
Here, what is this first row of the table?
How do I explain what's going on in the first row?
I said, suppose A is true and B is true.
A is true and B is true.
A is true and B is false.
A is false and B is true.
Just in explaining what the table was, I used and, right?
And I don't know how to avoid that.
So I've already got and sort of built in here.
That seems very odd because you could do all of those, do all the tables just like you said with just and,
but and is not logically complete, which seems very strange, right?
You can base it all on something not logically complete.
All right, good, good, good, good.
Yeah, notice what I, in this example, and really with any of these where I use the schematic letters,
it looks like, what am I presupposing?
I'm presupposing something about universal quantification,
whether I state it explicitly or whether it's really just in the background by me using letters like A and B.
And then here, do you even explain the row of the truth table?
Before I get to this, I've got to be using and.
And we've seen that here.
I've got both A and B so I can do A and B, etc.
I suppose you could argue, I've presupposed it then.
If both of these are true, then that's true.
So maybe I've presupposed if in that way.
In fact, once I get over to this, here I've just got A, right?
So I've got presupposing and.
But I am saying if A is true then, this post-connective applied to A is indeterminate.
And so I seem to be presupposing if then.
What about not?
When we got to negation, it looked like I had to say something about not.
I had to say not A is true if and only if A is not true.
And so maybe I've presupposed not.
But now if I've got all of that, I do have a functionally complete set.
So you're absolutely right that if I look at individual ones, I'm not using all of those.
I might, depending upon the way I'm doing it, be committed to let's say here all and and maybe if then.
But that's not functionally complete.
Only certain things are going to actually require negation.
And then I'm going to end up presupposing the whole thing.
If you did the truth table for the shephard stroke to build an entire logic counter, would you need all a logically complete thing to define it?
That's a good question.
Would you need the not?
Let's do it.
Let's do the shephard stroke, which is the not and.
So it means basically not both A and B.
Well, if you've got both A and B, it's false.
Here, you don't have both A and B, so it's true and true and true.
Now what did I presuppose in doing that?
Well, I said if this and that, then this.
So I've got and and if.
I've got the schematic letter, so I've got the universal.
Did I ever need the negation?
Did I ever have to presuppose negation?
Since this means not and, you'd think, surely I did, but how?
You might think it's already implied and false, but not necessarily, right?
Because we don't have to think of false as just not true.
And the possibility of many value logics indicates why we might think that's not right.
But for example here, I said if this is true and that's false, then this is true.
It didn't seem like I had to use negation there.
Now in thinking about, right, I did.
I had to think, oh, it means not both A and B, so here they are both true.
So if this is not true, it's false.
That went on in my head, but in terms of actually just stating what the convention is, I didn't have to do.
So I think it's kind of interesting that I don't at least see why this presupposes not.
Does it also presuppose truth values or would that not fit under there?
Well, yeah, it does presuppose truth and false.
So true and false get in here too.
And I suppose you might say, look, there's got to be someone there.
Moreover, if I've got false, then actually, can't I define not?
Some people have tried to do that and said, yeah, not A, for example, is just if A, then false.
And so if that would work as a definition of negation, then by having false in there, I can actually already get negation out.
But anyway, I think it's a good question you're raising and something to climb in both of these papers just glides over quickly.
Just like, oh, well, it presupposes logic.
I can't state the convention, I can't apply the convention unless I've already got logic.
But that's really sloppy.
What I need depends on the nature of the convention, right?
And maybe in the end, I need all the first order of logic.
But maybe I don't.
That's something that really has to be argued for.
It's not just something to vaguely allege.
So thank you for raising these questions.
And if it seems like I've gone off on a long logical regression here, not really because the whole idea here is that in stating these conventions,
we're presupposing not just a little tiny fragment of logic,
but logic, period.
And so it matters what we're actually presupposing to evaluate points of time.
Now, let's move on to math.
It's supposed to be okay to worry about the conventionalism of mathematics.
Again, he's not committed to the claim that math is true by convention,
but just that the question makes sense for mathematics.
So actually, before we get to that, maybe we should do physics.
What's wrong with saying that certain things in law in physics are true by convention?
Now, nobody's going to want to say, oh, physics is true by convention, right?
It's obviously an empirical science and there's a lot of experimental stuff and observation required.
But could there be certain things that are established just by convention?
You might say, for example, in classical mechanics, well, let's say Newton's laws of motion, right?
One of them is force is, I'm going to keep writing things low in the blank,
force is mass times acceleration.
Now, is that an empirical claim that requires observational backing,
or is it a definition of force?
Is that something that we could say is true by definition?
All right, suppose we say it's true by definition.
Now, what does that imply about certain other things?
What's another physical law that involves force?
Well, for example, work is force times distance.
Is that a definition?
All right, suppose we say it's true by definition.
Then we've got work is equal to, well, gosh, distance times mass times acceleration.
And presumably that now follows through our definitions.
That's just an analytic truth.
Well, what about this relationship?
Kinetic energy is equal to 1 half mv squared.
Is that a definition of kinetic energy, or is it an empirical claim?
I don't know.
Moreover, how about this?
Momentum is mass times velocity.
It's not very clear what I should take as a definition.
Now, I can axiomatize physics in the way that I might axiomatize geometry,
but the point is that it's sort of arbitrary which of these I take as definitions
and which I take as actual empirical claims.
And his point is, in a certain sense, physics stands or falls with all of these.
It's not as if, well, for example, I've chosen this example, Newtonian mechanics,
in part because we now think this theory is wrong.
We teach it to all our high school students.
We teach it to people in intro physics classes in college, but it's false.
Now, why is it false?
Well, because the speed of light should really be in here.
We need to distinguish between inertial mass and rest mass.
And so forth.
Now, where's the falsehood?
You might think, ah, certain of these things are just analytics.
So the falsehood all has to be in the empirical claim,
but that seems a scurry way of doing it.
The fact is we have to just figure out where to make adjustments in the theory.
And for example, this is one of the places we can make some adjustments typically.
And so if we start adjusting that in relativistic mechanics,
you might say, well, maybe that really wasn't a definition.
Or you might say, maybe our concept of energy has changed.
Certainly our concept of mass has changed when we distinguish rest mass from inertial mass.
So in a way, here, Klein's point is just, it's not that it's unintelligible.
It's just arbitrary.
There's this great line that says, asking which of these physical claims are really axioms
and are really definitions, is really kind of like asking which points in Ohio are starting points.
Okay? And presenting the theory, I can introduce anything as a definition that I want,
as long as that's the right logical form.
And then other things will emerge as empirical claims.
But it's really kind of arbitrary how you would do that.
It's not like some of these are just obviously definitions and others are obviously empirical claims.
So we adjust that with our presentation of the theory.
Just as we do in geometry, what should we take as the axioms of geometry?
Well, you could take all sorts of things as axioms of geometry
and then derive other things as theorems.
There's nothing about a certain kind of claim that just says, oh, that's going to be a fundamental axiom.
What we take as basic is just a matter of how we present the theory.
But Klein's point, on the other hand, is just that, look, in the end, when we change a physical theory,
it's not like certain things are analytically true and are off the table.
We have to figure out how to adjust things in the theory.
And some of the things in the theory we keep, other things we throw out,
sometimes we take one notion and replace it with two notions
and in short, draw a distinction we hadn't drawn before.
And there's no way to predict which of these things are libel and empirical challenge
and which ones are immune from that because they're analytic.
Do any of them have to be definitions or can they all be empirical?
Yeah, they can all be empirical. We don't have to make any of them definitions, right?
And in a sense, Klein's point is that in the end, yeah, that's really the right way to say it.
I mean, if I'm writing a physics textbook and I want to present some as really just defining the term momentum,
let's say, or defining this or that, then okay, I can do that.
I can do that as a matter of my presentation.
But that's a question of how I'm presenting the theory.
It's not like that's something that is fundamentally true with the nature of the subject.
So, for example, in thinking about actually every day in class how to come in and talk about what I'm going to talk about,
I think, well, where do I start?
But it's not as if I look at the subject matter, in this case the Klein-Karab debate,
and just see, aha, there is the foundational question.
I try to identify what I think the foundational questions are,
but in terms of my presentation, where do I start?
It's not like I look in and just find starting points in these debates.
I have to think how am I going to structure this, how am I going to discuss it and explain it,
and I pick a place to start.
And in short, it would be like that.
So, it's not as if in the physics book we couldn't introduce any definitions.
It's just that we're doing that as a matter of presentation, as convenience,
not as a way of reflecting that there really is a distinction in the underlying physical claims.
So, I suppose in that sense it could be easily misconstrued.
It could be, in a way, a bad idea in a physics book to say, ah, just true my definition of that,
because that sort of implies that it's really true about the claim rather than just my way of talking about it.
And indeed, physics books generally don't.
They're wise enough not to think, oh, this is a definition of force,
or a definition of kinetic energy or something.
Now, we should end with mathematics.
What makes this question intelligible for math?
Well, all math adds to luck, as we saw last time, was that.
And then other things that can be defined in terms of membership.
All we need really is sympathy.
So, how can we introduce that?
Now here, Klein says, actually, at this point we are doing something like preceding my convention.
Does my introduction of that actually presuppose sense?
He thinks it doesn't.
And so, I don't fall into the trap of logic falsification.
On the other hand, neither is it purely arbitrary,
because after all, I'm not just dealing with a bunch of empirical claims.
In characterizing the world of sense, I'm not investigating sense.
It's like, oh, there's a set of students in the room.
Let's study the set.
I don't do set experiments like that.
Instead, what do I do?
Well, I'm characterizing an idea that I'm going to affect making up.
So, what would I actually do?
Well, I characterize that theory.
We talked about this some last time.
But today, maybe we should do it a little more officially.
Here is a principle that we tend to adopt.
Extensionality.
And what it says in logical terms is that,
well, it establishes an identity criterion for sense.
It says, for any sense, x and y,
equals y if and only if for all z.
z belongs to x if and only if z belongs to y.
And so, to put it in English, sets are identical
if and only if they have the same members.
Now, notice that in doing that,
I am certainly presupposing logic, right?
I'm assuming you understand universal quantification
and if and only if and something about...
Well, actually, identity is being defined here.
That's not being presupposed.
Even though what I say this way, the same members
might make it sound like I am,
but really, I can characterize that
just in terms of the if and only if and the all.
So, this is presupposing logic.
And so, what it says is an arbitrary.
Well, no, not really.
I mean, I can treat it as a definition of identity
with respect to sets, or I can treat it as a claim,
a substantive claim about the nature of sets.
But the fact is, it does feel like I'm establishing
a convention that lays down what a set is.
How is a set different from a property, for example,
where this is not true?
So, it does have the feel of a convention.
Now, is it exactly a convention?
Do I have to be a convention when it's about it?
Well, no.
I can argue that there is an underlying truth
about sets and so forth.
So, he doesn't want to say this question is decided,
but it's not absurd to say I'm establishing
this by convention.
It's not really arbitrary, because I do need...
I do need that identity conditions for sets.
And moreover, it has the feel, it's a stipulative definition.
Remember, stipulative definitions are ones that
you thought actually do a set or something like an analytic claim.
Why?
Because I'm just saying let blah, blah, blah.
I introduce a term and I just define it in a certain way
and I'm not trying to capture previous uses.
I'm not introducing this in the context of a broad
mental understanding.
I'm just saying, let this be that.
Let a metric space be blah, blah, blah, blah, blah.
And that defines a metric space.
I'm just introducing the term in that way.
It's not like I have some previous terms up the map.
Yeah.
But isn't the set symbol in the definition?
The set symbol is in the definition.
Oh, I see what you're saying.
So, wait a minute.
Why don't I presuppose sets?
This seems like twice as clear as the logic
of why I would presuppose.
Yeah, right.
What I end up doing is introducing a bunch of different
axioms, all of which are going to involve this symbol.
And so now I end up saying, yeah, really, I can treat it
as a definition of this, but what about that?
Am I presupposing the sets in all of this
by putting in that symbol?
I think the claim is meant to be, no, I'm giving you
a bunch of statements about that symbol.
And then that symbol is supposed to be defined as
whatever those claims are true of.
That's silly.
But, yeah, that's a doctrine called implicit definition.
Russell was, well, other people were fond of it, actually.
At one point, Russell said it had all the advantage
of theft over honest order.
And so, in a way, that's why Quine thinks, look,
it's a meaningful question, but it would be possible to say,
can I treat it that way?
His claim is that that isn't presupposed.
It's in part characterized by this.
You could do the same thing for logic, though.
Right?
Couldn't you do implicit definition and just call it
implicit and say it's not presupposed?
Whatever.
Yeah, yeah, well, that's a good question.
Unfortunately, we're past off time.
So, next time, we'll think about that question
and we'll look at Karnab's paper,
Comparison of Autism and Autology,
and see how he tries to avoid it.
