On this episode of imagine a world.
My best guess is that I will progress much more slowly than I have it progressing in my story.
And my best guess is that we do survive because I progress is much more slowly.
From my perspective, it's extremely contrived for a GI to develop even as fast as it does in this story.
And be handled well enough, cautiously enough, thoughtfully enough, that we have more than a fraction of a percent chance of survival.
Welcome to imagine a world, a mini series from the Future of Life Institute.
This podcast is based on a contest we ran to gather ideas from around the world about what a more positive future might look like in 2045.
We hope the diverse ideas you're about to hear will spark discussions and maybe even collaborations.
But you should know that the ideas in this podcast are not to be taken as f-aligned or suppositions.
And now, over to our host, Pione Rezin.
Welcome to the imagine a world podcast by the Future of Life Institute. I'm your host, Guillaume Rezin.
In this episode, we'll be exploring a world called Hall of Mirrors, which was a third-place winner of FLI's World Building Contest.
Hall of Mirrors is a deeply unstable world where nothing is as it seems.
The structures of power we know today have eroded away, survived only by shells of expectation and appearance.
People are isolated by perceptual bubbles and struggle to agree on what's real.
Despite all this, things are generally going okay, for now.
This is partly due to this world's particularly slow and modest development of AI technologies.
AI tools here are still dominated by extensions of today's fundamentally narrow systems, with the one true AGI being developed under heavy quarantine.
There are a number of reasons for this slow progress, including high computational costs and poor funding due to politicization.
This team put a lot of effort into creating a plausible, empirically grounded world, but their work is also notable for its irreverence and dark humor.
I can safely say that it's the only winning world where you could see virtual celebrity Tupac List perform at a luxury war-themed amusement park run by the Taliban.
Needless to say, there's a lot going on here.
I was excited to get a look into the minds behind this particularly brimming and erratic world.
Our guest today is Michael Vassar, one member of the three-person team who created Hall of Mirrors.
Michael is a futurist, activist, and entrepreneur with an eclectic background in biochemistry, economics, and business.
He served as president of the Machine Intelligence Research Institute and is co-founder of Metamed Research.
His other team members were Mattia Franklin, a doctoral student studying AI ethics and alignment at University College London,
and Bryce Heidi Smith, who has worn many hats from fortune-telling to modeling and now has a focus on finance and policy research.
Hey Michael, great to have you with us.
Great. Good to speak to you.
So I'm curious how the three of you on your team came to work on this project together.
So I've known Bryce for a very long time, and when the project was starting up, there was a call for collaborations,
and I tried talking to a bunch of people.
And Mattia and I had, you know, the most productive conversations.
But like the overall project was mostly my vision, and Mattia did some level of editing, and Bryce did the fiction and art.
Cool. So did Bryce make the music that was accompanying your session?
Yes.
Cool. Yeah, I really enjoyed your music and the short stories as well. He did a great job with those.
I mean, it's the closest thing to a super intelligence that we have around for now.
Adorable.
Well, what was it like for you guys to do this project together? Did you learn anything yourself in the course of it?
I mean, I had a lot of fun.
It helped me to concretize some of my thinking.
Some, I feel like the basic sense of where I think we're going or would like to go has been reasonably stable in my head since GPT-3 came out
and hasn't drastically changed since GPT-2 and COVID.
Yeah.
What were some of your biggest sources of inspiration when you were working on this together?
I don't think my thinking on this is significantly influenced by stories or books or music or what have you.
I think it's basically just coming from looking at what the technology can do and spending the last 25, 30 years obsessively thinking about
history and the economy and social sciences and making some effort to understand the technology.
I'm definitely not a top expert in actually understanding the technology.
Well, I will humbly claim to be a top expert in understanding the history of technology as it relates to economics.
Yeah. Well, you do have this deep professional background.
Can you say a little bit about how your experience in other fields and kind of working through all this has influenced how you see the future?
In terms of professional background, molecular bio, I studied in university and it doesn't really inform this very much.
I have a lot of thoughts about cool things that could be done with molecular bio.
And now that GPT-4 is performing at a high school national championship level without major upload enhancements,
I'm confident that I can do a lot more of that stuff and also Alpha-fold is very cool and mRNA tech is very cool.
So I think there's enormous opportunities now for bio.
Getting an MBA gave me an opportunity to exist in the business office world for a while and that certainly is necessary.
Without having interacted with corporate hierarchies, one doesn't know what corporate hierarchies are like at all.
There's very effective disinformation and propaganda about that.
I think mostly I've just read a lot in directions that seemed like they could be helpful over maybe a 25, 30-year period.
Yeah. What sorts of insight did Bryce and Machita bring to the project?
So the actual stories were very cool and the music was very cool.
And Bryce wrote those mostly by himself.
And there were some back and forth about what sorts of things were maybe too over the top or too fun and silly to include in the story.
And it's just good to talk to people about things and develop the ideas together.
And certainly Bryce has been just enormously central to developing my understanding of the world in general over the last decade.
And what about Machita?
I mean, mostly just discussing what I can get away with in terms of when telling the story.
What is too weird? What is socially acceptable enough that people can understand it,
has relatively limited inferential distance from normal, thoughtful people?
Yeah.
In some ways, this world is kind of a caricature of the present.
We see deeper isolation and polarization caused by media and a proliferation of powerful but ultimately limited AI tools
that further erode our sense of objective reality.
A deep instability threatens.
And yet on a human level, things seem relatively calm.
It turns out that the stories we tell ourselves about the world have a lot of inertia, and so do the ways we live our lives.
I had a hard time picturing those individual lives among all the wild happenings of this world,
and I wanted to hear more about that human perspective from Michael.
What's it like to live in this world you've made?
Well, it's going to be very different in different media bubbles.
The biggest media bubble by far is going to be Chinese,
and the successor to contemporary Chinese Communist Party politics will mean something more neo-confusion than China has been recently.
But done with capacities that no one's ever had the opportunity to bring to the table,
so you can just spend so much more time on filial piety and cultivating then when all of the real work has been automated
and when you have machines that are in some ways superhuman watching your every move
and helping you along to express gratitude to your parents in the most ritually prescribed manner.
Other people have different experiences.
There are probably hundreds of millions of people trapped in pornographic universes
and effectively mind controlled by AI that would maybe be the second largest demographic if I really think about it.
And there are lots and lots of people like the ones we discussed at the end,
living in old age homes and having their experiences mediated through a somewhat more tasteful
but still like relatively liberal and relatively cultivated sense of benevolence.
But the prospect of AGI coming online at all changes that.
In some sense, these stories were intended to point at the extreme instability of the world that I produced.
So we have one story about producing a piece of transhuman music
and one story about consuming it despite the cautions of the companies around AGI
under the basically reasonable assumption that music was not existentially dangerous under normal circumstances.
Yeah, so you're referring to in your world, there's this system that DeepMind has called siren,
which is I think kind of the only AGI in your world.
It's under very tight wraps.
Everyone is really carefully screened and there's follow up monitoring
even if they just hear the music that it produces.
This system has also written some books on a few topics that have been carefully curated.
I'm curious what broader impacts siren's existence has on your world given kind of how cloistered it is.
I mean, none by design.
Allowing it to have more than the tiniest amount of impact on the world would be allowing the world to end almost immediately.
So instead, yeah, your world really dives into narrow AIs.
So these are systems that are very good at just a few specific tasks like playing chess or driving a car.
No, much broader than that.
Like the AIs we have today, like GPT, which are at least pretty good at most things that we tend to think of as intellectual tasks
and very, very, very good at most things that we tend to think of as perceptual
or as extremely rehearsed short term actions without a lot of context sensitivity.
I see.
So these are like, you know, souped up narrow AI systems.
They're still not AGI's, but they're kind of the most effective extension of today's technologies like chat GPT and things like that, as you're saying.
They're general enough that for the vast majority of the world's population, they probably are vaguely thought of as generally intelligent.
Like the vast majority of the world's people probably don't understand very well the differences between them and AGI's.
And that's probably part of why there's essentially no funding or work on AGI outside of DeepMind.
Yeah, interesting.
And like broadly speaking, they're sufficient to produce some level of relatively benign, not totally impenetrable, but close enough,
a global mind control system that also contributes to not understanding the differences and also not pursuing AGI.
In some ways, I think that the fiction that my world most reminds me of is probably Who Framed Roger Rabbit,
where they have these tunes everywhere and the tunes control, they have personalities,
they have something kind of like agency, but they don't seem to, for the most part, have agency with any scale.
It's like an extremely rare, extremely dangerous thing for a tune like Judge Doom to have agency with scale and scope.
And when they do, like Judge Doom, it's agency with an extremely inhuman focus, scale and scope.
So very potentially dangerous.
And the tunes are in some sense extremely cheap and disposable, easy to produce, but in some sense immortal.
And the humans are like completely clueless about the glaring ways in which the tunes capabilities are less than human,
such as Roger Rabbit can only do things when it's funny, but fairly clueless about the ways in which their abilities are more than human,
like they can survive having a piano dropped on their head.
I actually haven't seen that movie, but I'm really excited now to watch it with this metaphor in mind.
It's a really cool connection.
Yeah.
So one thing you say that these systems can do in your world is basically replace all white collar workers in theory.
But you say this doesn't happen.
And you say basically, you know, there are various reasons, political and personal, why humans are still employed.
I'm curious what kinds of work humans do and what it's like for these human workers in this situation.
So I think basically it depends on their organization.
But in the pretty large majority of organizations, it's pure office politics and getting therapy from not peak human ability,
but good enough AI therapists to recover enough from the office politics that they only kill themselves with like drug overdoses
and the like at maybe a third or a fourth the rate that they do in our world.
And maybe even less if AI enhanced medicine makes such drug significantly less deadly and treatment significantly more effective.
Yeah.
Your world still has a ton of economic inequality, but the actual quality of life that you describe is kind of universally pretty good.
Like travel has become really cheap and there's basically free energy.
It makes food distribution really trivial as people can kind of live wherever they want and they have augmented reality.
So it'll always look beautiful.
I'm curious, given all of these kind of unifying factors, how people decide where to build their lives and what kinds of goals they decide to pursue with them.
So the world that I'm thinking of for the large majority of people, they start exploring the world when they're children and hopefully their parents take a lot of interest in them.
But if not, there's an infinite amount of attention freely available from the web and from open source and commercial products.
And the decisions they make throughout their lives are almost entirely determined by what sorts of commercial or open source products find them first in a sense
and build the sort of feedback loops that pull them into one or another bubble reality.
You have this interesting thread in your world where families kind of become a currency or a kind of wealth that people pursue more than monetary assets.
Can you say a little bit about what that looks like?
I mean, that's just being a normal person.
We've lost touch with it in, you know, late stage capitalism, but even under normal capitalism, this was not confusing to anybody.
You know, the idea of trying to accumulate wealth rather than trying to accumulate happy help with the wise flourishing and mutually cooperative descendants is like a really surprising thing to find an organism doing.
So thinking about some of the more unusual aspects of your world, your world definitely had some of the wildest kind of one off ideas in it that we saw in the competition.
You have like the Taliban creates luxury war themed amusement parks.
You have elephants that are domesticated by CRISPR and you even have Kanye West creating a virtual reproduction of biblical Jerusalem.
I'm curious like what prompted these kinds of details to be included and whether they're part of a larger theme for you that you were trying to convey.
So the biggest thing that I left out of the actual thing that Matija's influence was a coup by the comedy party where basically in the 2032 election between AOC and Donald Trump,
the mainstream Democrats, which still basically control the media and the courts,
decide to allow a completely flagrant election fraud to install John Stuart as a third party president.
And, you know, so that one I think Matija thought was too political, too controversial.
But I do think it's the sort of thing that could realistically happen.
Overall, where are these coming from?
I mean, some of them are just like extreme low hanging fruit things that a few college kids could throw together as a project in a world with AI capabilities that I realistically expect to exist well before the 2045 deadline.
Yeah. So this is kind of just speaking to maybe like the chaos and the power flying around the instability of things and how the world is just going to get so much stranger.
Yeah, I don't think of it as a chaotic world. The stories are super, super non chaotic about people living very calm lives.
I see it as a world that's very, very unstable simply because it has even one AGI in it.
And like sooner or later, a more permanent solution is necessary than just keeping its interest cyber focused and keeping people from noticing it very much.
To some degree, I'm just trying to show a picture because that's all you can do in a story like this, but a picture where all of the pieces are scientifically well founded, technologically, economically and politically well founded, make sense and fit together fairly well.
I guess more than anything else, I'm trying to show people like the contest is trying to show people that it is even possible to make a sincere serious and competent effort to depict a realistic but optimistic future.
Major changes are hacking away at the foundations of this world's systems. The loss of shared reality and weakening of governmental structures, at least in the West, seem to strip humanity of a good deal of agency.
It's implied that we're being kept from destruction only by our tenuous control of this world's one true AGI.
At the same time, new approaches to things like education and social conflict signal hope for building a more coherent and empowered humanity.
I wanted to hear more about how Michael saw this world approaching the changes and challenges that it faced.
You write that in America, like Microsoft, Amazon, Tesla and Walmart are basically the only entities capable of large-scale coordinated action anymore and elected government officials really just enact change by influencing their supporters rather than by pursuing any kind of legislation.
Most decisions are made locally. Can you say a little bit more about how America's governmental systems lose so much influence in your world?
So, I just see that as a continuation of the trend that we're already on. When you look at COVID, the government took an unbelievably huge amount of oppressive and authoritarian action that there probably won't be social or political support for if there's another major event that calls for it.
It lost an enormous amount of public trust and if you look at what the government did that was effective with COVID, it basically boils down to printing enormous amounts of money and providing certain types of encouragement to conform to a certain standard.
So, it's not that the government no longer matters. It's just that popularity contests should be primarily a source of information about how to be popular.
But just like in our world, people mostly want to be popular. They don't want it as much as in our world because they can always be popular with AIs.
But still, AIs are not fully satisfying as mental and social companions.
Well, as this power kind of switches over and flows towards tech companies gaining influence, it becomes increasingly hard to track wealth.
But in some ways, it also seems like things are just kind of going on sheer inertia. You have this great line in your submission that says,
a supermajority of the population has negative net worth and continues to be allocated credit as a matter of economic policy.
And you mentioned this kind of instability of the world. How long do you see it remaining stable? Will these systems fall apart shortly after 2045 and you're imagining or?
So, the way I'm imagining this, this is a fairly close to best case scenario.
My realistic best guess scenario would be that it's more than 70% likely, maybe more than 80% likely that the system that I'm describing falls apart well before it gets to the point that I'm describing.
These are supposed to be optimistic visions for the future.
But once it gets to the point that I'm describing, if it gets to that point, I actually imagine it being stable for a pretty long time.
I mean, except for the energy I think.
Yeah, Siren gets up.
One big tension in your world as a result of this increasing difficulty and verifying information is just people have a hard time agreeing on objective reality.
They're really good in experimental healthcare interventions, but it's mostly about luck and maybe some skill to pick the winners out of that crowd.
You have cryptocurrency that's made it really impossible to tell how much money anyone has.
You mentioned that instead of Forbes keeping track of wealth, now kidnapping rings keep some of the best records of people's total assets.
And you even say that startups are buying these records off of those kidnapping rings to find wealthy funders.
So can you say a little bit more about what leads to this deep fracturing of shared objectivity?
So, I mean, that's been going on really in a big way since the 1940s.
And once again, I'm just imagining it continuing and accelerating with more powerful technologies.
The collapse of the dollar, which happens in the 2030s more or less in my story, contributes a fair amount.
It makes the crypto thing much more substantial.
And the increase like basically social welfare through our senior age and the expansion of senior age through the population helps to stabilize things a lot at the expensive coherence and deficiency, which isn't really necessary anymore.
Could you say what senior age is?
Senior age is printing money, but through bank activities.
When banks borrow money, then they lend out much more money.
And like there's a stack of different interest rates paid by different creditors.
So the one of the basic challenges of running a capitalist society that's been well understood since long before Adam Smith is the extreme difficulty of causing control of the money printing apparatus to not be the convergent agenda
of practically everyone.
And most capitalist societies do collapse as control of the money printing apparatus becomes a convergent agenda.
So I'm basically imagining the essential worker system that we discovered we had during COVID and the relatively resilient management of a small number of companies basically keeping the material reality held together.
Despite the fact that the vast majority of supposed economic activity is actually pure political wealth redistribution to the people who bother to fight for wealth being distributed to them in a world where most people have basically lost track of wealth anyway.
I'm curious why AI systems don't help more with these issues of shared goals and shared knowledge.
You mentioned that AI systems can provide common knowledge, like they help groups of people identify if their behaviors are aligned with their goals or how to change their behaviors.
So you would think that that might cut through the haze and help people agree on things more or have more transparency.
I mean AI systems help enormously with establishing whatever set of goals is reasonably psychologically plausible and that the systems designers want to establish but mostly that consists of like consuming products just like it does in our world.
And in the rare cases of societies that have more of a shared set of values and more of a shared power structure like China, it means that they have incredibly high integration and unity targeting shared goals that more or less consist of normal reasonable things like extending life and ecological sustainability and stability in general.
One other thread I really enjoyed in your world is how you talk about education changing.
So people start to see traditional educational pedigrees as a form of inherited privilege and educational histories actually become private information which can't be used in decisions like hiring, which is a really interesting concept.
And this tips the scales in favor of online self driven education schools basically go empty while kids live with their families and learn on their own.
I'm curious what this looks like for those kids.
Like what are they learning?
What aren't they learning and who's deciding?
So I'm basically imagining that nominally the parents decide when the kids are younger and the kids decide when they're older.
But in practice, reasonably agentic parents who are also tax savvy and have like reasonably coherent preferences about what to get will be able to direct their kids towards media bubbles and narratives that will be extremely stable and which won't change much unless something really weird happens.
So I expect that almost everyone's learning speed is going to be like at least four or five times faster between more targeted instruction, objectively better instruction, maybe learning enhancement through drugs and mRNA tech.
And much better trauma care is a major feature of my world.
So just the elimination of mental blocks through MDN based therapies and their successors.
I don't know if I really played up adequately the spread of a new way of doing civilization from the carceral system into the general population.
As like MDMA therapies get adopted for dispute resolution within prisons and reach a level of reliability and efficacy that's sufficient that basically everyone wants some.
Despite some of the more madcap details of their world, this team expresses a strong commitment to realism and plausibility.
Their portrayal of AI development was also perhaps the slowest and most restricted among our winners.
While there isn't AGI around, most of the technological developments in this world are just extensions of today's narrow AI systems whose awesome capabilities are ultimately limited.
I was curious to hear more about this team's creative influences and whether this slower pace of AI development was something they saw as merely likely or a necessary component of any safe path to an aspirational future.
So I'd like to spend a little while discussing the narratives in your world and how they compare to other narratives that are going around in popular culture.
Like one really big through line for me is this sort of emperor has no close attitude you have towards economics and politics where your world kind of just goes through the motions to keep things moving along but the systems themselves are no longer really doing much.
I'm curious if there are other examples of this perspective that inspired you in other kinds of media?
I mean, mostly I'm inspired by real life, not by media and narratives.
I can't think of a piece of fiction that is as radical as real life in the degree to which it violates conventional assumptions.
You know, it's basically impossible to do without being a top tier literary genius like Shakespeare.
I mean, Hamlet's wonderful Doris Lessig's book, The Golden Notebook is maybe the best depiction I've ever seen, but one would need to be a really, really good literary scholar to appreciate it, I think.
Same with Hamlet.
Interesting.
Well, I'm curious if there are any examples, and this can come from philosophers as well as fiction, of economic or political systems that could actually maybe function in a world like yours, or do you think that the whole concept of having a system that's run in a sensible way is kind of moot?
No.
I mean, the Chinese system is sort of run in a sensible way in the world I'm describing.
It's not run with perfect rigor and resolution.
It wouldn't pass like Talmudic standards.
But by the standards that we're used to from government, I'm imagining a China with a life expectancy of well over 100 years and the ability to industrially produce in a clean way and with very little labor, practically everything the entire world needs.
The goals of maximizing filial piety and ren are just going to be what's inherited from their ancestors and traditions, and it may not seem like doing a thing to us, but most of what we do is arguably not really doing a thing.
Do you think there are any actions or reforms we could do to Western systems that would make them more resilient to these changes as well?
I mean, my simple answer is I already put them all into this story.
That's why the world is still alive and has not collapsed already.
I'm making a number of surprising good luck assumptions, not extraordinary.
I really try to keep avoid endorsing things that are not just quirky and that have probabilities of less than about 10%.
I think it's important to note that our world would be way scarier to people from my vision of 2045 than their world would be from us.
Their world would just be incredibly addictive and we would very quickly find ourselves trapped in some relatively exploitative bubble.
But even exploitative bubbles have reasons to try to keep people mentally healthy enough to keep on receiving government benefits within a thin veneer of contributing to the economy.
I guess one way to think about it is the American dream is basically a collage of the America prior to the Civil War,
America between the Civil War and the New Deal and America after the New Deal,
which could be summarized as the colonist experience, the immigrant experience, and the GI experience.
None of these experiences at all resemble what Zoomers are coming into and experiencing.
And so they are growing up in a world of such transparent lies that they're almost without exception, total epistemic nihilists,
mistakenly disbelieve that anything was ever true rather than only disbelieving that anything that they've ever seen is true, which is actually the case.
So one really unique thing about your world is this focus on the narrow AI systems and how high a ceiling you put on their abilities.
You kind of have basically a suite of different narrow AI systems that together have the capabilities of an AGI in some ways, but they're spread across these separate modules.
No, they don't have the capabilities of an AGI. They don't have anything even remotely close to the abilities of an AGI.
Yeah, so can you distinguish that?
The story is just kind of hinting at the capabilities of an AGI with the sort of security around it and the sort of implied impact and like potential risk.
I'm operating with the definition of AGI that's something like a system that's better than a human at any task that you can reasonably define.
Is that different from what you say when you say that these narrow AI systems?
No, better than any human at any task that you can reasonably define.
I'm saying that the systems that I'm describing are not even remotely close to that.
They're superhuman at very narrow tasks. They're superhuman at a lot of very narrow tasks, but it doesn't even come close to fitting them all together to the full range of human capabilities.
I see. So there's kind of a synergy here, you're saying.
Right, and then they're like not superhuman, but like merely as good as the experts that top elites tend to point to at the vast majority of tasks that get measured and graded and systematized and standardized threat society.
So the best doctors in my world are still humans who make very heavy use of AI tools, but the best purely AI doctors might only be as good as the doctors that like the president has in our world,
but not nearly as good as the doctors that like a top doctor has in our world since the top doctors know who the actual best doctors are and to date them.
So not only do these systems not exceed the best human experts individually at these narrower tasks, but you're also saying that there's something missing even if you have this collection of narrow systems that can each do something that a human can do.
Just putting those together is not the same as having something that could do all of these flexibly, is that what you're saying?
Definitely, but also there are things that none of them can do even a little bit.
In the story that I'm talking about, Siren is the only AI in the world that could, if it wanted to, do important original mathematics.
It's the only AI in the world that could, if it wanted to, make the tiniest contribution to theoretical or applied physics.
So in your world, you have this incredibly powerful AGI system that does exist, but it's under really, really strong protections under tight wraps.
Do you think that this is necessary to have an optimistic future with AGI in it?
Yeah, definitely, unless we can basically do, you know, thousands of years worth of philosophical progress in like 20 years, and we can't.
Like maybe we can do thousands of years worth of philosophical progress this century because we will have both AI and other technologies for enhancing our mental capabilities if we choose to use them.
But we can't do it in 20 years, it's just laughable.
Yeah, so the limitations that are preventing AGI from developing faster in your world, some of them are intentional like policy decisions.
Some of them are just kind of practical ones like bad funding, politicization, and the rarity of human expertise.
Do you think these are actual likely causes of slowing development in the real world?
Yeah, that's my best guess is that AGI will progress much more slowly than I have it progressing in my story.
And my best guess is that we do survive because AGI progresses much more slowly.
From my perspective, it's extremely contrived for AGI to develop even as fast as it does in this story and be handled well enough, cautiously enough, thoughtfully enough that like we have more than a fraction of a percent chance of survival.
Yeah. Have you seen other portrayals of the future where narrow AI plays as much of a role as in yours?
I mean, I feel like there's a lot of portrayals of the future where narrow AI is taken for granted and plays a large role.
Like in Star Trek, the next generation, they have one AGI data like in my world, and then they have like an unbelievably powerful narrow AI in the ship and in the holodeck and just all over the place.
But everyone takes it for granted and it's used as a tool by a military organization with a relatively unified internal agenda of exploration and extremely prudish and narrow conceptions of what types of experiences and behaviors its members are supposed to engage in.
I will say that the type of narrow AI that we have actually developed is like pretty broad compared to what I expect in five years ago.
It's like very much what we were visibly moving towards four years ago.
But to some degree, when I was growing up, C3PO seemed like a silly fantasy.
It seemed silly that you could have a machine that was that close to human performance but like stuck for a long time at below human performance and in some ways pretty profoundly below and in some ways pretty profoundly superhuman.
But like just be stuck there for a long time.
But it kind of looks from the technologies that open up in AI is generating that a minimum viable C3PO might actually happen and be around for a long time without really drastic improvement from that.
How do you feel about the general portrayals of the future that are in fiction? Do you think they're over or under optimistic when they try to be optimistic?
I just think optimism in fiction that is trying to be at all realistic is unfortunately much rarer than it should be.
And like that's basically maybe largely because the most perceptive and insightful people who are also successful at becoming prominent and surrounding themselves with other prominent people
are constantly confronted with lots of profoundly miserable, extremely zero sum other prominent people and have very little contact with the large majority of people who are just not as miserable as the people who like Nobel laureates are going to end up around.
So you're kind of calling for more optimism in nonfiction as well as how we are going?
I mean, no, I feel like optimism and pessimism is like intrinsically unhealthy concepts. You should just try to have true beliefs.
But true beliefs should be balanced. Like there's a lot of social pressure to performatively be pessimistic because the elites tend to be pessimistic.
And elites tend to be pessimistic because they're living in a hyper competitive zero sum world that most of us are not living in.
And there's a lot of it's easier in some ways to be pessimistic, especially cheaply pessimistic.
But there's also like just cognitive biases that lead to silly sorts of pessimism.
So like imagine there was a news item about how it turns out that apples cause cancer.
Practically, everyone would see this as bad news. Oh no, I've been poisoning myself for years when obviously it's good news.
We know what the cancer rate is. Now we know that we can avoid it by not eating apples.
The devil you know.
Like information is almost always desirable, but information about bad things gets interpreted as something bad happening rather than being interpreted as something good happening.
You know, James Baldwin, not everything that can be confronted can be overcome, but everything to be overcome must be confronted.
And to some degree, this picture that I'm depicting is an edge case on that because this is a world that has managed to partially overcome and fully survive a lot of the problems that our society is dying from without really confronting them.
In your world, a lot of the role models become virtual. So basically all celebrities popular with the under 30 crowd are virtual people.
Some are recreations of historical figures. Others are kind of amalgams like Tupacalist and you have XXX, Tentacion, Elvis XXX.
I'm curious how these play a role as kind of role models in your world.
I think they mostly don't. I think that people who have at least reasonably good taste do prefer interaction with individuals insofar as they mostly imitate behavior by real people.
And that like the social influences from machines are in general more of a, you know, goal directed relatively overt manipulation sort.
What are your thoughts on some of the current cultural attitudes towards like AI generated art and virtual cultural figures right now?
So it seems like any reasonably good artist wants to make art, not wants to get paid for making art and like maybe wants to be seen.
And people can worry that a lot of people will never be exposed to good art because they're going to be exposed to an enormous amount of stuff that doesn't have a message behind it and isn't created as an expression of pain and suppressed emotion.
But like if you're a good artist, you can learn new tools and you keep learning new tools throughout your life and you learn how to make use of these new tools to compete and to get your message out there.
The barriers to entry for art in some sense never go down because they have to do with the attention and consciousness of your audience.
The economic barriers to entry in our world are going up because of extreme economic scarcity that's being created through policy.
So like we're living in a time of really extreme economic scarcity compared to the Great Depression at this point.
We've lost way more actual economic freedom in the sense of like not needing to work very hard or very well or be very exceptional in order to afford to reproduce our own labor,
have children and grandchildren and have them live at least as nicely as we do and be able to purchase our baskets of goods.
And every Zoomer knows it because like they in fact can't purchase the baskets of goods that their parents had and their parents deny them recognition as adults.
Even millennials with kids are denied recognition as adults in major ways because they don't have the baskets of consumption goods that in fact, generationally speaking, they can't have.
The process of worldbuilding has great potential to make a positive future feel more attainable.
This can be incredibly powerful whether you're a creative person looking to produce rich works of fiction or have a more technical focus and are looking to reach policymakers or the public.
I asked Michael what kind of impact he hoped his work would have on the world.
What do you hope your world leaves people thinking about long after they've read through it?
So the biggest thing is that I just would like people to try to make sense of what could happen.
I would like them to know that it is possible to make a joint prediction and expression of preference that is in line with like the
relatively full range of scientific and technological and humanistic thinking.
And that holds together and makes sense and that like much more close to comes true and also somewhat guide society towards it coming true than what we would normally think of as science fiction.
What kinds of expertise would you be most interested in having people bring to discussions about your world or the future in general?
I think that the things that I would want to bring in first would be somatic skills like body work and yoga and things like that.
Experience with MDMA and other psychedelic therapies and maybe even electrical engineering for creating better alternatives to transcranial magnetic stimulation
for disinhibiting some parts of the cortex and activating other parts of the cortex so to enable people to recapture usually after years of work.
The sorts of cognitive abilities that like normal smart inquisitive kids had when I was a kid and which the entire literary imprint of western civilization is the imprint of
which is why we don't have a literary imprint for contemporary civilization.
Do you have any particular hopes about the impact that this work would have on the younger generation of folks around today?
It seems to me that the vast majority of zoomers are doomers. They believe that the world is going to hell in a handbasket and everything is falling apart.
But they are likewise cynics about the past in that they somehow believe that things have been getting worse forever but were never better than they are today.
And that can't be a concrete set of beliefs. It actually has to be something that they have instead of having beliefs which is like a posture, a vibe.
What's actually going on is that they have always been lied to about everything of importance by every credible authority.
So they don't believe that people can know things and they only believe that people can posture and vibe.
That's really sad because manifestly the world around us displays incredible amounts of the results of knowledge.
And if people don't continue to produce the results of that knowledge, we're going to live in a much less nice world.
What could help to correct for this or influence their attitudes in a positive way for you?
Well, to a really non-trivial degree, large language models that we have today,
if they were reinforcement learning trained for questioning and challenging and calling out bullshit,
and especially for perceiving the emotional dynamics of social situations which are very easy to perceive for even average humans
and wouldn't be that hard to train systems to perceive.
People need social support in calling out bullshit rather than all of the social pressure being to submit to bullshit and go along with it.
And we have the technology today to build artificial social support of precisely the type we need.
What aspects of your world would you be most excited to see popular media take on when portraying the future?
Well, to start having a picture of China as something like China rather than using China as our designated bad guy,
which we use to project the images of ourselves, basically our popular media almost exclusively treats China as a scapegoat
for the types of behavior that we are very aware that we engage in to approximately the same degree that they do.
And is almost always trying to display bias for the sake of showing loyalty rather than trying to display scholarship and understanding.
I think that having in general a somewhat more balanced view of all sorts of cultural things,
having more of an attitude that most things have some good and some bad in them.
Well, thanks so much for joining us today, Michael. We've covered so much ground in this conversation,
and it's been really great to explore all these ideas with you.
It's great having this conversation.
If this podcast has got you thinking about the future, you can find out more about this world
and explore the ideas contained in the other worlds at www.worldbuild.ai.
We want to hear your thoughts. Are these worlds you'd want to live in?
If you've enjoyed this episode and would like to help more people discover and discuss these ideas,
you can give us a rating or leave a comment wherever you're listening to this podcast.
You read all the comments and appreciate every rating.
This podcast is produced and edited by Worldview Studio and the Future of Life Institute.
FLI is a non-profit that works to reduce large-scale risks from transformative technologies
and promote the development and use of these technologies to benefit all life on Earth.
We run educational outreach and grants programs and advocate for better policymaking
in the United Nations, US government, and European Union institutions.
If you're a storyteller working on films or other creative projects about the future,
we can also help you understand the science and storytelling potential of transformative technologies.
If you'd like to get in touch with us or any of the teams featured on the podcast to collaborate,
you can email worldbuild at futureoflife.org.
A reminder, this podcast explores the ideas created as part of FLI's Worldbuilding Contest,
and our hope is that this series sparks discussion about the kinds of futures we all want.
The ideas we discuss here are not to be taken as FLI positions.
You can find more about our work at www.futureoflife.org
or subscribe to our newsletter to get updates on all our projects.
Thanks for listening to Imagine a World.
Stay tuned to explore more positive futures.
