Hello.
My name is Jimmy Cupple, and I live a dual life.
By day, I work at MIT, I'm a researcher.
I work on program synthesis, programs that write programs.
By night, I lead workshops teaching software engineers like yourself how to write better
code.
Today I'm going to talk about something from intersection of both worlds.
Software engineering advice today is confusing.
For anything you read online, you'll find someone else arguing the opposite.
And today I want to ask the question, how do we find a source of truth in software engineering
advice?
This whole situation reminds me of another source of truth.
How do you prevent scurvy?
Scurvy is an ancient disease caused by vitamin C deficiency.
And after thousands of years of deaths, finally the 1700s, a British scientist named James
Lynde, proved in an experiment, the cure, eat citrus.
And so by the end of the century, the Royal Navy had started requiring all of their sailors
to drink lemon juice.
Scurvy rates went from crippling to almost none.
But then, in the 19th century, they lost the cure.
They didn't understand it well enough, they thought, lemons, why not limes, big mistake.
As a result, there were multiple voyages to the polls, as late as 1910, in which everyone
got scurvy and people died.
Now imagine that you are an 18th century sailor, and you ask the powers that be, how
can I prevent scurvy, and the answer comes, eat citrus.
But wait, lemons, not limes, and wait, do not boil it, and wait, do not store the juice
in copper.
If you store it in copper, it's worthless.
This is kind of starting to sound like witchdoctry.
Now compare soft engineering advice.
But first, so, before I get there, so from this, I coined the term citrus advice.
The advice to eat citrus is good advice to save people, but it was not precise enough
to capture the reality, and so it came with this long list of caveats that made it hard
to use.
The precise advice is to get vitamin C. And while it took about 200 years to get from
citrus to vitamin C, this is the ideal to be aiming for, the simple thing that explains
all of the caveats.
Now compare soft engineering advice.
The guru says, discover abstractions to make your code shorter.
Okay, I abstracted my code.
No, that is the wrong abstraction.
Duplication is better than the wrong abstraction.
Well, then how do I know fend an abstraction is a good design?
Well, you see, good design leads to simplicity.
Okay, I simplified my API.
No, you broke your API.
And if you break your API, that creates complexity for other programmers.
So this advice, not so easy, it's citrus advice.
And I think that if you were to take these four people, three people, these are all close
to but not actual quotes by these people.
If you were to show them the same piece of code and ask the same question, you would
get similar advice, which goes to show you that they have some deeper intuition about
some deeper reality that these words are not precise enough to capture.
So how do we get to more precise engineering advice?
Many years ago, I got really into program synthesis.
Program synthesis is amazing.
You like, it's this program where you just give them stuff, like you tell what you want
to do, on this input you should do this, maybe here's a little bit of information on what
the program should look like, and it thinks for a while with its algorithm and it gives
you a correct program.
It's cool.
But a really nice thing is that you cannot be as a synthesizer.
You cannot be as a synthesizer and you cannot be as a synthesizer.
If you ask a programmer, hey, Bob, if I do this thing, will it make it easier for us
to program later on?
It can be a pretty vague question, hard to answer.
But if you ask if I do this this way, will it make it easier to synthesize?
The algorithm is on paper.
You can just look at it, get an answer, and if you want to know if I have this data format
of the millions and millions of possible code that I can write, is there anything that's
clean?
You can just try it, get an answer, now.
So we're going to look at the parallels between synthesis and human programming.
We're going to dive into the different schools of synthesis.
Marley speaking, there are three kinds.
Non-synthesizers, theorem-proving, logic, enumerative, searching very cleverly through
large programs.
This is how your database optimizes your SQL queries, by the way, and using constraint
solvers.
In the interest of time, we're mostly going to talk about deductives today, a little bit
about constraint-based, no enumerative.
But there is a very important fourth school of synthesis.
And in fact, we have a few hundred examples of them in this room.
That is you.
You are a synthesizer.
You write programs.
And while you might work a little bit differently than these other algorithms, you do not have
the constraint solve in your head, although I do think you do work a bit like the deductive
synthesizer and do that kind of deductive reasoning, there is only one universe of possible programs.
Only one universe of possible algorithms for writing programs.
And so by looking at these other schools of synthesis, we can learn insights that we can
take into our own programming, and that is the thesis of today's talk.
And throughout our journey to synthesis lands, we will see three common recurring themes
of abstractions, constraints, and logic.
Enter deductive synthesis.
At a high level, deductive synthesis is about taking a high level idea, and through a series
of mechanical transformations, make it more and more refined and precise until you reach
an implementation.
So what is the information a deductive synthesizer works with?
When we talk about software, we are saying at one of three levels.
Here is a max function.
You can talk about the run time values, or you can talk about all inputs and look at
the code.
So run time is level one, code level two.
But this is not capturing the why of the code.
It does not explain why it works, it does not explain how you came up with it.
That information is in the logic, in the derivation or proof, and I call this level
three.
As you might guess from the relative size of these boxes, the most information lies
in level three.
But this is the why, this is the stuff that is only in your head normally.
But to a synthesizer, this is just as concrete as the code it outputs at the end.
So let's look at it from the synthesizer's perspective.
So quick background, here is what the deductive synthesizer looks like.
So it has some goal, like I need to get an integer, which is the maximum to other integers.
And you write down a logical formula for what that means, or specify it in some way.
And so our goal is we are given two integers, and we want a program such as after running
the program, then this condition, it is the maximum of the two inputs, will be true.
This tools, it has a bunch of rules that relate a piece of code to the abstract logical meaning
of the program.
And now it can do a search.
So we want this maximum, okay, let's try running the if rule.
Now we know the outer skeletons in if, and we have two sub goals to prove.
And we need to go into the search, maybe try if again, okay, let's try another rule, another
rule.
Maybe using if there was not a good idea, maybe it's trying to assignment instead, ah, that
works, there's my assignment.
Now I know a little bit more about the program, and it keeps going like this, and eventually
it gets the actual program.
So that was 40-year-old consensus nutshell, but you also see this idea in a lot of newer
systems.
If you're at Nadia's talk an hour ago, you saw her talk about an deductive synthesizer
called SYNQUID, Nadia was a post-talk in my lab.
The world of synthesis is very small.
And here are a couple other systems, Lambda squared and Fiat.
All these only do small functional programs because synthesis is very hard, which is why
instead of actually using this today, I'll tell you to not use it, but instead learn
the insights and use it to improve the only algorithms within your head.
By looking at things, this lens, deductive synthesis, we can come up with some deeper
insights to code.
Let's look at specification level notions.
I'm Ronnie at Web App, and I need sanitize strings, no excess attacks.
So to sanitize a string, I escape all single quotes.
And now I have two choices for how to use this.
Before I save my data to this, it must be sanitized, and I can do it either by calling
the sanitize function that I just wrote, or by doing it by hand.
And take a few seconds to look at these, decide whether you prefer option one or option two.
So when I've shown this before, it's a plurality for option one.
A slightly smaller number have no opinion, and a small minority for option two.
And in a minute, I'll give you a sense in which option one is a correct answer, and
there's some interpretations.
But so how else when you might have come to this conclusion?
Well, you might have used the folk engineering advice, and it's like it's more abstract,
but the other is more direct, and this one's hard to do in happening, it's more to understand,
it's easier to change.
And when you're working at this level, it's basically like two lawyers in the podium arguing
with their side, and both of them have case laws to support them.
It's hard to get a real right answer.
And even if you do, it might not be good enough.
So here's an engineer that I used to train, let's call him Steven, and his head is full
of citrus advice, and he looks at this and says, option one, it centralizes the code.
Good job, Steven.
But his understanding of the information hiding was not deep enough, because five minutes
later, I gave him a similar example.
So this time, I have my Twitter box, and I type in 139 characters, and it says too long.
What?
It's because it escaped my string, and it double counted every single quote, because
every single quote became two characters.
So let's not do that, let's undouble count the single quotes.
And I'm very glad that the Python standard library has this count function.
It made this slide easier to write.
But I propose, instead of doing maths, we abstract this counting pre-sanitized string
into a function.
And Steven looks at this, and he says, no.
Option one, it's a mistake in the slide, just say option one, is over-engineering.
This is premature abstraction, evil!
In a moment, we shall see how there is a principle that picks option one in both circumstances.
And if you adhere to this principle, then not only is option two disprofforable, it
is wrong.
And my wrong, I mean compile air level wrong.
This comes to the idea of encapsulating ideas.
And what the f does that mean?
So this is one of those vague things you might have heard before, where once you learn to
think like a synthesizer and actually see the logic it's based on, it becomes very precise.
And so let's do it.
And so through this lens of deduction and deductive synthesis, we're going to see how
option one is preferable in information hiding, how easy it is to think about and how easy
it is to write, and give precise meanings to all three of these lines.
And let's begin just by talking about what we mean by sanitized.
Well right now it means that every single quote is escaped.
And I can write this down formally in one of many notations.
I'm going to use cook because I'm familiar with it, but you can pick any of these others.
And you learned one of these earlier today, that's another session.
It looks like this, says before every single quote, there's a backslash.
And now other modules can use this definition when they're reading about code.
But there's something missing here, which is really that definition I gave a sanitized,
that's just today's definition.
And other modules can use it, but what if tomorrow I decide I need to escape other things?
I've changed the meaning of being sanitized.
Now all this other code, that in the reasoning, use the fact that this is what sanitized means,
those are now broken.
So what I want is to put all current and future meanings of sanitized behind some abstract
predicates.
Let's say I give this string, it is sanitized, what do you mean it's sanitized?
It's sanitized and that's final.
And now this sanitization module can change its mind about what it means by sanitized
and no one will ever know.
It's a secret.
And that is an abstraction barrier.
Do not cross.
Now, and you might have seen a diagram like this before, oh, I centralize my functionality,
I wrap it in a function, you can't expose it.
This is not like that.
This is purely an idea.
This sanitized predicate does not correspond to anything in your code, it's just how you
think about the code.
And on this slide, you'll see exactly how.
So in Cork, you write this idea of an opaque predicate, an existential predicate with the
opaque keyword.
Again, you can do this in about any other formalism, that is, this is the abstraction
boundary but written as code.
And now other modules do not get to think in detail, all they know is, I got a sanitized
thing, whatever that means, it's a black box.
So this is the sense in which option two is wrong.
Because in order to look at that code and read it as a human and say, I'm going to justify
why this is doing what I want, you have to do something in your head, access the information
that sanitized strings have single quotes escaped and nothing else escaped.
And so what it's actually doing is it's piercing the abstraction barrier, do not cross, and
relying on this old piece of information that may change.
Dangerous.
Whereas in option one, all the information about what sanitized means is encapsulated
into the sanitization module.
So maybe the sanitized Stirland function, which is right next to sanitized, is allowed
to know what it means to be sanitized, but this user code is not.
And so thus, it is a secret preserved, it may be changed.
And the same view the sanitized predicates gives us the answer to the first question.
So here, my sanitized function returns, was returned, means it returns a sanitized string,
whatever that means.
And before I save, I have to feed it in a sanitized string, whatever that means.
And so when I put these functions together, they line up.
But when I try to sanitize it by hand, it's like, you gave me a string where you escape
single quotes.
I need a sanitized string.
I don't know these are the same.
What do you mean?
That is a sanitized string.
Oh, no, you can't use that information.
It is opaque, hidden.
It's behind the abstraction barrier, do not cross.
But that's just an interpretation.
There's another way of looking at the program that gives you the opposite conclusion.
Suppose the sanitized function is not allowed to know what the sanitized means.
I don't know what it returns, but you can't show it does not know what that means.
But this other code does know what sanitized means.
Then it works when you do it by hand, but not when you call this foreign function, who
knows what it does.
But of course, there is in the third option in which both are acceptable.
This is the hippie version.
There is no abstraction boundary.
Everyone gets to know about sanitization, those dirty hippies.
And in that case, in both modules, you're allowed to think about the definition of sanitized
and see that these line up and do either.
Now when you're actually programming, you don't write down these formal logic things.
You don't write pre-conditions and post-conditions in gratuitous detail and everything.
No, you have an idea in your head about what you're supposed to do, but it's not given
to the compiler.
And so for all three of these interpretations, all three of these worlds, whoever is allowed
to know what sanitized means, these all result in the same code.
The difference is only at level three in the logic, in the why, not in level two code.
But it's still which one of these worlds you choose is your interpretation determines
which option is correct and preferable.
So is it just a matter of interpretation?
Well, there's some pretty clear, like everything's a trade-off, but there are some pretty clear
reasons to pick option one.
So in option one, I'm all sanitized, and I need a sanitized string for save, so I could
have sanitized x, I need to show sanitized x in order to save it, and this proof is trivial.
Not always is it trivial, but if I'm programming in Koch, I can actually type in the word trivial
period, and it'll say, yep, that's a proof.
And more generally, it can get more complicated when you have aliasing and conditionals, but
it's still going to fall within a fragment of first-order logic called effectively propositional,
or EPR logic, which is generally pretty easy to reason about.
There are fast algorithms.
In the other world, I'm doing this replace all thing by hands, and you show it satisfies
some complicated condition about what goes where, and we can do this, but it's a little
bit harder.
So hard that was only discovered this year.
So in the first case, when I first write sanitized, I still need to prove that when I sanitize
a string, it satisfies the meaning of being sanitized, and so there I need to think a
little bit harder about the sanitized function, but when I actually use it, I can use the
fast EPR logic solver.
It's easy for me.
It's easy for this program to think about, whereas in the other options, I don't have
to clean module boundary, and so when I call save with this complicated by hand, replace
alling, now I need to use the very fancy chun algorithm and think about strings.
It's also easier for the synthesizer, because if I say, okay, I have a string, now I need
a sanitized string, I need to satisfy some condition about what goes where, everything
escapes.
It's like, okay, look, how can I get a sanitized string?
Is there a way to use replace all, is there a way to concatenate things or reverse things?
It has a lot of options to choose from and try in its search.
When you say it is sanitized, what does that mean?
It means no basis.
Then it is only one option for how to get a sanitized string, which is to call the sanitized
function, which exports an interface saying, get you a sanitized string.
And so that is the precise meaning of easier to think about and easier to code, synthesis
style.
So we've explored some correspondencies between the deductive schools of synthesis and you.
We've seen the themes of abstraction in the way that we hid, hid sanitized behind the
abstraction barrier, do not cross.
How does put constraints on the program and what is it possible to write?
And of course, all this is only seen at the level of logic.
Let's look at another example.
How is it possible to write a straight line program, no, no indentation.
That contains a conditional.
Let's find out.
I have a program on the server, returns 496, I swear it returns 1024.
And my friend Stephen sees this code and he sees that if statement and he gets mad.
Because the internet told him, do not use if statements.
Off to the if statements, join the if campaign, if statements are bad.
So it goes back to this code, he gets an idea.
This is in C. That is on server variable is either 0 or 1.
We can replace this if with an array index.
The guru is not pleased.
You have only moved the conditional into the array.
What?
So this is the if advice, a little bit less straightforward than it may have seen.
Let's see what that means.
A quick change of notation.
I'm going to denote the array, 1024, 496 by saying start with the empty array, add 0,
insert 1024, add 1, insert 496.
On top of this notation, we have the array axioms.
I'm not going to go into them in detail, but they tell me exactly what it means for, they
tell me exactly what it means for to index the array.
And it gives me this, it says, that's 1, the index is 496, else let's go deeper to the
array, add 0, it's 1024, let's go deeper to the array, oh, we're out of array, we're out
of axioms, so now it's undefined, but really the only thing you care about is at the bottom
right.
This simplifies to the formula, if x equals 0, the index is 1224, and if x is 1, then the
index is 496.
That formula is conditional, if x is this, then it's that, if x is this, then it's that.
Now using this, we can go back to the program and come up with a logical formula to describe
what the program does.
And we get a conditional, if it's on server, then it's 496, I'll say it's 1024.
And we can use other axioms to do the exact same for the original program, and we get
the exact same formula.
And so there's a sense that both of these have an additional, the same conditional.
And so the synthesizer is only looking at these formulas.
And so from its perspective, these two pieces of code are not just semantically equivalent,
they're actually structurally identical, we haven't changed it at all.
And so conditionals are a semantic notion, not an intact notion.
Just because you don't write the words letters I F, does not mean there's no if statement
in your code.
So the thing that happened here was the array index was conditional in disguise.
Does this mean we should have an anti-array campaign and no arrays, definitely array?
No.
Not every array access is conditional, but the difference is subtle.
And it cannot be purely determined from the code, but it's a property rather of the level
three, how you think about it.
Let's inspect.
Here's another array.
It's a list of all the president names.
And using that, we can define a president after function.
The president after Washington was Adams.
The president after Thomas Jefferson was James Madison and so on.
Here's a pretty simple function that does that.
It totally breaks on bad inputs, negatives, the last president.
Don't tell me about those.
It's a simple example.
And let's talk about what it means index into the array.
And like before, we get a giant conditional at zero, it's Washington, and it's one, it's
Adams, and so on.
This does not look promising, it looks conditional.
But if you already have a notion, an external notion of the ith president, then you can
relate this formula to that.
And you can get the simpler formula, it's the index of the ith, to name the ith president,
which is not involved in any ranching at all.
And now we can use this abstracted formula to look at this code and think about it in
a very short foreign manner, get this index, I can name the next president, and I'm done.
That's how you would think about it, and that's also how a veripyrocynthesizer would think
about it, just like I've written down here.
There's no casework in here, there's no branching.
Just works.
And so that's a sense in which one array index is a conditional and the other is not.
So the difference is that we're able to abstract one and not the other.
And you could abstract the size of the array, find a better way of thinking about it, but
I didn't.
And because I didn't find it's a way, that was conditional, and this one is not.
So we've again seen this insight from the doctoral school of synthesis to the human,
and when you see the abstraction and how we abstracted the array access, this lets us
put extra constraints in a program like death of the statement.
But this only is understood at the level of logic.
Let's go into another school of synthesis, the constraint-based, and this section is
going to be a little bit different from the previous ones.
I said at the beginning that a human and a deductive synthesizer are kind of similar,
and so deductive synthesis can shed light on software engineering advice, whereas the
numerator and constraint-based, they're not like a human synthesizer, so they're just
going to eliminate the nature of the programs themselves.
We're going to be talking about a tool called Sketch, built by my advisor, Armando Suarezama,
and the sketch is about programming with holes, like humans are clever and insightful
and slow.
Synthesizers are dumb, thorough, and fast.
Let's put them together.
You're going to write a higher level of the program, what the program kind of looks like,
the synthesizers are going to fill in the details.
So here's the Hello World example.
That question mark is a hole.
So this thing is asking, find me an integer question mark such that x times question mark
is equivalent to x times x for all inputs.
And you might figure out the answer, it's 2.
And this synthesizer will figure that out, too, after 0.452 seconds.
You can do more complicated things like Sketch, like if you have a really inefficient link
to this reversal, you can get the fast one.
You do need a bit more of a complicated hole than an integer, say, like some number of
statements where a statement looks like this, but it can do it.
So I'm going to give you a two-minute version of the synthesis algorithm.
There's two parts, constraint and solving, and the see just loop.
So it looks like this.
For simplicity, all integers are two bits.
You'll think we have added a moment.
And we can just say, let's look at the bits of the inputs and the hole and the arithmetic
expressions.
And all these give us constraints that the bits of the digits of the plus expression
need to match the corresponding ones in the multiplication expression.
So we get a list of constraints on the bits.
And now we can also write down bits, level formulas for every bit of the plus in the
times.
And it looks like this, some big Boolean formulas, thank goodness there's only two bit numbers.
And now we'll just solve for what the bits of the hole are.
And if you're taking a theory of computing course, you might start getting a little scared.
Because in a theory of computing course, you might have learned that this is the Boolean
satisfiability problem.
We need to find a sign to these bits that the thing works.
That's the SAT problem.
Oh, no, that's NP-hard.
And that is a lie.
Because it's actually NP-easy.
And by that, I mean that modern SAT solvers can take in millions of variables and solve
them very fast, most of the time.
In this case, we're lucky enough to be in the most of the time.
And so we figure out the bits of the hole and we get the final answer of two.
Woo-hoo, synthesis.
But really, it makes it easier to think about if you just pick a few inputs at one time
instead of all inputs.
So on top of this, we build something called the counter-example-guided inductive synthesis
loop, sieges.
And it's basically a conversation between two parts, the inductive synthesizer and
the verifier.
The inductive synthesizer takes some input, takes some tests, gives you a program.
The verifier takes in a program and says, if it always works, if not, a failing input.
So does this work?
No.
It fails this input.
Does this work?
No.
It's a failing test.
Does this work?
Yes.
In other words, sieges is test-driven development.
And from this, I get the idea, maybe you can somehow use Sketch and sieges to tell us
something about testing.
Let's do it.
What we're going to do is I want to see if my test case is good enough.
If it's good enough, if the test pass, my program works.
So is there a way to write a program that passes all my tests but is the wrong program?
Let's use synthesis to find out.
A view of testing is that you have some space of correct programs that you want to find,
and every test is going to narrow down the passing programs more and more, hopefully to
just the correct ones.
But there's something missing from this story.
Here's a very simple kind of program, curves on an xy plane.
Here are my test points, and I want a curve that goes through all three points.
Can you guess what curve I have in mind?
That's right.
It's this guy.
No, no, no.
Here's another test.
Oh, you mean this one?
But if we add a structural constraint that the curve must be a line, then those two
options go away, and the only option is this line.
And not only that, but I need fewer points, fewer test cases.
And programs are just generalized polynomials.
And programs such that this is just generalized curve fitting.
So what does this look like for testing programs?
Well, if you have some kind of structural constraint in the program that you can write,
then maybe you don't need this third test.
So let's put that in action.
So I want to synthesize a function to do something very complicated, the length of a link list.
Here are my three test cases on the left.
And for this, I do need to have some kind of oracle that tells me what the correct answer
is.
Using this, I'm going to synthesize a length function, which passes all the three tests
that I gave it, whether it is some input list question mark, which differs from the
correct answer.
So pass all the test cases, but it's wrong on somewhere.
Let's synthesize.
So first, I say it'll have at most three branches.
Each conditional looks something like this, some reasonable list operations.
Now things can happen within each branch, and let's see if it can come up with something.
And it does.
Sketch produces correct output, not readable output.
And so in order to make sure I have the right program, I need to add another test, like
list of length three.
And now it says, if it passed all the tests, there's no way to make it the wrong program.
But if I restrict my program a little bit, then I don't need that test anymore.
And just the only three tests, I must have the correct program.
So there's all this talk about more coverage, more tests, more precise.
But we don't often hear about writing the simpler code, in that the more one we have,
the less the other we need.
Write simpler code, then you don't need as many tests.
And it's a choice, but I know which end I prefer.
Because there's a saying that quality cannot be tested in, quality must be built in.
And this is what it means.
So we've gotten some insights into writing programs, writing tests from the School of
Constraint-based Synthesis.
And again, we've seen abstraction in our use of this test oracle, constraints in how
we restrict the program space to make it work, and the synthesis algorithm itself is based
on logic.
So we've seen a lot of stuff today.
You've learned the high level of two different synthesis algorithms, seen a lot of stuff
you probably haven't seen before, but really what we're doing is reaching that black box
in your head of how we write programs, and kind of opening up a bit and seeing how it
works.
And in doing so, we can start to stop accepting vague answers for what we should be doing,
start to accept, maybe we can think a little bit deeper about what's going on.
What is it possible for me to write right now?
Sometimes we're on a wild west, not anything goes, there's a structure to what it's possible
to write, and we're accepting that we can find it.
So my hope is that becoming here today, you're joining me all, you're all joining me on a
journey to get away from the citrus advice to become used to, start to learn how to see
the vitamins in our code.
Because the first step, the most important step you've already done, to get to more precise
hard-generated advice, the big step is simply to believe that it's possible, because you
are a program synthesizer.
So if you want to see more about this, check out my blog, I love this stuff.
I also teach it.
I have a web course starting in two weeks.
We have one of my former students sitting right there.
I'd like to thank all the people who made this possible, people who invented what I
talked about, well as organizers, but most importantly, St. Louis is my hometown, and
so we have a very special guest today.
I'd like to thank my father for never telling me that I'm crazy, even when he thought it.
Remember, you are a program synthesizer, and do not cross the streams and do not cross
the abstraction boundary.
So one minute for questions, but I'll stay as long as I have askers.
So let's wait for this to load.
While it's loading, I'll take a hand.
It's loaded.
Let's see, I do not see any questions.
If there are no questions, it's great to see you all today, and I hope you had a great strange loop.
