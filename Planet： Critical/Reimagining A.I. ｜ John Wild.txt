The stated aim of a company like OpenAI
is the development of artificial general intelligence.
Now, artificial general intelligence
is in Google AI terms,
the equivalent of human intelligence.
What I kind of want to point out here,
when you look at what a general intelligence is,
then that's actually rooted in Charles Spearman
and the idea of the G factor.
But Charles Spearman was a hygienist.
And his reason for developing this ranking
of general intelligence
was to rank human intelligence
for selective breeding, et cetera.
So you've got this drive
for artificial general intelligence,
but when you actually work out
what general intelligence is,
it's got some very, very dark histories.
Hello and welcome to Planet Critical,
the podcast for a world in crisis.
My name is Rachel Donald.
I'm a climate corruption journalist and your host.
Every week, I interview experts
who are battling to save our planet.
My guests are scientists, politicians, academics,
journalists and activists.
They explain the complexities of the energy,
economic, political and cultural crises we face today,
revealing what's really going on
and what they think needs to be done.
These are the stories of the big picture.
Go to planetcritical.com to learn more and subscribe.
My guest this week is John Wilde.
John is a London-based artist
who works across performance, sound, text, code, electronics
and machine learning to research the future's imminent
within digital technology.
John joined me today to talk about culture
and artificial intelligence,
how the stories we tell ourselves inform our technologies
and then how those technologies inform the stories we tell ourselves,
getting caught in these kinds of circular loops essentially,
which make it increasingly difficult to imagine a different way of being.
John talks about this in relationship to artificial intelligence.
Artificial intelligence is an incredibly energy-hungry technology.
It is being used for profit motives.
We have very little understanding of what it could do
when unleashed upon the world
and at the moment, all it's doing is threatening jobs
rather than creating new ways of being.
John's research shows what we could do
if we imagined using mycelium as a framework for developing
something decentralized, interconnected, entangled and symbiotic.
To begin with, John explains the history of thinking
and artificial intelligence,
how Silicon Valley is infused with theories and stories
that came out of Russia in the late 19th century,
the desire to pollinate the universe with consciousness,
creating a hierarchy of consciousness,
as if humanity is the only thing that is truly conscious
or would be able to do such a thing as if the universe isn't already conscious.
And he also explains how this hierarchy of consciousness or intelligence
that is directing Silicon Valley to make an artificial general intelligence
comes out of eugenicist thinking.
This is such a fascinating conversation.
We had so much fun recording this.
I knew a fair bit about AI thanks to research into the effective altruist movement
but I did not know the history that John lays out today.
And understanding more of that history makes me really grateful
that people like him and artists around the world
and technologists around the world are trying to think about
how to develop permacomputing or the wood-wide web,
collaborative, interdependent, entangled projects
that reflect the intelligence and harmony of natural ecosystems
in order for us all to live more sustainably with one another.
And we end our conversation with a dialogue on exactly that.
What is sustainable computing and what is sustainability more widely?
I hope you all enjoy the episode.
If you do, please share it far and wide.
And if you're loving the show, become a patron on Patreon
or support Planet Critical with a paid subscription at planetcritical.com.
By signing up, you'll get the Planet Critical newsletter inspired by each episode
delivered straight to your inbox every week.
You'll also have access to the wonderful Planet Critical community
who are full of inspiring thoughts, ideas, critiques and determination.
The links are in the description box below.
I'm so grateful to everyone who chooses to support the project.
I'm a vehement believer in ad-free and open-access content
so Planet Critical wouldn't exist without the direct support of the amazing community.
Thank you so much to all of you who believe in Planet Critical
and keep the project going every week.
John, thank you very much for joining me on Planet Critical.
It is a pleasure to have you on the show.
Well, thank you for inviting me.
Happy to.
As I was saying before we started recording it,
it's such an interesting conversation with Maggie, who platforms you.
And I think that speaking with artists is a really critical component
to understanding what the hell is going on in the world
and what we can do about it,
which leads me to my first question.
Why is the world in crisis?
That's such a big question, isn't it?
I know.
I mean, I'm going to start with a report which was out last week,
which really struck me.
So I read an article by Duncan Agnew in Nature magazine,
which suggested that climate change is having an effect on universal timekeeping.
What?
So Coordinated Universal Time, or UTC,
is the primary time standard globally used to regulate clocks.
So UTC closely follows the rotation of the Earth.
But accelerating melt from Greenland and Antarctica
is adding extra water to the world's sea.
It's redistributing mass around the globe,
and that's causing a very slight slowing in the Earth's rotation.
And if you combine that with what we know about the shift in the Earth's poles,
so since the 1980s it's been shown that the massive melting of glaciers
as a result of global heating has caused a shift in the Earth's axis of around four metres.
So I think, if we think about this question,
the shifting of the Earth's axis and the slowing of the Earth's orientation
are both impressive, to be honest,
but terrifying achievement of human, global, well, geoengineering.
The impact that we've had has basically fundamentally shifted time and the axis of the Earth.
And that seems to be the ultimate mark of the amphipersine.
But I think what troubles me with this,
well, I mean there's lots of things which troubles me with this,
but such a feat could only be the outcome of sustained and coordinated human action and interaction.
Yet no one's planned, organized, voted for, or even imagined such a venture.
And I kind of wanted to start this conversation with a kind of provocation which comes from my own research.
My own research is looking at artificial intelligence, specifically narratives around artificial intelligence.
But what is the coordinating force that's playing a role here?
And I think the provocation that I want to put forward is that it's a non-conscious intelligence,
or an artificial intelligence that we call the market.
I think the market struck producers emergent forms,
which you could call a form of non-conscious intelligence.
Yeah, I totally agree.
What a way to kick us off, by the way.
Wow, I didn't know that, but climate change has been an impact on universal timekeeping.
I was thinking about this question that you asked as this appeared in my feed and I'm like, wow.
But not only that is that universal time, it affects computing
The computer programs made to keep track of universal time are going to struggle with this slowing down of the Earth.
So it kind of comes into the territory that I'm also interested in, in a way.
There's so much there, isn't there?
The idea of having a human system mapped onto a natural system,
the human system impacting the natural system, and then the natural system,
and then being unable to deal with the consequences, to understand even the new reality,
because the limits of that system were so fixed and rigid,
which is kind of a really classic feature of modernity, like there just being no flexibility.
And then watching reality as we understand it just kind of peel away in that moment,
because the systems aren't built for it.
So it really reveals this thread of domination that runs through modernity, like domination over nature.
It doesn't work, the domination over ourselves, it just doesn't work.
It's brittle and it's fragile and it will snap if it's met with enough kind of shifting, evolving resistance.
I guess the challenge that we have is if we understand this as a form of,
or if we understand the market that produces these kind of emergent forms,
as a kind of structural system that as an intelligence that structures human activity, etc.
How do we move beyond that? How do we imagine futures which are structured a different way?
How do we imagine technologies which are, which behave in a different way, which are sustainable?
My own research actually looks at the kind of imaginaries around artificial intelligence.
And I think they can tell us quite a lot really about why we end up kind of looking to the stars rather than looking to the soil, rather than looking to the earth.
That's beautiful.
On this artificial intelligence, I mean this is kind of what Hayek spoke about as well.
The invisible hand of the market directing people.
The sort of godfather of neoliberalism essentially.
I think you were Smith as well, weren't you?
The wealth of nations. I think Smith initiated it and then people kind of took on this idea.
But yeah, the idea of the invisible hand.
Which is interesting, isn't it? Because there's a concept there of like this physical thing being shaped.
But they weren't talking about a brain. They weren't talking about the invisible brain.
Whereas what is directing that hand to move?
The idea is that it would respond to needs or whatever and it's obviously not been the case.
Like we've sort of created a system that is impacted but also impacts its environment around it as it accumulates more historical precedent and knowledge.
And it's just embodied really with historicity, you might say. Kind of like self perpetuates itself and grows and grows and grows.
Well, I think that self perpetuation is the thing.
I think where this kind of connects with the kind of research that I do on artificial intelligence, it's kind of like looking at what intelligence is in some sort of way.
And obviously with the kind of common sense view is this kind of conscious intelligence, the human conscious intelligence.
But conscious intelligence is very rare in the world.
Most forms of intelligence that we come across are forms of non-conscious intelligence.
So this is kind of sensing and acting on the world in a way that produces very complex outcomes.
But don't have at the car this kind of conscious drive that maybe language produces in humans.
Okay, and can we pause there?
So conscious intelligence is rare in the world, but this unconscious intelligence is sensed. Is that the word you used?
Well, I'm saying that for something to act, there's some sort of sensing, some sort of information.
And then there's a behaviour that responds to that which produces complex outcomes.
But I'm thinking there's a good example, or an example that's quite often used is slime mould.
In my own practice, we've also been using mycelium, but slime mould is quite a common one.
So slime mould is a single celled organism which basically produces filaments which stretch out to find food in all directions.
And then when it finds food, it solidifies the filaments that it's produced.
And it's been used to mimic the Tokyo tube map.
So the Tokyo tube, because of the kind of geology of the area, etc.
The planning of it is there's quite a lot of complexity to how to produce the most direct roots.
But by creating an artificial map of the tube using food for the slime mould,
the slime mould managed to calculate the most direct roots, which pretty much mimic the actual Tokyo underground.
So that's the way that you could see that there's a non-conscious intelligence working.
And NASA has used exactly the same model to map the dark matter that holds together the universe.
So these kind of intelligences which aren't a model of conscious intelligence still produce very complex behaviour in the world.
I suppose I'm getting stuck on this unconscious binary.
Because what we're talking about then when we talk about consciousness,
because there's quite a lot of stuff coming out of physics and other theories that suggest that,
well, everything is just consciousness and that perhaps it's consciousness that predates matter.
And thus, perhaps the slime mould doesn't have a brain in the way that we...
Well, it definitely doesn't, right? It's one cell.
But that doesn't necessarily mean it's not conscious.
I guess I'm concerned about...
I agree, and it's exactly the hierarchy of consciousness which I want to break down.
I mean, I'm using the term conscious in this way as a relationship to language
and the modelling of the world as an abstraction of which then things are planned.
But I don't believe this is how humans behave.
I think humans, the vast majority of human activity is non-conscious.
Like riding a bike, you don't have to do the mathematical calculations to stay on the bike and direct and loop, etc.
I think the vast majority of action is non-conscious.
But wouldn't that suggest then that consciousness is only these kind of...
Consciousness is language because maths, for example, could be understood as a language for understanding the universe
or other laws for which words aren't quite useful.
And so does it not then become that consciousness is language and everything else is non-consciousness?
I think so in the way that I'm trying to say it.
But the reason why I'm going down this rabbit hole is because of the drive of an artificial intelligence
to develop what they call AGI, which is a general intelligence which is trying to mimic human reason in some sort of way.
But what I'm kind of arguing is against that in favour of something closer to accepting the intelligence that exists
in all species and plants, etc. on the Earth and recognising the importance of that kind of intelligence.
So I'm kind of trying to make an argument in opposition to the artificial intelligence drive towards AGI.
So assuming this comes back to your beautiful line, you know, wondering why humans look up at the stars and not the soil,
which I think we should unpack as well in relation to this.
I mean, I think a good way forward to that is probably good to introduce myself a little bit in that.
My own research explores artificial intelligence and real-world narratives.
So I'm actually interested in the imaginaries and the relationship between storytelling and imaginaries
and how that has a cyclic causality with technical production itself.
When computer scientists bring something new into the world, it's a creative act.
It's an act of futurism. Our future is it.
You've got to think in the future to be able to produce technology in the present.
So there is a creative act involved in that.
And that's the kind of creation of narratives or imaginaries.
And this has an impact on technical production.
But technical production, like what is possible has an impact on imaginaries.
So you have a cyclic relationship between the creation of kind of speculative imaginaries and actual technical production.
So the two things are different in technical production is rooted in the constraints of the present,
in the regulatory framework, in politics and ethics, etc.
Whereas imaginaries are that kind of creative leap into the future that are used by developers
to basically order, to create goals really for the technologies that get produced.
And by looking at the kind of imaginaries, the kind of stories that circulate within tech communities,
then you can get a sense of where the technical development is going is kind of what I'm arguing.
Go on, do you have any good examples?
I just wanted to make sure that that made sense, that relationship between the two.
Oh, definitely. I think it's just much in the same way when like scientists come on and speak science.
There's a lot of us here that are laymen and I think breaking it down out of some sense quite academic language is helpful.
To talk about how these two things inform each other all the time.
So yes, I have a better understanding there. Thank you.
I think when looking at developer narratives, so the kind of ideas which are driving tech developers,
I mean, these people don't normally come from a creative background.
So where do they grab the imaginaries is quite an interesting thing.
And what my research has found is that a lot of these imaginaries are driven by, I suppose, obviously sci-fi,
but more specifically by the kind of speculative avant-garde movements which circulate in tech circles.
But to name a few, there's cosmism, transhumanism, extra-peonism and effective accelerationism.
Oh, what are they?
Exactly.
So if you delve into tech communities, you'll come across these kind of like quite far out and fascinating ideas.
But what struck me is when I started researching this territory is the massive impact that cosmism has had.
Now, cosmism was a movement which developed in Russia at the end of the 19th century and the beginning of the 20th century.
So to discover that, these ideas from this period, from pre-The Russian Revolution or around the Russian Revolution,
currently has a massive impact on AI and tech developers in Silicon Valley and California is a little bit, whoa, really?
So if I dig a little bit deeper into the ideas of cosmism, I think where it would take us is kind of to answer that question of why the developers looked to the stars.
So, cosmism emerged in Russia at the end of the 19th century and the beginning of the 20th century.
And one of the key figures was a guy called Nikolai Fedorov.
And Fedorov connected his kind of quite strong Christian beliefs with a futurism.
And he believed that the common task of humanity was to end death.
So to end all death, to move towards immortality.
And this wasn't enough because this betrayed the older generations.
So the first step is to kind of end death.
But once you've achieved that, then the next step is to resurrect the dead.
That's the duty of all good sons, sons is to resurrect their fathers.
That's the language he used, not mine.
Sorry, just a very, very quick side note, but it's just fascinating to me that this man, for example, wasn't burned at the stake.
It sounds an awful lot like sorcery.
Imagine if that had been coming out the mouth of a woman, eh?
Please continue.
But anyway, you've got to remember my interest is the relationship between, like, imaginaries and technology itself.
Now, one of his students was a person called Konstantin.
My Russian is appalling, so please forgive me any listeners who speak Russian.
But Sayelkovsky, so Sayelkovsky took on a lot of the philosophy of Fedorov, sorry.
But he took it in a very practical way.
So Sayelkovsky studied kind of the physics of his time and etc.
And he developed some of the first practical designs for, like, the space rockets and the equations required for space travel.
And he did this in 1896.
So these kind of, like, developments in kind of the technology of space travel emerged from following Fedorov,
realising that if you ended death and resurrected the dead, then the planet would get overrun quite quick.
So it becomes necessary to leave the cradle of the earth.
Does that make sense in the logic?
As logic?
Sure.
Okay.
So the reason this becomes interesting is because Sayelkovsky is basically the founder of the Russian space programme.
And the former Soviet space programme.
And his rocket designs are currently, like, I'm not exactly the same, but are the forefathers of our current rocket design.
So you've got this link between kind of quite fascinating and crazy imaginaries, sort of futurist imaginaries,
linked with technology, which ultimately developed the US space programme.
But how does this link with Silicon Valley?
Well, if you look at, say, Ray Kurzweil, you know Ray Kurzweil was kind of the profit for Google's AI programme.
Okay.
I think he's probably a chief engineer, but he also believes in moving towards immortality.
He wanted to be the first person to kind of end death.
So a lot of these ideas that came from Cosmism have been translated directly into the kind of AI tech circles, which circulate.
So Kurzweil is a serious player within the AI world, particularly in Google.
And this idea of extending life or eradicating death is part of the discourse which circulates within this community.
That would be kind of groupings which call themselves extra-peonism, extra-peonists, so I'm not sure how you say it properly.
But these ideas link directly to actual technical production.
So things like the Fitbit and the quantitative self-movement.
So the idea of monitoring your health and maximising health, which you must have come across because that's part of the tech scene.
Human optimisation.
Exactly.
This human optimisation comes out of this attempt to extend life and eradicate death.
So you can see how the kind of Cosmism has kind of plagiarised really right into these kind of tech ideas,
which then find themselves being sold on Amazon as Fitbits or various other optimisation technologies.
Kurzweil himself, in an interview in a film called, what was it, I Human,
declared that one of his driving force for developing artificial intelligence,
and you've got to remember that this is a chief engineer, is to resurrect his own father.
Oh my God.
So you've got Federer repeating himself right at the top of the kind of Google development chain.
Oh God.
And taking a kind of slightly slight side-movia.
But when we talk about artificial intelligence, in tech circles it gets broken down into three different areas.
The first one's narrow artificial intelligence, which is what we have at the moment,
which it's mainly what we call machine learning.
So it's narrow in that it can do very intelligent activities such as playing go, or chess,
or predicting texts, but in a very narrow domain.
But the next, like the stated aim of a company like OpenAI,
is the development of artificial general intelligence.
Now artificial general intelligence is, in Google AI terms, kind of the equivalent of human intelligence.
So it's this ability to abstract and apply intelligence to multiple domains.
So it's wider.
But what I kind of want to point out here is that this idea of a general intelligence,
which is what people are striving for, an artificial general intelligence,
when you look at what a general intelligence is,
then that's actually rooted in what, in the statistician, Charles Spearman,
and the idea of the g-factor.
But Charles Spearman was a hygienicist.
And his reason for developing this ranking of general intelligence
was to rank human intelligence for selective breeding, etc.
So you've got this drive for artificial general intelligence,
but when you actually work out what general intelligence is,
it's got some very, very dark histories.
I mean Spearman developed this to support his colonial, to spark colonial policies, etc.,
trying to prove that perhaps other humans were less intelligent for various reasons.
So you've got this kind of hierarchical drive within artificial intelligence
for basically a superhuman, or an intelligence which is beyond human in that kind of way.
And just kind of, just linking back to the cosmos kind of ideas,
you see that the idea of colonizing the solar system,
or spreading intelligence to the solar system is something which is a core concept
within AI development circles.
I mean it's also the reason why tech billionaires are building their own spaceships,
if you think of SpaceX, Blue Origin, they're all influenced by these imaginaries.
And I'm sure there's probably a lot of people saying I'm over-exaggerating this at this point,
but I just want to give you a couple of quotes.
So this is from Jürgen Schmidhuber,
who developed the natural language model which is used in Apple, Siri, and Amazon's Alexa.
So let me just get this so I can read it properly.
So this is his understanding of what he's doing.
He says,
So I'm not a very human-centric person.
I think I'm a little stepping stone in the evolution of the universe towards a higher complexity.
It is clear to me that I am not the crown of creation, and that humankind as a whole is not the crown of creation.
But we are setting the stage for something bigger than us, that transcends us,
and we'll go out there in a way where humans cannot follow and transform the old universe,
or at least the regional universe.
So I find the beauty and awe in seeing myself as a part of this much grander theme.
I've got another one for you, if that's not enough.
Go on, hurt me.
This is Professor Dr Hugo Degares,
who was the former director of the China Brain Project Institute for Artificial Intelligence.
And he writes,
Humanity has the duty to serve as a stepping stone towards building the next dominant rung of the evolutionary ladder.
And Kurzweil himself says,
Does God exist?
I would say not yet.
Oh, God, right.
So what you get when you start digging into these narratives
is the idea of building intelligence which goes beyond humans
and goes beyond our time frame, our 78-year limitation,
and our body's limitation of living within certain environments like the Earth,
where we need to be within a kind of ecosystem, et cetera,
and can survive out there on the planets.
And it starts to feel like a spiritual movement to spread consciousness to the universe.
So the tech development, as I said at the beginning, looks to the stars.
Whereas I think to solve this problem, we need to start looking back to the soil.
I'm so upset.
Sorry about that.
It's so upsetting.
I think we've got to be upset to disrupt
and start saying we need to change these imaginaries.
You've got to remember I'm coming from an artist's background
and I kind of do a lot of work within the tech sector.
But we have got to be able to create some imaginaries which can compete with these dominant narratives
which circulate within the tech environment.
I have a few things to say on everything you just said.
Number one, these men need therapy.
Those are the words of fairly traumatized people, I would say.
Number one, especially the buggers that want to resurrect their fathers.
I'm so sorry for your loss.
Please go and pay a therapist to walk you through it,
rather than trying to develop a very energy hungry, we don't know what would happen if we released it.
Intelligence thing.
Number two.
The other thing I find really interesting about it is like this.
Oh, no.
Number two, one funny thing before number three.
That bit that you said at the end, when you were quoting these guys,
especially the, you know, I'm not a human centric person.
I consider myself a stepping stone.
It's not about me.
You could just imagine that quote being pasted on top of a cartoon of like one sperm cell talking to the other sperm cell.
And it would totally fly.
It would be really in place there.
And which leads me on to point number three, which kind of struck out to me.
And then what we will get into the imaginaries, of course, but like,
in a culture that is so deeply individualistic,
there is like a lack of individualism in what they are saying in a sense.
And that's fascinating.
What is going on there?
I agree with you.
I think this is like, there's a religiosity for the geosity in what they're saying.
It's very culty, but like to.
This isn't fringe though, by the way.
These ideas are really, really move in these circles.
Yeah.
I think the, yeah, that kind of spiritual that that link back to the kind of cosmos linked to religion.
Is it is definitely there in that it gives people that goal that like this drive towards AI is is a bigger goal for these people.
So you're right.
It's not necessarily that individual thing.
It's that they are seeing themselves literally forming.
Well, they said it themselves, isn't that the next stage in evolution?
No, our spreading consciousness to the universe are ultimately creating God.
So it's funny because they managed to like make themselves as small as sperm cells and yet be still incredibly arrogant.
Like the universe doesn't need you, you know, ejaculating all over it with consciousness.
Likely there is consciousness everywhere.
So it's funny, isn't it?
Because there's like, there's these interesting moments of kind of disruption even in the thinking of like lack of individuality in it.
And yet it's still so fundamentally hierarchical, like running with narrative domination.
That's why I was pointing out the AGI, the absolute link to eugenics in there.
Now, what was how does Charles Spearman link to them?
Is there like, do we have a kind of because, you know, we can walk through the Russian thing pretty clearly.
No, no, no, no, Spearman is general intelligence.
So if you if you look at the stated aims of open AI on their website, and they will tell you that they are developing that their aim is to develop artificial general intelligence.
And if you research general intelligence, that term is Spearman.
Right. Okay.
So that's where it comes from.
And the G factor as a measure of intelligence.
So if we are measuring intelligence with general intelligence, then we're already in the territory of eugenics as an idea.
I mean, I've got a feeling in this territory, eugenics, which goes beyond the human and wants to develop the superior artificial.
Totally.
And I think this, I can do a little linking of Silicon Valley to eugenics is thinking at this point, which is the effective altruist movement, which is very frightened of there not being enough babies of a certain kind being born in the world in an overpopulated world.
And so I kind of like, you know, Elon Musk is throwing money at reproduction research.
There's this like Silicon Valley couple that are planning on having 10 babies and inculcating those babies to have 10 more because they want to they literally want to replace, you know, sort of like, I can't remember what it was exactly.
But in 100 years, I think they could replace like 50% of the United States population at that rate, essentially.
And their purpose here is this.
Oh, well, because they believe that you should be investing in the top 1% of humanity rather than the bottom, you know, 10, 20, 30.
Because it's the top 1% that are going to have the, you know, intellectual reasoning and capacity to sort of fix the world really.
So there is a hierarchy of ability, capacity and intelligence.
And we don't have enough of the smart ones being born, which does equate to white, essentially.
Yeah, of course. Because that's also what the general intelligence historically did anyway, within the colonial, British colonial, I think, experiment with British.
I think you're working at King's, I'll have to reset, I'll have to look that up again.
I mean, I mean, what you're saying there makes sense with the general shape of thinking that I come across as well.
This is kind of like a shift towards like a super, super intelligence.
And there's either the direct mechanical group or there's ultimately the developing the human and kind of the cyborg and kind of shift, really, where you enhance the human to such a level that it becomes the super intelligence.
They seem to be the two directions.
Yeah, that's so interesting.
I don't think I hadn't quite clocked that as being sort of parallel tracks heading in the same direction.
The desire to, you know, birth as many superior humans as possible and this drive to create this kind of, yeah, mechanical.
I mean, I mean, in my list of things such as immortality, et cetera, I actually missed off the human augmentation.
But maybe I should have because human augmentation is definitely one of the things which comes up a lot.
The kind of cyborgism.
Elon Musk himself owns Neuralink.
Neuralink is the company which aims to connect the brain directly to kind of computer systems.
So, yeah, those ideas of human augmentation kind of completely link in with this idea, yeah.
I interviewed Olivia Lizard recently and she was talking about the fact that Mark Zuckerberg has been quoted as kind of, you know, he can't wait to like get rid of his body to get rid of the weight of physicality.
Get rid of the flesh.
Yeah, yeah, yeah, yeah, yeah.
And which of course links into this idea of like, oh, well, if I can upload myself, then I can live forever.
Like, transhumanism, I think, is this stepping stone as well towards immortality and then towards, you know, the ever-expanding stars.
Yeah, those ideas are all inter-connect, sir, in various ways.
But for me, the important thing is these ideas aren't just crazy ideas of crazy people.
These are ideas which are completely embedded in the development of technology, of current technology.
Well, the idea, what I was talking about earlier, the kind of cyclic causality of imaginaries and technology.
Yeah.
These ideas are part of the process of developing our technologies and our future technologies.
So that's why I think as an artist and as a creative that there's an important activist job to be done at challenging these ideas and developing alternatives.
Which is kind of the second part of what we do in our research is kind of carrying out workshops with different communities of people.
Kind of discussing these ideas, but also trying to get people to kind of think what a different form of technology would be.
A technology that does look to the soil, that looks to biological systems, that sees all species as intelligent and doesn't create this hierarchy with a
with a so-called conscious intelligence versus a non-conscious intelligence, which you quite rightly picked me up on earlier.
Kind of like break down those ideas and recognize the entanglement that exists between humans, other species, plants, the biosphere.
Yeah, beautiful.
The interconnectedness, the oneness, which leads to a different kind of, you know, potential for the duality.
The multi oneness.
The multi oneness, yeah.
The multiplicity, the entanglement of multiplicity, which isn't a oneness, but is entangled into, well, as we started off kind of like, our actions do have an impact.
Let's talk then about some of these potential technologies that look to the soil or what happens as well to our own kind of thinking and processes when we look to the soil.
What have you found?
What's good is like working with other communities and getting voices which aren't normally heard within these environments.
And we've done a lot of workshops with, yeah, just all sorts of different people.
But one of the projects which has emerged out of this is a project that I've been working with together with Shira Vashman, which is trying to rethink AI with Mycelium.
I think when I listened to your conversation with Maggie, you raised the idea of Mycelium, which I thought was interesting.
For people who don't know, Mycelium is the organism which produces mushrooms, ultimately.
But Mycelium lives under the soil.
It's an interconnected organism of individual hyphae, which is connecting to a network.
And they remain as that organism as long as there's no shortage of food, etc.
When there is a problem, when there's a temperature change or the area where there exists in runs out of food, they produce mushrooms, which then spur and produce Mycelium networks.
But one of the interesting things about Mycelium is the way that it's evolutionary or some Mycelium, because there's lots of different Mycelium.
But some Mycelium kind of work in a symbiotic relationship with other species.
So the best example of this is the idea of the Woodwide Web, which has been circulated quite a lot, which is the way that Mycelium connects between different trees within the forest.
And sugars and nutrients are shared between different species, or between different trees within a species.
So Mycelium works in symbiotic relationships within the kind of forest environment.
And another example of the way it works symbiotically would be with the orchid.
So orchids cannot photosynthesize while they are young.
So they couldn't exist basically while they're young.
But what they do is they create symbiotic relationships with Mycelium, which provides the kind of sugars that they require in their early stages.
And then when they mature, they become a net producer of sugars, which feeds the Mycelium.
So you get these kind of symbiotic relationships developing mycorrhizal networks between different species.
So by working with people taking Mycelium as a starting point, we've kind of been kind of looking at the way if we were going to think of a technology like AI,
what would that look like?
And I think the question that emerges from our rethinking AI with Mycelium is...
I'm going to read this, sorry.
What if AI significance lies not in competing with us, so planting, or surpassing us in a mainstream AI narrative, as in mainstream AI narratives,
but in fostering complex, ecologically sustainable symbiotic relations with both mechanical and organic intelligences?
We suggest the study of AI should involve a redress of our relationship to other non-human intelligences on the planet.
So that's the kind of outcome that we're kind of developing with rethinking AI through Mycelium,
and we kind of shift it away from the kind of hierarchical model that we've been discussing, and towards rethinking intelligence in this kind of wider way.
And how can we connect to these intelligences, rather than a combative survival of the fittest, eugenicist kind of model,
rather in a model of symbiotic, I suppose, solidarity?
And what would these technologies look like?
So I think one of the first things is that we've got to understand the impact that computing, obviously I'm coming from an AI computing background,
and also this is important to me, the kind of impact that computing itself has on the world.
So computing itself contributes to global heating and environmental degradation.
On some recent research that I read in Nature magazine, it stated that the IT industry could use 20% of all electrical production by 2025,
and that's next year, that's a lot, and that 5.5% of the world's carbon emissions comes from basically the global IT industry.
Now that's bigger than most countries, say China and India, US, etc.
So we've got to take these ideas seriously, and so if we're going to continue developing computer systems,
then we've got to think of how to create sustainable computing.
And there's quite an interesting movement called permacomputing, I don't know if you've come across it.
I haven't.
Like permacomputing is, it kind of takes permaculture as a model, but looks at how we can develop computing in a kind of sustainable and a kind of viable way,
kind of moving away from this ever-growing, storing of data within data centers which use mass amounts of electricity to keep them cool,
and also has an impact on water as well, because like water is used in these kind of large data centers.
Many of which, the storing of mass data is, the reason why we're storing mass data is ultimately to train AI, to train machine learning models.
It kind of comes round in a circle to some level.
The kind of the form of computing that we are developing, storing all of this data in the so-called cloud,
is ultimately collecting the data that is required to train mass machine learning models to develop the AI.
So how can we shift away from this kind of circular model to one where we can use computing perhaps to help solve some of the problems that we have,
we're having with the environment, but that kind of computing itself needs to be developed in a way which is sustainable with the environment.
So that's the kind of thinking that we are trying to develop with our practices.
Wonderful.
This is kind of the reckoning of all industries of the structure and history, isn't it?
How to get away from our legacy, essentially, and reimagine entirely new ways of being in order to survive ourselves.
I think that's, yeah, the ultimate job at the moment is to create these imaginaries, to create the imaginaries so that we've got something to drive for
and develop the technologies that allow for its existence.
And by technologies, I use that term broadly.
My ceiling itself can be a technology if we can use it as a way to understand what's going on within the forest ecology, et cetera.
It is a computer system itself, or a computing system itself, that if we can learn to understand and read.
I don't mean instrumentalising, I mean in a kind of non-destructive way.
Then that's kind of an interesting way to kind of move forward, I think.
Definitely.
I think the third thing we maybe need to bring in at this point, though, is as you spoke about the circularity between the ideas and the tech
and how they inform one another.
We've also got to add in, you know, for-profit motive and private ownership and competitive, the competitive market.
That very first artificial intelligence that you spoke about at the beginning of this interview.
Absolutely.
And whether or not it is possible to, not to reimagine, but to actually create the sustainable solidarities necessary
when that artificial framework will be, sorry, when that artificial intelligence will be moving to shut those kinds of things down.
Yeah, absolutely.
I mean, I think within our project that we've been working on, particularly the rethinking AI with Mycelium, is we've got to think of,
like, if we are developing intelligence, if we were developing AI, then we've got to think about the particular environments that AI has been brought up in.
Like, what sort of ecosystems we are raising and developing artificial intelligence in.
And currently, it's this kind of aggressive, domineering, environmentally destructive, competitive environment.
If you think of the way machine learning is, where it's currently used, high-speed trading, etc.,
then it's all about systems of winning and losing, of profit and loss, etc.
So what would an artificial intelligence look like if it was developed in a symbiotic relationship like a Mycelium?
And I've actually got a good quote from this from Tim Ingold.
But thinking through the social and the way the social is structured, I think, has to play a massive role in how we re-think, say, the market.
Let me just find this quote from Tim Ingold, because it would fit here really nicely.
Please.
Got it. Where has it gone? Here it is.
Okay.
So what Tim Ingold wrote in his book Lines a Brief History is, and his dad was a mycologist.
So this is probably why he's kind of talking about Mycelium.
But what if we take the Mycelium as our exemplar of the organism?
Arguably, the oil of biological science would be different, and so too would the science of society be different, where every person to be considered like the Mycelium as a thing of a line and the social as the domain of their entanglement.
So I think what is arguing for here is a breaking down of that neoliberal individualism that is so dominant within our culture, and to see ourselves both entangled with each other,
but also in a species relationship with the planet itself.
Like, how would we develop science and technology if we could, if we saw the world in these terms of entanglement?
And I think that's quite a good imaginary to kind of base our technology on.
So the image for me that came to mind was a weaving, a weaving of threads, a braiding, which kind of...
It's not a loss of the individual to the mass, but at the same time, it's not a separation of the individual from the mass.
Yeah, weaving textiles is, I think, a good way forward.
It's beautiful. I think if all of reality is relational, which it is, everyone listening, it just is.
And then the more that you braid and weave these relationships, the more that you are literally reinforcing the structure of reality in a good way, you're fortifying it with that entanglement.
And I think that's... I think that's a beautiful note to end on, John.
Yeah, brilliant.
Yeah, I've so enjoyed this. Thank you so much.
I have as well. We've been on a bit of a crazy journey, haven't we?
Hopefully from the stars back to the soil.
Yeah, exactly. Rewind people. Let's bring it back.
My final question for you is, who would you like to platform?
Okay, so the person I'd like to platform is an art activist called Jay Jordan.
So Jay Jordan is perhaps the most committed art activist I know.
He played an important role in the activist movements, Reclaim the Streets,
and was one of the founders of the laboratory of insurrectionary imagination and the clown army.
And he kind of lives resistance daily in the occupied zads in France, the kind of...
So hopefully we can get him on and he can take some of these imaginaries forward in a way of how we can actually take them into the streets and into the fields and turn them into direct action, which he's amazing at.
Oh, that is just wonderful. I can't wait to speak to them.
Thank you so much for today. It was just great.
Let's get together.
