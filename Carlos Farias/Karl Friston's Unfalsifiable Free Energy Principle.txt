You know, you take it something like the free energy principle, you try to think,
okay, what's even more fundamental than that?
What's behind that?
What's below that?
What kind of feeds into that?
I have to say, also, you won't get more fundamental or simple than the free energy principle.
When you realise that your environment is composed of other things very much like you, right?
You're young, you're your mum or as your own or your colleagues and your friends and your family.
I think that's interesting because now we get into a much more symmetrical sort of relationship
between me and the environment and certainly in this context, you know, most of my universe is
basically you and me.
So now there's a certain kind of symmetry in place, whereas you are my environment and I am
your environment and yet we both have gelatine models of our environments, which basically means
I have a gelatine model of you and you have a gelatine model of me.
The best way to minimise surprise when I surprising signal that generated by things like me,
namely you, is to ensure that I am as much like you as possible so that I can predict what you're
going to do next because that's what I was going to do next and exactly symmetrically so for you.
So that basically means that we come to share a gelatine model, a shared narrative,
we're seen from the same PIM sheet and everything becomes mutually predictable.
What it doesn't describe though is the going back to your phyline zone and the man in the nice
hell, the epistemic hell.
So if it was the case that we could become completely mutually predictable and just keep
on singing the same song together for hour after hour after hour, that would become boring.
And at this point I think you're now into sort of social neuroscience and joint free energy
minimisation that can sometimes lead to quite paradoxical results or
understandings of the way that we search for information or engage with people.
On the one hand I want to make my world as predictable as possible so I don't get any
nasty surprises.
So I'm going to go to those kinds of news channels, I've talked to this kind of person
because I think that we have a lined frame of reference, we have common grounds,
we speak the same language.
On the other hand I'm going to be compelled to be slightly curious about other ways of thinking.
It's not, you know, we're not all going to merge into one massive community and we are
one massive hive mind, one massive collective intelligence, it's not going to work because
we are compelled to, you know, what would happen if I looked at it this way?
Or what's that kind of person like?
What's this culture like?
So, you know, I haven't got any answers but there's a really, really interesting
field of information in social neuroscience.
Professor Carl Friston is a world-renowned neuroscientist and researcher.
He is best known for his work in developing groundbreaking statistical methods and mathematical
models to understand the workings of the brain and how it gives rise to complex behaviours.
Our discussion mainly tackles his free energy principle, which states that the brain is
constantly working to minimize the amount of free energy in its system.
According to this principle, the brain is a predictive engine
that is constantly trying to make accurate predictions about the world
in order to minimize its own uncertainty.
If you got this far, please subscribe and I hope you enjoy our conversation.
Professor Friston, thank you for coming up.
Thank you for inviting me.
Yes, it is a pleasure.
For the folks watching this on YouTube, I just want to say they should know that you are one of
the most cited scientists in the world and have made monumental impacts on the field of neuroscience.
So, it is the highest honour, honestly, to be speaking with you today.
And I thank you so much for coming on.
It's very gracious for you.
Thank you.
Yeah. And, you know, your time is very valuable.
So, I do want to jump right into it.
And as we discussed over email, the primary focus of the conversation
will be on your free energy principle.
So, I think it would be awesome as it is discover.
Let's maybe set the table, so to speak.
Could you provide a high level or simple description of the free energy principle?
And then I have a number of specifics to ask you about it.
Right. So, when confronted with that challenge, I normally say there are two ways you can...
I know.
Description.
So, there's a sort of intuitive, low-road approach, which I'll describe first.
And then there's the appreciation of the principle through the lens of a physicist
to understand self-organisation.
But from the point of view of a psychologist or a neuroscientist,
we're talking about a very long-standing way of formulating our capacity
to make sense of our world in terms of being able to predict.
So, these ideas go all the way back to Plato and probably Kantian in nature,
but probably best articulated by Helmholtz in the 19th century.
But in the sense that perception is a constructive act.
It is, in the words of people like Richard Gregory,
it is the brain actively constructing explanations, hypotheses, fantasies
for what might have caused my sensations.
So, this is very much, as Andy Clarke would say, an inside-out process
that you're creating a fantasy, an explanation for what I would have seen
if this was the right explanation.
And then you're using the actual sensations to correct, update,
revise your internal hypothesis, your internal fantasies.
On that view, you could regard the brain as literally a fantastic organ.
It's a purveyor of fantasies that are trying to make sense of the lived world,
or at least the sensed world.
And if you cast that in terms of inference mathematically,
abductive reasoning, and write down the rules that would have to obtain
if we were in the game of inferring the causes of our sensations,
then you get to a formalism that can be described in terms of optimizing
a quantity called variational free energy.
And this quantity is quite ubiquitous in statistics and machine learning,
also known as an evidence lower bound.
And it simply scores the surprise that is inherent in any sensory evidence
or any sensation.
And we use that surprise, if you like, to revise our beliefs.
And that mathematically can be written down as minimizing free energy.
So, all that you can think of in terms of what constitutes a good brain,
and possibly a good mind, can thereby be described as trying to minimize free energy
or minimizing surprise.
You can understand that in terms of the average surprise, which would be uncertainty.
So, all of this is really saying it's a mathematical statement
that self-organizing sentient systems look as if they are trying to minimize uncertainty,
trying to find the best guess, if you like, the best hypothesis
for the causes of their sensation.
You can understand this in a very generalized sense.
You don't have to think of it in terms of sentience.
You could understand this as just a kind of homeostasis.
But if your body or my body is in the same game of trying to minimize
surprising deviations from states of being, and we do so,
certainly on the level of physiology, by trying to keep ourselves within
prior ranges of states, a temperature or blood sugar and the like,
that would be very surprising if we found ourselves outside those regimes,
either very, very cold or in some kind of physical extremists.
So, that would be, if you like, a sort of biological perspective of the free energy.
The physicists would come along and say, okay, there are certain,
possibly quite remarkable systems in my universe that seem to
restrict themselves to certain characteristic states of being.
They have a peculiar capacity to resist the second law of thermodynamics,
which I should say just applies to some closed systems.
But I think it's a useful concept here in relation to this notion of homeostasis.
What characteristics must these systems possess in order to keep themselves
within characteristic states, technically, mathematically, of course, a pullback attractor,
if it's just states of being that look as if they're attracting certain systems,
so that they gather themselves up and keep themselves within these characteristic states.
And it turns out, if you write down the equations for the dynamics of these kinds of systems,
then you can explain or you can describe these in terms of a variational principle of least
action that just says you're always trying to flow down gradients established by these
surprises, these prediction errors that's quantified by the free energy.
And that's a really nice, or that has a very nice interpretation.
Because mathematically, this surprise is the negative of what the statisticians would call
log evidence. It is a quantity that measures the goodness of your model,
of the negative of this goodness of your model, which is just simply the probability of my sensations
given a model of how I think those sensations were generated. So this is exactly the same kind
of generative model you'd find in generative AI or say large language models and the like.
So that sort of gives you a theological gloss on this free energy minimizing process.
There's just a way of describing self-organizing systems that have this particular capacity
to organize themselves and resist this entropic dissipation on dissolution, decay and death.
And you can describe this as effectively looking as if they're trying to maximize the evidence
for their models of the world. So this can either be read as basically gathering evidence
from my own existence if I am a model of my lived world, also in philosophy by nicely denoted
self-evidencing. So it's a special kind of self-organization that can be read as self-evidencing
in the sense of gathering evidence from the way I think my world works and how I operate within
that world. So those would be two sort of perspectives on the same phenomenon.
Yeah, it's wonderful. Thank you. That's a great summation. And we're going to dive
into this in many different ways. We're going to slice this up in many different ways. But
one thing that I haven't heard, and I've listened to many of your podcast interviews and watched
some of your presentations and read your papers, what I haven't heard yet is what is the origin
story of the free energy principle? How did this all come together for you? I know you have a long
history in the field, but was there an aha moment or a eureka moment at some point? When did this
kind of all start to come together? What was the origin of this idea?
Well, I think the first thing to say in response to that question is that this idea has been around
for, if not millennia, certainly centuries and has been increasingly formalized and simplified.
So there could be many starting points to this story and each will have their precedent. So this
is a legacy, a legacy of what? Well, you could argue it's a legacy of ideas proposed by Helmholtz
and refined by psychologists like Richard Gregory, notions of analysis by synthesis,
and all sorts of, you know, the brain as a constructive organ, statistical organ trying
to make sense of its world that you'll find in the 20th century, ideas which were taken up to
great effect in machine learning by people like Jeffrey Hinton and Peter Dianne. They actually
invented a Helmholtz machine that had this sort of, this basic mechanics under the hood,
borrowing from another legacy left by Richard Feynman, which was the technical, resolving the
technical differences of doing this kind of inference, hence the variational free energy
that he brought to the table in the context of quantum electrodynamics. Personally,
it all started to make a lot more sense when reading the work of people like Raj Rao
and Dana Ballard. And that story was a predictive coding story, but he transpired that this was
just another way of telling the same story, but you know, using a slightly different rhetoric.
So the prediction errors in predictive coding just are a measure of free energy under certain
simplifying assumptions, but the key insight, you know, in the late 90s wasn't exactly the same
objective function. It could be used to describe both perception in the spirit of predictive
processing as championed by people like Andy Clark and predictive coding, but also the learning
the updates that you to connection strengths of the kind that you'd find in machine learning,
but also you find in natural intelligence and experience dependent necessity in the brain.
The thing that I found particularly intriguing was that if you just stood back and I repeat,
so I looked at this through the lens of a physicist, you could also explain all of action
through minimizing exactly the same quantity. So, you know, bit by bit, everything that needed to
be explained sort of fell into the camp of it's just minimizing free energy and everywhere you
looked, everything could suddenly be very simply explained in terms of minimizing free energy
attention. And even in the past few years, your natural selection is just another free energy
minimizing process. So, this is, I haven't really answered your question in this period
which was asked because there was no one moment. Every few years, I certainly get a nice aha,
oh, it's just another instance of minimizing free energy. And then you write a paper usually, you
know, using numerical simulations and a bit of analysis to say, well, this is another way of
looking at it. And it looks very much like this kind of thing, because it's all, if you like,
a reflection of the same fundamental process of self-organization.
Can you give us a sense of, I guess, the scope of this discovery? So, as far as I understand it,
it explains, you know, process of dynamic happening in the brain, which is the most complex
object that we know of in the universe. What is the simplest scale? What is the smallest,
say, dynamic or thing that would adhere to this principle? Does that make sense? Like,
basically, when does this principle start? Yeah, no, I just wanted to interrupt to
congratulate you on the question, because that's the second focus of many colleagues
in vertical biology and physics. So, I'm thinking here of people like Mike Levin and Chris Fields
and Jim Glaesbrook. So, that's absolutely key, I think, that notion. Does this apply to a particular
thing? Or does it apply to everything? And if it applies to everything, what scale does it apply?
And does it apply at every scale? And the answer should be, it's scale invariant,
and it applies to everything, literally. And that sort of perspective is being championed,
I repeat by my colleagues, Mike, Jim, and Chris, in the context of quantum information theory,
on the one side, on the point of view of physics. But on the other side, there's this story, which
I think is very nicely articulated by Chris Fields, that it is time to remove the bright
lines between physics, biology, and psychology. They're all just the same thing, and you get
this notion of basal cognition, which is something I think Mike Levin has brought to the table,
that all self-organization can be read as this kind of basic sentence, this sort of basal cognition,
that is just a reflection of the existence of things. And this may sound a little bit like
an overstatement, but the interpretation in terms of, or the interpretation of self-organization
and self-eventing is a relatively straightforward consequence of the individuation of anything
from the rest of the universe. And this separation appeals to what is now a little literature
on Markov blankets in this particular context. So the Markov blanket is just a definition of
thingness, where you start with the notion, okay, I want to explain the states of something,
and then you ask, well, what's a thing? You have to appeal to scrolling and formulation of,
you know, boundaries. Can you explain what goes on within the boundaries of living things? And
of course, as soon as you say that, you realize it's the boundary that's the important structure
that allows you to individuate something from everything else or no thing.
And indeed, if you just look then look back with that view on what you learned at school in terms
of physics, you suddenly realize how important that boundary is. There's a heat gap in physics,
for example. So wherever you look, there's this crucial notion of a separation, an individuation,
and simply by thinking carefully and articulating formally how you would define that boundary.
There is, if you like, a partial separation from states on the inside of something and states on
the outside of something. But there's a two-way traffic across this blanket or this, you know,
this boundary, this Markov boundary. And this two-way traffic enables you now to describe
the internal dynamics or dynamics on the inside as holding beliefs about probabilistic
subpersonal beliefs about the outside. And it is that that enables you then to assign this free
energy functional to belief structures in the brain. And you can do this for anything. You can do this
for a droplet of oil. You can do it for a virus. You can do it for a person. You can do it. In fact,
I've just signed off on a wonderful paper by my colleagues, Saagir and Lanceter Costa,
where they've actually applied it to the biosphere. So the same maths unfolds. Once you've identified
the separation of something from the else, you just apply this mechanics as Bayesian mechanics.
And then you can interpret the self-organisation in terms of sense-making and self-evidencing
and an implicit or a description of that sense-making in terms of belief updating by
minimising this surprise or maximising this Bayesian model evidence. So it can be applied to
single cells or it can be applied to the biosphere, though it should apply to everything. And so
that's what Chris Fields would say, at what level of analysis that it comes to, you know,
quantum information, theoretic applications of the emission.
Yeah, that's fascinating. I'm familiar with Chris Fields' work. I've read some of his research and
actually spoke with Michael Levin a few weeks ago. Yeah, we actually covered, I mean, in great
detail, one of his papers. I think it was 2019 paper called The Computational Boundary of the Self.
I don't know if you happen to see that, but he has this visual cognitive light cones,
sort of the boundary, the assumed boundary of nested cells, let's say, going all the way down
to the cell, say the cell, then you have ants, then ant colony, and it sort of, he brings up
just fascinating ideas around collective intelligence. All intelligence is being
collective and stuff like that. So yeah, a little bit, those things I'm a little bit familiar with.
So it's great that you could call them out. Can you define, one thing would be great,
to get some definitions down, can you define free energy? So I believe in a thermodynamic sense,
it's the amount of available energy for a system to do work, because a simpler,
perhaps one of the simpler definitions for it, is that applied in the same way in your free energy
principle? Yeah, again, an excellent question. Yes and no. So the, you know, the functional form
of the variational free energy, and that's why I tend to say the variational free energy, so that
people do not misinterpret it as a thermodynamic free energy. The functional forms are identical,
and they inherit from the same kind of physics and probability
institute dynamics. However, thermodynamic free energy is, I think, a very particular
application of this kind of mechanics to certain systems. So it is, you know, I think,
from the point of view of, you know, so somebody is not a physicist, I think it's important to say
that the variational free energy is an information theoretic measure. It has no commitments
to joules or Boltzmann's constants or anything of that nature. It's very much like a statistical
measure, like you're a variance or an average or an entropy. So the free energy as a free energy
is just defined effectively in terms of a relative entropy, or sometimes known as a KL divergence,
and a constraint or an internal energy. So the variational free energy is talking about
probability distributions, it's talking about information, and crucially it's talking about
information about things. And then we come back to the, you know, the central foundations of the
Markov blanket and separating the inside from the outside. So the whole point of the free energy
principle is that you can interpret the inside states as holding information or probabilistic
beliefs about outside states. So this is, if you like, something quite fundamentally different
from so Shannon information on the surprise of finding the brain in this state. So the brain
will have two kinds of free energy, it'll have a variational free energy, which is a comment about
its goodness of fit or its beliefs about what's going on outside, which a statistician would
understand, but it will also have a thermodynamic free energy in terms of the actual metabolism and
electrochemical signalling and the metabolic states of the world that requires a further
commitment to, I repeat, sort of interpreting certain quantities, you know, for the amplitude
of random fluctuations in terms of thermal constructs and applying things like Boltzmann's
constant to it. So there is a difference between the two. Having said that, I think that difference
is specious on two counts. First of all, you know, taking again a Feynman-esque point of view,
information is energy and energy is information. And at the level of analysis that we're talking about,
you know, a thermodynamic interpretation is just another interpretation. You don't need to
discuss self-organization. If you wanted to talk to some physicists in the 19th or 20th century,
it would be useful, but it's not necessary. The other point is if you did talk to that kind of
thermodynamic person, then you would find that there is a, that these free energies share the
same minimum. There is a necessary thermodynamic cost to any variational free energy minimization
or belief updating by things like that was principle. So there is a physics which really
binds these two things together. The final point of contact or perhaps the final,
some of your more technical viewers, the free energy principle that we're talking about can be
regarded as dual to James's maximum entropy principle. So James's maximum entropy principle
basically says that the universe or anything in the game of measuring anything else
will conform to the principle of a maximum entropy under constraints. And those constraints
are what are supplied by the generative model that generates the predictions that are necessary
to provide the surprise. So the surprise part, the internal energy part of the free energy
principle is that which rests upon or is defined in terms of our world models, our generative
models. So we come back to this notion of what is a free energy where it's an internal energy
minus an entropy. So where you want to minimize your free energy, you're going to maximize your
entropy in a chord which changes its maximum entropy principle, but under constraints that
you're trying to minimize the internal energy. And that internal energy just is a surprise that
we were talking about before. So on that view, I think there's a deep connection between
a certain kind of free energy in physics, but it would have to be a Jamesian kind of free energy
even with the kind of energy you did at school when you boiled in water at the high.
Sure, yes. Okay, it's so interesting. And actually, you bring up William James's maximum
entropy principle, something that I learned about listening to one of your lectures because
I believe you said, I think it's a quote, if I have no preferences at all, then my best bet is to
keep options open. So it's a bit of as that's like the non-technical kind of layman's way to look at
it, which I hadn't thought of before. And I was actually thinking, and it's one of the questions
that I have for you. And it's something that I think is really interesting about this principle
is that, please correct me if I'm wrong or fill in here, the preferences are built into the
Bayesian beliefs. Is that correct? Yes, you've immediately gone into a much more glorious
world of preferences and purpose and planned intentions. Yeah, sorry, we can go there later
if you want because it's a great place to be. But just at the moment, we've just been talking
about self-organization, self-evidencing, but what you've done is really speak to
the active part of this. So you're just to set the scene. When you look at certain kinds of
systems and specifically systems that have very precise internal dynamics, so the random
fluctuations are suppressed or at least at the scale of observation that you might want to apply
or the random fluctuations are averaged away. But these kinds of systems, basically systems like
you and me, but not systems that are very, very small and very, very hot thermodynamically that
would have lots of random fluctuations. But if you can get a big enough system like you and me,
then it is the case that the solution or the variational principles that have to be in play
in order for this separation to persist, separation of self from non-self to be in play,
and you apply it to the way that you act upon the world, then you can describe this in terms of
minimizing the free energy that you would expect if you pursued this course of action.
It's at that point, I think you get notions of preferences and how you could interpret
this expected surprise. Very much as we said before, one way of reading expected surprise just
is in terms of entropy. But there's another way of avoiding surprises, which is just to avoid
surprising outcomes, which means complying with the constraints that were implicit in
James's constraint maximum principle. The complement of avoiding surprising outcomes
is that it looks as if I am always acting in a way that convinces preferred outcomes,
outcomes that just are the characteristic states that define the kind of states that you'd find
me in. I think you're absolutely right that these prior preferences are just a way of articulating
the typical or characteristic states that define who I am. You can either put a teleology on that
and say, oh, this thing is behaving as if it prefers to be in these states, it's actively
choosing these causes of action, these paths into the future. The result that those consequences
are that you end up in your preferred states. On the physicist's point of view, you start
off with a system that seems to be able to occupy these preferred characteristic states
and then you work out what dynamics must these systems have. That's the deflation part of the
free energy principle. It's just a description of things that have preferred states effectively,
and these preferred states are literally the attracting set that constitutes the pullback
attractor that was mentioned before. You're absolutely right in one sense that these
preferences are part of Bayesian beliefs, but that does, if you like, commit you to a
rather teleological interpretation of the energy principle. You don't have to do that.
You can't do that. You don't have to do that. Please forgive my ignorance here, because I might
shrug my hand a little bit here, but is the brain trying to minimize free energy
because it's trying to use as much of it as possible? I know it's trying to minimize surprise
uncertainty, but I imagine something like a resourceful greedy brain. Is the minimization of
free energy sort of like the byproduct? Is this a downstream effect, or is it the real pump that's
moving the water along? Does that make sense? It makes sense. In a sense, it's exactly the question
which I try to intimate. There are two completely contradictory answers to, so if you're talking
to a physicist, say, no, no, no. There's no sort of pump here. There's no aspirations to
deploy my free energy in the most efficient way. It's just that's what systems do. Systems just
settle down to a free energy minimum. That's another way. Those systems that settle down
to an attractive set into their free energy minimum, that is their definitional attribute,
the stipulation, that is what things are. It is no surprise that when you describe their
dynamics, they'll look as if they're trying to minimize their free energy, because that's what
defines them. If you now talk to a biologist or a psychologist, then your description is perfectly
out. It will look as if these systems, particularly systems like you and me,
are actively trying to minimize a surprise in a resourceful way. I would actually frame that more
in terms of in a very efficient way. If you go to Wikipedia and you say, well, free energy is the
amount of energy available to do work, I mean, that's a thermodynamic interpretation.
I don't think it's quite necessary to put that out of all the size things in quite that one.
But it certainly, I think, would be,
you would be perfectly licensed just to interpret various parts of or decompose
variational free energy. And as for what would it look like if we just focused on this particular
part or that particular part? I think one really interesting decomposition
of variational free energy is that which a statistician would usually appeal to. And that's
basically accuracy minus complexity, where accuracy is effectively how accurate your
predictions of the world are. How good is your explanation of these sensory data, or if you're
a statistician, sort of your empirical data that they're trying to make sense of.
The other thing, the complexity, I think, is even more interesting.
So in the same way you were talking about before, keeping your options open and maximizing your
entropy in accord with James's maximum entropy principle, the same sort of Occam's like principle
emerges in terms of this complexity term. So the complexity is just a way of lumping together
part of the internal energy with the entropy to give you this relative entropy or this
KL divergence. To put this very simply, what it measures is effectively the degree to which some
sensory data or some sensations or some sensory evidence changes your mind. So if you're trying
to describe this as a statistician, this is the degree to which you move from your state of
priorities to your state of posterior beliefs. So it's degrees of freedom you're using up
in terms of providing an accurate account of your data. And it is this that is minimized.
Remember, free energy equals accuracy minus complexity. So well, actually it's going to
go around negative free energy is equal to accuracy minus complexity. So as you're minimizing the
free energy, you're also you're trying to maximize the accuracy but at the same time you're minimizing
the complexity. So this is where I think you get what you're alluding to. You're trying to
accurately navigate the world in the most efficient way possible using up the least resources.
But why do I say resource as well? Because of this link between the information and energy
afforded by things like the Ginsky equality and the Handao's principle, it costs energy to
change your mind. It costs energy to create and well to destroy information. So that complexity
is also a cost, technically it's also an information game, but it's also a complexity cost.
So what it looks as if a brain of this kind would be in the game of updating itself, changing
biophysical state, in a way to make predictions that are as accurate as possible, whilst at the
same time complying with complexity constraints. So do it in the most parsimonious way that it can.
So ends Occam's principle. So that would also translate into the most energetically efficient
way of making sense of the world. And if you sort of unpack that principle in terms of computation
in silico, then what that tells you is that the good computers are those computers that work on
the edge very cheaply with small amounts of electricity. They're doing it very in the simplest
way possible with a cool head, literally. So these are really interpretations of if you're like
unpacking the terms that go into a variational free energy and making sense of them. And I think
that's exactly what should be done. It's a wonderful game. And you could also repeat that game in
terms of the expected free energy. So now you have expected accuracy and expected complexity.
And when you look at the functional forms of these terms, you suddenly see things that people
have been dealing with and optimizing for nearly a century. So for example, the expected accuracy
or the negative expected accuracy is just the ambiguity or the negative precision
that would be used to explain an efficient sampling of the world of the kind that you might find in
the same, the visual cortex and the organization of the visual brain. The expected complexity becomes
risk of the kind you'd find in economics. It is basically the distance I move from my prior beliefs
if I pursued this course of action. And of course, we've just said that the prior beliefs
about the consequences of action are our preferences. They're describe our attracting
set of our preferred states. So now the expected complexity, the risk is just scoring the degree
to which I expect to be displaced from my third states of being probabilistically speaking.
We just measure that with the KL divergence on the relative entropy. So that's, you know, that's
bread and butter for many economists. Another way of, if you're like unpacking or rearranging the
terms is in terms of what is referred to as expected information gain and expected cost. So
those two components are exactly those things that you find in the two aspects of being base
optimal. So there are two ways of being base optimal. One way is to minimize your expected
cost or maximize your expected utility or valuable log preferences. And that's the kind of base
priority to find in Bayesian decision theory. And you can look at that as grandfathering things
like reinforcement learning and utility theory. On the other hand, though, you've got this sort of,
again, this sort of, it's not ambiguity, it's ambiguity with bells on, which is the expected
information gain. And that was exactly the objective function devised at the inception
of the principles of optimum Bayesian design. So if you have the problem of designing an experiment
that's going to yield some data, and you now ask yourself the question, what's the best kind of
experiment I could possibly design that will give me the kind of information that's going to resolve
the most uncertainty about hypothesis? What's going to maximize the expected information gain? And
it is exactly that quantity, that part, that epistemic value, this measure of the resolution
of uncertainty that defines Bayes' optimality in the context of experimental design.
That may seem a little bit sort of unconnected to you and me in conversation or just walking
down the road. But of course, we are experiment, we are actively experimenting all the time,
just by looking around. The way that we move our eyes, the category every 250 milliseconds,
every little act of this kind is an experiment. So we come back now to the notion of Richard
Gregory, that perception just is hypothesis testing. What's the experimentation? It's just
palpating the world in the right kind of way to get that kind of information that's going to resolve
the most expected surprise or the most uncertainty. And you can have that at the level of
visual palpation every four times a second, or the news channels that you would afford epistemic
trust, which is probably quite a hot issue. Or the kind of wiki, whether you've got a wikipedia
or what kind, who would you consult? We make choices all the time in terms of what's the best
way to act? And what are the, and what this notion of expected free energy brings to the table is
that the imperative of a dual aspect, this pragmatic aspect that is formally this expected cost,
where the cost of the negative or the surprise in relation to my preferred states of being.
But also, to my mind, even more important is this epistemic part, this sort of expected information
gain that actually makes us all little scientists of what sort of. Yeah, that's incredible.
I'm glad I'm recording this conversation because I'm going to have to listen to that a few times
over to fully pull together all the pieces because there's so much there. I actually found this when
I was doing research on the free energy principle that I was going off and finding definitions
for things because to bring it all together is, well, it's amazing that it incorporates so many
different ideas from different disciplines. I mean, you have your neuroscience, but you also
have information theory. I mean, it's physics, you know, you have all these different things
that you're pulling together and finding these deep truths that I think is fascinating.
Well, it's nice you say that because that's exactly what Chris Fields wants. He wants to sort of
do physics, psychology, biology, they're all the same thing. And again, you know, I was trying to
answer your question when was the harm moment. There really wasn't one, but every every few months
you say, Oh, that's just one of those. So to my mind, in a sense, it is that capacity
to accommodate very gracefully things that definitely have worked in the past,
that haven't been framed in this sort of simplifying, sort of unifying framework. It's that capacity
which lends the free energy principle of a veracity and a utility that it continually
impresses me that when you were able to articulate something that's endured for centuries, or at
least decades, that we all use in work, and that in terms of our understanding, and suddenly it
fits in with the free energy principle that to my mind is a reflection of the utility of the free
energy principle, but also interestingly, it means that the free energy principle is conforming to
itself. So if you remember, the whole point of the energy principle is finding accurate explanations
as simple as possible. So it should provide a simple explanation for everything. That's that's
that's it's if you like, that's its foundational premise. So you shouldn't really be surprised
that you can you can do economics and move forward. Yeah, one of your yeah, one of your
my favorite papers is yours. It's I think it's the free energy principle made simple,
made as simple, simple as possible, but no simpler, I think is the title or it's close.
I'll link to that in the description for folks who want to, to want to read that.
I may have butchered that title, sorry, but it's close. It was Einstein's famous quote.
Yes, it's from Einstein. Yeah, I even found that I didn't know this, but there's a great little
article in Wikipedia called just called the principle of simplicity. Simplicity. So there's
actually, you know, people like Nick Chater and colleagues have have found this, you know,
this formalization of outcomes principle. And it's not, you know, I think the free energy
principle could also be read as a dual to that kind of that kind of imperative to find the
simple minimally complex explanations for stuff. Yeah. So I'd love to, I'll have to
focus somewhere in time on surprise, the idea of surprise. It's central to this theory. And
correct me if I'm wrong. So it's, we're trying to minimize surprise or slash uncertainty, right?
Does the system want zero surprise, precisely zero surprise, or that might be, I imagine that
might be impossible actually. So is it, is it trying to approach zero? Is that optimally,
is that better? Does that make sense? It does. But again, you're, you're, you're asking as a,
as a biologist, not a physicist. I'm keeping it. Sorry.
But there is a lovely paradox here. The notice we've been saying in the past exchange,
that we are compelled if we exist as certain kinds of things that have these very precise
internal dynamics to maximize information gain. So we are compelled to seek out novelty.
We are compelled to seek out surprising informative, informative outcomes, which
needs to be contrasted with what you've just brought to the table, which is the, you know,
the underlying, the underlying imperative really is that of homeostasis to minimize surprise.
So you've got this interesting dialectic here, which just falls out of the maths.
That in the service of trying to minimize my surprise, to maintain my homeostatic,
to keep myself within these, within these attracting sets that have a low entropy.
Remember that the entropy is just the average surprise. So if I spend my life minimizing
surprise, I am by definition, when averaged over time, minimizing my entropy is minimizing
the other number of surprising physiological and mental and emotional states that I experienced
during that period of time. But to do that, I have to actually go and minimize, maximize my
expansion information gain. So I'm going to look as if I'm actually very curious. So part of keeping
my home, keeping myself out of unfulfilled states and minimizing surprise, which you can
read as like this prediction error, for example, part of underwriting my capacity to minimize
my prediction error is actually to go and seek out surprising or apparently surprising outcome.
So I will, I will be quintessentially curious. I will be sensation seeking. I will be altering to
answer, it'll look as if I'm going to want to answer the question, what would happen if I did that?
So when you say we all want to minimize surprise, we certainly want to avoid surprising sensations.
Yes, no deception underwrites our beliefs about being in pain, for example, being very cold,
being very poor, being very unloved, being dead. These are all very surprising states of being,
which we will in the moment avoid. But that does not mean to say that we will not seek out
those outcomes that can have information. So we're still very, very curious.
And I say that at length because there was an interesting philosophical paradox called the
dark room paradox that was brought to the table around the inception of the free energy principle
in neurophilosophy. And it went along the following, well, perhaps you know this,
you probably know this better than I do. Do you want to tell your viewers what it was all?
No, I wish I did. I'm sorry. I don't know about it.
I mean, it's a very common sensical argument. But if it's the case, you want to minimize surprise,
why don't you just go into a dark room, turn off the lights, lie down and stay there forever.
It's kind of a question I had. Why not just jump off a cliff, right? That's you'll know
the surprise will be over and then that'll, yeah, it's more extreme, but
Yes, it's interesting that. So why don't we do that? And yet we go bungee jumping.
Yeah, that's not jumping off cliffs and bungee jumping are, you know, they should be
explainable under the free energy principle. And of course, there's a crucial difference
between the bungee jump and the jumping over a cliff. But to come back to the dark room problem,
I repeat, it's just the paradox that why don't surprise minimizing machines or artifacts or
systems basically sequester themselves from their environment and close their eyes or turn
the lights off and remove themselves from any particular surprising sensations.
And the answer to that, well, there are a number of different answers, depending upon
how seriously you take the question. One less serious answer is, well, that's exactly what
I do every day when I go to bed. So it's not quite that surprising. Interesting. Yeah, that's
so good to counter. Yeah. But you're ignoring the fact that we do need some downtime. And there
are good reasons for that, which come back to this separation of free energy into accuracy and
complexity. But more importantly, the first thing I do when I go into a dark room, imagine, you know,
you're at a conference and you go back to your hotel room and the lights don't work in your hotel
room because you can't find the switch. So, you know, what tells you first of all, the first thing
you do, you and I would do as free energy minimizing creatures in the future, minimizing
expected free energy, maximizing my expected information gain, it's a turn on the light.
That's the first thing that any free energy minimizing system would do.
Which, and the second thing that that little analogy tells you is that you are going to,
you know, if you can't find the light, you just kind of feel your way around. So again,
this is exploration, this curiosity that is coming to the imperative to resolve uncertainty
remembering uncertainty is average surprise. So in resolving uncertainty, you are minimizing
your expected surprise. But this is about outcomes in the future that are not yet witnessed. So
again, I think there's a, you know, when you talk about things I do, then you are now talking about
the imperatives that underlie action upon the world and the consequences that live in the future.
And in those instances, it's all about minimizing uncertainty. When you're talking about things,
my states of being surprise, it's just a measure of my state of being, it's just a likelihood of
these sensations given my model, my predictions of the sensations at this point in time. So
the fundamentally different ways of using the notion of surprise. I hope that makes sense,
it's probably a little bit over answered. I've overshadowed. No, no, it's great. That was useful.
I mean, it is something that I think that's why I wanted to remain at this, on this topic,
on this level, because it is, I think the area where I do, I do still have the hardest time
intuiting the difference between information gain and minimizing surprise. Like those two
things, they seem counter or they seem like, you know, they can't have both, right? But I think
it's partly perhaps a problem of language and in terms of like assigning a positive or negative
valence to the term surprise. So something like, like an example, so I was thinking about this
the other day, if you won the lottery, if you had a winning lottery ticket, right, you won
$100 million, that's extremely surprising, and also very good, right? But it seemed to be counter
to minimizing surprise, right? So but I think it's a difference of scale, perhaps, like
it's like the difference between perhaps the overall model and a particular event
within that model, you know, you know, it is perhaps using that example, could you possibly help
help me into it, sort of the difference in where or these tensions kind of resolve?
Well, I think I think you've identified, well, actually, it's a wonderful thing,
let's talk about winning the lottery, which is very surprising. Yes, I left, I left you someday.
But also, I think it's just, you know, just to reiterate what you implicitly just said that,
yeah, the word surprise is applied to many different constructs, sometimes more anthropomorphic
and sometimes less. So when surprise is used in the context of the free energy principle or
and mathematically, it has a very specific and very deflationary meaning, it's just the
negative log probability of some data given your model of how those data were caused. So it's a
measure of the implausibility of getting these data given a particular commitment to how you think
these data were generated. So I repeat, it's probably best thought of as a prediction error,
you know, some outcome, and I had a prediction of the outcome, and the surprise is just the
measure of the mismatch or the distinction, discrepancy between my prediction and what I
actually observed. This is also known as the prival, AL, an information theory, a term coined
by Tribus, more formally, more generically, it's also called self information. It's just a negative
log probability of an event conditioned upon the model or the context in which that event occurred.
So I think that's, if I was talking to, you know, students of physics information theory,
I wouldn't use the word surprise, I'd use self information because immediately they know
that the expected self information is entropy of a Shannon sword. So when I talk about minimizing
self information, I'm using that as a shorthand to say I'm trying to describe systems that resist
a tendency to dispersion of estates. So notice that this is again, because it can be very confusing,
again, this is, if you like, almost the opposite of James's maximum entropy principle. And there's
a reason for that, because what we're talking about here is the entropy, the average self information
or the average surprise of actual outcomes, of real deterministic variables that constitute
technically the sensory states of my Markov blanket, the way that the world impresses itself
upon me. So this has nothing to do with beliefs or probability distributions. It's the surprise
afforded this outcome. And I want to, you know, being a good homeostat to you,
cybernetics notion, I'm going to want to make sure that everything, everything that the world
impresses upon me is within the bounds of, you know, that something like me can take. And this is
just a statement basis again. So that kind of entropy, we're trying to minimize. So remember
before we were talking about James's maximum entropy principle, but the entropy was about the
beliefs about the causes, it wasn't about the actual outcomes. So this is again, if you like,
a dialectic or a paradox, you know, on the one hand, they're trying to minimize the surprise or
the self information of my, of the actual outcomes that the world impresses upon me. But when it comes
to the Occam's principle view of free energy minimization, I'm now going to try to maximize
the entropy of my beliefs about the causes of that. So it is complicated. And perhaps I,
one should apologize for that. It's a little bit, it's the same kind of like dialectic that you get
into if you commit to James's maximum entropy principles, the right way of measuring things
and understanding things. Then you have to say, well, hang on a second. I thought the whole point
of biological self-organization was to resist the natural tendency to an increase in
entropy. I thought the whole point of Schrodinger's formulation of life was to minimize the entropy.
So who's right? Schrodinger or James? Well, they're both right. It's just that the entropy of the
things I talk about are completely different. So James and the free energy principle are talking
about the entropy of measurements and beliefs. Schrodinger and homeostasis and syllogetics,
for example, are talking about the entropy of outcomes, of measurements, of the data that you
use to make your inferences and build your beliefs and update your beliefs. So it's a fascinating
sort of yin and yang. And it really forces you to think about the nature of these mathematical
descriptions and to what they pertain. So things like entropy and surprise and self-information
are just attributes of probability distributions. So you have to say, of what? Is it the outcomes?
Or is it your beliefs about things? And with that sort of in mind, weighing the lottery,
is that surprising? Well, if you imagine the probability of it happening to you being surprising,
I can see that you might think, oh, that's highly implausible. So it's not. It's not. It is very
surprising. On the other hand, if you believe that you are the kind of lucky chap that good things
happen to, which you have to believe in order to actually self-evidence your way and predict
your way into being a happy chap and good things happen to you, winning a lottery is not that
surprising. That's the kind of thing that happens to people like me. I'm a successful New Yorker.
I wouldn't be that surprised because that's consistent. It's egocintonic. Winning the lottery
is not going to put me in a truly surprising state that if I had a car accident or I had a stroke
or my partner let me, these are truly surprising things. Winning the lottery is not surprising
because it doesn't take me out of my comfort zone, my attracting center, my callback attractor.
Furthermore, I'm not sure that this example works so well in practice, but certainly
you can now, if you win the lottery, if you did actually win the lottery, that actually reduces
a lot of surprise in terms of what you're going to do next. So that puts you in a certain position
with a certain attitude of ways forward and ways of behaving, which actually resolves uncertainty
about whether you're going to be able to pay these bills, whether you're going to be able to support
an elderly relative, whether you're going to be able to pay for your children to go to college.
All of these uncertainties are exactly what you're trying to actively resolve, but if you're very rich,
a lot of those uncertainties resolve themselves. So that kind of expected surprise, which is all
about the surprise that attends the things I'm going to do, is actually resolved by winning the
lottery. Winning the lottery is both good at that simple level of analysis. I'm sure if you
actually speak to people that actually won the lottery, you probably get a very different
impression, but at least at this level of analysis, it's both good and surprise minimizing.
That's interesting. Right. It depends on the frame, almost the frame of reference,
what state are you looking at it at. Are you familiar? This came to mind the other day,
as I was thinking about this principle. Do you ever watch The Twilight Zone?
Yes. From back in the day, there's an episode called A Nice Place to Visit and Spoiler Alert for
anyone watching, but it's an old show, so if you haven't seen it by now. But basically in the
episode, a thief, a robber dies and it goes to heaven and they're a gambler. They like to gamble.
So in a casino, basically the way it works is they win every game at the casino. They're playing
craps or playing blackjack and every time they win, right? And the robber is happy. He's like,
oh my God, this is amazing. Everything I play, it's so great. And then please stop me if you've
seen this episode already, but for folks watching, he's happy at first, but then it goes a month later
and he's sitting at the table and he's bored out of his mind, right? He's winning every time and
he's just like, I won again. Like, oh, why even play, right? And maybe you think about this,
I mean, maybe this is completely off, but in the fact that there's no more surprise in the
games that he's playing, right? So he's lost all of the will basically to go on. And of course,
at the end, you find out he's not in heaven. He's in hell, right? He's got everything that he wanted,
but it wasn't the right thing that he wanted, sort of, you know, the lesson, the story, I guess.
But maybe think about this a little bit because basically the surprise is zero. And
actually all the veil, it's only a negative outcome really for him. He hasn't realized that
the folly of his actions, there's no more hypothesis testing happening here. Every time
it's the same thing and what a dull life to live. And maybe think about this a little bit and
please tell me if that's anywhere close to this idea. I know it's art. I know it's
different. It's television, but... No, I think that's spot on. I hadn't seen that episode.
It's a marvelous, marvelous story. I know you're absolutely right. So this is, you know,
not only do you see this in psychology, but when you start to simulate, you know,
little animals minimizing the fear in you, you see exactly this kind of behavior. And
as you say, it's just the fact that the expected surprise entails
the motivation to do those things that resolve uncertainty. And if you're denied the opportunity
because there is no more uncertainty to resolve, there's no more curiosity out there,
there's no more epistemic importance, there's no more expected information gain
that you expect because you know everything and it just keeps happening the same again and again
and again and again. That would be awful. And when you actually simulate it,
you actually can simulate little artifacts who just get so bored, they do nothing.
And certainly if they have, you know, once they attain their preferred state,
so they've maximized their expected utility or minimized their expected cost,
because there's nothing to shape their behavior, because there's no now
reducible uncertainty out there, there's no more, there's no more epistemic
affordance, there's nothing to do. You know, they just sit there and do absolutely nothing.
And that must be an awful situation to be in. And I say that because, you know, 99% of your life
is not chasing, you know, if you were a mouse, cheese, it's not putting yourself in a position
where you're going to win the lottery. It's actually indulging in your curiosity. The very
fact you're doing these podcasts, having this exchange is just an expression of the fact you
are compelled to be a curious creature. So this is part of our makeup. And if we didn't do this,
then, you know, at least from a mathematical perspective, it's highly unlikely that we would
exist over an appreciable period of time. So yes, I hadn't seen that episode, but
I love the twist that you end up in. Yeah, he was a thief, so he deserved it.
So about the, let's see here, I'm trying to figure out where we're going to go.
I believe there's two ways to minimize prediction error. They were change the model to better fit
sensory input, or change the world, act on the world in order to better fit the prediction.
But I wasn't sure, are these two mutually exclusive? I mean, do you have to choose
between the two? And if so, how does the system decide which one to do?
Right, so we're now at a sort of more elemental application, the free energy principle, just to
understand the fundamental, you know, the fundamental drives to both perception and action,
and you face up beautifully. So, you know, if we now simplify things and just read
surprise and free energy in the moment as prediction error, then there are two ways,
as you say, that I can minimize my prediction error. I can either change my mind so my prediction
error has become more like the sensory data at hand, or I can act upon the world to solicit some more
or a different set of sensory input that are closer to my predictions. So what would that look
like? It would look as if I am basically acting to fulfill my predictions, which is what I meant
before, if you weren't optimistic, successful New Yorker, if you didn't have that prior,
that optimism, that sort of optimism bias, then you wouldn't be able to act in a base
optimal way because you need to fulfill your own predictions to survive. There's something
quite fundamental about that. But at the level I think we're talking the kind of self-fulfilling
prophecies we're talking about are very sub-personal. So all we're talking about basically is
effectively reflexes. So, you know, when we move, when we talk or move our eyes, what's
happening is that we're sending predictions down to the Pontine nuclear to the spinal cord
about the kind of signals we're getting from the state of our body. That's technically
it's called proprioception. And if I predict that I'm going to be moving in a particular way,
I would expect to get these signals from my muscles. And if I don't get them, there's a
prediction error. So by acting, all I mean or all that one means in this setting is that you
send these prediction errors back to the muscle so that it contracts to the right length. So it sends
the signals that you predicted. So this is just like a thermostat. It's just like
sort of feedback control that we find in many, many devices. All you need to supply is the set
point, the temperature you want or the length of the muscle you predict will happen. And then the
body does the rest. So this is how a very sort of elemental level of just moving around.
The, you can understand action, motor action, motor being the use of particular sort of kinds of
muscles as minimizing prediction error or minimizing free energy. So it's not quite what, you know,
this more deliberative and kind of action, you know, it's not how do I imagine myself behaving
tomorrow or generally unfolding in this conversation. We're talking about action in the moment as
basically eliminating prediction errors reflexes very, very, very quickly. So in answer to your
question, how do we decide which to do? And are they, are they mutually exclusive? They're certainly
not mutually exclusive in the sense that the whole point of this explanation of action and
perception and the action perception cycle is that there is a common theme. It's just all
driven by minimizing prediction error or minimizing free energy in a more general context. However,
in practice, I think you're absolutely right that we do seem to be built to switch between the two.
So in principle, you could do them both at the same time. In principle, you could dynamically
adjust your set points and your your reflexes could try to fulfill those set points or those
predictions. And the two could go hand in hand contemporaneously. But in fact, in practice,
it looks as if there was actually a turn taking. And it looks as if certainly sort of larger mammals
have a very particular schedule of turn taking. I mean, this may sound very specific, but I think
it's really interesting that it speaks to the cognitive moment. So it looks as if if we just
take say vision, then our vision is only active vision, where sometimes it's kind of active sensing,
where we actually have to go and palpate and select little parts of the visual scene,
bearing in mind, we can only actually see a very, very small part of the visual scene
without, you know, with high resolution enough for real representations. So basically,
although we think we can see everything, we're not, we just see little patches and we're knitting
it together in our heads. It's fantasy that I can see everything. That's not true. You could see
something if you looked over there. And that gives you the illusion that you can see everything.
In fact, you can't. So this is part of this sort of debate is a fantastic organ, having a fantasy
it can see all around me. You can't, you have to go and get very the most epistemically rich,
maximize the expected information gain, arts of the visual field to knit together and to
accumulate the right kind of information that builds your hypothesis about the scene that I'm
currently constructing in my head. But this process happens very, very quickly. So we move
our eyes about four times a second. Interestingly, well, yeah, it is amazing, but it's also, well,
I've had even more amazing is that everything seems to be about four times a second and by
everything I made, if you were a mouse, you wouldn't really be using your eyes so much,
you'd be using your whiskers as your burrows in the field. And you whisk about four times a second.
If you are talking, you produce little chunks of information called phonemes about four times
per second. When you're listening, you're listening about four times per second. When you sniff,
you sniff it about four times per second. The way that we sample, the way that we sort of
gather our information from the world seems to have this very saltatory aspect that you're
roughly at four hertz, technically a theta rhythm. We seem to go to sample in the information.
But even more interestingly, during the action, during the actual movement itself,
the way that you adjudicate between changing your mind and updating your, allowing your brain to
revise its beliefs by changing its neural activity to provide better predictions.
During movement, you actually attenuate the consequences of that movement to enable you to
act. So this is a really interesting phenomenon called sensory attenuation.
Quite simply, if I had the prior belief that I was going to lift my arm and I didn't ignore
or attenuate the prediction errors that were coming from my arm, telling me my arm is not moving,
then I wouldn't be able to lift my arm because those predictors would come and revise my beliefs.
Oh, no, my arm's not moving. But if I can ignore the sensations that I am going to generate,
then I can use my reflexes to fulfill my predictions that my arm is actually raising.
So in order to move, I have to attenuate the prediction errors that are, if you like, undermining
my predictions, and this is called sensory attenuation, and it's beautifully exemplified in
eye movements. So if you now look at this finger and then it's the card to this finger,
whilst you were moving, saccading and moving your eyes from one finger to the other finger,
you were suppressing and attenuating all the prediction errors. I know that because you didn't
see the massive optic flow, the shift of the world induced by moving your eyes.
You can actually see it if you press your eye, this is Helmholtz's famous experiment,
if you just gently nudge the outer edge of your eye, you'll see the world shift around.
Huh, I don't want to push it too hard. I like being quite careful of the viewers at home,
don't poke your eye out. Okay. Yep. Can you see it up and we'll just jump around a little bit?
It does, yeah. So that's because your eyes weren't causing the motion, and you were able to actually
register and attend to that visual motion, that visual, if you like, retinal slip. Exactly the
same signals were being generated when you were moving your eyes with your eye muscles,
and you didn't see that. You didn't see the world jump. All you saw was my finger,
and then my finger again in a different position, the world had not moved. So you were actually
attenuating your sensory prediction errors, your visual prediction errors during the movement.
That's called saccadic suppression. It's a remarkable capacity of the brain to temporarily
suspend attention to self, the consequences of self-generated sensations. And this happens everywhere.
It's a wonderful explanation for the phenomena when you've got two children in the back of the car.
He hit me hard, and I hit him, and the escalation and the argument was absolutely right because
when they're hitting, they attenuate the sensory information from the reports how hard they're
hitting. So they actually feel will be hit as as more intense than they feel they do hitting.
So they just, they're just, you know, like a little arms race, this ratchet up, and this is
due to sensory attenuation. You could actually use that metaphor for a political excretion.
Sure. Is that, is it related to, I know if you've ever heard this, I actually don't know if it's
technically true. I think it is. I've tested it out. I've asked people to test this out.
How you can't tickle yourself. Yep. Yep. Is the same kind of idea? That's a brilliant observation.
So that example comes from people like Daniel Wolpert, who I think is now actually in New York,
and Sarah Jane Blakemore. And, you know, trying to understand the remarkable, first of all,
why is, you know, it is remarkable you can't tickle yourself because you're attenuating
the consequences of self-generated behavior. So in a sense, you know, the fact you can't induce
visual motion by moving your own eyes with your eye muscles is an example of that. But you can
circumvent that by tickling your eye, tickling your eye by using something you're not used to,
which is your finger. So that, you know, it is exactly that notion you can't tickle yourself,
which explains this sort of little, little experiment that actually devised by,
by health, so you can perform on yourself. The interesting thing is that what Sarah and colleagues
and Chris Smith were pursuing, and Suki Schergel, was that people with schizophrenia have great
difficulty in this kind of sensory attenuation, you know, in another paradigm called the force
matching paradigm, which means that people, there may be certain psychopathologies that
interfere with your ability to suspend attention to the consequences of your own actions.
So for example, if you had inner speech, and you heard yourself because you were not attenuating
the consequences of your inner speech, you might then try to explain away these unattainuated
auditory or pseudo auditory inputs, as if somebody else was speaking. And then you had,
so this is the notion that Chris Ritterbock, the table is an explanation for auditory hallucinations.
If you were able to sense your own movements, and were not, you know, if you moved, and you were
not able to attenuate the sensations of movement, it might feel as if somebody had caused your
movement. So you've got this phenomenon of made acts. So they're all sorts of very quite frightening
experiences that would ensue if you failed to have this sort of turn taking between action and
perception, especially at this very, very fast time scale. And, you know, some of these frightening
consequences, you know, one could argue, are seen quite frequently in many devices in psychiatry
and in the neurology. For example, Parkinson's disease, an abnormality of dopaminergic neurotransmition,
where dopamine in this context is thought to affect the capacity to do this kind of sensory
attenuation at a particular level in the motor system, and therefore, subverting your capacity
to realise your intentions to move. So what would that look like? Or it would look like somebody
who can't initiate an act. And that, of course, is one of the carnal symptoms of Parkinson's disease.
So, you know, this adjudication between acting and perceiving, sort of, you know, quickly,
going out there, moving actively, ignoring the consequences of that movement until you get there,
and then fixating, not moving, getting the information, sorting it out, doing your processing,
and then starting again, the cycle of action perception, where you have actually got the
separation in play, you know, is, at least from a biological perspective, you know, seems to be a
sort of ubiquitous way that we actively sense our world or actively make sense of our world
and is very, very reliant upon this notion of selective attention, sensory attenuation,
to get that dance between action and perception exactly right.
Sure. That reminds me, if I tell you just a personal anecdote from last summer,
random day I was out on my fire escape eating smoke meal, and, you know, I do this in some days, and
all of a sudden, there was, I live on a one-way street,
but coming the opposite way was a police chase. There was a dark SUV being chased by a cop car,
and I remember the first, second, or two, where I was looking over at what was happening,
I didn't quite see the vehicles. I saw what I'm going to describe as like a fuzzy black cloud.
It took a second or two for my brain to catch up to what was happening and to construct a car
being chased by another car. It was very bizarre because, I mean, it was highly unexpected, right?
It just doesn't happen every day, and I'm not sure if that's a common thing with people who see
things that are extremely uncommon, but I did have that, and perhaps I was just getting into
sort of the perceptual science literature and reading about the stuff, so perhaps it's hard
to disentangle that from expectations, let's say, but, I mean, it really stuck with me as,
you know, one, confirming, although it's well-confirmed, obviously, in the science,
but that this is what our brain is doing, is constructing, correcting for errors because
that's a highly uncertain or really surprising thing to happen, and my brain, in real time,
took a second or two to cohere and make that a solid, those solid objects.
Yes, well, that's a wonderful story, and, you know, as you say, I mean, it really speaks to the,
you know, the brain as a constructive organ, as an organ that really is trying to actively
make sense of what's going on, and sometimes in an ambiguous situation, that can take many,
many seconds, so you would also, I think, you may be able to rediscover that remarkable
if, like, suspension of the fantasy that we can perceive immediately,
so see yourself seeing, using things like ambiguous figures, so psychophysicists have
a whole range of really beautiful experiments, you know, using ambiguous figures and different
kinds of illusions that deliberately put you on the edge, so that you have experience
the sense making, and all the sort of settling down on one option or another option, you know,
resolving the fuzzy cloud into, ah, yes, that's the percept that makes the most sense in this instance,
and sometimes it's, you know, when you're looking at ambiguous figures, for example,
sometimes it stops making sense, and you cannot voluntarily stop yourself seeing
the other interpretations, so, you know, famous, two faces or a vase sample, so, you know, I think
these kinds of experiments, that kind of experience really do speak very powerfully
to the kind of experiments you can do at home, to convince yourself you've got a very
fantastic organ, but it takes time to construct the fantasies in situations which you're not
used to, and either you're waiting till you experience a police car chase, or you can go
and look at some sort of illusory stimuli devised by my psychophysicist. I should just add, though,
if my erstwhile colleague Alan Hobson was here, he'd just remind you that, you know,
if you want evidence that your brain constructs all your percepts, just think about dreaming,
you know, that is such clear evidence that we, you know, our vision is actually something we
build from the inside, and it's just gently constrained by, in the form of prediction errors,
the actual sensations, then just think about your visual experiences, you know, during dreaming.
So I want to ask you about that, the, while you're dreaming, let's say having a
standard dream, I don't know what a standard dream is, but you know, let's say having a
typical dream where you're in it and you're not non-lucid, let's say, and you're out and you're
on the beach or something, is there, and so while you're in the dream, you're experiencing it,
you're not recognizing it's a dream, you're not realizing that you're constructing the
environment, the beach. So is there, in a sense, a Markov blanket between
your personal, your first-person experience in that dream and the dream world, or is that making
like, am I getting fuzzy here? I mean, is there technically the same thing, or is it different?
I think technically it is the same thing. It's just, you know, you introduced a really challenging
issue there, but you know that you're dreaming or not. I mean, sometimes you do know you're
dreaming, certainly as you're moving into lucid phases or something, really working, making up.
So I'm just thinking, you know, a proper answer to your question would have to accommodate the fact
that you perceive and you act in this world, and yet you do not, you're not aware that you are,
you are actually dreaming, and that must, as you say, induce a whole series of Markov blankets.
First of all, you're sequestered from the sensorium. So the biological state of dreaming rests upon a
particular kind of sensory attenuation, which is very enduring, unless for many hours, if you're
sleeping properly. But it's mediated by the same neurochemical, the same modulatory neurotransmitters
we were talking about before in relation to Parkinson's disease, different kinds, but
basically the same kind of functional role. So basically you're switching off sensory input
from the periphery upon the body. So you're now letting your brain freewheel in terms of
generating predictions and resolving, in a hierarchical context, where you're resolving
the self-generated predictions by other parts of the brain trying to explain them away. So
effectively you're rehearsing your prior beliefs about the narratives that you usually
are certainly constrained by the experiences you've had the previous day. And yet, as you say,
you're not aware that you are dreaming. So there are certain very high levels of this hierarchical
construct, or say deep levels, if we think of centripetal like hierarchy or heterarchy,
that have dissolved that sense of presence and selfhood. No, sorry, that is associated with
the reality monitoring. So yes, not only is there a Markov blanket established that separated you
from the sensorium, but there's possibly another higher one that separated your normal
reality checking and self-modelling from certain parts of the brain that are engaged in rehearsing
particular fantasies that are experienced as dreams. One of the things I was thinking about
with your model, with the principle, is I can understand what the system is doing
a bit in terms of like having its own internal states. Can we think of the
environment as doing anything with surprise, or are we staying agnostic on what the environment
is doing? Right, so again, a very leading question. Sorry. Good.
I'm just, there's a whole other podcast under the hood. Possibly I'm not the best person to
have that conversation. There are people who speak, I think, in an informative way about
this perspective. But what you are suggesting is that one can appeal to the mathematical symmetry
of this way of partitioning the inside and the outside of the Markov blanket,
which has an exact symmetry. So that technically, certainly at the level of sort of basic
sentence and sense-making of the kind we were discussing earlier on, it is mathematically
true that you can also interpret the environment as inferring your internal states. Because you've
got this generalized synchrony, which is another manifestation of self-information or surprise
or surprise minimization when the surprise is a measure of your sensory impressions. So
on that view, the environment now is acted upon by you in the way that, from the environment's
perspective, render your actions sensory inputs and the way that the environment acts upon you
is by providing you with sensory impressions. But yes, mathematically speaking, the environment
should certainly be modeling you. And there are various flavors of that truism that you could
pursue. One would fully acknowledge that there is clearly a vast asymmetry between you and your
environment. The environment is usually making it bigger. It doesn't always have the same delicate
structures or the precise mechanics that would require the sort of planning that we're talking
about in terms of the expected free energy. So we're not saying the environment balance, but
in terms of still trying to minimize prediction errors and doing the right kind of learning
about you, I think there is good evidence. Well, you can certainly read certain aspects of the
environment as doing exactly that. So the favorite example is the elephant path of desire path,
the shortcut that is worn by repeated use across a grassy lawn when you're getting to,
you know, what the cutter corner to walking through the park or to your favorite coffee
cafe. So one way of looking at this is this is something I've done, you know, to my environment
and I've done it with my conspecifics. And I've created a little path to my favorite face or
that is the favorite of me and my conspecifics. From the environment's point of view, it's learned
a lot about the behavior of its inhabitants, of its denizens. So, you know, you think you are
impressing yourself on the environment, the environment points, environment's point of view,
it's just a Vincent kind of plasticity, an experience dependent kind of learning,
whereas remembering things about you. And you can take that argument right through to
those kinds of parts of the environment that are actually constructed by conspecifics,
by traffic lights, by signs that have a semiotics and a sort of deontic value.
So you could just, you know, you could say that the lived environment that you would
express if you walked out onto the street, it's all man-made and it's all built to
maximize expected information gain. I mean, what is a sign? It is there to create an environment
that sates our curiosity in terms of making it easy to respond to epistemic affordances
that you're underwrite our curiosity or our plans to maximize expected information gain.
But we build that. So this, then you go into the role of, you know, into the game of cultural
niche construction and the notion of the designer environment from Andy Kerr, for example.
So, you know, all of these, you know, I'm just summarizing conversations you could have probably
with other people who they want to. The final kind of conversation you might have is that
when you realize that your environment is composed of other things very much like you,
right, when you're young, your mum or as you're old or your colleagues and your friends and your
family and your specifics on the street. I think that's interesting because now we're
getting to a much more symmetrical sort of relationship between me and the environment
and certainly in this context, most of my universe is basically you and me. So now there's a certain
kind of symmetry in place. Whereas you are my environment and I am your environment. And yet
we both have gelatine models of our environments, which basically means I have a gelatine model of
you and you have a gelatine model of me. Minimizing the surprise in the exchange is
one description of, can be understood as leading to a generalized synchrony at literally a meeting
of minds, a mutual predictability. The rest of all certain things such as communication and language
and certain common frames of reference common ground. But you could actually argue that in this
setting, it is an inevitable consequence of joint free energy or surprise minimization
when we put two of the things that are sufficiently similar together,
that this would be inevitable. The best way to minimize surprise, when I surprising signal
that generated by things like me, namely you, is to ensure that I was much like you as possible,
so that I can predict what you're going to do next because that's what I was going to do next.
And exactly symmetrically so for you. So that basically means that we come to share a gelatine
model, a shared narrative we're seeing from the same chemistry and everything becomes mutually
predictable. That would be one explanation for the kind of in-group formation and the kind of
the mechanisms you might find in evolutionary psychology that could be described in terms of
niche construction. What it doesn't describe though is the going back to your twilight zone
and the man in the nice hell, the epistemic hell. So if it was the case that we could become
completely mutually predictable and just keep on singing the same song together for hour after
hour after hour, that would become boring. So now we come back to what would this kind of mechanics
and this way of understanding self-organization look like when impact in societies and in exchanges
between different kinds of conspecifics. And you get to really interesting questions about
polarization in-group, out-group, the spread of ideas and the spread of memes that can be simulated.
And at this point I think you're now into sort of social neuroscience and joint free energy
minimization that can sometimes lead to quite paradoxical results or understandings of the
way that we search for information or engage with people. On the one hand, I want to make my world
as predictable as possible so I don't get any nasty surprises. So I'm going to go to those kinds of
news channels. I've talked to this kind of person because I think that we have a line frame of
reference. We have common grounds. We speak the same language. On the other hand, I'm going to be
compelled to be slightly curious about other ways of thinking. We're not all going to merge into one
massive community, one massive hive mind, one massive collective intelligence. That's not going
to work because we are compelled to, what would happen if I looked at it this way? Or what's that
kind of person like? What's this culture like? So I haven't got any answers but there's a really
interesting field in social neuroscience. Sure. It reminds me a bit about, I think you've spoken
to it a bit, the Explore, Exploit, Trade-Off, EETO, a little bit because it's sort of this balance
between exploiting sort of the linearist, say, most accessible forms of energy or, say, news
content, but then also having this balance between doing that and exploring, say, other modes of
thought or exploring what else is out there and that balance, that getting that balance right.
And I think you said something to the effect once about the free energy principle that it gets,
was it solves it in the right order, something to that effect. I think it's, in the way I
perceived it was, or viewed it was, in order to know what's surprising, you have to know what's
possible, kind of. Does that make any sense? Is that performing it? Absolutely. So yeah, I probably
said it sort of dissolves the exploitation, exploration dilemma, but you're absolutely right.
It does so in a particular way and it does match in terms of the order in exactly the way you say.
So if I go to this gambler's heaven, there's an enormous opportunity for me to resolve uncertainty
and to indulge my curiosity, to respond to epistemic affordances, which is the expected
information part of the expected surprise and the expected free energy. So I'm going to, first of all,
explore all possibilities. What is possible in this particular new environment? I moved to a new
city or I put a new device in the kitchen. So the first thing I'm going to do is explore by
becoming a little scientist and trying out this and that and going there and seeing what happens
until I have resolved sufficient uncertainty that there's no more, you know, reducible uncertainty
there. At that point, the component, the expected information gain will fall below
the expected costs or the expected utility. So I'll have innate preferences, you know,
that I put constraints on my exploration. So at the point where you literally, your epistemic
expected information gain falls below the expected value, then the expected value will
take over and I will switch deterministically to exploitative behavior. So that means the first
thing I'm going to do is explore and then so there is no uncertainty left to resolve and then I will
exploit. So exactly secure the possibilities and then just act in a way that is predominantly
dictated by my preferences or my constraints. Another way of looking at that is
we are primarily surprise minimizing or uncertainty minimizing creatures, but we do
so in the constraints. The constraints are provided by our prior preferences or by
the constraints afforded by the fact that being in this state would be very, very surprising.
So, you know, one way of looking at this resolution of the exploration dilemma
is that it's not a dilemma in any sense. We are quintessentially exploration machines,
exploration, curious artifacts, but we have constraints that we can't become dead or disabled
or dehydrated or dissipated. We can't allow ourselves to be damaged, but under those constraints
our primary imperative is to explore. Unless of course there's nothing left to explore and then
we get bored. Yeah, sure. The train off. Are you familiar at all with, I believe it's called a
number of different things, but it's like a game theory question. So you call like the marriage
problem or the secretary problem. Have you ever heard this before? Yeah, so would you like to
hear it? I don't know. Yeah, so basically the way the game works is you're looking for, you know,
a partner, a life partner, and the question is how many partners, how many people should you date
before settling on one person? You know, how do you know the available options? I guess,
how do you know when to stop looking is kind of the question. It's also called the secretary
problem. It could be called the hiring problem because sort of like the question of, you know,
you see one applicant, you have to say yes or no to that one applicant, and if you say no,
you can't go back to them, right? The jilted x, let's say. You know, you can't ever go back to,
apparently what's optimal is, and you have to know, it's what's interesting is you have to
know kind of how long you're willing to date, you know, how many partners are you willing to sort of
to suss out. And the answer is you basically date and you say no to the first 37%
of potential partners or potential applicants, let's say it's for a job. And then after that point,
you say yes to the first person who's better than all the options you saw already.
It's kind of how it works, right? So it's like, you have to date around, you have to kind of
explore, but even if you find someone that's incredible by this model, you're not supposed
to say yes to anybody until you've seen a little more than a third of the whole people that you're
trying to observe. And that just makes you think about EETO a little bit because, you know,
it requires a certain amount of exploration. Obviously, there are certain parameters here
that are more firmly set than you'll find for most system environment dynamics, but
that there is actually technically a mathematically precise sort of strategy that works across the
board. So I just thought I'd share that. No, I haven't heard that. That's brilliant. And it reminds
me of sort of evolutionary game theory, having sort of, you know, stay wins on different strategies
and, you know, which super things that an evolutionist has done as well.
The free energy principle. How it reacts to or how it's related to the Hamilton's principle of
least action. Can you possibly make that help make that link? Yeah, well, so the free energy
principle, as we were discussing earlier on, can be regarded either as a variational principle of
least action or a constrained maximum entry principle is depending upon, you know, your
favorite way of understanding the maths. So the variational principle of least action just is
an instance of how it's this principle of least action. Technically, what both when applying
Hamilton's principle of least action say to mechanics or movement of massive objects, for
example, what these principles prescribe is a prescription of the trajectory or path that
something will take. So you could apply Hamilton's principle of least action to the trajectory of
a ball if thrown at a particular angle with a particular velocity from this point. And it
would be the case that the trajectory caused out by that ball would be a path of least action.
It would be the path that minimized a certain energy when averaged along that path. So this is
a path integral, which means adding things up. So the path of least action, the path of least
resistance, if you like, where the resistance scores the expenditure of energy in order to
because it deviated from the path, is prescribed by the principle of least action. And you can
use that principle then to predict or to describe the most likely path that anything will take.
And indeed, that sort of path integral view is exactly where free energy, the variational
free energy comes from. But here we're talking about sort of Feynman trying to work out the
probability of various paths of small particles or say electrons. So a very difficult mathematical
problem that was finessed by introducing this notion of a variational bound on the probability
of a particular path in his pathological formulation, quantum electrodynamics. The
math is identical to the free energy principle. And it just says that there is a particular
path through a space of beliefs that is the most likely. And in the same way that there is a
particular path, if I throw a ball, that is conforms to Hampton's principle of least action.
And the space through which we're talking about paths traveling now is the space of probabilistic
beliefs encoded by the internal states of something. So it's slightly more abstract,
it's more about the measurement thing, more like the sort of James in use of the word entropy,
or the way that James would apply his entropy to belief structures. But the mathematics,
the variational calculus is exactly the same. It just tells you, given a particular initial
condition and some sensory input, for example, I can tell you the most likely trajectory of
beliefs that would be described in terms of belief updating, for example, will ensue using
this variational principle of least action, which is the free energy principle. It's exactly the
same maths. I'm just trying to think of even more intuitive ways of describing it. It's a path of
least effort. It's just a mathematical way of describing the path of least, path into the
future or the past of least effort, where the effort is effectively scored by the amount of
surprise I can avoid. Are you familiar with Jeremy England's work with dissipative adaptation?
Yes. Well, I was about four years ago pre-covid. Yes, I haven't read what he's been up to recently.
So he moved recently. He moved to Georgia, I think. Oh, really? Oh, I didn't realize he moved. Yeah,
but it's far more of it. I know it's more of a thermodynamic. It's solely, I think,
a thermodynamic, but it makes me, because one of my general interests or one of the things I try
to get to is, you take it as something like the free energy principle, you try to think,
okay, what's even more fundamental than that? You keep trying to cut away and say, okay, well,
how do you make this even, what's behind that? What's below that? What kind of feeds into that?
And I don't, I mean, it to be completely transparent. I don't fully understand
how dissipative adaptation works. I think that's something to do with the environment
adjusting itself to best accept the energy that's flowing through it, something like that.
But of course, it's very technical. Is that at least, I know it's maybe been a few years since
you follow the idea, but does that, does it conform? Well, I guess it would have to, but
does this play into the free energy principle at all? Or is this a dynamic that kind of works?
No, I mean, it's fascinating work. And you may also want to invite Suzanne Still
to one of these conversations who's been doing very similar work from the point of view of
sort of predictive information theory. And recently, she's also been looking at this sort of
remarkable capacity of systems to, again, resist the second law and, you know, use their free
energy thermodynamically, which she would frame it in terms of information theory,
to extract order from, from AELS. And you'll comment a lot of these notions, there's a notion of a
ratchet, that you, you, you, you, you, you can make little random jumps, but you, you, you maintain
them. And each jump is maintained. If it's heading in the right direction, you know, if they are
minimizing sort of free energy at the expense of something else. However, I have to say,
it's not really addressing the same kinds of issues that the free energy principle is addressing.
I have to say, also, you won't get more fundamental or simpler than the free energy principle.
So I look at thermodynamics as one particular domain of application of that kind of mechanics.
The only difference between thermodynamics and the free energy principle is that the free energy
principle actually commits to a thickness, it commits to a Markov blanket. So it's now got
a partition of states where you can start to talk about beliefs in a non-trivial sense,
in the sense that there is a morphism from the internal states of a physical system
to the states beyond the heat path or beyond, beyond the blanket. And all the more interesting
questions are really about the maintenance of that blanket or the heat math. It's not about
equilibrium physics or things on the inside. Most of them are just rather uninteresting
descriptions of ensembles of things on the inside that have some particular exchangeability
criteria, and then you can apply classical equilibrium physics to that. That's not terribly
interesting from the point of view of people looking at non-equilibrium physics, and even
less interesting from the point of view of people looking at real, randomly dynamical
systems, because these systems are not exchangeable. You mentioned before that Mike Levin's description
of sort of cells of cells of cells of cells are bounders and bounders and bounders and bounders.
Markov blankets are blankets and blankets and blankets. There's a heterogeneity to
implicit in that scaling variant description of actual systems that will not allow you,
I think, to apply to adopt the assumptions that we would have to commit to if you wanted to apply
thermodynamics. So I have a quite dismissive attitude to thermodynamics. So in that sense,
trying to understand the thermodynamics of self-organization, I think it's possibly misguided
because you have to make too many commitments to the kind of systems, particularly the exchangeability
of ensembles, to make it really interesting. On the other hand, the questions that people like
Jeremy England and Suzanne Still more recently have been addressing are, I think, deeply interesting,
and are not really addressed by the free energy principle. I think what you're talking about here
is the sort of the complexification that seems to be an inevitable property, certainly of biotic
self-organization. You could argue other kinds of self-organization, but certainly biotic self-organization
are far from equilibrium systems that have this kind of stale freeness and implicit heterogeneity in
them. I think that there has yet to be a simple story to express why we are becoming increasingly
more sophisticated increasingly, but if we are, we're organized. I think that's a fascinating
issue. I don't have a clear answer and I will repeat. The free energy principle itself does not
properly address that because the free energy principle starts by saying, let's assume something
in our self-organized, housed an attracting set. That's where it starts and that's really where
it finishes. I think if you want to think about how these attracting sets involve and contextualize
each other, I think you're going to be in a slightly more challenging frame, which lots
of people are addressing and it's a really interesting question. I'm not sure thermodynamics
is the right toolkit to address that, to be honest. I think you need to look at more fundamental
maths, probably quantum information theory at different scales and think about that through
the lens of say, theoretical biology and evolutionary thinking. Sure. I'm so glad you brought up
quantum information theory because that's where I wanted to go next. I was wondering if the free
energy principle lends any credence to the idea or has any relationship to, I'm not sure if you're
familiar with some theories about the universe being like a quantum air correcting code. If
you're familiar at all with that landscape, basically it's a speculative idea, but looks
like there's some evidence to support it that the fabric of space-time itself is actually
like a quantum air correcting code. When I hear that and I think about the free energy system trying
to minimize uncertainty, it's trying to, you know, close to air correction or it seems kind of
similar too. I wonder if there is a potential link there and if you have any comments about that,
or if that's something that's come across your desk. No, it literally came across my desk
about three or four weeks ago, so suddenly sent me this paper on the universe being air correcting.
Delighted. If I remember the sentiment of the email was, you know, it would be great to get
this chaps or this woman's take on this, you know, in relation to free energy,
theoretic formulation, because, you know, it seemed as if there was a very, very close connection
as you have spotted. I think the best person to comment on that would be Chris Fields, you know,
so, you know, I did quantum physics as a young man, but that was 40 years ago.
I usually defer to Chris when he comes to quantum information theory, so he has a beautifully
rounded perspective on these things and will probably be able to give you quite a definitive
answer. He'll probably say, yes, it's the same thing, but then try to explain why it's the same
thing. Yeah, it's hard to link it to. I can't do that. Again, I will be surprised if all of these
things weren't entirely conciliant. And I probably, ultimately, you know, you probably aren't going
to fall back on something like James' maximum entropy principle, certainly if you know quantum
information theory. You will probably find an equivalent description of the kind we've already
mentioned in terms of variational principles of least action, but you may also find similar
explanations in gauge theory and ultimately category theory, but they should all, I think,
be internally consistent. You should be able to sort of morph from one to the other without doing
too much to help you steal elements in anyone, your favorite way of framing them. I'm sure the
other directing universe is one example of this. Yeah, this is very well could be. It reminds me
too of Chris Fields, a frequent collaborator of his is a cognitive scientist, Donald Hoffman.
I'm not sure if you're familiar with his work. I've interviewed him a couple of times on this
channel as well. But one thing that you said that stood out to me, and it's something that
he said as well, or something similar, is that we don't need to know the truth. We just need
to minimize prediction error. You know, it's like this very separate thing. I don't know if you're
familiar with, he's got a few different theories. I mean, one of which is fitness beats truth
theorem, that we evolved in order to basically maximize fitness instead of to see what's
vertically actually there in the environment. So much of what we see is, or all of what we see
is an illusion. We can never, he posits that we can never actually get to the base reality,
the base truth. And I'm sure if you have any thoughts about that, or if it's something that
you've come across, or if you've spoken with Don.
No, I think that's absolutely right. And it sort of leads you to interesting discussions. Should
you want to go there in terms of skepticism versus realism, internalism versus externalism,
and the like with philosophers. But certainly, from the point of view of the maths, the physics
of this kind of sentence, it is all about making, forming or understanding internal dynamics as
encoding subpersonal probabilistic Bayesian belief about stuff which is fundamentally hidden
beyond your mark of blood, beyond your sensory veil. It is inaccessible. It is unknowable.
And I think probably Chris Fields would frame this in terms of holographic streams,
sort of appealing to the holographic principle that, you know,
acetyl exchange of information across your sensory veil or your mark of blanket
can be construed as a holographic stream from the point of view of quantum information theory.
But that's the only way you can entangle a couple to systems, you know, with classical information.
So, again, we come back to this fundamental separation between the inside and the outside,
which, you know, read in terms of your conversations would be exactly, you can never know what's out
there. But you don't need to. If you can keep your prediction errors very, very small for as
long as you live, job done. I mean, that's perfectly okay. It does raise the interesting
issue that is there an outside, which would be a more philosophical issue. So both Chris and I,
I think, would have to commit to the fact that there probably is an outside in order to help,
to actually be able to read and write to your holographic screen or to be able to
transact with an environment, you know, in terms of in both directions over your mark of blanket.
So the free energy principle puts you in a slightly ambiguous position when it comes to
philosophy. So on the one hand, you can be entirely skeptical. Everything that needs to be done
is beneath your mark of blanket within the skull bound brain. There is nothing else.
On the other hand, you're making sense of signals that are provided by something
out there. So you have to commit to a mathematical description of stuff being out there.
What the something is, sure. I'm just really looking at the time and I realize we've gotten way
over what we had sort of planned out to go. I hope you've enjoyed this discussion. I mean,
I've gotten so much out of it, Professor, and thank you so much. Anything else you want to?
I mean, I literally have so many questions I could continue to ask you, but I do want to be
mindful of your time and energy as well. So please let me know if, you know, if you have a few
extra minutes, I can ask you a couple more. But if, you know, if you've reached your limit,
please let me know also. Please ask me two more questions and then I'm going to go and have a
nice cigarette. Okay. Oh, that sounds nice. That sounds lovely. Yeah, one of those once in a while
isn't so bad. I think, okay, okay, two questions. So now I have to really narrow it down here. But
we'll see that's a little bit. Well, one, one I'll ask you is, and I'm surprised we actually
haven't touched on it, active inference, which honestly, for, I mean, maybe the first couple
weeks I was looking into the free energy principle, I actually thought they were the same thing. I
actually think it's written in other places. I think Wikipedia maybe kind of writes them as
equivalent. And I believe active inference is a subset of the free energy principle or it's like
well, perhaps, I mean, you could probably, you could definitely do the best job.
Can you help separate the two or help us make a distinction between
free energy principle and what active inferences?
I think you could be forgiven by using them synonymously. And so, you know,
that's how it was portrayed, I think, in the Wikipedia links. Having said that,
you know, in the world of philosophy, one's got to be a little bit more rigorous in the way that you
frame various offerings. So nowadays, I am, and a lot of my friends in philosophy are also very
careful to distinguish between the free energy principle, which is just a method. So very much
like we were talking about Hamilton's principle of least action as a method for determining the
path of least action or least effort. The free energy principle is just what it is. It's just
a method. It's a tool for describing the most likely kind of active sense making or belief
updating or, as you say, active inference. So it's not falsifiable. It's not a theory.
This is a principle. This is a tool. It's a method. If you apply that to purposeful behavior,
then you have active inference. So active inference, I think, is an application of the free energy
principle to usually simulate or predict or emulate or to model purposeful section behavior,
basically. So I've given you a long-winded technical answer. So free energy principle
is usually for physicists and philosophers. The philosophers like to shout about it. The
physicists think it's probably quite trivial. The active inference is more an application
that you might want to actually apply if you're a psychologist or artificial intelligence
researcher wanting to emulate this kind of behavior or understand, say, given subjects
behavior by fitting an active inference model to that subject's behavior using the much more
practical way. I mean, you can regard the free energy principle as only having utility in that
ability to simulate active inference. Just technically, the only thing you get from the
free energy principle is really a way of writing down the dynamics of self-organization
as a gradient flow on the generative model, on those prior preferences, on the probabilistic
description of those attracting sets, which means instead of just looking at the way a system behaves,
given its dynamics and trying to reverse engineer its Lagrangian, what you can do is actually write
down the Lagrangian as a Jamesian constraint as a set of prior preferences and then just apply
the rules of the free energy principle to simulate the behavior of a system that self-organizes to
that set of attracting states on that particular set of preferred states. And that's basically what
we do in computational science and machine learning research. Okay, thank you very much.
That helps. The distinction is super helpful. Great. Now, last question. I had a kind of
bunch of different ones. I'm like, oh, I forgot to ask them about attractor landscapes and
strange loopiness, but I will instead ask you if you, this is more of a metaphor, this is
personal question, but if you could give your 20-year-old self one piece of advice,
what would it be? So if you could go back.
My 20-year-old, I think it would, no, I'm trying to be too clever about this.
Okay. Probably to go to the dentist more often, to be honest. If you're much less
trivial answer. I think it would be nice to do a couple of years of philosophy.
I always say when people, when my children and when my students and when other people ask me,
what's good career advice? It's keeping your options open. You've used that phrase earlier
on today. And I think there's something quite fundamental about that. As broad a foundation
as possible, bearing in mind that we are all quintessentially curious creatures. And therefore,
if you omit your academic career, you are indulging that. But the best way to explore is to have a
very broad foundation. And I managed to do that to a certain extent. I didn't miss out a lot of
history and a lot of philosophy. And I remember one of my mentors, Gerry Edelman,
used to refer to me. I won't say fondly. He just used to refer to me as an intellectual thug.
My lack of scholarly understanding. And very little finesse when it comes to sort of
or history. So it would have been nice. I don't know what would have happened if I had spent time
doing that. But it would have been nice just to involve myself with a couple years in that kind
of training. Sure to have that base. But there's still time. I mean, it's not like, you know,
I mean, I'm sure you're busy. So you don't have too much free time. But, you know, it's always available.
Well, Professor Friston, thank you so much. This has been, I mean, this has been amazing
speaking with you. And I'm so honored, so blessed that you take the time to speak with me. And I'm
I'm sure the audience will appreciate everything here. And I'll include links in the description
of this video for people who want to learn more. If you want to read your papers, I'll link to
some of your papers and some of your some of your presentations. And yeah, thanks again. It's a treat.
Well, thank you. I really enjoyed talking to you. And I'm going to find out how long we've
been talking. I deliberately haven't looked. I shouldn't have said anything. I wish I had
said anything now because I'm going to ask you about attractor landscapes. But no, yeah,
it has been a while. And I appreciate so appreciate you going over.
Right, I shall go away thinking about attractor landscapes and what I should have advised myself
to do when I was 20 years of age. That's a great question. Bye.
