Mike, thanks for coming on.
Yeah, good to see you again, thanks for having me.
Yeah, such a pleasure, absolutely.
I can't believe we're on round three
of our conversations here right now, time flies by.
And for people in the audience who haven't yet caught
our first two rounds, those will be linked below
in the description.
And around one, we covered the computational boundary
of the self paper, the cognitive light cone diagram
that folks will be familiar with, I'm sure.
And then around two, we covered observer-dependent computing,
your paper with Joshua Bongard on polycomputing,
and also the technological approach to mind everywhere.
Today, we're going to cover a couple of papers
that were recently published just in the last couple of months.
Your paper on bioelectric networks
being the cognitive glue for organisms,
and then Darwin's Engential Materials,
that'll be the second paper we cover.
And then finally, Biology, Buddhism AI,
your paper with collaborators that I think will be
the third act of our conversations today.
So I'd love to get us kicked off first.
And those papers will be linked below in the description
as well for folks who want to dive into those.
They can be pretty technical, but I
recommend going through them and discovering them
for yourselves.
There's a lot of great diagrams in there as well
to help people kind of grok these concepts too.
So if we get started off on the bioelectric networks,
the cognitive glue enabling evolutionary scaling
and physiology to mind your paper,
could you provide us with a brief high level summary
of the paper and what's covered here?
Yeah.
Well, I guess the first thing to do
is to talk about what cognitive glue is
and why such a thing is needed.
And I use that term just to kind of draw attention
to the following thing.
We often people think about collective intelligence
as flocks of birds and colonies or termites or bees
or something like that.
And they contrast that sharply with themselves.
They say, well, I'm not a colony.
I'm a unified individual with my own thoughts and goals
and all of that.
But actually, if you sort of look inside, what you find
is that, no, actually, you are a colony.
Like each of us is a collection of cells, neurons
and a whole bunch of other stuff.
And I want to emphasize this idea
that that is not to be taken for granted.
You cannot take for granted.
It's actually kind of a miracle, not in the sort of religious
sense, but in the scientific sense of something really
profound that needs understanding and explanation.
It's kind of a miracle that a collection of individual cells
with their own agendas and their own ability
to pursue various goals in physiological space
and gene expression space and so on,
that there is a way to arrange those things that gives rise
to this emergent new self that operates
in a different problem space.
And in fact, we'll end up often, we'll end up denying the fact
that it is made up of parts with their own agendas.
I mean, that's kind of wild, right?
And has its own goals where some of these goals are often
at odds with the goals of the parts.
And we often do things that aren't particularly good
for certain cells in the body and so on, right?
Or even certain organs.
So that's it right there, that it's very clear
that there must be a mechanism for doing that,
for transitioning from just a pile of cells
to something with its own self.
And we can sort of define, we can do a little bit of definition
there too if you want, but so that's the goal, right?
So now, even though people don't think about that very much,
like that, the reality is that of course,
the whole field of neuroscience is predicated on the fact
that we know what the cognitive glue is
for behavior in the brain, it's electrical signaling.
And let's say electrochemical signaling in the brain.
So that's the idea.
And my point in this paper and in some previous papers
is that there's a reason why
by electrical signaling is so good at this in the brain,
it's because it's been, it's had lots of practice
evolutionarily where this all comes from
is by serving as cognitive glue for a morphogenetic agent,
which is the thing that arises
when a bunch of individual cells in an embryonic blastoderm
suddenly start to cooperate toward a very specific goal.
They're all going on a journey
in this anatomical space of possible configurations
of possible shapes that anything can be.
They're all committed to helping each other
get to one particular region of that space
that corresponds to the target morphology of that species.
And so, yeah, so that's what this paper is about.
It's about how bioelectricity serves as that kind
of cognitive glue and then evolution kind of pivoted it
to do the same thing in three-dimensional space
for the control of behavior.
Awesome, yeah, thank you for that summary.
And I'd love to hear, I mean,
one of the second question I had here was,
how did you land on the term cognitive glue?
Like, were there any other terms of phrases
that you were kind of deciding between?
For that one, I mean, I don't know,
I use a lot of kind of these kinds of terms
that I just sort of come up with,
but for that one, I'm not sure if there were any competitive.
I mean, you can think about some sort of binding policies.
You can call it some sort of an emergence,
a self-emergence mechanism.
I mean, you can come up with it,
but I just thought it was simpler to point out
that it literally is a kind of cognitive glue
because without it,
think about what happens during general anesthesia, right?
So you walk into the doctor and there you are
and you have all kinds of thoughts and hopes
about what happens and you say,
boy, I hope the surgery goes well.
I've got a big thing, I got to do a month through now.
And then the gas comes in and one of the things
that happens is the gap junctions
between your cells get inhibited.
So now you're gone for the next however many hours,
you're not there, your cells are still there,
all the pieces are still there, nobody's damaged,
nobody's dead, the cells are all functional,
but you're gone.
And one reason you're gone is because
that cognitive glue has been temporarily dissolved.
It's the, there really needs to be something
that binds all this together.
And glue, it's kind of silly
because it's not that physical kind of thing.
But with this idea that everybody has to be kept together
and the way that glue does in a particular space,
it's not just physical proximity,
the cells stay close to each other.
It's a kind of informational proximity.
And actually, people like Giulio Tononi and others
actually study this from an information,
study that integration from an informational perspective.
But that's really what's needed is a mechanism
to hold together the cognitive system
that is then going to make claims about itself
being a separate agent from the parts that make it up.
Yeah, it's interesting.
One very specific question I had in the paper,
and it may have been in there,
but maybe I just potentially missed it,
but there's a quote in there.
If you don't mind me just reading it off here.
It's developmental by electricity
as a precursor of brain like processes,
which reveals not only evolutionary pivots
between two different problem spaces,
but also shows a path to solving the problem
of collective intelligence across scales of organization.
What are the two different problem spaces?
And perhaps it's just an example being made there,
but I think there's a mention here of evolutionary pivots.
Can you give the audience an example
of what you mean by that?
Sure, well, so first let's name some problem spaces.
They're just kind of roughly in order
from the beginning of life.
So you've got the space of metabolism,
that's a problem space,
because you have to figure out how to keep,
if you're gonna persist in the real world,
you have to figure out how to operate metabolism.
And then there'll be some sort of physiological problem space
where aside from metabolism,
you have other physiological features
that you're trying to outkeep.
And then at some point you get a transcriptional space
where there's actually genes now that can be expressed.
And so that space, very high dimensional space
of the correct gene expression
for whatever you need to be doing at the moment.
And then when you get to multicellularity,
there's an anatomical morpho space.
How many eyes are you supposed to have?
Are you supposed to have eyes?
What's the, where's the head go?
Where's the tail go?
Those kinds of things.
So that's an anatomical space.
And then after that, you get to behavioral space
because eventually you develop muscles and nerves
and now you can actually move around
in three dimensional space.
And so now you can do what's classically known as behavior,
all these other things of behavior too,
that just behavior in weird spaces
that we don't normally think about.
And then maybe if you're,
if you're some sort of human or something else,
you might also operate in linguistic space.
So we actually have a project now looking at navigation
of linguistic space as exactly that kind
of navigational process.
Oh, interesting.
Yeah, yeah.
And maintaining, you know, this idea.
So there's one central concept to all of this,
which is navigation.
This idea that the space is rich,
it has structure.
You as an agent have various kinds of preferences
about which parts of that space are better for you
and which parts are worse.
And therefore you need to navigate it.
Now, you have different degrees of competency
of navigating it.
You might navigate it the way that a bowling ball
or a dandelion seed might,
which is you have very little internal control
if any of what happens,
or you might be some sort of something in between,
you know, there's various seeds with little corks,
corks, screws and things
that kind of help them do various simple things.
You might be some kind of a, you know,
a simple homeostatic agent,
like a little thermostat that's actually better
than these other things.
Or you might actually be a learning system
that can have anticipation and associative learning
and things like that.
Or you might be really complex and you might have planning
and you might be able to really think forward pretty well.
And then you might be really complex
and have a gigantic cognitive light cone
where you can sort of imagine
lots of complex things far into the future way
outside of your current scenario.
So anywhere along that continuum,
there are some, you might have some competencies, right?
And you navigate that, those spaces.
And so what I mean by evolutionary pivots
is simply that once you're good
at navigating one kind of space,
it's relatively, I think this is all, you know,
this is all kind of the framework that I work on.
So lots of things we don't know yet,
but I think it's relatively easy for evolution
to switch spaces on you.
Because if you're good at navigating
a particular kind of space,
we can swap some sensors and some effectors
and you can use all the competencies you have
to navigate some other space.
So just for example,
hybrids, right?
Hybrids are when you take a brain
and you put it in a robotic body such as a vehicle.
And so in that case, in that case,
the brain instead of leg muscles
might be connected to some wheels.
And instead of eyes, it might have some photo arrays.
And if the brain is good at doing these things,
it will, and then so people have made these things
and they have various behaviors.
And it sounds kind of crazy and wild,
except that that is the normal scenario.
You see, your brain doesn't actually interface with reality.
Your brain interfaces with your eyes
and your muscles and various things.
And all of this is highly plastic.
We've made tadpoles where the eye is on its tail
instead of in the head.
Those animals can see perfectly well immediately.
They don't require new evolutionary adaptation,
periods of evolutionary adaptation,
they can just see in this new configuration.
And that's because, and the same reason why
sensory augmentation and sensory substitution.
So this has been known since at least the 70s,
probably before that, that you can do all kinds of,
you can give humans all kinds of weird sensors
and effectors and they very quickly become part of them.
So they become, for example,
Bakirita in the 70s used to do this thing
where it's like, you know that toy,
I don't know what it's called,
but it's like the square thing
with a bunch of metal nails and you put your hand on it
and it kind of makes the imprint, right?
So you can imagine an inverse of that
where the little pegs go and move in and out.
So you take that thing and you put each peg,
you connect each peg to a pixel on a camera
that you wear on top of your head.
And then you take that thing
and you put it up against your belly
so that it's poking you based on the pixel
that nail is poking you or not, right?
And so he did experiments with people who were blind
who learned to navigate that way
because you can remap the information
that you're getting through your skin
because the plasticity is incredible.
Look at the rubber hand illusion.
You can see these videos online where you've had,
as a tetrapod, your brain has known how many hands you have
for how many millions of years now
and within seven minutes of this visual input
of somebody stroking this rubber hand,
you've now decided that you have three hands.
You're perfectly willing to abandon that prior.
And when somebody hammers the rubber hand,
people jump up and scream.
And so the plasticity is incredible.
And that's why when people get prosthetics
where the wrist goes 360 degrees around,
when they reach for a cup,
they'll rotate the way that your normal wrist never rotates
because they get used to it, that's your body now.
And so all of these things, this kind of plasticity,
so that's why I think evolution fundamentally
makes these kinds of systems that are,
they kind of figure out what they are on the flies
or like Josh Bongard's robots from what, 2006 or so,
when he made these robots
that didn't have a predetermined model of what they were
and where the effectors were and where the sensors were.
And they sort of flopped around like babies,
they flopped around until eventually they figured out
how to move around
because they built a model of themselves
and what their structure was.
And that has the awesome side effect
that if you rip off one of the legs,
it'll just go through a similar process
and remap to the new and then move in a different way
given what you have now.
This is exactly what we see in biology
where with a very wide range of various accommodations
to novel circumstances can be had
because evolution makes these problem-solving machines
that are very good at defining
and redefining themselves on the fly.
So that's what I mean, right?
These tricks that work well in one world,
swap some stuff around, swap a time scale,
swap the sensors, swap the effectors
and now you're walking around in some other kind of space.
I have a feeling that that's what's happening.
That's my guess.
That's wild.
I've never heard about this, the 2006 Vanguard.
Oh yeah, look it up, it's great.
I think it's very, it's really foundational, yeah.
I have to do some digging on that for sure.
Thank you for mentioning.
And there's, yeah, so many great,
wow, so much awesome stuff I wanna unpack there.
One of which, well, a few things that I think keep coming up
sometimes like a phrase or an idea
that's from our discussions
or from listening to you on other podcasts,
you say all intelligence is collective intelligence,
which I think is really great.
I think the emphasis, a lot of people need to hear that.
The other thing, and I think you just touched on it a bit,
is that, or maybe in our previous discussions you did too,
we, a lot of people think of the brain
as having this like exalted status
of that the brain can do all these things
that other parts of the body can't do.
But what's, and it's in this paper as well
and other papers too,
but sometimes there's memory stored outside the brain
and some of the research that you've done.
Can you give us a sense of what does the brain do
that's actually different than the body cells?
So, yeah, so what does it have
that say other parts of the body can't do?
Yeah, yeah, so as much as I try to lean
on the commonalities between brain and other tissues,
I mean, it's pretty obvious.
There's a reason why we have brains.
Brains give us extra features
that we wouldn't have otherwise.
And so just to, I mean, the most obvious one is speed.
So neural bioelectricity is way faster
than developmental bioelectricity.
And I think that was part of an arms race
at the beginning when things started moving around
and trying to eat each other and avoid being eaten.
Speed became of the essence.
I mean, developmental biology,
I mean, yes, you want to complete embryogenesis
quickly as you can,
but it's not under the same speed constraint,
I think as actual three-dimensional behavior.
So there's speed in this idea.
Then there are the point connections.
So neurons can be incredibly long.
And so if you want to make a directed connection
from here over there without that neural architecture
of having an axon that reaches all the way down,
I mean, they can be meters long in some animals.
Without that, the basic bioelectric system is cumbersome
because it basically things spread as waves
or they propagate through the gap junctional milieu.
It's not the same as, right?
So those are kind of the architectural things.
I mean, a lot of the components are conserved.
So ion channels, neurotransmitters, electrical synapses,
all that stuff is conserved,
but it's used in a different way,
both for speed and for direct connections.
And then there's just, there are the things
that we know that are associated with brains
that we haven't found anywhere else.
So for just as a sort of high-end example is language, right?
So I've seen no credible claims
that the other organs in your body
are using this kind of syntactic language structures
that brains use.
Not saying it's impossible.
Who knows?
We might find some kind of syntax,
but there isn't any evidence for that yet that I know of.
So that I think, but other basic stuff is the same,
perceptual control and predictive coding
and all kinds of that happens in all cells.
I wanna come back real quick
because I do think this is important
to something else that you said a minute ago
about the collective intelligence
and the fact that people need to hear that.
So I wanna just talk for a moment about
what it is that I think they need to hear about it
because some people and I keep, I'm always fishing,
let's see if this helps at all,
but I'm always fishing for a better way to make this point.
And I don't know how effective this is.
Some people get really kind of destabilized
by these sorts of ideas
because what they hear is, I'm not real, I'm an illusion.
And there are lots of scientists
that are pushing this narrative, right?
So we are to blame for this.
I'm not surprised that people have these ideas,
but this idea that, well, we don't exist.
You're a big pile of cells and you're not really here
and it's all an illusion.
And that's a really destabilizing idea.
It's destabilizing on a personal level.
It contributes to the loss of meaning.
It contributes to societal issues.
And so I wanna just say what I think the lesson here is.
When you see science like this,
the lesson isn't that you are somehow devalued
from what you thought you were
and that the meaning of your life is reduced
and that your primary experience
of being a coherent being with choice,
with the responsibility of deciding what do you do next,
that these things are now out the windows somehow.
I think that's the wrong conclusion to draw from any of this.
The conclusion isn't that the majesty
of the integrated mind is reduced.
The right conclusion is, well, two things.
One is that actually we just learned an amazing thing
that matter can do.
We didn't know that before.
We thought dumb matter was just kind of dumb.
And what we're learning now,
we're not learning something that changes
how we view ourselves,
we're learning something that changes how we view matter.
And this is something that I think Ian McGilchrist says as well
that we've underestimated certain kinds of matter.
This idea that, no, actually,
and this is, I know I've used this example before,
but there's a scene in a lot of science fiction,
most recently I saw it in X Machina, right,
where the guy starts cutting his arm
because now he's worried that he's an android, right?
And I mean, yeah, a lot of people feel that way,
but if you cut your arm or you go get a CT scan
and they say, whoa, you know what?
You're full of cogs and gears.
The conclusion from that isn't, oh, man,
well, I guess I'm not as real as I thought and I'm not,
I guess I don't get to use my free will now.
That's not the answer.
The conclusion should be amazing.
Cogs and gears can give me my spiritual meaning like amazing.
I've just learned something about cogs and gears, great.
So that's, you know, I just want to be clear
that I think this kind of analysis of what it is
that we are, how we get here, you know,
the self-construction of the self from cells
during embryogenesis and all that,
that doesn't, it doesn't have any negative implications
for what you are and what you can do, just the opposite.
It sort of raises the remarkable magic
of these unbinding principles that you say, wild,
you can actually create a being that I know I am.
I mean, that's the part that I think Descartes
had exactly right.
Apparently you can get there through this particular method.
And there was, I forget what it is,
there was also another, an old science fiction story
where, you know, these aliens kind of land on earth
and they find out that humans are basically made of meat.
And they say, that is the most disgusting,
like you're telling me a pile of meat
can have these exalted thoughts
that we in our silicon, you know, implementations have.
Like that's, there's no way.
There's no way a pile of carbonaceous agoo
is going to have these kind of, you know, mathematical truths
that we perceive with our silicon minds.
And right, and it's all completely arbitrary.
Somebody who doesn't want to find gears under their skin
and cogs and things like that, why not?
Because they've bought into the fact that proteins
and RNA does it, is that anymore?
You know, why are you any happier with that?
None of that is intrinsically any better than anything else.
So I think it's very important
not to get, not to take the wrong message
from all this kind of stuff
and to somehow dissolve your fundamental worth
just because we've seen some of the parts
that are under the hood.
We knew that we're going to be parts under the hood.
In fact, I'll go one step further
and for the people who, right?
Because one thing that people sometimes say
at this point is, you're right,
you've just done a deconstruction of all materialism
and none of it matters unless we're a soul.
Yeah, so some people feel that way
that basically, right, the proteins,
just like the gears all know good.
So the thing with that is,
without even getting into the factual nature
or just think purely logically, fine, fine.
Maybe you're a soul.
What's the mechanism of the soul?
There's going to be one.
It's going to do something
and it's going to have some kind of features.
If it doesn't have any, if it has no parts,
then it can't change, then you can't learn,
you can't make decisions, you can't improve,
you can't do anything.
It's going to have some kind of structure.
I'll give it to you that maybe it's a completely different,
something material science has never seen before.
Great, but it's still going to have some kind
of descriptive laws that govern how it acts
and wherever space it lives in.
And then we're going to be back to the same.
Somebody's going to say,
but it's got rules that govern its behavior.
That's not what I mean, but that's not enough
to give me my magical feeling of so, right?
So we got to get over this.
The non-material kind of way forward,
is it doesn't help at all.
And we have to get over the fact
that finding mechanisms under this somehow
robs the larger scale of its meaning.
That's just, sorry, that's a long diatribe,
but that's what I wanted to say.
No, no, that's great.
That's spot on too.
It's funny because I had on Bobby Azarian,
who's a cosmologist and wrote a great book
called Romance of Reality.
And he refers to this quite a bit,
more in the sort of the deterministic lack of free will,
but the similar kind of vein
that a lot of people feel like as soon as you start
to explain this stuff,
it's like you're explaining away the soul
or the mystery or what makes it interesting, right?
But at least it seems like to me
that it's just like a never-ending process.
Like there's always something to learn
and continue to be curious about.
And it's funny, yeah, if you update your priors
and you're not stuck to, if you're open-minded enough
to all the different possibilities that are out there
and you get this new information,
yeah, you just keep, like you said, if you're a robot,
you just say, okay, well, that's interesting.
Yeah, that's interesting.
And you move on and you've changed
how you view the world.
Yeah, that's fine.
I'm the world's most amazing robot.
I thought I was a meaty robot.
Now I'm a metallic robot.
Great, who cares?
My list of things I was gonna do,
the amazing things I was gonna do,
still nothing's canceled, still right there.
I'm still gonna go do those things.
So that's what I wish,
I don't know how convincing any of this is to anybody,
but that's one thing that I really wish
people would internalize.
There's so much, both personal and social loss of meaning,
I think is the best way, as Varvaki says,
around all of this kind of stuff.
And that's the last thing I wanna contribute to.
Yeah, I mean, that's a whole fascinating route
we could go down to,
because I feel like, let's just say this,
like if that new information would lead you down
this kind of nihilistic path,
and I kind of feel like
you were probably gonna go down that path anyway.
100%.
Yeah, it's sort of,
you're using it as a reason to get stuck
in a really vicious cycle, potentially,
but yeah, that's really interesting.
But actually, I think this,
where I was gonna go to next anyway,
and it's in this paper, in the next paper as well,
you had this concept called the play the hand your dealt.
And you, I mean, you're using this very,
how should I say it, materially,
you're talking about the cellular collectives
that can carry out different steps,
with it's sort of second order functions,
it's not, they're far more, let's say malleable,
and far more open-ended kind of strategies
for accomplishing their goals.
Can you talk to us about that,
and what that, I think the acronym is PhD,
so play the hand your dealt.
Yeah, well, let's just start with a specific example.
So, you take a salamander egg,
and there's a certain tricks you can do
to increase the number of the chromosome count
within the number of copies of the genome
that are in there.
And so, when you do that,
so let's say we increase instead of two n,
you can make four n, five n, six n, and so on.
So as you do that, the cells,
the embryonic cells get bigger and bigger.
The salamander stays the same size.
If you take a cross-section through a kidney tubule,
which normally is made of, I don't know if you can picture
this, but like six to eight cells that work together
to form this kind of like long tube,
they get bigger and bigger,
but the animal stays the same size,
and the tubule stays the same size.
So what this means is that fewer and fewer
of these larger cells participate in each tubule, right?
And so, so far, so we have two amazing things so far.
Number one is you've got the wrong number of chromosomes,
fine, you're still a good salamander, amazing.
Number two, your cells are the wrong size, no problem.
We manage the cell number to make up
for this different in cell size.
You're still a good salamander.
Number three, if you make the cells absolutely gigantic,
and these are I think six or eight and nudes,
I don't remember exactly.
What happens is there's not room for even two cells
to be there, so what happens is one single cell
wraps around itself and leaves a hole in the middle
to give you that same tubule, okay?
Aside from the whole issue, so what it is is
it's using different molecular mechanisms.
In the first case, it was cell to cell communication.
In the next case, it's cytoskeletal bending.
You're using different molecular mechanisms
in the service of an anatomical large-scale goal.
That's a kind of top-down causation, super interesting,
but for our purpose, more importantly,
look at your job as a salamander.
You come into this world, you can't tell
how many chromosomes you're gonna have.
You don't know what your cell size is.
You don't know how many cells you're gonna have
because people have done that too.
You can take away cells, you can add cells.
You don't know any of that stuff.
You need to be able to, your goal is to be able
to make a good salamander no matter what you start with.
So that's within limits, obviously.
I mean, all of these things are not infinitely stretchable.
So that's one example.
Here's another example, plenaria, flatworms.
The species that we work with reproduces
by tearing themselves in half and regenerating.
That's how they reproduce.
That means that they have somatic inheritance.
Any mutation that doesn't kill the stem cell
is gonna be proliferated into the body
and expanded in the body in the next generation.
So if you look at these worms, they're mix-a-ploid.
Every cell has a different number of chromosomes.
The genome is a total mess
because they just accumulate this stuff.
400 million years have been accumulating all this junk.
And yet that's the species with perfect regeneration,
high cancer resistance, no aging in the asexual form.
Incredible, right?
And so the same story there is what you have to do
is you have to have an algorithm
that builds a correct plenarian
despite errors in the hardware.
And that's what I think.
So there's my play-the-hand-your-delt concept
is that coming into this world as a new creature,
there's precious few things you can depend on for most.
I mean, there are hard-wired things like C. elegans,
nematodes, and maybe some other species,
but I think of, and there's a whole spectrum.
So I would sort of imagine that something like nematodes
where every nematode, every C. elegans
has exactly the same number of cells
and they all have the same lineage.
So that's a very cookie-cutter organism.
And that's here.
Plenaria are super plastic and they're out there.
And salamanders are somewhere here
and humans are somewhere, mammals are somewhere here.
We all have different degrees of that competency.
But that's the idea.
Most of us don't come into the world
being able to expect very specific things
and then just crashing and burning
when those assumptions aren't met.
This is why we can make tadpoles
with eyes on their backs that can see.
And this is why slippers go to when that two-legged...
Oh, yeah.
Right?
The gopher's, yeah.
Yeah, I do.
Jellper's, yeah, something like that.
Yeah, learn to walk upright.
And they found that a lot of the changes
that come along with bipedal locomotion
were already made because of the incredible plasticity
of the organism.
And it's why skin cells taken off of frog embryos
become xenobots and why,
and instead of just collapsing and dying
and all of these things, that's play the hand you're dealt.
That's the idea that we have to...
There may have been life at one point
that was much more cookie cutter,
but none of that survived.
Nowadays, if you're going to survive,
nowadays you're the kind of life that is able to do this.
Right.
Can you tell us about one thing I was thinking about too
with the play the hand you're dealt,
sort of like whatever materials you have there,
that's what you're going to use,
is, and with bioelectricity, of course,
like the electromagnetic spectrum,
that's sort of what's available to these cells, right?
And I'm thinking, and perhaps this is just
because it's at the limits of our science,
have you found, either in your own research
or research of the contemporaries,
like evidence of organisms making use of quantum fields?
Like are all the different fields that are available?
You know what, I mean, electricity,
I understand why bioelectricity is so great.
I mean, we use a lot of the same,
like the ion channels, like the logic gates,
we use that stuff in our technology,
you know, similar kind of processes.
But anything in the quantum realm that you've seen?
So we don't study that specifically,
so I don't have any data about it.
There are certainly people that study quantum biology
there's some great people who are, you know,
Clarice Aiello and my former postdoc,
Neurosha Morgan, they're into this kind of stuff.
And as our other people,
and I'm sure there are interesting things
that we don't particularly work on it.
My gut feeling is that, not being an expert in this,
but just for whatever it's worth, my gut feeling,
it's going to be the sort of thing that if it exists,
it's not going to be some weird special adaptation
where, you know, all look birds are using,
you know, quantum spin to navigate the magnetic field
and that's it, it's not going to be like that.
I think, I mean, that may also be, but I don't mean that.
I think what we're going to find is that it's everywhere.
Like it's a basic fundamental, if it's there,
if quantum biology is there,
which I suspect it probably is,
it's going to be used for everything.
We're going to find out all the things
that we take for granted now that are just, you know,
we kind of assume there's a classical explanation
or a verbal, we don't know what it is.
I have a feeling we're going to find out a lot of this stuff
is at bottom, explaining some of those properties.
That's just, that's totally a guess on my part.
I don't have any data to, you know, support any of that.
But that's my guess.
Yeah, yeah, that's interesting.
I would see, the very little I know about the quantum,
like quantum mechanics is that I would,
I assume these structures, even cellular structures,
they're tight to us, but they're too large.
Like, you know, it breaks down.
The quantum effects are just,
what happened to a way smaller lens,
but like you just pointed out,
like I think that there's some research
I've done a little bit digging,
but I have to do more about quantum biology.
So, yeah.
Look at, also look at the work of Chris Fields
and folks that he works with,
because there are aspects of what's important about that field
that has nothing to do with being small.
So there are really important aspects of, you know,
in terms of what's an observer and reference,
for observer reference frames
and these kinds of things that apply across scales.
So Chris has some beautiful papers about that.
So it's not just for tiny particles and things like that.
Gotcha, that's good to know too.
And before we move into Darwin's and Gentryl materials,
I think it's still applicable here.
Can you tell us about,
I think there was one podcast you did
where you talked about trophic memory and deer
and antler structures.
And actually the scientist that was studying it
actually sent them to you
and you have a bunch of these.
Can you just tell us a little anecdote?
Yeah, well, okay.
So first, what is trophic memory?
So there's certain species of deer
that every year they shed their antlers
and then they grow them back.
Antlers are real bone, they're not like horns.
They're real bone with velvet and innovation and all that.
So there was this team, last name Bubenik
and it was two folks, a father and son
and they live in Canada.
And they did experiments for,
I'm gonna say well over 30 years,
maybe 40 years together, something like that,
where what they found is that if you,
so you got this deer and you take a knife
and you etch a little cut into somewhere
on this branch structure.
And that year it kind of heals with a little callus,
the bone heals and that's that.
And then the whole thing drops off.
And then next year, when they regrow their antlers,
it grows with an ectopic branch point
at the location where the damage was last year.
Now, I read this, and so they got these papers
from 60s and 70s and beyond.
It's an amazing data set.
No one's ever gonna get a data set like this.
I mean, who's got a herd of deer
that they can watch for 40 years.
It's a, in modern biology careers,
that's not exactly conducive to getting a good associate,
assistant professor position.
But they've got this incredible data set.
And when I first read about this,
I thought it was amazing because
if you try to think about the current,
what passes for an explanation
for a biological phenomenon nowadays?
So if you find this, you look at a typical cell paper,
figure seven is gonna be a molecular pathway, right?
So there's some arrow diagrams on this thing bind,
so that thing, and then they go over here
and they bind to this other thing.
Just try to come up with a model like that
for what's going on here.
So there's a large scale structure.
It gets a damage and put at a particular location.
The whole thing falls off.
The cells at the scalp, which are tens of centimeters away,
remember the three-dimensional position
where the damage was last year.
And then when the bone cells start growing,
they revise the genetically encoded rules to say,
oh, by the way, when you get to this point,
make an extra thing to the right.
Like what possible explanation
using conventional conceptual tools that we have?
Could you come up with it?
It just completely fails.
And so this is one of the things I tell my students
is that your developmental biology textbook
is full of things that are readily explained
by the conceptual tools that we have now.
That's what's in the textbook, other success cases.
So what's fun is to look for the blank space in between.
What are all the things that are not in there, right?
And they're not in there
because we don't have a clue as to how it works.
So this is the kind of, I mean, I love that stuff.
So I'm always thinking about these kinds of things.
So anyway, so at one point,
so we wrote Daniel Lobo and I wrote a paper about this
and explaining like what the implications of that are
for the inverse problem,
which plagues regenerative medicine and so on.
And Bubenek emailed me and he said,
he said, you're one of the few people
that sites this stuff nowadays.
I need to like basically clean out the house, the garage.
Would you like these antlers?
And I was like, to hell yes, of course that would.
And that's such a unique, I mean, it's amazing work.
It's such a unique dataset.
And so we received in my lab 13, I think it was 13,
13 large boxes of these antlers.
And I sent them all to the veteran,
a Tufts Veterinary School.
They have a CAT scan machine where they CT scan horses
and things like that.
And so they CT scanned all of these things.
So I have somewhere, I've still got the antlers
they're in boxes in the closet.
I have a couple of them on the wall actually in the lab
as you walk into the lab, there's a couple on the wall.
But yeah, but I still got these boxes.
And it was incredible because every set of antlers
is labeled with the name of the deer and the year.
So it'll be like, Lenny 1987, Lenny 1988.
And because you have to do these longitudinal,
like you have to know which deer it was.
And he kept meticulous records.
And so we have all of these antlers.
And it's a very unfortunate model system
because if you want to do experiments,
I mean, who's gonna have deer and wait years
for an outcome like it's crazy.
But the closest thing to that actually
is our two-headed plenarium
because it's a very similar kind of thing.
It's a physiological stimulus
that gets somehow catalyzed
into multi-generational repair processes
because once you've make them two-headed,
you can keep cutting them, they stay two-headed forever.
And luckily, plenarium are much more tractable than deer.
So I suspect those things are highly related
but that's my deer antler story.
That's awesome.
That's so cool.
That must be what a fixture to have in the lab too.
It's right in the front as you walk in it.
Great story too.
Awesome, thanks for sharing that.
So I'd love to turn towards,
and there's gonna be a lot of overlap between this paper
and what we just discussed
and I'm sure we'll talk more about bioelectricity as well.
But the second paper, Darwin's Ingencial Materials,
evolutionary implications, a multi-scale competency
developmental biology.
And both of these papers, the first two,
they really just dropped in the last couple months,
few months, right, April 2023.
So these are hot off the presses for folks
and I've really heard you talk about these in other podcasts.
So it's great that we're gonna chance today to do that.
And before we jump right into the paper,
is this an illusion at all to the,
like his Dark Materials book series?
Like the title?
No, not really, no.
Okay, just wondering.
I mean, that's a little bit of a flyer
because it's Darwin's Materials.
I was like, is there sort of a...
Yeah, it does sound like that, doesn't it?
No, not really.
Okay, cool, yeah, just an aside.
But would you mind, I mean, just like you did
for the first paper,
could you provide like a simple overview
and then I have a bunch of questions to ask you about?
Yeah, let's start from this idea that,
and this, I tried to formalize this in my tame paper
from a few years ago.
This idea of a spectrum of, you can call it many things,
it's a spectrum of persuadability.
That's what I call it in the paper, a spectrum of agency.
Just the idea that you can put any system
on this continuous spectrum
that tries to capture how much autonomy the thing has
from an engineering perspective.
How much can I expect?
How much problem solving chops does this thing have
when I'm not around to force it?
So, and you can go from Legos to thermostats,
to animals that learn, to humans
and then everything in between is there, right?
Okay, so now we can ask the following question.
As an engineer,
and so this is another paper I wrote with Jamie Davies
a few years ago, well, maybe a year ago,
talking about engineering with a gentle materials,
because engineering is very different
based on where along that spectrum your parts are.
If you are engineering with Legos, everything is on you.
The only thing the Lego's gonna do is keep its shape.
That's all it knows how to do.
So everything else is on you.
Everything that you need to happen,
you have to somehow make sure it happens.
And this is how molecular synthetic biology works.
You're gonna put in circuits that do specific things.
It's on you to implement every part
of the functionality that you want.
If you, and so humans have been engineering
with bricks and wood and metal for thousands of years
and use a certain set of techniques to do that.
What are those techniques?
Well, they don't involve psychological tools.
They involve very kind of low level,
put everything where it goes and glue it down
and attach this thing to that thing.
That's your toolbox.
Well, if you're building autonomous vehicles
or self-guided missiles or houses or whatever,
you've got some other stuff,
which are, for example, thermostats.
So if you've got a thermostat,
it's interesting because you don't even necessarily need
to know how the whole thing works.
What you need to know is where is the set point
and how do I change it, right?
And what are the inputs and what are the outputs?
Where does the thermometer go?
Where does the connection to the heating,
to the cooling and heating go?
And what you know is that it's gonna do certain things
when you're out there to micromanage it.
Do you have to leave rules
for what to do at every single temperature level?
You don't, it's gonna do that on its own.
So you've got some other tools
and these are the tools of cybernetics.
So for more complex systems,
you'll have control theory and all these kinds of tools
to deal with something that has a simple level of agency.
It's got very basic, kind of primitive goals
that it tries to set, it tries to...
And if you don't understand anything about cybernetics,
you are not going to get the most out of these components, right?
If you don't understand what homeostasis is,
what goal-directed loops are,
you're not really gonna be very good
at using those in your engineering, okay?
And then you move forward and you say, okay,
I'm a proprietor of a circus, well, of a rat circus,
and I want these rats to do little tricks, right?
I could, I want them to, and in the Jamie's paper,
I think we talked about building a tower out of dogs.
I could try the traditional route
of stacking them on top of each other,
but that isn't gonna work.
They're gonna crawl off.
They're not gonna just stay where I put them.
So that doesn't work at all.
I have to use a completely different set of tricks
that people who work with wood and metal don't have to use.
I have to train my material.
I have to, now on the one hand,
it's a bit of a pain in the butt
because your material has its own agenda
and you have to have tools to manage it.
But here's the beauty of it.
Once you've trained them to keep a little tower,
if you knock it over, guess what it does?
They get right back up on their own.
You don't have to be there to rebuild it.
Isn't that amazing?
And so you've gained something very interesting
by switching the bag of tools you bring to the problem.
You've gained something interesting
and you were only able to do that
because you recognize the agency of the material.
You wouldn't do that, right?
You wouldn't do that if you didn't know,
if you thought that these things are dumb,
like bricks and Legos.
So it's very important.
And then you see this all the way up.
If you're a hacker, you might be hacking the computer,
but you might be doing what they call social engineering, right?
You might find out that it's much easier
to just trick somebody giving you their password
than to spend all their brute forcing,
the hash table or whatever.
So there has to be this impedance match
between the tools you bring to the problem.
And the successful engineer is one that recognizes,
what's the right level of agency in my material?
And so that leads to the question for regenerative medicine.
We have cells and tissues.
And you ask, so what are the tools that I'm going to use there?
And the assumption up until now, the assumption has been,
well, they're like the bricks.
You have to micromanage all of it.
That's been the standard assumption of the paradigm.
But it's very much an open question.
Are they more like the Legos?
Or are they more like the rats?
Or are they more like something in between?
Or are they more like the thermostat?
Or where are they?
And regenerative medicine is going
to be cracked by the people who pick the right level.
It's not going to be cracked by assuming the wrong level,
nor down.
So it's not going to happen if you assume these things are
low agency machines.
It's also not going to happen if you
assume that they're magical, inexplicable things
that aren't going to obey any kind of rational rules.
That's not going to work either.
Somewhere in the middle, which is what, of course, what
my lab tries to do is to pick the right set of tools
from cybernetics, from behavioral science,
to take advantage.
OK, so having said all of that, here's the thing with the paper.
What I just took you through is how human engineers view
the spectrum of agential materials.
And so now it comes time to, so Jamie and I wrote that.
And then I said, OK, so now what does evolution do?
Evolution is also an engineer.
So the question is, does evolution
assume that these things are like Legos and work
at the lowest level, which means search the really difficult
and really kind of rugged space of molecular properties?
Or would evolution take advantage
of the competency of the material?
Because the thing about evolution is evolution
doesn't work with Legos.
Evolution works with cells.
And cells and tissues used to be independent organisms.
They don't come as blank slates that are dumb
and have to be micromanaged.
They come with behavioral competencies,
with preferences, with various kinds of agendas.
And so what that paper is, is an exploration of,
if we take that seriously, the fact that evolution, of course,
evolution is very opportunistic.
It makes use of everything it can.
We know that.
What can we conclude if we take seriously the idea
that evolution will not have missed the fact
that it's dealing with a very powerful agential material
that these cells already know how to do things?
And so what I do in that paper is run down all of the implications.
What does it mean for evolution that it
isn't working with Legos?
It's working.
Of course, people have used evolutionary computation,
like genetic algorithms and things like that,
with materials that really are dumb.
So the typical evolutionary algorithm
is done over passive data and it shows you improvements.
But the material is very passive.
And here I'm saying biological evolution isn't like that.
So what does that mean?
What will that do to evolution?
And that's kind of the flip side.
A lot of people study how intelligence, how evolution
gives rise to intelligence of different types.
I sort of reverse that.
And of course, both are happening simultaneously.
But I looked at the other side of things,
which is how does intelligence impact the actual evolution,
the intelligence of the substrate?
Sure.
That's interesting.
It's so thought-provoking.
The impulse I had while reading the paper,
even though it's not stated explicitly and even
something you just said, how do you
view even the evolutionary process?
I mean, it almost sounds like evolution is an agent in and
of itself.
Do you view it that way?
Or how do you look at it?
Yeah, this is an interesting point.
That's a paper that is on my list to write.
It'll probably be next year at this point.
But this idea of evolution itself as an agent.
I want to be very careful here because a lot of people still
have this kind of ancient view that there
are two kinds of things in the world.
There are dumb material things, like the machines,
that the quote unquote machines, and so on.
And then there are the mindful things,
like humans and angels and God and whatever else.
And so when I say, actually, I do
think that there's a lens on evolution which does see it
as an agent.
What I'm not saying, so super clear,
not saying that evolution has a high level purpose, the way
that a human level purpose or a beyond human level purpose,
not saying any of that.
What I am saying is that there's a very rich spectrum
of agency from very low.
I'm not sure there's a zero, but certainly from very low,
all the way to human and beyond.
And I don't think we can blindly assume
that the level of agency for the evolutionary process
is down at the low end.
It might be non-zero, and it might
be important to understand what it is.
But just again, really clear, not saying
that there's any human or above level intelligence out there
picking where the lineages go.
I think Carl first and probably said this well before me.
This idea that you can use that framework to imagine.
So there's two ways to think about this.
One way to think about this is that imagine a lineage,
I don't know, 50 million years of alligators or something.
Just imagine some kind of lineage.
And you can imagine that whole thing as an agent.
It's a very long lived agent, but we're
just bad at noticing agency at different time scales.
It's a spatially a huge agent, but we're also
too fixated on agents that are roughly the size of us,
medium-sized objects.
So if you forget that and assume that agents can be whatever,
what is happening there?
What's happening there is that continuously
generates hypotheses about the environment.
Those hypotheses are cashed out as offspring
with different features.
Some of those hypotheses are proven false.
Some of those hypotheses are supported.
Supported hypotheses go on and shape
the cognitive system of the collective
to form new hypotheses that might be even better,
more correctly describe reality.
And what's interesting is that much like kind of consistent
with what I said before, what these hypotheses are not
flat kind of first order statements about the world,
meaning a hardwired solution.
And it is what it is.
These hypotheses are actually problem solving strategies.
They're heuristics.
They're like what comes out of evolution is not,
here's how you be a salamander and that's it.
It's a set of policies that cellular collectives
can operate depending on what's going on.
They're context sensitive.
So it's like instead of generating
guesses about the world, what you're generating are policies.
You're generating navigational heuristics.
And so that's what that agent is doing.
That's pretty good.
That's not super low agency to be able to do that.
That's something.
That doesn't mean you have self-reflective.
I'd love to evolve some humans because that would be just
like that's not what I mean.
But it's being able to generate hypotheses
and get them falsified and have this like.
So Carl Friston has some great thoughts on this.
Richard Watson has some great thoughts on this.
But yeah, I mean, there's another way maybe
to think about it, which is that the whole evolutionary,
never mind the lineage, but the whole evolutionary process
itself, and that gets hard.
I don't have too much to say about it right now,
but I'm working on it, this notion of what actually
can be an agent, processes as agents.
That's a whole other kind of kettle of fish.
So I think next year maybe if I get anywhere with it,
maybe we talk about it next year.
Yeah, yeah, that'd be interesting.
I'm going to definitely be able to look out for that paper.
And I think, yeah, you touched on so much already
about what's in this paper, the difference between first order
and second order goals or say a certain amount of flexibility
that is built in to the first initial levels there.
What else, what do you think is, I guess,
if you had to say for people to take one thing away
from this paper, say a lay audience,
what do you think would be something that is hard?
I want to get to a little bit of this.
I love your work.
It's fantastic.
But what I want to perhaps push some of the people I
interview a little bit more on is, OK, this is amazing stuff.
How does someone, an individual person,
is there stuff that we can take away here?
Are there truths that maybe as part of our day-to-day lives
that we can integrate ideas from this?
Or anything from your own life, perhaps,
examples of things that this is illuminated for yourself?
Yeah, well, let's put it this way.
I don't know if anything from this paper
will revolutionize day-to-day mundane life.
But a lot of people, but I will, let's try to pull in that direction.
A lot of people think about evolution.
And one of the things that always bugs them,
and especially a lot of engineers, too,
is this standard story of, well, we make random changes,
and then we pick the good ones.
I don't know about you, but when I first learned about this,
I had been building electronics and things
like that as a kid for some years.
And then I learned this theory, and it sounded laughable.
It sounded like you're telling me that I'm going to make random changes
in this thing.
I huff and puff for many hours, and then the person
who made these transistors and everything else
will put in even more work than that.
Like, we're all busting our butts on this stuff,
and you're going to make random changes,
and you think eventually things will get better.
Like, if you've ever built anything a written code,
that sounds crazy.
And then, OK, so you learn some things about modularity
and evolvability and some things that...
But a lot of people are still left with this idea
that, OK, in theory it might work,
but we kind of know that genetic algorithms,
they did great for a while, but they sort of peter out.
There's some limitations to what they can do.
And in particular, part of what makes it a little challenging
is what Andreas Wagner, which I think his work is amazing
and important, what he calls the problem of the arrival
of the fittest, which is that if the best solution is hiding
somewhere in your population, I suppose I'll give it to you
that eventually we'll sort of find it and let it expand.
But who guaranteed it was there in the first place?
How do you know that the right solution is ever going to be
there, depending on what your problems be?
So anyway, so a lot of people are still left with this
dissatisfaction about how there's just...
How do we know that there's been enough time
for this kind of process to give us the amazing things
we see in the biological world?
And I'm not talking about that.
I mean, so there are some people that will never buy the story
because they are fundamentally committed to another kind of story.
I'm not talking about them.
I'm talking about people with a scientific kind of worldview
that want to understand in a naturalistic way what's going on.
But the standard story doesn't seem like it's the whole story.
And there's a lot of very smart people who are sort of thinking
along those lines.
So what I would point out, my kind of contribution to that
is this, part of what makes that process so magical
is not just the process itself.
It's the fact that you're working on a material that's smart.
You're working with an agential material.
That's part of where the power comes from.
If the whole thing seems tough to you,
add to your sort of mental picture the fact that it's not
really searching the incredibly difficult and large space
of all the possible things that could happen.
What it's searching is the space of behavior-shaping signals
by which cells tell other cells what to do.
And that's a much easier space to search.
If you're dealing with, if you run that rat circus,
you could try to come up with a kind of an optogenetic strategy
to control every neuron to get the rats to sort of do
whatever they're going to do.
That's really hard.
We'll be here till the sun burns out before we can micromanage it.
But you don't have to do that because you can train the rats.
And that's a much easier, I mean, it's still a bit of search
because you still have to figure out, well, what's the reward?
What's the punishment?
What are they capable of?
Do they do place conditioning?
Do they do associative learning?
So there's still some searching involved,
but it's a much easier problem than going bottom up.
And so this is what I want people to take away from this
is that part of what makes evolution so magical
is that it's working with an agential material that
has tons of competencies.
Evolution is playing with hardware
that is so far in capability.
And I don't mean the fact that it goes down to the nano level,
and I don't mean that it's, in fact, it's way noisier and more
brittle and whatever than all the things we try to build.
Despite all that, it is so much more powerful than anything
we've ever made because it is not a single specific thing.
It's a learning machine, so to speak.
And that puts evolution on steroids.
That's what I think is a huge motivating factor.
And I think until we understand that,
we are not going to have, I mean, that's to me,
that's if I can dare to say this, the thing that I think
is missing from the standard evolutionary synthesis is this.
It's the appreciation of the intelligence of the substrate.
It treats the standard story, treats the substrate
as a bunch of dumb Lego blocks.
And everything changes.
When the material has agendas, everything changes.
And evolution changes massively.
So I don't know if that counts as everyday life for people,
but I suppose some people think about that stuff every day.
No, no, it's good.
I find it useful because it's a frame,
it's a perspective on how you look at the problem.
I mean, that's something we talk about in round two.
I think polycomputing and the role of the same thing
can be computed.
But depending on how you look at it,
you actually are extracting that different value,
different utility from the same exact thing.
So yeah, that's wonderful.
And actually, I think this will, just looking at the time
a little bit here, I do want to cover a little bit about the
biology, Buddhism, and AI paper.
I think it was CARE as a driver of...
I forget exactly.
Yeah, CARE as a driver of intelligence,
which you worked on with a few collaborators,
Dr. Wytkowski, Salmanova, and Dwayne.
And this, I think actually does bleed into this fairly well,
because in the Ingencial Point Materials paper,
you mentioned the idea of a beginner mind.
And you have a quote from Suzuki about the,
in the beginner's mind, there's many possibilities
for the expert's mind, there are a few.
So you kind of want to have a frame of always being,
having a frame of always being a beginner,
and being open and curious to things all the time,
is a lot better than, this is straw manning it,
but it's a lot better than being an expert
and being like, I know everything.
I've mastered, there's nothing else left to go, right?
There's always potential for more learning and more mastery.
So for the biology, Buddhism, and AI paper,
would you mind providing us, again,
just a brief overview of the overall paper,
and also how you got interested in this topic
to begin with and how you got into this group
of folks who are studying this?
Yeah, well, how I got interested in it,
I've been interested in these kinds of things
for a really long time,
both from the perspective of kind of Eastern thought
about the philosophy of mind and things like that,
and more broadly, questions of concern and compassion
and things like that.
How we met up, to tell you the truth,
I don't remember who reached out first.
It might have been Thomas' doctor that emailed me.
I mean, Olaf and I have known each other.
He's a great contributor to the artificial life community,
and so I've known him and his work for a long time.
Bill and Eliza and Thomas, I met afterwards.
Yeah, I don't recall who made the first step,
but anyway, we've been talking about this stuff
and thinking about it for a long time,
and there's actually a second paper that just,
it either just got accepted or we just returned it.
I don't remember exactly where it is,
but there's a second paper following up
on all of this stuff.
You can find the preprint is on the website.
But this idea of specifically this idea of care
and what do agents care about?
And for me, it has lots of important implications
because I try to understand collective intelligences,
and so if you're gonna have a collective intelligence,
what is it going to care about?
We don't have a good science of that.
And then there's the notion of embedding care
in artifacts that we make, so robotics, AIs,
what are they gonna care about?
It's kind of a funny story
when my kid was, my youngest was,
I wanna see who was three or four,
and he said, we used to build stuff together all the time,
and we did all kinds of engineering things,
and one day he said to me, let's make a cat.
And I said, well, like a robotic,
you wanna make a robotic cat.
And I said, well, let's make a list
of what are the design specs here?
Like what does this thing need to do?
And he says, well, it needs to move around.
I'm like, yeah, maybe like that, that may be doable,
and it needs to make meowing noises,
and it's pretty much doable.
And it needs to, there was something else
that it needed to do, and I said, yeah,
probably we could do that.
And then he says, and it needs to care.
And I said, what do you mean?
You mean it needs to walk over to you
and let you pet it?
He goes, no, no, not act as if it cared.
I wanted to actually care.
And I was like, all right, well, that's it.
You've just broke the whole project
because we don't have a clue
as to how that is going to happen.
And that is, that figuring out how that
ties into the whole, the cognitive light cone story
that I've been telling
and the kind of the spectrum of precipitability.
It's like, intelligence is one thing,
problem-solving is one thing.
But where does the care come from, right?
And what do we mean by that?
And a lot of people say things like,
I care about stuff.
That's just the machine.
They're usually pointing at some AI thing
or some robot or something.
And they say, well, that's just the machine.
Machines can't care.
And I'm like, well, you used to be a single cell.
And do paramecia care?
Because now you got a problem.
If you say that the paramecia care,
then well, guess what's inside of paramecia?
Bunch of molecular cogs and wheels.
So maybe machines and certainly molecular biologists
see single cells as a kind of machine.
And that analogy has done pretty well for us.
On the other hand, if you say, no, no,
the paramecium doesn't care.
It's just a bunch of chemical reactions.
I mean, we can sort of see what's going on in there.
It's a bunch of chemistry that doesn't care.
I care.
Like, well, you used to be a single cell.
So why don't you tell me where that,
when the care got beamed,
like what stage of embryogenesis
does the care get beamed down, right?
That's a problem too.
So you got this real issue
with people who think in binary categories,
they get trapped in this pseudo problem
that I think unsolvable.
So anyway, so we were really interested
and then of course, from their perspective,
they're interested in the questions of,
there's a Buddhist story about care and compassion
and those kinds of things.
And so I was interested to see how compatible
those things are.
Can we use some tools from that thought?
I mean, there's a whole other thing,
which is this notion of the impermanence of the self.
And it goes, I mean, there are obviously
all different kinds of opinions on this,
all the way from there is no such thing.
It's a total illusion, right?
That's one set of views.
And then on the other is the kind of like,
the sort of demand on the street version,
which is, well, you know,
I've got this permanent self and it's this like thing.
And then that's, you know, it exists.
And then what I'm interested in is kind of a,
the space in between, which I think is more accurate.
So, and by the way, I'm no Buddhist scholar.
I don't, you know, I don't pretend to like,
know who thinks what in that area.
I'm just, I'm trying to keep up with Thomas
and Elizabeth and so on.
But there's an intermediate version,
which is that it's not that you don't exist.
You do in the same sense as everything else exists,
which is as a useful metaphor.
And in fact, you are the most useful metaphor for all,
of all, because you might do away with,
you might somehow do away with metaphors of talking about,
you know, I don't know what social structures are,
what grocery stores are.
Maybe you don't, maybe, you know, you now see,
like Eddington said that a table is mostly empty space.
And so maybe you've internalized physics enough to know
that even the table isn't the great metaphor
that it's mostly, you know, fields and whatnot.
Like all of that is fine.
But there is this metaphor of a self that can do things
because it's on you to do stuff or not do it.
You have to make those decisions.
That's a pretty useful metaphor.
So I don't think it's not real.
Like I think it is real in the same sense
that everything else is real, which is a useful construction.
Also, I think what's useful about it
is that it is continuously self-constructed.
And here's what I mean by that.
At any given moment, so right now,
you don't really have access to your past.
The only thing you have access to are the engrams
left in your brain and body by your past experiences.
That's all you have access to.
And from that, you reconstruct a story of your past.
So including, you know, the school you went to
and various other things.
You're building that right now at every moment.
It's a little bit like, you know,
anterior-grade amnesia patients who can't form new memories.
And so they use these scratch pads,
at least some of them where you write down.
The first thing you write down is that
I have anterior-grade amnesia
and then some stuff that happened.
And then at the end, that says,
and don't forget, write this note again tomorrow.
And that's your, like most of us have the same thing.
It's just internalized,
but now they're using the Stigmergically,
this outside tool because there's some problem.
So we are all really in that state.
It's just we're using an internal scratch pad.
You know, right now,
you don't have any access to what happened years ago.
You just have the memories and they're actively rebuilt.
And we all know, you know,
our ability to rebuild accurately is crap, basically.
Right?
And these things morph and change and whatnot.
So the story of ourselves changes all the time.
I actually, I did a, I gave a talk the other day
at this UCLA symposium and I talked about a planaria
and this idea, you know, in planaria,
if you teach them something and then they,
you chop off their heads and the tail sits there
and then eventually they regrow a new head
and they regenerate their memories, right?
And so that means, okay, the memory is stored somewhere
to who knows where it is,
but the interesting part of that is the memories
are actually imprinted onto the new brain as it develops.
And so this new being, this new planarian
has to rebuild itself along with its memories
I mean, I don't know how rich a planarian's memories
really are, but, but whatever they are,
it has to like completely rebuild itself from these memories.
And, you know, that sounds all crazy and weird
and it sounds like, you know, the cases of like, like,
you know, what's the, you know, Blade Runner
and everything when you find out that, oh crap,
my memories aren't really my memories.
I mean, as far as this planarian brain is concerned,
it just got downloaded a bunch of false memories.
That brain was not part of any of the things it remembers.
They wasn't there, didn't exist.
So it's kind of a bunch of false memories.
And so, and so it was like, wow, these planarians are crazy
and this thing with the androids is nuts.
And my point was, no, no, no, this is what we are 24 seven.
This is completely normal
because all of us are reconstructing ourselves
at every moment and I don't know how wide the moment is,
but I'm sure that neuroscientists will tell us
you are reconstructing yourself from these past memories.
And so I think that's a deep kind of philosophical thing
because, you know, your self isn't some permanent
monadic structure that just kind of exists.
It's an active construction.
It's a process.
It's a, you know, it's a constant information,
processing, auto polices that, you know,
of the mind doesn't stop during embryogenesis.
It kind of keeps going.
It has to and it has these interesting implications
of somebody going back to, you know,
I guess I'm, I guess I'm now in the business
of trying to normalize a lot of things
that people get freaked out about, but, but, but,
but, you know, imagine, right?
So if somebody finds out that, oh my God,
like all of these memories that I have now,
that wasn't me, that were downloaded.
My body was just, you know, was it Boltzmann
or who was it?
Humor somebody had this puzzle, like what happens
if you're not, if all your memories were just like,
you were created 10 seconds ago,
including your memories, right?
There's something like that.
If you think about it hard enough,
given that that's normally our situation anyway,
my answer is who cares?
Great, like move on.
You've got them now.
Go for it.
Now you've got some great memories, like roll with it
because, because that's what else is it going to be?
Of course you were just constructed with your memories.
What else could it be?
You are constantly constructing yourself
from the n-grams in your, in your head.
You don't have access to what actually happened before.
You are, I just don't even, you know,
that view seems weird to people.
And I don't, I can't even verbalize
what the alternative would be.
I just don't even understand what an alternative story
could possibly be.
So, so from that perspective, you know,
in fact, you can go further with this.
The body that I have now, given the turnover of cells
and molecules in your body,
was this body actually around 30 years ago
to do the things that I remember doing?
It actually wasn't.
We know it wasn't.
Even though I've not been part of some weird memory
replacement experiment, you know, and I'm not an Android,
this body wasn't there.
I know it wasn't.
We know it wasn't there.
And yet I have these memories.
So am I complaining?
What would you complain about?
If you, if you, if somebody told you that, you know, you,
yeah, your body was just, you know,
you were, you were killed in a record
or maybe your body never existed.
But we just made you in like,
here are some great memories of a past life,
like bring it on, fantastic.
You know, I hope they're good ones.
And because, because I don't know what the,
I don't even know what the alternative would be.
So, so I think for that reason,
I think all of these things are,
are really, really hopeful and positive.
They're, you know, they just tell us that
we shouldn't be afraid of these, of these technologies.
This is, this is the amazing thing about,
about being a self in this, in this universe,
is you get to, you get to constantly construct yourself.
And by the way, guide what happens in the future,
what you do now determines the experiences
you're going to have, the reactions you're going to have,
which of course, you know, those, those kinds of disciplines
and, and, and the traditions are all about that
about, about consistent practice to train yourself
to be better, to have, you know,
to improve your cognitive, you know, apparatus and so on.
And, and the commitment is the last thing.
The, the, the body's out of a vow, which is, which is huge.
It's this, it's this commitment.
It's a, it's a meta goal.
It's the commitment to enlarge your cognitive apparatus
to enable bigger goals,
to enable you to pursue bigger goals
with more compassion facing outwards.
That's, that I think, that I think is critical
because I think once you are a system
with the ability to make that commitment,
it's sort of like, it's an exponential rise after that,
right?
It's like discovering the scientific process.
Before that, it was all sort of screwing around,
you know, trial and error,
but as soon as you figured out
that there's a systematic thing that you,
I am going to literally work to get, to get,
to get better at this and to be able to have more,
increase my light, cognitive light cone of compassion.
You can now, you can now sort of exponentially go up
because you understand what you're doing.
It's not just, you know, just random, just a random walk.
Yeah. Now I love what you've said before to you about how
something to this degree
that you can't control your next thought,
but you can't control your thoughts 10 years from now
by what you do today, right?
And what you do every day,
you can like influence the future.
One thing I really wanted to ask you about,
and it's not in this paper,
but I imagine other folks have worked on this.
The idea of what it's like to perceive,
let's say the self in a broader way.
And like you mentioned with the Bodhisattva vow,
and I think this is actually really nice
because it brings us full circle with our conversation
from our very first one,
which was around the cognitive light cones.
And in this paper, you do have a diagram
where you've, you've like overlaid what the,
what someone with a wider sense of self,
say one to help out the community
or something that's also one that takes the vow
to not achieve enlightenment until everyone else does, right?
It's like this leave no living being behind kind of idea,
right?
But do we have any research or even discussions
with say monks, people who engage in,
say like deep Buddhist meditative practices,
do they perceive themselves as like
a part of a whole?
Like is, is their actual sensory experience different
than say a very enlightened person like myself
or like most folks?
Like does that make any sense?
Like how, how do they perceive themselves in the world?
Yeah.
I think, I think that's a great question.
I don't think I've got the expertise to answer
that question.
I think you could talk to,
you could have Thomas Doctor on, for example,
and he's a very kind of experienced scholar in that area.
And I think, I think he would, he would,
you'd have a good time.
He could explain all that stuff.
Well, thanks.
Yeah, yeah.
I think I'll have to.
And let's see.
And that's great.
So you gave me so much to chew on
and so much for the audience too.
I'm sure this idea that who you are today
is not who you were 30 years ago,
just in a very literal materialistic sense.
And that there's like just this illusion
of a consistent continuous kind of experience.
That's really, it's a wonderful way to put it.
And if you, if you wouldn't mind, I mean, I do,
I'll probably overlay the your cognitive light cone
with the Bodhisattva, the Bodhisattva vowel one.
How has this been, because this came out,
this paper came out about a year ago.
How has it been received?
Have you heard any response from the paper?
A little bit, a little, a little bit.
Yeah, I don't know.
I don't track responses super, super carefully.
So I'm not sure.
Haven't heard a ton.
I'm gonna guess, I'm gonna guess Thomas heard more on it.
But I think that, I've certainly had interesting people
reach out to me to talk about it,
which is pretty much one of the things
I hope for in writing these things.
So I've had lots of cool discussions.
I don't know more broadly.
I mean, I have no idea how,
and any of these papers, by the way,
I have no clue like who, if anybody reads them
or who reads them or what happens after that, I don't know.
Yeah, well, I appreciate that.
And certainly people contact me,
but it's very hard to know how these things
are actually spreading or not spreading
through the community.
Gotcha, and I'm gonna let you go in a moment.
But before I do one last thing,
you're a big mid-journey fan.
You oftentimes have,
seems like you're also a fan of surrealist art.
I've seen stuff from prompts that are like,
do this in the style of the Codex Seraphoninus
or in the style of the Chironomus Bosch.
Do you know, like what is it that draws you towards
like those kinds of art styles?
I don't know.
I have had zero art training.
I kind of know what I like,
but I don't know anything about art.
I can't draw on myself at all, like nothing.
And I mean, all I know is that I really like,
I'm really interested in the space of the possible
and much more so than the actual.
And everything I look at art-wise
is either photography of nature or photography thereof.
I like nature, but other than that,
I'm really into imagining what could be
the latent space of possibilities.
And I think mid-journey and systems like that
are pretty cool in that respect.
They let you explore this wacky latent space
that it has of images of all different kinds.
Yeah, that's just kind of generally,
I think very much forward in terms of like what now,
what could we do next?
That's maybe that explains a lot of my kind of,
not getting worked up about whether the past is real
or not or what.
It's mostly the forward-looking stuff.
I mean, whatever in the past, but like now,
what do we do now?
So that's more what I'm interested in.
And I like this kind of art that lets you,
yeah, imagine things that could be,
what are the possibilities moving forward?
I share same love for that style as well, those styles.
And just want to say thank you so much, Mike.
These three conversations have been wonderful.
I appreciate your time, your energy.
And where should people find out more about you?
I'll link in the description.
Yeah, well everything is, there's an official website,
the academic website is www.drmike11.org.
So one word, drmike11.org.
And that's got all the links to the papers,
the software, the presentations, everything else.
I've got a science Twitter presence at drmike11.
And I think in a couple of months,
there will be a WordPress site.
So I've been working on a site kind of,
yeah, I was sort of thinking sub-stack WordPress.
I decided WordPress.
And so there's going to be a site
that's kind of less the official academic stuff
and all kinds of writing that I want to do
that doesn't really kind of tired of asking the question of,
you know, you write this thing
and it's not really, it isn't a primary paper
and it isn't really a review.
And it's kind of a perspective,
but it's really interdisciplinary.
It's way too long for a journal.
And I'm sort of just tired of this issue
of finding a home for it, you know,
what they say, like, where are we going to put?
Like, okay, forget it.
We'll just, it'll go there.
And then anybody who's interested can read it.
And that'll be that.
So yeah, so there'll be, that doesn't exist yet,
but in the next couple of months, it should be up.
Awesome, great.
Well, we will watch that space for now.
When it comes live, I'll update all the other videos
so that people can get there.
That's great, I appreciate it.
Thank you.
Thank you.
Thank you, Mike.
Thanks very much.
Yeah, thanks for having me on.
It was great.
Thanks.
It was awesome.
Thank you so much.
All right, bye-bye.
All right.
