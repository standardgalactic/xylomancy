So I think we're going to live in a world where there are going to be hundreds of millions
and billions of different AI agents, eventually probably more AI agents than there are people
in the world.
All right.
So Lama 3.1 was just released today.
And along with that, there has been a ton of additional information released from Meta
about how they think about open source.
Mark Zuckerberg wrote a letter, which I will also be covering, but he also did a 30 plus
minute interview with Rowan Chang.
And so today we're going to watch the video together and I'm going to give you my thoughts
on it.
Can I also just say I am absolutely loving Mark Zuckerberg's current vibes.
His transformation is going to be studied in business school for decades to come.
So let's keep watching.
Okay.
In this first section, he is going to introduce the Lama 3.1 launch and it'll be in his
own words and what he thinks about it.
So let's watch.
I mean, the big release today, first of all, happy to be doing this big fan of what you
do.
The big release today is Lama 3.1 and we're releasing three models.
The first time we're releasing a 405 billion parameter model.
So it's by far the most sophisticated open source model that I think anyone has put out.
And it really kind of is competitive with some of the leading close models and in some
areas is even ahead.
So I'm really excited to see what people do with that, especially now that we're making
it so that the community policies around Lama allow people to use it as a teacher model
to distill and fine tune and basically create whatever other models they want with it.
I already have to pause it.
So he said a lot just in those few words.
First of all, the 405 billion parameter model is outstanding.
It is leaps and bounds more sophisticated than any other open source model out there.
It is directly competitive with closed source frontier models and it is really the first
open source model that can be considered frontier.
Also all of this is a direct shot at open AI and other closed source companies.
And he is taking a tried and true playbook.
Microsoft did this for years.
Basically when you're behind in a technology race, the strategy that you employ is called
scorched earth.
Essentially invest a ton of money into replicating whatever that technology is and then release
it for free.
Because at that point it becomes ubiquitous, it becomes a commodity and why would anybody
go and pay premium prices for a closed source frontier model when you can have full control
over the model and pay fractions of the price.
Plus you are increasing competition greatly.
And so you have companies like grok groq who are able to take this large model and run
it at inference speeds that are absolutely incredible orders of magnitude greater than
what open AI can run at.
And by the way, I don't think open AI is down for the count by any means.
Sam Altman is a brilliant operator.
And this is likely why they just released GPT-40 mini, a model that is as performant
as GPT-40 but for a fraction of the price and it's much faster.
So they're getting the message.
They see the writing on the wall.
Models are becoming commodities and I just read an article and I'm going to talk about
this in another video that open AI is building their own AI chips.
And again, that's really where a lot of the differentiation comes from.
That is why grok is so special because of their unique chip design that allows them to run
inference at blazing fast speeds.
And open AI wants to accomplish the same thing because especially after this release, models
are a commodity.
Let's keep watching.
In addition to that, we've distilled the 405 billion parameter model down to make newer
and updated and now leading for their size 70 billion and 8 billion parameter models.
So that's actually one thing I didn't quite realize.
Even after reading the announcement, they took the 405 billion parameter model and distilled
it down into the 3.1 versions of the 8 billion and 70 billion parameter models.
I didn't know that.
Does that mean that the 8 billion and 70 billion parameter models that first came out the three
version were standalone models and now these are completely new models?
I'm not actually sure.
So if you know, let me know in the comments.
Yeah, I mean, taking a step back, I think this is a pretty big moment for open source AI.
Yeah, I've been reflecting on this and I kind of think it's, you know, I thought for a while
that open source AI was going to become the industry standard.
And I thought that it would basically follow the path that Linux did where, you know, if
you just go back to before Linux was popular, there, you know, there are all these companies
that have their own closed versions of Unix.
And at the time, you know, there's nothing that was sort of that sophisticated that had
ever been done as an open source project.
And people thought, Hey, no, this is like the closed model of development is the only
way to do something that's this advanced.
And at first Linux kind of got its foothold because it was cheaper because developers
could customize it in different ways.
And then over time as the ecosystem built out, it, you know, got more scrutiny.
So it actually became the more secure one.
It became the more advanced one.
There were more partners that basically built more capabilities in the case of Linux, more
servers, and things like that, that basically ended up making it have more capabilities
as well than any closed source Unix.
So I think that this moment with Lama 3.1 is kind of like that inflection point where
I think Lama has the opportunity to become the open source AI standard for open source
to become the standard, the industry standard for AI.
And even in the places where it's not yet ahead on performance, it leads on, on kind
of cost and on, on customized ability and on the ability to take the model and fine
tune it and do all the things that you want with it.
So he also mentioned, and I forgot to mention this in my last comments, but he also mentioned
that they changed the license and now with the 405 billion perimeter model, they allow
you to create synthetic data from that model to train smaller models.
So that is a huge change and extremely valuable for the ecosystem.
This is what NVIDIA did with their Nemotron model.
They trained a massive model that generates data and has the permission to do so to train
smaller models.
And this is going to allow a lot of companies, a lot of AI model companies as well to make
their own versions of these models, dependent on the use case.
And that is a really cool strategy and something, again, I really appreciate it from Meta.
I think that those are just huge advantages that, that we're going to see developers
take and we're focusing on building out this partner ecosystem and there are going to be
all these different capabilities that get built out around it.
So yeah, and that's another thing.
He's not doing this just to screw over the closed source companies.
He actually believes in this as a true business strategy.
If you build out the foundation for other companies to come build on top of you, then
of course you get to set the standards and then you'll figure out ways to monetize over
time.
That's essentially what they did with Facebook.
They built out a platform, other developers came and built on top of it.
Now the counter example to that is Apple with the app store.
They built a completely closed system and then other developers because it was so popular
came and built on top of it.
And there's the alternative Android, which is the open version of the smartphone operating
system.
So we needed a strong open source player in AI and now we have it.
All right.
Next is something you all ask me about all the time.
Whenever I put out a tutorial, whenever I put out some kind of news, you always ask
me, okay, but what's the real world use case?
And that's something that I've been trying to include more and more in my videos.
So now what Mark is going to talk about in this segment is what he sees as the real world
use cases.
He's probably going to start with the things that we all know are pretty obvious and are
the basic intro use cases for AI.
But I'm hoping he's also going to talk about the more sophisticated use cases and there's
probably a ton of use cases we haven't even thought of yet or that the capabilities aren't
quite there yet until today.
So let's watch.
The thing that I'm most excited about is seeing people use it to distill and fine tune their
own models.
Right?
It's, I mean, like you're saying, I mean, this is the first open source frontier level
model, but it's not the first frontier level model.
So there have been other models that sort of have that capacity and yeah, people are going
to want to do inference directly on the four or five because it's, you know, by our estimates,
it's going to be at 50% cheaper, I think, than, than GPT four or to do that directly.
And so I think that that obviously makes a difference to a lot of people.
But the thing that I think is really new in the world with this is the, because it's
open weights, the ability to take the model, and by the way, it was rumored that meta was
not going to release the weights for the 405 billion parameter model, but Mark Zuckerberg
corrected them.
And it seems like he held true to his promise.
They did release it.
It is completely open source.
And I can truly say that completely open source and distill it down to whatever size
that you want to use it for synthetic data generation, to use it as a teacher model.
You know, so our vision for the future, it's not just, okay, it was never that there's
going to be one singular thing.
I think this is like open AI sort of as this vision that they're going to build kind of
one big AI, Anthropic does to Google does to it's never been our vision.
Our vision is that there should be lots of different models.
I think every startup out there, every enterprise governments, they all kind of want to have
their own custom models.
And yeah, when the closed ecosystem was so much better than open source, it was just
better to take the vanilla clothes thing off the shelf, because even though you could
customize open source, there was still some gap between the performance that you could
get, but now we don't see that anymore.
So this is actually something that I believe in really strongly.
And if you've watched my videos as of the last few weeks and months, you've heard me
say it.
I truly believe that small, vertical, narrow use case models are going to be the
future, especially, and again, something else I've talked about as AI compute
continues to get pushed towards edge devices.
The only way we're going to be able to have capable AI is by running small models,
multiple small models on a device like this.
And when we also have algorithmic innovations like route LLM and mixture of agents,
all of a sudden these small models become so much better and know when to
offload to these giant kind of world knowledge models, if they have to.
And funny, that is the approach that Apple intelligence took, but they just took
the completely closed ecosystem approach, which is very Apple to do.
As open source basically closes the gap, I think you're just going to see this
wide proliferation of models where people now have the incentive to basically
customize and build and train exactly the right size model for what they're
doing, train their data into it, they're going to have the tools to do it because
of a lot of the partner integrations that the companies like Amazon are doing
with AWS or Databricks or different folks like that, who are building these
whole suites of services for distilling and fine tuning open models.
So I think that that's going to be the thing that's new here.
And that's really exciting is how far can that get pushed?
And that's a completely new capability in the world because there hasn't been an
open source or open weight model of kind of this sophistication that's ever
been released before.
Yeah.
And that's a really important point.
The battle for unique and diverse data is really going to be the front
lines of artificial intelligence.
That is why, as I mentioned in a recent previous video, open AI has been building
partnerships with numerous content companies like Time Magazine and so on.
And so if you're a company and you have this very unique, very proprietary data
set, you can now take these large frontier open source models and train them on
your particular use case for your business, whether you want to use it internally
or resell it to your industry.
And I think that's a really interesting approach.
All right.
In this next section, Rowan asks Mark Zuckerberg about how they're going to teach
the world how to use these AI models and specifically about open source and its
benefits.
So let's watch what he has to say.
Yeah.
So I'd say before Lama 3.1, our approach, I mean, the reason
that Meta fundamentally is investing in this is we basically want to know that we
have access to a leading model because of some of our history of kind of how
mobile worked and things like that.
We didn't want to be in a position where we had to rely on some competitor.
All right.
So he kind of revealed why he's employing this strategy.
During the mobile revolution, Facebook got caught flat footed.
They basically were completely platform dependent on Apple or Android, and they
even tried to make their own phone at a certain point, although it was a failed
project.
So he is obviously not wanting to make that same mistake again.
We built it for ourselves.
And before Lama 3.1, you know, we, we kind of had this instinct that if we made
it open source, there would be a community that would grow around it.
And that would actually extend the capabilities and make it more valuable
for everyone, including us.
Because at the end of the day, this isn't just a technology.
It's an ecosystem, right, that, that, that you're developing.
So in order for this to end up being a useful thing for us, there also needs to
be a broad ecosystem.
One of the big changes that I think we see with Lama 3.1 is instead of just
building it for ourselves and throwing it over the wall and letting developers
use it, this time we're really taking a much more proactive stance on building
partnerships and making sure that there's this whole ecosystem of companies that
can do interesting things with the model and conserve developers in ways that
we're not going to.
Okay.
Really what that translates into is they want control of the ecosystem.
They want to be able to define the standards.
They want to build up the ecosystem.
So there's obviously a financial motive for Meta and it's not just purely out
of the goodness of their heart that they release this model for free, but that's
okay, everybody can still win.
And quickly I want to show Mark Zuckerberg talking about GROC, which is, as
you know, one of my favorite companies out there right now in the world of AI.
At the same time, I think that there are also going to be folks like GROC, right,
who are doing really interesting work on really kind of ultra low latency
inference.
And I'm really excited to get this in their hands and they're building something
for launch that basically.
Okay.
So obviously this was filmed a few days before launch, if not more, and GROC on
day one already has it available.
I haven't been able to use it because there's been so many people trying.
It basically says they're bandwidth limited, but as soon as I can, I'm
definitely going to try it out.
Next, Rowan asks Mark Zuckerberg what the implications are of open source AI.
And this has been a fierce debate amongst obviously closed source
companies like open AI and open source companies like Meta AI, Mark Zuckerberg,
Jan Lacoon.
And what I really appreciate about the open source approach is that it hopefully
puts a stop to any regulatory capture that might be happening and likely is
happening from the likes of Google and open AI.
They want regulation.
They want the hurdle to start a new AI company, a new, innovative frontier AI
model to be as high as possible because they're already on that side of the
fence.
They don't want anybody else at their party.
My view is that open source is a really important ingredient to having a positive
AI future and that there are all these awesome things that AI is going to bring
in terms of productivity gains and creativity enhancements for people.
And hopefully it'll help us with research and things like that.
But I think open source is an important part of how we make sure that this
benefits everyone and is accessible to everyone.
It isn't something that's just locked into a handful of big companies.
At the same time, I actually think that open source is going to end up being
the safer and more secure way to develop AI.
I know that there's sort of a debate today about is open source safe.
And I actually take the different position on it.
It's not only do I think it's safe.
I think it's safer than the alternative of closed development.
Yeah.
So I'm going to cut him off for a second because I kind of already know where
he's going, something I've already talked about in previous videos.
And he actually talked about it a little bit earlier in this video.
Basically, when you open source something and everybody with diverse skills,
diverse perspectives and a much larger pool of talent can look and examine
every single line of code, every single piece of data, how it's behaving,
why it's doing certain things, you're going to harden the system.
Much more so than closed source systems.
Now, there's some examples where that's not the case.
There's some examples where that is the case.
But I think generally speaking, open source tends to be more secure
than closed source systems.
If you agree, let me know in the comments.
I'm not sure if that's even a controversial statement or not.
You know, I sort of break it down into, you know, there are lots of different
kinds of harm, so you can't just talk about one type of thing.
But on this, I think that there's unintentional harms.
So the system goes off the rails in some way that people didn't intend.
And then there's intentional harms where you have like some bad actors
trying to use the system to do something bad.
When it comes to unintentional harms, which I think, by the way, it's worth noting
that like most of the sci-fi scenarios that people worry about of AI
just going rogue are kind of unintentional.
I actually think that open source should be safer on that because it's
it will have more scrutiny, they'll have more transparency.
And I think all the developers who use it with all the Lama Guard
and the safety tools that it comes with, there's going to be so much
scrutiny and testing and pressure on those that my guess is that it will have
kind of just like traditional open source software, any kind of issues
with it I think will be ironed out and fixed a lot quicker than with
when the closed models.
So I think you've got you've got that on kind of unintentional harm,
which is why I think most of the discussion around safety for open
source revolves around intentional harm.
It's okay, it's open, it's out there.
How are you going to stop bad actors from doing it, doing bad things with it?
There, I think you basically want to probably divide the problem
into kind of smaller actors like an individual or
or some kind of smaller group that's trying to create some mayhem
and the larger actors who are more sophisticated and have huge amounts
of resources like big nation states.
I think it's kind of a different mix for the two of those.
This reminds me of something that Jan Lacoon talked about in his
interview with Lex Friedman.
I'm actually forgetting the name he called this, but he essentially said
that if everybody has open source frontier models that are incredibly
capable, as capable as closed source, then it's basically a battle of AI
versus AI.
If there's a bad actor and a good actor with AI, whoever has the
better AI is going to win.
And if both sides have equal AI, or if they're just off by, let's say,
5% in terms of capabilities, then it's pretty much null.
And one AI is going to protect the good actors from the bad actors AI.
Now, the instance that we're not talking about, which I actually don't think
is possible is if bad actors with huge resources suddenly get a massive jump
in capabilities in AI that nobody else even thought was possible.
So imagine all of a sudden a bad actors AI is 100% better than the good
actors AI.
At that point, we'd probably be in trouble.
But as I said, I don't even believe that's possible just because of the
iterative nature of artificial intelligence innovation.
There just aren't these huge step functions in capability gain.
You know, for the smaller actors, my view on this is that, you know, the way
that we've, I think that having a balance of power on this is super important.
You know, what we've done in managing our social networks is we have all these
kind of bad actors who are trying to do kind of bad stuff on our networks.
And the way, and a lot of times they deploy AI systems to do that.
And the way that we stop them and identify them is by having more
sophisticated AI systems that have more compute to go find what they're doing.
So I think that this is actually pretty similar to the governments and law
enforcement essentially maintain order in society.
It's like, yeah, you have a bunch of rogue people who might be committing crimes.
But, you know, generally the police forces and the militaries are much
better funded, have more resources.
And I think that that's basically going to be true here.
As a matter of fact, I think what you want is for open source to be widely
deployed, which I think that there's sort of a risk.
If it's closed, that that's not the case.
But when it's open, you're going to have all these big institutions that
have a ton of resources that they can basically deploy these systems in a way
that I think will check bad actors.
Then you get to the question of basically, you know, folks like
China or like large sophisticated actors.
And one of the questions that you sometimes hear debated is like, OK, if
you're open sourcing the really advanced models, how do you make it so that
that it doesn't get to to China or they're not going to use that against us?
And that's sometimes an argument that people have for, hey, you should lock
down development.
But I think that that's sort of missing a few things.
One is that in order for this all to work, the US has to have an advantage in
the first place or the West and in kind of our advantage is basically open
and decentralized innovation, where it's not just a small number of big
companies or labs, it's startups and universities and individuals hacking
on things who are in parts of companies.
And that's a big part of it.
And you don't want to shut that down.
And I think if you do, you increase the chance that we don't even lead in the
first place.
But then I think you get to the the issue, which is, OK, China or not even
China, any government, you know, they're all the risks of kind of stealing
the models and an espionage.
I mean, a lot of the models fit on, you know, a hard drive that you can, you
know, quickly put in your backpack or whatever.
And it's, I just think we need to be realistic about how likely it is that
we can secure and not just not us, but like any of the tech companies can
secure any of these models long term against very sophisticated efforts to do that.
So if you remember my video about the situational awareness paper by Leopold
Aschenbrenner, he specifically calls out China, but let's just use any large
state actor, the chances of being able to protect a closed source model, the
weights indefinitely is essentially zero in my mind.
How many times have U.S.
companies been hacked specifically by China and their IP stolen?
And here's the thing, it only needs to happen once.
You only need to have one minor lapse in security and then you lose the model
weights.
So with the likelihood of a private company like open AI getting hacked,
having their model weights stolen, then let's just assume state actors are
going to have these AI models.
So let's just make sure everybody has them.
Let's make sure all of the good guys, quote, unquote, good guys, quote,
unquote, bad guys, they all have the same capabilities.
And thus we're back to the original statement of it's one AI versus another AI.
My own fear is that if we lock down development, we end up in a world where
basically you have a small number of companies plus all the adversaries who
can steal the model are the only ones who have access, but all the startups,
all the universities, all the individual hackers are kind of just left out and
don't have the ability to do this.
So my own view is that a realistic aim that we should hope for is that we use
open source to basically develop the leading and most robust ecosystem in the
world in that we have an expectation that our companies work closely with our
government and allied governments on national security so that way our
governments can persistently just be integrating the latest technology and
have, you know, whatever it is, a six month advantage, eight month advantage on
our adversaries.
And I think that that's, you know, I don't know that that in this world, you
get a 10 year permanent advantage, but I think a kind of perpetual lead actually
will make us more safe in one where we're leading than the model that others
are advocating, which is, okay, you have a small number of closed labs, they
lock down development, we probably risk being in the lead at all, like probably
the other governments are getting access to it.
That's my view.
I actually think on both these things, spreading prosperity for more evenly
around the world, making it so that there can be more progress and on safety,
I think we're basically just going to find over time that open source leads.
Look, there are going to be issues, right?
It's like, well, to mitigate the issues.
We're going to test everything rigorously.
We do, we work with governments on all the stuff.
We'll continue doing that.
Um, but that's my view of, of kind of where the equilibrium, I think we'll
settle out given what I know today.
So next Mark Zuckerberg is going to start talking about economic possibilities
with the use of AI.
And this is something that I'm extremely curious and excited about.
I tend to be an optimist.
I can also see the pessimist point of view here and open AI just came out with a
bunch of research talking about UBI and economic effects of AI.
And I'm going to be reading and covering that in a subsequent video.
But for now, let's see what Mark Zuckerberg has to say about it.
There's a version of this, which AI will do no matter how it's developed.
Um, and then there's a version of this that I think benefits from open
source specifically.
So I think that AI has more potential than any other single technology
that's being developed right now to increase productivity, accelerate the
economy, um, make it set kind of every person has the ability to be more
creative and, and, and produce more interesting things.
And I think that that's all going to be great.
I also think I, I hope that it'll help out with science and, um, medical
research and things like that.
There were a lot of folks today though, who don't necessarily have access to
the ability to fine tune or build their own state of the art models.
So they're sort of limited to what these large labs do.
Um, and like I just said, I think, um, you know, one of the defining aspects of
our culture around innovation as a sort of a country or society is like, it's
not just big companies that do it, right?
There's all these startups and hackers and academics and people in university.
And I think you want to give all of those folks access to state of the art
models that they can build on top of, not just that they can run, which is
what they have today with, with the closed vendors, but that they can
build on top of and tweak and distill down to smaller models that they can run
on their laptop or their phone or whatever other device they're building.
And I think that that's just going to unlock a ton of progress.
There's also a version of this where there, you can look at it by, you know,
nation too.
Um, you know, so it's not just that startups might not have the resources
or universities might not have the resources to go train their own, um,
they know, large scale foundation models now or in the future.
But, um, but there are a lot of countries that aren't going to have the
ability to do that because I mean, you know, pretty soon these things are
going to cost many billions of dollars to train.
And I think that having the ability for different countries and entrepreneurs
and different countries and businesses to use it to serve people better and just
do better work is going to be something that, that basically like lifts all
boats around the world and, um, just has a massive kind of equalizing effect.
So I know that's really positive here.
Rowan asked Mark about specifically in his letter, which I'll cover in another
video, but he directly called out Apple in their closed approach.
And Rowan asked him to elaborate on it and what are his thoughts.
So let's listen.
I mean, my point in there is more, it's a little more philosophical on how
it's affected my own kind of approach towards things and psychologically
sort of affected how I think about building stuff.
Um, I actually don't know how they're going to approach AI.
Um, you know, they do some open development.
They do some close development.
Um, you know, by the way, I think it's worth noting, like, I don't actually
consider myself to be an open source as Ellen.
I just think that in this case, um, I think that open models are going to be
the standard and I think that that's going to be good for the world, but we
do open development, we do close development.
So I get it, right?
And I'm not saying that Apple is necessarily going to be on the wrong
place on this for AI, but if you look back over the last 10 or 15 years, it
has been a formative experience for us is building our services on top of
platforms that are controlled by our competitors.
And for a number of different incentives.
Oh, I can just sense, I can just sense the anger here.
And I can tell he's being very diplomatic about the way he's saying all of this.
But I know he got burned and burned for years on the fact that he had to
build his platforms during the mobile revolution, which really took over everything.
He had to build Facebook and the rest of his app portfolio on top of his competitors.
And he doesn't want to make that mistake again.
That is also likely why they invested and he invested so much in the metaverse
because he really foresaw the VR revolution as being the next computing platform.
And so he wanted to be way ahead of that.
And he was.
And although it didn't come to fruition either as quickly or at all, the way he
thought it would, AI seemingly is heading in that same direction.
And he wants to be the platform.
Meta wants to be the platform.
They absolutely, from my perspective, apply different rules to kind of limit
what we can do.
And, and yeah, they have all these taxes.
And, you know, at some point we did, we've done some analysis that we think
we'd be way more profitable if it weren't for some of these arbitrary rules.
And I think a lot of other businesses would be too.
But, you know, honestly, the money part, I think it's annoying.
But for me, it's not the biggest thing.
It's I think it's a little bit soul crushing when you go build features
that are what you believe is good for your community.
And then you're told that you can't ship them because some company wants to put
you in a box so that they can better compete with you.
Don't mess with the Zuck.
He thinks in 4D chess.
My concern for AI at this point isn't actually Apple.
It's more the other companies and how that would evolve.
And I think to some degree, it's not even that I'm not even saying that
they're like bad people.
It's it's I think that there's just a physics and incentive structure to the
system where, you know, if you build a closed system, then eventually there are
all these forces on you that that sort of kind of push you to to kind of clamp
down on things.
And I think that it will be a healthier ecosystem if it's developed more like
the web, but more capable.
And I think that, you know, because of how mobile developed, we're the closed
model one, right?
And it's like Apple, I think, has really reaped most of the benefits in terms
of, you know, they there might be more Android phones out there, but like Apple
gets like almost all the profits of for mobile phones.
I think there's a bit of recency bias because these are these are long cycles,
right? I mean, the iPhone came out in 2007, right?
So we're almost 20 years into this thing.
It's a long cycle, but it's easy to forget the fact that the closed model
doesn't always win.
If you go back to PCs, now, I know a lot of people have, especially if you're
using the Linux analogy, people don't necessarily consider windows to be maximally
open, but compared to the Apple approach of kind of coupling your operating
system with the device, the Windows approach was a more open ecosystem.
And it won.
And part of my hope for the next generation of platforms, which includes
both AI and the work that we're doing and augmented in virtual reality is to,
you know, meta wants to be on the side of building the open ecosystems.
And it's not just that we want to build something that's an alternative to
the closed ecosystem.
I want to restore the industry to the state where the open ecosystem is actually
the one that is leading.
As I said earlier, his motivations for doing this are clearly because he got burned.
That is why he is trying to change the way that this ecosystem is going to be
developed and play out in the long run.
And I kind of love it.
I love this approach.
This is also why Elon Musk decided to open source grok because he was bitter
at open AI being closed AI, taking a bunch of his money and then eventually
converting into a for profit company.
And so there is nothing like a burned entrepreneur with a chip on their
shoulder and a little bit of spite to really drive them to innovate.
And let me tell you, I am here for it.
I love it.
All right.
So Rowan now asks Mark Zuckerberg about llama for, and I'm sure he's already
planning llama for, but he just released llama 3.5.
He just released the 405 B model.
And so I think all of their efforts, probably for the foreseeable future are
going to be on iterating and innovating on llama three, llama 3.1, llama 3.2.
And they'll probably have llama for cooking in the background, but it's
going to be a while before we see that.
And I'm going to guess that's probably going to come out a little bit after
GPT five comes out.
Oh man.
I mean, it's, you know, we're just doing 3.1 for, for, for llama now.
I think it might be a little early to talk about llama four, but, um, but
we've got the compute cluster set up.
All right.
I think that was hilarious.
He's like, oh, it's probably a little bit too early to be thinking about
llama four, but we have all the compute necessary to do it.
I absolutely love this new version of Zuck to the data set up.
We, we kind of have a sense of what, what the, the architecture is going to be.
And, and, and have run a bunch of research experiments to, to kind of max that out.
So I do think that, um, llama four is going to be another big leap on top of
llama three.
I think we have, um, a bunch more progress that we can make.
I mean, this is the first dot release for llama.
There's more that I'd like to do, including launching the, uh, the, the
multimodal models, um, which we, we, yes, I can't wait for that.
That is the one biggest missing capability between llama three, four,
oh five B and GPT four, oh GPT four, oh can take many different file formats,
interpret them, including images, and really that one feature I use all the time.
And unfortunately we have not had a llama model that is really truly multimodal.
And there have been a few fine tune versions that allow for multimodality,
but they don't work super well.
If I'm being honest, you've seen me test them on this channel.
So I can't wait for a native multimodal llama three point one.
We kind of had an unfortunate setback on, on, on that.
Um, but, but I think we're going to be launching them probably
everywhere outside of the EU.
Ah, so for those who are wondering what he's talking about, just recently it was
reported that they are not going to be releasing multimodal AI in the EU strictly
because of their regulations and that is the setback that he's talking about.
Um, so I can't wait till they release it here in the US and other countries
that allow it, but not going to be in the EU.
And that is one reason why they need to ease up on the regulation in the EU.
And hopefully we don't overregulate in the US and from where I'm from, California.
Yeah, probably a little early to talk about llama four, but, but it is going to be
awesome and it has been one of the interesting things and running the
company is basically planning out the compute clusters and data trajectories
for not just llama four, but you know, the next, um, probably four or five
versions of llama, because I mean, these are long lead time investments to
build out these data centers and, and the power around them and, um, and the
chip architectures and the networking architecture.
So all this stuff.
Um, so yeah, I, I realized that's, that's a bit of a non-answer for now,
other than just some general excitement, but, um, I don't know.
Let's, uh, I think llama three deserves at least, um, you know, llama 3.1
deserves at least a week of, of kind of just processing, um, you know, what
we've put out there, uh, before we get into talking about the future.
All right.
I'm going to put this out into the world.
I want to interview Mark Zuckerberg and if I'm the one who gets to interview him
or one of the ones who gets to interview him as part of the llama four launch,
I would love that.
So if anybody from meta is watching this, please consider me.
I would love to do that.
All right.
Next, he's going to be talking about AGI and agents, something that I've seen
little bits of in the llama 3.1 launch.
They are defining their own agent architecture, it seems, or its own language.
I still haven't dug into it too deeply yet, but I plan to, but let's see what
Mark has to say about AGI and specifically agents.
I'm happy to talk about it, both from a technical perspective and a product
perspective, but since we've mostly talked about the models so far, maybe I'll
start with, um, with the products.
So our vision is that there should be a lot of different AIs out there and AI
services, not just kind of one singular AI.
And that really informs the open source approach.
It's, you know, it also informs the product roadmap.
So yeah, we, we have met AI, um, met AI is doing quite well.
My goal was for it to be the most used AI assistant in the world by the end of
the year.
I think we're well on track for that.
We'll probably hit it, hit that milestone, um, you know, a few months
before the end of the year.
That's a huge statement.
If true, that means that meta AI has more usage than chat GPT, which would be
surprising to me because anybody who knows about AI knows about chat GPT, but
they don't necessarily know about Anthropax, Claude or other models.
And many people have never even heard of llama before.
Obviously meta has the billions of built in user base.
So it's exciting to see that, but he's specifically talking about the meta.ai
product.
And I believe when he's saying meta AI, it's not just meta.ai, which is kind
of the chat GPT competitor, but it is also each of the implementations of meta
AI and each of their products, WhatsApp, Instagram, Facebook, et cetera.
A lot of what we're focused on is giving every creator and every small
business, um, the ability to create AI agents for themselves, um, making it so
that every person on our platforms can create their own AI agents that they
want to interact with.
And if you think about it, these are just huge spaces, right?
So there are hundreds of millions of small businesses in the world.
And one of the things I think is really important is basically making it.
So with a relatively small amount of work, um, a business can basically, you
know, a few taps, um, stand up an AI agent for themselves that, uh, can do
customer support, sales, communicate with all their people, uh, all their
customers, that's, it's going to be hundreds of millions, maybe billions of
what kind of small business agents.
Similar deal for creators.
Um, there are more than, it's more than 200 million people on our platforms who
consider themselves creators who basically use our platform, um, in a way
that is primarily for, you know, building a community, um, you know,
put, putting out content feel like it's, it's kind of like a part of their
job is, is doing that.
And they all have this basic issue, which is that there aren't enough hours
in the day to engage with their community as much as they'd like.
And likewise, I think that their communities would generally want more of
their time, but, um, but again, not enough hours in the day.
So I just think it's a, there's going to be a huge unlock where basically
every creator can pull in all their information from social media, can train
these systems, um, to reflect their values and their business objectives and
what they're trying to do.
And then people can, can interact with that.
It'll be almost like this.
Almost artistic artifact that creators create that, um, that people can, can,
can kind of interact with in different ways.
And then, and that's not even getting into all the different ways that I think
people are going to be able to create, you know, different AI agents for
themselves to do different things.
So I think we're going to live in a world where there are going to be hundreds
of millions of billions of different AI agents, eventually probably more AI
agents than there are people in the world and that people are just going to
interact with them in all these different ways.
So that's part of, you know, that's the product vision.
Obviously there's a lot of business opportunity in that that's where we want
to go make money.
So we don't want to, we're not going to make money from selling access to the
model itself.
Um, cause again, we're not a public cloud company.
We will make money by building the best products.
An important ingredient to the best products is building, is having the best models.
So this is echoing exactly what Jan Lacoon told Lex Freeman a few months ago,
where he said, they're not going to make money by developing and deploying
open source models, but as being the company who can define the standards and
thus make the best products around that AI, that's going to be meta.
And that's how they're going to make money.
All right.
In this last section, he talks about fear of AI, why people worry about AI, why
they should, why they shouldn't.
So let's take a look.
I mean, financially, one thing that I'm quite aware of is the internet, um, had
a big bubble burst before it succeeded.
And it's all the people who were very long on the internet, um, were eventually
right, but sometimes things take a little longer to develop than you think.
And you just need to have the commitment to see that through.
And, um, that's something that I'm aware of because yeah, I mean, I, I'm
really excited about, you know, all the unlocks that we're going to get from
llama three and then llama four and then llama five.
And I think that's going to translate into better products.
But realistically, it's hard to know in advance when something is good enough
that you're going to have a product that billions of people use.
And then when it's ready to, to kind of be a large business and I mean,
look, we're all spending, you know, a lot of capital and, and, uh, on basically
training these models.
So I think that people are going to be probably losing money for quite a while.
Yeah.
And that's what I've been hearing generally from the industry.
Every single big tech company, even a lot of VC dollars going into startups,
they're all spending their money buying the silicon.
They are mostly buying it from Nvidia.
That is why Nvidia's stock price has skyrocketed over the last couple of years.
However, all of that initial investment has not necessarily translated into revenue.
In fact, I think the number is only like 30 billion in revenue, even though
there's been a trillion dollars in spend.
So that's not sustainable in the long term.
There is likely a mini bubble that is going to burst eventually, but obviously
I'm bullish on AI and that's what I'm dedicating all of my time to right now.
So I believe in it in the long run.
And as he said, people who were early on the web and long on the web, eventually
were right.
Now, there was a bubble in between that we do have to think about and consider
and worry about when it comes to AI.
The other part of this that I think you are more getting at is people's
concern about what it means for their livelihoods.
And on that, this is one of the reasons why I think the open source approach,
the approach of lots of different models out there that are kind of
personalized and customized to every business and every creator and every person.
Um, I think that's important because if this develops in a way where it's just a,
you know, a small number of companies that build the products and benefit and
people use the products and maybe they like talking to, to, you know, an
AI assistant and that's valuable for them.
But, you know, if that, if this doesn't in some way help lift all boats, then
I think you end up eventually getting a backlash.
And part of what I've spent some time thinking about after just looking at
how the kind of web 2.0 stuff developed is in the next generation of technologies
around AI, around AR and VR, how do we create not just a kind of thriving
set of products, um, and, and kind of economic kind of productivity gains,
but how do we have like a better and more sustainable political economy around
it where there's just way more people who are, who, who feel like they're,
they're kind of bought in or benefiting from this, um, in support of, of, of the system.
And, you know, I, I, I thought we did that reasonably well with social media,
but, um, but I, you know, just looking at some of the feedback and some
of the response from, from the world, um, I think that it's going to be
important to do that even better with AI and some of the new technologies in
order to, to, uh, mitigate some of the concerns that people are going to have
about what this is going to mean for their livelihoods and, and jobs and their lives.
So we're going to end it there.
I think that is a great place to end it.
Something for us to think about over the coming weeks, months and years,
incredibly important stuff.
I'm so excited to see all the different innovations that come from Lama 3.1,
whether we're talking about an extremely capable model that can fit on your phone
or on your laptop or the massive 405B model that is as capable as any closed
source frontier model.
If you enjoyed this video, please consider giving a like and subscribe,
and I'll see you in the next one.
