Another special speaker that we have today is Professor Ahmed Al-Gamal.
He's a professor in the Department of Computer Science at Rutgers University and also the
founder of the Art and Artificial Intelligence Lab at Rutgers.
So let us ask Professor Al-Gamal to be a little more introduced themselves and give us a little
background and talk.
One thing that I wanted to mention is that his talk today is about the shape of the art
history in the eyes of the machine.
And I think that he has done many interesting work in the realm of understanding the patterns
and evolution of art through the history.
Please go ahead.
Thank you.
Thank you very much.
Thank you for joining me and thank you everybody who is here.
I will start by answering questions you asked earlier about why I'm doing this.
And I think it will be more also clear during the talk.
Basically during my high school years, I mean, I was raised up in Alexandria, Egypt, and
when you're raised up in the country, you see a lot of archaeology and history and art.
And I really wanted to study archaeology and art history.
That was really my passion.
But at the same time, computer science was something totally new at that time and around
the early 90s and I was fascinated by it and had to choose a major.
So everybody would tell me if you go to archaeology or art history, you'll have no career and
you're going to make no money.
And I went to study computer science and for the last 25 years, I've been doing AI.
But I find that actually my passion is really in art.
Every time I go to a computer vision conference, I escape 90% of the conference and I go to
galleries and museums rather than attending the sessions and I realize I have to do something
about it.
And it will be clear in the talk basically how I moved into doing that and why I moved
to do that.
So let me just start right away by sharing my screen.
So basically as an AI researcher, when I look at images like that, I mean we'll be
very happy if the machine will recognize a man, there's a woman, there's trees and things
like that.
That's what we do in vision and that's what I've been doing for a long time also.
However, basically we realize that art, when you look at art, is much more than that.
There are layers and layers of context, historical context, social context, understanding, there
are emotions that happens.
I mean, art is not about object recognition or anything like that, it's much more.
And since the ultimate goal of AI research is to make the machine, make machines that
have perceptual cognitive and intellectual abilities similar to those of humans, I find
that analysis of paintings, whatever the analysis means, involves actually all these tasks,
perception, cognition and intellectual abilities.
And that's why I think it's very important to advance AI to look at art and try to understand
art the same way human does.
So basically I find that the ability to understand and generate human level creative products
such as poetry, stories, jokes, music, paintings is fundamental to show that artificial intelligence
algorithms are actually intelligent.
And the first question that always been asked when I give talks, especially in humanities
with audience from humanities, is how to combine art and AI, basically isn't art is
a judgment which is subjective and science objective, how can this be combined?
And that's a very important question and actually it's rooted in Western philosophy.
And the Western philosophy has blazed aesthetic comprehension in the realm of subjectivity.
And we can trace that back to Immanuel Kant in 19th century, sorry in 18th century when
in his book about critique as the judgment, when he obviously argued that the judgment
of taste is not cognitive judgment, it's not logical, but aesthetic, which means that it's
one whose terminal ground cannot be other than subjective.
And that actually shaped the separation between art and science in the last two centuries.
So another quote here from Colin Martindale, who is a psychology professor at the University
of Maine, who has a totally different point of view.
As a scientist, I feel that if everything in the universe is governed by laws, then art
history must be as well.
So totally scientific approach, basically nothing is subjective.
And another viewpoint from Eric Kindle, who's a neuroscientist and winner of Nobel Prize,
by examining perception of art as an interpretation of sensory experience, scientific eyes can
in principle describe how the brain perceives and responds to art.
And let me go into basically saying, can any aspect of art which is creative and subjectivity
experience be studied objectively?
And finally, a quote from an art historian, which is very unusual art historian, his name
is George Kubler from his book, The Shape of Time, which I'm going to talk about in the
talk a little bit later.
He's saying basically that art history could move to contain unexpected potentiality as
a predictive science, which is very uncommon view within art history.
So my goal is really to understand what are the implications of looking at art through
the eyes of the machine.
And by that I mean AI in particular.
That's why I started the AI lab about maybe eight years ago at Rutgers, really focusing
on advancing AI by looking at art and also seeing what can we do about art if we do AI.
And here are some of my collaborators from art history, from fine art, and I have been
blessed to work with many students from Rutgers and from other universities as well.
And these are some of the activities that we have been done through the years, many others.
And these are some things I'm going to talk about today.
Building models to understand art, style, genre, art specification, try to understand
influences between artists, try to understand creativity, how to quantify
creativity, how to generate art, how to understand the evolution of art history.
Many things have been done during these years.
But let me start by the basics, basically.
So how artists talk about art.
So if you look at an artwork like this amazing Renoir painting, basically artists doesn't
look at this and tell you that multiple people or people are eating food or things like that.
Basically talk about artists talk about elements of art, the space, the texture, the form, the
shape, the color, things like that.
Principles of art, the movement, the unity, the harmony, balance, contrast, other topics
like subject matter, brushstrokes, meaning, historical context, social context.
All these things are basically what artists talk about when talk about art.
Their least least concern is things like object or scene classification and things like
that or genre caption.
So our goal really was, in the last few years, is try to quantify each of these elements.
And we have done a lot of work on quantifying each of these elements, how to do visual
encoding of the image in order to be able to quantify these elements and principles of art.
And in particular, one of the very, very important things in art is the topic of style.
So what is style?
So basically here, this is a depiction of the last suburb, so basically the famous
painting by DaVinci, but DaVinci's painting here is just one of them.
This is much earlier to version, many versions by many artists, to 20th century versions.
And really in here, you can see what is the meaning of style in one slide like that.
We're basically depicting the subject matter in two different ways, depending on
historical point in what happened in art history that specify how the artist will depict the scene.
And here's the first thing, I mean, if you look at this and what artists mean by style and
compare that to what we in computer vision or AI do when you do things like style transfer
and things like that, to tell your eyes, basically, it's a joke that the way we do
a style transfer in machine learning and computer vision, which is mainly basically
meaning taking the ballot from one image to another or a texture from one image to another,
has nothing to do with the concept of style in reality, because the concept of style is
much more deeper than just these simple things.
So the question really is what characterizes the sequence and evolution of art style change
over time? How can we characterize these changes?
And actually, what factors drive these changes of style over time?
Why even artists change style over time?
When that happened? What triggers it?
And how to characterize it when it happens?
Can we build conventional models that can help answer these questions?
So we started very early with a very simple thing, which is painting style classification.
You have a bunch of images and you have style labels on them.
So it's really a simple supervised machine learning problem.
And you want to classify the painting to think classes like Renaissance, Baroque,
Impressionism, Cubism, abstract things like that.
So very simple problem.
And we take a painting.
We have visual encoding using different pictures, trying to capture the low-level,
mid-level, semantic-level picture, which are parallel to a different concept art, as I mentioned,
and trying different machine learning techniques on them and doing supervised learning to classify
style. And basically, these show progress over the years from the year 2012 to maybe three years ago,
where we have been really trying any new things that have been machine learning and see what it adds.
Things from the time of Beg of Wards and classmates and HOGs, if you really remember that,
until the time of seeing ends and deep learning.
The number of style classes that have been basically increasing the
number of classes over time, trying to get deeper, but basically how to monitor the progress is
compared to random guess. How much better you can do than the random guess, starting from
four times random guess to 12 times random guess. So, okay, and can do better than that.
All right, so we do classification. The machine can classify style at the level of
maybe a first-year art history students. If you give it an artwork, it can tell you this
cubism, this is impression, this is renaissance. Good. The machine can do that. So what? Why that's
even important? So, when I talk to art historian about machine classifying style, they ask me,
so what? Why that's even important? And here is why I think it's important.
Classifying style by the machine is not what interest art historian, but actually instead
what the important is, what are that tell us about the characteristics of style and what
drive style changes? And we know that if the machine can classify style successfully,
that implies that the machine has learned some internal representation that encodes some features,
some discriminative features through its visual analysis of these arts. However, we also know that
the machine uses visual feature that's always very hard to interpret by humans. So, especially
if you're doing learning, so we are to interpret these visual features. So it's very hard to
understand how the machine did this vision of style to start to get something useful.
So we went into studying basically how the machine identify style and if there are
relations between the way the machine internally represents style and the way art historian
think about style. And for that, it's very important to look at how art historian look at style.
Here, this is Henrich Wolblin, one of the founding fathers of art history, modern art history.
He basically have a theory about style. In particular, he looked at how style,
how to separate the study of subject matter from the study of the visual form, which is
style. And in his book, basically, he really studied the difference between renaissance and
baroque. So in the top here is renaissance artwork and in the bottom is a baroque artwork.
And he suggested basically some visual schema that you can tell the difference between renaissance
art and baroque art. Basically, he mentioned five bears of elements. For example, linear versus
vinterly. In renaissance art, if you look at the contours, they are very sharp.
While in baroque, it's very fuzzy contours. That's was it linear versus vinterly.
In renaissance, if all the subjects are in one plane, while in baroque, there are depth in the
scene. So this is planar versus recessional. In renaissance, everything seems to be within
canvas. While in baroque, basically, you see like a cropped image from a bigger scene.
So this is called closed form versus open form. In renaissance, basically, every subject by
himself or by herself. So this multiplicity versus in baroque, this unity here, you can see the old
subject are part of one unit. In renaissance, everything has absolute clarity.
All the scenes, everything is in focus. While in baroque, artists start to have
relative clarity. There are depth, there are things that are in focus, things that are out of
focus, depending on what the artist is trying to do. So he suggested that these five bears
is really what make the difference between renaissance and baroque.
And even when to say that, basically, these five bears are the kind of feature that
can classify any style. So any style variation really goes along these elements. However,
this is very interesting. However, this is a theory in art history, which is what we call in
math or science, basically a congestion, not a theory, because there is no proof of that.
How can we even prove these theories, especially if you want to generalize it to all styles?
So what we did is really is we're trying to look at this internal representation of how the machine
classifies style and draw the parallel to what Wolverine suggested. So what we did is,
basically, we trained several models, several CNN models, and we keep doing that. So things like
Alex Net, when they appeared, VGG Nets, ResNet, every CNN model that comes around, we try that as well.
And the goal is basically to train the machine to do style classification in a supervised manner.
But the goal is really not to do classification. The goal is to look at what has been learned here.
So analyze the internal representation and do some statistical analysis and some visualization on top
of that. So after the machine learned style with acceptable accuracy, we kind of start adding
layers in the middle here to increase the interpretability of the representation.
Basically, go down to as small as the number of internal nodes as possible here to have
small interpretable representation, doing things like principle components on the activation,
source separation, ICA, understanding, looking at the manifolds of activations,
doing correlation with time, correlation with Wolverine. There's all these kinds of analysis
we have done to understand the representation. And here are some of the results that we found.
So this is the first thing that's very interesting. We used either B-trained model on ImageNet
that we fine-tuned on Art Collection, WikiArt Collection, about 70,000 images in our studies.
And by doing that, we reach accuracy of classification is about 60%, more or less,
all these networks. If you use a data from scratch, you can actually get 10% less, 50%,
only in 77,000 images. So there needs to be trained on a million ImageNet.
All right, so that's interesting so we can get reasonable results even without any pre-training.
But the interesting thing is this, looking at the filters that the machine learned, if you train
from scratch on style, you look very different from the filter that you typically see in object
recognition CNNs. You know, in object recognition CNNs, you always get these Gabor filters and this
edge-like, oriented edge-like filters. If you look at how the machine look at style,
only look at style construction, only nothing like that. We don't see almost any edges, maybe
only one filter looks like a horizontal horizon or something like that. But other than that,
it's very hard to interpret these filters, but definitely they are not edge-like filters.
We should tell you if you want to class high style, there's nothing about object or composition
that matters. There's something else, but what is it? We don't know. So this is one thing to
keep in mind. The most important finding is that looking at activation of the internal layers,
we find that a small number of factors can explain most of the variants in all art history
that we studied. We look at mainly at Western art history, over the last 500 years, just to be
clear. We didn't include any Asian art or African art or other cultures. So between 6 and 10 factors
can explain 95% of the variance in the data. And actually the first two modes of variations
explain about 75% of the variance, depending on the network. So and this is common in all the
networks we have tried, whether it's Alexnest or complex networks like Resonance, you can see that
75% of variance up to 75% of variance can only explain in the first two modes of variations.
So what are these? So here, for example, we visualize a small set of maybe 1700 images.
Every image is a dot in this graph and is the first two modes of variation of the activation of
the layers before the final layer. And here we color code them based on the time of the artwork.
So what you see here is Renaissance art is here and then Baroque art comes here and then
all the way 19th century, all the way to the impressionism here. And then you can see what's
happening in 20th century coming here, pubism and abstraction and art and things like that.
That's amazing. Why? That's amazing. Basically the machine put art in an arrangement, in a
chronological arrangement by itself, although we never tell the machine anything about
when the art was made. The only information the machine sees is the image and the style label.
You don't tell the machine that Renaissance happened before Baroque or Baroque happened before
impressionism or anything like that. But the machine to learn to classify style by itself
has to make the correct historical arrangement of artworks. So we find that basically there is
0.7 correlation coefficients with time if you go clockwise in this graph here.
And each of these axes, there is also a high correlation with time as well.
So that's very interesting. So the machine basically, why that's important? Because
that actually was one of Wolblin's theories, which he said basically
that style changed in a smooth way over time, exactly like a rock rolling down a hill.
That's basically his metaphor. And that's what we see here, that the machine found out that
in order to understand this concept of style, it had to put the art in order historically,
although we didn't get any historical context, but it really finds that by itself.
So that's really confirmed that styles are not just bends that are classification classes that are
isolated. It's smooth transition between them is one of the important things.
And this common in old representation, if you look at any of the networks that we
looked at, whether it's retrained or trained from scratch, can find this high correlation with time
in the representation. And as I mentioned, basically, this is a confirmed
Henry Wolblin congesture about that. So the question now is, what are these two factors
that explain 75% of what happened in art history? So if you look at this and try to interpret it,
it's very hard to really find one interpretation, people can have different interpretations.
But we look at basically how these axes correlate with the five pairs that I mentioned
by Wolblin, Binterley versus linear, Recessional versus Blainer, things like that. And we find
that in all the time, the first mode of variation, the most important mode of variation is being
Recessional versus Blainer. And the second, all the time, the second most important mode of variation
is correlated the most with linear versus Binterley. And that gives us a very nice way to look at what
happened in art history over the last 500 years. So basically, what happened is, here at Renaissance
time, art was totally Blainer and basically linear, all the contours was linear and sharp.
And came Renaissance, came Baroque and things started to be Recessional depth,
and art becomes Binterley and the contours become fuzzy. All the way till
Impressionism, where that's the ultimate Binterley experience. In Impressionism,
all the strokes are just fuzzy and we don't see any contours. So this is the ultimate
Binterley experience. But you can see that you still have depth,
artists looking at scenes and things are still Recessional. And then came Cezanne and came
20th century art, where basically things become flat, artists start flattening the canvas again
and becoming to be Blainer again, like Renaissance. And basically, most of 20th century is in the
Blainer side of things, but coming to be linear again. So if you look at Bob art, like Warhol
or abstract art, you can find that arts become linear again in the contours. So basically,
art history went into a full 360 degree cycle over the last 500 years in Western civilization,
which really captured by this one diagram that really came from the representation the machine
learned from looking at art style. And again, some other interesting things that we found in
this representation, if you look at two of the modes of variation, I think these are the fifth
and sixth or maybe fourth and fifth modes of variation, these are the ones that correlate
more with the discrimination between Renaissance and Baroque. So you can see Baroque in the top
here and Renaissance in the bottom here. And you can see that basically, these two factors
are created the most with the bears of Wolverine. So basically, Wolverine was correct in suggesting
that these bears are a good way to discriminate between Renaissance and Baroque. However, we also
found that he's not correct when he said that this is, this can tell the difference between
all other styles. All other styles basically are spanned by these five factors, because we find that
we cannot tell the difference between inversionism and most inversionism by looking at
these, any of these factors. There is no, none of them correlate with this discrimination.
Another very interesting thing that we find is
when we look at the activation manifolds of these networks, in terms of representation of these
networks, we look at the activation manifolds. And again, here we're visualizing different
artworks based on the time of creation from 1400 to 2000. You can see also the movement
of art history and how things have changed. And you can find interesting connections. So you can
see basically renaissance here, moving into Baroque, moving into nucleosicism in 19th century,
moving into realism, and then moving into inversionism here. And from inversionism,
basically, both the inversionism went in two directions, one direction that go to
exhibitionism and one direction went to abstraction. So you can see cubism and abstraction here.
So that really tells us much about what happened in art history. And we find very interesting
things when we look at this. For example, if you look at this figure here, look at this connection
between inversionism and what happened after. And if you look carefully here, we find that
this connection is mainly Cézanne's work. So all the circled artwork here are work by Cézanne.
So at the bottom here, you can find the inversionism and that's Cézanne and that connect to abstraction
and cubism. So that's interesting. As we can see here, cubism and abstraction in the early 20th
century happening after Cézanne. Here's another representation where really here is Cézanne's
work and this is inversionism and basically this is cubism, Picasso and Grace and other cubists.
And you can see how Cézanne's connection here, making the connection between
inversionism moving into 20th century and how special his artwork. And you can see that in
the data, you can even touch it. You can see how Cézanne is a bridge here. And the interesting
thing is that obviously being a naive person when it comes to art history, I always go to Wikipedia
when I learn about something. When I go to Wikipedia, I learn more about Cézanne. I found this
interesting quote, Cézanne is said to have formed the bridge between 19th century inversionism and
20th century's artistic inquiries in cubism and both Matisse and Picasso are said to have
remarked Cézanne as their father basically. And that's very interesting because this is not only
a metaphor, like a bridge here isn't a metaphor like in art history, but actually it's something
that you can almost touch in the data, in the visualization. You can see how Cézanne is really
connecting this. Not only that, but I mean another interesting thing here, if you look at this
manifold representation, you can see many artworks here are renaissance artworks that
are built away from the Renaissance crowd because the way manifold learning work,
in manifold learning you're building a graph, connecting all nodes and you do embedding of
that graph. So you see here that these renaissance paintings are embedded away from renaissance.
When you look carefully about this, you find that basically these are
particular artists that keep appearing again and again here. In particular, we find El Greco
and Dürer, the German artist. So it's clearly that El Greco and Dürer has
influenced modern art and many modern artists have really influenced by them and that's very
clear in the case of El Greco because of the way he drew in a very deformed way which really
affected exhibitionism and even cubism and that's very clear here. I see El Greco work
built away from renaissance close to modern art. In Dürer, it's very hard to understand
really how Dürer influenced modern art history, but also Dürer is very well
known that he's influenced art history in the 20th century, but not clearly exactly how.
So that's very interesting. All these tell us about how to characterize style changes,
but let's dig deeper into that and our work that I'm going to talk about now,
back from 2014, six years ago, was about confine creativity in art and art networks.
How can we quantify creativity in art? And you will understand a little bit how that relates to
style changes, how that characterizes style changes as well. So basically, you wanted to develop
algorithm that assess creativity of a painting given its context and art history.
That might seem to be silly question for some people, but I think it's very important
because if you want to build creative agents, it has to have its ability to assess
creativity by itself. Because at this point, at this point, when a machine creates art or music,
it's always the human that assesses creativity of this machine. We do human subject studies,
we give it to judges, things like that. But can the machine on one day be able to assess
its own creativity? And for that, we need to develop these algorithms to quantify creativity.
But that leads us to question, what's creativity to start with? How can we define
creativity in a way that is quantifiable? So there is a historically long and ongoing debate
on how to define creativity. We can describe a person to be creative, like Mozart is creative
or Warhol is creative. Or we can describe a product to be creative. So you can say, for example,
the Mona Lisa was a creative artwork. Or some people refer to characterize the mental process
to be creative. So there are different ways to describe creativity. We focus on novelty of
a product in particular, whether something is creative or not. So how can we do that in an
objective way? So it seems to be the two main conditions for some product to be called creative.
This product has to be novel compared to prior work, but also has to be of some value. So we will
take note of it and become influential. Which exactly like what happens in scientific community
when you write a paper, right? I mean, you have to be novel compared to prior research and doesn't
make a difference if nobody cites your work. So basically, that tells us it's not influential and
not that creative. This is a quote from a very good book, which is a collection of essays about
creativity, which basically concluded that although there are three different ways to define
creativity, these are the most common essence of what creativity is. And that actually relates back
to Kant philosophy. If you go to Kant philosophy, he defined five elements of what he called artistic
genius. And the very first two of them is originality. The originality must be its primary
characteristic and influence. Its product must at the same time be modeled or exemplary. So other
artists would start to get influenced by that. So these are the two fundamental reasons behind
what he called artistic genius or creativity. Let's move forward to the 20th century.
One person in the audience asked a question referring to Margaret Bowden. So Margaret Bowden
suggested basically two distinct notions of creativity. The psychological creativity or
big creativity, which assists the novelty of idea respect to its creator versus historical
creativity, which is assessing the novelty with respect to the whole human history,
is what I'm creating valuable and novel compared to all what have happened in history.
So this is the objective measure. The psychological creativity is more a subjective measure,
but historical creativity is an objective measure. So basically that's what we're trying to do. We're
trying to align ourselves with historical creativity of product and try to define an algorithm to do
that. So we propose an algorithm to assess creativity that's basically unsupervised,
meaning that we don't have any creativity labels. We just have a bunch of artworks.
And the only information we're going to have is the date that artwork was done.
So these are two information, the image and the date, nothing else. And we're trying to
infer from that something about creativity. Some fundamental issues we have to think about
before even we start deriving any algorithm about creativity, because these are common problems.
These are common problems that will face any algorithm that will look at creativity.
Suppose you have an algorithm that assists creativity, that algorithm looking at an artwork
and trying to judge whether it's creative or not. Obviously, that cannot be done in a vacuum.
The algorithm has to look at the context of that art history to judge. So this one limitation
that the algorithm only see a part of art history, whatever digitized, whatever reached us and
digitized and available as a data set. So that's one problem. So these are closed, what I call the
closed world limitation. And then the algorithm look at the art through some visual encoding,
which also add limitation. So there are some concepts and elements that are being quantified
here through these visual features. And there are others that might not. So that's basically
another limitation, which I call the artistic concept quantification limitation.
And then any algorithm has parameters. And these parameters will influence the output. So
we can get different results by changing the parameters. So how can we make use of that?
So, however, these are all, all should not stop us because first the closed world limitation
will always go away. We have more and more art being digitized and more data we can get. So this
will will go away. We have advances every day in visual encoding and become less blind and
have better encoding. And the parameters actually are not a limitation because the
parameter actually we can really give creativity scores and understand exactly how the parameters
affect the scores in a way to understand what we are, what we are measuring. Are we measuring
creativity based on certain settings related to composition or are you measuring it with a bit
to brush stroke work or color? So all that allow us to a rich way to understand creativity.
So the bottom line is we want to derive an algorithm that look at art pieces, images and
their timestamp and give us a score. So that's basically the input and output.
And let's, what we do is that we start creating a directed graph between all paintings in our
collection where there is an edge between each two paintings with a weight reflecting the visual
similarity according to the visual encoding that we are using, how similar these two paintings are.
And it's directed based on the time basically if BI comes before BJ, so it's directed that way.
And now let's think about a symbol inference we can do. Suppose you look at these two arts,
Caravaggio from 1602 and a less known artist from 1800, almost 200 years later.
If you look at these two artworks side by side, you can realize basically that
this second artwork is very close to that in terms of body bowls, in terms of light, in terms of
composition, subject matter, everything's very similar. So it's clear that that work is a derivative
of Caravaggio. So in one sense that artwork is not as novel compared to Caravaggio. And in another
sense, Caravaggio has an influence in a direct way to that artist. So high similarity between two
artworks in the network imply that creativity of the earlier work has to go up and creativity
of the later artwork has to go down. These go down because it's derivative and these go up
because it's influential, at least on these two bears. Compared to another case like that, these
are precisely from 1883 and this Picasso from between 20 years later from 1907.
They are very different, had nothing to do with each other, different ways of using color, composition,
totally different. So very little similarity between them, of course, depending on the
future you are looking for, but still very low similarity. And that imply that Cicely was not
influential on Picasso, at least in a direct way. And Picasso was basically novel in making that
art compared to this work. So that low similarity implies lower creativity for that artwork by
Cicely and higher creativity for that work by Picasso. So if you take these two elements
of influence and start building a formulation for creativity, what you can do, you can write
down a formulation like that where the creativity of any node can be described as the creativity of
all nodes connected to it. In this formula here, alpha is a factor that indicates the probability
that the similarity between painting can be just a coincidence. And the way to interpret this formula
is like that. Any node in the graph collects influence from all its outgoing connection
in this submission here. And for any node in the graph, it distributes its creativity tokens
among all incoming connections. So you reach this formula that you can write
where this formula actually, if you look at it, it's basically an instance of what's called
network centrality problems. So you can see how many other algorithms are special cases for this
or this special case for others. So you can think of this as a random work in a Markov chain.
If you set alpha to be one, this term will vanish and you have this term only, which is called
basically eigenvector centrality. You can think of it as a weighted variant of Hubel centrality,
if you're familiar with this body of work, basically, network centrality. But basically,
network centrality is very fundamental in studying social networks in these days,
in studying pandemics, propagation, things like that. Even in the big rank algorithm by Google
is basically a network centrality problem. And you can think of this formulation as basically
inverted weighted variant of a big rank. So we can even extend this in a way to
separate originality from influence. So we can see that, basically, originality can be controlled
by another parameter case. We can measure originality or can measure influence in particular.
So the question is, how can you even evaluate that? If everything is so unsupervised here,
you don't have any creativity labels, you can show results to 10 art history and everybody
will have different opinions. So how can we even evaluate this algorithm? So we worked on different
the sets, the wiki art sets, and something called archive the sets much older. And at that time,
we did this work on 714. And at that time, this is the art in the vision was mainly things like
jest and bag of words and things like that. And that was really excellent, because we really
wanted to use features that are not trained on art at all. So these are off the shelf features.
Class me, it was a feature that basically encode object representation in images.
So it's a very good way to encode subject matter in particular. Just come from MIT,
basically comes from MIT, which encode texture and other things related to object and scene
classification. So we thought that these two features are very useful. They are not trained
on art, they are generic, the capture things that we can relate to in art with a subject matter or
or brushstrokes or scene composition. So let's use them and try to make sense of the eyes of
based on that. So here's one short that show basically time x axis from from 200 to 2000.
And every artwork here is blotted with its creativity score. So the higher the score,
the y axis is the creativity score. And you have to remember that the formulation is a zero one
game, meaning that if some artwork, if you give it a set of artworks, the sum has to be consistent.
So for some artwork to score high, another has to score low. Everything that we give
to the algorithm are masterpieces of artwork anyway. So nothing here is really
scrambled by somebody in the street. All these are masterpieces. But the way to look and interpret
this, we essentially are using in particular class me and just we are really trying to
look at creativity with respect to subject matter, how creative were artists in
in in depicting the subject matter over time. So we can see, for example, what scores low in 19th
centuries is art by art by the amazing artist French, Hungary. Why this score low, because
basically according to subject matter, there's nothing really innovative about having a board
tree of a woman in 19th century, because this has been done a lot in Renaissance and Brock all
the time. So subject matter was not the novel. While in the same time what scored very high
was things like Monk, the Scream, or Monet, Haystack, very early version of that, and others.
So when we look carefully on the 100 years from 1850 to 1950, when we have a lot of data digitized
and a lot of artwork, we can find that the machine makes sense a lot about what happened
art history in that time. So you can see the machine identifying things like Monk, the Scream,
very giving very high score, Klimt Booster, things like Cubism and things like that. So
that makes sense. Here, deeper into that, if you look at the first 10 years of 20th century,
the first 10 years of 20th century, the highest scoring artwork, for example, is the Castle Ladies
of Abinon. I didn't know much about that artwork other than I like it, but I didn't know much about
its history at that time. But when I look at its history, I find that art historian now agrees that
basically artwork was the beginning of Cubism, very early, even before Cubism become a thing.
And what you see in this graph here, the machine gives this very high score, and what's stopping
that in 1912 is actually Cubism itself. So these are artworks when basically in the very early
Cubism exhibitions by Picasso and Brock. And you can see here that before that, that was
the high scoring one, and this is stopping that. What's stopping that even more in 1915 artwork by
Malevich, what's called supremist art movement, which is totally abstraction in 1915. That's
stopping even Cubism. Anyway, all that's nice, but how can we even say that it works or not?
It's all in total evidence, right? I mean, here is what's something very interesting. What was that
artwork giving very high score in that chart here? And when you look at Curfew at that artwork in
particular, you find it's an artwork by Mondrian that was dated in our dataset to be in 1910.
And that was very interesting. Obviously, when you find something that you have to look at it and see
why this is scoring very high. And I find something very interesting that basically Mondrian didn't
paint this in 1910. Mondrian painted this in 1932, I guess, I don't remember. So that was a mistake
in the dataset. So the dataset itself has something wrong that would say basically Mondrian
painted that in 1910. And if Mondrian would have painted that in 1910, that would have been even
before Cubism, before abstraction, and would have been the most creative artist in his time.
But obviously, that's not. But that mistake actually gave us a very interesting idea about
how to even evaluate this. So there are many results here. I'm going to skip that. And
the way we evaluate this is what's called the art time machine. So the idea is this very,
very, very simple idea that come from this mistaken, the dating of that artwork. So what
happened if you take an artwork from Baroque or Renaissance and move it forward in time
and change its date to, let's say, 19th century or 20th century? What do you expect?
If the algorithm work, that the creativity of a score for that artwork has to go down,
because if you create an Renaissance artwork in 19th century, you are not creative.
In the same time, you take an artwork from 19th century or 20th century and move it back to
1400 or 1500, you expect its creative score to be going very up, because it would have been very
different from what happened in the time and very early influence to what happened much later.
So you expect its creativity score to go up. And that's what we did. So what we did is basically
many experiments where we take only 10 artworks, change their time stamp randomly, either moving
them backward to 1600 from modern schools or moving forward to 1900 for Renaissance and Baroque.
Or basically as a baseline, just move them around 1600 randomly. We basically find that
that's interesting, but if you move forward, Renaissance and Baroque artwork to 19th century,
you can see consistent drop of creativity by 8 to 10 percent. So it's consistent when we
review these experiments. If you move modern artwork from 19th and 20th century back to 1600,
you can see that the creativity score increased, however, with varying degrees depending on the
art movement. And that makes a lot of sense. For example, if you're looking at exhibitionism or
cubism or post-embrations, you can find a huge increase in creativity if you move them back
to 1600, compared to a new class system. A new class system basically is a reinvention of
Renaissance in 19th century. So if you move it back to 1600, you have only a 5 percent increase
compared to 16 percent increase for post-embrations. So that's how we tell us basically the algorithm
is really doing something making sense in terms of quantifying creativity and giving a score that
really captured the novelty and influence that we're looking for. When I showed these
results to my art historian collaborator, Maria Mazzoni at the College of Charleston,
she was interested in the result and gave me this book, basically, a show of artistry,
which I quoted from in the beginning by George Kubler, who's an art historian. And in this book,
basically, Kubler had a theory about how art history evolved. So basically, he's saying that
artists copy ideas from each other all the time. That's what happened all the time,
within a style. Until, basically, some artist come and makes some artwork that is really different
for some reason. And that what he called primary objects really give birth to a new style.
And if other artists start to take a note of that and start replicating this new style,
that becomes a new style. So basically, he focused on this concept of prime objects,
which are iconic artwork, and really come as, as opposed to that really
drive style moving forward, within a style. And I even find very interesting quotes
in his book that say, basically, prime objects here. Prime objects resemble prime numbers
of mathematics, because no conclusive rules is known to govern the appearance of either.
Although such a rule might may some be found. So basically, this is a very amazing analogy.
You make the energy between these prime objects in art history and prime numbers.
They are prime numbers cannot be divided by a number before them, but they divide many
numbers that comes after them. And that energy is really give me something, give me thinking about
the algorithm that describe the graph in France algorithm.
If we can start with this graph, and the nodes are numbers, and the arrows are divisibility,
the algorithm basically will highlight will give you high score to two
prime numbers by definition by by construction, you find that that will give high score to
prime numbers. So really, he's very, very correct in this analogy that the prime object
is actually very similar to the concept of brand number. And what you're actually doing in this
network by giving creative score, we are identifying what are the prime objects in art history,
things like moon, the screen or the castles, ladies and gentlemen. So when art history and tell us
that this artwork is major or basically the population think of the screen or moneys,
his tag as really a masterpiece, these totally not subjective. There is some unconscious
reasons for that. And these can be quantified by these kind of networks. And they are really
a changing moment in history where something totally different happened and artists start
taking notice. So because of the time, I just want to go very fast towards the next topic,
which I'll try to finish in two minutes, which is basically, how can we actually use AI to
generate art? And if the machine generate images, would that be considered art or not?
These are very big topic. And I know that other speakers in this series will talk about that
in detail. Aaron is going to be speaking already in this series.
But basically, our work from three years ago called Creative Adversarial Network
can, which basically we try to make a variant of GAN that was new at that time
to really generate a novel art. We call it generating art by deviating from style known,
by learning about style and being from style known. These are some of the art that we,
this network is generating. So basically, here's the story. Obviously, the audience here
know deep learning and know GANs and know how they work. I don't have to go through that. And
for example, GANs have been very successful in generating these images of bedrooms and other
assets. Very interesting things like that. So one question would be, what happens if you train GANs
on art images? Suppose you give it art history images and you train GANs on that, would you
generate art? And actually, there was some trials in the early days of GANs where people
trained on both ways and still lives and things like that. However, this fundamental problem,
the generator in GAN is trained to generate samples that pulls the discriminator to believe
they're coming from the same distribution as the inputs. So that's basically, we can think
about Chinese room problem here. Imagine the generator have access to actual images and can
sheet. So you can take actual images of art and just generate it right away and give it to the
discriminator. So actually, this way can be fooled right away that thinking and generating
these art works. However, this is basically the Chinese room problem. So there is no motivation
for the generator actually to generate anything that's creative. The generator is just trying to
change something from the same distribution. The only creativity it can do is just to change
something that was not generated before from the solution. But basically, if we give it
artworks of board trays, it will generate some different board tray, but still a board tray
that's very similar to what it sees. There's no force that Bush GAN to be created. How can
you change that? There's some background here that I have to go very fast over coming from the
field of aesthetic evolution in psychology. Basically, these three in one slide say that
artists keep making the same kind of art all the time. Like if artists in Renaissance keep
doing the same kind of Renaissance all the time, because of habituation, we get bored of that as
the viewer get bored of that. And that becomes not exciting for the artist, not exciting for the
critic, not exciting for the viewer anymore. So artist has to innovate all the time to go to
Bush against habituation. However, if artists innovate too much, if artists imagine because
I did that in Renaissance time, or even when he did that in 20th century, that's too shocking,
that people will not like that. And people actually didn't like that, until now they didn't like that.
Because basically according to what's called one curve in psychology, too much arousal
relates to negative hedonics. Basically, people start to unlike what they see. So in one sense,
artists have to push against habituation in what's called basically least efforts. So artists
really have to really push the envelope with a minimum amount to push against habituation
without pulling into the negative part of that curve. So that's basically the concept that we
try to push. How can we push the network to be innovative, but keep it within the distribution,
push the boundaries, basically. So the way we did it is basically, in particular, we're trying to
go out of style by including style ambiguity. So the network here is again, we still have the
real false, real fake loss, which is in that case, art or not art, because we're training on art.
Then the network has a style classification, the discriminator also learn about style and try to
classify styles, we give it style labels. And we added style ambiguity, ambiguity loss,
which basically mean that the discriminator trying to see if the art as a generator fits within styles
or ambiguous in terms of satisfying style. And we're trying to basically maximize style ambiguity
and at the same time, minimizing the typical loss in real fake formulation. So basically,
this is the loss and we have art or not art, we have style classification loss and we have this
style ambiguity, which I think is very essential, because this style ambiguity
pushes against art, not art. Art, not art loss, typical gun loss, will try to push things into
the distribution. And style ambiguity will try to push things away from distribution, but
keeping that will put it back. So the dilemma between this almost objective, really push the
machine to try to explore the boundary. And that's why we started getting this very interesting
artwork that have very nice composition. Here we train the machine on art history from the last
500 years of art history, old subject matter, old style, we didn't do any curation. The goal is if
the machine see all that art, what will we generate? Will generate similar artworks or something novel.
And the interesting thing, most of the things I'm machine generate actually abstract artwork,
didn't give us much board trace or landscape, mainly abstract. And that was very interesting
question. If we remove the style loss, the style ambiguity loss, these what kind of things you
can get, which are basically things that looks like mainly repetition of art history. The machine
again is just basically trying to generate things that looks like the distribution.
Adding style ambiguity to the different results. Trying to, you can see it keep the
aesthetic, it learned the aesthetics, trying to keep it to be in the distribution of what's
appealing, but trying to come up with new compositions, new combination of colors, new
interesting things. And we did a lot of experiments, there's much time to go over them in details,
but here is the conclusion. When we show these two human subjects combined with artwork from
Art Basel 2016, which is a flagship art fair in contemporary artist and also combined with
another set of abstract exhibitions, famous artworks as a baseline. And to our surprise,
basically human subject thought art done by Cannes, the machine basically has done by human 75%
of the time compared to 85% of the time for the case of abstract exhibition. And
only 48% of the time for art from the Art Basel collection. This doesn't take anything
about creativity of the art. It's basically a touring test to tell whether a human can tell
what art is made by human or by a GAN. And at that time, basically most art that is done by GAN
has this uncanny look that right away you can tell it's a GAN. It's the format for trades,
the format so you can tell it's a machine, but for Cannes what we cannot tell difference.
It's give these high scores and moreover they give it,
described by words like intentional, has a compositional rules, has communication
inspirational, give it high score in all these aspects the same as art made by human.
One last thing is why it works, why style ambiguity work. And that connects to what I
talked about earlier. It is not by the data, some people are not able to argue because maybe you
have less abstract art work in your collection, that's why it's generating abstract. And it is not
because all the schools here are, we combine them into bins to make them uniform.
So according to our loss, if these are the solution and these are the styles,
those are a plenty of room in between to create something that belongs to art and doesn't belong
to styles, right? The machine tried to find out these spaces. However, if you look at this figure
from before, that's renaissance, baroque, impressionism, realism and things like that.
You can see that there's no relation art history. Everything has been moving smoothly. And if you
want to move forward, obviously this two-dimension block here, but the space is much bigger,
if we move forward, you cannot really create something just between renaissance and baroque.
You have really a budget trajectory forward, not insert something in between. And that's
exactly why it works. And that's why it tends to generate more abstract than more uncanny
repetition of the past, because it's figured out basically in the 19th century, things are moving
in that direction and there are more space to make creating abstract artworks and studio artworks
without having to go and creating board trees and battlefield and landscapes that the screen
can tell right away its renaissance and baroque. So that's at least my understanding of this board.
Anyway, I'll have to stop here because I went over time. I'm very sorry about that. The conclusion
is we just sketched the surface. These are not to be discovered in art history by looking at
art at a macro level using science and AI, and also they are to be discovered by trying to boost
the AI to be created. Thank you very much. Thank you very much, Professor Elgamal. It was very
interesting discussion and analysis over history of art. I really appreciate that.
I think that if anyone has any question, otherwise,
excellent. I think it was very interesting. I liked hearing about all of the art history
and then relating it to the computer science aspects. Thank you. I hope this was on the
board. It was very interesting, especially trying to quantify creativity was interesting and kind
of related to the previous talk as well. I also find it very important that there is a separation
between science and humanities. What we are doing in computer vision and if you talk about
being creative and doing machine creativity and you are disconnected from what's happening in
art history or rural art history, we are making a big mistake. As I said, for example, the concept
of style transfer in vision and machine learning, totally nonsense when it comes to artists and
it comes to art history, and we still keep doing that. We find like hundreds and hundreds of people
come every day about every year about style transfer, we should keep doing the same thing.
It was totally nonsense to me because that's not style and that's not what interests artists
and what interests art history. This disconnect is really not good.
Thank you so much for sharing your interest with us. I think that this is very intriguing for anyone
in the class who wants to, including myself, who wants to explore more in this direction.
So I appreciate your time and your talk. Thank you so much.
Okay, I think that we can stop you now. Thank you. Okay, have a good time.
You too. Thank you very much.
