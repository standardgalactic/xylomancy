Hello, everyone. Welcome back to your course, Learning for Arts, Aesthetics, and Creativity.
Our specialist speaker, Tom White, is here today to tell us about his exploration in art and
creativity in AI. He is an artist who actually creates art with computers and AI, and I should
let him to tell us more about his background, but he has done very interesting and fascinating work,
and I think that he also has some new galleries about what he has created his journey for arts.
So please, Tom, let us know what you are up to, what you are doing.
Sure. Thank you, Ali. I really appreciate you letting me participate. I often turn down talking
invitations, but I am an MIT alum. I really appreciate your research, and so I appreciate
your invitation, but I also really like IEP. When I look back at MIT, that was the IEP courses that
I took were really great, so I can tell your students that you might not remember everything
you are doing at MIT, but I am pretty sure you are going to remember some of your great IEP courses.
So my background is fairly eclectic, as you might imagine. I was undergraduate in math,
and I went to the media lab about 20 years ago at MIT, and I was part of a group that was doing
sort of incorporating graphic design into programming, and this was sort of exploring
that space, and so I will talk a little bit about some of the precedents that we did there,
but I was coming into that sort of looking at ways that people could think more about
coding as a creative discipline. There is a lot of tools now that didn't exist, and there is even
the idea of creative coding, and a lot of that came out of the work that we did in our group.
After leaving MIT, I sort of went off into industry for many years. I was always interested in
AI and art and the sort of intersection of those, but it was kind of the AI winner, and it was,
you know, I got out of school and went into industry, but when deep learning started getting
exciting, you know, maybe about five to ten years ago, that's when I re-vectored back into this space,
and so I found, I set up an academic academia, and I have a wearable hat, so I have my own
research students here, and I'll speak a little bit if I talk about some of the research we do,
so there's like Rebecca was saying, there's a lot of number of practical tools you can build
that will help other people use the medium creatively, and I do some of that research,
but as you alluded to on the side, I also have my own separate arts practice, and most of my talk
is going to be about that, and hopefully that'll be a good, I think everyone's art practice is
different, but I think seeing that might be hopefully inspirational for some students that
are wondering like what that's about, or how they might one day get into something like that.
Yeah, definitely, that would be actually very great. I think that maybe, yeah, I think you and
also the work that Rebecca details give us some taste about what it really means from our
practitioners as well as the computer scientists, so please go ahead.
Okay, I will try to share my slides and we'll get started. Okay, so I will briefly just reintroduce
myself for the video, so my name is Tom White, you can find me online on my handleTribNet,
and there's my website, trip.net, and as I said, I'm an artist and lecturer at Victoria University
of Wellington School of Design, and in my work here, I teach classes on creative coding, so I
teach primarily in the context of an art and design school to students that are interested in,
it might be that they're interested in special effects or that they're interested in
web design, but they want to sort of incorporate programming into their tool set because there's
a lot of capabilities and things that have a lot, so in the past where someone might learn
charcoal drawing or certain specific techniques, more and more today students want to learn
programming, so I teach programming, but not from a computer science angle, I'm a kind of creative
coding angle. I also have research which I do with my graduate students, and I'll touch upon
that briefly in the talk as well, where we make creative tools using some of these technologies,
and in that context, I also have a workshop at the NeurIPS conference, creativity and design that
I do with other co-hosts, where we post a lot of this research, and what my talk today is about
is about a lot of my artwork, and specifically the artwork that I've been doing the last
three to five years, and I'm going to sort of go through and give you a background of myself
and then talk about that a little bit. Let's see if I can get my first slide. There we go, so
this is the outline of the talk. I'm going to give basically a three-minute version of the talk,
the TLDR, like what's the point of this talk, so you can sort of understand it all at once,
what this is. Then I'm going to back up and give you a little bit more background about where I'm
coming from, my background in MIT since then. I'm going to spend a little bit of time talking
about the precedence in art, so when you're doing artwork, similarly, you know, if you're writing a
research paper, you have your references at the end, and that contextualizes and talks about how
you're building on things in the past. I think it's important in art, I think a lot of times it's
implicit to hear, I'm going to make it a little bit more explicit about what my precedents are and
what I find inspirational, and what I'm trying to, what I'm using as reference points. Then I'm
going to get into the meat of the talk. The meat of the talk is really, or the core of my talk here
is about AI representation and abstraction, and specifically my investigations into kind of exploring
what these neural net vision systems, what the representations are, and how to convey that.
In an artistic context. I will talk a little bit about other AI art approaches, including
other peers that I have that are in this space, and I'll touch a little bit on my research there,
and then I'll close out by talking about the sort of like some of the implications of the artwork.
So what happens when we're using these systems more and more as our kind of auxiliary eyes?
So that's the outline of the talk. This is the core of it, so this is the summary that my ideas
of artwork is that machines have their own way of seeing. So they see things, they're very
they're very accurate in classifiers, but I think they also importantly have slightly different
ways of seeing the world, and so what I'm trying to do in my artwork is trying to
expose that to a wider audience and trying to investigate how it is that these machines
see the world and how it might be the same or different as us. So as a sort of a corollary
that, because they see things differently, I believe we can create art that's kind of
for and by machines. In other words, you could use the machine perception to create different
types of art, which actually the machines themselves have some opinions about. So I'll
talk a little bit more about what that means. And so the summary there is that through art we can
actually appreciate ways the machines can perceive the world. So similar to how you might encounter
a new culture that you hadn't before, and you might explore the art of that culture,
I'm trying to explore the art that's created when we introduce machine perception into the process.
So the one line version of that is I'm interested in how machines read images,
so that's kind of the point of what I'm doing. Here's three prints that I've done,
the one on the left is an eye and that was created from a data set of eyes and I'll talk a
little bit about that later. The one all the way on the right is it's actually a face and that was
made not so much for a classifier but for a facial recognition system. The first step in facial
recognition is a detector and so that was made to look like a face to a face detection system.
And the one in the center here, which I'll make a little bit bigger, is a screen print of two
chickens and so this is all of these are based on pure images and I'll get as you can imagine
more into the details of how this happens as I go through the paper or go through the talk.
But this is based on a data set of many actual images of chickens, the system created this
output. And we can actually turn it around and we can show this to the system again and look
at its imagination of what it visualizes and we get kind of this so it can actually
introduce diagnostics into the process and say well what is it that the computer sees
when they look at this print and that gives us some kind of indication of the the richer
inner world these neural networks. So that is my I guess you know three-minute version of the
whole talk and now we're going to sort of back up and go through that in a little bit more detail
and I'll start off talking a little bit more about myself. So this is me and my studio currently
where I do my printing and I'm here in Wellington, New Zealand. I'm going to go back and talk about
not everything I've done but maybe some of the precedents along the way for getting to
sort of this this stage of my art making. 25 years ago at SIGGRAPH I did in sort of using
machine learning techniques of the time artificial evolution to make these real-time
video filters that processed video and then showed that on a screen and you could also
manipulate the evolution process to create different filters. In 1998 I finished my master's
thesis at MIT and so like I said I was in a group at MIT, John Midas Aesthetics and Computation
Group. I was there with many kind of inspired people that were coming in from both design and
computer programming software engineering and I was interested at the time on better human
computer human interfaces so I built a custom hand interface because I was interested in
multi-touch. So multi-touch wasn't really a big idea in the 90s so I had to there wasn't any interfaces
that did that so I built a camera optics-based interface so it's this liquid pad and when you
pushed on it you would get this handprint that you see in the bottom right and then on top of that
I built various interfaces for example sliding left to right to move to move something or
there's various different ways you could interact based on having more than a mouse so I think this
is common sort of ideas now but this was something that we did in the Media Lab and I did for my thesis
but maybe one of the one of the one of the other things at this time as I did another art project
which is still pretty well known which is called Stream of Consciousness which
in which I incorporated this hand pad which could measure sort of pressure across the whole pad
into this interactive exhibit where words were flowing through a stream and it was called Stream
of Consciousness. One sort of interesting footnote about this is that as the words were going through
you could push on a word and it would spring out related words so if you were looking at the word
you know university and you pushed on it it might say faculty or school or academia or something like
that and we used wordnet at the time that was part of the programming idea to kind of find out
interesting related words first anonyms and synonyms and kind of its synth set that it uses
which is the basis for ImageNet which is a lot of the artwork I do today so this is kind of a
again using AI techniques at the time incorporating it in these these interactive exhibitions
but one of the one of the interesting legacies and I think another bit that feeds into my
my current practice is that one of the interesting legacies of this group is that we made a lot of
interesting sort of core software that enabled a lot of people to do different things so there was
a handful of researchers and I and Ben Fry and Jared Chiffman were students in the group
and were responsible for creating and maintaining this core library called ACU and the library was so
that basically we could conduct our experiments and and it was constructed such that it was easy
to do kind of a sketch a software sketch and the reason I bring this up is that this software
was the basis for other systems that have come since so Ben who worked on this and Casey later
adapted some of these ideas and made a version of this called Processing which is actually quite
popular still as a creative toolkit and then later another group of students took actually the
the code for this and made a new toolkit called Open Frameworks which uses a lot of a lot of some
of the code in this ends up in Open Frameworks and then they of course built upon it and built a
community around it but many of the conventions and cliches of this programming style kind of live
on today and this is it's it's interesting as it alludes to my current work because what we were
doing at the time we were just trying to figure out how to make it easy for people to create
sketches or drawings on the computer and I feel that that's a lot of what I'm doing
currently it's just my audience is no longer other people it's actually machine learning processes
and then I did other things and worked at an industry but for the purpose of this talk we'll
just you know chalk that off to the AI winner and I'll come back to that in a little bit so there's
after I graduated from school I did some other things I'm going to also open the chat over here
in case other people had feedback that I can secretly see okay so now I'm going to talk about
precedence in art and and some of the background looking at it from a slightly different angle
of what it is I'm trying to do I'm going to go all the way back to 1927 and there's an artist
called Stuart Davis that I admired his technique and what he was doing or what he did for kind of
his central a core inspiration for his work is that there was one year that he did the egg
beater series and the egg beater series was his attempt to look at the world in a new way
and the way he did that his technique for that was he took some common everyday objects he took
an electric fan a rubber glove and an egg beater and he and he nailed those to a tabletop and
basically forced himself to paint those things over and over and over until he thought he was
doing something different and new his in his own words what he said his intent was in doing this
was to strip a subject down to the real physical source of its stimulus so here's one of his
egg beater works where he's you know taking these common objects and trying to find something new
in them and I think that that's some of the that that alludes to sort of some of the work
that I'm doing and I'll sort of touch on that in a little bit another precedent for me was Harold
Cohen who for many years experimented with generative drawing systems and is arguably the first
kind of AI artist he came at this from a different angle he was a very successful visual artist and
painter and he decided in the early 70s that he wanted to go into programming into an artificial
intelligence to see if he could codify some of his ideas on on mark making in a in a formal way
so here's an example of one of his programs and he initially set out to build an autonomous program
and he called the program Aaron and Aaron would kind of encompass all the ideas he had about how
to generate visual works so I visited Harold a couple of times and this is me visiting him and
when he's working on some of his later works and I think it's also interesting to discuss like
even though he had these ideas that the the artworks were being creative autonomously initially
later in life he was working more as a collaborator with these systems so he was sort of working a
little bit or finding ways where it was more of a co-creation process but across all of his all of his
his different phases his core question across this and this is what I kind of share his inspiration
is what is what his question was what is an image and the way he didn't mean that like
technically what is an image but he meant like what is the minimum condition under which a set
of marks on a page functions as an image or conveys meaningful information
this is a sketch he had from one of his papers and and I would kind of rephrase this in a machine
learning context is saying what is it that what is it that images could do kind of central to
representation and extraction like what makes simplification work how is it that simple drawings
can be evocative and seem to stand for something else so I think that this is kind of a core
a core concern of heralds that that I also share and then one last kind of precedent and art
that I think is important for me is just talking a little bit about pop artists this is a not so much
as a from the the content side but from the form side this is actually I share some techniques
with many of the pop artists like Andy Warhol Roy Lichtenstein and and how I actually keep my artwork
so for anyone that's not familiar with screen printing if I'm making this chicken image over
here on the right that's actually printed but it's printed from two layers of ink and so these
are essentially stencils that I have to mix inks for and then put onto the page so what I'm showing
on the left are the masks that generate the stencils to give you the image on the right
so the stencils themselves get burned transferred onto screens these are physical
kind of stencil there it's like a stencil except it can have holes on it there's a mesh there
and then you just sort of pour ink across the across this this screen and you smash some ink
through it and that's the kind of physical process of of making these these prints here's a little
slideshow I have where I'm starting off with a blank canvas it's actually a blank we base-coded
a color onto it we put a screen down I put some ink on top of it I spread the ink out that's called
the flood then you smash the ink through and you get a layer and then the more colors you want the
more layers you have to do that so for the second color you have to do another screen and another
layer for the third color it's another screen that's me pushing the ink through that layer
and then there's a fourth color there put the ink on the screen spread it out and push it through
they're just kind of emphasizing that there's a kind of a specific technique I'm using that has
you know precedent for getting these are acrylic on canvas works or acrylic on paper
but it's instead of a brush technique it's a screen printing technique
and here's the result of some of that so this is kind of just showing you what
happens at the end is that I have these prints and the prints end up kind of you know in an
exhibition or in in some type of art context so that's kind of the art precedence I think it's
useful kind of now to talk about more what this artwork is and what it is I'm trying to say with
this with my art pieces so I'm going to get into the sort of the main section here which is the
AI representation and abstraction like how is it I actually create these these works and what
is it that they stand for so just going back to revisiting Stuart Davis so in my mind Stuart Davis
spent a year basically learning how to perceive and represent familiar objects a new way so he
imagined going in every day and staring at these same three or four objects a rubber glove and
electric fan until finally you're seeing them in ways you hadn't before and then you're trying to
put that on the page and my kind of core question is is can we similarly use computer vision to
introduce new ways of perceiving or representing familiar objects so instead of going in kind of
going to this meditative trance can we kind of look at things through the eyes of the computer
vision systems and see if that causes us to see familiar things in new ways
so appropriately enough one of my first experiments in this was an electric fan
so this is an electric fan training set so this is the input into the system where you have
computer vision systems as you probably know you know need hundreds thousands of images so I
believe in the ImageNet electric fan data there is you know over a thousand images of an electric
fan and this is just quickly paging through some of those and then what I did with that is I made
a system that optimized perceptually for creating something that looked like an electric fan to
multiple trained neural networks and so here I'm showing the print that I made
of an electric fan it was created using a similar technique done in layers
and this is on the on the right side these are in the middle I guess is the graph showing
what the opinions of this print are when shown to different networks like Inception or ResNet or
VGG and they all are very confident that they're looking at electric fans so this
this is using techniques also from like adversarial examples so that's some
um that these are computer search security techniques where you try to essentially fool
a computer into thinking it's seeing something but in my instance I don't I'm not tricking it
I'm actually just trying to make a super stimulus or stimulus that is most evocative of that category
that it knows and so this is an example of me trying to see how these computer AI algorithms
receive these common objects here's an example of the the drawing system sort of in progress as
you can imagine it's an optimization it starts off kind of putting lines on the page where it thinks
they're most needed and then it's it kind of anneals or optimizes over that and makes the
image look more and more like the the target class that it's it's trying to make and in one way that
I contextualize this and or I talk about this in my writing is that for me it kind of inverts the
computer as a tool stereotype so for for many many years we've seen the computer as kind of a way
to execute someone's vision so use it down and use Photoshop and you have an idea and you kind of do
it you know use the tool to express your idea what I'm trying to do here is I'm kind of inverting
that and I've made it a tool that the computer vision systems themselves can use to create their
own visual outputs so so the I'm sort of making the tool for the perception systems
so after I finished some of those I did a series of of 10 of these and I'm going to talk a little
bit about them to talk about how they're made but also what machine learning concepts are kind of
bubbling through so this is this is a print called binoculars again using this sort of same
two-layer technique this is the data set on the right and then this is the print on the left
one interesting thing I thought about the way this print turned out is that it's viewing
the binoculars in three-quarter view which is kind of an interesting angle because you can see all
of the features pretty easily from from kind of not instead of a straight on view as much of the
data is this is a shark specifically a hammerhead shark which is one of the categories of the image
net and here it's done a very few number of strokes to kind of try to represent that the essence of
the shark outlines in fact we can kind of count the strokes I believe it's about 14 or so so this
is a little animation which is showing the the strokes one by one just so you can see the number
of primitives so from a you know from a programming point of view you might think
if this is the number of parameters in the space but this is also kind of defining the complexity
of the image that that it's able to produce after the shark I did a different one which is iron
again kind of an interesting view it took it to this kind of perpendicular view which is where
you might get the most characteristic view of the iron the iron used is the same number of strokes
as the shark does so one fun thing we can do is we can actually start with the shark
and then we can move the strokes around so that they create the iron and I did this in software
and then at each step at the end steps I show this to the networks to see what they're thinking
what what they believe they're looking at and on one side here you can see the six networks are
very convinced they're looking at an iron and then we move the strokes around and they're
so they're looking at a hammerhead shark I did this a couple years ago as a demo there's a lot
of debate in the deep learning community how these models work and there's a there's a camp or
there's a group of people that actually were proposing that deep learning was mainly triggering
on textures and didn't have any global structure information so I think this is a pretty compelling
counter example that says well no these deep learning systems might preference structure or
texture or might use texture but they do seem to have some global structure information in their
vision systems just a couple more of these this is a cello or I should say this is the the the
labeled cello which as you can imagine has not only cellos but cellists and other things
in the photos that are the used for classification and it's interesting to try to not I don't have
any I don't have any special insight into the the the drawing that is produced by the system so I
don't know people ask me what is it representing and I don't know particularly but I can go into
the data and poke around and take my best guess so to me this cello image looks like this these
kind of characteristic photos in the data so you might call this a mode of the data or a or
about 25 of the data has this general shape where you have a cellist behind the cello
playing and I'll point out a couple of things that I think I see that resemble these training
examples and I'll point out one thing that's very different so you might try to figure out
in the 30 seconds that it needs me to get there whether you can find the thing that's different
in those but the things that are the same as I see this like light colored object kind of looming
behind this darker one I I see that maybe fingers curled around a fretboard which was kind of
surprising to me but the one thing that's very different about the image that it drew and all
the cellists that I saw on the data set is all the cellists in the data set are right-handed
and all these that I just kind of pulled out randomly are but improbably the cellist it decided
to draw was left-handed and that's relevant because you know I'm interested in how these computer
vision systems see and they're actually because of the way they're trained they're blind to left
right symmetries so because of image augmentation to buffer the data sets they they cannot see or
they're not aware of any features that are that are not that are that are dependent on left
right symmetries and so it chose to kind of invert this one and draw a left-handed cellist
which I thought was was interesting and then there's a there's two more so this is one that's
measuring cup not too surprising here seeing the other ones where it's it's drawn a measuring cup
that you might see in your kitchen the thing that I haven't sort of so in addition to choosing the
shapes for these drawings it's also choosing the colors and I thought it was really strange that it
chose this bright green color because I've never seen a green measuring cup so again I dove into
the data and I found that the the data set actually had a a large number of examples where there were
green measuring cups and I dug into this a little bit more and it turns out that there's this
collectible measuring cup called depression glass measuring cups this was made around world war one
and for whatever reason people were putting uranium in the in the glass and these were collectible
and so there's a lot of these post donal onward people are trading them
because they're collectible and this is an example of sampling bias so arguably this
measuring cup is not very commonly green but because of the way this data is kind of farmed
off of the web there's a lot of green ones that end up in the training set so to this
computer vision system it's actually quite likely that there would be a green measuring cup so this
is again kind of showing how the machine learning techniques are bubbling through it in the in the
results and then the last one I'll show here is is tick so tick is one of my least popular at least
by sales prints that I've done no one wants to put a tick uh in their in their home I guess on the
wall but this one I'm pointing out because in in addition to uh sort of the the um the print
itself it actually had a really strong response across many networks and so I decided to to quantify
that and the gold standard on this is to take the validation set of the data set itself and so I took
the uh the validation set for ImageNet and I took a network that wasn't involved in the creation of
this uh it was InceptionResNet and I scored all of the uh validation examples and and they
they fell into two classes basically things that weren't ticks and things that weren't ticks
but the the short of it is is that this image of a tick registers stronger than all of the
validation examples which is fairly surprising like the tick response here is kind of like I said
a super stimulus or a stronger example of a tick to these networks than even pictures of the tick
from the validation set but this has precedent in uh art and design as well Scott McLeod in his
series in his book Understanding Comics talks about amplification through simplification and how
if you're trying to represent say a man then you're maybe not well served by using a particular
photo of a particular man because that's that doesn't well fit the concept it's too specific
to um to one particular person and actually by abstracting and removing some details you can
come up with a drawing or sketch that better represents a man or a person or you know different
levels of abstraction in the in concepts and so uh arguably I think that might be what we're seeing
here where we're taking a real tick and we're removing some of the uh some of the some features
that and leaving the most salient ones this is also just as a footnote kind of how symbolic
abstraction and writing started so Sumerian writing sort of start if you owe someone three oxes you
write you know a picture of three oxes in your play tablet and over time that evolves into kind
of symbolic abstractions so that was my my series Perception Engines which is Tim Prince I'm going
to talk briefly about some other series that I've done since then there's one that I did
after that called synthetic abstractions I've covered it here because uh as a as a warning
this is technically not safe for work imagery so if you are uncomfortable looking at images that
at least vision systems say are explicit imagery I encourage you to pause your video or look away
now so here we go these are these are these are abstract prints that I made specifically looking
at not so much systems for image depth but these systems that impact us all online so you know we
have google safe search and we have these other systems that try to shield us from certain images
and I'm wondering like well are there uh abstract versions of what it is that that that seems to
trigger these filters so as an example of one of these I made this print mustard dream it's on
mustard colored paper and it's just black and white ink and when you show a print this a picture
of this print to three division systems like google safe search it'll register as as adult or
racy similarly amazon thinks it's explicit nudity and yeah who thinks it's not safe for work so here
I am exhibiting that print I did a series of these there was another one pitch stream another one
composition with red blue and yellow that's kind of an an art joke here because it's a riff on a well
known uh other work uh except my arrangement of inks uh triggers these these algorithms uh these
these filter algorithms I have done some similar canvas baked works more recently in this vein so
these are two newer ones where I'm actually trying to you know I don't know what it is
in the other one so people ask me well what is it the computer sees and I don't know like I said I
don't have any kind of knowledge and maybe I wouldn't want to know I'd like that we don't have
interpretable ml where we can ask the system what it sees here I'm actually trying to steer the
data set a little bit more by influencing it with uh with uh influence the result by a data set
and so this is for example one of those I actually called this one illustrated nude
which I'll uh talk a little bit later about why I changed the title of it but that's because you
know when you show this to amazon that's what it classifies it at it says uh you know it thinks
it's looking at an illustrated nude and it's fairly high confidence and similarly google
safe search again thinks it's a racy or adult image so if you are searching for this uh you
insert safe search you wouldn't see it and if you uh got an email it might go in your spam folder
for example okay so I'm going to talk uh I'm just going to go a few more examples just to kind of
get a a gist of of probably so after that I made sure my systems were working kind of in the large
with these online api so this is a data set for killer whale a painting of the killer whale and
then the responses from google's online vision api so you can see it thinks it's a killer whale or
marine mammal part of the interest here is also what the ontology or the labels for the the these
different systems are uh similarly here's a penguin so we're looking at the data set on the left
thousands of images of penguins the uh version of a penguin that ended up being printed and then
you can see the the google api sees this as a penguin or a flightless bird or even particular
types of penguins like emperor penguin uh as I mentioned before there's the ability to do
custom data sets and so as a commission uh collaboration I did with yacht for their album artwork
I did a series of custom data sets this is one from from that series where we had a data set of
eyes and we trained the system to make a synthetic eye and as you can see when google looks at this
it thinks it's seeing a face or a nose or eyebrow or eyelash there's sort of uh eye features coming
through in the labels uh and then and this is another one I did similarly where it's uh pictures
of rabbits so um it's this one is a very kind of simple rendition of a rabbit and again it's kind
of funny what the google labels for this end up being evidently they have separate labels for hair
rabbit rabbit and hairs and domestic rabbit and it kind of triggers all of those different labels
in its api response more recently and this is kind of getting up to what I've been doing the last
year I've been exhibiting these in groups I found that instead of showing one example it actually is
more um enlightening to see many of these at once because you can kind of get a feel for what the
visual language or the common elements are so these are six chickens and six eyes which I exhibited
about this time last year at sipar gallery um this is something I did subsequently where I took
that kind of even a step further and there's kind of this room full of images the computer thinks are
knots and so we have um different shape and color combinations uh all all being different images that
the computer thinks um are reminding it of and I think knots is kind of an interesting one because
it's kind of this amorphous shape but there seems to be some commonality visually to what what
the computer thinks is a knot and then this is one I have this in progress maybe I'll give you
about 10 seconds to think about what these might be but these are actually this looks like it might be
computer images but these are actually photos of canvases which I take where I'm starting to organize
these into groups and these are all the canvases that are just getting completed and this is for
an upcoming exhibition on ants and so all of these are shapes that will will trigger in computer
vision systems to different extents in thinking that it's looking at at an ant so that's kind of
a summary of my work I'm going to spend the remainder of my talk talking about other approaches
and a little bit about and a little bit about my research and then I'll just briefly talk about how
my my artwork impacts the real world uh or effects it has once it gets out into the world
so as a lot of the other speakers have mentioned is uh these generative techniques and I think
these are very relevant uh and they're used on other AIR approaches but there's also this idea
that uh other AIR approaches had different narratives so I want to talk a little bit about that
so my interest so when I came into uh when I started getting interested in modern deep learning
actually got into generative networks as well and for a while I was doing a lot of important
research on this or research that I enjoyed digging into how these things worked in 2015 and 2016
this is an artwork I did in 2016 it was just large like two meter by one meter print here's a zoom in
showing um this and this was images of faces so at the time these were really high quality
um uh neural net outputs for faces you know before we had style again and these other
more modern networks um and I was interested in kind of the space of faces that could be created
and I uh and I wrote a paper talking about some of these techniques and how you could sample
these networks uh to get some of the best the best outputs from those I also since subsequent to
that have continued looking at these generative networks in more of a research sense so in my
research capacity at the university I work I work for example in this system with my graduate student
as Rebecca alluded to it's there's a interesting kind of getting these out to tools to other
creators and so one of the ideas I have with this graduate student was to make a spreadsheet tool
where instead of numbers in a spreadsheet you actually had samples from a generative model
and could you do use this as a way of giving people sort of their own create creativity tool
through the interface of a spreadsheet so it's looking at at some of these generative models
but in the context of this art talk it's it's I mainly just wanted to say this is a tool other
people are using so Helena Saran is using these Mario Klingeman Helena's using these in a way that
again Rebecca alluded to where she's using these small data sets and essentially overfitting those
data sets and changing the data set to get the result that she's looking for uh Mario Klingeman
in this project neural glitch uh was training one of these and then he intentionally kind of
damages the network and then displays how that damage comes through visually uh in his artwork
so it's the idea that there's a sort of an intentional glitch in there there's two other
artists that that I'll mention that that one is Robbie Barrett who did this project a few years
ago called RDC GAN where he looked at using these these generative networks to specifically
create portraits and there's another well-known at least in AR art precedent which is obviously
Edmond de Bellamy that's well known mainly because it went up for auction for a very high amount of
money at Sotheby's a couple of years ago these actually I'm putting up mainly because they
used very very similar techniques in fact they share some code and techniques across them but
they have very different narratives behind them and so I wanted to kind of point out uh and the
narrative here is I mean like what the story is behind how these are made so when Robbie is is
and when I'm you know showing my work it's very much talking about using these things as a tool or
as a collaboration but there is a strong push or there's a lot of people in the AR community that
more say that no it's the the computer is autonomous and it's making these artworks and that was the
kind of stance that obvious took and it's one that resonates with people I think taken to an
extreme what you get is you get a lot of people making work with robots so it's it's common for
people to make these robot artists and here's just one example of that but these have a long history so
there's actually a long history of making these drawing automatons and here's one you know that's
200 years old where it's basically uh being driven by gears and so I just mentioned this is that I
see this as a slippery slope and so I said kind of stay away from this and intentionally don't
use any at least for now kind of drawing a automaton because I want to contextualize what I'm
doing as a as a collaboration between what I'm doing so going back kind of again to to Harold
Cohen and his work and most of the AI artists in the space this is a what I'm what I'm doing is not
so much me handing over full autonomy and saying the computer is the artist but coming up with a
co-creation process where the there's a role for me and there's a role for these systems that I'm
making okay and in the last five minutes here I'm going to spend uh I'm going to talk a little bit
about what happens when we put these things out in the wild and how how these are some of my artwork
how it's kind of uh how we can understand it so of course there's we can ask the machine what it
sees we can use visualization techniques but the the one I'm highlighting most here is these
unintended consequences like what what surprises has happened and keep in mind that for from the
eyes of the computer perception per system this is Magritte's trajectory of images where he was
kind of pointing out like a picture of a pipe is not a pipe but that distinction often is lost with
these perception systems like if they see something a representation of something they more or less
think it's that thing so the first way you could tell uh or interpret or think about my artwork
is you can ask the system what it sees so if I take this picture I took of me with my artwork
six chickens and I feed it to the amazon api it will come back and so very diligently that it found
a chicken and a chicken and a bird and etc and there's a person over on the side and I think
that's one way to kind of understand how these systems are viewing or understanding these artworks
so the computer the systems themselves there was another way that I talked about in the beginning
where you can actually use visualization techniques so this is using some research from open ai where
they have visualization techniques similar to deep dream where they take I can take one of my prints
and feed it to one of these systems and ask it to kind of imagine how it relates so here's the
print two chickens here's kind of the the inner imagination or visualization of what the computer
sees when it sees that and you can even take that a little bit further and try to visualize that in
3d so this is a little slideshow where it attempts to add some fake depth to that to that image so
that it can kind of understand understand it but I think what's most interesting is how these things
kind of accidentally kind of bump into real-world systems so I'm going to talk about a couple of
those to close out so this is an exhibition I talked about in 2018 I had these prints that were
supposed to trigger various safe search filters and this is an exhibition on the left I have this
not so great photo of it with a lot of glare and stuff and I actually took a picture of this and
was going to post it to tumblr and it didn't allow me to post it to tumblr the actual post
failed and it said this post contains adult content which violates our community guidelines
I was flagged as adult content and it was not displayed so I think that's one example of it
kind of bumping up against these real-world systems similarly I had another work in that series
architectural digest wanted to put a print in one of their magazines I showed them some prints and
they wanted the most colorful one which was a lime dream again maybe not the most appropriate
because it's supposed to be explicit imagery but they decided to go with it anyway and so when I
got a copy of the magazine I took a great picture of the magazine and fit into the amazon api and
it was still commenced it was looking at explicit nudity so I think this might be the first example
of a cybernetic centerfold like a basically a photo of a nude made for these kind of vision
systems that has appeared in a magazine similarly like the art gets sold in weird ways and so
I had a print at a gallery and they sold off without my knowledge one of these prints to
Sloan Kettering wins so if you go to their academic offices in New York you can actually see one of
these prints again I don't know that I would that it might be the most appropriate for this
environment and in fact that's one of the reasons I alluded to earlier I gave these initially kind
of these vague names but now I've called them illustrated nudes explicitly because I want if
someone buys or sees one of these I want them to know what it's supposed to represent and so the
only way for me to package that is to put it in the title where it can't be missed. I did a print
a couple years ago that I took to Newreps I was stretching it in my hotel room and hanging it up
and when I went to take a picture of it I was very happy this is my camera interface when this
little yellow rectangle appeared so I think if anyone has a phone they know this is when
your camera is trying to focus on a face and so just the fact that this was a shape intended to
trigger a face in machine learning algorithms it's kind of pulled the focus onto onto this because
it thought there was a face in the scene and then the last one of these is just getting ready for
this talk so as you can imagine getting ready for this talk I'm trying to find images of my artwork
and I'm pulling them on my phone and lo and behold when I pull up my phone
down at the bottom it says we have several people in places in categories of things and here's the
categories of things that I've kind of partitioned for you that you might be interested in like your
animals and your food so of course these aren't real animals of food if I search for banana it
thinks it's you know I've done a print a banana and when I'm working on the print I take a lot of
pictures of it so these have gotten classified as bananas or scorpions this is a sombrero
a print I was working on but it's funny too because it kind of mixes the real this is a picture
of mine a friend in a funny hat and it ends up putting that in the picture with the artwork again
like I'm saying the computer doesn't have a concept of what a lot of times is a representation of
something versus what is the real thing so if I do a search for syringe not only do I get this weird
photo that I took and I don't remember why of a real syringe but and probably I get this like
really wacky hypercolor syringe print that I was working on a few years ago so I think it's
interesting how these kind of get collapsed in the in these vision systems is being kind of the same
thing so that's it uh those those just to recap the core ideas of my artwork is that the machines
have their own way of seeing we can create art for and buy machines which is what I'm trying to do
is trying to use the the capabilities of machines and understand art through their eyes and that and
through art we and by we I mean like people knowledgeable about deep learning but also
people who might not have any background in machine learning can appreciate the ways that that machines
perceive the world so thanks that's my online handle for twitter and my web page
um I'm open for taking questions and I will also say for questions that I'm I'm very open for
things that were part of the talk but also might have been things only loosely alluded to in the
talk if you had questions on um you know more about research tools or the community uh I think
something I'm happy to take any sort of a broad range of questions thank you
thank you so much Tom it was so great um so I was wondering if students have questions
uh this is from very early on in the talk but I'm wondering why you chose screen printing as your
medium of choice
great question sorry I had to take a sip of water there so um yeah so there's I wanted to
actually make physical work and I thought that was you know it's actually easier for me to make
work that is on the computer but it takes a kind of a step further to create something that's
printed and that's also um so I think there's two parts of the question why make physical work at
all and then if you're making physical work why have it be screen printed so I think that that
two reasons for making physical work one is I think that people relate to physical work
differently and when they go into a gallery and art setting so for years I did these interactive
installations with screens and things and I think that people come into those a little bit
the defensive because sort of it's technology right away like you go in and you see the screen
and you see um you know these camera looking at your something and I think it sets a tone for
for how this is for what's to be expected so I really wanted to do a physical a physical print
that sort of was more more about the
was more about how the computer sees it than about the sure putting the process in the gallery
but the purpose for doing the screen print is I wanted something that was very
exact so I could I actually have done some prints I there weren't part of the
start where I've experimented with other techniques brush techniques and so it's not really critical
to use screen printing but screen printing allows me to with some level of very precision like
make a traditional artwork so and it has precedent kind of in the art world through
through these pop artists so I felt it was kind of a good a good middle ground for kind of executing
these I could of course print them out on a printer or something else but I think that
um I wanted to kind of constrain my way you might think in the same ways that artists in
the past it could strain themselves so it makes it more easy to compare my works with existing
artists if I'm kind of operating with the same constraints or under the same interface you might
think of it one thing I'll say too about making physical work is it makes it much more difficult
to pull off these techniques uh these kind of adversarial techniques because I don't know what
the lighting or the angle of the photo is so I try I have to make these these results work for
a distribution of of possible photos that might be taken so if that's a part of you know if you
look at adversarial images research there's kind of doing it on the computer and there's doing it
in the physical world and it's always kind of more difficult challenge to take these to the
physical world but that's kind of where I was interested in taking this
cool thank you so much
excellent are there are there other questions
I think that this is very interesting how thinking in art and you know having this
dual view of computers and arts can inspire such an interesting work for instance we see that
you know as you said one of the applications of this could be really adversarial attack and
you know cyber security which it's really hard to think about it if you only want to think about
security and exclude this type of artistic practices I never thought about it in this way
like how art can help for better understanding of for instance data bias or algorithmic bias
or other aspects of AI so I thought that was very interesting
I think so yeah that actually came through in my in my original generative work so when I was
working with generative networks I found that they were actually really good at visualizing bias so
if you go back in my paper I talk a little bit about how the celeb a data set has a label for
smiling but in that data set and I talk about ways that you can build
dialers where you can turn up the smiling and down the smiling by using the labels on the
data set but there's bias in the data set where women are much more likely than men to be smiling
just as a product of how the data was collected like twice almost twice as likely it's like
1.5 or something like that and so as you build these tools that are that are intended or as you
look at as you tell the network that you want to make an image smile more you're actually also
changing some of the masculine feminine characteristics of the of the image and I
thought it was a very visceral way to kind of see some of the machine learning bias
so that can come through in these generative networks but yeah I think it also comes through
in the visualization of these and I'm kind of careful not to to couch my work too much in
adversarial examples because I think that I certainly use some of their techniques but
where I depart from them is that is they're always trying to do something imperceptible
or something that is uh well it's adversarial like in the name they're trying to trick the
system whereas I'm more using it as a as a visualization or kind of getting under the
hood and kind of understanding what the stimuluses are that that might trigger the these in the first
place yeah also it is very interesting how you know doing by minimal strokes you could
achieve these things and this is another way of thinking of compression for instance which was
as you said inspired from art you know that's that's a really good point yeah and I think that
so there's there's a very practical reason to do that too is because I'm not using any really
advanced techniques for generating these I'm basically doing like random search or genetic
it's basically doing a search over the space of outputs and it it just moves you know it does a
search estimating the gradient and so the fewer parameters you have the easier job you're going
to have sort of hill climbing in that aspect so it benefits me to have a simple representation for
this and there's other things about my drawing style when I talk about making a draw system for
for these like I can't have too many discontinuities and things like that and the drawing styles that
I have but but yeah I think it's also very interesting to come up with these kind of
tight like for the shark you know it's 12 strokes to kind of represent a shape that when
when shown to the system still seems to be a strong stimulus for that category yeah that also
reminds me of the work that scientists did in computer vision for instance the work of
Antonio Trollbaugh where the question is how many pixels do you need the minimum
number of pixels to show to a computer for instance and in terms of images to see
what is this object or get a gist of this object you know for instance the experiment
that set up only 32 pixels and they found that you know you can get a gist of what is going on in
this instance image with this computer vision techniques so that is also very interesting
yeah it's also similar to I don't remember the researchers that did the psychology research
where they take face images and they put them in very low like they basically make icons where
they're you know like eight by eight pixels or 16 by 16 pixels and you could still represent
you could still recognize Abraham Lincoln or these famous figures in these very low resolution
resolution formats so I think people also have this ability to decipher these very these very
low information images as well yeah very interesting excellent thank you so much Tom
it was great and really inspiring work and I appreciate that
thanks so much for having me and if anyone else has any questions I'm happy to you know
if you send me an email and follow up from the class I know not everyone likes asking questions
it's got I'm happy to follow up on you know you know every artist is a little bit different and so
there's no common there's no common template I think you can follow but hopefully this will be
a good uh this is one good example of a path that someone else might be interested in taking
certainly and then also Tom has been involved with the workshop of machine learning for
art and creativity at New Reeps for several years so that's also an interesting and valuable
a contribution that he is making so if any question yeah yeah exactly so I do know a lot
of that research and can direct you to those and I would encourage you if you are interested in
this space you can I believe still access a lot of the videos for example from this past year's
workshop just to get an overview of going a little bit deeper into some of these talks
excellent thank you so much time thank you thank you have a good night thanks everybody
