Thanks for watching and let me show you the math behind Google, at least the way it used to work
back in the 90s. Because when I was younger and we had other search websites like Yahoo or Excite,
it was quite a nightmare. Because if you were trying to look for a website about apples,
the one that would get the most hits was one where it just said apples, apples, apples, apples,
apples, apples, which was not very useful. But then came Google and life was much easier,
because they use what's called the PageRank model, which looks as follows. Because suppose you have
four websites which are connected as follows, so from three you can go to one, from one you can go
to two, three, and four. Then the way Google works is that it assigns what's called an importance
vector. Let's call it V. And suppose V is, for instance, 0.2, 0.1, 0.4, and 0.3. Then what that
means is that the highest number is better. So website three is more important than website four,
which is more important than website one, which is more important than website two. So three would
get suggested first, and then four, and then one, and two. Now how do we determine that importance
vector? Well, it's just a little bit of linear algebra and probability.
Because what we need is some initial vector, so assume all four websites are treated equally.
So assume our initial vector is just 0.25, 0.25, 0.25, and 0.25,
and some way of transitioning from the initial vector to the next step. And for this, we need
something called a transition matrix. And in order to find a transition matrix, we need some
probabilities. And you'll see why. In particular, think of it as follows. Suppose you start with
website one, what are the chances of going to website two? Well, there are three possibilities,
two, four, or three. And so in particular, from one to two, there's a third chance of
landing to website two. So one third, one third, one third. And well, then we can just complete
the other arrows as follows. It's a nice exercise to show that the other probabilities are as follows.
And this allows us to calculate our transition matrix. And the way you read the transition
matrix is from top to left. And so this is website one, two, three, four, one, two, three, four.
And you have to ask yourselves, well, to go from website one back to website one,
where there's no self-linkage here. So the probability is zero. To go from two to one,
again, two does not connect to one. The probability is zero. To go from three to one,
well, there's just one connection here. So the probability is one. And let's say to go from
four to one, the probability is one half. And well, then you can do the same spiel with websites
two, three, and four. And you end up getting the following matrix. Ta-da! Magic, isn't it?
Now, what are we trying to answer, by the way? We want to figure out in the end which website is
the most important one. And in order to simplify, we just want to ask ourselves, what happens if
we let this run infinitely many times? So what happens after infinitely many clicks? And well,
in order to do this, we first need to figure out what happens after one click. Well, if you think
about this, in order to go from the initial vector to what happens next, you just have to apply A
once. So V1 is Av0. And well, to figure out what happens after two clicks, so to figure out V2,
that's just what happens when you apply A to the first step. So Av1. But remember, V1 itself is
transitioned. So it's just A, Av0. And that becomes A squared V0. How cool is that? Using A squared,
you can directly go from nothing to the second step. It's like a teleportation. And in particular,
to go directly from the initial step to the end step, you just have to calculate A to the end.
So A to the end V0. And of course, nothing prevents us from plugging in infinity here. So in particular,
the answer to our question, V infinity, it's A infinity times V0. And so really, all we just
need to answer is the question, what is A infinity? And this is where linear algebra can help us.
And so the next step is to use some linear algebra where we diagonalize A. So it turns out A is PDP
inverse. And if you do the calculation or use Wolfram Alpha, you get D is a diagonal matrix
with one entry is one. And that one's super important. The other one are very small. So I don't
know. Let's call them epsilon, delta, and I don't know why not xi. And for P, we have the following.
So again, only the first eigenvector matters. You'll see why. And I think we get two,
two-thirds, three-halves. And I believe one. And the rest we don't really care.
And why is this important? Because this decomposition allows us to calculate any power of A quite easily.
Because, for instance, A squared, that is AA, which is PDP inverse, PDP inverse,
and the P inverse and P cancels out. And you get PD squared P inverse. So A squared is PD squared
P inverse. And in general, A to the N is PD to the N P inverse. But as we'll see soon,
D to the N is very easy to calculate, which allows us to calculate A to the N in a much easier way.
And nothing prevents us from letting N go to infinity. So in fact, the stuff that we want,
V infinity, it's A infinity V naught, which just becomes PD infinity P naught, or P inverse,
of V naught. 0.25, 0.25, 0.25, 0.25. But what is D to the infinity? Remember,
those eigenvalues are very small. So if you raise them to infinity, you get 0. So in the end,
we get 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0. So this huge mess that seems very hard to calculate
actually becomes quite easy. And if you actually do the calculation, which I'll skip because there's
a nicer way very soon, you get the following. So in the end, we get V infinities, this vector.
And finally, we get the answer to our question. After infinitely many clicks, which website
is the most important one? Well, website one, followed by website three, followed by website
two. And what is Google? Well, it's the same model, but with many websites. Think like billions
of websites. It's the same idea. Finally, I do want to tell you something cool because there is a
slightly faster way of doing this because it turns out, as you may have noticed, we didn't even have
to calculate the other eigenvectors. All that really mattered is the eigenvalue one.
And in fact, there's a theorem that says what is V infinity is just the eigenvector corresponding
to one, which is two, two-thirds, three-halves, and one, but not quite because, well, this is not
a probability vector. Well, but it is this but divided by the sum of the terms. So two plus
two-thirds plus three-halves plus one. And so in the end, you do get this vector, 0.38,
0.12, 0.29, 0.90. How cool is that? All right. I hope you like this. And if you want to see more math,
please make sure to subscribe to my channel. Thank you very much.
