I don't hear as much about, like, end of the world as I do.
What is the application in the school system?
And then how is my child learning?
When you first heard the notion of existential risk,
that, like, within our lifetimes,
there could be a world where there is no life on Earth.
We are expected lifetimes, I guess.
How did that hit you?
What was your first thought?
I think I believed.
I mean, I'd sound so crazy.
I feel like I've found a little crazy to say, like,
I needed to do my research.
Like, I needed to know who was staying there.
Were those people credible?
And where it's been really interesting,
the camps, right, being the advanceers versus the juniors
or their new camp.
And each camp has their expert that
went to this Ivy League institution
and worked at this, you know, this big tech firm
or used to work at the big tech firm.
Like, every, both sides of the camp
have their, you know, qualified experts.
Like, human extinction, like, you know,
society has been trying to, like, eliminate me my entire life.
Nothing will be able to, like, overpower us
because of what we've been able to endure
and what we've been able to survive.
So for me, I'm like, OK, come at me, AI.
Like, you know what I mean?
It's just like, like, come at me.
You're throwing down those.
You're throwing down the bell.
Like, like, like, come at me, tech bros.
Like, I got you.
Like, there's no way that you can, like, completely, like,
you know, erase me because, like, I've been through so much.
I think it means a little brand.
I think the term AI, so to speak, was boring.
I don't think anybody deflated about it.
I don't think they know what it means.
It sounds like a stinking moment.
Like, what?
Like, AI facing snoozer.
I think the scary part for me was that the people that created it
were warning us and said, I, we don't know how to control it
at this point.
And so when you have a creator that doesn't understand it,
it doesn't understand what it's doing.
That's very scary.
I was stunned to know that the people who make AI have no idea
why it does, what it does, or how to control it.
What did you think when you all first heard that?
Listen.
Welcome to For Humanity, an AI Safety Podcast, Episode 7,
Mom's Talk AI Extinction Risk.
I'm John Sherman, your host.
Thank you so much for joining me.
This is the AI Safety Podcast for the general public.
No tech background required.
As you know, this show is exclusively about the threat of extinction
from artificial intelligence.
Please like, subscribe, and tell a friend about this show.
And if you are on X and want to hear more about these issues
on a daily basis, please follow at For Humanity Pod.
Okay.
So the whole point of this podcast has been to move this debate
from the Silicon Valley boardroom to the family dinner table.
I also, as a parent, have been wondering how anyone who works
in AI could do this to their children.
And that if maybe awakening the parental maternal instincts
that are so foreign to this AI safety debate could be possible
and maybe even powerful.
So I thought, what a better way to do that than to just do that.
So I asked three moms to come on the show and discuss AI
as an immediate threat to their children.
I want to give a big thanks to Stephanie, Jen, and Crystal,
our three moms.
I asked them all to watch the first episode of this podcast
before we met.
I think this is a fascinating conversation,
and I am thrilled to share it with you.
All right.
Moms, I think we made it.
We made it for the Gauntlet Riverside Zooms
and getting on a video conference.
So nice to see you all.
Nice to see you.
Awesome.
So let's just take it from the top here a little bit, I guess.
So it's an interesting thing in your life when you start to talk
about these AI safety issues.
They resonate with certain people and not with other people.
And, you know, Stephanie has been a friend of mine for many years
and just, you know, it was an issue that sort of resonated with her
and we got to talking about it.
And one of the things we're talking about is, like,
where is the parental attitude in this?
Where is the maternal, you know, attitude in this?
And so I've been trying to sort of take this debate as much as I can
from tech people to regular people.
So why not just do it and take it right to the most regular people
of all the moms, right?
I will say as a father, as a son, you know, husband,
all these things that moms make the world go round.
And so I salute to all the moms everywhere.
I thought we could just start off right at the top.
Maybe let's just go around the horn, say who you are.
Tell me a little bit about your kids and maybe what you do outside of kids
and we'll just quick shoot around the horn and then come back up to the top.
Stephanie, why don't you start us off?
Sure.
I'm Stephanie Brando.
I am a mom of 30 kiddos.
My oldest is 13.
My middle is 10 and my youngest is 8.
So kind of early, but definitely that 13-year-old has opinions.
Two of my kids are neurodivergent and that is much a part of our lives.
I'm really open about talking about it with anybody who will listen
just around their gifts and the place that they need support.
And what I do and I'm not being a mom is I do recruiting.
So I do sales for a recruiting company.
I've been doing stocking and recruiting for almost 20 years.
And I'm really excited for this conversation and excited to share the podcast,
hopefully with my kids.
So watch your language.
Thank you.
Thank you, Stephanie.
I did make a promise to our group here that I would clean up my act for the show in an effort.
Maybe we can show it to the kids afterwards.
So that would be great.
Jen, please introduce yourself.
Yes.
Hello, everyone.
My name is Jen White-Johnson.
I do identify as someone who is neurodivergent.
I do have ADHD and also anxiety and also an autoimmune disorder.
So I, you know, live along the intersections of, you know, being black and having a disability.
And my son is also autistic and my husband is also neurodivergent.
So, you know, we are, we are very neurodivergent affirming family.
And, you know, it intersects with my teaching.
And I also, I teach graphic design within these past few years since my son was diagnosed.
I do a lot of disability advocacy work, you know, specifically under the, you know, under,
you know, the influence of art and where that can kind of be used as a tool to really uplift
the conversation of disability justice.
So thank you for having me.
Awesome.
Awesome.
Thrilled to have you.
And Crystal, please introduce yourself.
Hi, everyone.
My name is Crystal Putman Garcia.
So I am also a mom of three, like Stephanie.
I have twins that are nine and then I have in almost seven year old.
So six right now.
So they're a little bit on the younger side.
But I do have a neurodivergent son who is obsessed with technology.
He could hack into our like Amazon accounts when he was like five.
I think it's one of his gifts.
And so, you know, definitely try to balance like when is it, when is it okay to give your
kids technology because we live in a world with technology.
And so we want kids that are comfortable with it.
But where do you draw the line?
And I'm not just a mom.
I also, I work for a tech company.
So I work for a policy and global intelligence company in half or several years.
And I also in the past have worked to make sure that there's an intersection between
consumers and internet privacy.
And so this is an area that's particularly of interest to me.
One of the reasons why I thought this group would be really great to get together is,
you know, you all put so much work into everything you're doing.
You are badasses, you know, professionally.
And you're also incredibly devoted to your kids as am I.
I'll just introduce myself as well for a second.
I'm John.
I do video production.
I do a podcast that you may be watching.
And I have two kids, Boy Girl Twins, who are 18 years old.
I can't believe it.
They are seniors in high school and getting ready to leave us.
And it's a whole lot to take.
But, you know, I certainly, as we think about these AI existential issues,
I certainly make kids are always at the top of my mind.
So why don't we go around the world one more time and let's talk about our experience thus far with AI.
You know, we're going to talk a lot about existential risk and in the podcast.
But, you know, before you became aware of this existential risk conversation,
what were your impressions and just sort of briefly what were your dealings with it?
I know, Jen and I don't know, Stephanie, either you all were,
have been doing some really interesting things with neurodivergence and kids and AI,
which, you know, has some promise in that space.
So, Jen, you want to start off and just talk maybe a little bit about what you've been doing with AI in this area?
Sure.
I mean, you know, just as a designer specifically using, you know, graphic design as like, you know,
my trade and my weapon of choice, it's always tech and, you know, the intersection of how we use it,
you know, to kind of emote joy has always been like a part of like my world.
And, you know, so I really use, you know, AI to, you know, just amplify good.
Crystal, in the marketing world, I'm in the marketing world.
I mean, you must get hit every day with 65 new things AI will do for you
that are fantastic that you need to learn yesterday.
Yes, absolutely.
And, you know, there's this worry that, you know, you're not going to need marketers anymore
because generative AI is going to get so good.
I still believe that humans are better.
It still needs oversight, right?
There's a lot of pros, but a lot of cons.
It's like the smartest, stupid thing, right, around.
Stephanie, how about you?
AI up until we had this conversation.
Yeah.
It's funny.
Back this time last year, I was sent a link by a consultant that we work with,
a tech consultant that we work with who also does some strategy with our, to chat to you.
And he said, I know you're working on your presentation for your big company retreat.
Check this out.
What I ended up doing with, I used it to create the outline, to create the agenda,
to help me come up with activities, like specific work activities.
And it was awesome.
And I was like, oh my gosh, this is great.
But I think it's different.
Like the, the permission we're in now with generative AI and the like,
we're used to get to general, what is it?
Generalized artificial intelligence.
Yeah.
Yeah.
Artificial general intelligence.
That to me is a different story.
And that's where I start to get nervous.
And that's where my kids start to call me a ladder player.
Well, I didn't expect you to do your hug.
They have.
They have.
They have.
And it's the access, right?
So you've used it.
It's been embedded in the things that you've been using,
but now they have direct access to it in a way that's different, right?
Yeah.
I mean, I think when we all actually got to use it, you know,
like it was one thing to hear about this thing, artificial intelligence.
And then chat GPT-4 came out and we all, some friend of us talked us into logging into it
and signing up and checking it out.
And you were like, Oh my God, this is fundamentally different from anything ever before.
So that will lead me into my next question.
And this can go to anyone.
When you first heard the notion of existential risk that like within our lifetimes,
there could be a world where there is no life on earth.
We are expected lifetimes, I guess.
How did that hit you?
What was your, what was your first thought?
I think I believe, I mean, I sound so crazy.
I feel like I found a little crazy that for like, I needed to do my research.
Like I needed to know who was saying this.
Were those people credible?
And where it's been really interesting.
I think of the camps, right?
The, the dancers, the, versus the jimmers or their new camp.
And each camp has their expert that went to this, I believe the institution and work at this, you know, this big tech firm,
or you used to work at the big tech firm.
Like every, both sides of the camp have their, you know, qualified experts.
So, you know, it's really like sitting through, I think, for me and going like, well, in my guts,
because we all, as a parent, as mom, we all have the guts in this thing, which says,
you don't know something doesn't do in life.
And then when you start to see the onion peel away, like with that mess with
When you start to go like, wait a minute, like what's it going on with?
No offense, like believe in their toy.
That's all about the green meat and all about the money.
And oh, it used to be a nonprofit.
But no, it's not.
Now we're focused on profit.
Well, wait a minute, like wasn't your origin of your company focused on the good of the Nermit?
So I guess I'm still a little bit.
I'm slow with like, I will always continue to just kind of try and pull from various sources to make sense.
And then frankly trust my gut to go.
I need to take this seriously though.
I didn't take the pandemic seriously when I first came out.
My husband and my boss were like canary in the coal mine.
We were like, this is going to be bad.
I'm like, I'm going to the conference, you know, like, don't go to the conference in March.
I was like, I'll be fine.
I was like, Joe, go and then the conference.
But this is like my canary moment, I think.
Yeah.
Yeah.
Excellent.
Crystal, Jen, what do you think human extinction?
I think extinction is a strong word and over what period of time.
So I think, you know, I think that's that's the hard part about that.
Well, there's two different things.
There's the scary part is I think going back to what Stephanie said, who is saying this and based on what information, I think the scary part for me was that the people that created it were warning us and said, I, we don't know how to control it at this point.
And so when you have a creator that doesn't understand it, it doesn't understand what it's doing.
That's very scary to me.
That's the first thing that worried me.
The second thing that worried me is you look at social media, etc.
And these things were created so that you cannot, like as humans, like you can't win against it.
Right.
Like, like you become addicted to it.
You can't help it.
And so I think those are the two things that concern me as you can see how social media spreads misinformation.
Right.
So if you think about it's something that the people that created it can't control.
And you have this, this, and then the people that created it are warning you about it.
And then you've seen just implications from not generative AI, but a tool like social media that does use it that's spreading misinformation.
You can see how the risks could be there.
So I'm not fully doom and gloom like the human race is going away.
But I think it's very concerning.
And if you don't have people stepping in to take a stronger role in managing against it, then it becomes scarier.
Yeah.
For sure.
Jen.
Yeah.
I mean, I still think that it takes us as humans to be able to, you know, make a lot of these tools do what we want them to do.
You know, I've, I've watched my friends, I've watched other artists, my husband, like use them to the fullest extent.
And still, there's still essences of the person, the human that exists within the creations.
And that's what I really love the most is like how could you kind of coexist in the world that essentially we've built sort of.
Yeah.
Yeah.
I like it.
Even in this group of four, we have, I think, four unique takes on, you know, almost the same set of information.
Right.
Which is, you know, and so just Stephanie, to your point, first of all, are, you know, are we Flat Earthers?
Are we, you know, like Y2K people wrapping our houses in duct tape?
The answer is no.
I wish we were, honestly, I wish we were.
I hope we are.
How about this?
I hope we are.
I hope that this podcast is literally a duct tape wrap around my house.
And I'll wake up on the, you know, January 1st morning and I'll be like, oh, AGI happened and we're all fine and everything's fine.
I just, that is not my read of the academics in the field.
And I saw something on Twitter that I'm going to send you the other day.
It's a list of 125 professors in like a string of like heads of departments who are basically, you know, saying this same thing that they have grave concerns.
For, you know, existential risk for all life on Earth.
If we continue to proceed with developing artificial intelligence systems that are not aligned with human goals and values and that we don't know how they work.
So let's go to those two things.
Alignment and interpretability.
I was stunned to know that the people who make AI have no idea why it does what it does or how to control it.
What did you think when you all first heard that?
Anyone who wants that one.
I mean, Crystal, I'll go with you because, you know, if someone came to you and said, hey, I want to get this new product for our department, you know, it has tremendous power.
It could make us the best company on Earth or kill everyone in the building.
I don't know how it works.
And I, you know.
That's that's the scary part that I had mentioned earlier is that the people that created it don't fully understand it.
And they don't know necessarily how to necessarily stop parts of it.
And I think that that's the most concerning part.
I think that goes back to, I believe, Jen's part, you have to have a human interaction and you have to create roles around the use of it or else it's going to go into the hands of bad players.
You can't say that everyone's going to use it for good things because that's just not true.
And so how are we as human beings, as companies, as governments, as moms, as human beings going to all work together to make sure it's being used for the right reasons?
Because we've all experienced the good in it.
We've also seen how it can fail, right?
You look at it, you're like, well, that's not right.
And so that's where I think the human mind currently is different is we can differentiate between those two things.
But I think there's a point where it's hard to do that.
And that's what concerns me.
Yeah.
Yeah, no, I agree.
Definitely, I think it's shocking, but not shocking that people would want to run fast towards advancement.
I mean, towards being the first, like being the first company, the first person, the first team, you know, it's interesting, right?
I almost wish we had someone that being described more of like in certain values.
I don't know, like, and maybe you guys do.
I don't, you know, but in listening, John had recommended Mo Galdet, who has a book called Scary Smart.
Yeah, this is the last book that finds out in 10 years.
And she, you know, he even says like kind of the western drive to make more money in there, just succeed by any measure and get to the top.
And it doesn't matter if you leave in your weight.
We want to say that that's not the case, but it's so very much the case.
And so I think as moms, too, it's hard to, like, to, to parent kids.
Well, it's, you know, when you've got the pressure of social media or of your friends, kids or of a man on what school and, you know, you're fighting that all already all the time.
And then you sort of blow that out, you know, in this world of AI and how else are their systems supposed to learn other than our inputs.
And if our inputs are all for, like, the basis parts of who we are as humans, then that's not great.
Like, that's only setting up the system to be based in the way that they pursue.
And so it really worries me.
You know, I also am aware that, like, we're cognizant, we've got so many people as humans.
I don't know that AI systems, or maybe they'll be able to do that.
I don't know.
I feel like that might be a human, like, win.
Like, hey, I can hold two very opposing ideas at the same time.
Like, I am a practicing Catholic.
And I also am really worried about existential crisis.
But I'm not worrying to a point where I can't get out of bed or where I can't go to work or I can't parent my kids.
So, because I think at the core, I have this thing that, like, is my belief and says, like, you can't, like, offer that up.
You can't worry about that.
So, I don't know if that makes sense in, like, the, I'm very concerned.
And also, I can't later, day in and day out from up place to do another theory this way.
Yeah, no, absolutely.
Elon Musk was asked about it recently.
And he said, you know, he has existential fears of AI and says it openly and says, in 2016, he spent a lot of sleepless nights worried about
what I'm worried about right now, but that he has come to peace with it because he's decided that there's no more interesting time to be alive as a human.
So, he will sacrifice the potential for extinction with the excitement of living the most exciting life of any human generation.
I don't know that I can quite get there, but I did find something in that, something in that that was a little helpful.
Here's the question I have for you all, and then I'll throw it to you, Jen.
Where are the women in this whole thing?
You know, a lot of people have seen my first podcast.
I appreciate that you all watched it.
And, you know, this is a very male dominated thing that is happening to the world.
Where are the women and what are your thoughts about it, Jen?
Well, I mean, there's a ton of women that are really advocating specifically from, you know, the black and brown perspective when it comes to
ethical and responsible AI.
Oveta Samson is a really amazing voice.
You know, Gerald Thomas, who are specifically working to address the conversation on representation.
Because, like, I feel like the conversation shifts when you're asking, you know, black and brown folks to say, OK, well, what will you do with AI?
What will you do with these tools?
And how will you make them radical?
And how will you, what will they look like when they're kind of placed in the hands of multi pre-marginalized people who have always been
denied access for these specific tools to create and build the worlds that they specifically want to see?
You know, the tools that they want to see, you know, that have been, you know, kind of denied.
And so I feel like making sure that we can kind of have space.
And I have, like, my LinkedIn open and, you know, being able to just, you know, like, OK, yeah, well, who's having these conversations?
And I really love that the language specifically has been evolved into incorporating responsibility, you know, equity, being able to.
And I love that, you know, black women who are invested in machine learning and, you know, gen AI are, like, are leading those conversations.
So, you know, like I said, like, it begins to shift when, you know, when the conversation is put in the hands of the multi pre-marginalized.
Sure. Sure. Thank you.
And I feel like there's a there's a maternal attitude missing to this whole thing.
Like it's like some 30 year old guys are like, hey, I got this car, it goes super fast.
I'm going to go race it at 300 miles on the highway.
And nobody's being like, you might hurt someone.
Don't, you know, you might want to think twice about that.
Have you thought about the other people?
Crystal, Stephanie, any thoughts about the male domination of this, this suicide cult?
So it's funny, John, because I, as you asked this last week, I saw her film in Danny Herrera.
She was like, it's an AI advocate.
She posted about the New York Times article.
So I think, you know, there is complexity in particularly in media that if you're not going to cover, if you're going to cover like the 12 game changers and leaders in AI,
you can't find a woman and she was like, lazy, and it's totally right.
Lazy reporting, lazy coverage.
I'm not calling you crazy, John, I promise.
But it's like, because you were like, I didn't have any in mind.
And I was like, she posted this and she had over 600 comments of people.
And out of those, like probably let's say, let's just say half would listing women leaders in AI.
And you know, it's really interesting.
Just a couple that she mentioned, Miki Lee, Rana El-Tolubi, Margaret Mitchell, Tim Gidbrook, Siren Snyder, Vanilla Braga, Joy Bulalini.
All these women, the stuff they're doing is around gender bias and around like ethics and around same food and around all the stuff.
And you're like, yeah.
So I think that was saying in like that recorded this conversation around how do we protect our, you know, I think there's, there's a real issue when it comes to coverage.
And people in the New York Times got flammed and as they said, right, you know, a little hot about them.
I swear words, but I got hot.
I think I do think there are a lot of women that are doing things.
I don't think they're getting the coverage to Stephanie's point earlier.
I also think there's an interesting part to it about geography.
And so you see women and men right in the EU, it's always more kind of risk averse when it comes to technology.
If you look at privacy, so I have a background in privacy.
The strongest privacy laws are in the EU.
And then in the US, it usually goes to California next and then it might go federal at that point.
I think you're seeing that in AI.
And so you're seeing, so I think you also have to look geographically in the US.
We are capitalistic.
We're going to go for whoever is going to make the most money quickly.
I think the EU has more of a familial kind of community sense than the US and then you're going to see that play out.
So I'm curious how the EU standards are going to impact the US and other parts of the world.
So I'm not sure.
I think there's a male versus female US coverage, but there's a really interesting work happening geographically as well.
Yeah, that's super interesting.
I absolutely believe there are women doing incredible things in AI.
I think they're not getting any coverage.
And I think that it's also just really hard for those sort of stories to break through because it's so male dominated at the top that it's a real problem.
And it's a problem in bias.
And it's a problem in what I want to talk about today, which is some 30 year old guys believing that they have been authorized to exercise existential risk on behalf of us.
Like they go to work today thinking that somehow it's reasonable and appropriate for them to toy with all of us dying.
And I just can't get over how that's possible for people to get up then and say, I'm going to come back tomorrow for another day of this.
Crystal, I want to get at one thing you talked about a little bit earlier because I feel like even in this group of four, we may have, you know, some differences of opinion.
I feel like Stephanie, I feel like you can picture human extinction a little bit like we've had some conversations.
And I feel like, you know, it's a what like think about your street, like your, your, your literal street.
What is your street look like the morning after all life on earth is eliminated.
It's, it is laughable, like it's, it's, it's so uncomfortable that, you know, it's really hard to contemplate.
I did not think it possible in my life that I would be contemplating these things.
And yet I find that I'm doing it on a daily basis.
So Crystal, I, I feel like, and Jen, I don't know where you are on it, but I feel like crystal.
Well, I'm, I'm a black woman in America.
So like, I feel like I'm at risk every single day, like walking in, in the street.
I mean, that's why like, I have like, you know, if we really want to get deep with it, like human extinction, like, you know, society has been trying to like eliminate me my entire life.
You know, so it's just, to me, it doesn't take tech, to me, it doesn't take technology to do that.
It doesn't take technology to do that.
It just takes, you know, being erased and having like my culture become erased and appropriated.
And, you know, if anything, you know, just eliminated from the conversation, which is why it's so important for us to kind of take up as much space as we can within the AI space,
within, you know, ethical conversations on responsibility and what that means within artificial intelligence.
Because, you know, I mean, at the core, like, you know, as, you know, black people have been, we are the oracles.
I mean, we have been guiding people through the path of, you know, of survival for centuries, like, you know, Harriet Tubman.
I mean, she was literally using astronomy and her own disability to just to guide people to make sure that they can actually survive.
Yeah, it's really super interesting to think about it like that, Jen, to think about different people perceiving it in different ways based on their own personal experience.
Yeah, so glad that you joined, that we have these perspectives, that we are not, you know what I mean?
I'm really glad that you brought that up, because I think, I think within, you know, wake up in fear, in fear for your study,
that's something that you get within your bones.
And it's probably been, you know, in your family and in your bones forever.
And, you know, it's a privilege that we don't have that.
And now we're thinking about it.
And I also, my next brain, you know, brain, knowing I have one brain, two nos.
Maybe I have some other weird brain, couldn't even play though.
But I'm wanting to know one day.
But my next thought though, like, and let's not reach the system that way.
Like, maybe we have the chance to make the, if we have generalized AI, we need there's a chance that it can actually be better than us as humans.
In that way, like, we have the chance right now to teach it.
Yeah.
So like they teach our kids, like Murgale Dev said, right?
Like if they're in their infancy or their toddler thing was right now, which they are.
And like, I don't need, like, all of the good people, which is a lot more than the bad people in this world.
All the billions of really good people who come from all kinds, like, how do we get, how do we get people that don't even have internet?
To be able to participate in chats with, you know, in a generative AI, so that it had that perspective.
You know, the, it's glad to have those inflicted can have the influence of 3,000 dudes and a couple of ladies.
San Francisco.
Yeah.
San Francisco, to your point about John Birkin, it needs like the input.
I, there's a, people in my neighborhood, friends of Mike Kim's friends, and they're starting to be like, oh, you want to talk AI?
But one of, one of the mums is a lot of mums.
And soon as they're, what, is she losing it?
And I do.
I, I used it to draft content for, like, an invite for a party.
Like, that sounds silly, but I was sitting at a basketball practice for my son and I was, I'm like, oh, I'm trying to do this.
There's one thing.
We did this two seconds, right?
So I could actually be mostly present during the basketball practice.
And I gave it a quick prompt and then I revised it twice a game of three.
And I thought it's very great.
I feel better now if I got it.
But I use it.
And for some people, it's like, well, you shouldn't use it if you're worried about the end of the potential trip with other.
You got it.
Right.
Absolutely.
And that's what I was talking.
Yes.
I firmly believe that, you know, 99% of the AI out there is totally safe and should be used.
And there's a lot of incredible benefits we could get from it.
Like a lot of the safety research experts say, we just paused for 20 years and just dealt with the tech we have now.
For 20 years, we could get incredible benefits for health and, you know, medical and scientific breakthroughs and all these kinds of things.
But we appear to be racing towards it much more quickly than that.
What do you all hear in your conversations with your friends, with other moms out there at the park, at the water cooler, whatever?
What is the tenor and tone of the conversation at this moment here in December of 2023?
The year AI came out and we all learned about it.
How do you feel like people are feeling?
I feel like when it comes up in my group of friends, it's less around human extinction.
It's more like how the kids are going to use it.
So like, are my kids going to properly learn how to write an essay or are they just going to feed the data into chat GBT?
And so where I hear it more, it's less around are humans going to go extinct?
It's more around how is my child going to be learning to use it or to not use it?
How am I going to make sure that my child has the right skills so that when they do go into the workforce, they're able to kind of do the job?
You're seeing schools now have kids take tests with a pen and paper again.
I'm seeing several universities doing that.
Who would have thought that because they want to make sure they can still write an essay?
So I think it's going to be interesting as parents and then the education system as well.
So how do you make sure your kids are learning?
So I don't hear as much about like end of the world as I do.
What is the application in the school system?
And then how is my child learning?
Exactly.
Yep.
Yep.
Yeah.
No, I hear a lot of that.
And I'm actually going to, I'm actually going to circle right back actually to what Jen was talking about just a second ago because I had something I want to talk about, which is, so I started this podcast seven weeks ago.
I was working on it for a couple months before that.
And it was right around, it was all coming together right around the October 7th attacks in Israel.
And kind of, kind of, you know, to what you're saying, Jen, it's like people feel directly threatened on a personal emotional level in different ways at all times.
And it's really hard for this very abstract issue of AI safety, something inside a computer system to emotionally resonate in the way these very personal, very direct threats do.
And I sort of don't know the way around that.
Like I don't know the way this really amorphous thing can compete with these other causes that are so visceral for people.
I don't know the answer.
I'm just putting it out there.
You know, and I don't know that there is a good answer.
Like, like, I think people that are focused on issues of immediate human suffering and human condition.
I can't come in and say, hey, everybody should drop what they're doing and go work on AI safety and forget about any semitism and racism and all the horrible things out, hate and all the horrible things on the planet.
Like people working on those causes have to continue.
But it's like we as a society have some sort of like limit for cause stuff.
And I feel like we're tapped out and AI is not going to get, you know, the attention that things that affect people more directly and personally immediately do.
Well, then I also think you have to look at the inputs, right, going into AI as well.
So you have deeply personal things to people, but people have very different views on things.
And you have all those disparate inputs going into generative AI.
And so then what comes out of that, I think is, is an interesting question.
I think AI can see and also say it, I think it means a new brand.
I think the term AI safety was boring.
I don't think anybody's got the lightest about it.
I don't think they know what it means.
Well, it sounds like a safety poll.
Like what?
Like AI safety is sooner or later.
Let me ask this.
I think I'm going to know the show of hands.
I think it's me and Stephanie and Crystal and Jen on two sides.
Could you actually imagine the end of all living things on earth?
Because of AI or in general?
Yes, because of AI, because of AI.
No, I can't.
I mean, can't know.
I mean, just because like, I know how to use it.
Like I, I, I know how to use it for like, I just, I'd like it.
I just know how to, how to be radical with it.
And I know the concern is when it starts using itself, right?
When it starts recursively improving itself, setting its own goals, becoming its own agent.
You know, it goes off on its own and it's no longer checking with us.
That, that to me is very conceivable, if not likely.
But how, but how, how is it going to do it though?
Like, like, and this is where we need to get very specific about the tools.
Like, okay, so what tools are we specifically talking about?
Like what AI?
Like mid-journey, for instance, like mid-journey cannot create products on its own.
Totally fine.
Not a problem.
And anything that's out there that consumers are using is not a problem at all.
It's the 1% of the frontier level work that, that open AI, Google, Microsoft,
DeepMind, Anthropic are doing that is pushing the frontier boundary of the systems
where it starts to recursively improve itself.
And, and the, nobody knows what happens after that point.
So the, yeah, Crystal.
I would say the two things that I think about, I have a hard time thinking humans become extinct.
That's like, I have a hard time there.
Where I have, where I can see is questioning, what does it mean to be human?
And Stephanie and I had a conversation around this because at some point, do we make,
do you make generative AI so smart or kind of robots or whatever that they become citizens, humans, etc.
And then you have this, then you have a kind of a question on, you know, who makes decisions, right?
Because if generative AI keeps getting smarter, then you can see over time humans kind of move into a different role within society.
So I can see, I can see some interesting things happening if you look into the future of AI becoming human or how we define human is one aspect.
But the thing I keep thinking that generative AI can do really well more quickly is cause absolute chaos.
Because you have disinformation lies and then you lose trust in society.
And once you lose trust in society, that's where a lot of bad things happen.
That's where war happens.
You have groups of people, again, you know, fighting different interpretations.
And so the world I see that's more plausible more quickly is just sheer chaos with disinformation because of generative AI.
And I don't disagree with any of that stuff.
But I just want to pick at it a little bit further, right?
So with Crystal and Jen.
So you guys watched the first episode of the podcast or you know that there's this 22 word statement that everybody in AI put out that says that artificial intelligence is an extinction risk along the lines of pandemic and nuclear war, right?
And so my question is if they're saying it, if other people, if the literal people are making it or saying it, why do you think you and the 99% of the public is like, yeah, but like they don't really mean it.
Like they said extinction, but they really meant something else.
And like, I just, I feel like, like I could be extinct without it, like who I am as a person, like, like I could be extinct without it.
You know, like, I, like, I was like my, like my people, my culture, you know, without techno, I mean, you know, literally, they were using, you know, colonialism and, you know, racism.
And, you know, they were using black and brown bodies as, you know, they were harvesting like enslaved people, you know, in terms of, so I feel like it's going to take more than technology, more than technology to like make us extinct as a people.
I still feel like, you know, black people, multi-multiply marginalized people, like, we will never, like, nothing will be able to like overpower us because of what we've been able to endure and what we've been able to survive.
So for me, I'm like, okay, come at me AI, like, you know, you know, it's just like, like, come at me.
Matt's throwing down the, she's throwing down the bell.
Like, like, like, come at me tech bros, like, I got you, like, there's no way that, that you can like, completely like, you know, erase me because like, I've been through so much more than technology can, you know.
Yeah.
That's kind of like where I'm at.
Yeah.
I think it's generally hard to think about existential problems, like, and it's really hard then to think about existential problems with your kids.
Like, as it relates to your kids, because, and I love your shirt, Jen, for frames in humans.
And it's like, maybe that could be like the meat, like, is it like a combo of raising good humans and just raising, I mean, again, is we haven't read no go back fuck scary smarts today to play football.
We have Mallory white pop bars and we should raise them like they raise our kids.
So we kind of show them what it means to be a good person.
Like, what do we mean we're a family person?
Right.
What do we mean when we're saying I think human and how all the, you know, the interactions you've had in real life, you know,
living with that face.
So sorry.
Do they really mean well, do they try and do better?
Like, if that's what I don't know, like, John, even in that faucet point to toss about, like, as humans, we can agree on what we've known as to be a good human.
And then, you know, so if we can agree as humans, what it means to be good, and how will we going to teach a toddler?
Maybe, though, maybe, though, if the systems are set, and there's intelligence, there's that to be generically, not to be generated.
Not to be generate, right?
I get what generically, then other way is like, let's just break it down.
Like, if it is supposed to, like, it's needed to create and not be destructive, then what?
Like, let's have more people do that.
Well, I don't mind a real general good.
Some things that just went into that I'm like, you know, just more, more, more inputs on more, more people.
Yeah.
That aren't this one to kind of that.
Well, in some ways, it's like, don't stop using AI.
Like, let's get generous, like, let's get that generically.
Let's get more people using it in a good way.
I'm a little bit more bullish.
Like, Jen, I believe that you have 250 people that have signed this who own a lot of the companies that are working on this.
So the people that are saying it's a risk also have the power to put guardrails and to service leaders and I urge you.
And I also believe that so if they say that's a problem and we want to do something about it, that's a good thing.
You've got, you know, you're always going to have the regulation come in, governments tend to be slower.
But I do believe you've got people that can stop it.
It's in a toddler stage.
As women, as moms, it's all of our responsibility to make sure we have diversity of thought in all the products that we're building in our marketing that we're doing,
making sure that we're hiring the right people for the roles.
And so we're not powerless if we all are raising good humans and we're being good humans and we're making sure we're getting the right voices at the table.
And I believe that we can, we're not going to stop it, but I think we can use it for generative and not degenerative purposes.
You're always going to have the nefarious folks trying to do things.
But I do believe that these tech companies know what they're doing and because they're funding.
And if they can actually start to say, why don't we get a group together?
So I'm bullish.
I can see where it can go in dangerous places, but I have to believe that humans can be better, smarter to solve this.
Okay.
So what do you think?
I've watched a ton of AI safety podcasts, but I have never seen one quite like that before.
Real quick, I think Stephanie is right that AI safety is the wrong term.
It's boring and it's soft.
Let's talk about alternative terms to AI safety in the comments.
And honestly, I was surprised and maybe even a bit disappointed that all three moms did not fully buy my case even after having heard it that human extinction from AI is the most urgent threat we face.
I did not fully make the sale.
That was a little hard to take, but it's okay.
This takes time.
Quickly, my own mother, who I love dearly and I think is an incredibly smart woman, watched the first three episodes of this podcast and was still telling me she didn't really fully get it.
But then after episode four, she told me it started to make sense.
So that's how this is going to go.
We, the ambassadors of this message, let us not be discouraged when someone is not immediately convinced of what you're saying.
The idea of no life on earth at all is something that is very difficult to process for all of us, myself included.
But if we are to have a chance, if our children are to have a chance, we must go through the process.
We must try to save ourselves.
Thank you so much for watching.
Next week, we're going to start pointing fingers and naming names.
I'm ready to blame some people for all this.
Our next episode will be called The Top Three Dumers in AI, and here's a hint.
They are not AI safety researchers at all.
For Humanity, I'm John Sherman.
I'll see you back here next week.
The Top Three Dumers in AI
