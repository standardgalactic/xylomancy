OO is better than functional. Or is it the other way around? Maybe the next big thing
will be better than both of them. This is one of those arguments that exercises developers,
and they tend to fall into one camp or the other. Either you think that functional programming
is the only sane answer, or OO is the defining approach for complex systems. So what are
the differences and do they matter? What advantages does language paradigm have to offer?
And have we found all of the paradigms that there are to find?
Hi, I'm Dave Farley of Continuous Delivery. Welcome to my channel. If you haven't already,
please do hit subscribe. And if you enjoyed the video, hit like as well. I'd like to begin by
thanking my sponsors, Harness, Equal Experts, Octopus, and Speckflow. They're all helping us
to grow this channel. So please do check out their links in the description below.
Whatever programming and paradigm or technology you pick, a deployment pipeline will improve your
workflow. Check out my new Continuous Delivery Pipelines book on LeanPub, which will help you
to get started building and to build better deployment pipelines. Links in the description again.
In this episode, I want to explore programming paradigms. There's an argument made by Bob
Martin that we've identified all of the paradigms that there are to find. I think that he might be
wrong, but we'll cover that later on. I do, though, like his analysis of language, the
language paradigms that we currently have. He argues that a programming paradigm works by
removing a freedom of some kind. It constrains us in some way, limiting our options, in ways that
tend to help us to reduce or even avoid some kinds of mistakes. I quite like that description.
A good place to start is how these paradigms arose in the first place. The first languages
were unstructured, kind of paradigm-free. They were general-purpose languages, but this first
generation were pretty unconstrained. They were really like high-level assembler languages in
some sense. You could do anything. The usual way to describe the history of programming languages
is as some kind of linear progression. We started with unstructured languages, invented structure,
and then OO came along, and finally, functional, is the new kid on the block. This is rubbish and
completely wrong. In reality, it was quite a lot messier than that. Grace Hopper wrote the first
compiler of any kind in the early 1950s. Fortran was the first high-level language written in 1957,
which is quickly followed by Lisp in 1958. So languages began with an unstructured language,
Fortran, but then the second language invented was functional, kind of.
Fortran was intentionally mathematical. Fortran was named for formula translator. It was unstructured,
but was built on some core concepts that are common in programming today. Concepts like variable
assignment, conditionals, and loops. COBOL was the next big language written in 1959. It was trying
to make programming language more like natural language and so easier to learn, which I think
that most people these days would consider a mistake for a general purpose language. Lisp was
written for researching artificial intelligence at the time. We'll come back to the functional
paradigm that Lisp gave birth to shortly. So people built most systems in Fortran or COBOL
for a while. Lisp was a bit of an outlier even then, but systems were getting bigger and more
complex. So the lack of constraints meant that there were lots of balls of mud being produced.
Dijkstra came along in 1968. He wanted systems to be mathematically provable. So he said go-to
statements are considered harmful and gave birth to structured programming in 68. Structured
programming works by constraining the flow of transfer of control. You can't just jump to any
point in a program as you could in COBOL or Fortran or Assembler. You are forced to jump to fixed
points that are defined. Jump to points in the language if you like that we these days call
functions or methods. This allows us to be a bit more cautious at these points. We're forced to
assemble arguments and we can check them for validity if we want to when a call is received.
As I said earlier, it's a mistake to see this as some kind of linear progression of language
goodness. While all of this was going on elsewhere in parallel, OO was being invented. The term OO
was invented by Allen Kay in 1966, but the ideas that led to it were around for a few years before
that, even as early as 1961. The first real OO language was Simula, which was created in 1965,
but there were earlier attempts. The radical OO step, though, was small talk in 1972. The OO
paradigm is not really what most people think, though. It's not really about inheritance and while
it is about putting data and behavior together, I think that most OO programmers would say it is
much more about polymorphism. Later, Allen Kay said this, I'm sorry that I long ago coined the term
objects for this topic because it gets many people to focus on the lesser idea. The big idea is
messaging. I think that what Kay means here is that the real value is that we can send a message
to something and it figures out how to process that message. We can send the same message to
two different things and each of them deals with that same message, but in different ways,
ways that make sense to them. This is polymorphism, really. This is the real power of OO, not inheritance.
In fact, the 1972 version of small talk didn't support inheritance at all.
In Bob Martin's model, this is called dependency management through polymorphism,
that's how he characterizes the OO paradigm. The real value of OO is our ability to modularize
our systems and deal from the outside with different modules in consistent ways. This is
polymorphism. Structured OO and functional aren't the only paradigms. Logic programming
constrains programs to follow the rules of formal logic, for example. You could argue that machine
learning in its current incarnation is a different paradigm that constrains programmers by allowing
them to pick good examples and only define fitness functions. But let's get back to our topic for
today, though. Remember, on the timeline, kind of weirdly structured programming is historically
the last of these paradigms to turn up. But let's loop back to the current on-point fashion leader,
the functional paradigm. The defining characteristic of functional programming
is really that it constrains assignment. We write code with no side effects. Each function
translates its inputs into a new output, and that's all it does, without changing these inputs in
any way, and without relying on anything but its inputs to achieve its goals. Sometimes,
functional programmers talk about this as separating data and function. But if I'm honest,
I think that this is probably so that they can argue with OO programmers who talk about combining
data and behavior. In reality, I like the idea of the constraints. I think that we talk a lot
of rubbish about languages and paradigms. I am probably primarily an OO programmer. That's
where I spent most of my career. But a lot of my thinking was informed by my early programming in
assembler languages of different kinds, an unstructured programming approach if ever there
was one. By shooting myself in the foot many times when writing assembler programs, I adopted some
defensive habits that I later learned were part functional, part OO, part structured, so that
when I learned more about these ideas, they kind of fit together. And that is what I like about this
model of constraints, because that's exactly how and why I learned these things. I wanted to constrain
the freedom with which I made designs so that I screwed up less often. I adopt programming habits
that limit the degree to which I screw up when I write code. I don't really think of myself as a
language or even a paradigm focus developer. But I like to pick the tools that make sense to me at
the time. Modern languages are mostly a combination of these constraints, rarely pure in concept,
although there are some. I laugh when functional programmers rubbish OO, for example, and then
go on to use collections to implement folds. The degree to which the collections like these make
sense is really applying polymorphism to me and OO idea. The degree to which the data is external
in a list is an implementation detail in this case, as long as we don't change that data.
If I write immutable code in Java or C sharp or any other OO programming language,
then I can justifiably be seen to be writing in a functional style. I used to write C,
I used to use ideas that I now I'd call OO and functional in the design of my code.
My language didn't help me much in those days, in the same way that Java doesn't enforce no
assignment when I'm using it, but it doesn't take a lot of self-discipline to achieve the same results
if I want to. So at the technical level, I think that your choice of paradigm is just that. It's a
choice and it can be fluid and contextual. Let's be clear though, you can write crap code in any
paradigm and you can write great code in any paradigm too. There's no functional good OO bad here.
There's a fashion for each side to rubbish the other and if I'm honest, I think that that is a
little naive. There are advantages to different paradigms, different advantages for each. As
I've said, I am more of an OO than a functional programmer, so probably somewhat biased. The
problem with this kind of religious war is that people get over-emotional. So if I do trample
on any of your sacred cows during the course of this, please do forgive me. There is a social
dimension to all of this though and we tend to be too tribal in software development.
Broadly, I think that we could oversimplify the tribes like this. Functional programmers
tend to think of programming as maths. OO programmers tend to think of coding as a problem of modeling.
Neither of these are completely true, but may be a reasonable approximation. So the benefits
of a functional approach are that we can abstract ideas into functions that are always correct.
In every circumstance and so write less code. By excluding or at least constraining assignment,
we can create more stable systems and maybe even more provable systems.
The benefits of a model-based approach are that we can be guided in our analysis by the problem.
I think that this is one of the advantages that OO has over functional programming.
It's that when done well, the code is more navigable because it's closer to the problem.
It allows us to explore the relationships more clearly and understand the problem in small
pieces in a way that is closely related to how we think about the problem.
Human beings are naturally classifiers. This gets us to what seems to me like an important point.
I think OO is more closely aligned with how humans' brains work. I can certainly buy the claim
that the more mathematical functional approach is a more rigorous way to capture an idea.
But much as I love maths, it's famously difficult and in essence an unnatural way of thinking for
human brains. We value mathematical thinkers highly because their skills are so rare.
This is so obvious. If I throw a ball to you, is it easier to catch it or to work out the
physics of its flight and predict where it will land so that you can move to the right place?
We don't do the maths when we catch a ball. If we did, we'd certainly miss the ball.
So there's something to be said for ease of comprehension, clarity of expression,
which is clearer, this or this. Even if you are a functional programmer, I think that you
would agree that the second version was easier to read. Sure, we can argue about the flexibility
of folds versus loops and because of the immutability of functional style, our potential to parallelize
the computation of our programs, an argument which I confess as a developer of high performance
systems I'm a bit skeptical about, but the readability, the comprehensibility of our code
matters a lot. Here is a function written in imperative style, in this case in Java.
We're just going to look at a collection of numbers and form some kind of total.
Here is the same function written in Haskell.
In this case, we're going to define the function as a recursive function.
The first seems to me a lot easier to explain to somebody that has never written any code
because of this alignment with the way in which people think about things.
You have to access some reasonably complex ideas like recursion to even start to understand
the second example. Yes, the code is shorter, but that compromises its readability somewhat too.
The first is a bit more like catching the ball than doing the maths.
In reality, in Haskell, this sum function is a library function which I'm told is apparently
implemented like this. I rest my case. I think that the functional paradigm has a lot to offer
in particular, the idea of limiting side effects is an excellent one, however you choose to write
your programs. I've adopted that style of thinking in my OO code for a long time now,
not eliminating assignment, but certainly limiting it and reducing the side effects.
I confess that I've never tried to write a whole functional system as a pure functional system,
and I'm sure that I would learn a lot if I did, but I think that one of the reasons that
everyone doesn't do functional programming is that it's more difficult to transpose these
ISDs into the kinds of functions in a way that keeps the code readable and navigable.
I said at the beginning that I disagreed somewhat with Bob Martin about whether we have found all
of the programming paradigms. There is another aspect of programs and programming that we can
usefully constrain that has some very interesting properties. That is synchronicity. What if we
constrained our programs to disallow synchronous calls between modules of code? Each component of
the system only communicated with any other by sending a message. Responses sent in a different
message some time later. I'm not talking about async-awaits here, which I dislike. More like this.
A sends an add-item message to B. Some time later, B sends an item-added message back,
saying and confirming the receipt. Concurrency only allowed at these module boundaries,
no creating threads inside a module. Each module is internally single-threaded and so
naturally concurrent. Each module is allowed to be stateful or stateless as need arises.
This approach is significantly higher performance than any other approach that I am familiar with,
certainly higher performance than a functional design. Functional systems copy a lot of stuff
to achieve immutability. The best that they can do is clever tricks to pretend that they're copying
things, but actually not moving the bytes around in memory. However clever these tricks are, though,
it's still going to add CPU cycles. This is less tightly coupled than OO systems, this approach
of limiting synchronicity that I've described, but it has some properties of both functional and OO
design. It also sounds to me quite a lot closer to the vision that Alan Kaye had back in the 1960s.
I wrote about some of these ideas in a thing called the Reactive Manifesto. There's a link
in the description. If you'd like to hear more about these kinds of ideas in a future video,
do let me know in the comments. Thank you very much for watching.
I'll see you next time.
