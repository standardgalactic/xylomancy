Hi, and welcome to Imperfect Utopias, based out of the UCL Global Governance Institute.
This is a podcast about the challenges facing humanity and possible global responses.
If you're new to the show and you want to get a list of our favorite books, other resources,
to pass shows, and to join our community, go to ucl.ac.uk forward slash global dash governance.
We're really delighted to have Daniel Schmacktenberger on the podcast today. Daniel's a social
philosopher and co-founder of the Consilience Project, a non-profit media organization that
aims to capitalize a cultural movement towards higher quality sense-making and democratic dialogue.
Underpinning much of Daniel's work is the conviction that strengthening individuals'
abilities to handle and filter information is now a civilizational imperative in a context of
existential risk. I've been following Daniel on the podosphere for some time now, and he's definitely
one of the people I check in with most often when it comes to trying to make sense of what's
going on. Daniel's work has also been a major inspiration for this podcast, so we're super
excited to have you join us today, Daniel. Thanks so much for making the time.
Happy to be here. Thanks for inviting me. We're going to type in lots we could explore here,
but first I'll just ask our pod crew to introduce themselves.
So my name is Sam. I handle the audio and video and hopefully some of the thinking went out of
fun. I'm Zoe. I help with some of the research and more of the admin and social media side of things.
Okay, so Daniel, let's get straight to it. In a world of, as the UN recently put it,
certain near-term non-linear change. How well prepared are we to face some of the existential
challenges? And not just to say the natural ones that people might think of like asteroid strikes
and those sorts of risks, which are certainly present but possibly remote, but perhaps most
challenging of all. And as we've discussed at some length, the human-induced or anthropogenic
existential risks like nuclear, but also biotechnology and of course climate change,
which arise out of these kind of complex interactions of human and non-human systems
and which are, I'd say, already defining our times this decade, this century.
And perhaps to put a little bit more meat on the bonus to where we might go with this discussion,
we've talked before about how there is a risk that faced with major disruptions,
our societies could potentially default in the direction of either authoritarian oppression
or even chaos. And that some people do think that this is the direction of travel currently.
So how can we best avoid, what can we do now to avoid that kind of dystopia by default
as our legacy structures, systems, governance systems, as they falter
and there is that risk of major events sort of overtaking us?
All right, that's a few good questions. The first question you asked is how well
prepared are we to deal with the existential and catastrophic risks that are impending or at
least have a non-trivial chance of happening? And you were mentioning that this is a frame
that is recognized by the United Nations now. If we think of the UN as a starting place to answer
this in terms of the closest thing to something like global governance or an intergovernmental
organization, obviously it was created after World War II in the recognition that nation states by
themselves weren't an adequate governance system to prevent World War. And now that we had weapons
such that the wars between the major powers could never be fought in one anymore. We had to
figure out a whole new world system to do something different than we had ever done in the history of
kind of like the post-empire world, which was how do you have the major empires not fight wars?
And we don't have a very good historical track record of that. But then we got to the place
where you had weapons where the wars couldn't be won and that was a different logic. So I point this
out because catastrophic risk that was human-induced before World War II was different in kind than
after World War II because we didn't have any tech big enough to actually create global catastrophic
risk from human action. That doesn't mean that catastrophic risk is not a part of our history,
it was just always local. And not only was it a part of our history, it was what happened most of
the time in the history of the life cycle of civilizations. So we can see that for studying
the Mayan Empire, the Incan, the Aztec, the Egyptian, the Roman Empire, one of the first
things that we recognize is that they all don't exist in the forms of their dominance anymore.
They all either had sudden collapses or gradual collapses, but the collapse of civilizations
is the things that we call civilizations is one of the kind of most prominent features
that we can see in history. And so you can see that people faced an existential risk to them
from in the form of a warring army or overconsumption of their resources or internal descent that was
enough that it broke their capacity to continue to coordinate. Those were always local issues,
maybe a large locality if it was a large empire. And those were both for environmental
externality reasons, like the first civilizations that over farmed and created desertification.
It was a long time ago, environmental overreach is a multi thousands of year old problem.
And short term solutions regarding rivalry that in gender enmity, in the side of the other,
and where they then reverse engineer whatever weapon innovation you had and come back and you
just drive arms races, they're escalating. That's also a very old process. World War II is the
beginning of us getting to the place where the scale of our warfare, and then also shortly
thereafter the scale of even our environmental externality hit a global catastrophic possibility.
So you see that we created an entire world system following World War II to say, okay, we need to
we now have such incredible power that we can't use in the way that we have previously, we need to
steward that power differently. How do we deal with conflicts without war between the major
superpowers? So the UN was created the World Bank, the IMF, that whole kind of intergovernmental
organizations that would be able to broker nation state interests to have solutions other than war
and the entire set of Bretton Wood agreements, Marshall plan agreements for how we kind of
rebuild the world where the nations would be so economically interdependent on each other through
trade and globalism that it was more advantageous to them to continue to do trade with each other
than to bomb each other. That was a huge part of it and where we could have so much growth of
the economy that everybody's desire to get more could happen simultaneously without having to
take each other stuff. The idea that very, very positive some GDP situations could keep us from
going zero-sum conflict-oriented. Well, that very positive some meaning extract resources that are
unrenewable and turn them into trash much faster driving GDP for a very short period of time also
meant we hit planetary boundaries. And so now we're seeing planetary boundaries both on the
side of depletion of unrenewable resources and the waste side, both sides of a unrenewable
linear materials economy on a finite planet, lots of different ones. We're not just seeing
too much CO2 but too much plastics and ocean microplastics and all kinds of things on the
toxicity side and all kinds of things on the overfishing, cutting down to
many old growth forests, soil micro diversity loss, microbiological diversity loss, etc.
So you can't keep doing the positive something in that same way that is based on the exponential
growth of a linear materials economy on a finite planet. That's one part of the kind of post-World
War II solution that's kind of run up against an end. The other thing is that that world system
created a lot of fragility because when you have global supply chains where most
any of the products that we engage with now no country can make, they're made across six
continents. This computer that we're talking on, this phone in my hand, when you factor all of the
materials processing, the hardware, the software, the satellite infrastructure required for our
communication to be happening, the positive side of getting the world very interconnected was that
we were less oriented to war if we had dependence. The negative side of dependence is you can get
cascading failures. If you get failures anywhere, then you can get failures that start to cascade.
And we saw that with COVID, we saw that an issue in one province of China became a completely
global issue affecting almost every sector of the world, that needing to stop the transmission of
the virus in a much more transportation based world than any previous plague or pandemic ever
happened in also meant shutting down critical supply chains where fertilizers and pesticides
that were needed for agriculture didn't happen driving food insecurity at massive scale and
which means that the solution to one problem drove other problems. Second and third order effects
became very problematic. And so we can see that and so the interconnectivity that had advantages
also has these fragility disadvantages and the interconnectivity also wanted to have maximum
efficiencies and the efficiencies also drive fragility. We also see that in that World War II
till now-ish kind of Bretton Woods time, we had one catastrophe weapon. And so the one catastrophe
weapon could be responded to by that same catastrophe weapon. And so the game theory of it was somewhat
simple. And for the longest time, we only had two superpowers that had it. And as a result,
mutually assured destruction was very effective. You were able to create a kind of forced Nash
equilibrium. And also because it's very, very hard to make nuclear weapons. There's not that many
places that have uranium. Enriching uranium is difficult. You can even see it because of radioactive
tracers from satellites, so it seems to monitor. And so you could do mutually assured destruction.
Obviously, we're in a situation now where we don't just have two superpowers that have nukes,
we have many countries that have nukes, but we also have lots of other catastrophe weapons,
meaning lots of other weapons that are big enough that they could cause kind of catastrophic loss
of civilization harm. And they aren't hard to make and they aren't trackable anymore, right?
Like it's not hard to make CRISPR bioweapons or drone based infrastructure attack type things.
It doesn't even take a nation state to do it, not traceable. It's a very different situation. So
when you have many different catastrophe weapons and you have many, many different actors that
can have them, including a very difficult situation to be able to monitor which actors,
how do you do mutually assured destruction? And so how do you do that? How do you get the deterrence
strategy right? And so what I'm bringing up is that catastrophic risk before World War Two was
one phase. All of human history up to that point, right? Then World War Two till now was kind of
one phase. And now we're entering a new phase where the Bretton Woods mutually assured destruction,
IGO, exponential growth of a globalized linear materials economy set of solutions doesn't work
for the new set of the catastrophic risk landscape that we face. So we need a totally new set of
solutions which will require innovation in our social technologies of how we coordinate
game theoretic type issues. Now, when you say how well prepared are we, we come back to the UN,
we recognize that we have not succeeded in nuclear disarmament. Even while we kind of
claimed to succeed nuclear disarmament in some very limited ways, we still had arms races of
faster delivery mechanisms, hypersonic missiles, whatever to try to win first strike and other
things like that. We got more countries with nukes rather than less during that time. We got
more other countries that could affect the movement of a new nuclear weapon through other kinds of
geopolitical and less military advance but engaging the bigger military type tactics, plausible
deniability attacks that get blamed on a larger superpower and things like that. And during that
time, we've also had every new type of advanced technology create an arms race. There's an arms
race on AI autonomous weapons, on the application of CRISPR technology to bioweapons, cryptographic
type weapons for cyber attacks. And so we have succeeded in preventing no arms races.
We have not been able to reverse the one really critical one. None of the sustainable
development goals can really be said to have been achieved well. So I would say that our global
coordination on all of the most critical issues is inadequate to the timeline and
consequentiality of the issues. That seems very, very clear. And as exponential tech is advancing,
the total number of catastrophic risks and the total probability of each is increasing.
And the capacities that we're utilizing to address them are not increasing accordingly.
So there is a gap that we need to be focused on, which is what you guys are focused on,
which is this kind of global governance topic. We have global issues, not just local issues.
Everybody's scared of global governance, the frame, the term global governance or at least
global government for a good reason, which is we have a good long history of reasons to not trust
consolidation of power with no checks and balances. So nobody wants this kind of massive,
unchecked global government. And at the same time, you have to have governance at the scale that
cause and effect is occurring. And if we're having, if nobody can fix climate change on their own,
in terms of nation-states, and yet they're all affected by it, and they can't fix overfishing,
they can't fix nitrogen, runoff dead zones and oceans and et cetera, there have to be
global coordination solutions. Otherwise, multi-polar traps ruin everything, right?
Multi-polar trap being some kind of race to the bottom. Arms race is an example, as we've already
mentioned. Tragedy of the commons is another example. But the key to both of them is where the
agent focused on their own short-term well-being does something that advances their short-term
interest, but then makes everybody else have to do the same thing. And where everyone doing it
creates the maximally bad long-term situation. And so if we try to create some treaty around not
overfishing a particular region of the ocean and anybody violates it, then why does it,
if anyone else doesn't violate the treaty, if they can't figure out enforcement, then
you're just a sucker for holding to the treaty, right? Because all those fish are going to get
killed anyway, as the ocean is going to get messed up, it's just going to feed another
population that's going to grow and have more people to engage in economics and armies.
And yet how do you do enforcement on a nation that has nukes, or a nation that has some critical
aspect of infrastructure, or the globalized supply chain? And so enforcement becomes tricky.
So then you get these types of things, tragedy of the commons and arms race,
multi-polar traps. So you have to figure out how do we solve those coordination issues globally,
because we have global issues that can't just keep getting pushed down the road.
And yet we want to figure out a solution to do it that isn't a kind of global government that
becomes its own catastrophic risk of under the name of some problem that is scary enough,
we agree to some totalitarian power structure. And that's the thing you mentioned about order
and chaos, is that we can see that the thing we call civilization is a way of having some
order, some coordination between lots of people, so that they can do specialization and division
of labor, creating a richer world for everybody, and then coordinate all that, they can coordinate
their activity for not just those kind of productive purposes, but also protection purposes.
So the thing that we call civilization is how we coordinate behavior of lots of people.
And that's actually a pretty hard thing to do when you think about people that want different
stuff and believe different stuff and aren't necessarily connected to or bonded to each
other, like how do you get them to not just do the immediate advantageous thing to them
for people that are fundamentally strangers to them. So typically a civilization will try to
create order through some kind of imposition, some forced religion, forced patriotism, law,
whatever it is, and it can air in the side of an order to have everybody
participate with that order becoming increasingly tyrannical, increasingly dictatorial.
If it doesn't do that, people end up orienting towards tribalism naturally
and fragmenting kind of towards each other and you end up getting the thing failing in the
direction of chaos. The only other answer is how do you get order without it being imposed?
How do you get emergent order? And this was the kind of idea of democracies and republics and
open societies is maybe we could actually get emergent order if we, and it was based on the
idea of a culture that invested in the people enough, that the people didn't just believe
different things and want different things and be willing to defect into war. You had to actually
develop a people that could all come to understand the world similarly. Can everybody
understand the philosophy of science well enough that they can all come to understand
base objective reality that they share similarly? Can they all have something like Hegelian
dialectic capacities where they can notice not just their own values but other people's values
and recognize that only solutions that meet everybody's values will end up working?
Can they understand things like multipolar traps well enough to understand that a short-term win of
my political party just means that whatever technique we utilize that was effective gets
reverse engineered, the other side wins in the next four years and undoes everything that we did
for four years and we get nowhere and then dictatorships do much better than us and the
society fails. Can people understand those things enough that they don't orient towards the short
termism kinds of things? So this is why the modern democracies emerged out of modernity,
emerged out of a philosophic system that said we can come to understand the world and understand
each other well enough that we can actually have emergent coordination. Obviously the world has
gotten much more complex during that time and the cultural value of that kind of education has
eroded and so the question and I guess here's the way I would frame up the current situation
one way that I'm looking at the current situation.
This is a detour but I think it's helpful.
I'll go back to World War II and then bridge it to now since that was kind of the beginning
of catastrophic level technology. One way of looking at World War II
is and this is not the only way there's lots of ways this is a useful way for the construction
I'm doing. One way of looking at it is that there were a few social ideologies that were
competing for supremacy and what they were competing over was the emergence of a new set
of technologies that science made possible that were so much more powerful than the previous
technologies that kind of whoever got dominance and then would win and so the bomb is obviously
the center of that but it's not the whole of it. Computers, the enigma machine and the whole
development of computation, rockets and chemistry. Chemistry is a part of that and it's kind of
advancing in World War I but then advancing a lot in World War II and kind of those all came
from science getting to the place that we could do like atomic physics and physical chemistry well.
And the social philosophies we could say are capitalism and kind of like
liberal democracy. The intersection of theory of markets and something like a democracy or
republic. Communism, the Soviets and fascism and a particular kind of ethno-centric nation-state
fascism. So those were three different types of social systems and we can see that Germany was
actually meaningfully further ahead than the US or the Soviets in certain areas of tech. They got
the enigma machine first, they got the V2 first. Those other countries were obviously larger so
when they recognized that and fought to catch up they had an advantage in that way and we can say
and there's lots of problems with saying this but for the use of the construction we can say that
the US won that competition for that war. Those wars over the new technologies and we did it
not through the market running the Manhattan Project but the state running the Manhattan
Project. This actually a very, very important thing to recognize is that the United States
recognized that it was an existential risk and you remember it was Einstein and Sillard I think,
the Einstein Sillard letter that said no the physics we came up with really does say that
Obama is possible and there's a decent chance the Germans know this and they're working on this,
we were doing the physics over there together and so the idea that states don't innovate and that
markets innovate is just not true. Historically the ability to split an atom which is in a way the
most impressive innovation was done by the state not by the market that was not outsourced or private
contracted and the same with cracking the enigma code and the whole early development of computation
that ended up then getting private contract and leading to Silicon Valley was nation state funded
the Apollo project and it kind of stopped with the Apollo project for some important reasons
but what happened was the United States recognized that the technological advancement
was going to determine who had the power to determine the world so much that there was
an existential risk for them that they created a unlimited black budget brought all the best minds
together to drive innovation in technology to be able to make a democratic system stronger.
For a bunch of reasons after that in the decades that followed more and more of the innovation
got outsourced to the private sector and it started to become closer to true that the state
wasn't innovating and most of the innovation was happening in the private sector but the private
sector doesn't have the same patriotic interest it doesn't also have the same people in the private
sector aren't voted in they don't have term limits there isn't the same jurisprudence applied to them
so they have a different set of agendas right and the whole idea of the state like you can almost
think of what the state in a liberal democracy is as like a labor union for the people and as a whole
like a labor union is how do you unify all the people to have something that is big enough to
represent their collective interests so that the large corporations and the major wealth holders
within capitalism don't just rule everything like feudalism which is the thing we were trying to
replace before because it's very clear that if we have a trade system and it's mediated by an
abstract system for doing accounting like like currency that pretty soon you'll have a power
law distribution of wealth and a few people will own most of the wealth it just some people are
better at it and then getting better at it gives you more capacity to keep getting better at it and
there's compounding interest which is an exponential return on owning capital there's
compounding interest on debt and you know does that thing right and we can see the data of that
in Piketty's book and but it's also just kind of a natural thing to to look at so the idea was
since power law distributions are going to happen the most people are going to have really no power
how do you not have that be oppression well let's have the people all be able to collectively vote
where at least the majority of what they care about gets encoded as law so their values are the
basis of the jurisprudence of law so then rule of law can get enforced by representatives of foreign
by the people that are going to be bequeathed with a monopoly of violence so they can actually do
enforcement to be able to protect the people in the commons against perverse incentive while
letting the market do all the good things that it does but most of rule of law is actually
binding the perverse incentive markets okay so if that only works where the state can check the
predatory aspects of markets if the people are checking the state that it is truly of foreign
by the people there's transparency everybody's actively engaged as soon as that stops happening
then the government is just run by people those people are economic actors they're in there for
whatever a short period of time and it's they will be liked about the same whether they do
corporate interests or not because nobody's really going to know and so of course you end up
getting regulatory capture where the market captures the regulatory apparatus and you get
crony capitalism and that kind of institutional decay and as the founding fathers in the US said
and anyone who paid attention as soon as a couple generations pass and the people forget what it
means to fight a revolutionary war and be under oppression they won't keep investing and being
educated enough and actively being engaged in government because they'd rather keep up with
the Joneses or party or like some other some other thing and so how do you keep the intergenerational
transfer of not of not just the knowledge but the civic virtues necessary to uphold a democracy
which is not a trivial thing and especially as time goes on and the complexity of the world increases
understanding the issues well enough to really play a role in them and to be able to oversight
them and police them gets harder and harder and so there has to be more and more investment
into doing that so we can see that the people stopped investing in checking the state the state
stopped checking the market market captured the state all the innovation got outsourced and so
what we can see today so we see in that world war two example that the state really pioneered the
advancement of all these areas of tech to increase the integrity of the state
there is a jump in technology that is currently happening that is more significant than the
world war two jump in technology and the center of it is AI and computation with AI being the
very center right it's computation digital tech but then the application of AI and digital tech
to physical tech as well so the application of that to biotech and CRISPR kind of stuff and to
robotics and robotic automation and the other key areas of computer science from the evolution of
the computational basis quantum computing photo computing dna computing whatever and
again the application of that to the material sciences nanotech etc so we're undergoing this
huge jump in technology right now that is something like two orders of magnitude more
significant than the previous world war two jump was in terms of the total amount of verticality
of power and the speed at which it's developing and the number of verticals simultaneously
and the way I see it is that tech will confer so much power that only those who are
guiding it will have much of a say in the future and right now I only see two types of groups
really guiding it meaningfully some authoritarian nation states are where the nation state is taking
seriously the development of the tech in the nation state is investing a very big r&d budget and how
to actually increase the integrity of their nation state and this is a good thing for them to do
a line with whatever their system and their ideologies are and obviously China is a prime
example here where the application that the government is investing in the development
of engineers and in the application of all of those areas of tech to the nature of government
itself and that's everything from their iot system to their sesame credit system to the
transistor development and lithography to the belt and road initiative and getting
something like 94 percent of the world's rare earth minerals in there that are needed for
computational substrate in their supply chain to on and on right to the creation of their own
internet that doesn't have the same problems for their country that the US internet has
so authoritarian nation states are using the exponential tech to become exponentially more
effective authoritarian nation states and the only other kind of org are companies western mostly
companies and those companies are supported by a military and capital and infrastructure of the
nation state but they don't are not serving the interests of the nation state other than
gdp and jobs and some some very short term kind of stuff and they're becoming exponentially more
powerful companies but you know facebook and google and uh have more users than china and the
us combined have people right so these are humongous kinds of things of which there is no precedent
for a corporation in history now an rand never imagined things like this when she was thinking
about the symmetry of supply and demand um and she didn't think of things like metcalf dynamics
that end up leading to natural monopolies and anti trust law didn't think of that right so you
end up having amazon being bigger than all other online stores combined and google being bigger than
all other search engines combined and facebook being bigger for time on site than all the other
social networks you get a natural power law distribution not based on government crony
capitalism based simply on the nature of network dynamics that once you reach a certain escape
velocity there you're a natural monopoly will start to emerge based on the value of the thing
being associated with the second power of the number of users and so the interesting thing
is you see these corporations that are becoming more powerful than nation states in many ways
because of the development and direction of the exponential technologies
and as that happens they are less able to be regulated by the countries while still benefiting
from the infrastructure of the countries and simultaneously eroding the integrity of the
country we can see the way that the time on site optimization ad model of facebook and google and
youtube have eroded american democracies in specific and western democracies by doing
the time on site optimization appeals to people's cognitive biases and tribalism and limbic hijacks
and those types of things we can see that the kind of consolidation of market function like amazon
that amazon's growth during covet matched pretty closely the closure of all small businesses that
aren't going to reopen well the american dream without small businesses isn't the thing right
it's not a thing in the same way and we see the technological automation of so many jobs impending
and not the replacement in the current way that it's trending of a similar american dream
kind of sovereignty so there's a there's kind of a billionaire to centa billionaire class that
runs whatever the one big dog on the top of the power law distribution that defines a vertical is
and a increasingly less upwardly mobile in terms of real capacity to play those games
underclass um and obviously some kind of middle class that is serving the very upper class in that
context so what i see is that that is the movement to a new kind of feudalism right a tech feudalism
and that and it's even interesting some of those companies you know we see this with tesla we say
with the other ones some of those companies are getting subsidies government subsidies that means
they're collecting taxpayer money to do to to utilize taxpayer money to do the thing they're
doing but the taxpayers didn't vote on them doing that they were not elected representatives they
cannot be unelected and there is no traditional jurisprudence for the guidance of the thing
that they're doing that's something much more like a king than a president which is why i say kind
of an emergent tech feudalism so what i see is there's one stranger tractor which is tech
feudalism there's another stranger tractor which is kind of authoritarian nation states and anything
like an open society where there's participatory governance and jurisprudence that is grounded
in the will of the people there is no system that is based on those ideals that is innovating
in exponential tech to make better versions of that social tech that is the number one imperative
of our time in my opinion and either we figure that thing out or those are the only attractors
and the third attractor is that the exponential tech just causes x-risk and we're fucked right
so you have x-risk feudalism and authoritarianism as the current dominant attractors in the presence
of exponential tech or there's not 17 sustainable development goals that really matter because we
can't fucking achieve any of them without better coordination there's figuring out coordination
that it becomes the central goal of the world figuring out a kind of coordination that is emergent
order that is neither chaos nor oppression that is able to utilize the exponential technologies
and also to bind and direct them so that they do not either directly or through externality
create x-risk and that they don't erode that they don't create authoritarian systems or
kind of feudal systems that erode civil liberties in the process so we need to
have a kind of global innovation zeitgeist of how to apply all develop and apply all the areas
of exponential technology to building new social tech that can guide bind and direct the exponential
tech prevent x-risk and do it in a way that is commensurate with what are underlying kind of
deepest values for participatory and empowered governance and cynics are.
Thank you Daniel that was a fantastic riff on the opening question I think really sets the scene
and goodness we could go in lots of different directions now it made me think of you know
Nar Ferguson's book the square in the tower Nar Ferguson has said that historians haven't taken
network seriously enough and he traces these network dynamics back centuries and actually
says they were a much more prominent and important part of the the historical political landscape
than we than we often can think so that that was really interesting and I guess what I was thinking
we might pick up would be you said at some point that we often kick these problems down the road
and I wonder to what extent we're really coming up against the sort of cognitive limits of
of humans given the rapidity of change given the challenge that we confront in trying to get
our heads around exponential functions we have this kind of strange parallax right now between
continuity and discontinuity so we have these these unique unprecedented challenges but on the other
hand we have these very old forces of zero sum competition resource wars I certainly something
which I sometimes hear in in the academy is this idea that ultimately there's really nothing new
under the sun that we can repurpose our existing structures that we do have good enough global
governance if you will but I wanted to tease out a little bit more this idea of continuity
it seems to me also what we're seeing is kind of a resurgence of of understanding that actually we
do need to respect the laws of physics that we need to respect the laws of thermodynamics that we
might actually even have to listen to say E. O. Wilson on the the laws of sociobiology in terms
of how do we navigate through a viable path given the current situation we find ourselves in
but on the flip side we also have a sort of a real lack of radical vision within the half within
sort of the corridors of power even if the UN Secretary General Antonio Guterres is is calling
for a new international social contract it doesn't seem to be resonating and if you go back in the
historical record and you look at the the the debates of the 1950s in the shadow of the bomb
and how radical the vision was of course what what resulted was a compromise but nevertheless
there were very serious people who were thinking hard about global political federation what's
happened why is it you know to to to to draw on that that famous phrase it's easier to imagine
the end of the world than the end of capitalism why is it so hard for us to to work through
the a viable path to to to address the challenge that you've articulated so clearly
first on the topic of there's nothing new under the sun and our previous systems of
social philosophy and social technology are adequate I don't think that anyone believes
that who's actually studied exponential tech and x-risk meaningfully I have not met them
it it doesn't seem like a reasonable position to hold those things together
if you look at just a single category of exponential tech that idea will change
um I'm sure the listeners have all seen this but like when you saw the way that alpha go beat
stock fish at chess that was so fucking clear that we're dealing with phenomena that are nothing
like any phenomena that the Scottish Enlightenment or the founding fathers or Isaac Newton or
Marx or anyone ever had to think about that that the best chess player in the world which
is the cutting edge of there's nothing new under the sun like chess players got better but like
people been good at chess for a while right it's a slow evolution until AI and stock fish just
devastated the best chess players in the world we remember seeing Kasparov get beaten and then
stock fish kept getting better and better with the model of AI we're programming all the human
games until it was so much better that it stopped even making sense to calibrate it relative to the
best humans and then a breakthrough in AI says let's do this differently right let's make a type
of AI based on rival networks and we won't actually program any human games into it we'll just let
it play itself a bunch of times and fast forward and see what it learns and I don't remember exactly
but alpha go by google I think it I think it trained itself in three hours just playing itself with no
human input of information just the rules of chess and then it ended up beating stock fish there were
a few stales but it was like 38 to 0 in terms of the non stales and it's like oh wow that's it
and stock fish was so far beyond humans and it's like three hours of training and then that that
same thing could beat us at go and start to beat us at complex strategic video games and this is all
evolving over the course of almost no period of time right this is evolving over the course of
months and single digit years nothing new under the sun nobody can study exponential curves and
think that now this brings us to the it's just such a silly thing to say when you start looking at
scaled species extinction when you start looking at like the Anthropocene as a real thing where
humans are a bigger force than all geologic forces combined defining the surface of the
earth like fuck it's a different it's a different situation than the the history of the world was
and like we said just even starting with the bomb the world never didn't have the major
empire's war and the and world war two is like a second ago in historical time right and the solution
to not use that bomb drove all these other issues so a lot of our issues are just increases in the
severity of the same underlying type of game theoretic dynamics and so we can say they are
continuous with them in type but there are places where a change of magnitude becomes a change in
kind right like as soon as the magnitude gets beyond human information processing capability it's
now a change of kind as soon as we move from a war that's winnable to a war that's not winnable
even though they're both the logic of war it's a change of magnitude that becomes a change in
kind right so there's a lot of places where even the things that are continuous with the past become
discontinuous past certain thresholds meaning that the same types of solutions the whole
class of solutions doesn't apply anymore now that doesn't mean that we throw out everything that we've
learned it means that we have to make sure that we're applying everything that we've learned
that is effective that we aren't making the mistake of not paying attention to the total
amount of human thinking and ingenuity that's happened so far and that the new innovation
that we do is commensurate with the smart parts of it but it happens all the time that we're
exploring a search space and there's a couple branches and in the immediate term this branch
has more incentive and so we explore this branch and then we just forget about this one
and we just keep exploring and then we hit a cul-de-sac at a certain point but we have
reasons why there's momentum to keep you know some combination of sunk and cost fallacies
with the actual belief that this is the only path as earlier choice and that we wouldn't go all the
way back there to the not even knowing the other branches that were that were cleaved that we didn't
pay attention to to like perverse institutional incentives of standard models where it's hard
to get a research grant to do anything outside of that thing or to get your professor who believes
in that thing to change their opinion on it or whatever it is so there are a bunch of places
where we actually have to go back and say okay there was an incentive to make faster and faster
smaller and smaller computer chips and there was enough money around that that there were whole
other directions in computational substrate that we didn't take that for reasons of manufacturing
resilience and a bunch of other things might actually be meaningful and interesting. This
is starting to be a real conversation in theoretical physics with string theory and like maybe we
actually need to rewind and try a fundamentally different approach. I think there are places
in governance where like we've just accepted we've just kind of accepted
capitalism is the only in the west is the only reasonable answer combined with some kind of
open ish government state and if you think anything else you didn't study the history
of Mao and Stalin and Paul Potts and whatever because everything else ends up becoming that
kind of dreadful slaughter like that's kind of the dominant narrative where it like it's worse
than going against Christianity or it's similar to going against Christianity in the dark ages
right there's an almost religious tone to it and it's like well we could come up with better
shit that isn't any of those things like there's nothing new under the sun blockchain's new
like the ability to have an uncorruptible ledger where you can have a provenance of data that you
can't fuck up that makes it to where you can have a history that can't be corrupted or changed by
the winners afterwards that's kind of new that's a big deal makes it to where you can have a system
of justice where you can't actually fuck with the fuck up the data right it means that you can have
a system of accounting where let's say the government spending was on a blockchain that was
transparently oversighted there wouldn't be missing money anymore right now there's all these places
where the total amount of money going in and the receipts coming out don't add up and there's missing
money it's like well that couldn't be and so it's like does that make something new possible
yeah totally it makes something new possible you look at the way that AI can make
new sounds it can do error correction of sound where there is an error or make new sounds or make
new faces by doing an average composite of all faces that look similarish right you say well
could people express huge numbers of people express their sentiments about something and
have the AI actually come up with something that is like a weighted average of all of those as a
form of proposition creation and then could we use distributed methods of proposition advancement
that didn't exist when we had to meet in a town hall and ride a horse from that town hall to the
other ones and we haven't innovated the structure of government since we had to ride horses
um like why do we think this this particular thing is the best thing well because the other
things the last time we had that conversation seemed dreadful at least that was the the winning
narrative so but but totally new things that are not just those previous things are possible
and so what I would say is someone should not assume that the moment we say maybe there's a
problem with capitalism that we're instantly going to turn into Stalinism or like I and but to say
let's make sure we study that history well enough to know what was wrong with those ideas we don't
do that yes but let's also do the critique of the system and not just end with the critique
but take it as a design criteria to say what would a better system look like and have we got
all the design criterias do we have the critiques of the communist system and the socialist system
and the capitalist system simultaneously and then can we take all those as design criteria
and work on a fundamentally better design that might not look like any of those isms that utilize
this new technology which means new possibilities that didn't exist before with new forcing functions
that didn't exist before I think you're also saying Daniel that these kinds of challenges do
actually have comprehensive solutions and I think there's quite a lot of people who deep down have
a very they have they doubt that that's actually possible so whether they haven't even tried hard
enough to have that doubt mean anything it's just an emotional default that was the other question
you asked is are we hitting the limits of cognitive complexity that is such a like
shit answer if you haven't actually applied the full limits of human cognitive complexity and
seen that we're failing so we're not even trying like China's trying and they're doing
fucking amazing right like if you in the US we have no high speed trains none none in the time
that they've existed China's been exporting them all around the fucking world in that same amount
of time and it's so but a system that doesn't have term limits and that doesn't have a two-party
system where we just use all the energy wasted as heat fighting each other and then whatever you do
for four years the other people undo for four years and nobody invests in anything with longer
than four-year timelines because it won't get them reelected that system is just stupid that's
going to fail to a system that can do long from planning and so if we say okay let's imagine
just hanging out in the 30s and saying we got to figure out how to split an atom no not just
splitting atom we're going to figure out how to split an atom and deliver that as a warhead
with on a rocket to some other place with some decent precision in fact we're going to go beyond
that we're going to use uranium to fission something and split it to then drive nucleons into a fusion
it would be easy to say well there's no fucking way like we don't have the cognitive complexity
to be able to split atoms we don't even know what an atom is and but the Manhattan project was a
very serious investment in cognitive complexity and and we got everybody there right like we got
all the best thinkers in the world there we put the budget on are we doing that like are we even
fucking where we got von Neumann we got Tori we got Feynman we got you know Oppenheimer we got all
those folks in Bletchley Park and in Los Alamos and then like where is the equivalent of that thing
outside of very narrow areas of military which is why we have a dope military like we have an
awesome military but that doesn't that's innovation in military that's not intervention in the social
technology of governance itself we actually have to not just innovate our military but innovate
the social technology of governance for a participatory governance system and this is why we come
back to the there's this quote that I always forget so I paraphrase of George Washington's
that said something to the effect that the number one aim of the federal government has to be the
comprehensive education of every citizen in the science of government and science of government
was the term of art and I think it's so profound that he did not say the number one aim of the
federal government is to protect its borders and he did not say the name of the federal government
is to protect rule of law because you can do rule of law effectively with a police state
and you can protect the boundaries fine with a military dictatorship but they won't be democracies
if it's going to be a democracy then democratically the people will probably decide to protect
their borders and to engage rule of law but if the number one goal is anything other than the
comprehensive education of all citizens and the education was considered both a cognitive
education and a moral education the way they described it which is the kind of civic virtues
that people are willing to give something for the larger system that they also receive benefit from
and they're actively participatory engaged so that's the thing we need to be innovating in right
now not just innovating in military while turning it into a some kind of autocratic or
kleptocratic system but how do we apply the new digital and other exponential technologies
to be able to both direct the exponential technologies well so that they don't cause
existential risk and in a way that is aligned with the actual values that we care about as a
people and so then the core question comes what is a successful civilization well it's one that
doesn't fail but that's not the only criteria it's one that doesn't fail and that maximizes the
possible quality of life for everybody in perpetuity and then we have to find what is quality of life
mean right so these there's like core existential questions of what is a meaningful human life to
be able to design a civilization that is optimizing for that which is culture right which is why we
have to have innovation in culture which is why I talk about that there's a cultural renaissance a
cultural enlightenment that is necessary right now as the basis of the creation of these new
institutions that can solve the excess problems because our current problem solving mechanisms
can't solve them which is why they're not being solved we have to develop new institutions that
are capable of solving these types of problems these types of complexity but if those new institutions
are created by a few people that get it and impose them on force then it's some kind of autocracy
so they have to be created by people who want them and are willing to participate with them
and capable of participating that is that is the cultural enlightenment that has to be the basis
of it which and and of course there's a recursive process of some people engaging in that to then
build systems that in turn engage more people in it so you get a virtuous cycle between cultural
evolution and social evolution employing physical technologies binding physical
technologies and advancing them for the right purposes it sounds like we we really need a
sort of a new forms of wisdom education and obviously I'm glad to say that we've got a
Zach Stein coming on the podcast very soon to discuss that very question and obviously what
you're saying Daniel you know big implications for how we think about the university in the
current situation but I'd like to hand over to Sam I know Sam's got a burning question so please
Sam yeah hi Daniel yeah I've got a couple of burning questions but I'll go with one to start
it seems like with the problems we're facing they often as we talked about they happen at a
certain area so for example climate change is here already and it will exponentially grow out
and that's one of the issues that I think we're kind of alluding to that when there's not the
immediate threat of World War II for example it's quite hard to galvanize a whole group of people
towards a to solve a problem but do you think that we think about solutions in the same way to
the logic of problems in terms of Silicon Valley out or it will happen in this certain area and
slowly filter out you know there's that quote the the future is here it's just not that evenly
distributed and that's quite a worrying logic if we're thinking about the magnitude of exponential
risk and do you think that we're then following the logic that we apply for problems that they
happen and exponentially grow out and is that useful or harmful when we're thinking about
solutions that need to really permeate permeate around the whole globe and and not leave anyone
behind I'm not sure that I understand the question yet you are using the example of climate change
and saying it's already here but because it doesn't look like an agent in a way that we
evolve to understand as an immediate threat we don't respond to it appropriately
but that it's already here it's expanding in a way that maybe we don't respond to appropriately
and you're wondering is that the case with all of the risks there's already AI happening that is
risky and we're just not responding to it appropriately or it was a question different
yeah sorry Dan yeah the question was slightly different so that's how we understand issues
like climate change and we often talk about solutions in a similar way to that issue of
climate change i.e. there'll be an innovation in a certain part of the world so the solution is already
here and then it slowly permeates out and then eventually everyone will have it so you took
the example of high-speed trains they are already here the solution is already here it's just not
that evenly distributed and do you think that that follows the logic of where we think about
things like climate change and where it happens in a certain area and slowly distributes out
whereas with solutions they need to be get around everyone very quickly and they can't work in that
logic of slowly from one center expanding out. I understand though I think I don't think it's
fair to say the solutions are already here and unevenly distributed it's true for some things
obviously we already have a solution to caloric abundance but it's not evenly distributed because
there's extreme poverty right that's an example and that's one we've lived with for a long time and
we can see that it did not actually pervade out well for certain reasons it would fall a certain
to a certain degree and then not beyond and the same is still true for running water and
hygiene and medicine and right there's a very unequal distribution of problems we have solved.
I would say that many of the most critical issues we need to solve the problems don't exist the
solutions don't exist anywhere it's not true that somewhere has figured them out well it like we
actually have to do innovation like how do we solve global multipolar trap issues is not solved
anywhere and that's the most central thing we have to figure out how do we create digital open
societies you can say that it's kind that there are some places that are trying to pioneer like
taiwan and estonia that's true but those are very far from have really got worked out solutions
that are adequate to all the other places in scale so I think we have to acknowledge that
many of the most critical solutions don't exist at all and need to become the primary focus of
innovation and then where they do start to develop we have to say what type of governance and
incentive landscape would be necessary to get them everywhere they need to be in time and who
would have to be participating to make that happen and what kind of oversight and enforcement would
be necessary to really make it happen we know you know in the US the government making deals
with Native Americans and then not keeping them whenever it's inconvenient almost all the time
it's not just about did you say when you developed a new technology that will get it to the world
it's is there a method of enforcement that will actually ensure that that occurs and that it
occurs within time that becomes critical okay yeah I just had a follow-up to that we talked about
how we understand problems and how we understand solutions why do you think certain maxims are
held in higher esteem than others I remember in another podcast you talked about survival of
the fittest and how we've almost fetishized that concept above all others and how can we make sure
that other maxims are discussed in a kind of equal or more celebrated light and is that there
are logic that pervades a lot of these more harmful maxims yeah it's apologism so if I went
a war and we kill a bunch of people that we call terrorists or infidels or some bad thing that
makes them not human but what it means is we blew up a lot of civilians and a lot of women and kids
and whatever it was but we got more land and resources and whatever it was out of doing that
thing survival of the fittest is a nice narrative to say that's how nature works and that's the way
that it should be and it's actually the prey animals it's actually the predators that keep the
prey animals from eating themselves into extinction and that drive them to evolve by eating the slow
one so that the good genes kind of inbreed and you know most people are like prey animals so
that some more predatory humans that call the herd and that kind of drive them who are otherwise
kind of lazy eaters like that whole ideology is apologism for whoever is winning at an extremely
damaging rival risk kind of system naive techno capital optimism is one of the best examples
of apologism of this kind where like if you have a theory that criticizes capitalism nobody who's
winning at capitalism who has the money is going to upregulate it and if you are criticizing tech
no nobody that was winning at tech is going to say yes I like your idea of why I suck and I'm
going to upregulate that so you realize that for narratives to catch on they some somebody has to
upregulate them and there's cost associated in doing that and there has to be a motive associated
with that cost so there it's not just like the ideas that are the most true and the most
beneficial proliferate the ideas that have the most agentic basis to drive them through the
society are a lot of the ones that proliferate the idea which is often held up sort of as
counterposed to survival of the fittest is mutual aid which is this idea that Peter Kropotkin proposed
in the late 19th century and he essentially saw out there in nature actually it wasn't the the the
species that competed most fiercely that survived it was those that actually cooperated that moved
into a kind of a situation of symbiosis if you will so is is is that notional mutual aid is that
is that a useful reference point for thinking about these maxims that need to inform how we
move forward how how do we actually begin to have meaningful productive conversations
um within the classroom or within within the UN forum or within government
corridors of power and how do we begin to chisel away at the memetic sort of structures which
seem to reinforce that that particular mindset if we think through the wrong metaphors we're
obviously going to come to the conclusions of those metaphors predispose but they
they're the wrong ones then they'll be the wrong conclusions so what kind of animals are humans are
humans uh predators are we prey are we fungus are we slime molds what are are we um the relationship
between trees and animals where we can see gas exchange there's lots of different biological
analogies we can try to use and none of them apply like okay so let's say we do the most popular one
which is that we're apex predators pick an apex predator lion polar bear and orca right orca is
maybe the best example the biggest apex predator in the ocean compare what an orca does to a school
of tuna to what a industrial fishing boat a commercial fishing boat with a mile long griffin
that does the orca misses almost every time and when it finally catches one it catches one
right and as there's less of them it misses more often and we can pull up the entire
fucking school in a net that's we're not apex predators apex predators can't do that if a
polar bear decides that it's super pissed off wants to go on a rampage and destroy as much
stuff as it can like what's it going to do and look at human nuclear capability if we were
similarly disposed like wait the idea that we look at that we don't factor the way that technology
means that we are not like the rest of nature so of course we need to see in nature yes there's
some competitive dynamics and some cooperative dynamics this is true where there are competitive
dynamics there are mostly symmetries of power the tuna get away as often as the orcas catch them
right so the slow orcas die the slow tuna die the faster of both happen so they the co-selective
pressures have them both kind of get better together and so there's the symmetry of power
right the orca is not a lot more powerful than tuna in terms of that particular dynamic
and so we can see that if we were to figure out some way to quantify all the interactions
that were happening in nature almost all of them are symbiotic right of some kind some of them are
directly rivalrous and competitive and sometimes it's a kind of both right it's a place where the
competitiveness at the one-to-one level ends up leading to symbiosis at the species to
species level obviously both the predator and the prey animal depend on each other
predator dies prey animal eats itself to extinction prey animal dies predator serves to death so
micro rivalry ends up leading to macro symbiosis because of the symmetry of power thing right
so we can see that there are certain types of competition but they're limited the
symmetries of power and then there's a lot of symbiosis well as soon as humans start making tools
we were able to hunt any species to extinction anywhere and go become the apex predator in any
environment and more powerful than the apex predator in any environment there's we broke the
symmetry right we we became more lethal predators faster than the environment could evolve to become
more resilient to it as a result that was the beginning of an extinctionary process that was
following an exponential curve that was slow for a long time from stone tools and started to really
pick up with agriculture then really pick up with the industrial revolution is now verticalizing
in modern tech world but the but stone tools were kind of the beginning of it right and the other
stone tools and language and that type of coordination that came along with the abstraction capacities
so do humans need to ensure as the metaphors of nature go that where we have competition
that it's symmetrical and that it's constrained and that the micro competition really does lead
to macro symbiosis we need to ensure that this is true is the competition between Facebook for
your attention and you for your attention symmetrical no of course not well you say well
there's a competition the competition between supply and demand is symmetrical because there's an
equal number of dollars flowing from demand to supply bullshit right the demand side is not
coordinated the supply side's coordinated and so even though there's a total symmetry and aggregate
there's not a symmetry of coordinated capacity because it isn't google against all google users
as a google user labor union that is also applying similar exponential technologies to
bind this thing it's google against one person in terms of the person didn't think that they were
about to spend the next three hours on youtube and now they do which is better for their advertising
model not necessarily for your life that kind of and so then you can have supply side driving
manufactured demand well now there's not real market ideology is broken now that's not a
market ideology was that there was a thing called demand that was foundational
that people wanted real shit that would improve the quality of their life and that created an
environmental niche for supply and the rational actors would buy the product or service amongst
all of them at the best price that would drive innovation well at the moment supply started
to get much bigger than demand because of coordination it realized that it could manufacture supply
and the humans weren't all that rational all the behavioral economics and now the entire logic
of markets is broken right like market theory is broken with manufactured demand and radical
asymmetries on the supply side okay that's important to know and so if you go back to the nature
example where there's competitive forces do they need to have symmetries in order for the
competition to lead to symbiosis as a whole and metastability of the ecosystem yes if you bring
something in that is not symbiotic with the rest of it you get an invasive species that can destroy
a whole ecosystem right so we should study biology where we're not trying to compare ourselves to apex
predators or slime molds or whatever we could just study general principles of things like
cooperative dynamics and competitive dynamics and metastability we can kind of get a sense of that
what is needed for metastability and then say how does that apply in the human world but it will be
different it'll be very different see the rest of the animal world is not forecasting the future
and making game theoretic decisions based on forecasts of the future and so this is why
like complexity theory where we model us as termites is silly like we don't behave like termites
so it's not that it's useless but it's profoundly inadequate as a set of metaphors so we have to
recognize our humans part of nature of course is there a distinction between humans and the
rest of nature that is fundamental in type maybe it was just a change of quantity of
neurological complexity that crossed a threshold that became a change of kind but it is a change of
kind and so we will have to have fundamentally different metaphors for thinking about that
which is why it makes sense to just think about the problem space and make sure that
you understand the problem space well and that your solutions are aligned with the problem space
yeah yeah I think what an exciting research agenda and of course an agenda to live by as well
to engage with deeply and another maxim comes to mind perhaps which would be know thyself
it's not just a situation of impersonal inexorable forces bearing down on us but we're also talking
about systems of I think human intentionality which raises the the crucial issue which we
discussed with forest landry in an earlier podcast on how do we make good choices which perhaps you
know our education systems are not really equipping us with the tools we need to answer that
really important question I know that Zoe's got a question I want to hand this over to Zoe so go for
Zoe so I kind of building on sort of the meta we have the wrong metaphors I guess so we're using
the wrong ways of thinking I kind of wanted to know how do we deal on like on a societal on a
personal level with the amount of cognitive dissonance I think we're existing in because
I think part of the the difficulty with coming up with solutions is that that some of the
challenges are so overwhelming that I feel like majority of people just kind of stick their
head in the sand and they're like no and so we're existing in like I feel perpetual cognitive
dissonance and I was kind of wondering what your take on that was and how yeah how do you deal with
it personally and how does a young person who's trying to sort of move forward in society deal
with that as well without and you know exist as a functioning member of society without sacrificing
maybe personal ethics and values even though I kind of I guess I know that I'm going to have to
compromise somewhere down the line
you as an individual probably can't solve those issues
probably not one of them let alone all of them
and you can't focus on it and really look at it and feel the scope of the current harm and
the possible harm and not be able to do anything about it and have continuing to look at it make
any sense so let's say that our social institutions were adequate as they were at previous points
to deal with whether they were adequate or not depends upon which group you were a part of
and which problems you were looking at but let's just take for a moment that for some things they
were adequate then if there was a problem you really wanted to solve you could think about joining
the CDC to work on pandemics or joining the military to work on terrorist mediated x-risk
or joining an intelligence group or whatever it was
if you look around and you see that the scale of the issues requires institutional solutions
whether they're state or network based decentralized autonomous organization or
whatever but but collective intelligence of lots of people not just a person
and you don't see anyone that is currently doing that then there isn't something you can join then
what do you do it's a tricky problem because there's a fairly small number of people that have
the right psychological disposition to try to found something of that type
right there there are a few people who are like either going to try to start a new type of company
or a new type of nonprofit or a new type of social movement or whatever
there's a lot of people that can contribute value to one of those that are probably not
going to found it for really not just developmental but typological reasons different typologies
orient to different things so to the degree that there are particular issues you care about
and you can find organizations that are doing a pretty good job that you could
join or participate with that's a good answer that's one it's something of an answer
to the degree that you feel like you have the typological orientation to make a new thing or
to be part of make a new thing to find other people that could co-found some kind of new
process whether it is trying to get an upgrade to an institution with existing government build
a new institution build a you know ethereum some kind of platform for decentralized autonomous
organization that maybe will create the future of governance via networks rather than nation states
right those are all possibilities for can i is there some new capacity that i believe
is needed that i could help to bring into being
so you either right like either you have to join something or you have to make something
or you have to join people that are interested where maybe somebody in that scene or some
combination of them will be able to make a thing and it's very hard to know that the thing that
you're focused on even if it's awesome is not adequate to the scope of issues you're aware of
and put all your energy into it and not not go nihilist or just anxious all the time right
so for a lot of people i would say
they should put their sense making into things that they feel like they have agency and or
could develop agency and that there's some relationship between their sense making and
their agency so let's say they feel like okay well i i don't know how to fix
AI AGI risk issues i don't know how to fix silicon valley attentionalism issues but i feel like if i
apply my sense making to the problems in my community i could actually help improve the
quality of life of my community i could bring warm data labs there and have the people start
really getting to know each other in a multi contextual way much better i feel you know that
kind of thing if a lot more people did that they paid attention to where they could have agency
applied their sense making there a lot of problems would get better and a lot of other people in
those communities would evolve to want to do things as well and some of them would have
different aptitudes and people communicating better would have better collective intelligence
and once you solve problems at one scale you get better at problem solving you might be
like maybe i can do this for a second community oh i've just figured out a generalized principle
maybe i can help create a way to do this for communities writ large all of a sudden it starts
to be able to kind of inductively scale to the scope of the problems so one thing i would say is
like one approach is just try to understand what the world needs without understanding what you
can do just take you out just what does the world need because as you come to understand
that better you'll start to have insights of what needs to happen and then you'll at least be able to
parse where are the places doing closest stuff what is nobody doing how do i help make that
happen right that's one approach though the other approach is what is the stuff i feel
like i could do and how do i apply my study to be able to do some of those things where then in
the process i can be increasing my agency to then possibly be able to converge towards doing more
stuff both of those are valid uh on their own and in combination
what i would say is like that you're increasing your understanding of the world that you're
increasing your sense of your ability to act meaningfully and that you're increasing both
the depth of care and the emotional resilience in the presence of that care simultaneously
are things you want to be tending to there's not one good answer for how to do that
but there are things you want to be tending to now we spoke briefly before the recording started
about the very real practical inquiry of what kind of jobs are there you know in the space and it's
if let's say working in extension catastrophic risk or some of the most important areas in the
world and pioneering new types of social technologies that both apply and combine
combine physical technologies if these are some of the most important areas but there's not really
jobs there's not financial incentive there and as you're focused on them there's like
more emotional difficulty and psychological difficulty associated with looking at like
looking into the abyss the incentive landscape is wrong for getting the people engaged in the
things that matter so institutionally we should try to fix that and say how do we start to put
incentive on the things that matter the most which the manhattan project did right which is why
i'm calling for manhattan project type things right and in some ways you can say ethereum and
hollow chain and other orgs are trying to do that so maybe some of elan's companies whatever
like we're taking on a problem and we're trying to be able to create a lot of jobs and incentive
to get people to be able to work on problems that matter
but the other part of that answer i i'll just share is
for me a big part of because i was thinking like there's a lot more people thinking about
x-riss now but i was thinking about it from quite young age i just knew i couldn't focus on anything
else and i couldn't focus on anything that wouldn't converge to being adequate it was okay if what i
was working on wasn't adequate it just had to seem like it was on a path of increasing understanding
and capacity that could maybe converge so i kept for most of my life my overhead as close to nothing
as i could keep it and figured out things that i could do for work that took the least amount
of time possible so most of my time didn't have any market need on it i didn't so most of my time
was self-directed study in these areas because that was the only thing i could actually do and
be congruent with myself so sometimes i did construction to pay the bills sometimes i did
teaching or i became a therapist and did different things but i kept my bills low enough they didn't
take that many hours and so that most of my time could just be allocated based on my intrinsic
orientation of what would be most meaningful which i highly recommend that path
pretty well thank you daniel um i think we're rolling to a close uh we've covered
a lot of ground it's been really an exciting conversation i hope we'll have a chance to continue
this another time it does seem that we are in something of quite a sort of incredible moment
possibly a unique moment we're facing a lot of daunting challenges uh and we're all trying to
grapple with what that means i guess for us personally professionally for me for me and you
know in the seminar room in the university in society in my interactions with my loved ones
but i guess it's also in some ways it's a time of opportunity as well it's kind of a cool to
adventure as you sort of said is there anything more important than really sort of putting your
shoulders to the wheel on some of these issues that we've addressed and yeah i just like to say
thank you for all of your work and i don't know if you have any final closing thoughts anything
that we haven't covered that you'd just like to to share with us to close it is a thought that
comes to mind that kind of following where we just were um one way i think about how to live
a meaningful life a simple but kind of elegant model is uh
we can think about life in the in terms of the mode of being the mode of doing in the mode of
becoming and if you were to describe the mode of being it is in the moment focused on appreciating
what already is appreciating the beauty of life as it is the mode of doing occurs in time and it's
focused on adding beauty to life if it's focused on anything else it's not the mode of doing very
well right most people are in the mode of doing doing shit that if they didn't do it the world would
be better um but the mode of doing that matters for a meaningful life is adding beauty to life
and or protecting serving the beauty that's there the the mode of becoming is increasing
your capacity to appreciate life as it is more fully and to add to beauty more fully right
increasing being and becoming and being and doing and so then there's a virtuous cycle between those
but the doing only matters and the becoming only matters because of the intrinsic meaningfulness
of being if like ultimately the meaningfulness is grounded in experience and the fact that
experience is just intrinsically beautiful the taking reality is intrinsically beautiful
so if you because of the crises you don't focus on that enough you'll actually get disconnected
from the source of what matters and then your your motivational complex will if if i
if i wake up so like i wake up i go sit outside with a cup of coffee and i look at the trees
and i just love watching the trees move in the wind and the clouds in the sky and just
like how beautiful this planet is how much i appreciate it and there is a fullness in that
mode of being that doesn't need anything so then i'm not motivated based on what's in it for me
because i already feel like i could die right now and i feel lucky right i feel like i have lived a
really rich full life so now it's not what's in it for me it's not some doing that i have to do it's
that i actually want to protect that beauty and i want to protect other people's ability to keep
experiencing it forever or at least for a long time because i can and because as much as i appreciated
other people do too or can and i that matters to me right like it's intrinsically meaningful
but that's a different come from it that it has a certain anxiety and angst and feverishness that
isn't there and it has a sacredness that is there and then there's also a courage of like maybe i fail
i mean maybe we fail right and life has been meaningful each moment it's not like it wasn't
meaningful like it okay maybe the whole thing comes this whole thing part of it comes to an end
at some point but i will do what i can to be in service to it but that service is arising out of
seeing it and loving it as is and then wanting to be of service from there
so i can be in the mode of being just kind of chill and watching tv i can be in the mode of
doing doing a bunch of to-do-less shit that doesn't really matter i can be in the mode of
becoming trying to get better at doing shit that doesn't matter
i want to think about am i engaging in each of those modes and am i engaging in them deeply if
i'm in the mode of being i want to be looking at the sky and i want to be listening to music i love
and be wrapped i want to be feeling moved by the beauty of life so why do the mode of being any
other way i want to be with friends that i love where i'm like yeah i could die right now full
and in the mode of doing i want to know that the world would be worse if i didn't do this
otherwise i go back to the mode of being just chill and enjoy it i want to know that the thing
i'm doing adds something of meaning somewhere right and the mode of becoming of am i am i developing
my ability to appreciate everybody and everything around me and am i developing my knowledge and
agency and capacities to add to it that's a good framework to think about you know when you
inventory your day and your week what being on track means wonderful well thank you daniel thanks
so much and if people want to engage more with you and your work your website is called civilization
emerging is that correct civilization merging is just like a personal blog where there's some
podcast and old stuff up there and you can check it out and the project that we're focused on that's
really just in the earliest beta phase right now um but that is kind of the project where we're
trying to bring the information forward that will help uh decentralize innovation of what
the new social technologies that can employ and guide exponential technology are that project is
called the conciliance project conciliance project dot org and that will get increasingly
interesting over the next you know few months yeah and i'm hoping that we'll have a conversation about
how i could contribute to that project super exciting and do i hope people will go and
check out that website excellent thank you daniel look forward to it picking this up again at some
point take care thank y'all it was going to be with the three of you thanks for tuning into
imperfect utopias to get access to all of our content and to stay up to date with future
zoom calls workshops and events and more check us out at ucl.ac.uk forward slash global dash
governance if you like this content please do leave us a comment and subscribe until next time
you
