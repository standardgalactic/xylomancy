Hi everybody, I'm Peter Morgan, so I represent a company called Deep Learning Partnership
which is an AI consulting company, so it's plain old deep learning for my bread and butter.
But today I'm going to talk outside of that into what I see as the future.
So here's a little book that I wrote for O'Reilly, it's free to download, so go ahead, machine
learning is changing the rules, there's my company website, there's my Twitter handle.
I tweet on sort of what I'm going to be talking about today a lot, so you can sort of keep
up to date if you so desire.
So what am I going to talk about?
So what is intelligence?
It's a good place to start, if we're trying to solve it, we need to ask what it is, figure
out exactly what it is we're trying to solve.
So I'll start by outlining what I think intelligence is, I'll answer that question today.
And then we'll look at physical systems, biological, non-biological, so the non-biological ones
being computers, silicon, that type of thing, biological systems being us.
We are what we are trying to model, this is it, we're trying to model the human brain.
And not only the human brain, but how biology does intelligence, how biology does intelligence.
The aim of my talk is to describe that and a system that might actually build it.
And then we'll do a quick recap, a very quick recap on deep learning, because I've just
tried to convey that biology isn't actually deep learning at all, and a lot of the talks
today, particularly the neuroscience talk I saw earlier before lunch, made that very
clear.
We're not deep learning won't get us to intelligence.
And I'll explain exactly why, well basically it's statistical and what we want as a physical
theory of intelligence.
So I'll go more into the physics and the neuroscience.
Finally we'll have a look at a theory of AGI, and I'll talk about that, so that's the very
end of the talk.
Without further ado, hopefully the clicker will work.
Why do we want to build AGI?
Well we want to solve intelligence, we want to understand intelligence, so we want to
build systems that we can use to do all these tasks and then make money from that, or just
do all the automate all the boring stuff, and ultimately if it's general intelligence
we can automate everything.
So then we've got to ask philosophically what do we do if we build these systems, and my
answer to that is we'll just get back to being more human.
We won't have to work in factories and production lines, and even though a lot of people have
convinced themselves this is what the true meaning of life is, I don't buy it.
So once we build it, it'll become more obvious what we'll have to do with ourselves.
We're going to get too worried about, okay.
I'm not a doomsayer, I'm not here to say, oh my God, the world's ending.
But the conversation at some point always goes there, so I thought I'd just get that
out of the way at the beginning.
So let's focus on trying to build it for the rest of the talk.
So what is general intelligence?
Are any of these, general intelligence, AlphaGo, AlphaStar, playing StarCraft from DeepMind,
and I've come over from London where DeepMind are based, the Google company, DeepBlue from
IBM back in the late 90s, IBM Watson, winning at Jeopardy, natural language processing, none
of those even close to general intelligence.
They do very specific things, they're completely dumb, they're completely stupid, they use
statistical methods, so no, they're super clever, it's like they can totally outperform
us just like a calculator outperforms us with multiplication, right?
So not dismissing it entirely, but it's not general intelligence, that's not what I'm
here to talk about.
That's what DeepMind does, it's not what I'm trying to do, although ultimately they do
want to do that, and they've said that very clearly.
But right now they're not doing it.
So what is intelligence?
Well here's the answer, it's not one thing, it's many things.
So it's basically we are agents in our environment, so it's our adaptation to our environment.
If we were living in a different universe with different laws of physics, gravity goes
up instead of down, we would be adapted to that, and so that would be our intelligence
would be adapted to that environment, okay?
So it's simply adapting to our environment, exploiting our environment, modeling our
environment and successfully predicting what's going to happen next in our environment.
If you think about it, it just kind of boils down, it's deflate everything right now, it
just kind of boils down to that, whether we're trying to win the lottery or build a rocket
to the moon, or even build journal intelligence, we're just trying to model our environment.
It just so happens that we're trying to model our brain, okay, with journal intelligence.
So we've done a pretty good job, you know, we've done, you know, the laws of physics,
we've had Newton, we've had Einstein, we've had Feynman, we've had some super clever computer
scientists, biologists, neuroscientists, but it's all the same thing, we're just trying
to model just trying to model our environment, okay?
So it's not just Einstein, that's not the only thing that has to do with intelligence,
it's spatially, you know, we have athletes, you know, that are way better than Einstein
at doing the high jump, right?
So he was crap at that, but very good at modeling general relativity.
But when it came to hurling himself over a high bar at seven feet, you know, he would
just fail miserably.
When the high jumper goes to solve, you know, to understand the universe right down mathematically,
he would fail.
There's not one type of intelligence, okay, there's many.
And that's what the G and AGI stands for, it's general, okay?
So we're trying to build things that are spatially intelligent, aware of the environment, we're
not doing a very good job there, are we, with climate change and everything like that, Donald
Trump, blah, blah, blah, right?
So, you know, that's, for me, is a big part of intelligence is to understanding our environment,
not destroying our environment, but, you know, kind of living in harmony, that might be a
definition in naturalist intelligence, not getting too political, but, you know, that's
what I believe.
Musical, you know, Mozart, Beethoven, the Beatles, whatever type of music you like, and
I've managed to turn that off, that is a type of musical intelligence.
Not everyone can create, write a beautiful melody or a symphony, but some people can,
right?
These are all the different types of intelligence, linguistic, you know, Shakespeare, or, you
know, who can write a great poem, et cetera, et cetera, interpersonal people relationships,
how we relate to one another, social intelligence, emotional intelligence, introspection, how
we understand ourselves, you know, how we react in society, how we go about, you know,
place in the world, and then you build it up hierarchically into nations, you know, do
we go to war, do we not, I mean, how do we keep peace internationally, these are all
different types of intelligence that these machines will have to do if they're truly
general intelligence, okay?
So it's not just the building the Einstein, you can see that now, it's everything.
It's physical, it's political, it's social, it's emotional, okay?
A big ask, a big ask, but we do that in three pounds in our skull, right?
So biology has done it, using 100 billion neurons, roughly, somebody said 86 billion,
but it's of that order of magnitude, and perhaps it's the connections, 1,000 to 10,000 synapses
per neuron, so it's a very complex system.
So it's no wonder, you know, we can't give ourselves too hard a time, that we haven't
built it yet, because, you know, it's complex, and also, you know, the US 4 billion years
old, we've had a few years, okay, we didn't just come up with this stuff yesterday, you
know, we can go back 10,000 years, 20,000 years, we were pretty much living in caves,
right?
It's only the last 100 or so years that we've kind of, you know, hit this exponential where
we're taking off, and the singularity is there, and all that kind of stuff, right?
So we're living in very interesting times, but this is where intelligence has brought
us, and this is where we are, we're sitting in this conference talking about it, right?
We wouldn't have been doing this maybe even 10 years ago.
Okay, so we're ready to build it.
How far have we come?
I would argue not very far.
We've, all these talks we've seen today have all been about deep learning and statistical
methods.
The best we've done, I think, is around 50% for logical, mathematical, linguistic.
The last talk was on BERT, it's super impressive stuff.
There's GPT2 with open AI, there's BERT with Google, you know, Facebook, Microsoft, everyone,
all the big tech companies are plowing ahead with these statistical methods, but there's
nothing to do with general intelligence.
So, you know, statistics will only get us so far, right?
And in fact, when it comes to introspection, thinking about the universe, they're actually
zero, they're not even off the ground, okay, they haven't even started, haven't even begun,
and they never will do because it's, statistics won't do it.
Physics will, statistics won't.
I'm not trying to discredit anyone here, I'm just trying to focus on general intelligence,
okay?
Okay, so how will we get there?
Well, it takes a village to create an AGI, just as it takes a village to raise a child,
right?
It's going to take a village to build these things, so it's not just physicists, it's
not just computer scientists, it's not just, you know, psychologists, it's all of us together.
So it's neuroscientists, psychologists, physicists, computer scientists, everybody, politicians,
because this is general intelligence, we need everybody in the room together.
Okay, so what, you know, so physically, you know, biology, biologically and non-biologically,
let's have a, take a look at, you know, how, how physically intelligence manifests, okay?
So biology, very clever, we start with bacteria, no, no central nervous system, no neurons,
nothing, and yet they survive, they reproduce, they're intelligent, okay?
Maybe they'll survive longer than us, the rate we're going, I'm not putting my bets
right now.
So, you know, that is intelligence without even a single neuron anywhere to be seen,
so they're using chemical gradients, they're just using the laws of physics to wiggle and
wobble about, but they've learned how to reproduce, create DNA and reproduce.
They haven't learned anything, right?
That's an anthropomorphism, you know, this is what the laws of physics can do and has
done, you know, in terms of biology, the first thing with the central nervous system is the
C. elegans, I think it has 130 odd neurons, so arguably this is the dumbest thing with
the central nervous system, so, but yet it can, you know, understand, it can survive,
it eats, it reproduces, the bumblebee has about a million neurons, this is how biology
does things, it can navigate, it does its wiggle dance, it's societal, it lives in a
society and right up to us, the brain, the human brain, in fact, you know, you've got
all the mammal, elephants, fish, chimpanzees, us, right, so there's a whole spectrum here
of intelligence, you know, assumably we'll start with the, you know, the simplest systems
and build up, but is there something here that unites all of these systems here, you
know, because I'm interested in understanding theoretically what intelligence is, in other
words, you know, writing down the mathematical equations that we will use to guide us when
we build these things, okay, not just sort of trying, does this work, does this work,
I'll add another neuron, another layer to my deep neural network, I want to understand
the basic physical, the physics of intelligence, or, you know, we do as a community, the AGI
community, okay, so the first thing we notice is that biology is hierarchical, we start
off with atoms, they're certainly not intelligent, molecules, neurons, they're not intelligent
unto themselves, but when you start connecting these things together, the connectome, then
intelligence emerges from there, and then we have us, you know, agents, and then we
have societies and nations and finally the world, so, you know, the whole thing is hierarchical
from atoms up to nations, so this general theory will have to explain the whole lot,
okay, so it's a big ask, right, we're actually trying to describe the whole thing and not
just bits of it, okay, so just to kind of sort of expand your mind, put it all in perspective,
so we're coming up with a truly general theory of intelligence, and that's what a neuron
looks like, it's super complex, do we need to go to this level, you know, there's a
lot of open questions, we don't know, we'll see, okay, we'll just see, nature does clearly,
because that's what a neuron looks like, but when we build these systems will we have to,
it's a very, very, very interesting and open question right now, okay, but it won't stop
us perhaps coming up with the underlying theory, so this is what a brain looks like, this is
what intelligence looks like, it's organized into structures, repeating structures of about
two million neurons in these so-called cortical columns, again and over and over and over
again, so if somebody goes blind, God forbid, that some of those neurons that we use to
process visual information are quickly repurposed into processing sound, okay, so the kind of
general, there's a generality there, these are just information, these are information
processing systems that seem to have some sort of generality, so we do know that, that's
something we do know so far, and I'm going up the hierarchy here, here's the connectome,
so it's all connected, besides these tens of tens thousands of synapses between each neuron,
these things are organized into some larger, if you go up one level in this hierarchy,
then you start to see this connectome forming, whether that's in humans or even bees, you know,
there's this layer above the neurons that maybe that's the right layer to start with, okay,
and then above that, then that's attached to a central nervous system and all living beings,
a fish, a bee, a human, so, you know, it's not just a brain and a jar, although, you know,
some might argue Stephen Hawking was kind of that, because he had that terrible disease and
there are people, so we can function like that, but we're really interested in building the whole
physical as well, but the brain is the main thing, once we've cracked that, we've cracked
intelligence, I'm just saying, you know, we connect it to the rest of our system, we have,
do we need kidneys? I doubt it, I doubt we'll have this thing, a system with kidneys and lungs
and everything else, right, but that's how biology has done it in every single thing,
so there's this other part, 90%, you know, which I think we need to worry about the brain more
than the rest of it, but the rest of it's super clever, but kind of clunky, it's just, nature's
put us together like that, we may not need to go down to that, consider that so much, but if we're
building robotics, we will, but a robot might not have kidneys, but all have, you know, it needs to
have, be able to move around fluidly and we haven't quite got that yet, even though Atlas, it does
nice backflips and super, I mean, it's getting pretty good, isn't it, every month, you know,
Boston Dynamics comes out with a new video, it's like, oh my god, it's like so human and then they
up, they beat themselves, but it's not, it's not intelligent, you know, it can't play chess,
it can't, you know, ponder the universe, its own existence, it doesn't even know it's alive,
that's how dumb it is, but it's very good with the physical part, okay, that's all part of
intelligence, and then the social systems, we talk about cloud robotics, form robotics,
social intelligence, that's the final layer, okay, so here's what, here's where we are with the
non-biological, you know, we've started off with CPUs, the von Neumann architecture we've heard
about today, separating the processing from the memory, and then we've also heard that
biology doesn't do that, it does the processing and the memory on the same thing, Neuron is
both a memory and a processor, so none of these, there's this little von Neumann architecture,
okay, so that's what it looks like, it's beautiful, we saw a picture of a TPU version three in the
last slide, it's like a supercomputer, it does like a petaflop or something or more,
Graphcore, there's a hundred petaflops in like eight racks, you know, that's it's a world's most
powerful supercomputer, almost, not quite, but it's getting up there, so these are A6, they're
specifically designed to multiply huge matrix, billion by billion matrices together, which the
brain isn't doing clearly, and you know, that's how many times bigger than the brain is that,
right, it's got nothing to do with general intelligence, but it's super good at multiplying,
it's good at linear algebra, it'll statistically, you know, calculate things, that's why Bert
will get statistically brilliant, but it'll never understand Shakespeare, because it can't,
because it's linear algebra, right, linear algebra doesn't, doesn't do that, okay, and there is the
world's biggest, it's 3x a flop, it's summit, chock full of GPUs, and I think AMD processors,
super impressive, but it's as dumb as a brick, right, doesn't do anything, it's a big calculator,
so what are we missing, so we do all that in three pound, right, we don't need a three, three
football fields or 10 megawatts, we need a couple of sandwiches and apple and a drink,
you know, and we can discover the laws of the universe, okay, so clearly we're not even close
by any of those other approaches, maybe one approach in hardware is neuromorphic computing,
which stated aim is to replicate the brain, okay, in hardware, and so there's a project
called Spinnaker, part of the human brain project, which is doing that, Steve Furber, who was part
of ARM, based at the University of Manchester, been working for the last 20 years, he's built,
the team there have built, now under the wing of the human brain project, have built, I think,
a billion artificial neurons, so they're analog, they process the information using analog, not
digital, and it's more, it's not the von Neumann, it's kind of combined, so they call that memristors,
where the memory and the processing is combined in the same place, and the architecture looks
completely different, there it is, that's a billion neurons right there, so immediately we see, you
know, it's a little bit smaller than the others, that's all analog computing, and that's what it
looks like, so yeah, we start off with a thousand neurons per core, and then we put them into chips,
and it's hierarchical, then we put 48 chips in a board, 24 boards in a rack, we have 10 racks,
right, and that's sitting in a data center in Manchester today, and you can log in now, if you
want to, set up an account, log in and start processing stuff using neuromorphic computing,
and you can put in the MNIST data set, you can play Sudoku, you can play chess, and it doesn't do
deep learning at all, it's processing it with neuromorphic algorithms and hardware, okay, so
for me this is definitely a step in the right direction, so hardware is important, it's not
everything, obviously the algorithms need to be there as well, but I think we need to be running
on the right hardware, otherwise it's a simulation, you can always simulate anything on a chip, but
you need, you know, they've done that in the human brain project using, you know, the von Neumann
architecture, I think they processed a second of what the brain can do, it took them like a week
in, you know, the whole data center, so you know, you can always simulate things, but it's not
efficient, so you can actually simulate in real time using this neuromorphic architecture, because
it runs efficiently like the brain, I think it's about a thousand times less efficient in biology,
whereas the CPUs and everything else that we saw digital is about a million times less efficient,
so it's definitely a step, and this is the first generation, so we're going to iterate just like
we did with the CPU processing and the digital, we've had 50 years, we've got 10 billion transistors
on a thing a centimeter big, right, so we'll do the same with neuromorphic, we'll have generation
upon generation, and soon we'll have 100 billion neurons, because it's Moore's law, it's exponential,
and we will see, you know, sort of human level intelligence, whether it will be sentient and
is down to the algorithms actually, so I think we have the hardware, we're at the very beginning
of this journey with the hardware, but we need algorithms, so let's look at the algorithms, so
that's another one, the brain scales, that's the University of Heidelberg here in Germany,
that's part of the human brain project as a spinnaker versus a Google TPU, so I would argue the
one on the left with neuromorphic is the right hardware to be working on for general intelligence,
okay, and there's quantum computing, nothing to do with how the brain works, but you know,
sexy pictures, so I put it up there, and it is like the last form of computing, right, you cannot
forget it, it's a big deal, it's going to come online, but I don't think it will be, you know,
used to, you know, understand nature too well, I think biology doesn't use it, so I doubt we
have to go to the quantum level, but the quantum will be very important in other aspects, perhaps
not general intelligence, okay, so there's the four summary of everything I've talked about,
the four different types of hardware, the digital, the neuromorphic, quantum, and then biology, right,
so we want to try to build a thing in the lower right hand corner here, and I think neuromorphic
is getting, that's the way we'll do it, and that's what they look like, okay, so the brain,
you see the similarity a little bit, the neurons in the brain, the digital, the neuromorphic, and
quantum looks a bit out on its own weird, but ultimately it's these little units of information
processing, okay, and then the data center of the future won't just be classical computing,
it'll be a mix of quantum, neuromorphic, and classical, so deep learning, quick recap,
that's what it looks like, this is what general intelligence isn't, so it's not that, it's not
that, and deep learning is not AGI, so AGI is linear algebra, so you're just summing up the
weights times these vectors and billion by billion matrices, it does not give us a neuron,
absolutely, not even close, but never will do, and it was never meant to, to be honest, if you
talk to the researchers like Jan Lacoon and Jeff Hinton, we're not trying to imitate the brain at
all, we just found the stuff that works really well, but, and then Jeff Hinton, he's in my last
slide, says that, you know, if we think really hard about how nature does it, biology will,
that's how we're gonna do it, and he's recently said everything I've ever done on deep learning is
sort of, I'm gonna have to put that to one side now, because to get to the next level, and I saw
a slide in some other presentation today, you know, it's exciting to get a bit mainstream now, you
know, deep learning is running out of steam, you know, we can maybe tweak the knobs and get another
two or three percent of accuracy, but yeah, where do we go, it's not general, it's very specific,
it's not gonna give us those nine types of intelligence, and I think that's what people
are trying to say, you know, they don't quite realize perhaps what they're saying, but
that thing on the left is what we're trying to build, not that little bit of linear algebra on
the right, okay, so what is the theory, okay, you know, I'd be, I could just walk off the stage now
and say, huh, you know, we don't, I don't know, thanks for coming, you know, spending all your
money, but I'll try, I'll try, I'll give you something, a bit more than that, so let's see,
so I mentioned earlier that it's not statistical, right, so what is it, it's physics, right,
everything is built using the laws of physics, so why not the brain, right, why not, let's start there,
nice and simple, so what do we know about physics, right, well we know Newton's laws,
we know relativity, we know general relativity, we have Maxwell's equations from last century,
we're standing on shoulders of so many giants here, Maxwell, Newton, you know, all the greats,
Helmholtz, Boltzmann, Gibbs, you know, we got the laws of thermodynamics,
we got quantum mechanics, we don't think we'll need that, but we still have it, we have relevance
at quantum mechanics, we have dark energy, we have stuff we don't know, dark energy, dark matter,
we're probably not involved with intelligence, the thing is that all of that can be encapsulated
in something called the principle of least action, which says that nature behaves to minimize the
free energy of any system, you know, whether that's microscopic or macroscopic, whether it's a millisecond,
a nanosecond, or the age of the universe, there's this fundamental underlying principle of physics,
if you did a PhD in physics, who did a PhD in physics? Yes, so a couple of people here will
have seen this principle of least action, and you write it down, it's a nice beautiful formulation,
you can write it down in Lagrangian or Hamiltonian form, but it's, you know, one line, and you can
use it in principle to describe any system, okay, I say in principle because, you know, nature is
complicated, you know, the brain's complicated, as soon as you get more than a few atoms, you know,
or a few molecules, it's hard, right, so, but in principle this is the underlying principle,
so that's where I'm going to start, right, with the theory of intelligence, I'm going to say if we
can use it for everything else, then let's apply it to the brain, see how far we get, that's what
it looks like, there's a beautiful book just written, I think, yeah, last year at Cambridge
University Press, surprisingly there's nothing else before this, because it's been around about
at 100 years, it's called the principle of least action, it's got all the different examples in
the world of thermodynamics, classical mechanics, steam trains, computers, digital, quantum,
everything, chapter on each, how it's applied, how it's applied, how it's applied, how it's
applied, so they need an extra chapter on how it's applied to the brain, I think, but that's what
it looks like, you know, that S is the action, the Q is the momentum, T is time, and Q dots,
you know, the d, dv, dt, the change of momentum with change in time, and delta S equals zero is
all the physics, it's the change in action, nature acts so that that delta S, where S is the action,
is, it tries to minimize that quantity where S is that in terms of Lagrangian, okay, don't worry
about the math or the physics, we're not going to go there, but so let's apply that to the intelligence
and see how far we get, because it works for everything else, okay, so again, it's not just
about pattern recognition, it's about modeling the world, okay, we model stuff, we can imagine,
we can problem solve, we can build new models, we can understand, right, we don't just do statistical
analysis, otherwise it'd be zombies, right, or we'd be a silicon chip, we'd be built in an
Intel factory and we're not, so here are some theoretical approaches, I'm going to choose
the Friston active inference one, which uses the delta S equals zero, the others don't, but these
are, these are very, very, very, you know, credible attempts at general intelligence, and all of these
people have been working at least 30 years on these theories, so they're certainly not to be
dismissed, and let's pick this one and just, all the others are wrong, there's going to be bits of
each that kind of have some, there's going to be overlap, so you know, we've, Helmholtz started
with statistical physics, right, it's, the brain is 100 billion neurons, it's a big messy, warm,
complex system, so statistical physics is over 100 years old.
I don't want to rush you, but I've gone, I said you have 30 minutes here, but I've gone before
democracy, I know an XP is already... Oh, okay, so I will wind it up, yeah, let me wind it up, so
yeah, 30 years for all of these, right, I'm going to pick Friston in the last two minutes,
okay, now active inference, we can look this up, again it uses the free energy, it's minimizing
the free energy, let me just flick through and then I'll, I'll, I'll sum it up, there's Professor
Friston there, and we, we don't have time to hear, so this is what it looks like, we can draw diagrams
and pretty pictures, we can write down equations, we can have me, us in the environment, the environment
acting back on the agent, the agent acting back on the environment, all the physics is in place,
we can write down the equations for it, we can do it for bacteria or the brain,
so it works on all systems, there's the math, it's super, super ugly, but it's, you know, it's,
that's theoretical neuroscience, and this is, that's the equation of, that's like the general
theory of relativity for, for the brain, right, so there you saw it, he's got loads of papers,
can we build it, I say yes, we have the data, we have the theory, we have the algorithms,
and we have the hardware, okay, and there's some AGI project, there's Merrick's here, Ben's here,
there's a, Jürgen Schmidt-Huber's not here, these are all super clever people doing super clever
things, and I picked our active inference, it's one, because I feel it's the one most based on physics,
and I'd say we're at the beginning of our journey, it might take us five or ten years to sort of
build us, as we wait for the hardware especially, to mature, I believe we have the algorithms,
it's a super bold statement to be saying, but I encourage you to read some of the papers,
and there's Jeff Hinton saying at the very end, you know, this is three years ago,
the conceptual breakthroughs will take us, we need new conceptual breakthroughs,
I believe the breakthroughs are going to come when we understand the brain, thank you very much.
I'm so sorry for being so rushed, I also would like to know more, Mara,
can I steal five minutes of the Q&A, so like for just one question, I know that he overtake,
he's going to make it up to you. Okay, one question. He owes you five minutes of lifetime,
yeah, I'll make sure you get that. I do, I do. Five minutes of your lifetime to him.
Thank you so much for the question, sorry for your time, just in taking one question,
so I'm just going to be very quick to keep on schedule, so I'm going to just speak in
very short words, so Richard Feynman, you know, you've been a music producer,
besides all your other work in the academia, and you shown us a great slide where you said,
for AGI we need computer sciences, physics, neurosciences, and psychology, so bringing
these four things together, I mean the question is, and you've been in academia, in our society
every incentive is to be very specialized and to really focus on one subject, and then people don't
talk and connect enough with each other, and I think we need that for AGI, what are you doing,
or what can we do as a society to bring these four groups together, is there conferences to
exchange with those four groups, I mean how do you get these different people, these different
tribes talking with each other? Is that the short question? Is that the short question? Well,
it was a long question, I hope he has a short answer, but yeah, okay, yeah, so Professor
Friston's group's a neuroscience group, it's a theoretical neuroscience group, they have very
strong mathematicians, very strong computer scientists, DeepMind's a bit of a, you know,
case study in this, they get neuroscientists, computer science sitting in the same room,
so it's the very beginning, but I think you need more, I think you need psychologists,
yeah, so we need a little bit more input from other science sectors to begin with, and yeah,
I mean it's, yeah, I mean ultimately you have to build these things, the theory is going to come
from a very, very strong scientific, mathematically competent person, okay, you can get all the
psychologists talking in a room and everybody else, but ultimately someone or a couple of people
have to write down a scientific theory, just like Einstein wrote down the theory of relativity,
so maybe I was a little bit generous, you know, we need everybody, we need the ideas from everywhere,
but the actual person himself or herself is going to be, have to be super strong a math,
we saw some of the math, it's not simple, it takes a while, right, it's a huge, just like the theory
of general relativity and I'll end here, you know, we can understand the concepts, but the actual math
is really, really, really hard, right, I don't know if you've ever tried it to solve the, no,
the field equations, I have, they're not easy, right, yeah, so don't expect this to be easy,
it's going to be simple, but the math is still going to be, you know, hard, okay, yeah, that was
it, okay, thank you. Okay, Peter, one more question, where can we find your slides,
are you going to upload them somewhere? Yeah, I thought the conference was going to upload them,
if not, then my slideshare, if they're available on my slideshare, so if you go to slideshare and
just Google Peter Morgan, I guess, you'll find him, okay, I think that's the best way, and the
other thing is just to look at Carl Friston, he has a great website with all his papers,
which is super heavy going, but if you're really, really, I don't know, you know, if you really
believe you want to try and solve intelligence, that's the best place to start.
