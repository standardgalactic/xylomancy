Okay, wow. I don't know what happened there. Guys, I hope that the stream just cut, so
I don't know what happened. I apologize. I hope everybody gets back on, but like I said,
please hit the like button. I don't know what that was about. I know. Yeah. Hopefully it's
back guys. Please comment in the chat if it is back. Yeah, it should be back. I don't know what
happened, but yeah, that sucks. Dang, we were doing good there. I'm gonna have to, this is gonna
have to be two-parted, but we'll continue. Like I said, please hit the like button. This definitely,
you know, hurt the momentum of the stream a bit, but I was unfortunate. I don't know what
happened. The internet cut or something like that, and it's been doing that a little bit lately,
which is unfortunate, but hopefully it's back. Comment in the chat if you can hear me. Please
hit the like button. Help boost the stream again, and we will get right back to it. But we were
talking about just how perspective can change your abilities and how you interact with a system
of information and how that can help. But yeah, that was very odd. It's back. Good.
Yeah, sorry guys. That is technology. Cool. Five out of five. We're back. Good. Thank you,
memes. Like I said, please hit the like button and help boost the stream back up. But I do not
know what happened, and we will continue though, because this is a good stream, but now it's two.
So this next clip is about intelligence, and what is the definition of intelligence? And I think
that there's a lot of good points made. This is what people often react to when they object to
these kind of statements. You can just paint that on anything. You can say anything. Here's a ball
rolling downhill. Look at that. It's not amazing that it gets to where it's going. Cool. So that
isn't what I'm saying. What the TAME framework says is that all intelligence claims are engineering
protocols. That when you tell me that some particular system has a degree of intelligence,
what you really need to tell me is what's the problem space, what are the goals that the system
can achieve in that problem space, and what degree of sophistication can I assume that the system
is going to have on its own without me micromanaging it? Those are the three things that you are really
telling me when you say, so if you tell me it's a bowling ball on a hill, what I hear is it's not
zero competency. It actually has a little bit of competency to minimize things like the total
energy and all that kind of stuff. But I also know that if I want to change the way the ball
rolls, I'm going to gain zero benefit by thinking about internal state, how does the ball feel about
this landscape? That's not going to be a useful way for me to go. And the only tools I have are to
modify the actual landscape. So I can put in bumps or I can push the ball or something like that.
It does have a little competency that I don't have to push it down the hill. It will find its way
down, but really all I have is these kind of very low, very low agency ways to track it. On the other
hand, if you tell me that what you have is a mouse on a hill, now we have a different story because
now I know that well, the tools I was going to use for that bowling ball kind of useless. And what I
really need to understand is what is the behavioral landscape that the animal is seeing? What are the
things that attracted? What are the things that repel or scared? What are the things that it remembers
about having been here before? In other words, when I want to change that system's behavior, I need to
do a lot of thinking about what are the internal states of that system and how it sees the landscape.
It's not how I see the landscape that matters. It's how the system sees the landscape. And so that
tells me different ways that I can interact with it, right? And different ways I can change the
beliefs. And all the way up to humans and so on. So that's the sector of cognition that we'll talk
about in the team framework. So the idea there then is that when you say that the body is intelligent,
what you're really saying is, are there ways to interact with that aspect of it? And I really
don't make that much of a distinction between brain and body. I think they're very tightly linked.
But the question is, do I treat this thing like a dumb clockwork? Or am I better off assuming that it
has certain autonomous capacities? Does it have memory? Does it have homie-aesthetic properties
that I don't need to micromanage? The nice thing about your term is that you don't have to push it
all day long. You just set the step point and you leave it alone. And so what do I need to know
about this? So that's how I see all kinds of intelligence and agency statements as engineering
protocols. Okay, so what's interesting there is that he used a specific term that's very important,
which is that that term goal. Without a goal, there is no such thing as intelligence. Intelligence is
ability to competently interpret information in order to achieve a specific goal. That is what it
is. And that means that you have to have a goal in order to have intelligence. And if you have to
have a goal, then I would say that you must be a sentient being. There is no way for intelligence
to exist outside of sentience. Somebody said on Twitter the other day it was an AI researcher,
I forgot who it was, and he said that it might have even been the guy who created open AI,
Sam Altman, I think. And he might not have been though. And he said that intelligence
is an emergent property of physics. And I think that that's nonsense. If it exists,
it is an intrinsic property of existence. But it might be that intelligence as a scale is emergent
as a growing, you know, the complexity of intelligence is emergent. That's true. But the
necessity of a complex intelligence is also emergent. Because the simpler existence is,
then the simpler it needs to be, an intelligence needs to be to be said system. So it doesn't
really make much of a difference to its ability to know and understand things. People say this all
the time, Timmy, they'll be like, you know, how can God, how can there be more? Does God know
everything or can God learn? And it's like, this is the same exact kind of question of can God
create a rock so heavy you can't lift it. It's a bad question in that the organization of the
question doesn't have a good answer. The reality is, is that God knows all that there is to know and
also can create more that he knows. So as he creates more, he knows more, but he still always
knows everything that is. So it's, it's different from us. And that's why it's hard to understand,
not because it's so complicated, but because it's super simple. It's like, it's not just simple,
it's beyond simple. It's, it's, but it is different than us, where we, there are things that exist
that we don't know. Whereas if you're the system of existence itself, and you are sentient intelligence,
and then you will know everything that exists, that could be known. And therefore, it would
actually be part of the motivator in order to create more in order to learn more, because
you can't learn anymore within the system of existence that exists in the, in a current exact
moment. So therefore, you have to add more to existence in order to learn more constantly,
forever. And it, that's a fascinating idea. But it also seems to be inevitably logically,
in, you know, the case. So like I said, audio reverb is, is that still happening?
Is there an audio reverb? Yeah, let me see.
It seems, it seems like it's working. I just checked it on my phone.
Let me know in the chat if it's, if it's resolved. I might download these and edit them together and
repost it as a single thing, because I'm frustrated with the fact that this has happened. And it was,
we were doing great. But like I said, please hit the like button. It helps fuel the algorithm. And
we definitely need it now that, you know, our momentum was killed by something. I don't know
what happened. But yeah, next clip. Intelligence is, it's gold dependent. And which means it's
only sentient beings can be intelligent. This is, this is why I don't like the term AGI. And,
and I call it a technological sentience. It's because
you cannot have a general intelligence without sentience. And the reason for this is, is actually
something that maybe we'll get to next, but
here. Next clip.
This next clip is on the
paper. It might be the, I don't remember this one, but it might be the limits of agency.
One of the first figures on the spectrum of persuadability. And, you know, again, it's all
about engineering protocols. It's all, if you want to persuade that system to do something,
how do you do it? Do you do it the way you would with a mechanical clock by rewiring the hardware?
Do you do it like you would with a thermostat by changing the set point? Do you do it the way you
would with a, with a dog or a horse by giving it awards and punishments for specific behaviors?
Or do you do it like with a human by, by giving them actual cogent reasons for them to do things?
So, so, so, so I, so we construct this kind of, and of course I'm not the first person that could
try for this kind of, um, uh, uh, spectrum of, you know, Wiener and Rosenbluth and Bigelow did this
in like 1943. They tried for one. And, and, and before that, that William James talked about this
kind of thing before that. So, so the thing about those kinds of spectra is that the natural question
is, well, where's the bottom of it? So, what is there a bottom of it? And if there is, and most
people assume that there is, and most people put the, put it, put it pretty, to me, quite, quite
far. The thing actually, you know, people talk about, people have, have concerns about plant,
um, you know, plant agency and, and, and insects and things like that. So far off from where the,
if there is a zero, there's so far off from the zero that it's, you know, it's completely wrong.
But, um, but do you mean they're so far close to zero? No, no, no. I mean, zero should be this,
yeah, yeah. I mean, we have, we have so many things, so many interesting things to worry about
that are really minimal compared to that, that plants and other things are like,
to me, of course, of course, they're on the spectrum. So, so, but okay, I'm, I'm being told
that there's an audio reverb. I'm so frustrated with this, but, um, uh, this basically, so I'm
going to cut it for now and we'll see what's going on. Um, but, uh, it, it seemed to be doing fine.
And then I can now hear it, um, when I checked, but, uh, it, what is being said here is they're
looking for to see whether or not there is an, a limit to the, uh, to agency, basically, where,
at what point does there appear to be no, um, no agency in existence and, uh, and agency in this
case is being specifically defined, which there's nothing wrong with this, but it does, um,
you know, change the way that you have to approach this. Um, it changes it from a non fundamental,
you know, kind of a pro question to a, or from a fundamental question to a non fundamental question,
which is that, uh, agency is the ability to persuade a system. Um, uh, and the more easily
it is persuadable, the less agency it has. I actually think that this is true. Um, and
it, but I'm not sure if I would describe it like that. Um, I use the term agent, but, um,
but I also think that maybe it is the right term. But there is something to this. There is a
relativistic, uh, aspect or approach or perspective to agency in which this does make sense where
the definition would be how in, how reactive are you versus how self motivated are you kind of,
and how easily persuadable are you by external, um, inputs versus your own internal goals. And,
um, and then there is also this kind of more, uh, objective or, um, super subjective, not, not
relativistic, uh, leveling of agency that has to do with degrees of freedom and constraints due to
available perspectives that you, that one, that an agent or a sentient being would have,
which is different than, uh, kind of a sliding scale of agency that you have, which is like this
relativistic, um, uh, aspect to it. And so this, this is not an idea that is, uh, it is an idea that
is, it's not the, it is, it's not one that my work attempts to address, but it is one that,
you know, seems to fit within my work, which is just that there is, uh, it's kind of like evolution,
uh, which people talk about macro and micro evolution. There is a macro and micro evolutionary
impact of agency, which is exactly macro and micro evolution. They use these terms in the,
in the, uh, interview with, uh, Steven Meyer and, and, um, Joe Rogan, which I, I'm not really a big
fan of these two terms because they both depend on size in a way, but, uh, or seem to be interpreted
in a size, in a size context. But, uh, what it, what it is is that, uh, there's a, there's a level,
objective levels of sentience or of evolution. There's a jump between single cells and multicellular
organisms. That is an objective jump. There's a jump between molecules and to cells. That is an
objective jump. But then there's also, once you get into cells, there's a bunch of different kinds of
cells that can evolve in a space, uh, and, and look different and have different, you know,
features to some degree. Same thing when you get into multicellular organisms,
they can evolve different features and different traits of fish versus, you know,
a monkey or something like that. That is not the same as, uh, single cell, um, you know,
bacteria to, um, you know, a worm. That's, that is a, that's a jump that is objective and do,
comes from a specific pattern and, uh, and a changing in perspectives and degrees of freedom and,
and, um, uh, and also comes from a relationship based approach to an assembly structure of,
of all the participants within it. And, uh, we'll get more into that another time, but they do kind
of get into it in this stream later. Uh, but then there's also, uh, just this kind of scaling,
not scaling this, this relativistic, um, scale, I guess you could say sliding scale type of
scaling versus leveling type of scaling. And, um, that is within each level and that
the agency, the amount of agency that an agent would have on each of these levels
could be defined in what he's saying, which is that how, how
much are you subject to persuadability by external, you know, incentives versus, um,
how much are you, uh, kind of self motivated, how active versus reactive are you? And, um,
this is, uh, this brings up all kinds of fascinating, you know, uh, relevancies to things like
gender and stuff like that. But, um, uh, so it, it seems like agency you could say is multi-parted
and, um, there is a leveling aspect to it, uh, and also a sliding scale aspect to it that is
within relativity. Um, and that is kind of an approach to evolution that my work is eventually
kind of putting forward, uh, which is there's, uh, I call it, um, uh, replication and stacking.
And, um, these are different levels of, uh, sentience. So, or different ways of sentience
is grown. So there's a stacking aspect to it, which is changes the level of agency.
And then there is, um, in an objective sense, and then there's replication kind of
process to this growth, to the, to growth, um, uh, that is where relativistic, you know, um,
agency differences would be kind of more manifested. So, but, uh, I see more people
have jumped back on the stream. I hope it's better. Uh, please comment in the chat, Tyler,
would you be like, um, running versus writing one's own code? Um, would that be like writing?
It will, may, I think so to some degree, or be like, um, it'd be like how aware are you of your own
code versus, um, versus not being aware of your own code as you are running it. So, um, as it's
running on you. So that's, if that makes sense, um, are you aware of what impact your instincts
are having on you and your actions are having on you versus, um, versus not and, um, uh, but that,
that has, would have to do with agency to some degree, but it would also have to do with
how your programmed to how your goals are programmed to arise in some way as well. And
I will say that all of us have a code which is instinctual and, um, and that that code,
that instinctual code is, uh, its impact on us is contextually dependent. Um, it, it, you know,
the things that motivate you to eat sugar are good in a specific context of, you know,
where sugar is scarce and, and, um, but when you end up living in, you know, technological world and
you can go to McDonald's or, you know, get a milkshake whenever you want for a dollar,
the same code can end up negatively impacting you and, um, uh, and so I guess agency would be
to some degree in the way that Levin is talking about it is kind of related to how aware you are
of that. And, um, uh, so it's, it's a bit tough because there's multi, this is, there's multiple
parts to this system of growth and, um, but at the same time we're, we have not nailed down
universal ways to use certain terms. Um, uh, and so the way he's using agency or agent
is not exactly the same way that I used it, which is not exactly the same way that Donald
Hoffman uses it. So it's a little bit, um, it's a little bit tough, but, uh, I want to
play another clip, but I don't know if this is, um, the best, um, uh, you know, thing to do. We'll
try it because I know that it was having some reverberation, but we'll see here. Let me see.
We'll try this. Let me know in the chat if this, if it's having reverb issues.
Question is, uh, is there a zero? And if there is a zero, what does it look like? And so I, I
don't, I, you know, I don't have a super firm conclusion on this, but I tend to think the
answer is no, that there is no zero. And I'll tell you why. Um, let's imagine for a moment,
and this is an exercise I recommend to everybody and anybody who thinks that, uh, well, of course,
I have it, whatever it is, you know, it's a cognition. I have true, I have true agency,
whatever that is. I've got it. And, uh, you know, definitely, um, this, this rock here doesn't,
or a cell, let's say doesn't, or a, you know, an unfertilized OSI, which all of us were at one
point, doesn't. So, so the exercise that you need to go through is what is the most minimal version
that had it? And, and, and what happened right before that? So, so you've got it. And you sort
of roll yourself back to however old you are, and then nine months back slowly, but surely,
and guess what? You're an unfertilized OSI. So at one point, at some point, it showed up. And if
you really think there's a sharp zero or non zero, you have to say where it showed up. And of course,
developmental biology offers absolutely no place where you can say, ah, that's it. That's it right
there. That's weird. And so, and so that's a problem. And so, and so I suggest to everybody
to do this experiment and to say, what is the absolute minimal version of, of agency that you
think it would take to get on the spectrum? And, you know, and, okay, so, uh, please let me know
in the chat now if the audio is better. I think I have figured out what it was causing this. And
I think I fixed it. So, um, but, uh, OBS is updated and it is taking multiple, um, it's taking
audio from multiple sources. This could be actually useful in the future, but, um, uh,
and it answers questions that I have about how to use OBS for certain things. But it, it also,
at the same time, um, might have caused some issues today. So, uh, but please let me know and hit the
like button, uh, if to help fuel the algorithm and let me know in the chat if this sounds better
than it did. I think, I think I fixed the problem. But, um, hopefully, uh, but it, this is, uh, this
is interesting that he's saying this because, uh, this, this shows a brand new direction for
science that is different from the last 50 years minimum, which is, it is contrary to the idea
of anti-theism, of, uh, to the narrative that, that agency or consciousness, which are the same thing,
arises from unconsciousness. And that, and, and, you know, as he states in the example that he gives
at what point does something that has no agency turn into something that has agency? And if you
continue the thought process back and back and back and back and back, you realize at no point does it
appear like there's no agency in the system. There is no point in which information does not appear
to be being processed to some, to some degree. So there is no zero point. There is no unconsciousness
is another way of putting this. And that is profound. And it's, it's also something that,
you know, many people have been saying for a long time, but the fact that somebody like Michael Levin
is starting to say this type of stuff is going to lead to one of two things. One is, I mean,
I think eventually it means that we will get, realize again, um, we will return to the God
hypothesis that we're all inside a single sentient being and that that is the inevitability of the
nature of existence itself is that it is an information processing system is an agent.
And that's, that's something that we've kind of been missing in along for a long time that if that
is the case that we and we go down that direction, it does appear to be correct, which it appears to
be correct. It will change our abilities with physics and metaphysics and chemistry and,
and, and biology and, and engineering and politics and economics and sociology,
all these different fields, because it changes how we view them. I saw Lee Cronin posted on Twitter
today, he said, uh, going to, you know, tonight's project is to start a, you know, metaphysics
paper on paper on the metaphysics of, of chemistry and, and it's just, it's,
that is an interesting approach because inevitably what it means is
you're taking a, an approach where the patterns of mind are being used to
make arguments for chemical interactions and constraints. Uh, I'm not saying he would state
that, but that is the inevitable inevitability of that task. Um, whether you call it that or
realize that or not. Um, because what is metaphysics, if it is not the information patterns,
which is the patterns of mind, that's information is not separate from mind.
Information is context. The context is mind. That is the context. So, um, but let me know
how the audio is, please, uh, in the chat. Uh, like I said, I think I fixed the issue, but, um,
uh, hopefully, let me see. Yeah, it appears like it's better. Um, uh, but here I will get this
fixed, uh, and settled for future streams. I, I, like I said, I think I figured out the issue. Um, but
uh, you know, there is no zero point. There is no point in which consciousness arose. It always
existed. Sentience exists. Uh, on my website, it says beyond the beginning, existence is sentient,
sentience exists and, um, and sentience is one, essentially. And, uh, and that is just an
inevitability. And, um, having that idea as the, to contextualize everything else that you try and
think about has, will impact how we think about everything and also what we can think about.
Uh, you know, this, like you said, changing your perspective adds information. Um, and
changing how you look at existing information literally adds information to what you can examine.
And, uh, when we are stalled out in our ability to understand something like infinity or, or the
cosmos or the, you know, future of humanity or the beginnings of the universe, um, then we need
to change how we're looking at everything because what, how we're looking at it, uh, has reached
its limit in its ability to in, you know, process the information that is available. And so to gain
more information, we need to change our perspective. And, um, what is the, it's interesting that, that
our ability to access even creativity, when you look at the creative industry, I live near
Hollywood and I see just the absolute lack of creativity in, in the, um, you know, the entertainment
industry. Why is that? It's because there is a systemic issue that is the same exact systemic
issue in physics and biology and, and in movie industry. And if there is, if there is this,
this, this systemic limit that we seem to have hit, then we have to change
some universal perspective that we have on, on the world in order to reopen all of these,
the creativity in all these fields. It's not just a physics problem. It's not just a philosophy
problem. It's not just a mathematical problem or a chemistry problem or, or a biology problem or
a political problem. We have no new ideas and creativity seems to have stalled in everything.
And it is because there is something fundamental that we are assuming that is not fundamentally
true and maybe allowed for some contextual, you know, um, and specific revelations, um, for some
reason, but it, and, and has stuck since then. But it, it's not whatever, and even if that,
I don't even know if that's true, but whatever it is that is causing a lack of creativity is,
is something that's not ice. It's not a bunch of isolated different problems in each field.
It's one big perspective that we've got wrong. And I think that what he's getting at here
uh, uh, with the idea that consciousness arose at a certain point, meaning it, it, it's not
fundamental is the problem. And uh, it, it implies that if you do that now there is no
assumption of a greater goal and, and direction for, um, humanity or, or the universe beyond
our own personal preferences. And if you don't think that that will impact your ability to
produce a good show or movie, then you haven't thought about it long enough because uh, it means
it means that you might want to just force your own ideas and your own, um, goals into whatever
it is that you're trying to create. And they're not in alignment with the universal, um, patterns
that we would reckon, recognize as, as, you know, being like the skeleton key that fits into every
single one of the locks of our mind, if that makes sense. Like we recognize certain patterns,
you know, it's fascinating because on my Instagram page, which I've started posting to again, um,
it's not nearly as interesting to me as this because I, people send me messages on it and stuff
and they hit, you know, they like my images and it became hard for me to keep up with it when I
didn't have a scheduling tool because I'm not motivated by likes and, uh, very much at least.
I'm not going to say I'm, you know, not human, but, uh, but it's not the most important thing to me,
whereas the interaction of the live chat is very important to me. So I ended up just letting my
Instagram kind of go a bit and focusing on this because I think there's more substance and value
to it. But I also think that it's valuable to just post on Instagram too, even if it's just to bring
people to hear. But what's, what's fascinating is, is that I understand why people want to watch
these streams if they start. And I think that they, it makes sense to me at least, why it would be
interesting to listen to me talk about this stuff. Otherwise, why would I be talking about it? You
know, if I didn't think it was interesting. But the thing is, is on Instagram, I post pictures of
these like, you know, models with a bunch of numbers in them that are likes, you know, just excel,
uh, cells and in symmetrical formats of some type. And I don't explain exactly what's going on in
there because it just would take too much time. And I, I don't want to literally write a paper in
every single, uh, or paragraphs in every single post. And so I'll just make a certain comment about
it that, you know, is some is related to it in some way and then hope that if they're more interested,
they'll click and they'll, you know, buy out to the YouTube channel. And, but people seem
absolutely inspired by it, not even seem to, they send me messages and they'll be like,
your work is so inspiring to me. And I'm, this is not belittling them at all. It's, but it's
interesting because I don't think that they understand what I'm posting, like in a, in a
in a, in a detailed way. Like they look at these math, um, these numbers and grids and stuff like
that. And they're like, fascinated by it. And they tell me that it's inspiring, it's inspiring to
them. And for a while I was like, why, you know, you don't know, do you watch the YouTube channel?
Cause then I can understand. But if you don't, then why are you even finding this interesting,
let alone like telling me that it's inspiring. And, um, what it is, is that there are certain
patterns that we recognize subconsciously and identify with subconsciously because they are
easy to see as the patterns of mind. And, um, that you can see this with kind of Eric Weinstein
on Joe Rogan, when he showed the hop vibration. And he's like, he says, this is the most important
artifact in the universe. And he doesn't explain what it is. He just explains, you know,
kind of the shape of it, you know, it's a, it's a hypersphere basically. And nobody knows what
that means. And it doesn't matter to anybody what he said about it, but something about the way that
it looks is fascinating to people and not just fascinating, but, um, but, but recognized, recognizable.
When we look at it, it's some way, in some way, we're like seeing ourselves in the mirror. We see,
I think, subconsciously that, you know, the EH structure, um, uh, in mathematics or the, or the,
or the, um, or the hop vibration or some of the models that I post, they are the patterns of mind.
And they, when we look at them, we see ourselves in the mirror, we recognize it to some degree.
And, uh, and we, it's somewhat intuitive. When you stop doing that, and because you
would stop assuming that it has any, that the math or geometry or, or anything has anything to do
with mind whatsoever, which it inevitably must, because it's being interpreted by mind, even
just if it's just you. Um, uh, and that if you take it further, then it must be within the,
you know, environment of a mind itself, uh, God. And, but even if it's just you still,
if you divorce those ideas, then math has anything to do with mind, then, or that anything has anything
to do with mind, then what happens is, is that everything just becomes blind to you. You become
blind to, to, to the reality of, of the, of universal patterns because you're denying of them.
How can you see patterns that are universal if you deny the idea that there even could exist?
And this is what materialism in its traditional format, you know, or, or it's the way that we
think about it often has done to us. It has, it has literally blinded us from seeing beyond
the, the wall that we have constructed. Um, and, and, and we are a prison of our own, of our own
false assumptions. And that is true of, of physics and also it is true of Hollywood, even.
It's why everything is just remade now, but just worse because it's just remade, but with somebody's
agenda pushed into it because they don't assume that there is a greater agenda to appeal to.
They assume that there isn't. And so therefore, why doesn't it make sense to just push what you,
what you see, um, on others? And, and also why, why it explains why nothing new has been created.
Everybody keeps saying why, why do you have to remake snow white with just like a, you know,
a, a very artificial agenda built into it. And, um, why can't you make something new
that's inspiring? It's like, because we are limited by this idea that, that consciousness
arises from unconsciousness. And it is that idea that is causing even that problem.
Um, and it's also the, it leads to us creating all kinds of nonsense like Schrodinger's cat,
which makes no sense and everybody just repeats it. And, and also I'm not saying the original,
you know, idea for Schrodinger's cat didn't make some sense, but just saying it doesn't
in its current configuration. And, uh, and it also, um, you know, it, it leads to a lack of
creativity in art in, uh, and, and that makes everybody copying each other. And just all you
can do is just take what has been done and, and then just kind of inject your own personal ideas
into it artificially, um, not naturally. And, uh, and it's just, it, it's not constructive.
And so, uh, it's amazing that this one idea is having such a far reaching impact, but it's also
obvious that this would be the case when you actually start to deconstruct what this really
implies completely. What's up, Justin? Um, I hope, uh, uh, I'm glad you are enjoying the stream.
Please hit the like button to help fuel the algorithm. I am going to probably, um, uh,
download both of these and put them together into a single one, because I do think the stream was
very good, but it also had some serious tech issues. Um, but it's interesting this next clip
he says here, um, we will test, this will be a test to see if I actually solve the
the audio problem, but, uh, he talks about in animacy and how it, it is nonsensical.
Different disciplines and it was incredible and, uh, such a treat to talk to him directly. So I've
sort of this, um, related to that. You see, one thing it just said, I correct me if I'm wrong,
but you said our world doesn't have zero agency anywhere. Is that your belief? I mean, yeah,
I think at this point I would say that. Yeah. Yeah. Yeah. I think that's true. Um,
yeah, I think that's true. Somebody else, I just came across somebody else's quote. Uh,
was it Robert Rosen? I forget whose quote it was unfortunately, but somebody said that,
you know, that, that, that the thing we think of as true in animacy is the exception, not the rule
that, that, that the, you know, that, that really it's, uh, and, and I, and I would take it further.
I, I'm at this point, I'm not aware of anything that I would say is truly zero. But again, let's,
let's make sure we understand this is a rigorous, uh, position that has to do with,
as an engineer, what can I take advantage of? Right. And, and there is nothing to my
knowledge where, uh, those tools that come right. So, so again, the thing, the thing about that
spectrum is what, what changes as you go from left to right across that spectrum are the tool kits
that you need to interact with that system, right? The things that are useful for the mechanical clock
become less useful as the system progresses and, and vice versa. And conversely, things that are
useful for, for human subjects become less and less useful as you go down the, down the road.
So this isn't the kind of, um, uh, kind of, uh, lu, luci, luci, uh, sort of talk where you say
everything is, uh, you know, everything is alive. I mean, you can do that, but that's,
but that's, that's pretty useless. Okay. That doesn't advance you at all. What I'm talking about
is a very specific, uh, way to, to, to drive research agendas, which is to take tools that
are useful in one field for dealing with one kind of system and ask what other kinds of
systems are these tools useful for? And to not be able to, I mean, I'm, I'm arguing against
having these sort of armchair, uh, philosophical, um, preconceptions about what things have to be.
Somebody, somebody said to me once, um, we were talking about this thing and I was,
somebody said, well, well, well, surely you don't think the weather has any intelligence to it.
And being perfectly serious, I said, has anybody tried training the weather? I honestly don't,
this is an empirical question. You and I cannot decide whether, whether patterns, meaning patterns
of air movement in the atmosphere do or do not exhibit habituation, sensitization, associative
conditioning of some sort. You and I sitting here in our chairs are not going to be able to decide
that. And, and, and a lot of people don't, don't think that's the way to do it because they feel
that if the empirical, um, you know, if, if, if those kind of empirical things, uh, are, are, are
the prediction of your worldview, then you, then you, then the, then the worldview must be wrong.
That, you know, they sort of assume that any worldview that, that, that can possibly tell
you that you're, that the weather, the weather pattern is, has, has certain problem solving
capacities is obviously wrong because, because you, that you're already, you know, you're starting
with, with something that's wrong. I think that's completely upside down philosophically. I don't
think you can do it that way. I think you have to say, uh, see, see, see what the, see, see what the
empirical results are. And then you'll know how good your, your, your outlook was. Was it, was it,
was it helping you or not? I don't think we were, you and I can't decide this about these systems.
So I, I actually think that massive, um, opportunities exist for looking for the surprising
and, and we have some, we have some pretty cool stuff coming out on this, um, soon, um,
in the next few months, uh, that's not peer reviewed yet. So I don't really want to talk about it,
but there, there'll be some, once it's, once it's peer reviewed, you'll see that the, the project
of looking for these kinds of, um, cryptic capabilities and systems that we normally are
no good at recognizing as having these kinds of capacities. I think there's massive opportunities
for this. We, we don't, we don't realize we are, we are so bad at it. We do not realize how much
intelligence is, uh, is, is all around us. And, and I said, I said, um, uh, there was a, there was a
tweet a few weeks ago where I said something like this, that, you know, one of the things I love
about AI is that it's, it's like a lens or a, or a translation device that's going to help us
see a lot of the intelligence that's all around us all the time. It's like being able to suddenly
being able to communicate with an intelligence, with a parallel set of intelligence that they were
here all along. We just never knew, we never knew how to recognize and we never knew how to relate
to them. And so, and so, you know, some people liked it and some people just said that was the
craziest thing they'd ever heard. But, okay, so a lot here for one, uh, my work does put forward
a scale or a scaling of sentence or a lineage of levels of sentient levels or levels of
sentience, um, that, that would show what is sentient and what is not. Um, uh, but so the weather,
for instance, would not be an intelligence, but that, but it's hard to say because it depends
on how you define it because we are inside of an intelligent existence that is a sentient being.
But that doesn't mean that every subcomponent that we look at has intelligence, like this
water bottle does not have intelligence or sentience. Um, and the weather, I would say probably does not.
Um, but you do have to, like he says, kind of assume that that there's more to figure out
in order to figure it out. So he is right in saying that we shouldn't just make these assumptions
kind of, I don't know, willy-nilly, like just off the cuff without deep investigation, but my work
is deep, has been, you know, years of deep investigation. Uh, it's not just, um, and I'm not
saying anybody should take my word for it. I'm just saying, like, we'll see if my predictions hold up
eventually, um, uh, through various, you know, means, but it, it, you know, they're not the same as
just kind of off the cuff assumptions either. They're very rigorous, well-formulated, constructed,
you know, logically constructed, uh, concepts and ideas that are connected. And it's not just,
um, an assumption that I have off the cuff. But, uh, I do agree with him, though, that, that
changing our perspective on, on what intel, on what intelligence is, is going to unlock a bunch of
new, um, things, but an AI is going to do that as well. But, uh, it's, the issue is, is that in terms,
with the term AI, there isn't really an issue, there is an issue with the term. And, um, and
Eric Weinstein put it this way once he said, um, uh, what if intelligence is completely natural?
And, um, it's something like that. And I may, I, that might have been, you know,
in a modification of what he originally said by me, but, uh, something along those lines is that,
it, that, I think it was in his talk with Stephen Wolfram on, um, on Brian Keating's channel that
he said that at the end of the very, very end of the podcast, I think, uh, that what we'll come
to realize is that intelligence is not artificial. It is natural. It is a, it is a component of,
it is, it is an, is an intrinsic aspect of reality or naturally occurring, um, you know,
concept or constructive of reality or ability of reality. And, uh, it's not, um, able to be created
artificially in the way that we think of the same, uh, way as like, if it could be, then you,
then a calculator could be intelligent, but it's not mid-journey is not intelligent. We think these
things are intelligent and we call them artificial intelligence, but it's us that's the intelligent
component that's interacting with them. It's other than that, they are just an, an algorithm looped
into a network that's, that is constantly acting and reacting, um, in, in it, but, and those, and
the network is composed of intelligences, i.e. us, but it is not actually intelligent. And, uh,
but it does, it will help us kind of see kind of the, the universality of intelligence, but it will
also, I think AI mislead us into thinking that certain constructs are intelligent, that are
actually not, uh, and, um, that is potentially dangerous, but you know, whatever is inevitable
is inevitable. So I'm not saying we need to definitely try and stop this, but we'll, you
are, John, but even on an individual basis is to say what is true, what is true, and,
or what we believe is true, and that's, that is what, you know, our obligations are. So, uh,
but there are also going to be emergent, assemble inevitabilities, you know, gliders that are created
and, um, and there's nothing you can do to stop that, I don't think, um, you know, but in order,
if there is a way to stop it, you have to assume there is a way to stop it in order to stop it. So,
but I, I have thought about that too, and I'm just saying there are some things that I think are
inevitable. If there wasn't, then a glider wouldn't have even be something that could occur in the
game of life. Like if there weren't inevitabilities, gliders wouldn't exist, governments wouldn't
be needed. There's lots of things that, um, do imply that there are just inevitabilities.
So, but, uh, and he goes on to say that we're not good at recognizing agents in, um, novel spaces,
basically, and, um, here, this is the next clip, and then I'll probably do one more clip and then
we'll, we'll wrap it up. The last clip is very important.
In this three-dimensional space, that is what we're good at recognizing. That is just an
evolutionary, um, uh, consequence of the way we're built. What we are really not good at doing
is recognizing unconventional agents, meaning very large ones, very small ones, very fast ones,
very slow ones. We are not good at recognizing unconventional agents in novel problem spaces.
So what is a, what is a problem space? So imagine for a moment if, um, if we had an internal,
uh, and I think we can build, uh, you know, this is on our list is to build a creature like this,
but, but I think, I think we could, we, you could imagine a being that had an internal sense that
was, for example, sensing your blood chemistry all the time. Let's say it was measuring, let's say,
you know, like with a, with a tongue or something like this, you could, you could measure, um,
uh, 10, 10 different, uh, aspects of your blood chemistry. If, if we had the ability to, to measure
that or in the way that, to, to, to sense that the way that we sense with vision, you would know
that your body lives in this 10-dimensional option space, right? Where just like we live in a three
dimensional space, if you could sense 10 different things, you would, you're, you're about your blood,
your blood would be in this physiological state space that would have 10 dimensions to it. Of
course we can't visualize that, but we would, if we had evolved that way, we would be able to.
Um, and you would also know that there are these things called liver, kidneys, and so on
that are really clever about navigating that space, that when they get perturbed by specific
things that happen in terms of your blood chemistry, they can find ways around it. They keep you alive
despite all sorts of, you know, terrible things that you do to them with you, you know, with your
lifestyle and all that. Um, we would have no problem recognizing them as beings that live
in this space. We would know we live in this space. We just don't, we just, we're very bad at
recognizing this and, and it is no less real than the large scale three dimensional space in
which we navigate with our muscles. We are constantly navigating physiological state space,
which has way more than 10 dimensions. Of course we are navigating transcriptional state space,
so gene expression space. So if you have, you know, I don't know, several tens of thousands of genes
as an organism, that is a very high dimensional space that you are walking in all the time by
turning different genes on and off. You're navigating that space. We have metabolic spaces.
You know, we now modern humans have linguistic spaces and who knows what else, what else is out
there. So, um, so, so for sure, uh, all of these things are as real. They're, they're, they're
super real. Why? Because if you didn't have ways of navigating them, you'd be dead. That's the
interesting that he used the term super real, uh, not metaphorically real, not, not, not, um,
not, um, you know, physically real. He was like, they're super real. That is a term that I have
been basically using, been using on this channel for like years at this point is, um, when people
ask me, you know, is something real and it's something fundamental or I'll say it's super
literally true. It's, it's not just, it's not metaphorical. It's not, uh, and this was the
question that, that I think what got cut off in the beginning is that, um, Carlos asked, is, are
these spaces real or are they metaphorical? And, um, and he said they're super real and this is
the right way to think about any kind of navigable choice space and, um, uh, but really what that is
eventually is, uh, it is the mental space. It is navigating this space of mind and, um, uh,
it's, it's interesting, um, uh, because this is in my work, there are four primary perspectives
inside, outside, separate and oneness and that they are responsible for the creation of
all constraints and degrees of freedom that can be observed in every single system that we navigate
because they are the dimensions of mind itself, which is used to navigate any system.
And according to sentient singularity theory at least, this system that we are navigating within
ultimately as well is a mind itself, a sovereign mind. So it's your mind and, and you're navigating
within another mind. And so, uh, this is, uh, it just means that there's going to be a universal
pattern that is able to be applied to every single one of these spaces that he's talking about,
whether it's genes or it's lineage interactions or it's friendships or whether it's family,
whether it's, um, you know, three dimensional space, uh, or time, uh, or, uh, you know, I don't
know, anything that you can think of, um, any option space, any information space is going to
follow some specific universal pattern at its fundamental, at its fundamental level. And that,
you know, you'd be able to create other perspectives that build on this, this one fundamental pattern
that, um, that builds on just, is built on just the unit, the, the singularity, the singularness
of existence and the sentientness of existence itself. From that emerges these four primary
perspectives. And then from those emerge, you know, more, more dimensional spaces than just four. But
even in, you know, geometric unity and, and emergence theory and all these other construction
theory, everything seems to start with a four dimensional space, even space time.
And, uh, and that's because of there's this meant four dimensional mental
space that is ever present in every other space in which we are existing. So, uh, it's,
it's just, um, interesting. But, um, yeah. So, next clip.
So this is, this is, I'm going to show a couple more because this is actually, it's just great.
Which has way more than 10 dimensions. Of course, we are navigating transcriptional
state space, so gene expression space. So if you have, you know, I don't know, several tens of
thousands of genes as an organism, that is the, okay. So this is what I wanted to show. He already
was talking about this, but this is where my work differs from his. I'm not going to say his is wrong
or mine is right or something, but is, it has to do with fundamentality is, and this is where almost
all attempts at like a fundamental theory go wrong, is they'll have something like atom, molecule,
organelle, cell, tissue, organism, population, community, ecosystem, biosphere, solar system,
galaxy, universe. And the issue with this is that's not all of these structures are following the same,
kind of mode of manifestation. And they're not all the, you, they're not all these like
unified, Hellonic structures, like a molecule would be, and a cell would be, and an organism would be,
and maybe some types of communities, but not necessarily tissue or cell, because
what you have, what most people focus on is size. And I've said this before, they'll say, well,
what's bigger than a cell, multi cellular organism, what's bigger than an organism,
a population, or community, or, I mean, I don't know what the difference is between these,
but I'm sure he has a specific way in which he's differentiating them. I don't know what the
difference is between these, but I'm sure he has a specific way in which he's differentiating them,
but they're not the same differentiation as like these. I don't think so, at least. Maybe
I'm wrong. And I do see why he would maybe do this is because organelles do look like little
unified assembly structures, but then he gets to
like tissue, which I don't know if that means like organ, like an organ.
And, but I would say that those are not, they're not part of the scaling of sentience,
but they are part of an assembly, you know, pattern, some type. But what you, what you have to do
is you have to look at this from a perspective of lineage. So atoms form from hadrons,
molecules form from atoms, cells form from molecules. And, and in a way, they have to be
able to exist on their own absent what is above them in a way, but not even if they are an assembly
of what is below them, whereas like tissue does not exist absent an organism and an organelle,
I would think probably doesn't exist absent a cell, just like a heart never existed,
absent an organism. But a cell did exist absent a multicellular organism, but a heart did not.
And, and so it's, and, and when you, when you look at this on an even larger scale, and you look at
like biosystems and, and, and the planets and, and solar systems, we did, when you look at the,
the earth, it does not seem, and I might be wrong about this, but if I am wrong about this,
then it means the earth is not what we think it is. It's a different kind of thing, which might be
the case actually, but it does mean we would have to change our thinking on what the earth is.
And it would mean that our perspective on what it is is, is not as fundamental as it should be in,
in terms of understanding it, but it, it would mean it's a sentient being, it would not be just
like a, a kind of a structure that we can observe due to, you know, the way in which we interpret
information. But it, like you don't get a solar system from an assembly of, of, of
organisms, like there is no lineage structure there. The solar system comes first, or at least in our
current understanding of it. And if it is part of this system, then what it would mean, part of this,
these, these levels, then what it would mean is that actually a solar system is constructed of,
of, you know, little or sentient beings, and then that's constructed of little or sentient beings.
It's not that the solar system came first. And, and then, and then we arrived, it would be that we
arrived, and we are responsible for the, the generation of the solar system, even if it doesn't
look like it to us, because we have a problem interpreting the information from inside the
system. That's possible. But it would mean completely scrubbing everything that we think we
know about the solar system. And so the model that I have put forth in my work, I'm not saying that
his is wrong, I'm just saying that there is a lack of, appears to be a lack of
fundamentality of it, is this is the model right here. So it also kind of showcases that there is
like an endpoint to this process, or, or, and then it restarts basically. So it hits this and then
the system restarts within itself, and you start again here, and then you
again and again and again, this repeats. Otherwise, if it's just a matter of size,
then it's just kind of this never ending kind of
just soup that doesn't have a pattern to it in which, in which it manifests. There is no pattern
to the logos, which is difficult to justify. So I don't know if that's the best way of explaining it,
but when you're looking at a fundamental framework for reality, you're going to look for
a lineage of sentient beings that follows the same pattern as the one before to some degree, and
that, that has an endpoint to it that seems like, you know, to never, like sentience is never
divorced from the system. It's just, there's just this nested, halonic structures. And
I think that this is, this is actually the way that it is done. But some of these terms may not
be the best, like caste, because we don't, we might not have the best way of, we're the best term
for this. It might be like tribe or nation, but it's maybe not, you know, I don't know. This might
be nation, but it is also a technological singularity. But it's a singularity with people. It's a human
singularity as well. It's not just a tech singularity alone. It's the unification of technology and
people, which, you know, event is an eventuality. But this pattern follows, or at least my attempt
was to follow a lineage-based construction of halonic structures versus a size-based nested system
that kind of ends up being more arbitrary. It's like, why, why stop at biosphere? You know, yeah,
why not go to solar system and then to galaxy and then universe? But why, why, why not, why go
galaxy and then universe? Why not go galaxy and then, I don't know, I'm not an astronomer, but maybe
like a nebula or something. I don't know if that's the right term, but what's a cluster of galaxies?
You know, and then universe? And then what about a cluster of a cluster of galaxies? Like, it's just,
to me, it seems to break down, but I might be, you know, who knows, I might be wrong.
There does some, it seemed to be some type of singular gravitational
aspect to many of these structures, and that is important to recognize, but it, and it might,
but at least from within them, it does not, they appear like they are actually
unified into a hole on, even if, but that might be wrong. But there's,
you know, tissue doesn't exist outside of organism, I don't think, you know.
So that kind of destroys the lineage aspect there, but I might be misinterpreting this and might need
to read more into his paper and figure it out. And if I'm wrong, then I would. And I think that
it's not, if it changes my mind on something, and I feel like I need to share, then eventually,
well, but I'd love to have them on the channel eventually, and it is part of the plan to discuss
it specifically. And it might not be that either one of us is wrong, we're just doing something
different, which I mean, inevitably is true to some degree. It's just, is the attempt of that,
that model that I showed in his paper, the same attempt as my model, in which if that's true,
then maybe one of them is wrong, and maybe one of them is right, or maybe both of them are wrong.
And there's a different version of it that is correct. But yeah. So last, two, two last clips,
but this, this one I thought was very interesting. I've talked about on here super how shape is,
the shape of things is dependent upon kind of our perspective in the entanglement sub structure of
the cosmos. And how we observe the shape of things is dependent upon this, even, even our
arms and limbs and things like that, and our bodies have a shape to them that is dependent upon
the mental structure that we can, of information interpretation that we have. So
there's models that I have that show that there's a tryality of, I guess, information
specification that happens that is, is a, it's a hierarchy of information that forms into a
tryality. And in our, in the way that we interpret information. So you'll see this in every thing
that you look, you'll look at time, you'll be like this past present future, you'll look at space,
you'll be like there's XYZ or length with height, or you'll look at limbs and you'll be like,
there's arm, hands and fingers. Okay. And that these are like a tryality manifestation of
information that we can observe even of our own bodies. And
then you can see this in senses too, like the senses that you use to interpret information
that you view as outside you is like smell and, and sight and hearing. That's a tryality.
But, but this, these types of
this structure of information interpretation that is the structure of mind,
and its relationship with other mental structures that it is entangled with in this
substructure of, of sentience that we all exist in, your position in that does matter to
the shape that you perceive of something. And even, you know, I don't know the shape of this pen
is dependent on that. It's dependent on where these molecules and atoms are in the assembly
structure of the cosmos. And also their mental structures, how that interacts with my mental
structures and with the mental structure of the cosmos is a whole. And with all that together.
And my goal, my goal, which also depend dictates what direction I'm looking at something
will show me this shape or not. And he shows something interesting here about the shape of
beings and, and things that can be observed. And I just thought it was interesting.
And prescient images in there, which I still, I think people still haven't quite,
you know, utilized to their full, full. Do you recall? Do you recall the books called?
Yeah, it's called on growth and form. It's very famous. It's a 1940s book. I mean,
most biologists know it, but few people really pay attention nowadays. But there's a couple,
there are a couple of things in there, which I think are super profound, which is, which is
specifically that, that he shows him, he draws, he draws these grid grids and then superimpose
a creature onto that grid, let's say a fish. And then you apply a mathematical deformation to
that grid, and you get a very different looking fish. That's actually another fish. So anyway,
so, so, so a classic explanation of morpho spaces comes from a paper by, by this guy named Raup.
And what he envisions is sea shells and snail shells of all kinds. And the thing is that there's
only, there's only a few two or three parameters that can be used to describe any coiled mollusk
shell, you know, because you got a big, big flat one. Interesting that he said two or three.
Pointy ones and everything in between. There's only a few, there's a mathematical formula
generates the spiral, and there's only a few parameters in it. And so what you can imagine
is this, this virtual space. So let's say, let's say just for, for, for fun, let's say there's
three parameters, so you know, A, B and C. So you can imagine this is the A dimension, this is the
B dimension, this is the C dimension. And so every possible shell is somewhere in that space,
because it's defined by a point that has those values of A, B and C. So every, every possible
shell is somewhere here. So now there are regions of the space, there are regions and he actually,
in his paper, he actually draws this up. There are regions that correspond to this set of species.
And there are regions that correspond to no set of species, because apparently those kind of
shells wouldn't be very good in the real world, but they're possible. And so he talks about different,
he talks about the geography of the space, that here are the actual ones, here are the possible,
but not the current, here are the ones that are impossible given biological development,
and here are the ones that are, you know, possible, but really not adaptive and so on,
right, in that different region. So, so that space, so, so now think about anatomical morpheus space
for the, for the, for the rest of us, there are very high number of parameters that determine all
of the possible anatomical configurations that you might take. So your eyes might be, you know,
closer or further together, your, your head might be different shapes of, you know, and, and people,
um, uh, uh, and other people have studied this and bird beaks and, and various things.
The point is that all of these morphological spaces have a tractor. So tractors are regions
in that space, which are easy to slide down into that. Once you sort of come close, um, you don't
have to do a lot of work to end up down there. And once you're down there, it's harder to climb up.
So this kind of keeps like gravity, it, it, um, so, so, so different species, for example,
different shaped planaria heads. So we've worked with these flatworms, these planaria different
shape heads correspond to, and that's the figure that you're talking about, correspond to different
attractors in that space, because all things, uh, being equal plus or minus various to, um,
environmental influences, you still, you know, the, typically the acorn ends up in the oak tree
attractor and the, the, you know, the frog egg ends up in the frog. You attract it, not always,
because we can push it into the xenobon attractor, but that's a different, that's a different, that's
a different story. Um, and, and by the way, even for the oak tree, this is, you know, kind of my
latest thing that I, I point out to everybody, uh, if, if under normal circumstances, acorns are
really good at making flat green leaves, right? Oak leaves. But actually, if you hack it the
right way, there are wasp parasites that send certain signals to those cells that create gauze,
that are these amazing, uh, spherical red spiky things that don't look anything like flat green
leaves. And that tells you that with the right prompting, um, uh, you can hack these kind of
competent systems into finding other attractors in more for space that they normally never go to.
And you can push them into that space and, and that space contains xenobots and various gauze
and who knows what the heck else it contains. And so, and so those attractors are things that,
that evolution has, has selected to, uh, to utilize in the normal standard version of what
happens. And then we can do interesting things like in planaria, we can, uh, drive them into
other attractors that belong to the wrong species. And that doesn't require changing the DNA, that
requires just, uh, changing the electrical decision-making that happens during the regeneration
process. And they end up in, as, as other, with, with heads of other species. Fascinating. That's
all I have to say about that. Um, there's one final clip and then we'll, um, I'll take any final
questions and we can wrap up the, uh, discussion. So comment any questions or thoughts that you
have or anything you want me to touch on before we, uh, close up. But this last, uh, clip is just,
I just, it was awesome to hear him say this because it's, it's what I've been
stating as well. And it is kind of the inevitability of, of where science is going,
science is going. I don't even know what that means anymore. Um, but, uh, you know,
you kind of get what I'm trying to say at least, I think, and that is how if, if consciousness is
fundamental, which I hate, or sentience is fundamental, it is the fundamental nature of
existence and that everything is a construct of, of sent the interactions of sentient beings.
All things are constructs by created by the interactions of multiplicity of sentient beings
that are all created by a single sentient being initially. Then this implies that
they're, that, that our relationship with it, with the system itself as a, as a sentient entity,
a sovereign sentient entity, and with even molecules and, and atoms, if they are sentient
entities, which I think that they are, and, and even hadrons, like protons and neutrons,
we have to take moral and ethical
considerations into account in ways that we never have before. And I'm not just talking about, oh,
well the nuclear bomb could hurt people if it's used because, you know, it causes people to be
vaporized when it's used on different countries. I'm not talking about that. I'm talking about,
maybe there is moral ethical considerations to fission, to the fission process itself,
or to the fusion process itself, and that, that we're impacting sentient beings on a level
that we need to consider. And this is kind of where his last clip touches on.
A facilitation of research that that does feed, and understanding, and, and, and by the way,
in the last, you know, sort of two minutes, I'll say this,
that, that, that tape paper with a spectrum of persuadability, it was very focused because I
think it's important to push people in that direction, very focused on an engineering approach to
modifying and controlling systems and engineering news systems. Okay, that's all great.
But as you head towards, I mean, I think it's very important, and I'm writing stuff about this,
that'll come out at some point, as you get, the further you get to the right side of that spectrum,
you have to shift over from ideas of control to ideas of relationship. And this is where a lot of
the, you know, ethics aspects come in, because, because our system is of ethics, we have, we're
going to need new system and systems of ethics that really take seriously the existence of
unconventional minds that are not just built on ancient, and really just very childish notions
of how you separate things you have to care about from things that you don't need to care about,
you know, where they were they engineered versus where they naturally evolved,
do they have a big brain, none of these criteria are going to survive the next decades, this is all
that all this stuff has to go. And new new systems of ethics has to come, because all of this is
really about how do you relate to others, other systems, how do you relate to things that look
like you to things that look nothing like you, things that don't share the same evolutionary
tree with you. And, and, and in some cases, that relationship means control in the way that we
do with with clocks and thermostats. And in other cases, it takes a completely different form with
various beings, unconventional beings, possible aliens, possible AIs, whatever, that where that
relationship is going to be quite different, where, where you benefit from their agency,
you don't try to, you know, sort of micromanage it, that that's the lesson I think from all of this.
Bingo. Bingo. That's brilliant and accurate. This is why a fundamental theory, as I stated in my
theories of everything, the how to guide video, inevitably leads to moral repercussions,
because it can't not. It has to, because of the inevitability of, of, of a sentient system and,
and of what that implies. And in every way, I mean, in literally every way. And it was great to
hear him say that because if there are systems of agents that exist, it's, it's their agency is
important. That doesn't mean that there aren't hierarchies of agents of sentient agents that
each where each one is sovereign, but at the same time subject. That is true, you know, but
it does matter to how we handle things. You know, people say things like, you know,
how we treat fish versus how we treat dogs should be different or how we treat dogs should be
different than how we treat, you know, cattle and how we treat cattle should be very different from
how we treat, you know, E. coli cells in the lab versus how we treat plenaria worms in the lab
versus maybe there is a difference in how in ethics and how we approach a plenaria worm if it's, if
it's a not a sentient being versus how we treat a C. elegans worm, which may be a sentient being.
And, but maybe there's, you know, we need to take into account the sentience of how we treat
any coli cell even in the lab. Maybe there are moral, moral considerations for that that we just
do not consider. And maybe there we are breaking assembly structures in the fission process that
is immoral, you know, and maybe that immorality is something that we should consider because it
might have scaling repercussions for us, even if it's if they're not, you know, directly observable
initially. So, you know, this stuff is nothing like what our current academic
chemist, physicists, or even a lot of biologists, how they think about
about what the work that they're doing. But I would say that what he stated at the end there,
which is that we should, we should, that there might be a benefit to not trying to just
basically take away the sovereign sentientness of, of certain beings, and just treating them like,
like tools, it might be more beneficial to treat them in a differently and in a more cooperative
and consensual type of way. And I think that this is absolutely true. And it is, it seems to be
inevitably true. Anytime there is sovereignty, you would want to take that into account and
probably try and maximize consent. And that that doesn't mean you don't recognize hierarchies,
because they exist. But you also, you know, recognize feelings. And if this is, if existence is
fundamentally sentient, which I think is inevitable, if so, if there are agents that
have feelings must their feelings must be taken into account. It's very interesting that,
you know, there, there are implications even in the scriptures that support some ideas that I have
about corporisms versus organisms and things like that. It's like, if why, why, and I'm not saying,
we're going to branch into scripture for a bit, because, and I realize not everybody here believes
in scripture, but I'm just saying to those that do. Isn't it interesting that like,
there is, and even if you don't, even if you don't actually,
believe in scripture, isn't it interesting that vegetarians will be vegetarian, but then
often we have this narrative that there is that animals and plants are both organisms.
But yet we somehow intrinsically feel a difference in the morality between eating
a cow and eating an asparagus. Why? We should recognize that maybe our feelings are telling
us that there's something fundamentally different about them. It's not just about whether or not
that one has a brain that is obvious to us and one of them does not, one of them has two eyes and
one of them does not. That's not, we know that there are animals that have feelings that have
different morphological, you know, characteristics than us. And if that's the case, then why do we
treat? Why is it treated in scripture if you're a believer in, you know, the divinity of scripture?
Or why do we innately believe if you're not, even if you don't believe in the divinity of
scripture, why do we innately perceive it to be a moral difference in eating asparagus versus
cattle? It's like there's something different about these two organisms. One of them
is just seen so differently than the other. And by us, and I don't think it's just because one of
them is easier to relate to than the other. I don't think that that is the case at all.
And, you know, we, otherwise why do, why wouldn't, you know, vegetarians quote unquote eat starfish,
you know, or like sea urchins or something like that. Does a sea urchin look more like a human
being than a tree? I don't think so. And it's not just about morphological characteristics.
And there's there's something innate there that I think we pick up on. Like I stated with the people
on my Instagram earlier with how they just perceive something in math, but in certain mathematical
structures that just draws them that they see themselves in. And I think that it's interesting
that this is true even on the organism level, that we do make these distinctions. Whereas
otherwise, why would an asparagus be any different than a rabbit? Or a or a why would a carrot be
any different from a sea urchin? But there is something different. There's something different.
And I think that that's fascinating. And exploring that is I think something that science
will scientific experimentation will get much more involved with eventually.
Maybe we'll realize that there is a difference between an earthworm and a planaria worm.
They're not the same type of being. Maybe the specification of any value for the fundamental
particles or forces of nature and how they behave is surely a decision. Yeah, it is. But that doesn't
mean that an electron is sent is in and of itself a sovereign sentient being. It just
but it might be part of a sentient being, you know, like a finger of a sentient being.
I think that that's true. Basically quarks are the fingers of a sentient being that we're within.
But that doesn't mean they are individual sentiences of themselves, whereas maybe hadron
would be it does seem to display more characteristics of a sovereign being in that it
it seems to be animated in a specific way that is internal. And it has follows a specific pattern
of decision making and what we can get into it another time. But kind of reminds me of the
growth and derex infinity groupoid. I've heard of the infinity groupoid, but
and I'm pretty sure that I agree with you on that. But I don't I've never actually heard
anybody mention that name. I've heard Wolfram talk about the infinity groupoid though. Let me look
this up. The notion of infinity groupoid is the generalization that of a group of group oids and
group oids to higher category theory. Homotopical model for topological space. Hold on, this is
I feel like it's like the monad in a way. It's like that which contains it all and that which
starts it all is that's my like, intuition, but I don't know if that's true. Maybe you can let me
know if I'm on to something with that. In category theory, a branch of mathematics and infinity
groupoid is an abstract, okay, okay, okay, I think I see what you're saying. Oh, yeah, this has to do
with like category theory and information structures, okay, vibrant objects, like vibrations,
the category of simplectical sense. Yeah, I'm gonna have to look more into this to know for sure
whether or not what I'm on to something. But yeah, I remember years ago hearing Wolfram
talk more about it and looking more into it, but it's been a long time since I've looked at it.
Yeah, resonance is a powerful thing. It is, it is. There's something about that that, you know,
and I don't, I understand that people will be like, oh, that's woo or whatever. But like I said before,
sometimes woo, what's what seems a little woo is also a little true, you know, wouldn't that be
inevitable? That doesn't mean that everything that is said within conversations of communities that are
often called, you know, woo are are all, you know, true. But I'm just saying that there are some basic
truths that we all do resonate with. And, and that that must be inevitable, because of the
universality of the structures that we follow as sentient beings. But, you know, it's just interesting.
And, and that that just pertains on so many different, different levels. But, yeah, I don't know.
It's, it's a, it's very interesting. It's kind of like the category theory version of the rulliad.
Yeah, yeah, yeah, that's what I've, yeah, that makes sense. Yeah, it's, it's, which is kind of like,
it's similar to the monad, but it's like focus is on different, one of them is focused on
categorization, one of them is focused on rules, one of them is focused on just,
you know, encapsulation, I guess. But I think that that's, I think we're on to the same thing.
Tech padawan, I've got a chance to elaborate my point since the stream restarted. I've also been
listening, of course, I tried to finish it before you ended here.
Rather than imagining the fate of a cat whose survival has been engineered to be 50% via a
root Goldberg method of poisoning, to illustrate the idea, let's simplify it to measure in particle
spin. That is, let's completely forget the cat, when I said through the thought experiment,
had its flaws, referring to the cat, a sentient being, being built around a sentient being is
the flaw. Yeah, that's true, it is the flaw. But don't throw the baby out with the bathwater,
these ideas that is intended to teach whether wrong, despite the fact, I understand the point
of the thought experiment of Schrodinger's cat to some degree, but I just think it's so bad that we
should throw it out. I do think we should throw it out. We should use not just a thought experiment,
we should figure out what it is that is true about what the thought experiment is trying to convey,
and then we should figure out how to say it, not have a thought experiment
that is fundamentally flawed because of this structure that it's built around does not work
with the thought experiment. I mean, I will say, I do think we should throw out Schrodinger's cat
completely. That doesn't mean that you throw out any real aspects of reality that might be related
to the thought experiment, but we just get to those, not through a metaphor that flawed and
doesn't teach people the actual, actually what's going on. So I am absolutely a fan of throwing
out Schrodinger's cat, even though I recognize that there's, there's something about indeterminacy
that it is teaching us, but even then you're placing the whole thing inside of some mechanistic,
you know, non-decision in space of where a sentient being is not pulling the trigger almost
and making a deterministic outcome, which is also flawed. And, you know, I think we're gonna,
I might have to do an entire stream about this, but I think that we should throw out the thought
experiment entirely. I think it's absolutely a mess. It's, it's beyond saving. I just thought it
seemed like by taking literal issue with the logic of what was fanciful through the experiment,
you're not allowing yourself to get the underlying ideas it was intended to raise.
Okay, hold on. You wrote a lot. My point was,
the point of the thought experiment was to try and illustrate core concepts key to understanding
quantum mechanics, namely superposition, that conscious observation is necessary to collapse
the probability wave. But see, that's wrong though. I think that is wrong. Probability in
it of itself is not a fundamental characteristic of existence. It is an emergent perspective
of a geometric structure and the, of a geometric interaction space. Like, it's not, probability
is, is a tool for, for, for, you know, us in, in our current limited understanding of
quantum mechanics, but it's not actually part of quantum mechanics. And,
and if we are going to really put quantum mechanics into its proper
context, we need to put it into the context of an interacting
minds. And like, that is the context of, of quantum mechanics. It, it is, it's, those are
strings of information of overlapping strings of information inside nested mental
vibrations, like the, that are, you know, causing excitations in these strings that are
overlapping. Like, it's not probabilistic. It is deterministic, but it is, it must include choice.
So I don't think that we should have metaphor at all. I understand what it was intended to do,
but I think that it's, it's wrong. Like it, it's just wrong.
But until consciousness, conscious observation, reality is in a state of mere
determinate probability and that upon observation, state is crystallized retroactively. That's
not even accurate though. I understand why that sounds, why that, that is a, what that is, is,
it is a useful model, but it is not an accurate description of what's actually happening.
And, and that's why I'm a fan of throwing it out, because it, it might be a useful model that might
help people, you know, conceptualize of, of, you know, what is happening in a useful model. But
it's the, let's just describe what's happening is what I'm saying. And, and that implies, that
that requires admitting that sentience is the, is the context of all this, which you're already
starting to do when you're talking about observation crystallizing reality. But it's,
it's not that reality doesn't exist in some probabilistic state. It's that that part of
reality doesn't exist yet. And that it is created when we, when, when, you know,
two strings of information cross and you get an excitation, that is the reality of it. It's not
that it exists in a probabilistic indeterminate state and then retroactively or retrocausatively,
you know, something is then pops into existence. There is no time in this state. That's why we
shouldn't even say retrocausatively. It's like, in this space, simultaneity is just
the, the way it is the, it's the state of things, I guess, in a way, it's, that's not even the
right way to put it. I need to think about how to, how to word it, but it's, it, there's no retro,
retrocausal actions in the way that we think about it. And it does appear to be the case,
and I understand that, but you can, if you, we, we just need to learn how to say what's actually
happening, which is tough because it's happening in a space that is outside space time. It's beyond
space time, which means we can't use temporal and spatially dependent terms in order to describe
this very much. So I, I think it was a, I get it was useful model to describe a useful model, but
that's, let's move past it because at this point it's just, it's, it's holding us back. It's not
helping us anymore. It might have helped us do some engineering stuff regarding what, you know,
what we already knew existed regarding certain particle interactions and, and, and structures
and properties and things like that. But that's, if we want to make progress beyond, we need to
start understanding it beyond just the useful model that is not actually telling us the real
story. And, and that means throwing it out, I think, you know, we figured it out enough to,
we have equations that, that can make use of that metaphor, or that made, maybe came from that metaphor,
or that way of thinking, but it's, we've got those, like we've got to move forward. And
continuing to talk about the Schrodinger's cat in is, it's not helping us at all.
I just thought that it seemed like by taking the issue with the logical
of a fanciful thought experiment, you're not allowing yourself to get the underlying ideas
it was intended to raise. That's it. Please read it all before you pontificate them. You're not
talking about what I said if you don't finish the whole idea. It doesn't even have to be
observation. It just has to be intent, not even conscious intent, but merely a conscious being
having a subjective experience changes reality. Yeah. But I don't think that Schrodinger's cat
is helpful to understanding that as much as we, I think it's more harmful than it is helpful at
this point. It's more limiting is what it is. I moved past it at the end. I built up from that
as the foundation. I get, I get that. I, I, I focused on Schrodinger's cat to at a certain
point and I was like, wow, reality is created by our observation. And that means that like
sentience is in like, I did think about that. But I think, and I'm not saying it wasn't helpful
to me to some degree, but it's because I was contextualizing it under other assumptions
already. I think that was what allowed it to kind of even seem useful, because eventually you
realize that it's not actually true, even though the assumptions that you contextualized it within
might be true, which means implies to me that those assumptions are coming from somewhere
else more fundamentally than just that. And it's your, it's kind of our false interpretation of
something that we're then using it. It's like, that's not good evidence, even if it leads us to
the right conclusion, if it's a false interpretation. So I, I'm not a fan of it anymore, but I was,
you know, and the double slit experiment and all this stuff. I think we can understand the
double slit experiment. And that's a much more interesting one to focus on than,
than Schrodinger's cat, because it's an actual experiment. But we can contextualize that one
and actually kind of explain what's happening, versus Schrodinger's cat has built in flaws to it
that, that are irreconcilable. And, and therefore will if taken,
literally will lead you astray. And if taken metaphorically, don't move you along,
really, not really. So I'm just, I'm not a fan of the idea. But I do understand why, you know,
there's a context in which initially it might help you understand, it might make it seem like it
helps you understand things, but I don't think it actually does, because you eventually come to
the realization that it's, that it's, it's impossible to make sense of, once you actually
have all the information. And so, you know, it might be wrong. We can talk more about it on the
Discord calls. By the way, we do have a Discord to anybody who would like to join every Thursday,
we have at 7pm Pacific, we have open calls on any subject, and there are great conversations.
If anybody wants to join that Discord community, it is a great group, just private message me
on Instagram links are down below. And I will send you the link. But, but yeah, that's my thought
on Schrodinger's cat is, it's just we got to get rid of it. Like we got to stop talking about it.
It's not helpful. It's limiting. And, and any way in which it is helpful is usually due to a
misinterpretation of what is even possible. It's just not even trying to make sense of it is just
worthless. It will, it's like chasing a chicken with its head cut off, like don't, it's nonsense,
don't chase nonsense. But even if, you know, it's like if you chase the chicken with its head cut
off, and it led you to something that was, that was interesting. And then you're like, oh, see,
like, it was, you know, it was aware, almost, but it's like, no, it was not. I'm not saying it was
random. I'm just saying, you probably could have got to that place by chasing something that actually
would have led you there, much more coherently. Or maybe it's even that it, the illusion is that
it led you there. And it's not even that it really led you there. It's kind of more closer to what
I'm trying to get at. I don't like the metaphor at all. I think it's terrible. But I do understand
what it's meant to try and convey. I just think it doesn't do a good job of it. Because even what
it's trying to convey is not fundamentally true. It's literally a metaphor that makes no sense the
more you do less and less sense the more you deconstruct it, that is meant to make sense of a
metaphor, or a kind of like a more a useful model, it's a map, it's meant to make sense of a map.
Probability is a map. It's not the territory. And I'm not saying that you can get perfectly to
the territory, but I'm saying there are maps that are better maps than probability. And that
probability is just, there's a better way of getting at what is understanding fundamental
reality, which is kind of that is an interactive relationship, like what Michael Levin was saying.
That is not, right now we just think about it as probabilistic. It makes it seem like it's just
this mathematical tool instead of it's a relationship that causes the illusion of, or builds the picture
that is probabilistic picture. Anyways, isn't Schrodinger's cat a model based on quantum mechanics,
which is basically a black box, so to speak? Yeah, but I don't know what you mean. I mean, I
don't know if you're talking to me or if you're talking to tech, but we should do an entire
stream on that kind of subject at some point and when I've thought more about how to word what I'm
trying to say. But I explain more like a video game rendering on a screen. No, I know, I know. I
see what I thought about this too when I first started this project is like, it's like a game,
reality is like a game. When you look all of a sudden the map forms, but like before you look at
the map, it's not there. That is true to some degree, but Schrodinger's cat is not a good way
of thinking about that because the cat is sentient and it's a bad model. We can think about the
video game model of, okay, you look at the house that is, you know, when you turn in the game
before you're looking at the house, it doesn't really exist. That I agree with. Like when nobody
looks at the house, the house doesn't exist. The molecules in it, I think exist. The atoms,
I think exist. Even the protons and neutrons, I think exist. I think they're all sentient, but
the house doesn't and that's true. That is a good way of thinking about this, but not the cat.
The cat is a bad one, but you can do this with a car too. A car is a good way, you know, right now
is my car really in the garage? Like when nobody's there to look at it, is the garage even exist
when nobody is observing it as a garage? In a way, no, but the cat argument doesn't make sense. But
you know, if we're going to talk about like non-sentient objects, that is a much better
way of thinking about it. When nobody looks at this pen and I put it and I close it in this drawer,
does the pen exist? That is a good question and I would say no, it does not actually exist as a
pen. But it's not probabilistic either. It's, it doesn't exist. It doesn't exist in a superposition
state. It doesn't exist as a pen. The molecules are there and they are entangled in a certain way
and that's true and, but the pen doesn't exist. Now I open the drawer and I look at the pen and it
yes, now the pen exists, but there is no superposition state where it exists and doesn't exist.
It just doesn't, and then it does. It's deterministic in a way that includes choice and observation.
This is why there's so many issues with Schrodinger's cat and I don't think it's a good model.
There are better models that are actually true. Like think about it with a black, you know, you
put a pen in a box, you close the box, then we can talk about does the pen exist?
As a pen, no, it does not.
When I, okay, anyways.
Sometimes I said to myself that I am a read, write, head of the universe.
I don't know exactly what that, what a SAAS game is, but anyways, I really appreciate everybody's
participation. Please hit the like button and I apologize for the tech issues. I did figure
out the problem, it seems, so those will not happen again other than I have no idea why their
stream just cut out, but I'm probably going to download these, put them together and, you know,
do a bit of editing to make it coherent because this was a good stream and I really like
what we talked about and I appreciated all the comments and I am also very grateful to
Carlos and Michael Levin for putting their conversation up online and having it.
There's three parts to that discussion. This was just part two that they've uploaded and
I, or they've had three discussions, you could say. I definitely recommend checking it out.
The link to the talk that we went over and that included the clips that we,
that I showed are, is in the description below and like I said, please hit the like button.
It helps fuel the algorithm. If I re-upload this and you see it, please hit the like button
because we did lose, you know, some steam, unfortunately, with some tech issues, but
I will be back next week and, you know, lots of big plans, you know, going forward and,
and, you know, very excited for the rest of the year. So, like I said before, though, you know,
I've got a lot of personal stuff going on. I have a child on the way and, you know,
just bear with me as I figure out how to reorganize my schedule a little bit.
But with that, thank you everyone and I will talk to you next week or in
the Discord stream, or Discord call this week. Like I said, if you want to join that, please
send me a private message on Instagram. Thank you. Peace.
