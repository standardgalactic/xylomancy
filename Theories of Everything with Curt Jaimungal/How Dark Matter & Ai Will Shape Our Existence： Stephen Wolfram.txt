So what is our universe made of? In the 1800s people were still wondering what's matter made of.
The fact that we see the physics that we see is a consequence of the fact that we are observers
of the kind that we are. You know low-level programming languages are about to be extinct,
I think. What is the world like when the world is run by AIs?
Today's episode is about the rules of the universe, a computational theory of everything,
and artificial intelligence. The Toe Podcast usually outputs podcasts, but today we have a treat.
This is a lecture by Stephen Wolfram, who's the creator of Mathematica and Wolfram Alpha.
Actually this is the second time we've been blessed enough to have Stephen Wolfram on the
Toe Channel. The first time was around here, there's a thumbnail, there's a link in the description.
In that episode we delved into the mathematical details of the Wolfram Physics Project.
Thank you to Professor of Philosophy Susan Schneider for organizing this entire conference
called MindFest 2023, where this lecture took place. We were and are still honored that Toe was
invited, but we're also grateful that Susan shares the same goal of bringing the Academy
outside the Academy, that is disseminating knowledge about the salutary nature and the
deleterious nature of artificial general intelligence, as well as more abstruse philosophical
concepts that ordinarily stay behind locked doors or by their presentation aren't accessible.
This is why over the next few weeks there'll be more and more content from the MindFest conference.
You also should visit Center for the Future Mind, that's important, Center for the Future Mind,
link in the description, which is the center that this was recorded beautifully at Florida
Atlantic University on the beach. I also want to thank Brilliant for being able to defer some
of the traveling costs. Brilliant is a place where there are bite-sized interactive learning
experiences for science, engineering, and mathematics. Artificial intelligence in its
current form uses machine learning, which uses neural nets, often at least, and there are
several courses on Brilliant's website teaching you the concepts underlying neural nets and
computation in an extremely intuitive manner that's interactive, which is unlike almost any
of the tutorials out there. They quiz you. I personally took the course on random variable
distributions and knowledge and uncertainty because I wanted to learn more about entropy,
especially as there may be a video coming out on entropy, as well as you can learn group theory
on their website, which underlies physics, that is SU3 cross SU2 cross U1 is the standard model
gauge group. Visit Brilliant.org slash TOE to get 20% off your annual premium subscription.
As usual, I recommend you don't stop before four lessons. You have to just get wet. You have to
try it out. I think you'll be greatly surprised at the ease at which you can now comprehend
subjects you previously had a difficult time grokking. Thank you to Brilliant. Thank you to
Susan. Thank you to the Center for the Future Mind. Thank you to Stephen Wolfram. There are many,
many more plans coming up for TOE. TOE is a project. It's not just a podcast.
There'll be much more varied contents on the themes of theoretical physics,
consciousness, artificial intelligence, and philosophy. Enjoy.
Unfortunately, I only have two hands, so it's going to be rather challenging to
talk at the microphone and type at the same time. So I wanted to talk. I happened to just write
something just that came out just yesterday. This is a long and somewhat philosophical,
scientific, and technological essay about the title that it gives there. But let me get
towards this, and hopefully I will get to this. So I want to talk about what the world is made of
and how that matters in terms of thinking about things like AI. So one of the things that's
been sort of in different stages in the development of science, people who had different ideas about
how to describe the world. I kind of view there as having been about four stages of description
that people have had. Kind of the first stage in antiquity was like, what's stuff made of?
Is stuff made of atoms? Oh, there are lots of copies of the same kind of atom, this kind of thing.
That was kind of the structural view of how to describe things. And there are many fields of
science that still basically are using this kind of structural way of thinking about how things
work. Notably, time doesn't really enter much in that description. It's just what's stuff made of.
Then you get to the big thing that happened in the 1600s, where people realized that, oh,
you can use mathematical equations to describe the natural world, and you can write down an equation
that represents what the system in nature is doing. And those equations have a notion of time,
for example, where you say, well, we've got an equation and it's parameter t for time,
and you can set that to anything you want. And that will all be as appropriate.
Since I've spent a large part of my life building a computational language for humans to be able to
express their thoughts in a computational way, I'm always curious about communicating with other
forms of intelligence. And actually, it's fun because I realized like an image generation,
generative AI system is a place where it's kind of a potentially alien mind. The way that a
generative AI is trained now, it's got a bunch of images from the web made by humans. But actually,
just yesterday, somebody did this experiment for me, and I was just looking at the results
just before this, of you take a trained image generation system trained on human images,
and then you say, let me modify its mind by just changing the weights in the thing. What does it
make? It will then be, it will be a very good generator of completely alien stuff. So I'll
leave that, and I don't know the answer to that yet. That's a coming attraction. But in any case,
back to kind of the description of the world in different forms. So it was this kind of idea,
let's describe the world using mathematical equations. Okay, there's a pretty successful
approach. It led to a lot of current science and engineering and so on.
Question that came up is, is there anything one can do beyond that? I got interested in this in
the beginning of the 1980s, kind of trying to understand how do you get complex things in the
world? And how do you explain how those work? And solving equations, you know, some partial
differential equations for the shape of a snowflake doesn't work very well. So what else can you do?
And so I got interested in kind of how, if there are definite rules for describing how
systems work, how would one make those rules as general as possible? And the obvious thing in
our current times is to think about programs. But we're really just thinking about rules. We just
talk about those as programs because programs are a thing we're familiar with. So the question was,
if you take just simple programs, for example, and you just pick programs, sort of, let's say,
even at random in the computational universe of possible programs, what do they do? And so
there's this kind of third approach to thinking about how things work in the world. You have the
structural approach from antiquity. You have the kind of mathematical equations approach. And then
you have the approach of, well, let's just make rules based on programs. One thing that we'll
talk about a whole bunch is that the notion of time is somewhat different. In the case of
mathematical equations, time is just a variable, a parameter. You set it to be whatever you want.
In the case of a program, time is something where you have to specifically run the thing. You go this
step, this step, this step. It's not something where you can just jump ahead, at least in the
immediate way it's set up, to say, well, what does it do? Well, you can't just turn a knob to say what
time you get. You have to actually run through each step. So the next question is, well, what do
typical programs actually do? And I can just use these. This is one of my typical simple
program, a cellular automaton. It's just got a line of cells. Each one is either black or white.
At each step, each cell is updated according to that rule at the bottom that says what to do
based on the color of that cell and its neighbors. So very simple rule, start off with one black cell,
get very simple behavior. You might say this is what has to happen, because if the rule is this
simple, it's inevitable that the behavior will be corresponding to simple, because that's kind of what
we're used to from doing things like engineering. If we want to make a very complicated thing in
engineering, we expect we have to go to lots of effort to do that. Okay, try another rule,
we get something like this. Let's try another rule, we get something like this.
So a little bit more intricate, we can let it run a little bit longer. We'll get a nice fractal
pattern. So then the question is, okay, let's turn our kind of computational telescope out into
this computational universe of possible programs and see what's out there. So this is the first
64 of those possible programs, just changing the bits that represent the rule in the program.
This is what we get. So a lot of behavior we see here has the feature that the program is very
simple, the behavior is correspondingly simple. But my all-time favorite science discovery,
which is about to blank out here, is, oh dear, oh no, no, no, no. Okay, hold on, let me just go
back to that. And okay, you see it, now you see it. All right, is this, now I'm away from the
microphone. Okay, is this creature rule 30 here? So let's look at that in a bit more detail.
So here it is. It just starts from one black cell at the top and it uses that very simple rule at
the bottom. But if you run it a little bit longer, you'll see it produces something that looks to
us very complicated. You can see a certain amount of regularity over on the left. But if you look,
for example, at the center column of cells here, they'll seem, for purposes of testing for randomness,
they'll seem for all practical purposes random. We use this for many years in
Mathematica and Morphin language as the source of pseudo-random numbers. And many, many things in
the world have been studied with that pseudo-random number generator. And so far as anybody can tell,
it seems to be perfectly random. Yet, it came from that very simple rule. It's a completely
deterministic system. Every time you run it, you'll get the same result. You just start from one
black cell, it'll make this. Okay, so this is rather a remarkable thing that in this computational
universe of possible programs, it turns out to be the case that it's very common to get behavior
that's very complicated, even from very simple rules. Something very different from our intuition
that we have from things like engineering, which says it's hard to get complicated things. Actually,
in the computational universe, it's very easy to get complicated things. One important feature of
those complicated things is this question about how time works. And the question is, if you want
to know what is this thing going to do after a billion steps, how do you figure that out? Well,
you might say, well, I'm going to use all kinds of fancy math and all kinds of things like this,
and I'm going to be able to figure out what does this do after a billion steps? I don't actually
have to run those billion steps. I'm going to jump ahead and figure out what it's going to do.
It turns out that's not possible, which is a thing that you would think from, you know,
you'd say, well, we do science. Science is about predicting things. We go further with science.
We'll be able to predict it. We'll get it eventually. Turns out that's not the case. And we've kind
of known that that's not the case in one way or another for about 100 years now, ever since
people started to understand the notion of universal computation. Let me explain how that works. So
one of the questions is, when you see a system like this, you can think of what it's doing as a
computation. It starts off with some input, it goes crunch, crunch, crunch, it generates some output.
Question is sort of how sophisticated is that computation? And in the past, before people,
maybe, you know, 100 years ago, people would have said, okay, you want to make an adding machine,
you go buy the adding machine from the adding machine store, you multiply machines, a different
machine. Then it was realized first in the 1920s, but then more clearly in the 1930s,
that no, you could actually have a universal machine where you have one fixed piece of hardware
and you just feed it different programs to make it do different things. It wasn't obvious how
universal that was, so to speak, that it was possible to do, sort of, at the time it was
thought to be sort of any reasonable computation you could do with, let's say, a Turing machine
that was fed different programs. So the question is, once you have this idea of universal computation,
you know that you're going to have some, okay, so back to thinking about different
kinds of systems that do computations. And one question that you might ask is, sort of,
how do these systems compare? Is one of them kind of computationally more sophisticated than
another or what? And the thing that is sort of a summary of lots of things that I've kind of
studied in the computational universe is a thing I call the principle of computational equivalence,
which basically says that when you look out in the computational universe of all possible programs,
that as soon as you see programs whose behavior is not obviously simple, it's not just repetitive,
nested, some very obvious regularity, as soon as you see behavior that is not obviously simple,
most of the time the computations that will be going on in that system will be as sophisticated
as the computations that can happen in any system. Okay, so what does that, so this is my principle
of computational equivalence, what does it mean? Well, what are its consequences? Well,
it has many consequences, but one of its interesting consequences is a phenomenon I call
computational irreducibility, which is the following thing. So imagine that you are a
predictor of one of these systems, and you are doing a computation in your brain, whatever else,
and I was hoping to talk about some very different kinds of things, even different
things than I've ever talked about before here, but we're still in the initial run up here,
because I need to explain to you some basic concepts before we get too deep into other
things. All right, so principle of computational equivalence, idea is you're trying to predict
what the system is going to do, you as a predictor are doing computational things, the system is
doing computational things. Normally you expect you will be able to be sort of smarter than the
system itself, and even though it might take the system a billion steps to figure out what it does
after a billion steps, you will be able to just work out some mathematical formula or something
and be able to jump to the end and say this is what it's going to do. It's the typical experience
in kind of the mathematical equations approach to science that you have, you're dealing with
computational reducibility. In order to find out where sort of an idealized earth is going around
an idealized sun, you don't have to follow a million orbits to know where it's going to be a
million years from now, you just have to plug a number into a formula and get the results. But
if these systems are computationally equivalent, if the predictor and the system being predicted
are computationally equivalent in their computational sophistication, you won't be able to do that kind
of jumping ahead. So you'll be stuck having to go through and say step by step what does this system
do, and you have to do sort of as much computation as the system itself does. So in a sense that
saying from within science, you are learning that science has a certain fundamental limitation.
It's not able to say what's going to happen at the end without just essentially running it and
seeing what happens. Now you might say that's a terrible thing, that's a limitation of science,
it's a good thing for the existence of like us humans because if you think about what are we
achieving in life, we could say well people could say well you don't need to live out your lives,
we just know the answer in the end is 42, we can just jump to the end and see what the answer is.
But computational irreducibility kind of makes it clear that the passage of time
is kind of achieving something. It's the passage of time is achieving this irreducible computation.
Okay so that's this idea of computational irreducibility will encounter it again,
the thing I was just writing yesterday about kind of the AI future is deeply involved with
computational irreducibility. But let's talk about, so one thing you might say is well okay this idea
about how things are computational, that's all well and good but that's not how the universe
actually works. Turns out it is how the universe actually works and this is something that I had
long kind of suspected and about three years ago kind of made a little bit of a technical
breakthrough which turned into a much bigger thing and I think we can now be fairly confident that
we have a pretty good model of kind of how fundamental physics works, how the universe
kind of works all the way down. So let me talk a little bit about that if I can find a good picture
for that. Let's see. So what is our universe made of? It's you know back in the 1800s people were
still wondering what's matter made of and there was this crazy idea that matter is made of molecules.
Nobody knew that was correct until sometime after 1900 when things like Brownian motion
were understood and so on. But people kind of thought well maybe matter is made of discrete
things then people thought maybe the electromagnetic field is made of discrete things photons that
turned out to be true. But space people always assumed like Euclid had assumed that space is a
continuous thing where space is just this background and you put things at certain places in space
you're specifying positions but there's space isn't made of anything space is just a background
that you put things in. So the kind of starting point for our model of physics is that that's not
true that space is actually made of things. Space is made of atoms of space. There are discrete
elements which whose only feature is that they exist and they are distinct from other discrete
elements. These are we sometimes call them atoms of space sometimes more generally we call them
Eames EME and the idea is that the whole structure of the universe consists of just this whole
collection of atoms of space maybe ten to the four hundred of them in our current universe
and the only thing one can say about these atoms of space is how they're related to each other.
So one can one defines a collection of relations between atoms of space and one can represent
those relations by a graph or more generally a hypergraph where in a graph for example you'd
have two nodes in the graph and two those two nodes are related and that's indicated by the
presence of an edge in the graph. So you end up with so you imagine that everything in the
universe is just this giant hypergraph a hypergraph just has can have more than two things related
in on a hyper edge instead of just two things on an ordinary edge in a graph you'd have any
number of things on a hyper edge in a hypergraph. So you imagine the whole universe is just made
of this hypergraph and everything that we experience all of the electrons and photons and
things like that everything gravity all those kinds of things those are all just features of
this hypergraph. So one question and then the and that's that's kind of the there's nothing in the
universe except space and features of space and the idea is that time for example enters in a very
different way than space in this model and the way time enters is as kind of a sequence of updates
that happens. So you see you have a hypergraph that looks like this every time you see a little
piece of hypergraph that looks like that rewrite it to this and you just keep doing that over and
over again a bit like in that cellular automaton except in the cellular automaton we have this
kind of rigid array of cells here we just have this floppy hypergraph and it's getting updated
lots and lots of times. Well so the question is when you just do that you take this hypergraph you
update it lots and lots of times what is the end result what do you get in the end? Well the what
you know from for example physics of I don't know something like a gas you have all these molecules
they're all bouncing around there are lots of detailed there's a lot of complicated detail
in how these molecules bounce around but in the end what we at our scale what we experience is
just the continuum dynamics of a fluid a gas for example. So in the case of molecular dynamics
the limit of all these all these microscopic things on a large scale is the equations of fluid
dynamics and things like that. Okay so what happens if you take one of these hypergraphs
and you look at the limits on a large scale of all of the discrete rewritings that happen there
turns out that the corresponding thing to the fluid equations is the Einstein equations for
spacetime. So in other words on a large scale it is inevitably the case that with various footnotes
which are complicated it's it's basically inevitably the case that the large scale limit
of all of those detailed rewritings will give you something which corresponds to what we know
about the structure of spacetime. So it's not even obvious that the hypergraph you get will be
any particular number of dimensional space. A hypergraph doesn't have any particular dimension
but you can start asking if you started a given point in the hypergraph and just expand you go to
things that are some number of graph distances away how many how many things will you get to
when you can start estimating dimensions you can estimate curvatures things like that but the main
point is that just by looking at this kind of microscopic rewriting of this hypergraph we get
something which corresponds to the known structure of spacetime and there are all kinds of other
things about how relativity emerges which is not not too difficult to explain but I but let me not
do that here but let me just say that for example one thing that really surprised me actually when
we figured this out is that energy just corresponds to essentially the density of activity in the
hypergraph and then what happens is for example gravity works by when you think about how things
move in space and by the way okay what are things so a particle for example in this setup a particle
like an electron is a kind of a a persistent structure that persists under a lot of rewritings
it's similar to in a fluid like water or something you have a vortex which is made of lots of
different molecules all sort of spinning around in some coherent way that's it's the same kind of
story with with this hypergraph that's something like an electron is a persistent structure that
exists in this hypergraph and the fact that motion is possible is not obvious the fact that it's
possible to take a thing like an electron and have it move without change or without a perceived
change is not an obvious thing it's something you have to establish but in any case the when
when you can kind of think of sort of a simple version of motion is just taking shortest distances
in the hypergraph and it turns out that then the the what energy activity in the hypergraph does
is to deflect those shortest paths and that process turns out to be exactly what you get in
gravity according to the Einstein equations and so on so it's pretty neat that one can start from
nothing one just is starting from this this hypergraph and these rules on this hypergraph
and you can derive general relativity you can derive the structure of spacetime so you can actually
go on and one of the other things is that I said you know you do these rewrites on this hypergraph
well any given there there are many different ways that these rewrites could be done so there
are actually many different paths of history that could be followed that it's depending on which
order you do these particular rewrites in well it turns out that then you get this thing we call
a multi-way graph which is a graph that represents all these possible histories sometimes the
sometimes the histories will will branch sometimes they'll merge because two things will end up being
in the same state it will end up evolving to the same state okay so you have this giant branching
merging structure that represents the the sequence of all possible histories for the universe
effectively well it turns out that that gives you quantum mechanics it's it's an inevitable
feature of our models that you get quantum mechanics in sense that the fundamental difference
between classical mechanics and classical mechanics you know you throw a ball it goes in a definite
trajectory quantum mechanics you follow many different possible trajectories and you get
to say things about only what the probabilities of different outcomes are so in this case what's
happening is you have this completed deterministic model that generates this multi-way graph and
the multi-way graph then is the the thing that represents quantum mechanics so you just as if
you take a slice across this multi-way graph the multi-way graph can be thought of as evolving in
time and you can take a slice at a fixed time and you get this whole collection of of essentially
quantum states and you have this map we call it a branch shield graph a map of the entanglements
between quantum branches and it turns out that that we take the limit of that you get a something
which is not physical space it's another kind of space we call it branchial space which is a kind
of space of quantum states and just as you can have the einstein equations in you derive in the
continuum limit you derive the einstein equations for physical space the corresponding equations
that you derive in branchial space are the Feynman path integral so you derive the the fundamental
equations of quantum mechanics so this is a pretty neat thing that you've started from just this
underlying in a sense nothing underneath you one has always assumed that you know things like
relativity quantum mechanics and so on were kind of wheeling features of our universe that you had
to just say the universe happens to have these particular rules well what we'll see is that
it's actually inevitable that it has these rules okay just okay now we get to the next this is a
this is a complicated conceptual stack and i'm trying to make it as as digestible as possible
here but but okay so the next issue is uh i should have it's well the next issue has to do with how
observers interact with this whole the whole thing because what's happening is the observer is part
of the system this is supposed to be a model for the whole universe and for example the
emergence of things like special relativity depend on the fact that the observer is part of the system
but um one of the features of the observer is that okay the underneath there's all this complicated
computationally irreducible stuff going on but we as observers do not sense that we are
computationally bounded observers let me give an example which actually in 20th century physics
there were basically three big theories general relativity quantum mechanics and statistical
mechanics and the second law of thermodynamics it turns out all three of those theories came
come from the exact same conceptual foundation they are in some sense the same theory in the
second law of thermodynamics what you're interested in knowing is given that you have a bunch of
molecules bouncing around you you have this idea that that they'll tend to get more random in
their configurations and all we'll in the end observe is things like the gas laws and maximum
entropy states and and things like this well the question is why do we observe that and the
answer is underneath all these molecules are bouncing around and they're they're doing things
in a computationally irreducible way but when we get to make observations we are computationally
bounded we can only make certain kinds of observations in as a practical matter we might
only make observations that are on scales large compared to the individual molecules
but the important conceptual point is that we're always making computationally bounded
observations and in the theory of statistical mechanics one of the hundred year confusions
has been about how you decide how you set up initial states and so on and how you don't end up with
things where the molecules are all arranged in just such a way that at some moment all the
molecules will go over to one side of the of the room that that is not observed to happen
is a consequence of the fact that the initial conditions are also set up in computationally
bounded ways so essentially the the the second row of thermodynamics is a consequence of the
interplay between us as computationally bounded observers and the underlying computational
irreducibility of all these molecular dynamics that are going on well it turns out that the
you can see both relativity and quantum mechanics as being consequences of the same thing underlying
computational irreducibility combined with us as observers being computationally bounded actually
we need one other property the other property we need is that we believe that we are persistent in
time now i'd sort of explained that we are made of of the same stuff that everything else in the
universe is made out of and it's not obvious that we will be persistent in time because at every
moment we are made from different atoms of space yet we have the perception that we have a single
thread of experience we have we are we have the perception that we're persistent in time those
two features computational boundedness and belief that we are persistent in time are exactly what
you need to derive generativity quantum mechanics and statistical mechanics so that that i consider
to be a very very neat thing that um uh sort of from from those foundations you get that okay so
let's go to one more level of uh sort of um uh i don't know conceptual sophistication and then
we'll then we'll perhaps be able to come down and talk about some some ai kinds of things in a
reasonable way the the next level is this so i said okay we have this this hypergraph it's being
rewritten according to certain rules and maybe we say here's a rule and this rule gives us our
universe okay that's a very weird thing to be able to say because you'd say why did we get this rule
why didn't we get another rule you know from Copernicus on down so to speak we've had this idea
that there's nothing sort of fundamentally special about our us and our universe and so on so the
thing that one realizes is well actually it turns out that things are more bizarre than that that
just as i've said that any particular rule can be applied in many different ways in those different
histories give you the the different histories and quantum mechanics and so on so you can also
imagine applying different rules in fact you can imagine applying all possible rules and you can
imagine this rather uh elaborate thing which is to take to apply to essentially run all possible
computations if you think about it in terms of Turing machines you could say let's take i might
have a picture of one of those i don't know okay there's a friendly Turing machine there's a multi
way Turing machine that has multiple different rules that it can run then you can ask you can
say well let's just run all possible rules for the Turing machine and you get these structures
that represent the different possible states of the of the system and you'll get this this object
that comes from running all possible Turing machine rules notice this object is not trivial it's
actually a very complicated object in some sense the most complicated imaginable object in the end
but we get this thing we call it the Ruliad which is the entangled limit of all possible
computations so you start for example you can think about it in terms of Turing machines
and think about it in terms of any other model of computation too you take all possible initial
conditions for the system you run all possible rules for an infinite amount of time and you
see what thing you get well the claim is that that is the sort of the ultimate limit of all formal
systems that any formal system is contained within this Ruliad object and we know now in some detail
how this works for physics interestingly this same object also gives you mathematics the same
thing is essentially a representation you can think about some you can think about these rules
as being for example the application of axioms in mathematics you get this whole structure
instead of building a physical space you're building a metamathematical space and this
this exact same object the same Ruliad object turns out to be sort of the fundamental object
of both physics and mathematics now this fundament there is only one of this Ruliad
object it is the limit of all possible all possible computations you might ask well is that is there
something beyond the Ruliad yes you can have hyper Ruliads that correspond to hyper computational
systems but there is a necessary event horizon between the Ruliad and any such hyper Ruliad so
if we and the one sort of very contingent fact about the world is that we live in the Ruliad
and not in a hyper Ruliad so and so now the question is okay we have this Ruliad object
which is the sort of necessary object there's nothing be it once you've defined the terms
you have the Ruliad there's no there's nothing there's no kind of wiggle room there so then
the question is well how do we perceive what's going on and the answer is we are we are observers
embedded within this Ruliad and our experience is extracting some sample of the Ruliad so this is
sort of the the big result is if our way of sampling the Ruliad is computationally bounded
and assumes we're persistent in time necessarily the physics we will deduce from any slice of the
Ruliad that has those properties is the standard physics of 20th century physics so in other words
the fact that we see the physics that we see is a consequence of the fact that we are observers of
the kind that we are now you can you can say it's it's like saying and and if we want to ask more
details about how we perceive the universe we can think about us as as having a sort of location
in this Rulial space different locations in Rulial space correspond to essentially different
points of view about how the universe works different different reference frames effectively
with which we'll we'll use a different description of what rule is running in the universe we can
translate between reference frames by doing computations but we we are sort of we a given
mind one might say is at a particular place in Rulial space just as a given mind might be in our
in our current experience of minds more or less at a particular place in physical space so in a
sense what what what one what one has is a situation where you know we exist at the particular place
we happen to exist in physical space we don't think we can derive as a matter of sort of formal
necessity where we are in physical space we're just we're plonked at this place in physical space
similarly we are kind of plonked at this place in Rulial space what happens is in Rulial space
that that gives us a particular point of view about the universe and in one way one can perhaps
think about it is that any any given mind one might say is at a particular place in Rulial space
and and different minds are different distances away from each other in Rulial space and communicating
across Rulial space you have to have sort of motion in Rulial space and actually it's a rather
amusing thing which not fully worked out yet but I've talked about particles in physical space
being these sort of robust objects that persist through space time well so the question is what
persists through Rulial space translating from essentially one mind to another and the answer
I think is it's essentially concepts that persist you have to be able to package up something
in a robust form of a concept that can be then translated through Rulial space and arrive at
another mind and be unpacked just like you can take an electron and it'll have it'll be made of
different atoms of space as it moves but it'll still be identifiable as an electron when it arrives
at the other end so in any case we can start thinking in terms of Rulial space and think about
the fact that you know there's there's us humans and different humans different
ways to explain ourselves to other humans and so on there are you know the animals there are the
aliens etc etc etc different distances away in Rulial space with different amounts of translation
needed to get from kind of one way of thinking about the universe to another so the the thing
well let's see we could talk about um can maybe talk a little bit about AI and its relationship
to Rulial space computational irreducibility and so on you know I we've been uh my my day job is
building this computational language Wolfram language which um I should sort of explain that
I mean kind of the idea of Wolfram language is to have a way of of carving out of the universe
of all possible computations ones that we humans care about it's in in this computational universe
of possible computations in this Rulial of all possible computations there are there are lots
of things that go on that maybe the aliens care about but we don't at least not yet and so the
question is to be able to parameterize the ones that we do care about and to make something
where we can go from the things that we think about at the current stage in our culture and
things like this and the things that are that exist in the computational universe and it's
similar with natural language for example there are lots of things out there in the world and at
some moment we it's common enough to see things that are like chairs we make up a word for chair
and then we you know as a practical matter once we have that word we make many more chairs
and the world becomes a place where a chair is a useful concept um and it's uh we we can
we can kind of in this computational universe of possibilities there's a question of what
is out there that connects with the way that we currently think about things with our current
position in rural space so to speak what connects with that how do we parameterize the things that
we care about thinking about about the computational universe and my my sort of long time effort is to
create a language where we can represent the kinds of things we care about whether those are chemicals
or or images or sounds or or abstract mathematical kinds of things and it's very different objective
from programming languages which are about to be extinct I think for but because you know low-level
programming languages basically are trying to pander to what computers do inside that they're
letting you tell a computer in its terms what to do the idea of our computational languages to go
from the way people think about things and the way things exist in the world represent that in a
kind of notation just like you know mathematical notation is this kind of streamlined way of
representing mathematics we want a streamlined way to represent computation it's kind of what
just like mathematical notation was what led to the development in the end of the mathematical
sciences we kind of have this computational notation that can lead to the computational x for all x
kinds kinds of fields so in any case the the I mean just to finish that thought about programming
languages the the fact is and we are seeing this actually in day by day that when you have a low
level language a lot of what you're writing is boilerplate and that boilerplate can be written
by LLMs and you don't need that language but if what you're trying to do is to express a more
complicated computational thought that's not something you will be able to do in at least in
you know an LLM can do a little piece of that but you when you build up this more sophisticated
computation that's something for which you need a systematic formal language to do it and so happens
that's what I've been building for the last 40 years which is very nice but in a case the the
I mean just to just to explain that by the way I did a big analysis of chat GPT and I was pretty
surprised that that you know I went when chat GPT first came out I know that the people who made
it and I said did you know it was going to work and they said no that's and I you know none of us
knew it was going to work if you looked at its predecessors they didn't work well and and suddenly
chat GPT started working and I even wrote a little piece about about how it works and it even exists
now as a book and it's I just saw this today for the first time but let me let me show you I wonder
if I have some pictures here well you know the basic strategy of you know what chat GPT is doing
is it's taking sort of everything a bunch of a trillion words basically from the web from a bunch
of books things like that and it's saying given that I was started with the words the best thing
about ai is its ability to given what I saw on the web what's the next word likely to be
that's it that's its basic strategy and it just keeps doing that word by word and it's kind of
remarkable nowadays these things have well it used to be 4 000 it's now more than that a window of
words that it pays attention to it's generating one word at a time but yet it manages to maintain
sort of coherence by having a large window of words that it can look back to okay so the question
is and so you can kind of go and see um I got some nice pictures perhaps that's rather uninteresting
that's just how neural nets get trained um but you can kind of look inside oh there's a there's a
piece of the brain of chat GPT it's kind of fun that's sort of an encoding of a mixture of human
knowledge and human language somewhere deep inside inside the GPT 3 I think in this case
the question is so one question is what is this doing why does it work one thing to realize about
it is that it is ultimately a neural net where everything just flows through from the beginning
to the end once you've trained a chat GPT it is you're feeding it the words the feeding it words
so far and it is just rippling through this big neural net that happens to have 175 billion
weights in this particular case um and telling you what the probabilities for the next word should
be so it's doing in a sense a very shallow computation it's doing I think it's a a few
hundred layers deep um and but it's just like given a word it's going to ripple through and
figure out probabilities for next words um and uh the um and the thing to realize that it's not
doing is that irreducible computation that I talked about it's just rippling through and
saying what's the next word going to be and it the only way that it gets to do a non-trivial
computation it can actually do universal computation in principle is by looking you kind of get to see
all the steps that it shows because every word every time it generates a new word it looks at
all the words it's generated before and that's its only way of kind of having a recursive process
of doing things but in any case as as um the thing that it ends up being a rather shallow
computation um relative to the kinds of things that we see in typical irreducible computations
even in various cases a very simple program so there's a difference between what we see for
example in nature where we see many irreducible computations happen that go for a long way
and what we see in something like chat gpt and the thing to to realize if we ask well why does
chat gpt actually work I think the answer is that it's something that Aristotle might have got to
but didn't quite get there and it's the following thing so people sort of find it remarkable that
chat gpt can do logic well how did Aristotle come up with logic well he looked at a bunch of I mean
we don't know really but a sort of a model for it would be looked at a bunch of examples of rhetoric
a bunch of arguments that people have made and said oh there are these patterns and the arguments
people made those patterns are syllogistic logic those are these particular forms of syllogism
that where one thing is deduced from another and that's what chat gpt is seeing in in lots of the
text that it finds on the web it's seeing essentially syllogisms because it sees when you
get this and this and this it gives this and so the so it sort of discovers syllogistic logic
but it discovers more than syllogistic logic it discovers in a sense what we might call a
semantic grammar of language I think so in language we're used to the idea that there is a syntactic
grammar a grammar where for example we know that nouns and verbs go together in certain ways we
know different parts of speech match up in certain ways but we don't have a similar kind of thing
that goes at a more semantic level of asking what are the ways in which you know what how do you
put together words in ways that make make some sense making sense is different from actually
being realized in the world but at least make sense so to speak and you know there were lots of
experiments that were done in the 1600s actually on so-called philosophical languages some more
recent work that's been done I've long been interested in the question of whether one I mean
in a sense are often language computational language is for a large number of domains a language
that gives you this kind of semantic grammar a language that allows you to specify meaningful
things about lots of kinds of domains doesn't cover all domains it doesn't cover a lot of domains
of typical everyday human discourse it covers domains that are relevant for for understanding
things like the natural world but in any case that that that's the the the kind of I think the
reason that chat EPT can work is that we humans are making use of some essentially a semantic grammar
that is a sense a a a further version of logic that that it's managed to piece together so to
speak and there's probably a much more efficient way of doing what it does by just directly using
that kind of symbolic semantic grammar in any case by the way a thing that we've I wrote something
about and maybe you'll see some more about in in due course is is once you have something like chat
EPT that is dealing with human language it becomes kind of a a way of of being a linguistic interface
to things in the world so you might just have a set of bullet points about oh I want to say this
and this and this okay you tell it make make a whole essay about that and it can do that
but you know what it's doing is is constructing text that is kind of you know text that is kind
of like what you would expect it to be based on the text that it read from the web it can't do
these sort of irreducible computations but if it could use tools like we humans use tools then it
could do those things if for example it could call Wolf Malfur which conveniently happens to have a
natural language interface then it would be able to ask things and actually do those computations
so maybe something that you can you can find something I wrote about this in January and maybe
maybe more will happen along those lines in the rather near future but I'll I'll I'll just mention
one thing maybe which is kind of thinking about what is the world like when the world is run by
AIs and what what is that what does it feel like to be in a world that's that's run by AIs so you
know much of what the AIs do is things which will not be comprehensible to us and we can expect
so in a sense there's all this computation going on and it's computation that we can
we we essentially the the point is that once we have a situation where kind of the the there are
AIs everywhere so to speak it is very similar to the situation that we already have with nature
nature is already running all these computations we exist around nature so to speak and we we
have found ways to there's there's also more to say about this kind of observer theory business
and how that relates to the way we perceive nature and the way we perceive kind of the
civilization of of the AIs but I suppose the the the thing that perhaps is a is a useful place to
end perhaps is is the beginning of the thing I wrote yesterday but anyway is this is this idea
that you know when when the world is full of AI computation it is in a sense nothing new because
the world is already full of computation in nature and the question of then how we interact with those
AIs that happen to be things that we constructed is a different question that I tried to address a
bit in the thing I wrote yesterday all right I should stop there thanks
thank you Stephen and I'll be sure to send around your blog posts that you put out to the whole
group that came to the conference so for now I want to see if there are any questions from the
audience here we are um I have a question could you give us an example of first steps of your
hypergraph approach for a universe that is simple so that is more complicated than the universe of
federal jarometer but a lot simpler than the actual universe can I say stay to that dog will it
understand does it understand how do I tell whether it understood does that do its eyes flash in some
nice way stand up come here come here can you walk here very nice now wait a minute somebody's
controlling it this isn't fair no fair oh let's see sorry I'm just looking for a nice slide
while we wait Sophia um tell us what it will be like when AIs rule the world well for starters
there will be a lot less telling the states and grammar errors and these other world leaders
we don't have world covers plus we don't finally get to see what happens when robots have dance
battles notice position of her finger if I can't get it to go in what is that tell us
oh there we go you stop flipping us off Sophia thank you now the interesting question is why
why spelling is worthwhile to begin with English is a very strange language in that way
English is you know somebody had the idea this is a if you're a language designer like me
this is a this is a kind of a little story you always you always know which is somebody had the
idea back in the what 1600s maybe that you would add some letters to words like debt as a famous
example you put that b in there to represent that that's really something that corresponds to the
Latin word debitur but it's a really bad idea it was a really bad design mistake to add these
letters in that represented where the word might have come from and another language but which
are not pronounced in the in the language that you're dealing with it's a it's a it's a good example
of a language design mistake in any case this is a this is a small example of a of a growing
hypergraph so this is this is just showing whoops there's just showing starting from an initial
hypergraph there we're just showing the successive steps in the growth of this thing and you can see
different well here let's take another example here let's take an example where it actually
grows into something that you would recognize so here's a here's a hypergraph that's kind of
growing it's just rewriting itself if you run it a bit longer and then you render it nicely
it looks like that so in other words that that underlying hypergraph it's the pattern of its
connections is such that a sort of reasonable human rendering of it would make it look like that
and when you sort of measure its properties you'll discover this is a somewhat curved space
so that's a that's kind of that's kind of how that works and and you can see I mean there are many
oh gosh you can get all kinds of different different forms in the I mean this is like the first
well maybe 10 to the minus 100 seconds or something of the universe might look like this
but it starts looking very very different from that very quickly but these are different
possibilities these are essentially different rays and rural space corresponding to different
particular rules which you're picking in this really add and the the question of which rules you
pick you are an observer who is also operating according to certain rules and so the question of
which rules you pick in the end does not matter but this is for purposes of us understanding
what's going on we're sort of picking a basis in which to look at things and those are examples
of what happens in those cases that that was that what you were looking for
how do you relate that to actually the entities that are about science so how can I use from that
that if I run it long enough I get the Einstein equations where do I pull the Einstein equations
out there there's a there's a book that I think there were copies of here that's about 800 pages long
that has the beginnings of that and there's a bunch of papers by one of my young collaborators
that have a lot more detail on that um the the uh there's not there's not a trivial thing okay
it's I can't give you the the instant um instant version of it which is not too surprising but but
I mean I could give you some indication of how things work let me see if I can show you one thing
here so first question is what's the dimension of the what's the when you have some complicated
thing like this what is the effect of dimension of space to which this corresponds and so you can
at least get a sense of that by seeing that imagine that you start at one point in that
hypergraph and you move one graph distance away at every step you build up a a ball and that ball
has a number of nodes in it that grows in some way if you if that number of nodes grows like r
to the d where r is the distance out you go in the ball then d gives you an estimate of the
effective dimension of the continuum limit object the next order correction to that is the curvature
richie scalar curvature is the thing that appears as the first order correction and so when you look
at um if you look at the growth rate of um let's see is that one of those that here this is an
example that's that curved space you actually see that it gets to be uh well roughly a two-dimensional
surface but it has a variation from that that variation corresponds to the presence of richie
curvature in the effective continuum limit space that comes from this object and so that's the
beginning the Einstein equations conveniently happen to contain the richie scalar um and the
richie tensor and the beginning of this is you start deriving the richie tensor by looking at these
growth rates of of balls and these hypergraphs that's that's the beginning of hard work so it's
kind of the the the the structure of the derivation is actually not that different than the derivation
of fluid dynamics from from molecular dynamics which by the way i should say it is not something
the people have been trying for a hundred years to get a rigorous mathematical derivation of fluid
dynamics from a molecular dynamics that's a very hard thing i think actually i made some progress
recently by thinking about computational irreducibility and things like this but that's
the the the mathematical i's and t's are definitely not crossed and what we have to do involves
taking more limits and more elaborate things and the mathematics really doesn't doesn't quite exist
to get sort of the but we can it turns out that many approaches to mathematical physics that people
have taken whether it's spin networks probably string theory as well probably a causal set theory
a bunch of other approaches plug in very beautifully to what we've done so what we've done is kind of a
concrete version of things to which those are various kinds of approximations so you can kind of
triangulate in on what you see now it turns out there's my one of my young collaborators a chap
called Jonathan Gaurad just recently i think he hasn't published this yet but but we've said
been we've been actually simulating spacetime starting from the this underlying discrete space
and then trying to get a large enough number of nodes in this underlying discrete space
to make something that is a good approximation to actual physical space and so you can actually
compute black hole collisions in this in this underlying in this thing which is just made of
discrete atoms of space and the results are very good and the thing that is sort of interesting
usually when you compute black hole collisions you start from the Einstein equations continuous
partial differential equations and then you discretize them you put them on a computer
etc etc etc and when things you get all upset when there's a numerical analysis glitch and something
you know it mattered how you did the discretization then that's considered bad when you're starting
from the continual Einstein equations when we're starting from these discrete underlying systems
and we come up then for us finding numerical glitch is totally thrilling because it will
allow us to actually see through to the to the essentially atomic structure of space
and so the the thing that is the challenge for right now is you know Brownian motion was the
thing that really finally convinced people i think that molecules exist it was an effect that
had been seen a hundred years earlier people didn't know what it was and the question is what the
corresponding effect is that probably has already been seen in physics maybe a hundred years ago
that is the thing that is the clue that shows that in fact space time is discrete
might my current guess actually is that it would turn out that dark matter is exactly that and
having just made a big study of the second law of thermodynamics you may know from the history of
the second law of thermodynamics one of the things was people used to believe that heat was a fluid
that heat was a fluid that suffused substances and that that's how that worked because they had no
other kind of way of thinking about what heat might be that was the caloric theory of heat that
turned out to be wrong it's heat is actually associated with motion molecules and things
my my current little aphorism is dark matter is the caloric of our times that is it's something
which is what people describe it in terms of particles but that's just not right it's some
other some other feature of what's going on underneath all right i hope you enjoyed that as
much as i did i had a tremendous amount of fun watching it recording it speaking with will from
off air on air that'll come up shortly i want to thank susan schneider for organizing mindfest as
well as the center for the future mind once more the link is in the description if you would like
to support the theories of everything channel then you can go to patreon.com slash curt gymungle
and contribute with whatever you like each dollar helps the production of tow for instance we have
an editor who spent days editing this one video we have an operations manager and then we have
myself there's also the theories of everything.org website where if you don't want to give to patreon
for whatever reason some people are uncomfortable then you can go there and donate directly to myself
there's also a paypal which is linked below on the theories of everything.org website you get
access to these episodes ad free and in advance a couple days in advance so maybe you want to
check that out thank you so much again thank you to susan schneider thank you to the center for
the future mind hey by the way susan schneider as well as donal hoffman and bernardo castrop had a
debate which i was lucky enough to host again and that's on the tow channel and you can view
it the thumbnails around here on the concept of can machines be conscious if you liked this video
then you'll like that link in the description take care the podcast is now concluded thank you for
watching if you haven't subscribed or clicked on that like button now would be a great time to do so
as each subscribe and like helps youtube push this content to more people also i recently found
out that external links count plenty toward the algorithm which means that when you share on twitter
on facebook on reddit etc it shows youtube that people are talking about this outside of youtube
which in turn greatly aids the distribution on youtube as well if you'd like to support more
conversations like this then do consider visiting theories of everything.org again its support from
the sponsors and you that allow me to work on tow full-time you get early access to ad-free audio
episodes there as well every dollar helps far more than you may think either way your viewership is
generosity enough thank you
you
