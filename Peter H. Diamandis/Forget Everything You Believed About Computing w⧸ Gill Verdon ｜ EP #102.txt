There's a lot of dystopian thinking in the world right now.
Either you embrace progress and abundance and growth or...
How tightly can we embed the machine learning algorithms into the physics of electrons?
The tools that you're about to inherit are tools that can boost intellect,
not just thousands, but billions of fold potentially.
If people have a mindset that they want to embrace technological change,
they want to figure out how to best augment themselves, augment their businesses with AI,
they will have a place in the future.
Welcome to Moonshots, Peter Diamandis here.
I'm about to have a conversation with Guillaume Verdun.
He's the founder of the Accelerationist Movement, Effective Accelerationism, EAC.
He's also the founder and CEO of Extropic AI.
It's a new form of computation, thermodynamic computing, different from digital, different than quantum.
He spent three years at Google working with Sergey Brin.
He's a quantum physicist, a brilliant individual.
We're going to go deep into why is it important to have an Accelerationist abundance mindset
and what is the future of AI computing?
When the cost, the thermodynamic efficiency is something that is hundreds of thousands of times cheaper.
We make this ubiquitous throughout the universe.
His mission is to increase the amount of intelligence per watt and the amount of intelligence in the universe.
If you love conversations like this, please subscribe, please upvote this.
Help me bring incredible Moonshot engineers like Guillaume Verdun who goes by Gil to the Moonshots podcast.
All right, let's jump in.
Gil, welcome to Moonshots. It's a pleasure to have you here, buddy.
Thanks for having me. Super excited to be here.
Yeah, we've seen each other twice in the same quarter, first off on the stage of Abundance 360 this past March.
And then you joined us at the XPRIZE DeepTech Quantum Trip in up in the Bay Area.
Yeah, it was fun.
That was a lot of fun. Yeah, met some brilliant folks there, always amazed by the quality of the XPRIZE community.
So super happy to be here.
Thank you. So today we're going to talk about two of my favorite subjects.
The first subject is the whole abundance acceleration movement.
And just to give people an understanding of how fast things are changing and why that's a good thing.
Because so many people are fearful of the speed of change and want to put on the brakes.
Mostly I would almost say governments are like, if you don't understand it, the answer is stop, slow down.
And so why is that a bad idea? And can it actually be slowed down and stopped?
The other is what you're building, which is a new class of computational hardware to enable this acceleration movement.
So we're going to jump into both.
If you don't mind, let's start with what is your moonshot?
If you, you know, you're on Verdun have a moonshot that you want to make happen the next decade.
What is it? What's the equivalent to Elon's going to Mars for you?
That's a great question. I think having a processor that is brain scale in terms of numbers of parameters and model capability,
but that is for more energy efficient. I think that's my more energy efficient than the brain.
Yes. Yes. The brain's pretty damn energy efficient.
That's right. And why is that? And that's what we're trying to reverse engineer.
Interesting.
So just to put a number on it for folks, you know, 100 billion neurons, 100 trillion synaptic connections running on what?
How many watts do you tens of watts?
I think like 14 to 20 watts of energy. But the equivalent for a GPT-4 system would be what?
Tens or hundreds of millions of times less efficient.
Yeah, it's really, but you want to be more efficient than that.
More efficient than the brain. That's what we're aiming for.
Amazing. You know, I am listening to you and I've studied your work and I'm just fascinated by it.
I wrote down that your mission would be, you know, the ultimate substrate for AI compute to build the ultimate AI computing machine.
And also to propagate as much intelligence per watt in the universe.
Yes.
Is that fair to say? What does that mean?
Yeah, I would say, you know, there's kind of two dual missions that come together towards one greater mission.
The broader mission is to scale intelligence throughout the universe, scale the total amount of intelligence in our corner of the cosmos.
But to do that, you have to increase, you know, how much energy we produce, right?
Going up what is called the Kardashev scale.
And we'll talk about Kardashev, yes, for sure.
It's a way to measure how much energy we produce and consume.
And so that's kind of the core cause area of EAC is to argue for policies that will help us scale our energetic consumption and growth of solarization.
And with Extropic, our goal is to get more intelligence per watt.
And that is ultimately a race to the bottom, right?
It's how tightly can we embed the machine learning algorithms into the physics of electrons?
I love it.
I love it.
We're going to get into all of that.
And I want to talk about the accelerationist movement and talk about Extropic hardware.
Cause if you love tech and you love the future, you're going to love this conversation.
All right.
So let's begin with the accelerationist movement.
What is it?
You know, you wrote a manifesto.
Where were you?
Why did you write this?
You know, it aligns 100% with my world vision, but talk about what is the EAC movement?
What's that stand for?
And how do you think about it?
Yeah.
I think, you know, the original manifesto I wrote around the same time as founding Extropic,
I was going through a bit of a lull just, you know, founding paperwork, right?
You know, you're waiting on, on some, some lawyers and so on.
And I had, I was like, okay, that's probably the last two weeks of vacation I have the
rest of my life once this gets going.
And so let me, let me try my hand at philosophy, right?
Instead of just doing science and math and algorithms, which, you know, I did for more
or less 10 years before that, what if I just like tried to apply my sort of physics mindset
to understanding the rest of the world and write up, write something up pretty quickly?
I've been having, I was having conversations late at night with other technologists sort
of online, there's sort of communities where people have anonymous accounts, right?
Cause they're employed by XYZ and they don't want their opinions to reflect that of their
employer and they want to have the freedom to experiment with their thoughts, right?
And have candid conversations of like, hey, where's civilization going?
Where's society going?
Where's this all going?
And we would have these conversations late at night and essentially we decided to write
something up and, you know, I added my own twist to it and, you know, put out the manifesto.
It went viral.
At first it was kind of dismissed and then it just kept compounding, kept compounding
and now it's kind of, you know, truly like a counter narrative to the culture of sort
of AI doom and over-regulation and safetyism that we see today.
I mean, there's a lot of dystopian thinking in the world right now, right?
There's a lot of fear.
And I remind people that our default mindset is that of fear and scarcity, right?
Fear and scarcity evolved in the savannas of Africa 100,000 years ago and it saved our
lives back then.
And today it doesn't contribute.
It's not valuable in the world we live in.
E slash ACC stands for?
Yak.
Yak for effective accelerations.
And your manifesto, if you're going to summarize it, would be what?
The idea is to understand the process that got us here, the process of progress itself,
of advancement of civilization, of inspiring ourselves from, well, trying to understand
it from a physical standpoint, right?
Like there's been quite a bit of work in the physics of life, right?
Like understanding how did life assemble and become so complex, right?
So the science of complex self-organizing systems that have energetic constraints.
So out of equilibrium thermodynamics and taking inspiration from those ideas and applying
them at civilization scale to have a prediction of where are we going?
How do we reach the better futures ahead?
And how do we maintain a sort of robust advancement of progress towards this greater grander future?
And essentially what I saw was that we need to maintain variance and dynamism as a core
value for us to be malleable and adaptive to whatever challenges come our way rather
than trying to freeze everything, slow down and panic.
Actually what we want is actually more malleability, more dynamism, more acceleration.
So important.
So important.
The adaptability, the agility, I would say, is if you don't have that when you get hit
by a disruptive force, it can destroy you, right?
The analogy I use and you're free to use it is, you know, 66 million years ago when an
asteroid struck the earth, the dinosaurs that were slow and lumbering were not malleable.
They were not adaptive and they died, but it was the furry mammals that flittered around,
jiggled around to use the free electron analogy that ended up becoming dominant.
And so that malleability and agility today comes from what?
From millions of entrepreneurs trying millions of ideas?
I think like every potential parameter space of how we organize ourselves, what are our
cultures, how we do things, which technologies we're pursuing, where we live, how we live,
every possible space should have some amount of variance to it and we should allow the freedom
to explore and dynamically optimize ourselves.
Because, for example, the dinosaur example, if you didn't have genetic variance at the
time, if we were all big dinosaurs, we would have been wiped out, right?
But because we had variance, we were robust to a change in the landscape, right?
So I would say right now, there is a sort of weird trend in the past, I don't know,
decade or so with the arrival of the internet that there's a trend towards over-centralization
and top-down control of culture amongst other things, right?
And now it's that sort of centralization around a monoculture is trying to also potentially
control a core technology like AI, right?
So if AI is in the hands of very few, it's not a lot of variance in how we do AI, right?
There's going to be a couple prescriptions.
Dominant models, dominant players.
Exactly.
And their tactics for how to align the AIs are going to be the only options we have.
And to me, that doesn't seem robust because there's too much uncertainty right now.
And in times of uncertainty, you want to have variance in how you do things so you're hedging your bets, right?
Yeah, there's a great biological analogy.
You really want genetic variance.
So when a new thing enters the ecosystem, it might kill a large percentage,
but a few of the variations will be resistant and will survive.
So we're talking about human survival in one sense here as an underlying optimization function.
But we're also talking about sort of how do we keep up a varied culture,
different subcultures will have different opinions about how to embrace technology or reject it
and really in the end, each subculture is going to be tested.
You might have people that want to merge with the machine,
people that don't want anything to do with it, some people that fully embrace it.
And I think all paths will be explored.
But in the end, whoever, like the message of IAC is, you know,
there's a tendency of the universe towards growth and it will adapt and reconfigure everything that is alive towards this growth.
And whether you align yourself with this growth or not is your choice,
but that choice ultimately has consequences as to whether or not your influence
or you are part of that, those likely futures, right?
And that comes from some very esoteric equations from thermodynamics,
but essentially it's a message of, hey, either you embrace progress and abundance and growth
or, you know, maybe you're probably not going to be, you're going to miss the boat in a sense.
In fact, at the Abundant Summit this year, Alexander Wiesner Gross was there.
I was talking about, AI is coming on strong.
It is going to, you know, reach whatever we call AGI and then digital superintelligence.
There's no barrier that says AI only goes towards an IQ of humans.
It blasts through and continues out of an item, especially if the hardware you're building comes into existence
or when it comes into existence, I should say.
And the question is, does humanity couple with it or do we decouple?
And that's really a lot of the interesting conversation.
I'd like to talk about that.
I'd also like to talk about what people's fears are one second because, again,
so the coupling with AI means that we get a chance to accelerate alongside it, enabled by it.
It's almost like when life began and we had these prokaryotic life forms
and they absorbed mitochondria and became a eukaryotic life form
was able then to utilize the free energy of oxygen for oxidation to grow more rapidly.
So today we have our phones and our devices are kind of like our mitochondria to some extent.
Which I definitely want to implant in my head.
They're intellectual powerhouses of our system, right?
And in a sense, we're already pretty augmented.
We kind of feel naked and incomplete with our phones.
And, you know, over time, we're going to have wearables that share our perceptions,
share our experiences, have priors of our actions based on the state of the world
and on previous history of what they've seen.
And that's a sort of exogenous neural augmentation of ourselves.
Of course, there's our friends at Neuralink that are working on the full merge
with even higher bandwidth, but even without that sort of invasive approach to merging with the AI.
I think we're already, most people are merging without realizing it.
Sure.
And so, you know, what does the human of the future look like?
Well, I think it's one that really harnesses all these tools of cognitive leverage, right?
To augment itself, right?
And I think that the humans that maybe dismiss technology or don't embrace it,
those are the people that are going to maybe be in trouble or relative disadvantage.
And so, I think so far the beauty is that, you know, we're both CEOs, right?
We both have like standard issue iPhones or androids, right?
And it's the same as anyone else, right?
Everybody has access to the same technology and it's ubiquitously accessible and cheap.
And that's the beauty of capitalism, right?
I think that hopefully AI and neural augmentations can be cheap enough and ubiquitous enough
so that everybody can own their own AI, the AI that is an extension of themselves
and that they have control over it.
Because I think if we only allow for AI augmentations that are controlled by central parties,
we're kind of losing a sense of self there.
We're kind of delegating to this sort of...
I've always imagined for the longest time an AI software shell.
The closest thing is Jarvis from Iron Man, but an AI that is my...
I used to call my AI Jamie Joint Anthro-McCano interface that was...
My AI was able interface with everything in the world.
I could step into an F-35 fighter, not know how to fly it, but Jamie knows how to fly it.
And, you know, I can say, you know, move that image here or there or...
How, you know, the technology that you're enabling and I want to go there yet,
but because it has the ability to operate potentially at room temperature
and with very low wattage, it also feels like a technology that could be incorporated into me.
A lot more than any of the other AI technology.
Do you imagine a future in which I have become a cyborg with those AI implants?
Yeah, I would say, you know, at least one of my goals is not just, you know,
to augment humans exogenously, but potentially integrate these devices into our bodies.
Obviously, that's very moonshotty speaking, you know, sort of thinking,
but at the same time, within a certain thermal budget, right,
which is a bottleneck today for implants in our brains,
you know, our goal is within a certain thermal budget to be, you know,
the most performant neural information processor out there, right?
And we're going to keep iterating to maintain our lead there.
Yeah, and I love it.
You're, again, we'll come back to this in detail,
but the power and temperature and efficiency vision you have
because it's orders of magnitude different than what exists today enables integration for the humans.
That's a lot of fear. There's a lot of fear out there.
Yeah.
And the fear dominates the conversation.
You know, I blame the crisis news network and then used for basically broadcasting
every negative piece of information on the planet.
Yeah.
Have you been, as you have been leading this conversation on the accelerationist movement
and you've had folks like Mark Andreessen who's sort of come in as well into that conversation.
What's been the feedback from society?
Have you gotten a lot of pushback?
Yeah, I mean, it's very polarizing, right?
Like there's some people that are, you know, positive some abundance mindset.
They're like, yes, we think technology will help us conquer our problems
and help us tackle any issues.
And there's the people that, you know, think technology maybe is net negative
or they've seen how it impacted their lives and maybe they want less technology, right?
They're kind of techno progressive versus techno regressive, right?
It's kind of a new access of polarization of opinions.
And clearly from my experience online, it's been very polarizing.
We've had quite a few fans.
We have quite a few opponents, but, you know, I welcome discussions, right?
The whole point is to have discussions about how fast we want to go, right?
But if it was only one one-sided discussion beforehand about slow things down, centralized, you know, let's regulate, then we were going to head towards that without any sort of opposition.
Whereas now I feel like we kind of brought balance to this force of sort of novelty seeking, you know, favoring entropy versus sort of higher, you know, more order, more constraints.
And there's kind of this, there's kind of this thing that happens in complex systems where the optimalities at criticality, the balance between order and chaos between energy minimization and entropy is where you want your complex system to be.
Because that's where it's most performant.
So I don't think people realize there's no on off switch on this technology.
Yeah.
And I don't think there's a velocity switch either.
I think it is.
I often ask myself the question, if you'd gone back in time and said to Einstein, listen, stop thinking about this.
It's going to lead to the atomic bomb, whether or not he would have been able to stop thinking about it.
And if he did, the next person would have taken over and moved it forward.
So, you know, I tell people there's no slowing it down.
And if you believe that, which I do, then the question is, what do you do?
And I think it's guiding it that is the only real option we have.
Correct.
And I would say that, you know, the market itself, right, is a very powerful aligning force, right?
If you have a product that is not a positive utility to us, we don't buy it.
It runs out of whatever company makes that product, runs out of capital and the product dies off, right?
There's a selective pressure on the space of products.
And right now, because AI models are products, right?
You have model as a service companies like opening an anthropic, eventually XCI.
This competition for users and ultimately of capital to, you know, fuel the GPUs, they keep these systems alive.
This competition induces a certain selective pressure and models that are not aligned that don't do what you ask it,
that are hard to interpret, hard to read, actually don't do well in the market.
And in a sense, it's a much more careful sort of gentle guidance towards systems that are aligned compared to sort of centralized regulation.
Like this is how much compute you're allowed to use for a model, nothing more and so on.
I think that's going to be net negative overall.
So in a sense, people have a vote in the system.
They can vote with their dollars.
They can vote with their usage, their API calls of which systems they like.
And that's going to steer the market sort of evolutionarily in the space of potential neural nets towards more of models of that kind, right?
But Gil, what happens when someone comes to you and say, listen, I get this.
I like it.
I love the abundance future, but let's be serious.
This is super powerful technology, right?
Like Claude III is already at 101 IQ.
It's more intelligent than humans and we're giving infants nuclear weapons to play with.
And these things are going to ultimately destroy society.
And there's a small chance we survive, but this is way too powerful and we need some level of control.
We need some level of centralization just to make sure things don't go off the rails.
How do you respond to that?
I would say that I'm more weary of the dangers of centralization than giving everyone access to neural augmentation.
Like you said, I don't think there's going back, right?
I don't think we can go back to not knowing about this technology.
There's too much upside on the table to creating it.
It is an arms race like never before.
And so for me, it's like, how do we guide this acceleration towards the positive future?
To me, I think if only a few people or parties have control over the only AIs that are legally allowed,
we're going to have a lot of problems because that's going to create a sort of gradient of power.
But we have duopolies now in cell phone networks, in cell phones, in computers and so forth.
How is this different from those duopolies?
I think if we're going to truly augment our own intelligence with AIs,
I think in order to maintain the benefits of having individuality, right?
We celebrate individuality in our society, at least in the West, and it's our greatest strength
because this variance, everybody brings something different to the table
and we're searching over all sorts of spaces of science, art, culture and so on.
And we find new optima, something original that then gets spread throughout the network
and is of massive benefit to everyone.
And if we only have centralized models, right?
A few models that are trained for everyone, they're amortized.
So there's one model for everyone.
We lose the benefits of having sort of individuality.
And so to me, my quest, both on EAC and Extropic,
is for people to be able to own the compute that is an extension of their own cognition
and for them to have the right to run their own AIs
and have the right to fine-tune models in a way that's private.
So 8 billion AIs, basically.
Or more.
Or more.
Yeah, or more.
Maybe you have 20 agents that work for you, right?
Yeah, Peter, 3 of 10 is going to hang out with you.
Yeah, I think that's the future.
I think that people, you know, it's kind of like having, you know, employees,
you know, management is prompt engineering to some extent.
You can prompt different agents to do tasks for you.
Maybe you fire them up and then boot them down when you're done.
And I think that gives us a lot of intellectual and operational leverage.
And I think people tend to think too much about the economy as this zero-sum system
or like if AIs have, take some of the jobs or to be less jobs for us,
but we all know that's not how the world works, right?
Like if we're able to do more at a certain cost,
we're going to try to aim higher.
And, you know, there's plenty of room to grow out there.
I think that's a really important point.
And, you know, when I think about what do I worry about,
and I'm definitely the guy who says, you know, the glass is not half full,
it's overflowing.
But I do think about if AIs are doing all of the work
and if I can write a book at the snap of a finger and start a company at the snap of a finger
and what's challenging and that we humans need challenges.
There's a great paper I read recently.
It's called Universe 25 if people want to Google it.
And so the studies were done in the 60s in which a large open space was created for field mice.
And it had all of the room and the nests and the food and they had no struggles at all.
And the mice, you know, breeding pairs were put into this and they grew and they grew and they grew.
And then after a couple of generations, it basically died off because there was no struggle in there.
And so one of the things that I think about is that humanity is going to have to up level our ambitions and our struggles.
And I'm excited about that, but people need to have, you know, the ability to have a massive transformative purpose, to have a moon shot.
So let's talk about the Kardashev, you know, scale here.
So a Russian cosmologist, astronomer, comes up with this idea.
So explain where it is.
Yeah, it's a sort of milestone system to keep track of the progress of growth of civilization.
There's originally there was three types or three big milestones and then Carl Sagan found a way to interpolate between the milestones.
So we have a continuous scale there.
But the original scale was in type one, the type one Kardashev scale civilization would would produce as much energy as is incident onto earth from the sun.
Right.
So if you take the sun, we occupy a certain amount of solid angle, some certain amount of the sun's rays hits us.
That's a certain amount of power.
And by the way, the numbers that I remember because I speak about this when talking about energy abundance is that today, I think there's 8000 times more energy that hits the surface of the earth that then we consume as a species in a year.
We're still we're still really early.
We're still below type one.
Yeah.
Well below type one.
Type two would be having the equivalent of the energy production.
Yeah.
Dyson sphere that captures everything being emitted by our son and type three would be the entire galaxy.
Right.
And so I think in general, if you set.
This guy was really ambitious back then.
Yeah.
Yeah.
He didn't start with like a type one as a fire.
Yeah.
A river.
So we're still type zero.
Yeah.
We're still at the beginning of this.
Yeah.
But I think this is, you know, in our moonshots conversation in our abundance mindset, when people think about, well, what am I going to do?
You know, it's like, you've got to point your your vision, you know, 90 degrees up and start talking about, you know, how do we achieve transcendence in our solar system and in our galaxy?
Yeah.
And a lot of our goals, people's goals are too anthropocentric or they want to do relative to others.
And now that AI comes in and kind of breaks this sort of zero sum competition between humans, right?
We got to set our sights on a non anthropocentric goal, right?
And we have a goal prescribed by the universe in a sense, which is to grow.
Yes.
Because any life form seeks free energy and looks to grow.
The point is that if we have a eyes that help us and extend our intelligence, we should tackle harder things.
And there's an near infinite scale of harder things to tackle because unlocking that next scale of civilization, there's tons of challenges to achieve that.
And so that's the sort of mindset I bring to the table.
And frankly, you know, my whole career was trying to tackle, you know, how to leverage AI to understand the physical world.
I haven't been trying to, let's say, automate humans.
I've been trying to engineer, matter, understand chemistry at the base level, understand the physics of the world so that we better perceive, predict and control it, which is kind of a, you know, a core based technology for us to unlock all sorts of other technologies.
And just when someone hears this conversation, they say, well, my God, I can't think about that.
I don't know how to, I'm not Elon to build, you know, Starships or Gil to build quantum computers and such.
But the reality is the tools that you're about to inherit are tools that can boost intellect, you know, not just thousands, but billions of fold potentially.
Well, we'll see how it shakes out.
I think that the current approaches where we train on human generated output, right?
The internet is broadly, at least right now, I'm sure in a couple years won't be the case, but generated by humans, right?
And we're kind of distilling a mixture model of whole human intelligences, right?
You could think of the LMS and trying to distill a mixture across the outputs of all our brains, right?
And so, at least to me, it seems like it would saturate to something nearing, you know, typical human intelligence.
Until?
Well, until it's embodied and then can interact with the environment and get its own samples and query the environment in a way that, you know, is in bottlenecked by what was generated previously by humans.
I mean, one of the conversations we had on the abundance stage was the excitement about AI helping us decipher and deeply understand physics and math and biology and chemistry in ways that we can't fathom right now.
Yeah.
I mean, you do believe that, don't you?
Yeah, I do.
I do think it's possible.
I do think it's much harder than distilling human intelligence.
I think understanding biology and chemistry is going to take orders of magnitude more computation.
And so, the computers we're building, yes, they'll be able to run models that are anthropomorphic, right?
Like LMS and so on, train on human data.
But ultimately, it's machines that are going to help us grok the physical world.
And there's this beautiful theory by Stephen Wolfram on complex and self-organizing systems.
And his prediction is that certain systems in nature are irreducible.
You can't get a, you know, a TLDR.
You can't compress, right, the gist of it to something very simple.
You actually don't have a choice but to go through the highly complex computation to predict what's going to emerge as a behavior at a different scale.
And so nature is very hard to predict at all scales.
And I don't actually believe that, you know, there will be one God AI model that will emerge overnight,
immediately understand all of physics and, you know, create nanobots that eat the earth, which some people believe in.
But at least fundamentally, you know, from my own experience, studying complexity and quantum systems and quantum machine learning.
And then, you know, from Wolfram's theory, it seems that there's a fundamental complexity in nature where we're going to have to scale our computation of intelligence proportionally to the complexity of the systems we're trying to understand.
And there won't be like an overnight sort of runaway intelligence explosion like that.
It's going to be consistent, exponential progress.
And to me, there's much higher likelihood that we shoot ourselves in the foot and stop this beautiful process of exponential progress.
Then there is, you know, us, you know, giving the keys to singularities.
Thus, the boomer versus doomer points.
Yeah, that's right.
I mean, because the majority of people feel just the opposite that this is uncontrollable.
This is a reaction that has no bounds and therefore is dangerous.
And I hear you saying this is a precious flame that we have to be careful we don't blow out.
Yes.
It's a different narrative than what you've heard.
You typically hear people have sci-fi based priors, right?
Like, what are their priors on what the future holds?
They've seen a lot of sci-fi movies.
I blame Hollywood.
I really do.
Yeah.
I mean, the only film that I think has done a good job here is her.
You know, where the AI gets bored and leaves.
Yeah, that's actually accurate.
But, you know, in my case, I think once we've created AIs that are, you know, of similar
intellect to us, we're going to learn how to interact with them.
We're going to learn how to employ them in a positive fashion.
There's going to be a big adjustment there.
But once we do so, we're going to have way more challenges for us to scale civilization
to the stars.
And there's plenty of challenges left.
So there will always be more work to do, right?
And we're going to put our most capable systems on the most complex and difficult tasks.
And there's still going to be work left of all kinds.
And so I think if people have a mindset that they want to embrace technological change,
they want to figure out how to best augment themselves, augment their businesses with AI,
like they will have a place in the future.
And if we have those that want to, you know, stay away from it, then, you know, I mean,
they could give back.
We have the Amish.
We have the Amish example.
Yeah.
Yeah.
And the challenge becomes, you know, people who feel this way.
I'm like, okay, just for just a week, go without your phone, your TV, you know, your
car, all the technology.
Don't buy food in the supermarket.
Go find a cow and milk it yourself.
Go plant your.
And the reality is what makes the leveling the playing field for humanity is the poorest
and the wealthiest all have 24 hours in a day, seven days in a week, 365 in a year.
It's how you use your time that differentiates you.
So my ability to have ultimately hundreds of extraordinary agents that can do the things
that I desire and bring back the answers for me is a massive force multiplier for productivity.
Yes.
I think people should think more like that, like a capital allocator, like a manager, as
the way we're going to merge with AIs.
And it's going to allow them to do much more.
I think more people should be entrepreneurial.
More people should think, hey, what opportunities do I see in the world now that we have these
AIs that are on the verge of human like intelligence?
What should I aim to build?
How will I direct capital to unlock more value?
Right.
And if everybody shifts to that sort of mindset, I think the fears about what are we going to do in the future will fade, right?
Everybody want to take a short break from our episode to talk about a company that's very important to me and could actually save your life or the life of someone that you love.
A company is called Fountain Life.
And it's a company I started years ago with Tony Robbins and a group of very talented physicians.
Most of us don't actually know what's going on inside our body.
We're all optimists.
Until that day when you have a pain in your side, you go to the physician in the emergency room and they say, listen, I'm sorry to tell you this, but you have this stage three or four going on.
You know, it didn't start that morning.
It probably was a problem that's been going on for some time, but because we never look, we don't find out.
So what we built at Fountain Life was the world's most advanced diagnostic centers.
We have four across the U.S. today and we're building 20 around the world.
These centers give you a full body MRI, a brain, a brain vasculature, an AI-enabled coronary CT looking for soft plaque, dexa scan, a grail blood cancer test, a full executive blood workup.
It's the most advanced workup you'll ever receive.
150 gigabytes of data that then go to our AIs and our physicians to find any disease at the very beginning when it's solvable.
You're going to find out eventually.
You might as well find out when you can take action.
Fountain Life also has an entire side of therapeutics.
We look around the world for the most advanced therapeutics that can add 10, 20 healthy years to your life and we provide them to you at our centers.
So if this is of interest to you, please go and check it out.
Go to fountainlife.com backslash peter.
When Tony and I wrote our New York Times bestseller life force, we had 30,000 people reached out to us for Fountain Life memberships.
If you go to fountainlife.com backslash peter will put you to the top of the list.
It really is something that is, for me, one of the most important things I offer my entire family, the CEOs of my companies, my friends.
It's a chance to really add decades on to our healthy lifespans.
Go to fountainlife.com backslash peter.
It's one of the most important things I can offer to you as one of my listeners.
All right, let's go back to our episode.
So a lot of folks listening are entrepreneurs and they're looking at moonshots.
They're looking to do something big and bold and significant.
Like I jokingly say, not another photo sharing app, you know.
How do you, what's your advice for entrepreneurs today looking over the decade ahead?
Yeah, I would say, you know, everything that's like white color work or software, you know, doesn't necessarily have everything that has preexisting abundant data sets might not have too much of a moat.
If intelligence becomes more abundant and if the current systems we have don't necessarily generalize too well, but they're really good at interpolating across data points that are pre-existent.
Maybe stay away from things that are typical, right, and go towards the atypical.
Do something that's never done.
Great, unique data sets.
Yes, right.
So something that's like surprising, contrarian, and so on.
You know, yes, that gets people to judge you that like, okay, this sounds like a crazy idea, but actually everything that is typical is going to have plenty of AIs that can do those tasks, right.
And so to me, I think we're seeing a sort of deep tech renaissance.
And even I think this narrative is floating amongst the venture community that actually deep tech, you know, the world of Adams is where the hard problems are and where AI won't be able to follow you yet.
Right.
There's a fundamental reason why that is.
I think the physical world is really hard.
And even even with all the help of white collar AIs that we can muster, there's going to be a bottleneck to creating things in the world of Adams.
So build companies that are doing hard things in the world of Adams and you will do very well in the future.
That is my advice.
I want to dive into your startup.
Again, there's a lot of folks who are super excited and all they think about right now is how can I get access to each 100 networks and how do I start coding for this.
And if if you're able to pull off what you're building right now, you will disrupt those that capability.
I don't want I can't put orders of magnitude on it massively.
Yeah.
But let's go back to your history that led you here.
You were at University of Waterloo.
Yeah.
In studying quantum physics.
Quantum.
Yeah.
Quantum gravity, quantum information during my masters.
And then over time, I realized that actually to better understand the physics of the world, it wasn't going to be a couple mathematicians in a room on a blackboard to solve the theory of everything.
But it's probably going to be some form of computation and AI that would solve it.
And so to me, that journey led me to be a pioneer of a field called quantum deep learning.
Wrote some of the first algorithms in the space.
You got recruited out of school, didn't you?
Yeah.
Yeah.
That's right.
Basically first year of PhD.
I met Hartman Neven, who now leads.
I know Hartman.
Well, yeah.
Google quantum AI lab and essentially, you know, we were on the same wavelength.
Right.
What did he say to you in his German accent?
I won't imitate his accent.
But you know, I think we met at NASA.
I gave I gave a first talk after writing a very large paper on how to do deep learning on quantum computers.
And he was like, come give a talk in Venice Beach, not too far from here and talk to our scientists.
And so we, you know, brought my co-author Michael at the time we did.
And they asked us, hey, you know, try to build a prototype for what a TensorFlow, which is for quantum computing would look like.
TensorFlow is Google's core machine learning framework, right?
Or at least used to be.
And we hacked it together.
They liked it and basically on boarded the whole team.
They gave you a co-author you could not refute.
Yeah, yeah, exactly.
And frankly, you know, Waterloo is great.
It's a great school, but you know, it is in the middle of nowhere in Canada and to me to move to California seemed like the right, you know, opportunity I should take and, you know, just went for it and have a look back really.
And so it's been, it's been, it's been a ride.
Yeah.
And then you actually spent some time working closely with Sergey Brin.
Yeah.
So after we, you know, built TensorFlow quantum that there's a team that was forming around Sergey working on quantum technologies and AI and physics and AI more broadly.
And to me, I was sort of getting a bit impatient with the timelines with the compute, the computing stack.
And I saw that there were opportunities and quantum communications and sensing that were maybe shorter term.
And so I wanted to try my hand at that.
And to me, it was a completion of sort of the vision of understanding the world at a quantum mechanical level.
Because if, even if you have the algorithms running on quantum computers that can understand quantum data and learn AI representations of them, how do you acquire quantum data and how do you transmit it?
And so that's what I worked on.
So I worked on quantum analog digital conversion, the US quantum internet.
And so to me was completing the stack for us to be able to perceive and predict and eventually control our world at a quantum mechanical level, which to me is kind of a very deep node in the tech tree.
Let's say it's a civilizational technology that's really important.
But during that time in quantum computing, I realized that actually there was going to be different nodes of our tech tree that need development imminently that use a different kind of physics.
That's not quantum mechanical physics.
And that would be much more useful for Genovii as I was seeing sort of Genovii workloads eat more and more of the compute internally at Google.
So we've got classical digital computers right now, the classical CPU from Intel and such.
And then NVIDIA, I think very luckily fell upon the opportunity with GPUs.
Most people hopefully know GPUs, graphical processor units were originally created for video games.
For graphics.
And then they just happened to get a market in Bitcoin mining.
And then all of a sudden here comes the whole generative AI world and NVIDIA becomes a $2 trillion company.
That's a lot of good luck.
Yeah, turns out matrix multiplications, which GPUs excel at are very useful for all sorts of different applications, including AI.
But as you mentioned, GPUs weren't designed from the ground up from first principles to be AI processors, right?
It's kind of a co evolution between the hardware and the algorithms, right?
The algorithms that ran on GPUs, like modern deep learning tended to do well because GPUs already existed and then both kind of fed off each other.
So we're trying to create an evolutionary fork in the space of hardware.
It's getting gender evolutionary forks in the space of algorithms and they're going to co evolve.
That's why we're a full stack company and we co design the algorithms.
Let me let me read something here that sort of describes what you're doing and see how this how this hits.
We're building the ultimate substrate for AI compute, looking to hit the limits of physics in terms of energy efficiency and speed of AI,
embedding AI algorithms into the physics of electrons dancing around.
And we're doing this by building a full stack of hardware and software reinventing at first principles how to how to create generative AI.
You call it thermodynamic computing, probabilistic computing.
And this is a third branch of computing, isn't it?
Yeah, it seems like it because today we have the deterministic computers, right?
Your transistors are definitely on or definitely on one or zero.
It's one or the other, right?
And you definitely know which one it is, right?
And then you have a quantum computer which has super positions of ones in zero.
It's zero plus one zero minus one and everything in between everything in between complex numbers.
You can make those interfere with one another, but actually having a computer that you're unsure of the state of the computer.
And it's probabilistic, it's zero or one or something in between, but you're not sure exactly the state of the computer.
It's actually much more energy efficient because knowledge costs energy.
There's this old tale of Maxwell's demon.
I don't know if you're familiar with it.
Bringing back faint memories, go ahead.
Yeah, so Maxwell's demon tells us that actually it's a thought experiment that examines the energetic cost of knowledge, right?
And I guess I could go into it.
But yeah, Maxwell's demon essentially, you can imagine having a box with a partition in the middle, right?
And you have one side of the box has a bunch of red particles and the right side of the box has a bunch of blue particles.
And you have a trap door in the middle with a little demon, right?
And if you keep the trap door open, you wait a long time, the balls cross and on average you get a mixed thing where you have red and blue balls in both partitions.
Now, where the demon comes in would be you can actually reverse this process of going to a higher entropy state, right?
Which would violate the laws of thermodynamics by having the demon look if a ball of a certain color comes in, opens the door,
the ball of the right color comes in, the other side opens the door and can filter and again separate out into red and blue partition,
which seems to violate the second law of thermodynamics that states that there must be a cost to that observation.
It's an energetic cost exactly.
And so what we see is that a lot of the cost of running a computer comes in when you're trying to maintain its determinism, right?
And it turns out that you don't need to always be maintaining determinism when you're running AI algorithms because AI algorithms are natively probabilistic.
And so having AI run on a digital deterministic program that is emulating probabilistic programs,
yeah, super inefficient, so why not run probabilistic programs on a probabilistic computer?
And so just from that, we have just an efficiency and a tightness to the embedding of the algorithms into the physics of the hardware that's really hard to achieve on digital computers.
But not only that, we're actually catering to the imminent what would be otherwise problems of transistor-based computing, right?
You scale down transistors and you try to make them more energy efficient.
Unfortunately, the fact that transistors are made of matter and they're jiggling causes your transistors to misfire and get hot, right?
They get hot and sometimes they say things they don't want to say, no, but they're misfiring and they become effectively stochastic.
And instead of trying to filter that noise and filter that stochasticity and make it deterministic again, right?
Through error correction, similar to how we have to filter out the stochasticity in quantum computing with quantum error correction.
Instead, we embrace the noise and use it as part of the algorithm and it's part of our models of the hardware and it's part of the algorithm.
And so it's a very different way of thinking.
It's very challenging because we have to rebuild the whole stack to go with it.
It's very ambitious, but to us, it's a necessary and clear from first principles, evolutionary step in computing.
And it's one that we think is inevitable.
We're just the ones that are boldly going for it right now.
You described thermodynamic computing as being particularly valuable at describing chemistry and biology because we're talking about thermodynamic systems there.
Yeah, so chemistry has some quantum effects in there mixed in, but biology, proteins, molecular dynamics at the mesoscales, right?
They're bouncing.
Yeah, they're bouncing around.
They're jittering around and that's very tough to simulate because we have to embed that stochastic process into digital computers, right?
And it's a process that these fluctuations happen on very small time scales so you can't just fast forward the movie very efficiently.
And so for us, we're looking to embed the physics of protein folding eventually, not initially, but protein folding, which happens on a certain time scale because you have big proteins and they're jittering about into the jitters of electrons that we control how they dance in electrons
because they're much lighter, they jitter much faster.
So you get a speed up by embedding the dynamics of proteins into the dynamics of electrons.
And that's it.
It's very analogous, the physics of the mesoscales of matter to the native physics of the hardware.
And so we get a speed up there, but we're going to work on quantifying exactly what sort of speed up we expect.
Right now, it's an intuition similar to Feynman's intuition about why would you build a quantum computer where, well, there are quantum mechanical systems you'd want to simulate.
And it turns out that, yes, in fact, you get a significant speed up running quantum simulations on quantum computers versus classical, right?
So you had this insight while you were at Google and this was what liberated you?
Actually, before I started my career in quantum machine learning, I wrote down the equations for our very first chip while I was at Waterloo.
And I thought this idea was crazy. It was too original. You know, I was straight out of my masters in theoretical physics.
I had just learned machine learning.
You wrote it down on one of these notebooks over here.
Yeah, just a notebook. Yeah, exactly.
Crazy ideas.
And I thought the idea was too crazy. You know, I was still, I was wrapping up my masters at the time.
And I wanted to understand and go through the exercise of inventing a bunch of algorithms in physics based AI more generally before I went for it.
Right? So I built up, you know, years of credibility, shipping a lot of papers and products and going to Google and so on to have the experience to do this moonshot.
At the end of the day, you got to find what is your best idea? What is the most impactful idea that you can work on for the rest of your life?
What are you like willing to die for?
Yeah, this is what we call that a massive transformative purpose and your moonshot, right?
Yes.
And you know, I wrote down, again, what I hear as your MTP, which is maximizing the amount of intelligence in the universe.
Yes.
And along those lines, intelligence per watt, like maximizing that. And if you can do that, it's up leveling everything.
Yeah. It's the highest, it's a very, it's a point of very high leverage, right?
And obviously, not everyone has to create technologies that are as impactful as that.
But at the same time, if everybody thinks about which technology they can build, which technologies do they have the unique skill set for that they can that they think would truly impact the world in a massively positive way.
If everybody goes and does their moonshot, they're thinking about, I think the world would be a much better place, right?
And that's kind of the ethos of the acceleration community.
I know it's the ethos of your community, which really, you know, was around, been around for much longer than we have.
And I think a lot of people sometimes just need a push to, it's okay to be ambitious.
It's okay to go for it. It's okay to take risks.
You know, you'll have a supportive community go for it.
It's actually like, if you achieve what you're looking to achieve, we're all going to benefit.
So we're going to support you. And I think having a supportive community is so important.
This very simple concept of maximizing intelligence per watt and in the universe seems like a fundamental.
It seems like what life would always trend towards.
And given the fact that we humans are only some four and a half billion years in a 13.8 billion year galaxy universe as we know it,
I'm wondering where all the intelligence is.
You know, I don't want to get into Fermi's paradox of why aliens aren't here.
But I have to imagine there is a maximization principle for intelligence in the universe.
And I always thought about intelligence being the countervailing force to entropy, like an entropy increases.
The countervailing force for that would be intelligence increasing as well. Does that make sense?
Yeah, actually, there are theories, for example, Carl Friston, someone you should talk to, an absolutely brilliant scientist.
His theory of intelligence is that we seek to minimize surprise and entropy is expected to surprise.
And so intelligence is trying to model the world to have the minimization of surprise.
And it turns out that for biological systems, if you can predict your environment really well, you're in a position to extract more free energy and consume it in a clever fashion.
And that's thermodynamically optimal.
So now, I guess my theory, which, you know, I've only loosely kind of had time to put my thoughts on paper through the manifesto and some tweets.
But something I'd like to formalize in the coming years on the side is, you know, how did intelligence potentially evolve as a byproduct of this concept of thermodynamic dissipative adaptation,
which is a concept from a professor named Jeremy England from MIT that posits that systems that are complex and subject to the laws of thermodynamics self-organize in order to dissipate more heat over a long time scale, not instantly, not overnight.
To acquire more energy and then dissipate?
Yes, yes. Essentially, more precisely, the theory says that trajectories of states over time, the ratio of likelihoods of two different histories, two different trajectories, scales exponentially with how much free energy was dissipated.
So path toward the future where we've dissipated more heat are exponentially more likely.
And so there's actually this probabilistic bias of the universe towards growth.
And that's what that principle, at least according to some theories, is what led to life self-organizing and creating the complex systems that we are today.
And to me, that is the process that led to all the creation of all the wonderful things we see today. And it's almost like sacred in my book, we should keep that process going.
We don't know what upside we're leaving on the table if we were to stop it or decelerate and obliterate ourselves.
Is there any way to know, given this basic theorem, whether a tendency towards a recurrent simulation would be the end result?
Recurrent simulation.
Well, meaning we are an nth generation simulation that keeps on re-instantiating.
I've studied simulation quite a bit. My job was to figure out how to simulate. I've simulated early universes for fun on quantum computers as a hobby and sold it as art in the past.
But there's a certain density to information, if you will.
And my work on quantum internet was actually studying how densely you could pack quantum information in various substrates.
And in a sense, this assumption that you can have a simulation within a simulation, within a simulation, really doesn't hold.
Because at the end, there's a base reality. And in that embedding universe, you have a maximal information density for your computer, if the laws of physics in that universe are anywhere close to ours.
And so the assumption that we live in a simulation from this assumption that you can embed a simulation within a simulation, yeah.
Only goes so far.
Only goes so far. It doesn't really hold, yeah.
So to me, I don't think we live in a simulation and I'm happy to chat with anybody who thinks we do and show them the mathematics of how hard it is.
One thing we can test is whether we live in a quantum simulation or not, right?
Because I think Google's quantum computers, amongst others, are reaching the number of qubits where there wouldn't be enough atoms in the observable universe to emulate the quantum computer with a classical computer.
And so we can at least rule that out.
And if one of the quantum computers show that, I'll be very satisfied with that.
I think that's a very interesting thing to answer.
So you have this idea of a thermodynamic computer and when did you pick it up again?
I picked it up.
I left my career in quantum computing, quantum machine learning, took a couple of months to gather my thoughts and I went for it basically summer 2022 and just got going and got the company going and now it's been going for almost two years.
And I've seen some great video of your fab and your cryo hangout spots.
So your goal here is not something that's operating at cryogenic temperatures.
It's something that is operating at room temperature and being built on the silicon fab.
Yeah.
So when you prototype things, you start with the biggest, most macroscopic prototype you can because it's simpler.
It's easier to get going and you can probe it and understand it better.
In our case, we couldn't do a breadboard prototype like you would do with other electrical circuits because we want to operate it in the regime of ultra low power and the right ratio of power of noise where we have the right properties of the electron physics.
So for us, the first prototype is the most macroscopic we'll make of a thermodynamic computer, but we had to super cool it because that's how the physics works out.
Essentially, we did a super connecting prototype.
It's our first prototype, but our next chips are going to be in silicon and we're excited.
You talk about embedding physics and embedding the algorithms.
Yeah.
Explain what that means.
I mean, my whole career was figuring that out how to embed quantum physics into a quantum mechanical computer, how to embed AI algorithms into quantum mechanical physics.
Right.
And so for us, it's very similar sort of mindset.
There's ways to compile things into primitives that then get compiled to primitives of the hardware physics.
Right.
In quantum computing, they're called quantum gates.
Right.
And we have something similar in terms of frameworks that we have internally and we're looking forward to putting out a lot of the details on how to compile for any sort of algorithm to a thermodynamic computer.
And frankly, part of my goal is to partially open source the concept of a thermodynamic computer so a broader community can join us on this quest.
You know, we're one effort for this, but it's too important of a technology to keep it on a shelf for a few more years.
We don't have time.
I mean, the potential for this, and if you can describe the potential for this in the generative AI world, because today there is, if we're projecting the growth of generative AI, are we running out of chips or energy first?
Bit of both, right?
I think energy is going to be a big bottleneck because chips are reacting to the market right now and there might be an overproduction of chips.
I doubt it, but it's going to be up there.
What's the state of the best chip today?
Is it H200?
What is it?
What's out there?
These are manufactured in Taiwan by TSMC, right, with machines from ASML, which is a supplier of lithography machines, and those are exquisite machines.
But, you know, our goal is to have a different way to embed the problem into the devices and for us to not depend on the same processes that everyone else depends on.
Which we feel is an important hedge because otherwise Taiwan is a very sensitive area and the world supply chain depends on it.
And so if we could, you know, forgo our reliance on Taiwan to make the most cutting-edge chips for AI, that would, I think, put everyone at ease and be a net benefit.
Did you see the movie Oppenheimer?
If you did, did you know that besides building the atomic bomb at Los Alamos National Labs, that they spent billions on biodefense weapons, the ability to accurately detect viruses and microbes by reading their RNA?
Well, a company called Viome exclusively licensed the technology from Los Alamos Labs to build a platform that can measure your microbiome and the RNA in your blood.
Now, Viome has a product that I've personally used for years called Full Body Intelligence, which collects a few drops of your blood, spit and stool, and can tell you so much about your health.
They've tested over 700,000 individuals and used their AI models to deliver members' critical health guidance, like what foods you should eat, what foods you shouldn't eat, as well as your supplements and probiotics, your biological age, and other deep health insights.
And the results of the recommendations are nothing short of stellar.
As reported in the American Journal of Lifestyle Medicine, after just six months of following Viome's recommendations, members reported the following, a 36% reduction in depression, a 40% reduction in anxiety, a 30% reduction in diabetes, and a 48% reduction in IBS.
Listen, I've been using Viome for three years. I know that my oral and gut health is one of my highest priorities. Best of all, Viome is affordable, which is part of my mission to democratize health.
If you want to join me on this journey, go to Viome.com slash Peter. I've asked Navin Jane, a friend of mine who's the founder and CEO of Viome, to give my listeners a special discount. You'll find it at Viome.com slash Peter.
So the extraopic chips in success, and I'm curious what your timeframe is, would be how people would stand up their general AI large language models on their every place.
So at first, it's going to be application-specific devices. It's going to be small-ish devices with not that many neurons, right? But they're going to be very fast and very energy efficient.
There's all sorts of applications for that at the edge. But over time, yes, as the chips grow and more and more of the program becomes part of the physics of the chip or become thermodynamic programs, then eventually we could run the whole program on the chip.
Because for us, most of the energy and time is actually consumed by the computers that have to interface with the chip itself, which is really weird to think about.
But yes, over time, we want to tackle the broader general AI market. It may seem far off at the moment because we're just building a couple of building blocks.
But given that we're using a lot of the existing supply chains for semiconductors and how semiconductors have a very mature set of tools, you know, semiconductors are the things we can manufacture at scale the most reliably, right?
And so if we use a lot of the know-how there, we can actually scale this technology much faster than previous attempts at novel computing technology.
Can you give folks listening an understanding of the potential efficiencies in terms of power, speed, cost, these things? How do you think about this? Because it's pretty staggering.
It's, you know, at a fundamental level, like the primitive itself of, you know, simulating the physics of this device, if you were to just sample it, right?
If you somehow embed your algorithm directly in the physics of the device, for example, Monte Carlo algorithm fits very nicely into the physics of the device.
A Monte Carlo algorithm, usually you could program it on a computer, a CPU or GPU, you get maybe a thousand samples per second.
You know, this chip does samples on the, you know, one to ten picosecond timescale, depending on the landscape, but picoseconds is below, it's a thousand times below a nanosecond.
And so it's really fast, right? And the speed up you can expect depends on the algorithm and how well it fits on the device. So it's hard to give, like, one number.
So help me understand what this looks like in the world ahead. These extropic chips are in my body, in my glasses, in my phone, in my car.
Are they the base for AI everywhere at some point?
I mean, that's part of the goal, right? Yeah, that is ultimate success. And it's certainly possible. We're starting with something humble, you know, just put on some edge devices.
But over time, yeah, it would be the most performant chip, not only for the cloud, but the edge as well.
And, you know, personally, I would love to wear some chips or gadgets powered by our chips someday at scale, of course.
And, you know, I think intelligence will be embedded in far more systems than we're used to if we achieve our mission.
You know, that's on a, you know, 15 to 20 year timescale, right? Like, we have so much to do until then.
But I think it's certainly possible. And to me, it's going to be much faster in scaling than quantum computing by quite a bit.
So let's go there one second. In terms of, you know, Ray Kurzweil and I had a conversation, he says, listen, we're going to see as much change in the next decade as we've seen in the last century, right?
In the very steep segment of the curve. And do you imagine, I mean, I can imagine a world where everything is intelligent, where intelligence is embedded in every aspect of our lives and AI is everywhere.
Yeah, I think that makes a lot of sense.
Do you think people are going to be able to adapt to this speed of change?
I think so. I think if people maintain an open mind and, you know, the speed at which we can adapt, you know, if you look at the fundamental theory of natural selection from Fisher,
the speed at which you can adapt a system is sort of bounded by or proportional to its variance.
So having variance and how we do things helps us adapt quickly because if you try different things, you get a better sense of what's better.
You're not locked into a local minimum.
Exactly, right? And you get out of the local minimum. And that's basically the message we're trying to tell people is like, I know right now, if you're at the precipice of a lot of change, you know, our first reaction is to stop and try to freeze things.
But that's exactly how you become fragile. To be antifragile, you need to be constantly adapting in high variance and malleable.
And, you know, if you, this is, you know, this is the theory of complex systems.
If you have systems that are malleable and flexible, they can adapt. If they're too stiff, they break and they have catastrophic failure, which is what we're trying to avoid.
And so part of the message of acceleration is for us to be robust and adaptive to whatever's to come.
We cannot predict the future. You provably cannot predict the future.
If you could, there would be a couple of people on Wall Street making all the money right now, right?
And clearly they can't, right? You can't reduce the markets to a simple model.
And so you can't predict the future. All you can do is prepare for it and maintain dynamism and adaptability for whatever's to come.
And that's what we're arguing for.
What's next? You're, you've got a fab, you're going to be demonstrating silicon, your chips on silicon.
Is this going to be a partnership with an Intel or NVIDIA, or are you going to go it yourself? What do you think?
At least right now we're looking at partnering with the traditional fabs directly ourselves, right?
And so I think a lot of the ways that the traditional players and digital computing, you know, the ways they've been creating computers and programming them won't necessarily carry over to our systems.
You've had to build a full hardware, software stack for this.
Yeah. And I mean, we're still very much actively building it.
You know, we're looking to get our first prototypes, you know, in the coming year or so on the silicon side.
Are you hiring moonshot engineers?
Definitely. I mean, I think anybody who is kind of tired by the old way of doing things, maybe an electrical engineer that's been in their career for a while wants to go for something cutting edge and very ambitious should consider joining us.
I think there's a lot of people in machine learning as well. They're getting jaded by sort of the monoculture around LLMs and transformers today and just training big models on data.
There's not a lot of artistry to it. What we offer is basically a big mathematical challenge to figure out the new software stack and algorithms and architectures for this new substrate.
We've been able to attract some really top talent there. So anybody who needs a really strong intellectual challenge and has a lot of AI experience should consider joining us and help us pioneer this new paradigm.
Extropic.ai
Yep.
Well, buddy, thank you for your passion. You love what you do.
I do.
I think the importance of having an accelerationist mindset, a mindset for exploring and creating intelligence and being able to solve problems.
I think mindset is the single most important asset we humans have and thank you for your mindset.
Thank you so much. Thanks for having me and thanks for pioneering the way as a techno optimist.
Great to be here.
