Are you still a reader in mathematical neuroscience?
Is that still accurate?
I've changed all our titles a little bit.
OK, so a man of many titles.
Whatever I was at Bristol, I know
you were the head of the Computational Neuroscience
Unit, and he was also an examiner for my PhD five-hunt.
So super, super happy to have him here today.
Thank you, Connor.
Brilliant.
Sorry, one second.
Cool.
Well, I'm super excited to be here.
This has always been kind of a legendary location for me.
I've always wanted to visit.
And I just really blowed him away.
It's an amazing looking place.
It's my first time in New Mexico.
And oh, my god, the countryside here is just incredible.
I assume that it's traditional to start talks here
with some reminiscence about the time
that you met Murray Gaumann.
So I met Murray Gaumann 20 years ago.
I was still a particle physicist then.
He was coming through Trinity College Dublin
where I was working at the time.
And he asked me where I was from.
And I said I'm from Galway, which is true.
And he said, oh, yes, Galway, home of this.
At Galway, off whose coast the Spanish Armada
founded in a storm, saving the British Navy
the trouble of sinking it.
Home, too, he said, to the myth that the lusty sailors thus
wrecked, swam ashore, and bred with the local women
to create the black-haired Irish.
Something he said that is not true,
the black-haired Irish are presumably
the remnants of the indigenous population,
the population there before and accounts
of population whose traditions and cultures we know
from archaeology, but whose language is wholly lost
and unknown.
And I was just incredibly impressed by the whole thing.
I mean, he knew where Galway was.
He knew that we had this link with Spain.
He knew about the Spanish Armada sinking.
He knew that we all believed, as it turns out incorrectly,
that the Spanish sailors had created
these sort of black-haired folk in Galway.
And he told me this interesting thing
about how these black-haired folk are probably
the remnants of the indigenous population.
And I was always intrigued by this idea
that there was a language that they spoke,
which is now completely lost.
The idea of these completely lost languages is lovely.
It also struck me with something in the show-off.
That's true too, but it was very impressive.
And so I'm very, very, very glad to be
in the Murray Gilman building.
I was, I did start life as part of his list
and then became a neuroscientist
and only started working on language recently.
So I don't know that much about it,
but the reason I started working on language was
I read this kind of bizarre quote from Nob Chomsky,
which says, in their essential properties
and even down to find details,
languages are cast in the same mold.
At the Martian scientists, my reason we conclude
that there's a single human language
with differences only at the margins.
And that just seemed so wrong to me.
And I thought that maybe that is an accident
of not thinking enough about how different languages are.
And it seemed to me,
the languages are incredibly different from each other.
And I'm looking with where I'm from
to know a little bit of Irish.
And Irish is, although an inter-European language,
it is more different to English
than maybe French and so on is.
I mean, for starters, it has a different word order.
One of the more striking features is the,
it doesn't have a verb possession.
So here, this is the Irish for,
I have a newspaper, Thon, Nugton, Ogham.
And what's happening there is that there's no,
the Thon is just the verb is.
So the literal translation of that sentence
is the newspaper is at me.
The Ogham is a preposition combined with the pronoun,
which is a feature of Irish.
And preposition prepositions do a lot of work in Irish
that it's done by other parts of speech in other languages.
So instead of saying that you have a newspaper,
you say the newspaper is at you.
And similarly, Thon, Nugton, Ogham,
the new newspaper is from me.
It's how you'd say that you wanted the newspaper.
So it's strongly that languages are very different
from each other.
And that it's wrong to presuppose that languages
all spring from the brain
in the way that Chomsky is suggesting.
Because his idea is that the languages bear
the imprint of the human mechanism.
Whereas for me, as a neuroscientist at the time,
somebody knew about how vision worked and so on,
it seemed that languages were much more likely
to just be the unfolding of some search
for statistical structure.
And maybe something to do with the properties
of the world around us,
the fact that there are actions
and there are enhanced verbs
and there are objects and hence nouns.
But of course, I'm no longer sure
that I was right in thinking that.
And I've begun to appreciate something
of the wisdom of what Chomsky said.
And of course, another example from Irish Thon,
Nugton, Foum, the newspaper is under me.
That's how you'd say the newspaper is about me.
But there you can see that even in the English,
the same work is being done
by the prepositional construction
as is being done in the Irish.
In other words, although, you know,
the Irish uses a different preposition
and prepositions tend to vary as you probably know
a lot from language to language.
The idea of using a preposition
where you might otherwise have a different verb
is not so unique to Irish.
And so maybe, you know, languages are all somewhat,
you know, similar to each other.
And it struck me, or strikes me,
as I'm sure it strikes you,
that this is a really important question.
I love this sign because, you know,
it says the vehicles will be prosecuted without warning.
But this is a warning sign,
so of course it makes it impossible for them to do that.
And I have here started to remind me
to comment on the idea that, you know,
language is complicated because some aspects of language
are to do with what's in the world.
You know, the structure of language is structured
by its use case, by communication.
And some parts of language, presumably,
are to do with the human ability to communicate
or our ability to perceive
or the calculations we do in producing,
interpreting meaning and in producing meaning.
And some parts might be more idiosyncratic
to do with some linguistic mechanism.
And deciding between these,
deciding, you know, recognizing the fact
that we can say something like this,
which logically, it makes no sense at all,
but which, you know, in a Wisconsinian fashion,
or communicate something,
is a property, you know,
is something that's deeply rooted in who we are
and our language is a part of how we conceive of ourselves
as conscious individuals.
And separating what's special about language,
what's special about us,
what's special about with, you know,
what language necessarily has as a communication medium,
that seems an interesting and an important challenge.
So, of course, as a neuroscientist,
when I decided I was interested in this,
the first inclination was to do EEG experiments.
And I wanted to start talking a little bit about that
before talking a little bit more
about models of language evolution.
I started off actually trying to do EEG experiments
on Irish speakers.
I don't know how much you know about Ireland
than Irish speakers.
So it turns out that trying to do EEG experiments
on Irish speakers is very difficult
because lots of people who claim they can speak Irish
actually really can't.
As I did a whole series of experiments
on people who claim they can speak Irish
and discovered, in fact, the EEG just told me
that they were lying.
So I went back to working on English speakers.
And I was interested in testing this idea
that the brain does privilege grammatical structure
over mere statistical structure.
Now, if any of you have done EEG experiments,
you'll know just how damn difficult they are.
I mean, the idea that we detect electrical fields
outside the brain is actually slightly surprising
because you'd expect all the electrical fields
to cancel out.
And the only reason we can detect anything at all
is that there's a slight preponderance
of synapses pointing one way or another.
And then, of course, you bathe the whole thing
in salty fluid, which makes it hard to detect anything.
For cognitive experiments,
the difficulty is still greater still.
And I'll refer to this a few times.
This EEG data is obviously showing somebody
having an epileptic fit and they were induced
by toothbrushes that started brushing their teeth
and here they have the fit.
And you can see that it's a very pronounced activity.
But for cognitive tasks, of course,
not only is the activity not so pronounced,
I mean, epilepsy is distinguished
by the synchrony of neural activity.
So that's exactly the thing that's recently easy to detect.
Cognitive things aren't so distinguished.
And secondly, of course,
that when you're doing an EEG experiment,
when you're a participant,
you tend to sort of think other things.
You know, you're there, the stimulus is being played to you.
You're supposed to be thinking about the stimulus,
but in fact, you're thinking, you know,
oh my God, I wish I wasn't doing this experiment anymore.
Oh my God, this is really boring.
Oh my God, all people are immortal.
I'm gonna die someday.
I wonder what I'll have for dinner.
I mean, you know, we just don't...
It's very hard to detect cognitive stuff with EEG.
So the thing that we did, again,
following a paradigm that was introduced
by David Peeble and Naidin and his co-workers
was a frequency-tagged experiment.
So in a frequency-tagged experiment,
to try and separate a signal from noise,
you concentrate your stimulus at a particular frequency.
And so that noise tends to stuff that you're not interested in,
people thinking about their mortal end
or the end of the experiment,
that happens at all sorts of frequencies.
But if your stimulus is at a particular frequency,
then you can use prior transform or whatever
to concentrate on the thing that you're interested in.
So in this experiment,
we play people adjective noun sentences.
We've choose the adjectives and nouns,
so they're single syllable.
We record them and then coerce them a little bit
that they're all exactly the same length.
We play the syllables at 3.125 hertz.
That just turns out to be a particularly good frequency for...
It's a comfortable frequency for listening to syllables.
We have long, long streams of these things.
I mean, we have old rat, sad man, ill wife.
It goes on and on forever.
And we choose the adjective nouns quite carefully
so that the bigrams between old and rat and rat and sad
are roughly the same.
You can't get them exactly the same.
But you try and keep the statistical structure the same.
And then what you see here
is that obviously there's going to be a response
in the EG to the stimulus at 3.125 hertz.
But there's something else happening,
which is the noun phrase.
So if there's a response at 1.565 hertz,
that's a response to something
that's not directly in the stimulus,
but is related to the meaning of the words.
And one interpretation is that that's because the brain
privileges noun phrases over not noun phrases.
And the other example is an adjective verb stream.
In the adjective verb stream, we
make sure we have the same sort of biogram structures
as we had for the adjective noun.
Ill and sad are as likely to come beside each other
as old and man or whatever it was I had before.
But now there is no grammatical structure.
So if we see a response at 1.565 hertz
for the first stimulus and not for the second,
that's indicative of the brain responding, hopefully.
It's indicative to the brain, privileging
grammatical structure, which was, I guess,
one thing to be interested in.
It turns out these data are quite hard to analyze.
You think all you have to do then
is take the Fourier transform and look
at the size of the peak at those particular frequencies.
But EG is extremely noisy.
And so if you do that, you don't see anything.
What you have to do is look for the phase locked component
of the response.
So you play lots of these streams.
So you make each stream five seconds long.
You play repeatedly the stream.
And then you look for that portion of the response
once you've taken the Fourier transform,
that portion of the response which has a similar phase.
And the complication, of course, is
that the overall phase is not so important.
It depends on how big your head is and where the electrode is
and all sorts of other things.
And so the actual phase of people's responses
at whatever frequency, at one point, whatever it is,
isn't important.
And you can see that here.
So this is just each of these dots.
Each of these lines corresponds to our participant.
We had 16 participants in this experiment.
And then for each participant, we've
got all the different electrodes.
And this is the average phase of the response averaged
across, as it was, 10 trials for each participant,
for each stimulus.
So this is the adjective noun, stimulus.
And the dot is for the 32 electrodes.
Just for convenience, for ease of comparison,
three of the electrodes have been picked out
and are colored the same across the participants.
And basically, all you can see is
that the actual overall phase is quite different.
And so what's interesting is each of these dots
hides the fact that there's 20 trials.
Each trial has its own phase.
And the signal is in the degree of alignment
of that phase.
And so to analyze these data, well, the easiest way to do it,
it turns out, is to make some complicated Bayesian models.
So we imagine the phase is being drawn from some distribution.
In this case, it's circular Cauchy distribution.
It turns out to be the nicest.
The circular Cauchy distribution is quite cool.
It's just a wrapped Cauchy distribution.
And when you do the wrapping, you can start some of the series
and come up with an analytic formula for it.
Yeah?
You say the data is kind of noisy, right?
Immensely, yes.
Yeah, so the Fourier transform is also pretty noisy.
Yes, so you have to go through several steps.
So obviously, for start, using the frequency type experiment
makes it less noisy, because the other stuff is having
different frequencies.
But even then, you have to do this sort of phase lock
analysis, which I'm briefly reviewing.
I don't want to spend too long on it
if you're interested in the analysis of EG data.
We've been thinking about it a lot,
and I can talk to you about it afterwards.
But basically, in summary, we make a big Bayesian model
of the results.
What we're looking for, we imagine the phases
have been drawn from a wrapped distribution.
We have some prior for the variance of that distribution,
some prior for the mean.
That doesn't matter.
And so the signal will be in the posterior distribution
of this phase of this variance for the phase.
And so this basically is the result.
Here, we're looking at the, basically,
it's the inverse of this variance,
what they call the mean circular resultant,
against frequency.
And so, sorry, I'm standing in front of the camera.
And so what we're seeing here is the different frequencies.
This is the frequency of the syllables,
and this is the frequency of the phase.
For the adjective verb condition,
you see that there's a big response at the syllable rate,
as there is for all of these conditions.
These are other conditions.
This is mixed lexical, mixed phrase, random.
We did six different conditions,
but we'll just concentrate on these two.
For both the adjective noun and the adjective verb,
there's a response at the syllable rate,
showing up as a reduction in the variance of the phases.
But for only the adjective noun,
are you seeing a response at the noun, at the phrase rate?
On the right, this is some basic equivalent
of the usual bar and star type graph.
All it's really indicating is that the adjective noun
condition shows substantially, or you might say significantly
more response, which is, again, a significantly
more mean resultant, just like the inverse of variance,
than these other conditions, which
is basically showing that the brain has a response
to the grammar, that we can't just think of the brain
as performing a statistical inference on the sentences,
trying to extract meaning, and so on.
It does something every time it hears a noun phrase,
and it doesn't do anything every time it hears an adjective
verb word pairing, because that isn't a grammatical object,
or at least that's the interpretation.
So having done this, I was kind of amazed.
It shows that there is sort of stuff
happening in the brain that is more formal or more akin
to a grammatical manipulation than you might have expected,
and shows sort of the presence in this discussion
as to what part of language is about the world,
what part of language is about communication,
what part of language is about machinery the brain has
to deal with language.
There's more in that sort of brain part than you might think.
And it's certainly, will it be of interest
to start to consider grammar and the brain's view of grammar?
Now, of course, these stimuli that we were dealing with
are quite new that we were using, as I said,
following this idea of people and a thing,
this frequency-tagged paradigm, where
you are playing the stimulus at a set frequency in order
to be able to extract the EEG signal of interest.
But it's very hard to come up with,
there's lots of things that you can't do with that.
We were able to examine the presence of noun phrases,
et cetera.
But what you'd really like is to use free text like this,
with complicated sentences, different types of grammar,
and so on.
This would be better as well, because one problem
with the frequency-tagged experiments
is that they are quite boring and annoying
to be a participant in those experiments.
And it doesn't encourage this kind of thinking away
from what you're supposed to be thinking.
The problem here is the difficulty
in analyzing the data and trying to show a relationship
between the EEG response and what's going on.
So what we'd like to do, I think,
is to understand what grammar looks like to the brain.
We know what grammar-ticians think grammar looks like,
but we don't know.
I often think about the phonology skills
that people were interested in in the 19th century.
The pseudoscience phonology divided the brain up
into regions of the brain that did different things,
which is actually true.
There are regions of the brain that do different things,
but they got it completely wrong.
They thought that the cerebellum was the organ
of amateurshipness, which is bizarre.
In fact, it had some role to do with predicting
the consequence of motor commands or something.
So the ideas we have about grammar might be quite different
from what grammar actually looks like.
And to probe that, one thing certainly to do
would be to do EEG experiments with free text.
Conor, just to kind of get an idea of the experiment itself,
so you'd have, I know you said this is going to be
really complicated, but in principle,
you'd have your participants in a room reading this out loud
and you'd just be looking at the brain signals.
Is that the...
You would be reading it to them and you'd be looking at the brain signals.
So here's the result.
I mean, there are people, it's not just us that's trying to do this.
There are lots of labs doing experiments along these lines.
Stefan Frank in Nimegun, for example.
You have measures of kind of comprehension,
like some behavioral output.
What is the point of the brain responding to these things?
Are you measuring that as well?
Like in the previous experiment,
you showed that there was a response better, but like why?
Like what is that doing for?
What we do do is we make sure people are paying attention.
Okay.
So we have a detention trap.
We introduce particular words that they're supposed to press a button
to show that they're still paying attention.
One advantage of the Bayesian analysis is you can check the participants are.
You know, there's terms in the, you know, you have a big Bayesian model.
There's a term to do with the participants, you know, attentiveness.
You can see that some of the participants are clearly not paying attention.
You can look at them through the window and see they're not paying attention as well.
You know, I guess I'm asking like a deeper question about.
Yeah, no, I, yeah.
You're, you're, you're asking what, what is language for or what's the brain for?
Or just like some of these responses.
I'm always skeptical, particularly.
I mean, I'd know the fMRI literature much better than the EEG literature of
where you just record a response and you say, okay, this brain,
this part of the brain, there's a response to something.
But without some sort of behavioral output that you're measuring connected to that response,
I'm always skeptical of how much, how much does that actually tell us about.
You know, what's actually happening and why, why we should care that there's a response there.
I mean, we should care there's a response there because it shows that we are
responding to the noun phrases and that's part of a story where, you know,
we want to understand how the brain understands language.
How do we answer that?
Well, I'm not sure.
And, and, and you, you know, people try behavioral experiments.
They try manipulations to see how it changes people's understanding and so on.
There's, you know, there's a long history of this.
But it hasn't yet produced an account of language.
And I'm not to answer your question going to produce one either.
But that's absolutely what we need to do.
I mean, so I guess my idea at the moment is that we start that we use the
response as some sort of proxy for, for what's happening.
And we try and see, but just let me say what we've done here, for example.
So again, we're looking at the response to free text.
We're doing some big regression and we're trying to see how people are responding
to different types of words.
And what we can see, what this is showing is that for part of the EG response,
there is a difference in how people are responding to words,
according to the categorization of the words, into function and content.
And so we can see that people, people's brains respond differently
to, to, to some particular categorization of word.
And so what you might be optimistic about is that if you've got better at this,
you could try different categorizations and match them to different ideas
about how the brain might approach parsing language.
But I agree.
You can hear that then to maybe the, the grammars of the linguistics.
Yeah, and then separately, of course, Mel asked me not to mention
transformers, but then separately, you, you look at, you can probe how large
language models deal with language.
You can probe the grammaticians approach the language.
You can probe the whole tradition of linguistic tradition of, of, of our
accounts of how languages dealt with, and then this gives a sort of neural
account, the neural view of what grammar is like.
But whether that's going to work or exactly the details of that, I don't know.
And, and so certainly what I would advocate is that we,
we collect a big data set, you know, with lots of dots of different languages.
The, the, the little prints, as maybe you know, is the, the non-religious text that
has been translated into the most languages.
It exists in 300 languages.
It exists as an audio book in 50 or 60 languages.
And so this is, it's been suggested by these folk here, Jinseng Lee, Brennan,
Haile and some of their co-workers, that we collect a large corpus of different
varying qualities, some, you know, some MEG, which is, you know, very high
quality, some consumer EG, but with many more participants across lots of languages.
And we start trying to, to understand from the point of view of the brain what,
what, what grammar looks like.
Yes, so far, this hasn't been done.
And I guess people are trying to raise money to do it and have, have failed.
So that's, that's, you know, that's just by way of sort of motivation.
That's, that's where I came into thinking about language and, you know,
my interest in language is trying to understand, you know, how is language,
well, what's special about language?
What makes language, language?
And of course, when you start thinking about this, you start asking these
questions, how do we do these experiments?
And it strikes you that there's, there's a whole sort of separate story to
language, which is to do with evolution.
And maybe the hope that if we think a little bit about evolution, about how
languages arise, sort of from a, you know, evolution, the species point of
view, and then separately how languages change, it would be, it might tell us
something about the, the, the innate structure of language.
And maybe we can then think about how language, why languages might have to
be the way they are compared to other, other ways they could be.
And I think this is a, you know, a very interesting question.
One of the sort of striking things is that, well, you know, we know from
Creole languages and sign languages and so on that languages do arise with a
large amount of their structure already present.
But it's still an open question as to whether there are parts of language
that develop through time, you know, as languages evolve, do they, do they
change in a consistent way, or are they, are they the same from the very start?
So near where I work, there's a, there's a museum, the Bristol Museum and Art
Gallery, I left that bit out, and they have some of these, these freezes from,
from Nimrods.
The palace at Nimrod was broken up by people who went there and they, they
took the panels and sent them all around the world in, I guess, an active
gross theft, although what was left in Nimrod had since been destroyed, so in
a way it was quite lucky.
And these, these, these panels do have this kind of cuneiform script written
across them.
It's a standard inscription and it's, it's basically showing off in this, in
this description.
So this, this standard inscription here in cuneiform explains what a great
person he is.
And some of it's quite sort of bloody as this bit is.
There are men, young and old, I took prisoners of some, I cut off their
feet and hands of others.
I cut off the ears, noses and lips of the young men's ears.
I made a heap of the old men's beads.
I made them heads.
I made them in a rash, et cetera, et cetera, et cetera.
Some of it's much nicer.
It's about making pleasure palaces and, and, and beautiful things, et cetera.
But I couldn't find any of that in an easily cut and pastible form.
So I had to get this rather bloody bit instead.
It says something about our, our civilization.
But the point anyway is that what is striking in the, in the text is the
lack of sort of the normal clause structure.
There's very few instances or no instances of the sort of clauses that
you might expect where there's who and which is, and so on, linking together
the sentences.
Instead, it's this rolling list, this very sort of list-like structure.
And so you wonder, is that because the language has not at this point evolved,
all the structures of modern language, the sort of merge and clause structures
that we have now, or is it just that, that, that's how they, they like to
write in their, in their ceremonial functions.
So, you know, it does strike you that there's, there's a lot to be gained from
trying to understand something about, about the evolution of language.
And so that's what I wanted to talk a little bit about now.
And so the first thing I wanted to talk about is really is to urge a, you know,
a return to considering the iterative language model that Simon Kirby and
his co-workers that came up with about 20 years ago.
So I don't know if you, you know, the iterative language model.
It's a language, it's a model for the evolution of languages.
The story is that Kirby and his co-workers discovered it.
They, they, they simulated a little bit, but they, they came quickly hard up
against the computational limitations at the time.
It is quite computationally expensive.
And so they, they, they worked in it, and then they kind of abandoned it, and
went on to try and do the same experiment that they'd done in simulation in real
people. And so Simon Kirby has very successfully spent the last 20 years
using toy languages and toy language learning as a pro into, into how people
learn languages, but hasn't considered much beyond the original work,
the iterative language model itself.
And now that we've got faster computers and so on, it might, I think, be very
interesting to go back and think about this much more.
So in the iterative language model, basically you have a teacher and the
teacher teaches a pupil, and then the pupil becomes the teacher and teaches
another, another pupil and so on.
So it's a chain of learnings, teachings and learnings.
And the idea is that the language progresses or changes through this
teaching and learning.
And the hope is that we might learn something about how the structure of
language arises by seeing if it arises through this simulation of the teaching
and learning process.
And the crucial point, as we'll see, is that there is a bottleneck.
So the agent has a language, the teacher.
They teach only a number of exemplars to the learner, to the pupil.
And then the pupil, in turn, the pupil becomes the teacher.
The pupil is teaching the next learner and they have to extrapolate from the,
well, they've extrapolated from the few examples, exemplars they've been taught,
the whole language.
And then they choose other exemplars from that language to teach the next
pupil.
And it's this process of bottleneck and extrapolation from the bottleneck that
Simon Kirby hoped and, in fact, found, did produce some of the properties that
we believe languages should have.
And so, again, this just summarizes it.
The teacher provides signals and meanings.
So they say, you know, cat and then shows a cat.
Just like in cartoons, the cartoon idea about how we teach children,
although people who work on children point out that that's not actually what
happens, that we very rarely teach children language in this supervised way.
But here, we do have this naive picture.
The teacher provides signals and meanings.
The learner learns the mapping from signals to meanings.
And then when they reach maturity, they use that to, they then use a version,
which I'm going to talk about in a minute, to invert that map.
So they get a map from meanings back to signals.
And then they choose some random meanings, produce the signals, as an
exemplar, to the new learner and the process continues.
And the idea is that the language that's produced should have some of these
nice properties.
So the properties they have that we're to look for are expressivity,
stability, and compositionality.
Expressivity is basically, can all meanings be expressed?
In other words, if you map signals, the signals, set of signals onto the space
of meanings, how onto is that map?
If a completely expressive language is one where the map from signals to
meanings is onto, if the signals all map to the same meaning,
that would be not at all expressive.
And expressivity is just a counting of, I mean, basically it's a counting of
the map of the signal space into the, into the meaning space divided by
the size of the meaning space.
Stability, that's just how, after the languages has had time to mature,
is it roughly stable from, from iteration, from generation to generation?
And then compositionality, of course, is the, the sort of more difficult one.
That's what makes languages, languages, what makes a language a language?
The idea that a, a, a part of the signal should consistently code for
some aspect of meaning.
So, you know, in this case here, we have the word for orange.
I think it's funny to make this as an example when I was making these slides,
but of course it's the worst possible example.
So, so the idea is we have a word for orange, the color.
You can see my problem, I mean, I'm really screwed myself, but yeah,
we have a word for orange, the color, and it's used here to describe orange,
the fruit, and then we have blue used to describe the blueness of the orange
on the right.
And, and, and the idea of compositionality is that the word orange,
it means the color orange when referring to the color of an orange,
or it means orange when referring to the color of a, of a high-biss jacket.
And one of the things, you know, that people have learned in trying to do,
make agent models of, of language evolution is that
compositionality is actually quite hard to enforce.
So, you know, if you have two, you know, reinforcement learning agents and
there's playing what they call the Lewis-Signaling game, they're trying to
learn a way of telling each other about things.
What tends to happen is that, you know, if you don't, if you restrict their
signal space, so they just don't have a separate word for every possible
combination of attribute and object, et cetera, but rather they're forced to
have some symbol for attribution, some symbol for what's being described.
They have to have a word for the color and a word for the, the object.
You can do that, but they don't consistently use the same color word.
You know, they might use orange to mean orange when describing oranges,
but they might use blue to mean orange when describing high-vis jackets.
The, the, it's enough for the communication between agents, you know,
reinforcement learning agents that, that, that, that, that there is a word
to distinguish potential colors of the orange fruit.
It doesn't, but that, that word, the word for orange doesn't have to be the same
word as, as, it doesn't have to match to the same color as when you're using it
to describe something else.
You know, and we, we do this a little bit ourselves.
I mean, you know, we, you know, we, when we're talking about horses, we, we,
we use the word chestnut for what we would call brown in other instances.
So, but generally speaking, the, the main property of language is compositionality
and the idea is to seek that here.
So in this version, in the simple version of the iterated language model,
we just have eight bits of meaning and eight bits of signal.
So the meaning space is just 256 potential meanings.
The signal space is 256 potential signals.
And then the, the learner has a, has a simple neural network.
You can see that this all dates back to the year 2000.
So it's, it's a two layer network.
Signals come in so that the teacher says a signal and then provides a meaning.
And then the learner maps using, you know, using a sigmoid nonlinearity.
So probability of ones and zeros for all the potential meanings compares it to
the actual meaning back propagates and does, and learns to map from signals to meaning.
So that's, that's the, that's the plot.
And of course, the, the thing about this is that this neural net has been trained
on only these exemplars, the, the small part of the space of meanings that form
the teaching event from the teacher to the learner.
But the, the mechanism of course provides a map from any signal to, to a meaning.
So that's the, that's the first part of the teaching.
But then the, the next part, which is that the, the learner has to, has to also get
a map from meanings to signals.
And so the way that's done is, is using a version, you know,
without worrying about it too much.
Here's a two bit example.
So here we have a signal mapping to a meaning using the neural net.
So, so, you know, what, what the learner is learning is, is the correct mapping.
So maybe the correct mapping here, the mapping that the teacher is trying to teach
is that one zero goes to one one.
But, but literally speaking, the learner can provide from this mapping,
coming from their neural net, a probability for all four potential meanings.
And this is a contrived example, so that the probabilities are 0.1, 0.1, 0.7 and 0.1.
If you, you know, obviously multiply P1 by P2 or 1 minus P2 or whatever.
And so in that way, the learner can produce a table of all possible maps from, from signal
to meaning.
So here are the signals and these are the probabilities of given meanings.
And in a version, all you do is you, if you run the table the other way.
So basically, if you're given one, one, one, so if you, if you see the signal one
zero, you, your neural net tells you these are the probabilities of the different meanings.
And to get a map from the other way from a meaning to a single signal, you look across
this way and see that 0.7 is the largest number.
And then you decide that in your, a, a, a version in your inverting of the, of the map
from means to signals, you'll map one one to one zero because that's associated with
the highest probability.
So that's the process of a, a version you take, you read across each of these lines,
you put a one there and then this gives you the map.
So zero, zero will map to one one.
So if the learner wants to, it's, you know, randomly decides to teach the next learner
the, the, the, the signal from zero, zero, they'll say zero, zero, sorry, they'll say
one, one, that's the signal and they'll point out that that corresponds to the meaning zero,
zero.
So that's the, that's the iterated language model.
You can see that this aspect of it is completely unrealistic and something that you might want
to get rid of, but it's the, the thing that seems to work and what the reason, of course,
it's unrealistic is that it requires that the, the learner on reaching maturity goes
through all potential, all potential signals and all potential meanings, works out the
corresponding probabilities and then does this a version map.
And that's obviously not true of language learning, the whole point of language is that
you can't go through, you know, you don't have to go through all meanings and all signals
and even from a computational point of view, it's extremely resource heavy and even with
modern computers, it means that you couldn't.
So the hope is that you could look at this iterated language model far beyond the sort
of eight bit examples they're doing here and maybe even use it, you know, on language itself.
So replace the set of meanings with actual sentences and force the agents to come up
with their own internal languages and see what happens.
But so, but anyway, with this a version process, you do get a way of mapping and so you can
run the iterated language model.
This is, this is just us recapitulating what Kirby and coworkers saw 20 years ago.
You can see that if you do this, the, you know, with the suitable size of bottleneck,
so 256 meanings, you allow 50 of them to be taught, you run it across generations.
The expressivity goes up, stability, so this is the instability, the opposite of stability
that goes down and more remarkably still, the compositionality increases.
So this I think is intriguing and worth sort of reminding or sorry, this is just some,
you know, interview.
There's two different measures here going on of compositionality, but it's basically
a measure of compositionality based on entropy, but I mean, I do think it's remarkable and
I think it's worth us going back to the iterated language model and trying to see what it tells
us about language evolution.
To get rid of the inverter, it turns out you think it's going to be easy.
So for example, you could, you think that you can just add another, you know, in the
learning process, you could think that the learner could have, you know, a meaning and
then also learn its inversion at the same time, stick in as an objective function, getting
to the right meaning, but also recovering the original signal.
That seems like it would almost certainly work and I guess this is one of the sort of
few original results we have in this area and it's sort of a negative one, which is that
it turns out that a version, although clunky, something that you hope might just be a convenient
way of doing the inversion is necessary, it creates some sort of pressure which drives
apart the mapping and makes the mapping from signals to meanings onto and produces expressivity.
So if you just replace it with a recurrent neural network, well, you might call it recurrent
neural network, with this architecture here, you lose that expressivity.
I think that it's, so what we're seeing basically is that the bottleneck which forces the neural
net to generalize, or sorry, the agents to generalize is producing compositionality,
but the inversion is also required for expressivity.
The bottleneck also tends to cause this pushing together of the mapping, which loses the impressiveness
of the language.
And so I think there's ways around that.
I think, you know, maybe if you think the whole thing is a sort of Bayesian reconstruction
problem, you can come up with a new objective function which has a sort of contrastive term,
which forces it not only to get the right mapping from signals to meanings, but also punish
it for other meanings being close in probability.
That, when you started doing that, it hasn't worked yet.
It's still not producing the expressive map.
It goes up for a while and then something happens, but I'm sure we can sort that out.
But the plan here, the hope, the public conclusion is that there's a lot going on in trying to
understand how compositionality and expressivity can arise in these simple agent models.
It'd be nice to have a sort of working example first and then try and decide, you know, could
we generalize it to much larger, more difficult cases?
But I think, you know, the problem is that, and this slide is just to remind me to sort
of announce the problem, which is that, you know, with these models, you're starting to
worry about how much you're just following your own footsteps.
You start putting things into the models to produce some sort of behavior, and then you
start to worry about exactly what we can compare to when we look, you know, how we compare
the model to the actual behavior of languages, how easy it will be to decide, you know, whether
the model is a good one or not, and then work out from whether the model is a good one or not,
you know, what is it about it that it tells it, what does it tell us about the brain?
I mean, one thing we sort of, one of the things we try, obviously, is look at how it affects
language, language synchrony between different communities.
So here we've, we've taken the iterated language model, and we've stopped it being a simple
learner to, to, teacher to learner interaction, but rather have some sort of web of interactions
where a learner has a privileged teacher, but also learns from, from their community.
And then we take networks where there's greater connectivity within, within a cave, as you know,
it's one of these cave people graphs, so there's greater connectivity inside the cave,
that across the caves, and we look at how the languages evolve and stabilize, and we discover
that you can, you know, depending on your parameter choices, you can end up with, you know,
five different languages in six caves, this cave, they don't even have their own language,
or a case where there's, everybody speaks the same language, or where some languages are shared,
and some of them are different, or where there's two different languages.
And so you can use this model to, to try and understand properties of the distribution,
or the sizes of language, languages. But the problem there, of course, is that there's millions
of parameters, you have to work out how to, how to, you know, what the network should look like,
how to structure the teaching events, how to, how to structure the size of the bottlenecks,
compared to all possible being single pairs, etc. And so the model, although intended as a very
simple one, when you start trying to apply it in ways that can give you data that you could
compare to the real world, the model becomes still simple, too simple to produce something,
you know, directly comparable to language, but much too complicated to draw easy conclusions from.
And so it struck me at this point that we should try and think of what the very simplest model
of language evolution is, and that's what I wanted to finish by talking about briefly.
So the idea here is that we want to look at language change and look at the, the,
the most parsimonious description of what goes on as languages change. And so, obviously,
one property that languages have to have is alignment. If you're talking to someone,
you want their language to be almost the same as your own, or else you won't have,
you won't be able to understand them. And the closer their language is to yours,
the less sort of cognitive-low communication will play, will place on you.
So I think the first properties of languages as they change is that they should align.
The second property is the converse, this inclination towards change. You know, obviously
teenagers do this all the time. I have teenagers, they use words in different ways,
they delight in language invention. I mean, weirdly, my mother is almost the very opposite of
a teenager. It's the same. She's forever making up new words and new ways of saying things,
often based on puns, and then the puns turn into words, and then she just uses them in everyday
conversation that expects people to follow. And she just does it out of sheer delight in language
invention. There's also a kind of a more strategic point to language invention, which is to find
shorthands for saying things. Obviously, the words are pushed in with the words that they're
exiliaries to, the pronunciations are changed. People say small phrases to mean more complicated,
large phrase things, etc. So there are these two sort of competing forces that work in language
change. The third one as well, which is an inclination towards consistency. That's exactly
the sort of thing that the bottom leg in the iterated language model deals with, and I'm not
going to deal with that one here. That's the idea that, you know, if in one sentence you put,
you know, if at some point you decide that the verb goes at the end of the sentence,
it does that for, you know, that can sit that rule doesn't just apply to one one's type of
sentence, but rolls through the language that once something starts changing, other parts of
language change to suit it. So that's an inclination towards consistency. You know, and it's obviously
kind of amazing. I mean, if you think of how noun and verb modifications work with Arabic and Hebrew,
I mean, it's just incredible the way that, you know, everything has three consonants,
and then you've got the verbs and the endings and, you know, how did that happen? I mean,
it's just some small changes then became rules. And so that is obviously an important part,
but not one we'll talk about now. So obviously, agreement alignment between speakers and
spontaneous change. You probably guess what we're going with this, that that's a nising model.
So in a nising model, it's a model of magnetism, as you'll all know, at different lapses sites,
you've got a spin, the spin goes upwards or downwards, and there's an energy associated
with the alignment of the spins. It's a lower energy state. If the spins are aligned,
then if they're not aligned. And so you would obviously expect an ising model to evolve towards
total alignment. But there's also in the ising model thermal effects. So in an ising model,
this is the metropolis formulation of the ising model, what you do to evolve the model is you
choose a random, you choose a site, and then you consider what would happen if you flip the spin.
So we'll label the spins plus one and minus one. And if the consequence of flipping the spin
can be written down like that. I hope I have the signs right there. But basically, if the spins
become more aligned on average with the neighbors, so the one site, these are the four, for example,
neighbors of the middle site, if it becomes an average more aligned with them, then a DE will
be negative, and you'll accept the change. If it becomes less aligned, you'll still accept the
change. And this is the terrible part with some probability given by the exponential of minus
DE divided by T. And so DE is positive in this case. If T is negative, as I said, you always
accept the change. T is the temperature. In the case of when you're modeling magnetism,
it's literally the temperature. If T is very large, then this is always one, you always accept
the change. And so you just get a random up and down. If T is very small, then this will be near
to zero. You'll never accept the change. And you'll just get it flowing to total alignment.
And so you get these different patterns. This is the very random. This is the very aligned.
And this is the critical point in between. So this is a model of a phase change.
At the phase point, at the critical point, you have scaling behavior at the cluster size.
And that's what you get. And that's why people are interested in the IC model. So obviously,
we can map these two things, the movement towards alignment, towards the idea that you're trying
to lower the energy. And the spontaneous change is like the thermal fluctuations.
But clearly, of course, if you had only one spin, then you'd have only two languages,
the upper language and the down language. And that wouldn't be very interesting.
So what we do instead is we've got a vector of spins, d dimensions, where d is some number,
yet to be chosen. And we imagine that these are coding for different properties of the language.
So one spin might be, how do you say father? And obviously, in lots of languages like Latin,
German, Irish, the word is almost the same. And so that would be plus one. Do you use
derivative of pattern for the word for father? And minus one would be languages where you don't.
And I don't know any languages that don't use pattern like derivatives. Anyway, not a good example.
Or it could be something to do with word order. So here you see the word order in English,
subject followed by verb, and adjective followed by noun. Whereas in Irish,
it's verb followed by subject, noun followed by adjective. And they would correspond to two
further spins. And then a further complication is that that choice tends to be the same. So if the
subject comes before the verb, the adjective comes before the noun. If the subject comes
after the verb, it's the other way around. And so you can imagine there might be two spins,
one for this part of the word order, one for that part of the word order. And then in some
elaborations model, there'd be some relationship between them. But that's basically the model.
We have, as it were, in this first idea, we've got d independent ising models and a given set of
plus ones and minus ones constitutes a language, which use some temperature,
we run it forward and we get some behavior. I do have a graph in a minute, I'll show you.
But the main thing that you do see is that because it's lots of interlocking patches,
one for each of the d dimensions, you tend to see language continuum. And language
continuum are a property of languages. So these days, everything's a bit more complicated,
national boundaries and official government documents and radio stations and so on.
But in the olden days, you tended to have no hard language barriers, boundaries. So if you
walk from Portugal all the way to Sicily, well, Portuguese would be very different from Sicilian,
but as you do it, you'd never actually be somewhere where we're depending on your route.
And that's going to be the point. If you go this way, you're never going to be somewhere where
people in nearby villages can't understand each other. The languages gradually change
one to the other. And so that property of language distributions is well reflected by
this ising model of language. And obviously the temperature determines how big these clusters
are and so on. And that's something that you might try and fit against some knowledge of the
distribution of languages. But the problem, as you could probably anticipate, occurs here,
which is the Basque country. And if you, if you instead of walking from
Portugal through Galician and Castilian and Arganese, you kept along the coast as well,
you might, particularly if you're a pilgrim. Well, if you're a pilgrim, you're going the other way.
But either way, if you strayed into the Basque country, you would encounter a linguistic barrier.
Basque is quite, quite different from, it's not an Indo-European language. And this is a sign
remarkably in French Gascon, which is a Pocodin language. And Basque, the Basque is this here.
And you can see that it's very different from the others. This is Basque here as well.
And so there is, in real languages, a language barrier. There is the possibility of language
barriers. And also, of course, you know that we don't, we don't have to be able to talk to everybody.
You know, we, we can have neighbors who speak a different language. And we can talk to them
without necessarily aligning our language to theirs. We can speak to them, for example,
through a lingua franca. These days, using translation by using somebody who's bilingual
or being bilingual ourselves. This is an example of Kiswahili, which is a language that, you know,
100 million people, that sounds a bit much, a large number of 10 million people can speak
as a second language, but only a million as a first language. And because it exists as a
lingua franca, allowing people who don't have a mutual language to live beside each other.
So the, the next version of the language evolution model is this preference sizing model. So the
idea here is to run the same sort of dynamics, alignment, and thermal change, but only allow
or only have each, each side interact with which of the ever of the four sides around it in the
simplest case has the most similar language to its own. So, so the idea is that for each of the,
for each pair of, of sites, each pair of speakers, I guess, you can work out the difference between
their languages. And then you could, you need to, you only run the ISIC model between the speaker
you've randomly chosen to consider changing one of their plus ones and minus ones, and whichever
neighbor is closest to it. And so that is the idea being that you only speak to the people who speak
the same language as you. And so that's the new version. There's a paper about it there in A-Life.
And it kind of works. So there's lots more to be done on this, but this is, this is the basic idea.
This is the originalising model. And here is a histogram of, so this is only five dimensions,
you can run it in far more, you know, five different language attributes, you can run
in far higher dimensions. But in the case of the firstising model, you can see that this is the
number of different, average number of differences between the speaker and their neighbor. And you
can see that the speakers and their neighbors tend to have very similar languages. And very few
people, very few pairs of people have languages that have very little in common. In other words,
this version of the model does not allow for linguistic borders. Whereas in this preference
model, where a comparison, where the dynamics is only relative to whichever neighbor has the
closest language to you, you do have lots of pairs where people speak the same language,
or very similar languages, but you do have pairs where people speak very different languages.
So this is the, this is my proposal of the simplest possible model of language evolution.
This is work that's only just started, but the idea is to consider, you know,
consider different structures of preference and how many neighbors you interact with and so on.
And then try and find, in different temperatures, and then find, find the structure of the size
of language groups there and compare it to real data. And so that's something that we'll do in
the future. And that's it. Thank you very much. So I was assuming throughout this presentation
that the bottleneck in the iterative model kind of corresponds to Chomsky's poverty of stimulus
argument about language learning. Is that right? I mean, corresponds to, I mean, it's
meant to be representative of the fact that people, children only like experience a very
limited amount of, but it adds something extra to what Chomsky says. So Chomsky uses the poverty
of stimulus as evidence that the brain must have, you know, linguistic things. Whereas here,
the poverty of the poverty of stimulus is a mechanism for, it says that the structure of
language is a response to the poverty of stimulus. So it changes that. I mean, that's what I think
is really nice about this model. It turns that language upside down and says that, in fact,
it's not that the brain has some special language mechanism, it's that language has evolved
so that we can generalize from a poverty of stimulus.
I was interested in, because I can imagine a more innate style person saying, you know, it's this
convergence from the statistics to just a definite mapping in the aversion process that is leading
to compositionality. But maybe there is some sort of innate mechanism, which is responsible for
something that has the same effect as aversion. But do you think that the work you're doing with
this model, is there something that makes you lean more towards the empiricist take on this?
So, I mean, I think one of the things that we're learning at the moment, you know,
obviously, you know, the objection to transformers as a model of language is that
they require this massive stimulus. But conversely, they are very sophisticated at learning grammar.
You can see that if you back away from the learning aspect, and you just look at the
ability of these models to perform grammatical tasks, it's quite incredible. We do do experiments
now where we ask, you know, a transformer or an LSTM or something, can you learn gender agreement?
And so I have a student, Priyanka, who's teaching new words to an LSTM, so she takes an LSTM,
is pretrained, she freezes everything but the representations, she teaches it a new word,
she gives it some grammatical context, gender context, so she doesn't French, obviously.
So she says, you know, la, we use the word trilobie for some reason, because it's the
least common word in the vocabulary list that we're using. So we take the word trilobie, we cut off
its representations, we reintroduce it somewhere else in the representation space, we train just
the representation space on a few examples where you use the word la or le, describing trilobie,
and then you ask it to do other gender agreement tasks, and it does it completely
well. So even though it's learning one aspect of gender, it's been taught the gender of the word
through one aspect of gender, and it's been tested on another, it has abstracted the abstract
category of gender. And so, you know, the initial bias that you had, that you needed,
you needed special mechanisms, you know, Chomsky mechanisms to allow the brain to perform the
formal manipulations associated with grammar, that I think has been demonstrably made false by
large language models. They have this very, I mean, the structure of Transformers seems
completely bizarrely crappy, right? And yet they do these amazing things. And so, it's quite possible
for these, you know, simple network models that are doing statistical learning to learn this stuff.
But that's not the same as saying that it can learn it against a poverty of stimulus.
But what I think the iterated language model is maybe indicating, and again, we need to start
using the iterated language model on much bigger examples. It's indicating that you don't have to
put much more in, you know. Once you start thinking about aversion or exactly what the
objective function is, and the needs to generalize, it's possible that it's not just that the
it's possible that the language that evolved, that you could evolve the language where
you can learn from a poverty of stimulus. Does that make sense? I said that in a very
roundabout way, but I mean, I think I'm essentially agreeing with your initial point.
Who are you coming from? Thank you.
Thanks for the lovely talk.
But yeah, I was wondering, are you thinking with the Shelling model, are you thinking of maybe
looking at the, or maybe you already have the different patterns of, like actually taking
different patterns of like verb order and so on, and kind of encoding them and plugging them into
this model and seeing what you get out? Because I think, I mean, one thing is, I think with subject,
verb, object ordering, there are certain patterns and some patterns are more frequent than others.
For example, I don't know. I guess that wouldn't... I mean, it's very hard to know because we tend to
think that the patterns represented by the Indo-European languages are much more common.
I mean, just to answer that specific point, it is, you know, so you think... Well, for example,
the claim is that verb object is much more common than anything else, but that's only if you can't
buy speakers, if you can't buy languages, that's maybe not so obviously true. And Irish, of course,
that was one of my original interests is a language where verb and objects aren't beside each other.
So, you know, I mean, I think the point with the ISI model is to make the simplest possible
model. And so, you know, I don't think you can retain that advantage to the model while at the
same time tying your coding to specific features, but rather the idea would be to introduce into
these dynamics some abstract version of these features. So you could include some sense of
consistency, which would be an interaction between the spins. So not only is a speaker
interacting with their neighbors, but there's also an interaction within the spins themselves.
And that would be the idea that once you flip one thing, other things should flip as well.
But I think, you know, there's two types of models here. There's one that you might,
the iterated language model, where you might actually try and use that to probe
actual properties of actual languages. But with the difficulty that, you know, it's
not a completely parsimonious model. You always have the problem when you're doing ancient modeling
of deciding whether you're looking at your own model or you're looking at the world.
And then there's the ISI model, which is supposed to be the simplest possible language,
a model of language evolution. And the idea there would be to look at very simple properties,
such as cluster size, cluster distribution, et cetera, and compare them to real languages,
which hasn't been done yet. But that's, that's where we're going.
So it could be wrong in assuming this, but sort of tying together the
start and the middle of the talk. And in the iterated learning model, you have this mapping
between meaning and sensations. And in the EEG experiments, I guess, is the
purpose there to try to uncover how that mapping is established in the brain and how,
you know, maybe, you know, neurophysiology or segregation in the brain, biases or influences
that mapping itself? Like, is that what you're trying to get at with the EEG experiments?
Yeah, I mean, as he pointed out, we're a long way from actually doing any of this, that the,
that the sort of overall picture is language has a structure. We can discover that structure.
How do we discover that structure? Probably, I think the best way to do it is by looking at
EEG responses. You know, we do have commentaries on language invented by geneticians. That's
really them trying to impose what they've learned about Latin onto other languages. And it's probably
sort of quite naive compared to how the brain considers parts of speech and the relationships
between parts of speech. But the parts of speech and their relationships are probably
important either as a reflection of, you know, and again, the discussion there is relevant,
of the mechanisms the brain uses for producing language and understanding language, or the
language that the, that's the languages that have had to evolve so that we can learn them
despite the poverty of stimulus that we experience as children. And so the iterated language model
is trying to find out what, I mean, potentially is trying to find out what those properties of
language might be. And we'd like to compare them to the real properties of language, which we
discover through EEG. That's the big plan. Where my thoughts were going with that, I was just
wondering if there are any, you know, takeaways from that EEG research or from, you know, the neuroscience
realm that could perhaps be brought back over to the, the iterated learning model, but specifically,
so in that bottleneck layer in your representational bottleneck in the meaning.
Oh, yeah, no, I don't agree with that.
Can you take any principles from neuroscience to apply, you know, to constrain that, you know,
the structure of the bottlenecks? But I mean, I mean, the story of my life is that
when I started working in neuroscience, I thought, you know, we really want to map from
actual neural networks to what they're doing, you know, we want to go from, from, you know,
this is a neuron and this is what it's connected to, to this is how it works.
And so, you know, I ended up working on tadpoles, because I thought tadpoles are really simple
creatures. Maybe we can understand tadpoles. And tadpoles, there's a tadpoles neonatal tadpoles
make a decision. So basically, older tadpoles are fearsome hunting animals, but the very, very
young ones, when they've just emerged from the, from the egg, and they're still carrying, they
carry with them kind of a egg pouch. So the material from the egg that they grew in, so they
don't have to eat for a couple of days. And these animals are very, very simple. So you touch them,
and they swim away. You grab them, they struggle. So that they have this exactly one decision they
have to make, which is whether they've been grabbed or touched. And I thought this is the simplest
decision that any creature makes. And there's like eight different neurons involved in this.
Maybe we could go from the network to understanding the decision. And I had a PhD student who worked
on this model for, you know, four years, reduce it all to two dimensions so we could draw a phase
diagrams. And it was like just the most unbelievable mess. You know, and at the end, you know, we just
knew nothing about tadpoles, yet alone, you know. So I think, you know, I just don't think that's,
I think we're so far away from, you know, something as complicated as language and mapping
anything but the broadest principles of neural dynamics to the cognitive dynamics. I think
the gulf between, you know, the neural substrate and the cognitive function is so great
that I would be trying to stay away from that. The idea is rather to look at the structure of
language and ask, look for the structure of language in EEG. So the mechanism there is only
to try and find out what the brain regards as grammar. And then to compare that to the
iterated language model and how it might, or some other model and how it might treat grammar,
basically. Which is not to say that people are, you know, I mean, maybe the cerebellum,
you know, maybe the hippocampus. But if you can't understand tadpoles, what could you do?
I mean, basically we disproved the existence of tadpoles, I think.
I'm sorry, sad. Do you, do you worry that expanding kind of this type of EEG work to
a much broader set of structures would result in the same sort of mess?
Yes. Yes. I mean, I think, I think it's a good strategy. I agree with you that it seems promising
and much more, much simpler than that or some of the stuff that's been done mapping kind of semantic
content into the brain with MEG and fMRI. But it turns out like the tadpoles, it's a mess.
Yeah. It seems more promising. But I mean, who knows? I mean, yeah, I mean,
we, what we've done compared to what we want to do is tiny. So it seems to me to be the most
straightforward strategy. But, you know, at the moment, I can't even get my little Prince
experiment funded. And not only an eye, but these are greater people who are trying to get money
for the same thing and get it done. So, but you know, I, yeah, I had, so they're building in
Bristol, an instrumented museum, an instrumented cinema. So it'll be possible to do simultaneous
EEG experiments on 100 people at once with consumer level EEG. So, and I think they're
building this thing without any clue what they're going to use it for. So I think, I think this
is a potential to persuade, you know, to get hundreds of recordings of people listening to
the little Prince in lots of different languages. And you can't help but feel that you can discover
something that way. Because languages are just so different, you know, I mean,
you know, if we could get Malay speakers, they don't, they don't, it's an isolating language,
they don't change the words for the plural, you know, if we can get speakers of, you know,
Irish, they put the verb at a different place. I mean, it's just, there's such a variety,
it'll be really interesting to see what we can see. But I agree, you can probably turn into a mess.
And I think the way that you can turn into a mess is to try and
find things that are too detailed. We have to try and find the very broad principles,
you know, because even that's unknown. Is this cinema? Like, yeah, yeah, they've built it.
It's, they got, they got funding for something called a Future Institute. And it's good to have
this instrumented cinema where people wear EEG and they'll watch films, basically. So, like,
when all the new films come out, you can have, like, the EEG response alongside.
Exactly. Yeah, exactly. I mean, I think that's how they solve it. Yeah. I mean, it's nothing to me.
It's people in the psychology department. And the idea is that I think they'll have, you know,
all sorts of instrumentation, right? They'll have, you know, we have to work out how sweaty
people are and the heart rates and, you know, how much they're breathing, you know, and the EEG.
So, I mean, it sounds like one of those things that sounds really cool. So, they were able to
get money for it. But I think when it comes down to it, they're going to struggle to find
experiments. So, hopefully, they'll do experiments for me. Nightmare giving a talk in that room,
you can track in real time. Yeah, there's lots of cool things you can do like that. Yeah.
Cool. Alrighty. Thanks for coming in.
