This public lecture series.
Many of the most cherished books in science, Einstein's relativity, Schrodinger's What
Is Like, Richard Feynman's QED, were all based on public lectures.
In this spirit, we want to welcome you here tonight, this public lecture.
In the special series beginning tonight, the ULAM lectures, we bring a notable scientist
to illuminate a cutting-edge topic in honor of the late theoretical mathematician Stanislaw
Ulam.
All of our public lectures are underwritten by the McKinnon Family Foundation, who allow
us to continue to provide the lectures at no cost, and we want to take a moment to thank
them first.
We are additionally supported by the Santa Fe Reporter and this Lenzick Performing Arts
Center.
Stanislaw Ulam was long associated with Los Alamos National Laboratory, and is highly
regarded by the Santa Fe Institute scientific community.
Former SFI vice president Mike Simmons said, the enormous range of Ulam's scientific thought
encompassed not only mathematics, but also physics, computation, biology, and much else.
He would have been very much at home in the present day Santa Fe Institute.
In this tradition, I am proud to introduce Ricard Soleil, our speaker tonight.
Simply put, Ricard is one of the most abundant and interesting theorists alive.
Ricard leads Icreia, the complex systems lab at the Universitat Pompeo Fabra in Barcelona.
He is also an external faculty member here at the Santa Fe Institute.
Ricard originally studied both physics and biology and undergraduate before achieving
a PhD in physics.
His work touches on everything from how life originated to present day ecology to the very
nature of thought.
In the late 90s, Ricard connected ecology and mathematics by demonstrating the fractal
structure of forest canopies, and that these structures emerge from the statistical dynamics
of self-organization.
This is a fundamental idea in ecology, and the full extent of the impact of these ideas
are still being woven into our study and predictions of forests today.
They are ideas that inform and inspire my own work constantly.
Ricard has worked on other fundamental mathematical questions related to complex networks.
More broadly, he is interested in how life works, spanning from how cells first originated
in our past, to how brains developed to know and observe those same cells today, to how
technological societies network brains to design new cells and engage in global bioengineering.
And it is necessary to point out that Ricard's aggregate breadth of study is never at the
expense of depth.
This combination of expansive topics pursued with deep rigor is one of the rarest talents
in science.
In my own interactions with Ricard, we often discuss literature, and I am the fortunate
recipient of many quotes from novels, biographies, and historical scientific works.
The wonderful drawings that you are looking at tonight are made by the man himself.
This shows that his imagination is constantly in motion, and it is a pleasure to discuss
any topic with him.
He is a true polymath and an ideal speaker for this lecture series.
With that, please help me welcome Ricard Soleil.
Hello, you hear me?
Thanks for coming tonight.
It is a real honor to be here, delivering the Olam lectures this year.
Thanks, Chris, for this great introduction.
My talks have to do with a very exciting domain of research, which is mapping the space
of cognitions.
Not only the cognitions that we are familiar with, what I call the solid brains, but trying
to understand what is there, what I call the cognitive biosphere, what is there, how much
is complex, and whether or not we can understand the evolutionary dynamics that brings us.
And if we can maybe go beyond evolution and try to engineer that complexity.
So, before I go to that, since this is an Olam lecture, I want to say a little thing
about that, because when I was in high school, I stumbled into this book, The Monte Carlo
Method.
It was a tiny book edited by the former Soviet Union in a series of little books with all
kinds of things, where I discovered that Stan Olam, along with John von Neumann, they invented
this method that physicists would use all the time to actually model complexity that
has to do with some kind of randomness.
And that brought me into play myself.
It was the time of, there were no computers, so I'm old enough to say that, and so I had
a calculator, I have a coin, and I did a model of a gas.
You can see this is written with a typewriter, and I elaborated with that using that book.
And one of the things that I learned is that there's a lot of power in being able to approach
reality using, let's say, synthetic approximations.
And the other thing I learned is that it's something about popularity.
This series is called Popular Lessons in Mathematics.
Did that make me popular at all?
No.
And I understood that popularity is not exactly that kind of stuff.
But the other thing that I did connect is, I was mentioning Olam and von Neumann, which
you can see there on the left.
In the middle we have Richard Feynman, another big name.
It was important in my life.
And von Neumann, and I will mention him today and tomorrow, brought me also into something
else.
I discovered this book by Michael Arby, Brains, Machines, and Mathematics.
And again, I was still in high school.
I found out that there was people thinking in the brains using mathematics that you could
approach, actually, brain complexity using mathematics.
I found out extremely fascinating.
And over time, I got involved in trying to figure out how to solve some of the interesting
questions.
There are plenty of good things that we would like to understand from the question of why
brains?
Why brains is part of a more broad complex, a more general question on complexity?
Because some people said that why the biosphere is not just made of microorganisms.
They are cheap.
They reproduce.
They propagate and proliferate.
Thinking that it adds complexity and brain is a lot of complexity with a cost seems to
be superfluous.
Why actually is any complexity?
And brains are especially important.
What kind of brains?
That's one of the big questions we'll try to bring.
Are there other minds?
It's a very hot topic these days.
What is a mind and how do we define and what we can find out?
All the way up into the artificial.
So whether or not beyond evolution, beyond what we see, beyond what we can infer about
how nature happened to construct complexity, whether we can actually create new things.
And that connects with the big question of the major evolutionary transitions, namely
how the big innovation happens in the real world.
Many years ago, Eosia Smarty and Don Miner-Smith made this list of transitions that had to
do with the origins of cells, the origins of information, the code, et cetera, et cetera,
all the way up to language.
Of course, the list is more complex.
You could ask yourself, what is the origin of consciousness?
Why do we have consciousness?
I will address that, and I'll have an answer, which might be wrong, but you'll see.
And in the middle of all this discussion about what is the nature of innovation and how innovations
happen is precisely this special thing of biology, the special status of information
in biology.
And Eva Javlonka and Marian Lam made this beautiful work where they bring precisely this idea.
Cognitive agents bring something extraordinary.
In evolution, you have genetic information dominating the story of life for a very long
time.
Information that is based on something that is not genetic has enormous advantages.
Information that can be shared, can be propagated, and for us humans, can be propagated beyond
ourselves.
All right?
So that's the main thing I want to address.
And the first part of the story is to actually ask ourselves, how likely is a brain to happen?
And that connects with something that is fundamental in evolutionary biology, but goes
beyond that and percolates into many other areas of knowledge, which is the role of randomness
and contingency and history versus the possibility that there are very strong laws that constrain
a lot what is possible.
And I put kind of two kinds of views here.
Here on the left, Stephen Jay Gould was a strong advocate of the idea that evolution
is so historical that any kind of little change that you put in place will modify the outcome.
And he made, he used this mental experiment based on this movie that, sure, you have seen,
I mean, I don't know here, but in Barcelona, you see every single Christmas, we have wonderful
life at some point, right, on TV.
And I remember for you the story, it's this guy, a very, very nice guy who had a lot of
trouble for a very unfair reason that at some point he decides that his life is worthless
and says to himself, the world will be better if I haven't been born.
And then comes this angel, which is a kind of quite annoying character, which is proposing
the experiment of, okay, let's do it, let's do the experiment.
You haven't been born, right?
What happens?
And he shows this, all this chain of events, he didn't save his brother who fell in a frozen
lake and died, and because of that, his brother in the war, in the Second World War, couldn't
save a whole company, and so on and so forth.
And eventually, the city where they live is very crappy.
So the message is, any single event can change everything.
And Steve Gould used that in the context of evolution, saying, if we were able to replay
again the tape of evolution, like starting 600 million years ago, the biosphere that
we'll see now will be totally different, will be an alien biosphere.
I don't think that's the case, but this is the idea.
Other people like Jax Monod also brought the idea that randomness plays a very, very important
role in evolution, and more recently, I'm very much a book person and a movie person,
my students know that very well, and I'll make recommendations.
Recently, Sean Carroll, the biologist, wrote this beautiful book where he kind of puts
these random events that seem to be relevant.
But this randomness really is so important, let me show you the other part of the story.
In fact, when we look at the natural world, we find out that very often, the same solutions
appear again and again and again independently in very different groups of organisms.
I put the eyes here.
The complex eye that we have, this camera eye, has been invented in evolution probably
about 25 times in a totally independent way.
We have this eye, and Octopy, for example, they have an eye that is essentially the same.
In fact, it's better than ours.
And this is what we call convergence, that the reason that these solutions appear again
and again and again is that they are very, very strong constraints, even maybe mathematical
laws that limit the possible.
This is a book, Life Solution, sounds like a self-help book, but this is a book of evolution.
It gives a lot of very interesting examples that go from cells and codes, genetic codes,
to minds.
Here is the Catalan scientist, Per Albert, who, unfortunately, I met him years ago and
died very, very soon, and he made the argument that even when you look at the structure of
monstrosities, when you take the ternatologists in, for example, in nature, you see that they
are very well organized.
You can make a taxonomy that is very well organized because not everything is possible.
In the context of brains, we wanted to do something about that because, and that's one
of the ambitions of the Santa Fe Institute, right, that think in really broad terms and
ask ourselves difficult questions.
So at some point, we talk about the idea of why not to try to make a kind of a space
of brains, of cognitions.
And in particular, it was clear that we have these solid brains, right, brains that I'm
going to go into that in a moment, brains that are made by neurons located in specific
positions, right, and connected, and everything happens in the connections.
But ancolonies are a kind of brain of brains that are moving around, they're liquid.
The immune system is a class of network in many ways, it's like a neural network, right,
but the cells are moving all the time.
And so on and so forth.
So what happens with all these cognitions?
How likely are they?
How powerful they can be, all right?
So we decided to organize a little workshop with my colleagues, Melanie Moses and Stephanie
Forrest, about liquid brains, solid brains.
This is kind of a very ambitious idea because we brought together this group of very, very
interesting people, but of course we didn't know what was the outcome of this because
we didn't have even a definition of liquid brains, right?
So it was like our Saint patron, Colma McCarthy, said once, we met together to have more fun
that should be legal.
But the idea was actually to come out from that, from our first roadmap of cognitions.
I put it here, this was a special issue that came from this, a list of examples, right,
that include the microbiome, include plants, we'll talk about plants also because they're
kind of a solid organism, and in around everything we look for regularities, they are common
laws that we can use, common languages that we can use, and networks appear to be the
key here.
In a standard brain, right, you have the, as I was saying, fixed positions for neurons.
In an uncolony, your individual scarring brains are moving around, right?
So they are no constant connection, the connections are broken and formed all the time.
And the same happens for the immune system.
So first question, why brains, right?
What is the evolutionary force that actually pushes things towards complexity towards brains?
There's one very nice hypothesis that we'll use in several times, which is the moving
hypothesis.
It essentially says that if you live in an environment where you need to search an uncertain
environment, you need to search for resources, you don't know what resources are, you need
to move, you need to detect, you need to sense, brains are great for that, right?
They centralize information and centralize the way you move, okay?
So that's important for a number of reasons.
And the other way of looking at that is that brains, to a very large extent, are prediction
systems.
Some people say prediction machines, but they want to avoid the machine metaphor in the
sense that prediction is absolutely fundamental.
You predict all the time, right?
Okay, so first of all, and it will be totally unfair with our brains, right?
Because we don't have time.
But I brought a brain, okay?
Yeah, my family was so happy when I said that I had a brain, finally.
So this is kind of a very good model, right?
It kind of weights kind of a real brain.
The human brain is a spectacular combination of accidents.
So there are things that have been occurring over time.
Many things we don't understand, right?
But also of optimization, it's optimized circuits.
As you probably know, it consumes a lot of the energy that we bring into our bodies,
about 25%, which means that it has to be important, right?
Not everyone uses that much, but it's important, right?
And it's made of, we know now, 86 billion neurons, that was, it was a Susana Riculano
in Brazil, found out the way of counting.
And it works in a very dynamical way, right?
At any time, you record the activity of the brain, you will see waves moving around.
We know now that these waves happen to occur between order and disorder in what we call
a critical point, and allow synchronize the system so that you can actually put together
information for different places, right?
And so have specialized areas working together, right?
It's a compromise between trying to modularize the system and trying to put everything in
place.
So there are several brains that correspond to this solid picture.
Very simple brains like Hydra, which is kind of a, kind of a simple network.
Some more complex nervous systems, right?
But brains by themselves come later on in evolutionary history, and again, going into
this idea of randomness versus strong loss.
Is the brain unique?
Could be very different ways of generating brains.
And in the recent years, people have been trying to think about that, whether we can
make a theory of that, and try to understand what makes the brain special, or maybe what
makes the brain inevitable, all right?
So we could say, but if you want to build a revolutionary story of brains, that's a
difficult task, isn't it?
Because, for example, in terms of language or the mind, you could say language, which
is very central, in the next lecture, we'll see how important is this and how robots can
help understand the origins of language.
But language, for example, somebody could say, it doesn't leave fossils.
The mind doesn't leave fossils.
Well, it's not completely true.
This is an example that I wanted to bring, because it's simple, but it brings an idea
of what kind of things we can recognize.
Does anybody see that there's a strong regularity here?
These are hands of different people, right?
That painted is the cave of the hands in Argentina.
And what happens here is that if you look, it's all left hands, all of them, right?
Because the people who use whatever they use to paint, you're using the right hand, right?
You know that nowadays, most people is right-handed, and that symmetry was there already.
So we can see there's a trace of that particular thing.
The brains do spectacular things, and particularly the human brain with a visual cortex, which
is an amazing system that we have been using to do a lot of very important things that
we will discuss.
But one particular experiment we can bring, and that allows me to go into how we make
theories of the brain, is this, right?
In the left, you have a picture, which has been kind of pixelated, and you only retain
part of the texture, right?
Everybody sees what is there?
There's a dog.
The usual thing, it's a pattern here, right?
We don't know exactly why.
The pattern is, some people already know.
Some people see the dog, right?
It's kind of like a Dalmatian.
Some people doesn't see anything, but when you say, there's a dog, right?
The brain finds out, okay?
And then there's people who don't see it, right?
It's okay.
But the thing is that that kind of pattern recognition system, which is extremely effective,
we use constantly since we are toddlers almost, is impossible to simulate with a standard program.
You cannot write a computer program to do this, right?
On the right part, what I'm putting is also the fact that once you recognize that, that
particular pattern here, it's going to be stuck in your brain forever.
So one day you go, 10 years ahead, you go to the house of a friend, and on top of the
table is this picture covered in part, right?
Is very likely that those of you who recognize that say, oh, look, this is from that great
lecture I went, right?
So how do we actually make a model of this, right?
It would appear that it has to be a very complex, very complicated model.
And everything starts and comes from the work of these two amazing characters, Warren McCulloch
and Walter Pitts, who actually came about with the first formal model of a neuron.
And from that comes out all the neural networks that we use in all the artificial neural applications,
chat GPT and everything else.
We don't have time to talk about them, but if you search a little bit, particularly Pitts
on the right, he was a child prodigy, has a very, very interesting story.
They figure out how to do it, and what they did was to transform a neuron, which is a
really complex system itself, into a mathematical representation to make the long story short.
The idea is you have a neuron, you have inputs from other neurons, then set signals.
The signals can be positive, trying to make you to activate, or can be negative, trying
to make you put down, getting active.
And you wait everything.
And once you wait, you have a threshold, and if you go beyond the threshold, you activate.
And the neuron sends another signal somewhere else.
You can bring that mathematically in a very elegant way.
And you can use now that for modeling a lot of things.
For example, John Huffill, this amazing model, which I will put in a nutshell as follows.
Imagine you have a collection of neurons.
For me, my neurons will be elements that are just on and off, either active or inactive.
And I can put them like in a two-dimensional layer, like in a retina, like it's something
that detects images.
Now it's possible to show, I connect everyone with everyone.
I use the maculok pits, threshold units.
And then it's possible to train the network, show images, letters, whatever it is.
So the network learns how, well, the rule is very simple.
If two neurons receive the same information, for example, two black pixels, they reinforce
their connection.
If they receive contradictory signals, black pixel, white pixel, the connection between
them is reduced.
That's all.
No long computer program, nothing.
And you can show, using this, that this network is capable of doing precisely what I was
showing you before.
It's possible to show that in a space that is highly dimensional, that depends on the
number of connections, you create kind of valleys, this abstract space, valleys where
the bottom of the valleys are the memories, the things that you have made the network
to learn.
For example, imagine that I have trained the network to learn only two images, this one
here, that one here.
You will create two valleys, and in the bottom of the valleys you have the memories.
In what sense?
In the sense that, if now I show an image that is incomplete, it's distorted.
The network, just using the dynamics of maculoc and pits, goes down the valley and reconstruct
all the information.
I think this is totally amazing, and shows the power of artificial neural networks.
But of course, this corresponds to a given model for a given class of brains.
What about the potential universe possibilities?
I could imagine things.
My drawing is about four things that we don't observe, that don't exist.
We'll offer them.
In my lecture today, I want to explore this idea of what kind of brains are there, whether
there are very strong constraints, whether or not brains are expected, or there's a
lot of possibilities.
I'm going to use, there's a huge amount of examples here.
I'm going to use ants as one example, fissarum, which is kind of a very alien creature.
It's about plants, because there's been a lot of discussion in the recent years about
plant intelligence, and show you that we can start to think in a space of possible conditions,
and how we do it, right?
So a very important point, liquid versus solid.
On the right-hand side, you have a very small part of a neural network, of neurons connected
again, their locations remain the same over time, and on the left, it's a very tiny part
of a swarm of army ants, right?
I was very impressed when I was in Panama years ago seeing the army ants, which are blind.
They communicate in simple ways with their nestmates, but forming these huge forms, that
if you look from the distance, look like a single organism moving around, right?
Swarming in the middle of the forest, quite a thing.
So we want to see how we approach all these problems, and in particular, one good question
is, is a liquid brain able to be as complex as a solid brain?
The question is, is it relevant for a number of reasons?
One of the reasons is, let me see this, oops, there's a movie here, oh, oh, yes, okay, sorry.
Let me see.
And the question is, in particular, because one good comparison we can make is about us,
right?
The, oh, man, what's happened?
Let me see.
Is that into me?
And the question, of course, for a colony of ants is, who is in charge?
I mean, ants are moving around, right?
It's not like a centralized system saying you have to do this and that and that, right?
It's not such a thing as a queen giving orders to everyone else, right?
The queens in a way, as in European monarchies, are very useless, except in this case, to put X, right?
So how do you control that?
And this sentence by Deborah Gordon, I think, is very to the point, right?
And for those of you who are fans of Richard Feynman, Richard Feynman himself was interested in ants
and started to bring quite interesting questions about how ants work, right?
Well, two important things to say.
What makes ants and termites and social insects, I can only address a few things, special.
And what do they do that is close to the brains that we're discussing, the human brain, for example?
Well, on the one hand, they have managed to modify their environments.
They do what we call extended minds, right?
They create superstructures and the nests are the clear example.
And the nests can be extremely large compared with the single organisms.
In a termite nest, in some cases, you can have the very tiny, millimetric organisms,
whereas the nest, like for termites in some parts of Africa, can be three, four meters high, right?
So ten orders of magnitude larger.
How do you build that?
Of course, the termites don't know anything about that.
Again, they are blind.
They communicate in simple ways with chemistry.
So whatever creates the organization comes out from a collective phenomenon, from self-organization,
or what we're calling complexity, emerging phenomena.
Phenomena that we can describe that even scale, network architecture,
or in our brains, consciousness, memory.
And that cannot be reduced to the properties of the individual parts.
You can spend your whole life studying single termites.
You'll never understand how they build the nests, right?
The key is that the collective behavior, the fact that the interaction between, for example,
termites and the material they use creates amplification phenomena
that lead to self-organization, in particular, to order it patterns.
That picture there is a small part of the fungi factory that you have in termite nest, in some cases, right?
And the explanation of the mathematics comes from what's called tuning structures,
but it emerges from the interactions, right, in a liquid brain.
Another thing that is quite fascinating is ants can solve the problem of finding out the shortest distance.
How?
Imagine you have the ants, like in the movie, right, that are in the lab.
You put a food source somewhere, and here is the nest.
If some ant detects that there's food here, they deliver a chemical signal,
which other ants find out, reinforce, and eventually you create a signal that goes beyond the individuals, right?
And individuals in the signal interact in all linear ways,
and you make this trail of ants that exploit the source very quickly.
What happens if you put two?
Well, things can also be dependent on its scenario and its species,
but for example, if I have more food here than here, they split at the beginning.
But the source that is more abundant is reinforced.
What happens if you make an experiment like the following?
Imagine you have the nest, you have the resource, the food here, and you have a double bridge, right?
So there are two branches, and one is longer than the other.
Okay, individual ants are unable to know that if this is longer or shorter.
But since they leave a chemical trail, the longer part will lose,
because of course the chemical signal is dissipated, is evaporated, will lose more by evaporation,
and eventually everyone will go into the shorter chain, right?
So you need a collective phenomenon here to actually solve the problem of the shortest path, okay?
And let me go into the question.
Is an ant colony going to be as complex in terms of cognition as a brain?
I think the answer is no.
And the reason is you can represent ants in different ways.
And I want to remember you that the ants have brains, right?
They are not neurons, they are brains.
And brains can be half a million neurons, so it's not small.
But interestingly, when you make models of how the ants solve the shortest path problem,
how they build their nest, you can represent the ants in extremely simple ways, right?
Sometimes even in on and off systems.
And so you can use that, you can represent the ants in this way,
and instead of using the McCulloch-Pitts model where neurons exchange things in a fixed way,
you can actually make what we call a liquid brain.
Here, for me, each ant can be, for example, an active or an inactive neuron.
They move around, right?
And over time they interact exactly the same way that neuron networks,
except that now they are changing in time, they are moving.
And one of the beautiful examples that we have explored comes from a war by Deborah Gordon
and her colleagues, where actually they have these ants that live in the desert,
and you can see the ants doing special tasks, right?
They are exactly the same morphological identical, but they do different tasks.
They can forage, they can have nest maintenance, they patrol,
and you see that the same ants, over time, they might change tasks, right?
And also if you are a bad person and you take, for example, all the foragers, right,
and see what happens, what happens is the colony reorganizes,
so some ants that maybe were just making nest maintenance become foragers,
it reorganizes in such a way that it optimized the number of individuals that do each task.
But then if you represent that with a mathematical model, etc.,
what you realize is, remember the model I showed you with these ballies,
that were the memories, right?
Here you have also ballies, but in this landscape,
what is at the bottom is the number of ants that are involved in each task,
which is something that is much, much, much less rich, right?
You are not exploring a hyper-dimensional space of connections,
because the connections are destroyed all the time.
You generate something that has to do with the average number of things needed
so that the colony works, which for us suggests that things like that depend on liquidity
may be very limited.
In the science fiction literature, right, or in the movies, for example, Star Trek,
I'm not a tricky person, right, but it's an interesting example.
They propose this idea, the Borgs.
The Borgs is kind of a race of cyborgs, each one with a big brain, right?
With a queen that has a big brain and controls some things, right?
But the thing is, right, why do we don't see, for example, what I call brainy ants?
We don't see ants with a large brain, right?
It's a possibility in the space of what we can imagine.
And we find out, although the theory has to be developed,
is that actually, if you look closely, you find some things that are extremely interesting.
For example, it seems to be a trend for colonies that in a nutshell, the pattern is,
you have a very small colony, individuals can be complex.
I saw them in Panama also.
I saw these groups of ants, colonies with 100 individuals only, very large ants.
Everybody warned us, don't touch them, right?
Because they are called 24 hours.
That's the time we'll suffer the pain.
So I believe that, one of my colleagues didn't, and, you know, the experimental method.
And it was interesting because you approached the colony and the ants were outside with big eyes,
and clearly they saw us.
And if you look at the individuals, they were more or less making their decisions
without much worrying about anything else.
But if you take very large colonies where the colony itself can do extremely complex things,
interestingly, individuals get more and more and more dumb, as if there was a trade of fear.
This has been called the complexity drain.
The complexity drain is something that we need to develop the theory of that.
Essentially, we'll say that the more complex the society, the less complex the individuals, right?
Don't try to apply that to our societies, okay?
Anyways, my second example.
My second example has to do with an extraordinary organism.
And I wanted to start with this.
This is a labyrinth that is in Barcelona in the orta quarter.
That is a replica of the famous labyrinth of Gnosis, the minotaur, right?
Labyrinths have been something that mathematicians and all kinds of people have been fascinated in.
How do you escape from a labyrinth?
Or is this the entrance?
And is this the exit?
How do you find the shortest path, for example, okay?
So Fissarum is able to do that.
Fissarum is not an animal, not a plant.
It's a slime mold.
It's a very simple creature.
And actually, some people describe it as a single cell.
It's a whole thing with many nuclei inside.
But essentially, it is a single cell, except that it's extremely large, right?
You can see it in the forest.
And actually, when it was found many years ago in the time of the Sputnik,
the people who found out that blob, which is yellowish as it is like this,
and it can be large as my hand,
found in the forest, they thought it was kind of an alien thing, right?
That came with a spacecraft, of course.
And Fissarum is amazing.
It shifts all the time, has these network structures,
it looks like a neural network,
and such is in space looking for resources, right?
And if part of Fissarum finds something that is very rich,
and here finds out it's not so rich, it deviates everything in this direction.
So you have all these tubes that pulsate over time.
It's quite a thing.
And that gets thicker and thicker as you approach something that is richer.
And somebody used that in a very clever way, right?
So since Fissarum is so easy to cultivate,
one thing I can do is take pieces of Fissarum,
put it within a library, an maze, right?
Like here.
And then I'm going to use what Fissarum likes a lot, which is flakes, right?
One at the entrance, A, one at the exit, B.
And then over time, what you see in the movie, is that Fissarum is detecting two sources, right?
It's totally distributed, there's no centralized mind, there's no neurons at all, okay?
And what happens is that it's an amplification phenomenon.
As you go over time, you see that close to entrance and exit, right?
The tubes that Fissarum forms, that is what they need to actually push forward
the detection and exploitation, right?
They have these nice waves.
Eventually, what happens is that you get in a single tube that goes all over the place
in the shortest path from the entrance to the exit, okay?
And if you want to model Fissarum, it's possible to do it.
You model with a network, a network of what?
Of tubes connected like a fluid, all right?
And interestingly, the mathematics that is behind is a threshold network, right?
Even in that case, you need to use one mathematics that might be universal.
Fissarum has been used in a number of applications, mazes.
You can actually find out a network of roads.
You take a country, for example, you put flakes in the locations of different cities.
Fissarum is distributed all over the place.
And then the tubes that reinforce the connections between different pairs of sources, right?
Eventually, draw this map, which you find out that is more optimal than the ones that engineers built.
And it's been also used to actually map dark matter, right?
Some astrophysicists find out the way of actually using Fissarum to make a large-scale model
of the universe and infer the distribution of dark matter.
But I want to make a point.
Very often, and you can make logic gates and many things, very often it's said,
look, Fissarum can solve complex mathematical models.
And it's a distortion a little bit of what really happens.
We exploit the properties of Fissarum, this extraordinary capacity of searching around.
And this special capacity that, and that's very important, is based in a way of computing things,
a computation that has nothing to do with the standard computation we use.
The computation is the form, the shape.
The final shape is what is being computed.
But of course, we, the humans, we put what in physics we say the boundary conditions or in mathematics, right?
We put in place things and Fissarum just goes on with its dynamics, right?
So Fissarum doesn't solve problems in nature.
Solve problems that have to do with resources, but not mathematics, okay?
What about plants, right?
I hope there are not so many enthusiasts here of plant intelligence.
I'm a skeptic.
In the literature also, we have this, I don't know if everyone knows, the day of the triphids.
It's a classic novel science fiction.
We have these plants that are capable of moving, right?
And that, well, I don't want to spoil anything.
Just read it. It's really cool.
So are plants intelligent?
Well, let me say first something.
These plants are extraordinary.
They have really transformed completely the planet.
When they invade land, they invented the sorts.
They created the forests.
They have this system of photosynthesis that creates quite an amazing super molecular system with quantum properties that we're still trying to understand.
So they are amazing by themselves, right?
Do we need them to like Mozart?
Maybe not. Maybe not.
Have in mind that plants, on the one hand, have this extraordinary capacity of changing morphology, of adapting in a way that animals cannot do.
They give them a lot of advantage.
The thing is, when you look at plants and plants in the context, right, like in a forest, of course, there's a lot of complexity that has to do with things that we know from ecology.
There's a lot of competition.
Mutualism plays a very, very important role in many ways.
And we start to uncover a lot of complexities there.
But is really this connected to cognition?
And I think it's important to go and look closely.
What do we have?
Plant cells, and there's a big constant with animal cells, are very rigid.
We have this wall that makes connections between them extremely constrained, right?
Connections, plus more of this matter, like this.
On the right in the upper picture is an electron microscope picture of a channel that connects to plant cells.
But the architecture constrains a lot what happens there.
Of course, there are no neurons.
It's been told that there are analogies, but no neurons.
And everything very much goes into two directions.
One is growth.
I have to grow and grow in a plastic way.
Another is defense, right?
Plants have developed a huge battery of chemical signals that connect them with the challenge that we have from insect herbivores in particular, right?
There's a lot of investment in that.
And it shows, it shows very much.
On the other hand, one thing I wanted to mention.
We will discuss that in the second lecture, but John von Neumann, the mathematician that I showed you before,
in his studies about brains, unfortunately it wasn't at the end of his life, of brains versus computers, he made this the following point.
At that time, the computers, these very big electronic computers, were very prone to fail.
Because the basic components were not much reliable, right?
And if a vacuum tube failed, the computer could fail.
And they knew that brains don't work like that.
Your neurons, every day you lose neurons.
And you can even have a big loss of neurons and the brains capable of have plasticity to return the system to the previous state, not computers.
And he ended up in a conclusion which was, maybe we need systems that are very redundant, right?
Very, very redundant. That's part of the solution, really.
But if you look at plants and compare with animals, what is the difference?
Well, many differences, right?
On the one hand, they stack in the same place, right?
So, if you think in the moving hypothesis, if I have to move, I need brains.
If I don't, maybe I don't need brains.
On the other hand, for example, you think in organs.
If I ask you how many organs you have, you are not going to say, well, I don't know exactly how you do it.
No, right? You do.
One heart, two kidneys, et cetera, et cetera.
And all of this is decided in embryogenesis.
In plants, we see a very different situation.
How many organs we have?
Many.
Every single leaf is an organ, right?
But they are formed and degrade and happen all the time.
And also, for example, at the level of leaves, we have discovered that
if you analyze the network of transport within leaves, which is a beautiful structure,
you can see that it's optimized for doing two things.
One, deliver the nutrients everywhere, right?
In the most efficient way.
Second, to protect themselves from damage, right?
An insect can make a hole.
You have seen, for sure, leaves that are damaged in different ways.
But you want to warranty that you get there.
The transport keeps going well.
If you have loops, the right amount of loops, you can do it.
And this is a picture of one of these damage experiments where using a kind of fluorescent marker,
you can see how it propagates and goes into the whole leaf again using the loops.
And it's optimized.
You can do a theory of that.
So you have many organs that can be lost.
They are essentially redundant.
So you don't really need to have a central control system.
In the second lecture, I'll try to convince you that this is probably the case, right?
That plants, because of they don't need that,
and they are extraordinarily well-adapted in different ways, right?
Might not have anything like brains or intelligence.
So, fissurum, plants, brains, ants, how do we put this together?
And the idea, still work in progress, right?
Is to create what we call a morphospace, a space of possibilities.
In this particular example that we used some years ago, I used three axes.
The vertical axis is how important is development.
Development is very important. Nature constructs things, right?
You have embryos that develop and get into complex architectures.
In the horizontal axis is the liquid to solid, right?
The state of matter that we have.
And the other axis is how complex is your cognition?
How complex are your decision-making and how diverse is the way you actually sense and respond to the environment?
We locate things here in relative positions, okay?
For example, organs are kind of simple cognitive systems, right?
They are the outcome of development.
They might be just responding to simple signals,
or they might involve feedbacks that are more complex.
This is the artificial part of the story.
Organs and organs have a counterpart in bioengineering, which is organoids, right?
Which opens on your possibilities that we will discuss in the second lecture.
Of course, brains.
And of course, you can see I put a single sphere here representing all solid neural networks, right?
This is an oversimplification.
The immune system, which is a system that can learn where cells can have memories,
where collectively you have phenomena that remind us a brain, right?
But they are liquid.
They move around, right?
We are living in a very interesting time now where it seems that because our understanding of these networks,
we might actually fight cancer and other things in a very effective way.
And of course, I put hands in the middle between liquid and solid.
High development because an uncolony actually, if you look at how it generates,
it comes from the queen, the first ex, the first individuals.
The structure that goes emerges in a totally predictable way
and ends up into something that is the structure plus the colony that is inside kind of a liquid system, right?
The microbiome, the millions and millions of bacteria that we carry out
that makes us something that is not anymore a single species.
The idea that we are one species, we have to abandon because we really are much more than that.
The microbiome, we'll talk about that also in the second lecture, has been co-evolving with us.
The more we know, the more clear it is that many diseases we couldn't understand but how they work
are connected with the microbiome and the great thing is that we can intervene, change the microbiome
and maybe fight those diseases, right?
And this microbiome interacts with the immune system and with the brain, right?
Which means that we have a lot of things at play.
Fissarum, somewhere also in the middle between liquid and solid, okay?
And this is kind of the big picture.
And I want to bring to your attention something that is quite visible is this big sphere that occupies a lot of space.
This big sphere is what we say is a void in the morpho space, meaning that when you look at the natural world,
you don't see anything there.
Why is that? Because it's forbidden.
Because evolution for some reason is unable to get there.
That's a big question.
For many of us, it's an indication that is a lot, is plenty of space to explore
and that if you are able to engineer things, we might go right there, right?
And I'll show you examples soon.
Okay, so now I just give you all these examples, but I'm sure that some of you are thinking,
yeah, yeah, but there's one particular example that you are not talking about, right?
Something that is quite bizarre, right?
Of course, yeah, octopus.
Octopus has been receiving a lot of attention over the last two decades.
Why? Well, on the one hand, it's an extraordinary example of how evolution creates in a totally different trajectory
in the Tree of Life, a mind that is remarkable, right?
Octopi, they can learn, they have memory.
You can see that they repeat the same words, right?
But they also have clearly curiosity.
There's been described many times that Octopi can be really interested and engaged into approaching humans, for example,
and trying to, I don't know, figure out what we're doing.
In the lab, it's been discovered that they recognize particular people
or sometimes that they can escape from the fish tank by night because there's a camera recording.
Go to another fish tank to visit someone, I guess, and get back.
Why do they get back? I mean, there's plenty of things that we don't understand.
And not surprisingly, it has been used often in the context of science fiction.
This comes from a snapshot from the movie The Arrival, right?
Where is the question of the language? We'll discuss it tomorrow.
Language is the big thing, right?
And you could say this is totally bizarre, right? Totally alien.
But, well, not that much.
The interesting thing I want to bring is if you analyze the brain of an octopus, right?
You're going to have the microscope, you make slices, see what's the architecture.
If you ask a histologist, what do you see here, right?
You might not have seen any time an octopus brain, but he will say,
okay, this is a brain, probably some vertebrate, because you see the neurons.
The neurons are these amazing structures that, you know, they have the polarity,
you have this special structure. When you look at the shape of a neuron,
why do you see? You see a cell that is trying to connect, right?
This is a big function. You see multilayers.
So interestingly, in a different universe of possibilities in invertebrates,
a totally different branch, you generate an animal that has the same kind of eyes we have,
that has a neural architecture that resembles things that we are very familiar with, okay?
Of course, they are peculiarities. They have the central brain,
and something that acts like eight autonomous brains, one for each tentacle, right?
But what this brings is that, again, it looks like maybe the space of possibilities is not that big,
even in that case where you have this amazing animal, right?
So why octopus are not more complex, right?
They are interesting. They are clearly interesting.
But, for example, why cephalopod in general have not gone into using tools, for example.
And it comes this interesting constraint that has to do with the life of these animals.
Very unfortunately, octopus don't live much.
In some species, one year, in some two years, maybe three, but that's all.
So thinking in the bioengineering, the possibilities in the future, you cannot avoid to think,
what if we were able to make an octopus to live more, right?
An animal that clearly learns over time has a brain that has this potential, right?
Could it be done? And that brings me into...
And I am trying to attract you to the second lecture, okay?
Of course, to answer the questions I'm making about how brains originated,
why brains will require to have a picture of evolution, what happened, really.
We don't have a time machine.
But we have an alternative, which is extremely interesting,
and I will show you, provides very new fundamental questions that I think in the future
might solve the questions that we have been making before.
And that will be all. Thank you.
Do we have time for questions?
Maybe I can try... Oh, there we go.
So we have time for some questions.
Excuse me.
I would like to just ask about the maze.
Can we go back to the maze and tell me how...
Oh, sorry.
I would like to know how that plant, or whatever it was, you're not to laugh at me,
got in and out of that maze.
How did something go into the maze and find its way out?
But you mean for the organism I was mentioning?
Yeah, there was Fissarum.
It was this single cell organism.
And in nature, you have, for example, imagine you put Fissarum in some place,
and you have different sources of food, right?
Fissarum is all the time expanding, like I'm searching around space.
And then this information about the different resources comes to the collective.
It's kind of integrating information all the time,
and making decisions about which one is richer,
and minimizing the trajectories.
You don't want to make a lot of channels and invest energy and resources to create tubes.
You want what is necessary.
So what happened in the maze is that you put these two resources in those particular places
that have sense for us.
We know this is the entrance, this is the exit.
Fissarum doesn't know anything.
But then the amplification that is made here creates these tubes that are very strong here, right?
And the same principle applies.
In the end, you try to exploit what is really rich, right?
And connect these sources in the shortest path you can make.
And that solves the maze.
But again, have in mind that we humans put the maze there, right?
We prepare the problem.
It's an important difference.
Thanks for a brilliant lecture.
Your drawings are like Leonardo da Vinci, really.
Thank you.
Fantastic.
This question is very stupid, but I've been asking it since I was six years old,
which is today, of course, it seems completely obvious to all of us that we think with our brains.
But I wonder whether early man knew that they think with their brains.
Because if you look at all the cave paintings we have, you have the hands, you have animals, you have human figures.
But you don't have heads necessarily as being more important than any other body feature.
So I just wonder if there's any history in the scientific research of when we began to realize that we think with our brain.
You mean as a rational teacher that we knew that it was a brain?
Or when the brain became relevant?
I think back to earliest human beings, the earliest development of communication, language, hunting, coordination, whatever it was.
Did they realize that this was what was working?
Okay, okay.
It's not a stupid question.
It always happens in all the talks when somebody brings it.
This is going to be a stupid question and it's not at all.
But tomorrow I'm going to bring a little bit about what part of the singularity of the human brain is there.
I will make a bit of spoilers here.
The human brain is interesting for a number of reasons and had a very important impact in evolution history.
Just to mention a few things.
One is language, of course.
Language is a pretty extraordinary piece.
In these days of chat GPT, chat GPT for a number of reasons is not intelligent, right?
But brings some interesting ideas about the importance of language in evolving reasoning, right?
One thing that I find extraordinary is very, very important and we also bring that tomorrow.
It's a time.
Somebody said that we are mental time travelers, right?
Meaning what?
You remember what we mentioned before.
We are prediction machines, right?
The brain is something that tries to predict what's going next.
This is very, very important because in the end what makes brains worth is that they are able to reduce uncertainty, right?
They make us more prepared to actually be understanding what's next, what's going to happen.
But we have this cortex that expanded so much, right?
And this kind of understanding of time became something that was the narrative, right?
We became able to make narratives, not only one feature.
We can imagine many possible features, right?
And it's very interesting to see how it happens in evolution.
Somebody said, you all know that memory is faulty, right?
Memory sometimes fails and sometimes you have even memories that are not real, right?
Memories that are being constructed.
And somebody can say, why is that?
Because natural selection doesn't care about that.
Natural selection wants you to predict the future.
The future is important.
If you remember well or not, the past is not so important.
And an important thing that connects maybe more with your question.
One of the things that made us successful, as ants are successful because they cooperate,
some days doesn't seem so, but we are cooperators, right?
And being a cooperative species made a big difference.
And one of the drivers of that was our amazing capacity of understanding the mind of the other, right?
Understanding that somebody that's looking at me is suffering or is scared
or is something that can create trouble, right?
I can put myself in the mind of the other.
And when you combine all this stuff, right?
We have a singularity, right?
Plus a lot of other things like mental diseases.
But it's a whole story.
I don't want to spoil because, as I was saying, one of the things I want to bring tomorrow is
when you try to approach the complexities of the human mind, right?
There's a kind of a synthetic or artificial path that can bring a lot of understanding.
At one point, you were talking about ants, I think, and their colonies,
and that the more complex the society, the less complex the individuals needed to be.
But we shouldn't apply that to humans.
What? Sorry.
But you said we shouldn't apply that to humans.
No.
I think.
Why?
Well, I mean, not every day I feel like the human race deserves good words.
But individual humans are spectacularly complex, right?
Provided that you're being immersed in the cultural thing.
Our brains are nothing unless you are in a society, right?
That goes from language to almost everything else.
But I think that, on the one hand, because of the evolutionary pressures that apply for ant colonies
that had to do with warranty that the colony works, and eventually that reproduces, right?
It's a different story for us in many ways, right?
I also try to bring that tomorrow and make a good comparison.
I must say that this trend we observed, but we still don't have a good theory for the complexity drain, right?
But definitely, I remember that Michael Lachman, which was a faculty also at Santa Fe Institute one day,
or discussing about this, the brain of humans, right?
And he brought me to something that is, in a way, is trivial, but it's interesting,
is that you isolate a human from society.
And the brain, this extraordinary potential machine is worthless, right?
You might survive, maybe, as some kids survive with wolves,
but all the potential of the brain is never going to develop, right?
So it's, again, says something about the fact that we are also cultural animals, and that makes a difference.
I understand the utilitarian and the intellectual reasons like that you do experiments on octopus, octopi,
but aren't there ethical considerations on how we do all these studies on sentient beings that aren't us?
Yeah, that's a very good point, and I'm sure you know that there's a hot topic these days.
The more we know about some species, the more clearly we need to have ethic criteria
of what is reasonable and what is not for the next experiments.
And even if we will say that, because we don't know, to what extent we can talk about the sentience and consciousness, etc.,
we still don't know, but the precursors of a complex mind, clearly we are seeing it in many species, right?
The elephants clearly mourn, I mean, they kind of feel the loss of others.
In the octopi, we see that kind of extraordinary curiosity.
What brings that there?
So this is on the table.
It's a hot discussion because one thing, as you can imagine, is that to make, if you want, decisions about what is ethically reasonable or not,
we first need to actually have good definitions of whether or not you have sentience.
Can this be measured in some way?
That's a good point and it's a relevant research problem now.
I have a question too.
Are you wondering about instinct?
Is that also part of the brain or is the instinct separate from the brain?
Which you have kind of not mentioned in your lecture so far?
I don't know if you understand. You say, insect brains?
The instinct, the instinct that living organisms have, I mean, is that part of the brain or is that something else?
You mean for, you say, insect?
Instinct.
Oh, instinct, sorry, sorry, sorry.
But you have to, I mean, I came here, you don't know that, but I came straight from Barcelona, 26 hours, and I was brought here.
My brain is not as good as it should.
Yeah, actually, that's a good point.
Instinct clearly is something that is part of the machinery, right?
In many cases, you see that working in a very almost algorithmic way, right?
This is a famous example of these wasps that kill, no, sorry, that use these things to actually put the eggs inside prey that are paralyzed, right?
Could be spiders, could be something else.
And they first make a hole, and then they hunt, they take, I don't know, could be larvae or whatever it is.
They go there, they leave the prey there, which is paralyzed.
They go inside, check out that everything is okay, go out, take the larvae, put it inside.
But then what happens is, if you, while this is happening, imagine that you are a mean entomologist and you are looking,
and then when it goes inside, you move the prey, which is paralyzed, right? Somewhere else.
So you see the wasps coming out, finding out that something has changed, they kind of managed to touch a little bit, they go inside again,
and if you can repeat that operation as much as you want.
It's like an algorithm which clearly goes from instinct, right?
But on the other hand, in insects, we also been finding in the last 20 years many unexpected things, like some wasps recognize the face of others.
There are asymmetries, apparently, in the brains of some ants, so it's plenty of still of things we need to know.
There was a question here, and another there.
You defined, you defined some really interesting questions that are very simple, like why brains, and what kinds of brains,
but I didn't hear you say what constitutes being a brain, like what's your definition of a brain?
So how do you define a brain?
I try to avoid that question, right?
I mean, in a simple way, a brain is a collective of neurons that centralizes the activity of an organism, right?
So for a hydra, for example, you have a net of neurons, or for a jellyfish, you have a ring and a distributed thing,
but you don't have really a core of neurons that are playing a role of kind of integrating information, right?
So that would be a kind of, I think, a potential definition, but it's disputed, right?
I think, for me, it's satisfactory.
When you were showing the example of the ants who managed to figure out the shortest route to the food,
or the termites who end up creating something that is of benefit to the society,
or the single-celled organisms that find the shortest route to the flakes in the maze,
it seems like more often than not, in these experiments you have similar sort of outcomes
that the ants are successful in doing this, the termites are successful in doing this,
and the single-celled organisms are successful in doing this.
But when you take humans acting like a liquid brain,
they often come out to solutions that are harmful to the organism as a whole,
especially in the area of finance, where if you have a lot of individuals here coming to conclusions,
they're more likely to come to this wrong conclusion, which ends up making a few people very rich
and other people very poor, and I'm puzzled by this.
Okay. Well, it's not an easy question, so it requires a long answer.
So close the doors.
No, I'm now seriously.
Yeah, when we go into humans, it's interesting to see two things.
One is what you mentioned, because humans, as you move beyond pure commission and you have society,
with all the biases that some can deal with in complete information,
plus the big problems we have about polarization and everything,
which is something that in complex systems we want to solve, but it looks like very, very difficult.
But on the other hand, it's just a small part of research, but it's interesting for the insight it brings.
When humans are under the situation of panic, you can make very well-defined models,
which essentially is like particles moving by forces and amplifying phenomena.
Things that we see and have consequences. For example, in a stadium, you have two exits,
and this has happened unfortunately a number of times.
It's panic. It's a panic attack. We don't reason there. We just want to survive.
And a typical trend is that the more people go into one exit, the more people go there,
which of course is harmful, because there's another exit.
You can model that, and it's interesting to see that you do the same experiment of panic with ants and with humans,
and that's one place where you can compare. Very unfortunately, we behave like ants.
If we move beyond that, and it's a legitimate question,
the question is under what conditions we can actually be described as systems like collective intelligence in ants,
and what is the threshold that separates from that and gets into society and all the conflicts that you're mentioning?
But this is a whole area of research. Good point.
One thing that we need to actually figure out is to what extent these ideas of collective intelligence apply to humans.
And if theory develops, whether we could actually explore the insight of the theory to actually help us to exploit common knowledge,
that clearly now is underexploited.
So maybe a third lecture on third theory?
On third theory, you have to be in Barcelona.
We have time for one more question.
Hi. I was interested in your chart where you have your three dimensions,
and you have this big sphere of the unknown or the unexplored.
I wanted to know, it was like, yes, that's the one.
So what we're missing is cognitively complex and developmentally complex as well, or maybe that doesn't matter.
But I'm wondering what you think that could look like.
You said that we might be able to manufacture it, something in that space.
I said what? Sorry.
I thought I caught you saying, sneakily, maybe that in this unexplored space,
maybe that's where we have space to manufacture some sort of brain-like thing.
I'm just wondering what you think is in that space that we're missing.
Okay. If you come to the second lecture, I think I have the answer for that.
I don't want to make more spoilers.
Thank you so much.
