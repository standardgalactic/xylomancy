I'm going to use a few terms throughout this video that not everyone might understand.
A plane is a mathematical term for a square or rectangle.
This is mostly the walls, ceiling and floor.
Vertices are the corners of said planes, the singular being vertex.
Polygons are another term for surfaces derived from computer science rather than maths.
It's going to be used interchangeably with plane.
To do something recursively means a process must repeat itself over and over until an
end goal is met to solve a problem.
A data type is a way data is classified in programming.
For example a string, which are words or a series of letters, and int, which is an integer,
a typical number.
There are different kinds of numbers as well, such as float for precise decimal numbers
and long for, well, long numbers.
Of the total size of the games industry today, around 20% are games within the shooter genre.
Around a fifth of games in this 300 billion dollar industry are shooters, most of them
being first person shooters.
The amount of money generated by and riding on the success of this singular genre in this
industry is stupefying.
The first person shooter as developed early on was a huge departure from every other kind
of game that existed at the time.
Games at the time, PC games especially, were often slow or methodical.
The personal computer platform was known for careful and considered games.
Turn based strategy, grand rpgs with a slowly unfolding world, often times these games would
be indistinguishable from a spreadsheet.
Action was the realm of console gaming.
Platformers were the most immediate real time action packed games available, and besides
notable games like Duke Nukem and Commander Keen, people didn't really play those kind
of action games on PC.
This was until the advent of the first person shooter.
Suddenly, people were hit with this visceral representation of violence.
They represented something which films could not.
You inhabit a world through the lens of the character.
You were closer to the action hero than ever before in any medium in history.
What is widely agreed upon as the first first person shooter ever, is Maze War.
Developed in 1973, that's the same year Britain joined the European Union, Dark Side of the
Moon was released, and the United States announced it would withdraw from Vietnam.
It was developed for NASA computers by Steve Colley, Greg Thompson and Howard Palmer.
It was constructed with simple wireframe graphics.
People had the idea of adding multiple players using networking, then connecting over the
ARPANET.
Then it took off.
We saw other first person shooter games after that point, Spasm or Space Sim in 1974, Battle
Zone for arcades in 1980.
Besides these few examples, for the majority of the decades following its inception, the
first person perspective was known mostly for its association with the role playing genre.
For example, games like Ultima.
Now, first person shooting did technically exist, but you were merely shooting projectiles
at your friends.
You weren't inhabiting a character.
You weren't the action hero fighting bad guys.
That was until Wolfenstein 3D.
Each software was founded in 1991 by four former soft disk employees, John and Adrian
Carmack, no relation, they just happened to have the same name, Tom Hall and John Romero.
This was the same year the Soviet Union fell.
Carmack is going to be more important later on.
They originally began with a Mario clone named Dangerous Dave before the company was officially
founded.
This was mainly to shelf the beginnings of John Carmack's technical wizardry, encoding
an efficient 2D side scrolling graphics renderer.
The early 90s, when everything was a dark and edgy statement, the satanic inversion
between PC and console was no exception.
PC graphics using software rendering were terrible.
John Carmack developed his adaptive tile refresh for the PC to compete with the raw computational
power of the Super Nintendo, a true beast.
Adapted tile refresh meant that slightly more of the game world could be included in the
screen buffer just outside of view.
This meant they could render smooth 2D scrolling.
It also made the sprite animations independent from screen scrolling.
This little bit of code magic powered their games, including the Commander Keen series.
The Commander Keen series was spread through Shareware with subsequent episodes releasing
over the next year or so for purchase from Apogee, their publisher.
This Shareware model would be important because it would be used in their subsequent games.
Speaking of subsequent games.
Wolfenstein 3D began development in 1991.
It would use the raycasting technique, earlier employed in Id's Catacomb 3D.
Raycasting was a rendering technique necessitated again by the limited processing power of
PCs at the time.
PC master race just can't stop losing.
PCs almost all used software rendering, rather than a dedicated graphics chip.
The Shareware model involved getting the game on as many PCs as possible.
Raycasting was the solution to help them do this.
Raycasting allowed their game to run on basically any PC.
Raycasting means you're able to draw only the surfaces which are in the player's field
of view.
This helped massively in saving processing power, but how does it work?
In effect, a ray is cast, from the player to the geometry, to the nearest object blocking
its path.
In Wolfenstein, none of the levels were truly 3D.
Every level was drawn out on a flat 2D plane.
The program scans horizontally, checking that every pixel on the horizontal axis has
something drawn in it.
If there's nothing drawn in a position, a pixel column will be drawn out.
This is simplified from the process of ray tracing, where this process is done for every
single pixel, rather than every pixel column.
The distance between the viewer, or the camera or player, they all have the same meaning,
and the nearest piece of geometry is obtained.
The height of the pixel column is calculated using the distance from point of intersection
in the direction the player is facing.
It uses trigonometry to find this point of intersection.
This effectively allowed them to give the illusion of distance to render a 3D scene.
This makes the process of rendering 3D much easier, as a line, that line being distance
from player to geometry, directly transforms to a line, that being the height of the rendered
column.
This process is done multiple times every single second.
The planes in the scene had been texture mapped, where an image is applied to a 3D surface.
When the columns are drawn, they are really drawing slices of these wall textures at different
sizes.
The height of the column being drawn is smaller when the plane, that being the wall, is further
away from you.
The textures are scaled appropriately to the size of the wall, relative to the player.
This gave the world of Wolfenstein so much believability for the time.
You were no longer just navigating wireframe mazes.
You were an action hero, BJ Blazkowicz, infiltrating a Nazi castle.
The walls were adorned with flags of the German Reich.
You felt closer to the world than ever before, you were interacting with a true 3D space.
This process was, however, flawed.
In Wolfenstein 3D, there was no verticality at all, no difference in elevation, only the
walls had texture, the ceiling and floor had to be flat colours.
If they wanted texture on the ceiling and floor, they would have had to add horizontal
scan lines.
You were still ultimately navigating a maze.
A colourful maze, with Nazis in it, but a maze nonetheless.
Wolfenstein 3D was released in May 1992.
The sequels Spear of Destiny was released later in the same year.
While the rest of the id team was working on Spear of Destiny, John Carmack, the ascetic,
high priest of technology, locked himself away to study.
He would brainstorm the revolutionary tech that would power their next massive game,
the next game that the rest of the team would start working on in September 1992.
It would be something inspired by Evil Dead, brutal and violent.
The name, green and pissed, was ultimately passed up for the much snappier, Doom.
Doom would launch in 1993, the game would truly be able to transport you into a world.
The levels truly felt like places.
The architecture of Doom consisted of supernatural science facilities, with Geiger-esque and
halish environments as well.
The enemies were a combination of horror and sci-fi with cybernetically enhanced demons.
The architecture, over the top setting and violence, was inspired by films such as Evil
Dead and Alien.
The floors could now be angled, they could now have multiple levels with stairs and elevators.
The pools of toxic fluid surrounded these risen platforms.
It was truly 3D, but it wasn't really.
They were yet to achieve the full 6 degrees of freedom that John Romero wanted.
This wouldn't happen until Quake.
Rooms couldn't be stacked on top of each other, there was no vertical aim, the game
was entirely played on the horizontal axis.
The thing is, vertical aim was actually possible at the time.
They could have limited the enemy's vertical hitboxes to the size of the sprite, but they
didn't.
They couldn't, but to save processing power.
You see, Doom was still using software rendering.
Its shareware model relied on getting their games on as many computers as possible, like
I said.
It was essentially the beginning of the free to play game model we have today.
They aimed for the IBM PC, for machines running DOS.
They had to sell their game to university students and wages who were bored at work
so they could run off as tournaments.
They didn't calculate the enemy's vertical hitbox so that they could save memory.
They didn't want to give the enemy's hitboxes a height value, just have another factor to
calculate.
All the levels were drawn on a 2D plane, like Wolfenstein.
Just this time, the map creator is quite different.
The ground is divided into sectors, this will be very important later.
Each sector has two associated values, ceiling height and floor height, well it has several
associated values, but those are two important ones.
This is also why one room could not be placed above another and why every surface had to
be made out of a flat square or rectangle.
Another reason that vertical aim couldn't have worked is due to how the texture mapping
worked.
One game that did have vertical aim and levels on top of each other, before quake and not
that long after Doom, was Bungie's Marathon.
And look what happens when you look up and down in that game.
The textures start to distort, this is because the game, like Doom, uses affine texture mapping.
This, like many of the other methods, was done to save memory on the processor by taking
advantage of CPU caching.
Basically what happens is that texture coordinates are linearly interpolated, using screen space
distance between vertices, rather than the actual 3D in-engine distance between them.
The distance between points on a plane remains the same when you look up and down.
What this means is that perspective when looking up and down is not accounted for.
You know how pixels on a texture start to warp as you get closer?
What looks like a straight line from far away begins to turn inward as closer pixels get
larger while more distant pixels get smaller.
This doesn't happen in Doom, because accounting for perspective is taxing on 90s computers.
You know how the game only draws things in columns to save processing time?
They'd have had to do vertical scans as well as horizontal scans.
Several ports of Doom with newer rendering engines made for new hardware like GZDOOM
obviously don't have this limitation.
As such, they use more current texture mapping and don't have this issue.
But all of these concessions weren't enough.
John Carmack's coding brilliance met its most devious enemy yet, Stairs.
John Romero came out with a really way out and strange idea on his early incarnation
of E1M2.
Yes, he wanted to mix things up with the earth-shattering invention of Stairs.
You see, just raycasting alone wasn't enough to efficiently optimise the game.
Raycasting saves memory by only rendering things which are visible to the player.
However, surfaces on the inside of these stairs were visible to the existing algorithm, thus
they were drawn when they shouldn't have been.
You see, for 3D rendering to not waste performance, they need to draw as few surfaces as few planes
as possible.
This necessitates occlusion culling, or visible surface determination, or backface culling.
Basically, the renderer should only draw what is in the player's field of view.
They need to be absolutely no overdraw whatsoever.
Adding height as a variable, such as with Romero's stairs, requires a much more sophisticated
algorithm than was present in Wolfenstein and in Id's existing rendering engine.
There are many different rendering algorithms out there, it seems that we need to dip into
the hypothetical algorithms to start trawling the literature for some better algorithms.
Let's explore some of the options.
There's the painter's algorithm, named so because, like in a painting, the background
is rendered first, with detail laid on top.
Basically, the polygons are sorted by their distance from the viewer, and the more distant
polygons are rendered first, and the closest polygon is rendered last.
It is easily the most simple solution, it was developed in 1972, the year MASH started,
as an easy to implement solution for CAD.
It also has the worst possible case for space complexity, meaning it takes up as much memory
as an algorithm possibly could.
Every single surface in the field of view is drawn.
Obviously, this isn't a good fit.
It's more of an example from the early days of exactly what not to do.
There's also Warnock's algorithm, John Warnock was the founder of Adobe, and this
algorithm originated in his doctoral thesis in 1969, the year man landed on the moon,
and in the court of the Crimson King was released.
Essentially, it recursively subdivides the screen into four parts.
What this means is it splits the screen into four windows and splits each window into four
smaller windows.
It does this again and again until each window is trivial to render, meaning it has only
one or zero polygons present.
The algorithm also checks if multiple polygons are within one window.
If the closest polygon covers the whole window, then it is drawn.
This is more efficient than Painter's algorithm as it renders front to back, but it's still
not very well suited.
It will eventually keep subdividing to a ridiculous degree, to the point where a window is smaller
than a pixel.
Yet, this ain't a good fit for a game.
You could do a Zed buffer, for every pixel you want to draw, check if there's anything
in front of it.
Using a check on every single pixel?
Yeah, there's no chance in hell.
The final solution does kinda use a Zed buffer, but it doesn't do that check on every single
pixel.
It finds a much more efficient way to do it.
No.
In order to truly revolutionise not just gaming, but 3D graphics forever, our protagonist,
John Carmack, needs to go to a much more inspired source.
Something that hadn't actually been implemented before.
Something you just read in a white paper.
Just a concept.
Yes, how common is it in gaming to see people run into optimisation issues, and seek out
a white paper to solve their problem?
Cause nobody else had done it before.
Yes, that's Carmack for you.
We needed a renderer that would draw objects closest to the player to furthest away until
every pixel was written to.
That had no overdraw.
The solution was in a 1980 white paper.
That's the same year Genesis released the reclaimed album, Duke, where they really came
into their own.
This 1980 white paper by Bruce Nailot was given the humble title, On visible surface
generation by a priori tree structures.
It described a rendering model we know as binary space partitioning, or BSP for short.
This was the method that would change gaming for years.
This wasn't the first time binary space partitioning was alluded to.
A 1969 study by the Air Force of the Good Old US of A, alluded to the use of partitioning
3D scenes to solve the visible surface problem.
The study was conducted to determine the viability of 3D for flight simulation.
We can thank the armed forces of the United States for giving us doom.
They explored using a matrix to track which objects are occluded.
This of course wouldn't do so well as the size of the matrix would need to be the square
of the number of objects in a scene.
That wouldn't scale very well.
It wasn't until 1980 that binary space partitioning was properly realised in the white paper that
would reach John Carmack alongside its core tenet, the binary tree.
But what is binary space partitioning anyway?
Well, the name gives you a clue.
Is partitioning space in a 3D environment?
This is done using a BSP tree.
What is a BSP tree you may ask?
In computer science, a tree is a data structure used as a mathematical model for displaying
certain data types.
It's separated into nodes with parent nodes that have child nodes.
BSP uses binary trees.
Binary essentially meaning two.
A binary tree is a tree where there are two or less child nodes stemming from any given
parent.
From any node, there are never more than two child nodes.
This is as opposed to a non-binary tree, which is a tree that has dyed hair and a gender
studies degree.
The data stored in the nodes of the binary tree are the subsectors of the map.
Subsectors being smaller parts of those map sectors I spoke about earlier.
Remember, each map is designed on a flat 2D map editor, with each sector having associated
height values.
The genius is that the map is sliced up via binary space partitioning after the map is
built.
The hard work is done when the map is created, rather than by the processor at runtime while
the player is playing the game.
The map is already split, already partitioned when the player loads it, reducing processing
needed at runtime.
To create the binary tree, a root node is established, covering the whole map.
After this, the map is recursively subdivided along every plane, until only convex subsectors
are left.
Subsectors are carved into smaller subsectors.
The entire map is essentially cut in two along every single wall.
Every time the map is cut in half, the two halves are added as nodes at the bottom of
the tree.
By the end, you're left with a tree where each node at the bottom of the tree represents
a distinct subsector.
Remember, this tree is entirely conceptual, it doesn't actually exist.
So long as the planes don't move, vertical movement is accepted from this because vertical
movement is a separate value, the same BSP tree can be used.
Dooms BSP tree generation was done after levels were complete and would search for the best
possible tree, that being the one that generates the fewest binary tree nodes.
A binary search is performed to determine what sector the player is in.
A binary search is when an array of pre-sorted data is searched through by continually halving
said array.
A search through a binary tree is, by its nature, a binary search, because every time
you go down a node, you're removing half of the possibilities.
After the player's sector is determined using this binary search, the subsectors are then
sorted by their distance from the player, closest to furthest.
The tree is iterated through to determine which planes to draw.
The horizontal scan lines from ray casting are still used to track the parts of the screen
that have been drawn over.
This way they are able to render front to back and ensure that there is no overdraw.
When each node is passed over in the iteration, a few things are checked.
Has that area already been painted over?
If so, don't bother drawing it.
When a plane, polygon, or wall is drawn, it is akin to a curtain being drawn left to right.
To unveil an area, so to speak.
Whenever a curtain is seen by the player, it is unveiled, from closest to the furthest.
To be exact, it's the closest 256 walls that are displayed.
Remember how height of the pixel columns drawn on screen depended on distance from the player?
For Doom, this required determining the angle of both ends of every wall, relative to the
player's field of view.
In the early 90s, most processors didn't have dedicated floating point capability.
This is a float in programming, if you've ever heard of that, basically a data type
for very precise decimal numbers.
The Doom engine had to use binary angle measurements, which avoid floats, and used a lookup table
to determine the X coordinates.
A lookup table is essentially a cheat sheet.
Instead of the processor doing the maths itself, it just looks up the answer in this lookup
table.
They also use these angles for backface culling, with a simple and elegant piece of mathematics.
Backface culling basically means the renderer doesn't draw the inside of every polygon.
It only draws the part on the outside that you actually see.
The walls are rendered first as pixel columns, from front to back.
Then the ceilings and floors, using pixel rows.
The objects, such as barrels and enemies, are rendered from the furthest to the closest.
The ceilings and floors are determined using vizplane underscore T, or vizplanes.
Vizplanes were determined using height values within each sector.
Vizplanes are not constrained to single sectors, and will be continuous provided they all possess
the same height, illumination, and textures.
Pixel rows are drawn, top to bottom.
One final thing you may wonder about Doom's graphics, is why are all the enemies just
pictures facing towards you?
Only something to do with them being what we call front facing sprites.
They're rendered last, and like I said, furthest to closest.
That's the opposite order to the geometry.
They are just pictures, taken from the data files and projected onto screen.
Of course, there are a range of pictures.
The one that is drawn depends on the player's location relative to the enemy, and the direction
the enemy is facing.
The enemies do actually have a full 3D hitbox.
The pictures, as most fans know, are actually from real pictures taken of sculptures made
by the artists.
So, John Carmack was faced with a fierce issue in the problem of visible surface determination.
He had to find a solution that was both incredibly fast and very accurate.
BSP doesn't completely solve the visible surface determination problem, but it is one
of the most reliable and efficient methods of optimization.
It saw massive acceptance.
BSPs were evolved and made their way into Quake's dramatically improved game engine
when they took on Michael A. Brash and finally figured out the full 6 degrees of freedom.
From there, it was in every FPS, and I mean all of them.
Half-Life and Half-Life 2, every source game, Counter-Strike to Left 4 Dead, the Halo series
used it.
You know the Scarab from Halo 2 is actually a BSP object?
Yes, it's a moving piece of level geometry.
Many would say it's a sign of Carmack's genius, that he took an idea from concept to
mainstream solution.
He did all this crazy work in between supercharging Ferraris and becoming a judo master.
You know, one time he got locked inside a building.
Instead of, say, waiting for security or calling a locksmith, he devised a brilliant solution.
He'd luckily gone to Renaissance Fair earlier, where he bought a medieval battle axe.
So, naturally, he smashed down the door with his mighty axe.
He was rich, so he could afford to get the door fixed.
He truly is a unique figure in the gaming industry, and you can see why he's so highly respected.
If you made it this far, comment, thank you, John Carmack.
The use of BSP trees has begun to be replaced over the last few years.
Developers instead opt for things like static meshes.
With more powerful hardware now, they could afford some level of overdraw.
Other methods give artists more creative freedom and a much quicker workflow.
BSP often leads to the distinct, blocky look that many old games had.
One could certainly argue that these technical limitations are what gave Source Maps and
early 2000s maps in general their distinct charm, their soul.
With stark and distinct architectural choices, some magic is truly lost in busy modern day
maps.
Many new games have actually tried to go back to recreating these older, cleaner, more distinct
visuals.
BSP is still occasionally used today in prototyping levels for games, quickly blocking them out.
It's of course still used in games such as Counter-Strike Go.
This was a big video, and naturally, it took a bit of research, which I've provided links
to in the description.
If I got anything wrong, please feel free, in fact feel obligated, to call me out in
the comments.
Like, join the Discord server, and subscribe with notifications on to join the Nerd Army
and become a Sigma Male.
Thanks for watching, goodbye.
If you saw anything in this video that was factually incorrect, please do not hesitate
to correct me in the comments to contact me.
As well as that, there were actually some tools that I was trying to get running to
visualize some of the graphics rendering.
This includes the Doom, Vism, and Headless Doom, for which I've included both of the
Githubs in the comments section.
I've also included every source I used in this video.
What was specifically helpful during this video was this article by Fabian Sunglad.
I definitely recommend checking it out.
If this interested you at all, please check out these sources for further reading.
Thank you, and goodbye.
