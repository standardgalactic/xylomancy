Welcome, everyone, to the Cartesian Cafe.
We're very lucky to have Scott Aronson here with us today.
Scott Aronson is a professor of computer science
at University of Texas at Austin and director
of its quantum information center.
Previously, he received his PhD at UC Berkeley
and was a faculty member at MIT in electrical engineering
and computer science from 2007 to 2016.
Scott has won numerous prizes for his research
on quantum computing and complexity theory,
including the Alan T. Waterman Award in 2012
and the ACM Prize in computing in 2020.
In addition to being a world-class scientist,
Scott is famous for his highly informative
and entertaining blog, Shtetl Optimized,
which has kept the scientific community up to date
on quantum hype for the past two decades.
Welcome, Scott. How are you doing today?
I'm doing all right.
Thanks so much, Tim. It's great to be here.
Yeah, great to have you here.
You're clearly one of the best guys to talk to
about quantum computing, but before we get into that,
I wanted to get to know you better as a writer and thinker
and dive a bit into your famous blog.
You have such a unique writing style.
It's some mixture of refreshing honesty,
self-deprecating humor, scientific profundity,
and it's really inspired so many people, including myself.
I just wanted to get your thoughts on blogging overall.
You're part of this small vanguard of scientists
who began blogging early on and continued to blog
people like John Baez, Peter White, Sabina Hossenfelder.
What's the journey been like?
Are there any highlights you'd like to share
and how has blogging shaped your scientific career?
Well, when I started my blog,
it felt like I was very late to the game, right?
So from like 2002 and three and four,
people kept telling me,
well, gosh, you should start a blog sky.
You seem to have a lot of strong opinions about things.
And I gave them all sorts of reasons
why that would be a terrible idea.
I could put my foot in my mouth,
I could say the wrong thing and could be blamed for it.
I'd have to, it would take up all this time.
Anyway, long story short,
all of those reasons turn out to be valid reasons.
So, you know, but I think in late 2005,
I just had as a little experiment,
I had guest posted on Lance Fortnell's blog previously,
since that had given me a little taste for it.
And so I started a little thing on blogger
and I wasn't sure if anyone was going to read it.
It might just be a few posts and then it would go away, right?
But, you know, for whatever reason,
it did attract an audience.
And then, you know, I think what happened was
that around 2007, you know,
you started seeing the beginnings of,
I would say, you know,
the sort of crazy misleading quantum computing hype,
you know, that is now, you know,
now there's, you know, 50 times as much of it, right?
But, you know, you saw the beginning of it there.
And it was weird because, you know,
like within the quantum computing, you know,
research community, like everyone knew
that, you know, that this stuff is not serious, right?
That, you know, these claims in the popular press
are, you know, are wildly exaggerated or, you know,
blah, blah, blah or just completely
misunderstanding basic concepts, right?
But then those things would just keep getting repeated, right?
And somehow there was no one who was just saying,
look, you know, just taking stuff
that is not controversial at all
within the academic community
and then just saying it for a broader audience, you know,
where suddenly it was controversial
because it was going against this narrative
that, you know, people were using to raise funds
and so forth.
And so then, you know, my blog kind of fell into that niche
just because of the lack of an alternative, you know,
just because it just seemed like, you know,
if it just became a place of last resort
for, you know, getting that message out.
And then what happened was that, you know,
like science journalists would start calling me, you know,
or, you know, would sort of use my blog
as their jumping off point.
And then, you know, not only about quantum computing,
but about, you know, whatever other science stories.
And so then that's how it kind of picked up
this momentum, I guess.
I don't blog as much now as I used to, you know,
I mean, for one thing, I have two kids now.
I have students and postdocs, you know,
so real life can be annoying, you know,
that way that it gets in the way of blogging, right?
And then, you know, also, you know,
I feel like in the 2000s, you know, it was just fun.
You could just, you know, explore ideas,
you could, you know, try to push the envelope,
you know, even, you know, be controversial,
like, you know, people would argue with you,
but, you know, no one really cared that much.
You know, also at that time, I was, you know,
I was a relatively unknown postdoc, right?
And now, like, if I say one thing that's wrong,
it's, you know, Scott Aronson,
director of the Quantum Information Center at UT Austin
has, you know, put his foot in his mouth
by saying such and such,
and that'll be all over Twitter and all over, right?
So, you know, it's like, you know, I don't want to, you know,
I don't think that I'm cowardly, you know,
and I, you know, I have taken all kinds
of controversial public fans on my blog, right?
But it's gonna, you know, I have to think very,
I have to think carefully about it, right?
But, you know, and am I willing to spend the time
to deal with all of the blowback that I would get
if I talked about, you know, this issue, right?
And, you know, maybe I should, you know,
just post things on Facebook, right?
Or it's, you know, a little bit lower stakes, right?
And so, you know, I do feel like the internet
has become more of a battle zone.
And, you know, and so, you know, I feel like
I still want to use my blog for outreach,
but it's somehow, it's harder to just play around
and have fun with ideas than it was years ago.
Now, as for its effect on my career,
I mean, that's hard to say.
I am very happy that, you know, I do have research papers
that, you know, where my blog kind of played
a major role in their origin, you know, I did a survey
about the busy beaver function a couple of years ago.
And, you know, I had to keep expanding that survey
because of new observations, new ideas
that came from readers of my blog, right?
So, you know, I mean, you know,
now that was kind of perfect for that
because it's kind of a, you know, a recreational math topic
where, you know, with a very low barrier to entry.
But, you know, also in quantum computing research, I mean,
you know, I have posted things on my blog, like, like,
you know, here is this quantum algorithm called, you know,
this QAOA.
This was maybe, I don't know, eight years ago or so, right?
Here, you know, this amazing claim
that gets a better approximation factor
for an NP complete problem, you know,
and then a bunch of classical computer scientists say,
like, no, we can beat that classically, right?
You know, and that's because they saw it on my blog, right?
So, you know, it's kind of been a clearinghouse
in connecting people to each other
or to, you know, results that they might want
to pay attention to, you know, and, yeah,
and it has had, you know, some impact on my research,
I guess, you know, not a decisive one.
You know, now, you know, it is hard to separate,
like, when I, you know, went on the job market,
the blog meant that, you know, people might have hated me,
but they knew who I was, right?
So, you know, I do, I am kind of, you know,
I do sometimes try to maintain some distance
between, you know, research and blogging,
like not hawking my, you know, my own papers
on my blog too much, because, you know,
I don't want to feel like I have an unfair advantage,
you know, over people who are not blogging, right?
Sometimes I'm just too excited about something
that I'm working on.
Wow, you're too kind.
I feel like in the, like, for example,
with machine learning, it's all about, you know,
drawing up the Twitter audience
and getting people to see your paper, right?
So, you know, I think you're too kind.
Yeah, I have still refused to get a Twitter account,
just because it, Twitter reminds me too much
of like the cafeteria of my high school, you know,
this was like the whole thing that I was, you know,
trying to get away from in life, right?
And, you know, I have lots of friends who are on Twitter,
you know, I read some of them, you know,
I mean, you can't ignore what, you know,
people are saying on Twitter all the time,
even if you might like to.
But I decided that the blog is enough for me.
And, you know, the blog, you know,
at least if people are angry at me, you know,
they have enough space to spell out their argument for why.
Well, I'm glad you're alive and well,
and so is your blog.
Thank you so much.
This year, something interesting happened too.
You're on sabbatical, I guess,
and you decided to work with OpenAI a bit.
Can you say a little bit about that?
Because I guess that's maybe a little unexpected,
at least when I saw that.
Well, how is that a continuation of the things
you're interested in and how does that,
yeah, fall into your interest?
Yeah, well, it actually, you know,
this actually did start from my blog.
Oh, how it shaped your career.
So, in my comment section,
someone was saying, well, you know,
Scott, like, how much money would it take
to get you to stop wasting your time
on all of this quantum computing theory?
And you're welcome, like, the one problem
that really matters for the future of civilization,
which is AI safety, right?
And...
Actually, on that front, aren't you,
this is where your self-deprecating humor comes in.
Did you say something like,
did you say something like,
I prove things that we can't do
using computers we haven't built?
Well, I study what we can't do
with computers that we don't have.
Exactly, which is hilarious.
I mean, of course, that is a lot of what I do
in quantum computing, but, you know,
I, you know, now, one thing that happened
since I started my blog in 2005 was that, you know,
a lot of the same people who would read my blog
were the people who were a part
of this rationality community
that formed around, you know,
Eliezer Yatkowski and Robin Hansen
and people like that, right?
Who also had blogs and, you know,
that were read by a lot of the same people.
And so I became very familiar early on with their ideas,
which were, you know, many of them involved, you know,
that, well, AI, you know, in the relatively near future,
just, you know, exceed human abilities, you know,
across just about every domain.
And, you know, this will, you know, by default,
if we don't do anything else,
this will be very, really terrible for humans.
And, you know, and we should maybe just drop everything else
that were, you know, even climate change and nuclear war,
these are all just kind of like minor worries
compared to this worry about AI becoming super intelligent
and taking over the world.
And, you know, and we should really think about, you know,
how to prevent that and how to make sure
that the AI is friendly.
And I, you know, so I was familiar with this
and I always kept it at arm's length, right?
Because, you know, I mean, you know,
part of it might have just been, it was sort of,
it was presented in this very kind of prophetic way, right?
Like, you know, it did not look at all
like academic research, right?
And, you know, it struck many, many people
as looking kind of like a cult, right?
You know, with like these sort of messianic prophecies
and these, you know, right?
And, you know, now, now rationally,
I could not say that I knew any reason
why this was impossible, right?
Like, yeah, you know, science fiction has been there
for, you know, generations before, right?
Asimov was writing about such things in the 1940s, right?
And of course, I, you know, read his stories as a kid
and was, you know, hugely influenced by them,
by, you know, his three laws of robotics and so forth.
And so, you know, I can't say that any of that is impossible.
But first of all, you know, I did study AI somewhat
when I was a grad student at Berkeley.
I spent a year doing machine learning
before I sort of fell in with the quantum crowd, you know,
which I sort of secretly, I guess,
I wanted to do quantum computing,
although it was the AI people who recruited me to Berkeley.
Yeah, and even in 2000, you know, I, 2001, you know,
I had a sense, yeah, that this machine learning thing
might turn out to be pretty important, right?
But it was just so hard to prove anything.
It still is.
Yeah, yeah, right, exactly.
And I just had more fun doing quantum computing.
And that was kind of the reason I got drawn there.
But, you know, then, you know, this was, you know,
this was all more than a decade
before the deep learning revolution, right?
And at the time, you know, you could look at the state of AI
and say, like, this is not actually, you know,
anywhere close to human abilities, you know,
in an interesting way, right?
This is, and who the hell knows
how long that could possibly take
until you get an AI that you would really want to describe
as understanding something, right?
And, you know, it could be hundreds of years
for all we know, right?
And so then, you know, you get to this position,
actually, my mentor, my first year in grad school
was named Andrew Whitton,
who is now a very famous, you know, machine learning person.
But one thing he's famous for is for this quote
that worrying about, you know, AI taking over the world
is kind of like worrying about overpopulation on Mars.
Yeah, it's just like, it's so far in the future
that, like, even if you decided to be worried about it,
it's like, great, well, what do you want to do about it?
Right?
Like, I didn't really see anything
that looked like a clear research vision, right?
But now, you know, starting around 2011, 2012, you know,
I think the thing that very, very few people predicted
was that just taking the same ideas
that had been around for decades, right?
Of, you know, bad propagation, neural nets, you know,
that hadn't worked that well before, right?
But if you just scale them up enough
and you just train them on enough data,
then they do work, right?
Like, usually you take a non-working idea
and you scale it up by 10,000,
it's still a non-working idea, right?
But in this case, no.
In this case, it started working
and it started, you know, handling a translation
and recognizing images.
And then within the last few years,
we have seen these absolutely astounding new artifacts
like GPT and Dali and, you know, and Lambda
and, you know, and the amazing things
that DeepMind has done, you know, AlphaZero, AlphaFold,
AlphaTensor, you know, that discovered
new matrix multiplication algorithms, right?
I mean, so we now have AIs that can, you know, make art.
I mean, you know, well enough that it's going
to sort of revolutionize the commercial art industry,
you know, they can write poems that like,
if I didn't know it came from the AI,
I would think it was just something
from the New Yorker or whatever, right?
And, you know, that all came about
because, you know, a few new ideas
like transformers and so forth, but mostly just scale, right?
And so we're, you know, and a lot of my colleagues,
I think, are still in denial about this.
They're still in the mode of like trying to invent reasons
why it doesn't really count
or it doesn't really matter, right?
And I think that it does really matter, you know,
regardless of whether you say it really understands
or it doesn't really understand.
Like we're now at the point where just the existing AI,
right, is already going to have massive effects
on civilization.
That just, you know, in fact, I'm astounded
that it's like, you know, the sort of, you know,
that the world has not woken up to this,
to the, you know, extent that it should have.
You know, it reminds me of like when I was an adolescent
in like 1992 or 1993, and I first saw this thing
called the World Wide Web, right?
Like why isn't everyone using this?
Why isn't this the biggest story in the world?
And within a year or two, it would be, right?
But, you know, when you use GPT,
like that is how I feel right now, right?
And so I had already been primed
that like this is a thing to think about.
And also this sort of suddenly changes the calculus
about, you know, the AI safety program, right?
Because now there are actual AI systems
that are going to be deployed in the world.
Or hopefully, you know, GPT or something like that
is not going to destroy the world, right?
But, you know, it's going to be used
by a hundred million students to, you know,
write their term papers, right?
Or at least they're gonna be tempted to use it for that,
right?
It's gonna be used for propaganda.
It's gonna be used for impersonating people, right?
It's gonna be misused in all kinds of ways
that, you know, we can try to think about
and we can think about how would we mitigate that?
Okay, and these questions seem continuous
with the eventual questions that you would face
about, you know, how do you deal with an AI
that is just smarter than humans are
across just about everything, right?
And so now there's like an actual research program
in AI safety where you can get feedback
from the external world,
but you can have something external to just, you know,
your pure thought that is telling you
when you've got it wrong, right?
And to me, that is kind of the crucial prerequisite
to making progress in just about, you know,
any area of science, right?
Like either you need experiments or you need math, right?
But, you know, you need something
to tell you when you are wrong, right?
And so then, so what happened was, you know,
that this person's commenter on my blog
was asking me when I work on AI safety
and I'm like, you know, well, you know,
it would just depend on whether I could find
a concrete problem to work on.
Like maybe I'd be open to it.
And so it turns out that open AI people read my blog.
And so then they got in touch with me
and they're like, are you serious about this?
And I'm like, oh shoot, now I have to figure out,
was I serious?
So I talked to them.
Somebody else put money where your mouth is.
Yeah, I guess so, yeah, no.
And they said, you know, you can stay in Austin,
where your family and your students are,
you can still run your research group
and we'll just, you know, sort of like buy you out
of, you know, so you don't have to teach for the year.
And, you know, and you can think about, you know,
we want you to think about what can complexity theory
contribute to AI safety?
And they gave me some examples of what they had in mind.
Actually, the whole safety group at open AI
was started or co-founded, I should say,
by a former student of mine from MIT,
you name Paul Cristiano.
Okay, and so Paul did a, you know,
worked with me, then did a PhD in quantum computing
at Berkeley from Umesh Vazharani,
who was also my advisor,
and then switched from quantum computing
fully into AI safety,
because he decided that that was just more important
to the world and so helped start the safety research
at open AI has since left
and now has his own AI safety organization.
Okay, but Paul had really convinced the AI safety world
that maybe like interactive proofs,
like, you know, like in theoretical computer science,
we know a lot about how a very, very weak verifier
can sort of force a very, very powerful prover
to do its bidding, right?
And like, ah, so that's exactly the kind of thing
that we need for, you know, for safe AI, right?
We need to know how to control these entities
that are actually much smarter than we are,
verify their behavior.
And so I said, okay, you know, it's not,
it's still not completely obvious what I'm going to do there,
but you know, I can see that there is going to be technical,
you know, there is going to be actual progress
that can now happen in this field
and maybe it would be exciting
to be in on the ground floor of that.
And so I'm spending a year
and I'm thinking about various things.
And I guess if we do a different conversation,
maybe at the end of the year,
you can ask me about AI safety
and tell you what thoughts I'm having about that.
Okay, well, thank you for that, Scott.
Let's actually talk about quantum computing.
All right then.
All right, and long last.
So let's see, I think this is obviously a very timely topic.
We did mention that a Nobel Prize was awarded
to several individuals this year
for their work in verifying Bell's inequality.
So quantum physics has been in the popular mind space
for a while now.
And of course, you have a lot of thought
and expertise on this.
And part of that is also sort of putting the hype
on the right footing.
Of course, you know, quantum computing is important
and worth setting, otherwise you wouldn't be doing it.
On the other hand, as you mentioned through your blog,
there's a lot of overhype
and you have, I guess, a moral obligation to fight that off.
And I thought what would be unique on our episode
is that because we have a whiteboard,
we can actually explain quantum computing in a way
that's more than what an audio-based podcast can do.
And also even more than what, say,
a typical blog post can do.
But also, you know, and kind of get the right perspectives
with the technical detail
so that we really can kind of get the idea across, right?
So I think one way to start out
is just giving a high level of what your take
on the field is.
And the way we're gonna start out is by looking at an excerpt
of this funny Saturday morning breakfast cereal cartoon
that you are a co-author of.
It's a long cartoon, you know,
maybe there's like 30 or 40 of these kind of images.
I just took the relevant ones.
It's called The Talk.
It's sort of obviously a play on a typical talk
that an adult would have with their child.
But this is The Talk to sort of get the story straight
about quantum computing, right?
Do you wanna say in your own words a little bit
about this cartoon and what you wanna convey
about how to understand quantum computing
at a high level?
Yeah, yeah, so I got to know Zach Weiner-Smith,
who's the author of SMBC Comics,
which is this, you know, fantastic nerd webcomic, right?
It's the one that's not XKCD, the other one, okay?
But, and actually like,
the, you know, Zach and I decided to do this comic
about quantum computing,
where like actually the mouseover text,
like if you click, you can see Zach saying,
now out nerd me now Randall, right?
Randall Monroe being the author of XKCD, right?
But so we, it's basically like a parent discovers their,
their mother discovers her son in his bedroom
with all of these trashy popular magazines
that are mis-explaining the basics of quantum computing,
right?
Saying that a, you know, a cube bit is just a bit
that is both zero and one at the same time.
You know, a quantum computer can solve a hard problem
by just trying all of the problems
that are being solved by quantum computing, right?
A computer can solve a hard problem
by just trying all of the possible answers at once
and then just magically picking the best one, right?
It can store, you know, two to the thousand bits
of information and only a thousand cube bits
and all this stuff that, you know,
that sounds like amazing, like, you know,
too good to be true almost, right?
And in a way it is too good to be true, right?
It's all trying to get at something true,
but just sort of skipping over, you know,
the like subtleties that are actually really,
really crucial to the story, right?
And to sort of why this story is sort of weirder
than any science fiction writer
would have had the imagination to invent, right?
And so then the mother just kind of has to explain,
like, look, you can't understand this without talking
about, you know, linear algebra a little bit, right?
And, you know, what is a qubit,
which is the basic building block of a quantum computer, right?
And so, you know, what every popular article wants to say
is that what classical bit has to be either zero or one,
but a qubit can be both zero and one at the same time, right?
It is, you know, just like Schrodinger's cat
to be both dead and alive, right, at once.
And, but, you know, now that the trouble is,
well, what does it mean?
Is there something to be zero and one at the same time?
Does it mean that the zero and the one are just like both,
you know, being maintained, like you can see them both?
Well, no, clearly it doesn't mean that
because when you look, you only see one of them, right?
As soon as you measure a qubit,
then you force it to make up its mind
about what it wants to be, right?
And then, you know, with some probability,
it will collapse to zero.
And with some probability, it will collapse to one, right?
And then, you know, and then that's all you see.
You don't see the other possibility.
So then as soon as people understand that,
then they say, oh, so then all a qubit is,
is it just some fancy way of saying that you don't know
whether the bit is zero or one, right?
It's one or the other, you just don't know which.
So you just say it's in superposition, right?
You know, it's just a pompous way to describe that.
And then, you know, you look,
and then you know which one it is,
and that's collapsing the superposition, right?
And really it's just one or the other, okay?
And then what you have to explain is that, no,
there is another ontological category that you've missed,
right?
It's not and, and it's not or either.
It is a complex linear combination, okay?
It is somehow a sum of the two, right?
Of the form like alpha zero plus beta one,
where here alpha and beta are going to be complex numbers.
Okay, so they're gonna be numbers that, you know,
like, you know, if you would ever thought
that complex numbers were just something
that mathematicians made up to, you know,
to be perverse or something in the 1500s.
Well, guess what?
We learned with quantum mechanics
that complex numbers are there at like,
at the deepest level of physical reality
that anyone has ever discovered.
I mean, I suggest maybe,
because I think we'll get to that
and write equations soon enough.
I thought maybe, I thought you,
I thought what you're gonna talk about actually was this,
trying all things in parallel kind of quip.
Oh, yeah, yeah.
Yeah, why don't we go over that?
And then, then once we get,
we'll go to the nitty-gritty teals
and start diving in qubits, yeah, yeah.
Yeah, yeah, yeah, no, no, I mean, I mean, so, so,
so yeah, no, I mean, I was getting there, right?
Okay, yeah.
But, you know, the issue is, you know,
if you, you know, what a superposition means is,
it's like, it's a vector of these amplitudes, right?
That's what we call these complex numbers, right?
You have to assign one of these amplitudes
to every possible configuration that you could see
when you looked at your qubits.
And now the key is, if you have, let's say a hundred qubits,
right, then you need two to the hundred power amplitudes,
okay, one for every possible hundred bit string.
If you have a thousand qubits,
then you need two to the thousand power amplitudes.
Okay, that's already more amplitudes
than you could write down in the entire observable universe,
right?
And, you know, so then, you know,
so then that, that, that is amazing, right?
That this is a staggering metaphysical claim about the world.
Okay, but it doesn't mean that you can literally see
these two to the thousand numbers, right?
You know, somehow these numbers are just going to be involved
in calculating the probabilities of the things
that you can see, right?
And when you look, you're just going to see
a single thousand bit string, okay?
But now the crucial point is that, you know,
these amplitudes are more than just probabilities, right?
So the amplitude is related to how likely it is
that you will see this particular string when you look, right?
The greater the amplitude, the greater the probability, okay?
But the amplitudes are not probabilities, right?
And we know that because they can be positive or negative,
you know, or even complex numbers,
whereas of course a probability is always from zero to one,
okay?
So, you know, what would it mean to have a negative 30% chance
of, you know, someone, you know, winning the,
winning in the midterm election or whatever it was, right?
That would be nonsense, okay?
But amplitudes can be these complex numbers.
And when we don't make a measurement,
then then these complex numbers evolve by rules
that are unfamiliar to everyday experience.
They evolve by some linear equation,
namely the Schrodinger equation, right?
And the key in quantum computation is always
that if something could happen one way
with let's say a positive amplitude
and another way with a negative amplitude,
then you can get two contributions
that is to say interfere destructively
and cancel each other out
so that the total amplitude is zero
and then that thing doesn't happen at all, right?
Whereas, and so with every quantum algorithm,
what you're trying to do is sort of choreograph a pattern
of interference so that for each wrong answer,
each answer you don't wanna see,
the different contributions to its amplitude
are canceling each other out.
They're sort of pointing every which way
in the complex plane.
Whereas for the right answer, for the answer,
you do wanna see the amplitudes,
the contributions to its amplitude
are reinforcing each other, right?
And this is the ability,
that this is the new ability
that quantum mechanics gives you, right?
So it's as if nature has just provided
this absolutely bizarre new hammer,
like one that no one asked for
or imagined would be possible, right?
And then the job of the quantum algorithm designer
is to figure out which nails can that hammer hit, okay?
Right, but the hammer is all about interference.
If you can't choreograph this pattern
of positive and negative amplitudes,
then a quantum computer is not going to help you
and you might as well just use a classical computer.
Okay, great.
Why don't we actually,
because you said a lot of things there
and I wanna unpack what you said in writing
because that's the benefit of our podcast.
So why don't, let me kind of write a brief outline
of what I think we can talk about.
Maybe share me your thoughts on that.
But I think the first thing we'll do
is just set up the setup in terms of what qubits are
and how that differs from classical bits, for example, right?
And then the second thing, just to really get concrete
because you said a lot of things there,
but I think what we really wanna do is dive deep
into a particular example to see how it works.
So the kind of one-on-one example
of how you get quantum computing magic, so to speak,
is this Deutsch-
Oh, you want the Deutsch-
Yeah, Yoshi algorithm.
I mean, I think it's the simplest one, right?
I mean, the other ones are a little bit more involved.
This was historically also the first one, right?
Yeah, and I think it already illustrates all,
essentially the essential concepts already in this example,
right?
So this is where we'll see kind of,
for lack of a better term, quantum magic, so to speak,
or where you start diverging from classical computation, right?
And I think from there, probably one thing we could mention
is sort of the complexity classes
because I think that's where things really,
I'd say this is where you can really disentangle
sort of the hype by saying this is what quantum computers
can or cannot do versus classic computers, right?
And then time permitting maybe a few remarks
about quantum supremacy because that's also
then sort of a landmark result.
And of course you have a lot to say about that.
So I think that, how does that look like as an outline?
Sure, looks fine to me.
Okay, great.
All right, so let's do it.
Shall we start with what is a qubit then?
Yeah, exactly, let's do that.
What's a qubit, Scott?
So like I just said, a qubit is a bit
that can be in a complex linear combination
of the zero state and the one state.
Okay, so now what do we mean by that, right?
Well, okay, so if we start with just a classical bit, right?
It can be either zero or one, okay?
And if I have n bits, then well,
now I have two to the n possibilities, right?
So I could say that I have a string x,
which is an element of the set zero comma one to the n,
like that, okay?
Now, the next thing we could have
is a probability distribution over strings, right?
So if I have a bit and I don't know
whether it's a zero or a one,
well, then I'm going to give it some probability
of being zero, right?
And some probability of being one,
these two probabilities, they should be real numbers.
So let's say,
they should be between zero and one
and they should add up to one, okay?
So,
so now I could say that my knowledge of the bit
is described by a two-dimensional vector, right?
Of real numbers adding up to one, okay?
And then the one other thing to say
is what would happen if something were done to the bit?
So for example, if without looking at this bit,
I apply a not gate to it, right?
Which flip zero and one,
or imagine that I flip the coin
and then without looking to see
whether it's heads or tails, I now flip it over, right?
What does that do to this vector?
Well, it just acts on it by some linear transformation, okay?
So, in this case, it's just a linear transformation,
zero, one, one, zero, okay?
So I can apply a linear transformation
that will change this factor.
Okay, well, why is it linear?
Well, intuitively because sort of it really is
in one of the states, right?
And whichever state it is in,
that should determine the probability distribution
over the next state that it could be in, right?
And it's merely that I don't know, you know,
which state it's in, right?
And if you think about it, then that kind of means
that the transformation of the vector of probability
should be linear, okay?
So now, you know, I guess the one other thing to say
is well, what happens if I've got multiple bits?
Okay, so for example, I could have two bits.
Let's say one of them is,
let's say a one with probability p
and zero with probability one minus p.
And my second bit will be one with probability q
and zero with probability one minus q, right?
So just to clarify, so are you kind of motivating
the transition from classical bits to quantum bits
right now or are you, okay, okay, yeah, okay, great.
Just wanted to clarify, okay.
Yeah, okay, yeah, yeah, so, okay, right.
So now what I can do is I can say, you know,
I now have a two bit state, okay?
And that state can be written
as what we would call a tensor product
of these two vectors of length two.
And I draw it like that, this, you know,
that's the tensor product symbol.
And now I get a vector of length four,
which has an entry for each possible two bit string.
So I could say both bits are zero
with probability one minus p times one minus q, right?
And then I get like a one minus p times q
for the probability that the first bit is zero
and the second bit is one.
And then I get a p times one minus q
for the probability that the first bit is one
and the second is zero.
And then p times q for both bits to be one.
Sure, maybe just one clarifying remark
just to keep this pedagogical.
You mentioned this tensor product.
Let me just say very quickly what it is.
So we have a tensor product, right?
And just to be concrete,
because we're gonna work with complex vector spaces.
But if I have the tensor product of say
two vector spaces, Cn and Cm,
then this will just be written as Cn tensor Cm.
And it's also a complex vector space
of dimension n times m.
So it's gonna be isomorphic to C to the n times m.
And you could sort of think of it
as sort of multiply the basis vectors, right?
So every basis vector-
That's what I did here.
Exactly, every basis vector of Cn
and every basis vector of Cm multiply or tensor
to give you a basis vector of C to the n times m.
And that's exactly what you did there.
You had, these are kind of the zero one
so-called computational basis.
And as you wrote here, there's zero zero, zero one,
one zero, one one, all the possible combinations.
Okay, just wanted to-
Yeah, yeah, thank you.
That is the much more professional way
to say little example, yes.
Okay, great.
Okay, so now I guess the one interesting thing
that we can observe here for the future
is that we could also have a probability distribution
over two bit strings where I do something like this.
I say with half probability, both of my bits are zero
and with half probability, both of my bits are one, okay?
And there is no chance that they are different, okay?
And now this is a distribution over two bit strings
which cannot be factorized as a tensor product, okay?
So there is no, you know, you can,
if you just think about it,
you see that there is no P and Q
for which this equation is satisfied.
Right.
Oh, yeah, actually, this is a good point to clarify
because the tensor product,
of CN and CM are all linear combinations, right?
Yes.
Of, let's say, U tensor V
where U is in the first vector space, V is in the second.
And what you're saying is that this state you wrote here
is not a simple tensor.
It's, in other words, it's not,
this cannot be equal to some fixed U and fixed V,
but rather it has to be a linear combination of them.
Yeah, yeah, exactly.
So, another way to say it is that what I've done
is I've just correlated the two bits.
Yeah, okay.
Actually, what's the correct name?
Is it simple or product?
I think product state, maybe, or what do you call it?
Well, I mean, I would just call this
a correlated probability distribution.
I see, okay.
I wasn't sure what the linear algebra term
off the top of my head is.
I guess we'll get up later.
Okay, or yeah, or I would just call it
a, a, a, a, a, a, a.
I think a product state, maybe, yeah.
It is a vector in the tensor product space
that is not itself a tensor product, right?
Okay, yeah.
I'll call it product state, yeah.
Yeah, this is right.
This state is not a product state.
And learning about one of the bits
can tell you something about the other.
Okay, if I looked at one of the bits
and I saw that it was one,
immediately I would know
that the other one is also one, right?
And it doesn't matter how far apart they are.
One could be on earth.
The other one could be on Mars, right?
And, and often people will talk about that
as the signature of quantum entanglement, okay?
It's not, okay?
Right?
So far we've said nothing about quantum mechanics, right?
This is a purely classical phenomenon that, you know,
if I, if you, you know,
you know, if you take a pair of matching socks,
this was John Bell's example, right?
And you put one on earth and the other one on Mars
and you look, and you then look at one
to see that it's red.
Then immediately you know that the other sock is also red.
Sure, sure.
No one calls that spooky action at a distance.
I wanted to make clear like all of the picture,
you know, all of the elements of the quantum picture
that, you know, sometimes people go on and on about
as special to quantum mechanics and none of them are, right?
These are all things that we can just see
and we just have seen as features
of classical probability theory, okay?
So now what is new with quantum mechanics, right?
What is the crucial change that we're going to make?
Okay, and that change is going to be
that we're going to upgrade the components of our vector
from probabilities to amplitudes.
Amplitudes can be complex numbers, okay?
So, right, so it was already implicit
in the fact that, yeah, it was already implicit
that these were complex vector spaces,
but I'll emphasize it, complex linear combination.
It's that complex linear combination
that's key to what you just said.
Yeah, yeah, that's right, that's right.
This is what's going to distinguish quantum mechanics
from just conventional probability theory, right?
From just saying that, you know,
the thing is in one state or the other
and you just don't know which, okay?
Right, okay.
Now imagine that I have a,
I again, want to have a vector with two components,
which, you know, I'll call alpha and beta, you know,
guess we'll use Greek letters
to make it a little bit fancier, right?
And so this is a complex vector.
Now, we could ask what should be the analog
of, you know, the probabilities adding up to one, right?
And we could say, well, maybe it's that
it should be a unit vector, right?
So, okay, but when I have complex numbers, you know,
the meaning of having a unit vector,
a vector of length one becomes a little bit different,
you know, from the Pythagorean theorem,
it's just that the sum of the square should be one,
or since these are complex numbers,
actually the squared absolute values, okay?
So this is what it means to have a unit vector
of complex numbers, okay?
That the sum of the squares of the absolute values
of the two components should be one, okay?
And in some sense, this is what we mean
by a qubit, we mean, you know, a unit vector in C squared.
Yeah, and just to make this clear, right?
C two, we think of as the span of the zero basis vector
and the one basis vector.
We haven't yet, you know, said anything about ket notation,
you know, actually for computer scientists
who are learning the subject, like,
that is like the single biggest hurdle for them.
Oh, really?
Okay.
Like, yeah, like, like, you know,
linear algebra they know, right?
But then, you know, this weird notation for vectors,
like, where does that come from?
Sure, do you want to say about,
or do you want to use ket notation?
Yeah, let me just say, yeah, sure, I'm happy to.
So what we do is we just give these nice little names
to the basis vectors, you know, of our vector space.
So like the zero vector, like, you know,
like the bit having the value zero, right?
We just, we write it like this.
The bit having the value one,
which is a vector that's orthogonal to that.
Okay, we write like this.
And these asymmetrical brackets,
these are, you know, these, these are what are called kets.
So it was a notation introduced by Paul Derock, okay,
in 1930 and that, you know, physicists still use to this day.
Okay, and the nice thing about it is that then, you know,
you have these very nice labels for your basis vectors
and then you can just write other vectors
as just linear combinations of those basis vectors
without having to write some gigantic number of zeros,
you know, to fill out your,
because we will be dealing with quite enormous vectors.
Right, so, so, so for example,
let's just, just think about the possible values of a qubit
where both of the amplitudes are real.
Sure, maybe just while we're on this ket thing,
it's a people who don't know,
ket is just a, it's the second syllable of bracket, right?
Because you deal with inner products
and sort of inner products involve two vectors
and the ket is sort of like half the bracket.
So just maybe just worth mentioning.
Yeah, sure, right.
And the other half is called the bra.
Exactly.
Which is, you know, these are actually kind of terrible names,
but-
I agree, but yeah, okay.
It's stuck.
Yeah, yeah, yeah, yeah.
So, so, so, so kets are column vectors
and the corresponding row vectors are called bra vectors.
Okay, so, so now, if, if, if I just say
that both amplitudes have to be real,
then my normalization equation simplifies to alpha squared
plus beta squared equals one.
This of course is just the equation of the unit circle.
I guess with some, I guess with the, with norms there, yeah.
Right?
No, no, I said, I said if they're real.
Oh, of reals.
I'm sorry.
Okay, yeah, okay.
Yeah, sorry.
What I just said, right?
Okay, okay.
In order to be able to draw this in two dimensions-
Sure, sure, okay.
It is convenient that they are real.
And then, and then, and then I just get a circle.
Okay, so now, what I say is that the horizontal direction
is, is the zero qubit.
The vertical direction is the one qubit,
but now I also have all of the other points on the circle.
So for example, I have this one here,
which is zero plus one over the square root of two.
Okay, an equal superposition of the zero and one state.
This is important enough that we give it its own name.
We call it the plus state.
Okay, just cat, cat plus.
And there's also another superposition of zero and one,
which is orthogonal to plus.
We'll be not surprisingly, we call it minus.
Okay, the minus state.
And what is this?
It is cat zero minus cat one
over the square root of two.
Okay.
And I could have any other possibility.
I could have a state here, which is mostly zero,
but with a little bit of one mixed in, right?
And now, you know, now the, you know, there are sort of two,
so these are what my states look like, right?
And okay, so now there were two, given these states,
there are two main things that I can do with them.
Okay, the first is that I can make a measurement.
So I can look at a qubit and ask it whether,
let's say it is zero or one, okay?
And the rule for what happens if I do that
is that the probability that I see the outcome one
is just equal to the squared absolute value
of the amplitude for the outcome one, okay?
And we could say,
if I have a vector of n amplitudes
and I now measure it in the standard basis,
so like to ask it, like, which one are you?
Are you one, two, three up to n?
Then it tells me that it is the ith one
with probability equal to the squared absolute value
of the ith amplitude, okay?
But in addition to that, the entire vector collapses
to just the ith basis vector, okay?
So basically, after nature decides
that it wants the answer to be i,
then it just, you know, it makes the vector i,
it sticks with it.
Let's pause there because this is really kind of also
one of the spooky things about quantum mechanics.
And in some sense, well,
I don't know a controversial to the right word,
but there are various interpretations
of quantum mechanics.
And this is, I guess, the default one, so to speak,
the one you learn in university courses at least.
Right, right, at this point,
I'm not making any statement about interpretation.
I'm just saying this is how quantum mechanics gets used.
Yeah, yeah, fair enough, fair enough, sorry.
Yeah, yeah, yeah, yeah, yeah.
So this is what's called the Copenhagen interpretation.
I am not committing myself
to the Copenhagen interpretation, right?
You know, regardless of whether there is something deeper
under lyingness, like this is how you use it.
Sorry, what I wanted to say, okay.
Okay, let me push back a little bit
because you did use the word collapse,
and that's sort of one of the key words
for the Copenhagen interpretation
as opposed to say many worlds or whatnot, right?
So that's a whole, I don't want to go down that rabbit hole,
but I just wanted to emphasize
that that's part of that package, I suppose, is that right?
I mean, Copenhagen would say that collapse is then
just a fundamental part of the picture
and is not to be explained by anything deeper, right?
You know, it is just, you know,
because all, or you shouldn't even ask for anything deeper
because, you know, all that you have the right
to ask for from physics is that it account
for your observations.
You know, the many worlders, the Evradians would say that,
no, you too have a quantum state, you know,
you are part of, in fact, the global quantum state
of the whole universe, and this whole process
of measurement and collapse is just to be explained
as a side effect of you becoming entangled
with the system that you are measuring, right?
So that is the difference between, you know,
the Copenhagenists and the many worlders.
They both, you know, if they're actually in the lab,
they're both going to completely agree
about doing exactly the thing that I just said.
Yeah, sure, sure, sure, okay, yeah, yeah, yeah, okay.
I think unfurling that will take us way aside.
Yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah.
I just wanted to.
No, I mean, we could spend the entire time
just talking about that debate, but.
Yeah, yeah, sure, but okay, but, okay, but, yeah.
The point is forget, forget the whatever metaphysics
that surrounds what's going on here.
The point is that you have, you have a vector,
there is a non-unitary operation after you measure it,
which is this collapse of the wave function
to sort of the, you know, now the direct distribution
on the measurement that you observed, but.
Okay, sure, yeah, yeah, yeah.
Okay, I know, I mean, I mean, yeah.
It's funny how you know, your clarifications
actually use much fancier words than I was using,
but that might actually be like for mathematicians
who are listening, like they might understand
the fancy words much better than the simple words.
Oh, I see, well, maybe, well, let's hope that our
different cells are constructively interfering
and not destructively so, okay.
Yeah, yeah, right, all right, all right, all right.
Okay, well, I guess let's just pick,
you or me to listen to what they watch, okay, great, all right.
Yeah, okay, okay, so if all I could do was measure,
then you might have just said, well, then,
then why do the complex phases even matter at all, right?
Like I might as well have just talked about
the squared absolute values of these amplitudes,
you know, the probabilities, in other words,
and just been done with them, right?
But now we kind of come to the key about quantum mechanics,
which is that I don't have to just measure in one basis,
right, I can do a change of basis, okay,
and to change, to sort of rotate our state, you know,
to sort of change its basis, okay,
I can apply, in principle, quantum mechanics says
that I can apply any linear transformation
that preserves the norm, okay,
that maps one unit vector to another unit vector, okay,
and such transformations are called unitary, okay?
So sort of all of the unitary transformations are,
you know, so the transformations with the property
that, you know, the norm of UV equals the norm of V
for all V, right?
These are the transformations that I am allowed to apply, okay?
So let's just look at some examples
for what are some unitary transformations
that can act on a single qubit, okay?
Well, you know, there's the identity, of course,
which just says do absolutely nothing to my qubit.
There is the logical not operation,
which we already saw, okay,
which says just map one to zero and map zero to one, okay?
But now, you know, there are some things
that have no classical analog, such as this one here,
which says flip the amplitude, flip the sign of the amplitude
if the qubit is one, okay?
But if it's zero, then do nothing, okay?
So this is called a phase operation.
I could even have some complex phases, like, you know,
I could say if the qubit is one,
then multiply the amplitude by I, okay?
And now I can also do things that will rotate
between the zero state and the one state.
So here is an example.
I could do one over the square root of two,
one minus one, one, one, okay?
What does this do?
If you think about it, this is actually a 45 degree
counterclockwise rotation in the plane, okay?
So what this is saying is that if my qubit is zero,
then I should map it to plus.
If it's plus, then I should map it to one, okay?
You know, and if it's one,
then I should map it to this thing here,
which is minus the minus state, okay?
And then if I do it yet again,
then I should map it to minus zero, okay?
Now one very curious feature of quantum mechanics
is that the global phase is irrelevant.
So if I multiply my entire quantum state vector
by a scalar, that has no effect.
So for example, the zero state and the minus zero state
are just two different notations
for exactly the same quantum state, right?
There's no physical difference between those two, okay?
So in some sense, I've gotten back to the zero state
just by rotating, okay?
But something interesting has happened here
because just by taking the zero state
and rotating it twice, I've gotten to the one state.
And so it's kind of like I've applied a square root
of the not gate, right?
And that's already something
with no classical analog, right?
There is no operation on a single classical bit
where if I apply it twice in succession,
then I get the not operation, right?
I would, yeah.
Yeah, there's a lot of, just to emphasize more
what you just said, right?
So it's the overall phase, as it matter,
but of course the key magic are relative phases, right?
So, you know, zero and minus zero,
there's no distinction, but one plus zero
and one minus zero, those are different, right?
Exactly, exactly, yes.
Yeah, and I guess you can already see it from the picture.
I mean, the magic behind the quantum world,
there's more room to move, right?
Because bits are just discrete things.
You could basically only permute things.
It's rigid, but in quantum physics,
you have a continuous space of transformations.
Yes, yes.
So, yeah, so it is sort of this beautiful way
of sort of enlarging this discrete space,
you know, zero, one to the n,
to this whole continuum, right?
All of the unit vectors.
And so now, just to emphasize the point,
okay, now the key to,
a key to quantum computation is going to be
that when I have multiple qubits, right?
Then how does this picture change?
Well, you know, a single qubit
was just a unit vector in C squared, okay?
If I have two qubits,
that's going to be a unit vector
in the tensor product space,
C squared times C squared,
which is isomorphic to C to the fourth, right?
And now if I had a thousand qubits,
then that's going to be a unit vector in C squared
tensored with itself a thousand times, okay?
Which is isomorphic to C to the two to the 1,000, okay?
So, already with a thousand qubits,
I now have a two to the 1,000 dimensional vector space, okay?
And we can understand that very, very concretely.
It's just saying that if I have a thousand qubits,
then my state, you know,
and often we use the Greek letter psi
to denote some arbitrary quantum state,
some, you know, arbitrary superposition state.
I now have to write it like this.
I have to write for every possible thousand-bit string X,
what is the amplitude for that X?
Okay?
So, you can see that just to specify the state
of a thousand qubits, right?
I may in general need two to the thousand complex numbers.
Yeah, let me interject here
because I think there's something very interesting.
Is this where the distinction between hardware
and classical storage of bits really makes a distinction?
Because for example, at a high level,
even something like the number pi, right?
If you want to store all the digits of pi, you couldn't do it.
It would exhaust any computer.
But yet, you know, I don't know,
to the extent that there's a physical object in the world
that is of length pi or whatever real number or whatever.
In other words, the things that exist out there
kind of can contain unbounded information
merely by them existing in some sense, right?
Well, you know, this becomes very tricky
because it depends what you mean.
Can you actually see the information when you look?
Like I could say that I could encode pi
in just a single coin by just, let's say,
making a coin that is heads with probability one over pi
and tails the rest of the time, right?
Okay, but then, you know, even supposing
that I knew how to do that, do it exactly,
which, you know, of course, in real life,
it's never going to be exact, right?
But even supposing I could do it exactly,
like it would be of limited use, you might say,
because then all I get to do is look at the coin,
see whether it's heads or tails,
and that might give me this extremely crude approximation
as to whether, you know, pi is likely
or to be large or small or something, right?
But I can't just look at the coin
in order to read off the digits.
Amplitudes are going to be subject to that same limitation.
I see.
That in some sense, they are there
in the physical description of the system.
You know, we need them there
because we need them to calculate the probabilities
of the things that we can see.
And yet we can never directly see the amplitudes, right?
The amplitudes are just, are only used
to calculate the probabilities
of the things that we can see.
And so even though the amplitudes form a continuum,
you know, we would not really say
that we can usefully store infinite information into them
because as soon as you look,
we don't see the amplitudes.
Yeah, yeah.
And I think this is where I was trying to get
because it's like, you know, you can make a,
whatever, a thousand qubits in the lab, right?
That's just a matter of being able to make a qubit
and making a thousand of them, right?
And that's what I meant
in the sense of like hardware versus storing information.
And how the qubits kind of contain all,
I guess contain is in quotes, I guess,
is the point you're trying to make,
contains all this information.
And somehow it's a little bit tricky
to kind of think about it in terms of storing it all
in a classical way, right?
Right, right.
But now, you know, even after we've sort of understood
that point about, you know, that you don't get
to see the amplitudes and, you know, you don't,
you know, if I stored the complete works of Shakespeare
or all the digits of Pi in the binary expansion
of some amplitude, I couldn't then read it out afterwards.
Right?
Even after you know all that,
like there's still something going on here
with this entangled state of a thousand qubits,
which is that even just to represent this state
approximately, right?
Forget about exactly now, okay?
Even just to approximate it to any reasonable precision,
you would already need something
like two to the thousand bits of information, right?
Yeah, assuming it's not infinitely many,
but exponentially more than you might have thought, right?
Assuming it's not a product state,
because if it were a product state,
then you would just...
That's right, that's right.
But in general, it doesn't have to be a product state, right?
So, okay, so maybe we should come back to this point, okay?
Because now, you know, how do you create
these kinds of programs, right?
I talked about unitary operations
that act on only one qubit, right?
But we are not restricted to only those, okay?
So like I could have two particles that, you know,
each one would store a qubit.
And let's say it's spin state or something like that, okay?
But these, you know, nature has interactions
between particles, right?
If I bring two particles close to one another,
then, you know, some unitary operation could act
that couples the two particles together, okay?
And so let me give an example of that, okay?
So now we're gonna talk,
we're talking about a unitary operation
that acts on C2s, tensor C2, right?
So it better be a four by four unitary, okay?
And we can have such unitaries,
which are not just tensor products of one qubit unitaries,
but which actually couple the two together.
So here is maybe the simplest example.
This, in quantum computing,
we call the controlled knot or the C knot operation, okay?
And if you think about it, what it is doing
is it's saying the string 00 should be mapped to itself.
You know, I mean, you know, I can think of what it's doing,
you know, it's just permuting the basis states, right?
It's a permutation matrix.
The string 01 should be mapped to itself,
but now the string 10 should be mapped to 11,
and 11 should be mapped to 10, okay?
So basically it's saying,
if the first bit is zero, then do nothing.
But if the first bit is one, then flip the second bit.
So in that way, it is coupling the two bits, right?
It's saying act on the second bit
in a way that depends on the value of the first bit.
Exactly, another way of writing it in a synced formula
would be x, y goes to x, and then y plus x.
Yes, excellent, yes, good.
So yeah, you know, in quantum computing,
we like to use this notation of quantum circuits.
Actually, David Deutch, who's the co-founder
of quantum computing, hates this term circuits
because, you know, they're not actually loops, right?
You know, they're not closed loops,
but they are, they're sort of, by a quantum circuit,
we mean a sort of list of what simple unitary units
you want to apply to your qubits in which order.
So when you draw them, they almost look like a musical score.
Yeah, but you know, we do have circuit boards that aren't loop.
I'm just wondering what sense of circuit is to be a loop.
I don't know, okay.
Yeah, yeah, yeah, yeah.
You could call them, you know, networks or something like that.
Okay, but we, well, I'm fine to call them circuits.
So what we do is we sort of list the qubits
from top to bottom, you know, with their initial states.
Like, so here I'm saying, I want two qubits
that both start in the zero state,
which is like the traditional initial state
for a qubit to have.
And then I can say, now I want to Hadamard the first qubit.
Okay, so I'm going to draw that like this.
So I should say, what is the Hadamard gate?
This is a very, very important one qubit gate,
which is just this two by two matrix here.
Okay, and the Hadamard gate has the very important property
that its square is the identity.
Okay, so it's a little bit like that 45 degree rotation
that I had before, except, you know,
the minus one is now in a different place.
Okay, so it's actually a rotation
composed with a reflection.
Okay, that's what the Hadamard is.
And you can think of Hadamard as just the gate
that switches you between two different orthogonal bases,
the zero and one basis and the plus and minus basis.
So like Hadamard of zero is plus
and Hadamard of one is minus.
And the reverse is also true.
Hadamard of plus is zero, Hadamard of minus is one.
Okay, so now you'll very often see Hadamard gate
on these quantum circuits.
So that would look like this.
And so now I've said my first qubit is now
in an equal superposition of the zero state
and the one state, right?
So it looks like this.
Right, because that's the plus state, yep.
Yeah, that's the plus state, right?
And now that is still in tensor product
with my second qubit, which remains in the state zero
because I haven't done anything to it yet, okay?
But now I can use a C naught to couple the two qubits.
So let me draw a C naught, okay?
C naught looks like that.
So we call the top qubit the control qubit
and the bottom one is the target qubit, right?
Okay, and now C naught, remember it says
if the first qubit is one, then flip the second qubit
and otherwise do nothing, okay?
So let's see what that does.
I had zero plus one over square root of two,
tensor with zero, okay?
Now that is just the same thing as zero zero
plus one zero over square root of two, right?
I can take the tensor and I can distribute it
among the zero and the limit, right?
Okay, and by the way, if I write something like zero zero,
all I mean, that's just a shorthand for zero, tensor zero.
Yes, yes, we've been using that shorthand implicitly
for a while now.
Yes, yeah, all right.
Okay, okay, but now I do a C naught.
Okay, now everything in quantum mechanics is, well,
other than with the possible exception of measurement, right?
All of the unitary transformations are linear.
Okay, since they're linear,
I can think about what they do
by just thinking of each basis state independently, right?
So what does a C naught do to this basis state zero zero?
Well, it just maps it to itself, to zero zero, okay?
But what does it do to one zero?
Well, now it's gonna flip the second bit.
It's gonna make that one one.
So when I do the C naught,
I get zero zero plus one one over square root of two,
and now I have an entangled state, okay?
So this shows how starting with two qubits
that were unentangled, both in the zero state,
I do a hat and a mart and then a C naught,
and then I can get an entangled state.
I can force the qubits to no longer have separate states.
Let me ask maybe a very naive question.
You could have also made this state
by just preparing zero zero, preparing one one,
and just adding them, I suppose, right?
Oh, you want to?
Yeah, but adding them is not a sort of physical thing
that I can physically do to my qubits.
Oh, I see.
The thing that I can do in the mathematical description
of my space of states, right?
I see.
But then there would still be the question,
what do I physically do to my qubits
that are in my magnetic trap,
or in my dilution refrigerator or whatever,
in order to get that linear combination?
I see, I see.
So I guess the whole point is that circuits are implementable
and circuits are a sequence of unitaries.
Is that the point?
Exactly, yes, that's right.
So a circuit is kind of telling me,
what do I physically have to do to my qubits
and in what order in order to get the unitary transformation
that I want?
Yeah, I mean, not being in the know.
It's not, I say, actually what you said is appalling to me
because as a mathematician,
adding two vectors is the most trivial thing you can do.
You say it's physically difficult.
On the other hand, it sounds like what you're saying
is that an arbitrary unitary is somehow physically
realizable, which is counterintuitive
because an arbitrary unitary
is like a complicated object, right?
Well, yeah, no, no.
So now everything is going to come down to a question of,
well, given a description of the unitary
that I might want on n qubits.
So the group of unitaries that act on n qubits
is going to be, I guess, u of two to the n, right?
So it's going to be, we're talking about two to the n
matrices, right?
Which take like four to the n real parameters to specify,
okay?
And so these can be immensely large objects, okay?
And now, a first question that you might ask
is just for any such unitary,
acting on some, let's say n is, I don't know, 100 or 1000.
I have some huge number of qubits.
Can any such unitary be decomposed into just unitaries
that act only on one or two qubits at a time, right?
And that are the identity on all of the other qubits.
So can I sort of take any n qubit unitary and realize it
by one of these musical scores by these quantum circuits?
Now, the answer turns out to be yes.
That is a theorem that one needs to prove, right?
It was proved in the early to mid-1990s.
Is there a name for the theorem?
I think it's just like universality
of various sets of quantum gates.
Okay, we just call this universality.
So what was proven was that various sets
of one and two qubit gates, you know, have the,
in fact, even if I just took, let's say,
the CNOT gate plus the set of all possible one qubit gates.
This already has this property of universality, okay?
Which means that by composing enough of those things,
I could get any unitary I want on any number of qubits.
And is there a bound on the length of that circuit?
Excellent, excellent.
Because now, right, because now, you know,
you might say, aren't we done?
Haven't we just solved quantum computing theory?
Well, the reason why we haven't is that in general,
the number of one and two qubit gates that you would need
is going to grow like four to the n power.
Okay.
So, you know, if n is 100, right?
This could already be astronomical, right?
If n is 1000, like more than the number
of subatomic particles in the known universe, okay?
So, and we can see that this has to be true, right?
And the way that we can see that it has to be true
is just by accounting.
Like we can say, how many parameters does it take
to specify an n qubit unitary, right?
If we need four to the n parameters,
even just to specify such an object, right?
And so then, you know, the, if I have, you know,
much fewer than that number of gates, then, you know,
just even if I vary those gates, however I like,
I will generate a manifold whose dimension is just too small
to encompass the full unitary group, right?
And so just by counting dimensions,
I can see that four to the n must be necessary.
Sure.
Okay.
Okay, but now this still, you know,
that was, that's kind of an abstract argument
and it doesn't, it tells me nothing
about how many gates would I need
to implement some specific unitary
that I might care about, right?
And so now we come to like the whole subject matter
of quantum algorithms and quantum complexity theory, right?
Which is all about, well, how many gates do you need
to do some particular unitary that will, you know,
produce some interesting behavior
that will help you solve some computational problem
that you would like to solve, right?
And so now what we always want
in quantum computing theory is we want
to apply unitaries where that I can compose using only a,
using a number of gates that is only polynomial
in the number of qubits, right?
So I want the complexity of my unitary to grow
only like the number of qubits raised to some fixed power.
What did you write here?
I couldn't tell.
I wrote n to the L of one power.
Okay, okay.
Or, you know, n to the C power, okay?
So given any n qubit unitary,
I can define the complexity of that unitary
to just be the minimum number of gates that you might need,
you know, in any circuit that produces that unitary, right?
And then what we've just said is that for most use,
C of U will grow like four to the N, okay?
Yeah, let's take a step back here
because this is kind of like a general question
about the complexity of algorithms
and distinction of building your own handcraft algorithm
from the get-go like Deutsch, Yosha and Grovers, et cetera,
right?
I just think that there are two different ways
of thinking about it.
I don't know, yeah.
Well, okay, no, I mean, you know, also, you know,
if you're, you know, building a concrete algorithm, right?
The first question that people will have for you is,
well, how many gates do you need to implement that algorithm?
Right?
The reason why Schor's algorithm was a breakthrough, right?
Was that, you know, it solves the problem
of factoring an N-digit number,
but, you know, the number of gates
that you need to do that is not exponential in N, okay?
Oh, sure.
It is only quadratic in N.
Yeah, I guess what I was trying to get at was,
I mean, maybe I wasn't clear enough.
In practice, do people come up with the unit,
some unitary and then try to look at the,
how minimal you can express it,
or did they come up with the clever circuit to begin with
and then the value that circuit was
in the fact that it was short to begin with?
You see what I'm saying?
Yeah, that's a fair question.
People do it both ways.
Oh, I see, okay, got it, got it.
Either way, I mean, in that,
we can talk about the case of Schor's factoring algorithm
since that's the most famous quantum algorithm of all, right?
You know, in that case, Schor first knew
that he wanted a certain unitary operation,
what we now call the QFT,
the quantum four-year transform, right?
He then said, now I have the technical problem.
How do I produce a small circuit?
Got it, okay, got it.
And he then was able to solve that problem.
Okay, that makes a lot of sense now.
Yeah, okay, okay, great, great, great.
Yeah, because I was thinking of Doge-Joseph,
it was like, okay, you just write the circuit, okay.
Well, yeah, right, so the issue is,
you said that Doge-Joseph had all the main ideas,
and the issue is there were several years
where people knew about Doge-Joseph,
and they were just not impressed, right?
Okay.
So Doge-Joseph was like the first quantum algorithm
that we ever saw that was not about
simulating quantum mechanics itself, right?
And it was able to get a clear speedup for something,
like for some classical task,
but the speedup was just not an impressive one.
So it was more theoretical than a practical interest.
Maybe there's just slightly, slightly more to say.
Because so the name of the game in quantum algorithms
is going to be that I have some problem that I wanna solve,
like find the prime factors of this number
or whatever it is.
And now in order to help me solve that problem,
I can initialize a whole bunch of qubits
into let's say the zero state,
then I can act on them via some network of,
or some circuit of a one and two qubit gates,
such as Hadamard and CNOT and various other gates.
Hadamard and CNOT by themselves actually will not be enough.
This is an interesting fact,
but I can have as soon as I throw in a few more
one qubit gates, then I can get a universal set
or at least an approximately universal set,
which is good enough in practice, okay?
And then at the very end, I have to measure my qubits.
So these little speedometers,
this is how we would denote the measurements
in a quantum circuit, okay?
And these sort of force the qubit to randomly collapse
to either zero or one,
and then we read out what's the outcome, okay?
According to that rule I said before,
that the probability of some outcome
equals the squared absolute value of its amplitude.
Right, and the key here is that measurement,
you can do it component-wise,
that's exactly what you're doing here, right?
Yeah, yeah, that's right.
I can also, I haven't really gone into this,
but I could also choose to measure some of the qubits
and not measure others.
Sure, that's right.
That turns out to like in a certain technical sense,
not be needed, right?
I could always, without loss of generality,
defer the measurements to the end, if I want to, okay?
But, you know, often in practice,
the way we think about quantum algorithms,
we will imagine measuring some qubits
even at intermediate stages, okay?
And certainly if I wanna ever correct my qubits,
then in practice, I will be measuring.
Yeah, actually maybe just to clarify,
when you measure, I guess,
because we had this discussion about
what's like physically realizable,
I guess are you always gonna measure
with respect to some relatively simple basis?
Because, which-
Yes, yes, good.
Right, so here I was just imagining
that I could just pick some individual qubit
and measure it in the basis zero comma one.
Right, right.
Okay, right?
And now, I don't like, if I just write this,
if I just draw this measurement symbol
and don't say anything else, then that is what it means.
Now, of course, if I had wanted to measure in the basis
plus and minus,
then I could have easily done that as well.
I mean, for one thing,
I could have just first applied the Hadamard gate
and then measured in the standard basis, right?
That'll have exactly the same effect
as measuring in the Hadamard basis.
Hey, I could also just invent a new symbol for it,
like measure in the Hadamard basis or something like that.
Okay, but I can't just write down some enormous unitary
on thousands of qubits and just plunk it into my circuit.
Like, oh, now I'm going to apply that.
Right.
Like the engineer is going to come back to me and say,
how do I actually realize that?
Right.
And by realize it,
they mean using simple operations
on only one or two qubits at a time.
Yeah, yeah, yeah.
I realized actually,
this is actually now obvious in hindsight,
because with all these things,
just like a unitary can act on the bra or the cat,
of course you can't have an arbitrarily complicated bra vector
because you could just shove the unitary in there, right?
So it's sort of like, yeah, I mean,
that's basically the point, yeah.
So your bra had better be a simple vector as well.
Otherwise you could just smuggle your unitary into there.
Yes, yes, yes, right, right.
So we kind of have,
we have rules against smuggling complexity
into your definitions, right?
Because then ultimately,
when you have to build the actual device,
then you will have to implement all the complexity
one way or the other, right?
Right, right.
So good.
Okay, so now what I've just told you about
is called the quantum circuit model, right?
And this is kind of a fundamental way
that we tend to think about quantum computation.
We think of a quantum algorithm,
in some sense is a quantum circuit, right?
That's right.
Or a little bit more precisely than that,
it is just a classical algorithm.
So just some piece of code
that can run on your ordinary classical computer,
but which will then output
a description of a quantum circuit, okay?
So if you actually walk into a quantum computing lab,
what you will see is usually some grad students
sitting at computers that are running windows
or Linux or something that are quite ordinary computers, right?
But they are hooked up to microcontrollers
that then have wires going into a dilution refrigerator
or lasers that can control the ions in a trap
or something like that.
So the classical computer is sending instructions
to sort of tell these devices
which gates to apply to the qubits.
Sure.
Maybe the way to say it is the circuit
is basically a classical API.
And then there's some backend
that translates that into a quantum implementation
because what you don't wanna do,
and this is the whole point,
what you don't wanna do
is write out the full unitary as a classical matrix, right?
That's right.
That's right.
And we also don't wanna play any tricks where we say,
well, even just to the quantum circuit
that I have in mind is a quantum circuit
whose very description encodes the solution
to the halting problem or something like that, right?
And then you say, okay, great.
Well, now, again, the engineer says,
how do I write down that circuit, right?
So what you have to do is you have to give them
a classical computer program,
they can run on the classical computer
and that will generate the quantum circuit
that will sort of generate the instructions
to send out to the qubits to say,
which simple unitaries do you apply to which qubits when?
And ultimately, that is what we mean by a quantum algorithm.
So I think because the halting problem, of course,
is famously not a subtle problem on a classical machine,
but what was this remark you make?
Could something about quantum computers,
are they able to do something special in this regard?
No, they're not.
And I just said the definition of what we mean
by a quantum algorithm is not allowed to smuggle things in.
Oh, I see what you're saying.
Okay, yeah.
Okay, okay, got it, got it, okay, yeah, yeah, yeah.
Right, so this is why we say,
you need an ordinary computer program
that can output descriptions of the quantum circuits,
given the input, given how many qubits you wanna be
operating on and so forth.
Yeah, in other words,
a quantum computer is still a Turing machine in some sense
in that you can't have these oracles
that just do magic things for you.
Yeah, exactly, exactly.
Now, I should say this was not the original way
that people thought about quantum computation.
Like David Deutsch in the 80s,
and then Bernstein and Vasarani in 1993,
when they tried to write down theoretical foundations
of quantum computing, like their first idea was that
you have to take the whole notion of a Turing machine
and make it quantum.
Ah, I see.
So you have to have a quantum tape,
you have to have a quantum tape head
that can be going a superposition of moving left
and moving right, and that can be entangled
with the contents of the tape and on and on.
Now, that turns out to be doable,
but tremendously complicated and nasty
to work out the details of.
And what people realized shortly afterward
was that the version that I told you
where you just have a classical computer
that is controlling a quantum circuit,
that is mathematically equivalent.
Oh, wow.
And it's a hundred times simpler to think about.
Yes, well, that's a great result.
Is that, is that?
Yeah, it is.
Are there some names associated to that?
Andy Yal, who actually won the Turing Award.
No, not for this specifically,
but this was a paper of his in 1993.
Okay.
And yeah, so people realized that there is this equivalence
between the sort of quantum Turing machine
and quantum circuit models.
And the circuit model actually,
not only is it simpler to think about,
it corresponds more directly
to what the experimentalists will actually do,
which is use a classical computer
for everything that you can use it for
and use the qubits only where they're actually going to help.
Yeah, I mean, I guess you could say this is one of the,
I don't know, rare triumphs of complexity theory,
where you actually know something's equal to something else.
No, I mean, we know many, many results
about things being equal to other things.
I mean, you know, we do, you know,
if that's the definition of a triumph,
then we have many, many triumphs of that kind.
Okay, okay, okay, although there's still a lot more to know.
Triumphs of the kind that look like P not equal to NP,
those are much rarer.
Okay, okay, okay.
Yeah, yeah.
Okay.
Great.
Okay, all right, so do it, Joseph.
Yeah, let's do it.
All right, all right, let's do it.
So, you know, having defined this whole model
of quantum circuits, right?
You know, unfortunately, you know,
when you get to a concrete problem,
we almost never know what is the smallest quantum circuit
for that, you know, for that, you know,
to solve the problem we want
or implement the unitary that we want.
The best we can say is, well, here's a circuit.
And oh, maybe here's a better circuit.
But as for what is the best circuit,
typically we've got no idea.
And this is deeply closely related
to some of the hardest open problems in all of computer
science or really math for that matter,
like the P versus NP problem and things like that.
We're just not very good at proving
that natural problems require exponentially many operations,
even when we strongly suspect that that's the case.
But now one thing that people realized very early on
is that there is one simplifying assumption
that you can make where you can start getting immensely
sharper answers about what is and isn't possible.
And this is already true with classical computation,
but it's even more true with quantum computation.
And so the thing that you do is that you switch attention
to a model that is called query complexity.
And it goes under other names.
It's also called the black box or the oracle model.
OK.
And so these all mean the same thing.
But what they mean is that we're going
to have some kind of subroutine that
computes some function, OK?
So like this, OK?
And the resource that we're going to care about
is how many calls to that subroutine do we have to make,
in order to learn some property of the function
that it's computed, right?
And the only way we get to learn about the function
is to call this subroutine, OK?
So we do not get to look inside of it.
We don't get to look at its code.
And that's why it's called black box, right?
It is like literally a black box, OK?
Now, often this does model how we think about algorithms, right?
Like you say, if you're trying to do optimization, right?
You're trying to find the minimum of some cost function, right?
And then often the way that you'll think about that
is just that, well, given any solution,
you can evaluate what is its cost.
And now you want to kind of move around in the space of solutions
to find a solution that has the lowest cost, right?
But as you do this, you're just going
to be treating the cost function itself as a black box.
You're not going to be looking inside of it, right?
And in that setting, very often we
can actually prove things about what
is the best possible algorithm that you could have, right?
Maybe the analogy would be like if you do gradient descent
and machine learning, right?
Like I don't need to know what the definition of the function is.
I just need to call dot grad, basically.
And that's it.
Yeah, that's right.
That's right.
So gradient descent, that would be an excellent example
of an algorithm that does use only black box access
to your function, right?
And so then if we can show that a problem is easy, even
in the black box setting, then voila,
we have a useful algorithm, right?
Whenever someone provides that black box, then we just combine it
with what we did and get our algorithm, right?
So now what does this black box model
look like in the world of quantum computing, right?
Well, now the new twist in quantum computing
is that since everything is quantum can be in superposition,
we also get to call our black box, our subroutine,
on a superposition of inputs, OK?
And get a superposition of outputs, OK?
So this is going to be the big new twist.
Yes, I have to say, I don't know if I'm jumping ahead of it,
but I know I've looked at Doge-Joshia several times,
and I find that to be the biggest, I don't know what
to write to call it, leap of boost.
There is a conceptual leap here, right?
And the truth is, if all you knew about was Doge-Josa,
like it is not at all obvious why there is any net gain.
Exactly, exactly, because it seems like you've actually done
a slight where you said, well, I'm
going to work in a world where my query complexity is larger,
because another way you could say, oh, here's an allowable query.
I'm just going to write a really large vector, evaluate F
on every component of that vector, and that's my new query.
So of course, you're going to be able to get away
with fewer queries, right?
OK, but again, remember, we're still
subject to the limitation that at the very end,
you have to make a measurement on your state
to get a classical output, right?
And if I just had an equal superposition over all
the different answers, let me show you what that looks like.
Yeah, sure, OK.
So let's say that I have n qubits.
So now I could easily create an equal superposition
over all possible n-bit strings, which will look like this, OK?
And I could get that by just taking my n qubits
and hat-amorting them all, like this, right?
So this is an easy thing to do.
And then I could even take a function,
and I could, let's say, a black box function
and evaluate it on the superposition.
And that could give me a state that would look like this,
sum over all x of ket x tensor ket f of x, OK?
So I can sort of evaluate my function
on all possible inputs in superposition, right?
And this is what makes the popular articles all excited,
right, that now sounds like I get this free exponential
parallelism, right?
But so far, I haven't yet done anything useful,
because if I now just measure this superposition,
not having done anything else in the standard basis,
then all I'm going to see is some pair x f of x for a random x.
Right.
Let's just let's call it x star or something like that.
There's just some x star, you just get one value.
Yeah, yeah, yeah, good, right.
And if that was all I wanted, then I
could have just flipped the coin a bunch of times.
Sure.
You took the bits of x, and I could
have saved all the billions of dollars
to build this quantum computer, right?
So the only hope of getting a speed up from a quantum computer
is going to be to do something else afterwards, right?
Which is going to have to be some unitary transformation
on this vector that is going to choreograph
a pattern of interference that's going
to cancel out all the different contributions to the answers
that I don't want, and it's going
to produce constructive interference on the answers
that I do want.
Yeah, maybe let's pause here.
Yeah, because I think the key conceptual hurdle for me
is that, OK, so as you said, there's
a difference between the unitary operator
and then getting useful information through measurement.
But I guess what I'm struggling to understand
is how would you build this unitary operator efficiently
in the first place?
Because naively, to build it classically,
you would have to build this matrix
where you're evaluating f at every entry.
But somehow, by not having to measure,
you avoid that computation.
So how do you?
Oh, yeah, OK, so that part I can explain, right?
OK, OK.
This I can explain.
OK, so what do we mean by a quantum black box?
So the most common definition would look like this.
Let me give it a name.
So let's say that I have some function f that I'm interested
in, then I could define a unitary transformation, which
I'll call use of f.
And what's it going to do?
All right, well, it should somehow take x and give me
f of x.
But now, the catch is it's still got to be unitary, right?
So I can't just take x and overwrite it with f of x, right?
If f is not a permutation, then that won't be unitary, right?
Even if it is, I still might not know how to apply that, right?
I might still have exactly the problem that you said, right?
I can't just take x and then write f of x next to it.
Because again, if I'm just saying take whatever was next to x
and replace it by f of x, then that's also not unitary,
because it would destroy information.
Whereas we know that every unitary transformation
is necessarily invertible, OK?
So the definition that turns out to work
is that I take f of x and I XOR it into an answer register,
which is next to x, OK?
So I sort of write it into that answer register,
where if A was all zeros, then I'm just writing f of x here.
But if the answer register were initialized to something else,
then I would just be overwriting.
I mean, I would just be XORing f of x into that.
Yeah, so C0 is just U of f, where f is the identity, correct?
C0 would be U sub f, where f is the identity, right?
Yeah, that's right, that's right, yeah, exactly, good.
Yeah, OK.
So yeah, so you do the C0 kind of thing,
but just generalize to any f, right?
And this will be unitary.
In fact, the square of this is just the identity, right?
Because XORing points gives me back what I started with.
That's right.
And now there's a further, very crucial fact, OK?
Which is that if I have an efficient program for f,
just in the ordinary classical sense,
I know how to compute f efficiently given x,
then I also get an efficient quantum circuit for U sub f, OK?
So whenever f is efficiently computable,
then so is this U sub f, OK?
This is another theorem that one can prove.
Yeah, what does this mean exactly?
So it's going back to the C0, right?
So like, obviously the identity map is very efficient to compute,
yet naively to compute U sub f,
you have to kind of run through every basis factor.
Right, but you don't.
You don't.
OK, so I'm saying that you don't.
Yeah, sure.
I'm saying that whenever I have an efficient algorithm for f,
so that's not going to be for every f, right?
Sure, sure.
But whenever f is something that is efficiently computable,
then U sub f is as well.
So maybe it would be instructive to go through why that is.
Yes, exactly.
So the first thing to say is that there are quantum gates
that can simulate like a universal set of classical gates,
like the and or and not gates, OK?
OK.
So and or and not are universal for classical computation, right?
Like any, when I say that f is efficiently computable,
I mean that it has a small circuit made of and or and not gates,
right?
OK.
And and, you know, which is which is sort of equivalent to,
you know, in the in this sort of non-uniform sense to there being
a polynomial time algorithm for f, right?
OK.
And and now there is this gate called the Toffoli gate.
OK.
Toffoli looks like this.
It's the controlled controlled not gate.
OK.
And and so it's just the generalization of the C not gate
to three qubits.
OK.
So it just says, like, if I have three qubits X, Y and Z,
then I want to flip the third qubit if and only if the first two
qubits are both one and otherwise do nothing.
Yep.
OK.
Yep.
So the key is that is that this this can now simulate an and gate,
right?
Because, like, if I initialize Z to zero, then what is going to be
written in the third qubit?
It's just the and X and Y, right?
It can also simulate a not gate, right?
Because, like, if I just wrote, if I if I put ones into X and Y,
then this is just going to map Z to not see, right?
Once I have and and not, then that's a universal set of classical logic
gates, right?
So I can now do any by chaining together enough topolies.
I can do any classical computation that I want, right?
So quantum computation can simulate classical computation, right?
You know, I've said this is kind of like you could use the space
shuttle to drive around the parking.
Right?
That's right.
It's that kind of, you know, theorem.
OK.
But now so now, you know, remember what we wanted.
We wanted to take X comma a and map it to X comma a exclusive or with f of
X, right?
So now our, you know, and we know that we can compute F by some let's say
by assumption, you know, we can compute F by some short sequence of
topoly gates, right?
And now are we done?
Well, not quite.
OK, there's one more detail that we have to worry about.
So the one thing that we, we, we, that we still have to worry about is that,
you know, after I, so I can take my input X and I can do some network of
topoly gates, which all, you know, just to draw it schematically, it'll look
like something like this and blah, this, this, this and so on.
I can do some network of topoly gates, which will give me, you know, X the
answer that I want F of X. So, you know, I maybe I initialize these qubits to
zero or something.
But then there could also be all kinds of scratch work, which is left over.
And the technical term for all of that stuff is garbage.
OK.
So, you know, we could have a lot of garbage bits left over in addition to
F of X. And so now I do not have the unitary that I want, because I've got
all this garbage still hanging around.
And in quantum computing, that's actually a huge problem.
Garbage can prevent the interference phenomena that you want from occurring,
right?
And in any case, it means that I have not achieved the definition from before.
OK.
But now fortunately, there's a trick to deal with it.
OK.
The trick is when you just have to clean up after yourself.
OK.
If you leave garbage, you just have to clean it up.
OK.
But how do you clean it up?
So now that the...
OK.
Is this a schematic?
It's not a product of X, garbage and F. Otherwise, you could just...
Well, it's a tensor problem.
Oh, I see.
I mean, I mean X.
No.
Oh, so sorry.
Oh, right, right, right, right.
So, so if X were a classical string, right?
I was assuming that X was just a classical basis state.
Then what we will end up with is a tensor product.
Oh, I see.
A tensor garbage, tensor FFX.
However, ultimately we want to be applying this to a superposition.
Got it.
Yep, yep, yep, yep.
And then the garbage is now entangled.
Yes.
Yes.
And with FFX.
And that's the problem.
Yep.
OK.
So that's why we need to get rid of it.
Yes.
OK.
OK.
So the key trick for doing this was actually invented by Charlie Bennett in
the 1980s and it's called uncomputing or computing in reverse.
OK.
And so what, so, so what you're going to do is you're going to take the final
answer, like let's say the final answer is here.
And after it's been, you know, FFX, after it's been computed, you're going to
see not it.
You're going to see not it into the answer register A.
And then you're going to run your entire computation in reverse.
OK.
So every gate that you applied, you're going to apply the inverse of that
gate.
OK.
And you're going to apply them in the reverse order as you applied them,
you know, going forward.
OK.
So like if you had this, you know, the top of the gate happens to be its
own inverse.
So, you know, so that would just look like this.
OK.
So the whole musical score reverses itself.
Suppose you have whatever you have this toughly gate.
Yes.
Right.
And so you have some other stuff, whatever.
So are you, is the reverse gate now the guy that's just the mirror reflection?
Is that what you're calling in reverse?
Yeah, yeah, yeah.
OK.
So if, if my, look, if my.
Yeah.
OK.
If my original sequence of gates was let's say G1 up to GK.
Yep.
Then my new sequence of gates is going to be GK inverse.
And then GK minus one inverse and so on.
And finally G1 inverse.
Oh yeah.
OK.
Yeah.
Yeah.
So it's just the, right.
Inverse of the, of the associated unitaries.
Yeah.
There's a literally the, it's literally the inverse.
Yeah.
Yeah.
Yeah.
OK.
Right.
Right.
I would have just done a very fancy implementation of the identity.
Yes.
Right.
But I was careful to write down, to copy the answer at the very, you know, in the,
in the middle.
Oh, that's brilliant.
Yeah.
Yeah.
And so now what I end up with is just my input X and then a X or with F of X.
Right.
Which is, which is what I wanted.
OK.
So, so that, that, that is the uncomputing trick.
Now, given any efficient algorithm for F,
I get an efficient quantum circuit for querying F on a superposition of inputs.
Okay.
So I get use of F.
Okay.
I think I, yeah.
I think I, I know enough to fill in the details, but let me just verbally state.
So, okay.
So basically if I, since F by hypothesis was simple to compute classically,
you, you stack the appropriate quantum gates to implement F.
Yeah.
And then you just kind of shove it into a C not gate in some sense so that you
can kind of, or so that you can kind of have this scratch bit that will record
F, right?
Yeah.
And then you do this reversing trick to erase all the intermediate stuff you
don't care about.
And boom, there you go.
That's right.
Yeah.
Yeah. Exactly.
Exactly.
Okay.
Okay.
All right.
And now to explain the Deutsch-Joseph algorithm.
Okay.
The one further detail that I need to say is that we can,
if F is just a zero or a one,
then I can actually have this behavior where I will take F and I will write it
into the amplitude of the basis state X.
Okay.
So I will multiply the amplitude of cat X by minus one to the F of X power.
Right.
And how do I do that?
So one way to do it, all I have to do,
I actually give this as a homework exercise and like, you know,
undergrad quantum computing course, but I'll, I'll, I'll give it as a freebie.
Okay.
So, so it turns out all you have to do is just do that use of F that I
explained before, but now have, you know,
initialize a the answer register to the plus state.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Okay.
Let me just say, so here is X. Okay.
And what you can show, you know, is that the answer register will always be left in
the plus state.
You know what?
Not the plus state, the minus state.
I'm sorry.
The minus state.
Oh yeah.
Of course.
Not going to work.
Minus state.
Okay.
So I initialize the, the answer register a to the minus state.
And the minus state has the property that, well,
if you apply a not gate to it, then it maps minus two minus.
Right.
The point, the special thing about the minus state is that whenever,
whenever there's a bit flip, there's a sign change.
That's exactly what, what minus one of the F is doing. Yeah. Yeah.
Yeah, exactly.
Yeah.
So, so, so it, so it does this and this is in practice, you know,
whenever F is a Boolean function,
this is often how we want to think about a query to F.
You know, as you're writing, writing the answer into the amplitude.
Okay.
You know, I, yeah.
So the thing is that the only quantum computing book that I've consulted
based on my, you know,
a non-experience with the subject has been Nielsen and Schwann.
I should look at your book, of course,
but I've only looked at Nielsen and Schwann and they don't go into it.
All, all this backfill would have been so helpful for me because.
All right.
All right.
All right.
There are plenty of books that explain this.
You could also look at my, my undergrad lecture notes.
You know,
actually is actually even more so than quantum computing since
Democratist because that was kind of, you know,
that those,
that my Democratist book was based on lectures that I had given for
students who already knew all this stuff.
Oh, I see. Okay. Okay.
Explain some, you know, something more philosophical to them,
but my, my undergrad lecture notes that are on my homepage, I do,
I do carefully explain all of this.
Great. Great.
Okay.
All right.
So now, you know, knowing that we can make those phase queries,
right,
and that it only costs the same as a normal query. Okay.
Now what is the Deutsch-Joseph algorithm? Right.
Well,
so now what we're going to imagine is that F is just a function
mapping one bit of input to one bit of output.
Like that.
Okay.
So, you know,
there are only four possible such functions, right?
There's the constant zero function, the constant one function,
the identity function and the not function. Right.
Okay.
And now what do we want to know?
We want to know the parity of F of zero and F of one.
Okay.
So this is what we want.
Okay.
And now we can ask how many queries to F are necessary and sufficient to
get this information, you know,
the XOR of the two different F values, right?
And like, you know, if I ask this classically, like this is a,
this was a completely trivial question, right?
The answer is two queries, right?
You know, I can, I have a choice, I guess, of which one to learn first,
right?
But whichever one I learn, I still got to learn the other one, right?
Or else I don't know their parity, right?
So we could say the classical query complexity of this problem equals
two.
Okay.
And now what we want to prove is the remarkable result that the quantum
query complexity of this problem is only one.
Okay.
So it is half of the classical query complexity. Okay.
So this is, this is the, you know, this was historically the first example
of a quantum speedup in query complexity.
As I said, not very impressive.
It is merely by a factor of two, which normally in theoretical computer
science, like we, we, you know, we, we don't even bother to count.
Yeah, I think, I think historically this was the first case that
Deutsch worked out by himself, right?
So this was actually, actually,
which is didn't even do this because it only worked with half probability.
Okay.
Okay.
Okay.
So this is still a special case.
No. And then, and then, and then Deutch and, I think Deutch and Joe is that kind
of corrected it later to, I see.
I've been saying, if I've been saying his name, I've said, yeah,
Yosha, but is it Joe?
Is it J?
Oh, I see.
I wish you corrected me earlier.
I just thought that some of the, yeah,
then there is a generalization of it to end this, but yeah, that,
that to me is not.
You know, it's, it's again going to be a constant separation if we do a fair
comparison between the quantum algorithm and a classical probabilistic
algorithm.
So it's, you know, so, so, so we might as well just do the case with one bit.
I see.
Yeah, yeah, yeah.
Of course, let's just keep it simple. Yeah, yeah, yeah.
Okay.
Yeah, even simpler, right?
Yeah.
Okay.
So now how are we going to learn?
So now this is the question.
How are we going to learn the XOR of two bits using only one query?
Right.
Well, clearly, we can't just query the bits one at a time.
Right.
We're going to have to query them in superposition.
Okay.
What I'm going to do.
Well, I can just write this.
I can just write it in circuit notation and then we can talk through it.
Okay.
So I'm going to start with a qubit in the state zero.
I'm going to had a more that qubit, which puts it into the plus date.
The equal superposition of zero and one.
Okay.
And then I'm going to query.
F.
So I'm going to apply that use of F.
And, you know, you can see that I've taken the answer qubit and I've
initialized it to the minus state in order to get that phase query
behavior.
Right.
And then there's just going to be one more had a more gate.
And then there's going to be a measurement.
Okay.
This is the entire do it shows algorithm.
Okay.
Now we just have to explain what it's doing.
Okay.
So.
All right.
So, so as I said, the, the, the zero qubit is going to be mapped by the
Hadamard.
To.
The plus state.
Which is also called zero plus one over the square root of two.
Okay.
Now.
We're going to apply this use of F.
Which, as I said, is going to act as a phase query,
which is going to do this.
It's going to give us.
Okay.
So now you're keeping track only at the first bit, right?
We've kept the minus.
It fixed.
Yeah, that's right.
That's right.
Yeah, exactly.
I don't care about this.
The only purpose of the second qubit was to get this phase,
but for a query on the first.
Right.
And this is actually a very common thing in quantum algorithms.
So,
so do it shows actually has a structure that recurs.
And from one quantum algorithm to the other, like.
Step one is to just create an equal superposition over all different
inputs.
Step two is make a query on that superposition.
Right.
Step three is throw away the answer to the query.
And then you say, like, wait a minute, what, you know,
what was the point of making the query?
If I don't even look at the answer, right?
If I throw away the answer register like that.
Okay.
Well, it was the only reason I cared about the query was because of
the effect that making the query had on my input register.
Can you map your terminology to what's going on in the circuit here?
So this is the, this is the first, the top one is the input register.
Yeah.
Okay.
Yeah.
The second one is the answer register.
Yep.
Okay.
And now, you know, I am making a use of F is applying a query that
will write the value of F of zero or F of one into the answer
register.
But the only reason I care about that is because of the effect
that it will have on the input.
Yes.
Yes.
Okay.
And again, you know, again, this is very, very common, you know,
Simon's algorithm, Bernstein,
Vasarani algorithm, Shor's algorithm, you know,
the core of Shor's algorithm, Grover's algorithm,
and they all have that same kind of character.
Right.
So just, yeah, just to wrap this up.
So you only care about this guy and this, this, this thing is just,
it doesn't matter what's going on anymore.
Yeah.
That's right.
It doesn't matter anymore what's going on in the answer register.
Yeah.
Okay.
And now what we're doing is, okay.
So, so, so I applied use of F and in order to get this state here,
which it was, it looks like minus one to the F of zero.
Plus minus one to the F of one, one.
Okay.
And now what I'm doing here is I'm taking that.
Cupid and I am measuring it in the Hadamard basis.
Okay.
Right. I mean, you know, that's what I had a more followed by a measurement
me right now.
I'm checking to see like, is that Cupid plus or minus.
Right.
And now here is the key observation.
Okay.
If F of zero equals F of one.
Right.
Which is to say, suppose that their parity is zero.
Okay.
If F of zero equals F of one, then this state at the bottom here is the
plus state.
Yes.
Right.
Well, it's either the plus state or else it's minus the plus state,
which as we said is just the same thing since global phase doesn't
matter.
Yes.
Right.
So suppose on, on the contrary, that F of zero is different from F of one,
which is to say, suppose that the parity is one.
Okay.
In that case,
this state down here is the minus state.
Right.
Because I've got either zero minus one or else I've got minus zero plus one.
Right.
Which is either the minus state or else minus the minus state.
Okay.
So this is either going to be plus if F of zero equals F of one.
Yep.
Or plus or proportional, I guess, maybe proportional to.
Mm-hmm.
And then it'd be minus.
Yeah.
If F of zero is not equal to F of one.
Right.
Yep.
Okay.
Yeah.
Yep.
Okay.
Yeah.
So that's the do it shows it out.
Yeah.
Yeah.
Yeah.
Yeah.
Right.
Right.
You can also say like, like we only got out one bit at the end.
Like if we had wanted both F of zero and F of one.
Right.
We could not have gotten both of them.
Right.
But we know the one bit that we got out happens to have been the parity
of F of zero and F of one, which is the one bit that we wanted.
Yep.
Okay.
So that that's one way to think about it.
Another way to think about it is like, if you just, you know,
explicitly wrote out all of the contributions to the amplitudes,
you could say,
look, you know, when I, when I make this measurement at the very end,
you know, there are,
there are sort of two different contributions that could have given
me, you know, the, the output that is not the parity.
But they canceled each other out.
Right.
One of them, you know, was positive and the other one was negative.
Right.
And so, so I get a destructive interference.
Like if I, if I, if I just multiply out the matrices explicitly,
then I'll see that.
Like, you know, I would like if F of zero equals F of one,
for example,
then I could calculate the final amplitude of the state of the output
one as like a half minus a half.
Right.
So it'll be zero.
Right.
So whereas, whereas the final amplitude of this,
the state zero, which is the output I wanted,
that one will be a half plus a half.
It'll be one.
Okay.
So in this case,
I get perfect constructive and destructive interference.
Right.
You know, it gives me an amplitude of one on the correct answer,
the one I wanted,
and it gives me an amplitude of zero on the incorrect answer.
Yep.
Yep.
Yep.
You say like, this is like the paradigm case.
Right.
And then in every other quantity,
you know,
you are trying to, you know,
for some much more interesting and more impressive problem,
but you're trying to do something that in the best case will be
approximately like that.
Yes.
Yes.
Okay.
Wow.
This is, this is great.
So actually, I think maybe this is a good segue into what BQP is
because I think you just alluded to that, right?
You just walk right into it.
Yeah.
Yeah.
So, okay.
So let's just recap really quick.
So we already talked about this.
You just walked right into it.
Yeah.
Yeah.
So, okay.
So let's just recap really quick.
So we, okay.
So we've, we've set up the qubit language and explain what's magical
about quantum physics.
We've now explicitly shown an example of where there's a quantum,
I mean,
speed or quantum complexity reduction through the query structure,
let's say,
and then now the next thing to do is to kind of take a step back
and to look at what is the relationship between quantum
complexity classes and, and, and classical complexity classes.
Cause, cause this isn't really, well, first of all,
this is not a useful problem.
But second of all,
this isn't really a speed up in any meaningful way in terms of like,
you know, reducing the search,
search complexity or whatnot, right?
So I think, I mean, what we talk about next,
we'll be clarifying.
I mean, I mean, I mean, to be clear,
computing parity can be useful, right?
But it's just that all, all that do it shows it gives you is that
you could compute the parity of n bits using n over two queries.
Right.
So it's a factor of two speed up.
And then, you know,
and the way that you would do it is you take your n bits,
you just group that you, you pair them off.
You just, you know,
split them up into pairs.
You run the way it shows on each pair separately.
Right.
That that gives you your factor of two, right?
And then it's not even kind of a real speed up because then,
you would have to get the final answer.
You have to take the parity of all of those final bits anyway.
Right.
And there's another n over two.
So it's only a factor of two savings in terms of query complexity,
not in terms of the total number of steps.
Right.
So, so yeah, so as you said,
it's not really directly useful.
Right.
The, the do it shows up, but then, you know,
and, and, and, and there were people who saw it and said,
you know, that's probably going to be the general case.
Right.
You know, it's just like it's, it's, you know,
actually apparently Simon.
So, so shores out shores,
factory algorithm grew out of an earlier quantum algorithm called
Simon's algorithm.
Right.
And Simon's algorithm came about because Simon apparently looked
at the way to Joseph and did a later thing called Bernstein
Vasarani and Simon said, I really don't think that these quantum
speedups are, you know, are that impressive.
And let me try to prove that kind of you never get an exponential
quantum speedup for like a, you know,
in a truly interesting sense.
And that turned out to be false.
And Simon's algorithm was the counter example.
Okay.
So it's still for a quite artificial problem, but in that case,
it was an exponential speedup where you can show that any classical
algorithm, even a probabilistic classical algorithm, you know,
must make at least like two to the N over two queries to this
function F in order to learn a certain property of it.
Whereas there is a quantum algorithm that makes only N queries.
Simon's algorithm was the first example of an exponential speedup
for one of these query complexity or black box problems.
Okay.
You know, it had that it was this kind of reduction.
Okay. And then the story goes that Simon submitted his paper about
that to, you know, one of the premier conferences of theoretical
computer science, which is called stock or Fox, and it was rejected.
Okay. It was rejected because people said, well, this is just this,
this black box model, right?
Like who knows if this is telling us anything about the real world.
Right.
And, you know, it doesn't seem that interesting. Okay.
But there was one guy on the program committee who said, I think it is
interesting. And that was Peter shore.
And so then Peter shore said, well, it seems clear that if you just
change the black box problem to one that's a looks a little bit different.
That's like about, you know, finding a hidden structure in a different
abelian group, like Z, Z mod N instead of Z two to the N, right?
Then, you know, you would get finding the period of a periodic function.
Right. You would get a fast quantum algorithm for period finding.
And then, you know, it was obvious to Peter shore, albeit not to most
people, right? That if you could find the periods of periodic functions,
then just through some classical number theory, you would also be able to
quickly factor large numbers and calculate discrete algorithms.
Okay. Which would then break, you know, most of the cryptography that is
relied on for the, you know, on the internet. Okay.
So, you know, and now to work out all the details of that, you know,
he took shore like a year. Okay. So he had to figure out, you know,
what is a small circuit for the quantum four year transform, for example.
Okay. But, you know, he ultimately did all of that. And, and that was, you know,
that was then what put quantum computing kind of on the map as a field rather
than just as an idea that, you know, a few odd balls had looked into.
What year was that?
That was 1994.
Okay. Okay. When Shor's algorithm came out.
Yeah. That is when Shor's algorithm came out. Right. And that's
So,
yeah, I think assignments algorithm was actually earlier in 1994. So that's
Okay. Okay.
A crucial year for, for, for the history of quantum computing. Right.
Okay. Okay.
Okay. But so, so now you asked me, you know, what is BQP? Yeah, right.
So, so in some sense, you know, BQP.
Well, it stands for bounded error quantum polynomial time.
And I'm not going to try to write that with my finger.
But that is the, the central object of study in quantum computing theory.
And you can think of it as the class of all of the problems that are
efficiently solvable using a quantum computer. Right.
Up to some, up to some bounded error.
Up to some bounded error. Exactly. So, you know, we will allow the quantum
computer to make, you know, to have, you know, so, so, so formally it's a class
of only of yes or no questions. Like what we call decision problems in computer
science. Okay. And this is, this is not a huge, this is not as big of a
restriction as you'd think, because many other problems can be phrased as
decision problems. Right.
Yeah. Yeah. Yeah.
Yeah.
The, the bounded error, how essential is that?
Yeah. Yeah. So that, that is pretty essential. Okay.
Because, so we, you know, because, because in practice, most, you know, so,
so, so the Deutsch-Jose algorithm, which we saw was an exact quantum
algorithm. Right. It had no error in it. Okay.
With most quantum algorithms, we do not get that lucky.
Okay.
With most quantum algorithms, the interference that we're able to arrange
is, you know, is pretty good, but not perfect. Right.
Which means that there will be some probability of measuring and seeing the
wrong answer. Okay. But, you know, computer scientists have understood since
the 1970s, if not earlier, right, that as long as the probability of a wrong
answer can be bounded, you know, is small, then it's just not a big deal at
all. And the reason is simply that you always have the option to repeat your
algorithm a whole bunch of times and then output the majority answer.
Right.
Just like if you had a bias coin with a slight edge, you could just keep flipping
it over and over until the, the overall edge you get is exceeds whatever
threshold you have. Right.
Exactly. Exactly. It's just, it's just the law of large numbers. Right.
So like as long as on every input, your algorithm has at least a two-thirds
chance of getting the right answer. Right.
Then, you know, if you want to be more confident than that, then all you do is
run the algorithm say a thousand times. Right.
And in computer science, we don't really care about a thousand, not just some
constant factor. Right. And then, you know, you take the majority of all the
outputs and at that point, the chance that, that, you know, your computer would
have, you know, the chance that your algorithm would have given you the wrong
answer because of some gigantic fluctuation, you know, is probably smaller
than the chance that like an asteroid would have just hit your house at that
exact moment. So you're not really worried about it anymore.
How about this? In terms of complexity, if you did not allow bounded error, do
we know that to be strictly a subset of BQP?
Well, we, we, you know, we know almost nothing to be strictly a subset.
Okay.
We don't, we don't even know that P is strictly a subset of P space, for
example.
Although this is about determinism and not determinism. I thought maybe there'd
be a different kind of.
No, no, right, right, right. But, but, but, but now like, like, if we, if we
looked at the version with no error, which is called EQP or exact quantum
polynomial time, like in some sense, like, like, it's not even very well
defined as a complexity class. And the reason for that is that, you know,
which EQP you get might depend on your choice of gates.
Okay.
So, like, which, so, so depending on which set of gates you allow, you might
get a different set of problems that are exactly solvable.
Right.
Whereas with BQP, you don't have that problem.
When we solve that problem by like taking the union over all circuits or
something.
Well, yeah, but you still need some way to specify which gate you have at a
given moment, right?
Okay.
Like you, like, like, like you're, you're like, again, you need a classical
computer program that can output a description of the quantum circuit.
Okay.
Which means it needs some finitary way to refer to the gates.
Right.
And if there's a whole continuum of gates, then most of the gates will have
no finite description.
Right.
Okay.
Okay.
So, so you could say, all right, I want to allow all gates with rational amp,
you know, matrix entries, or I want to allow, you know, just this particular
finite collection.
Oh, I see.
I see.
Or, or, or you could even say all gates with, with computable entries.
Oh, you know, there's a nice thing with that.
Right.
And, and, and, and then, you know, you're, as far as anyone knows, you know,
you're the EQP might be sensitive to, to those kind of low level choices.
Right.
I see.
And now, now the truth is that, that in actual practice built in building a
quantum computer, none of that would ever matter.
Right.
Because there's already noise and.
Yeah, exactly.
That's so much noise in the system anyway.
Right.
Okay. Got it.
You know, and, and so, so then, you know, in some sense, BQP is the much more robust
and natural.
That makes sense.
Right.
And it could be proven to be insensitive to those choices of like exactly which set
of gates.
So, you know, in computer science, one of the main things that we try to do is
we try to understand the space of all computational problems and sort of
organize that space in terms of what are called complexity classes.
Right.
The classes of problems that are solvable within different kinds of resource
constraints.
Okay.
So the most basic complexity classes are first of all, there's pay, which
stands for polynomial time.
Right.
And this is just all of the decision problems.
You know, so like families of yes or no questions for which there is some
algorithm running on a standard computer, you know, that will solve, you know,
deterministic, you know, that will solve each instance of the problem and that
will use an amount of time that is polynomial in the length of the instance.
Right.
At most the number of bits raised to some fixed power.
Okay.
So examples of problems and pay would be like, I give you a graph.
I, you know, like a description of a graph by a string of bits.
Now, is that graph connected?
Like is every vertex reachable from every other.
Right.
This is, you know, like every undergrad in computer science would learn how to
solve that problem.
You know, breadth first search or depth first search or some algorithm like
that.
Another example would be, I give you an integer written in binary.
Is it prime or not?
Right.
That's a much more non-trivial example.
Okay.
That one was only proven to be in the class P in 2002.
In a breakthrough by Agrawal, Kyle and Saxena.
Right.
It had been known long before that to have a fast probabilistic algorithm.
Okay.
Yeah.
Yeah.
Yeah.
But the, the deterministic one was, it was a big breakthrough.
Okay. Yeah.
So that's, so that's.
Yeah.
So primes is in P, right? Yeah. Yeah.
Yeah.
So that's P.
Yeah.
And now the second most famous complexity class after that.
Is called NP.
Which stands for non-deterministic polynomial time.
Okay.
And this is, you know,
it's the class of all of the decision problems for which,
whenever the answer is yes,
there is a short proof that can be efficiently checked.
Okay.
So, so there doesn't,
so I'm not saying that there has to be a fast algorithm to find a
solution.
I'm just saying that if there is a solution,
if there is a positive solution,
then it must be efficiently checkable.
Okay.
And then there's, you know,
once you've seen it. Okay.
So a classic example of a problem in NP would be factoring.
Like I give you a huge integer and I asked you to find its prime
factorization.
Right.
Now,
technically I would have to rephrase this as a decision problem
somehow.
Like I can ask, for example,
does given this integer,
does it have.
Does it have a prime factor ending in a three?
You know, right?
You know, but, but if I,
if I can answer all the different yes or no questions about the
prime factorization,
then I can easily recover the prime factorization itself.
So, so often we'll just be sloppy and we'll talk just talk about
factoring itself as an NP problem.
Right.
And, and so, so now the key point is that, you know,
given, you know, if I give you, let's say a 10,000 digit integer,
right,
no one knows any fast algorithm running on a conventional computer to
find its prime factorization.
Right.
And every time we order something from Amazon or, you know,
we visit any HTTPS website, you know,
our,
our,
our,
our data is being protected by a crypto system that depends on
the belief that factoring and some closely related problems are
hard, are not in P.
Right.
Do not have polynomial time and algorithms.
Okay.
But, you know, the factoring problem is easily seen to be an NP,
which means, like, if I, you know,
a claim to you that yes, this number does have a prime factor ending
in three and you say, well, I don't believe you.
Right.
There's always a way I could convince you of that, which is,
I just show you the factor.
Right.
I say, here it is.
Okay.
Now, if you're given that factor, you can very easily check it.
I mean, first of all, I already said that primality testing is in
pay.
Right.
So you can check that it's prime.
Okay.
And you can also check that it divides the input number.
Right.
That's, you know, at least using a computer.
That's a very easy thing to do is a division.
Right.
So.
So, so, so the factoring problem is a perfect example of an NP
problem, which might, you know, which, which, which might not be in P.
Right.
But, but where the answers are easy to check.
Okay.
Now.
I should say that, that a P is P is a subset of NP.
Okay.
So every P problem is also an NP problem.
And this is simply because well, if you can solve a problem yourself,
then, you know, you don't even need the witness.
Right.
So, you know, that's the answer for the yes answer, right?
The witness to the yes answer can just be the empty string or something.
Right.
So, okay.
And now the super famous question that sort of is sort of the,
the defining question of theoretical computer science itself,
if you like, is the question, is this a strict containment?
So is P equal to NP.
Okay.
And, you know, I, hopefully, you know,
it's not the case to people listening of the importance of this problem.
I mean, it's been featured on the Simpsons and Futurama, you know,
I didn't know that.
Yeah, yeah.
That's not the main reason it's famous, but okay.
Yeah, yeah, that's right. No, but it's one of the clay millennium problems.
It's, you know, and I would personally put it forward as the most
important of the clay millennium problems. Okay.
And the argument for that is simply that with P equal NP.
And via an algorithm that was very efficient in practice,
then it would not only mean that, you know, and you could prove that it
would not only mean that you could solve that clay problem.
It would mean that you could program your computer to solve the other six.
Right. You could just say, is there a proof of the Riemann hypothesis
that is at most like, you know, that in some formal language like ZF set
theory, you know, that is at most 100 million symbols long.
Right. And if such a proof exists, then, you know, you should be able to find
that in time that is linear or quadratic or whatever in 100 million.
Right. And so on for every other mathematical question.
Okay, so, so in some sense, P versus NP is really asking about to what extent
can mathematical creativity itself be completely automated.
Right.
You know, as soon as I tell you that a problem is efficiently,
that solutions to it are efficiently checkable.
Does that also mean that the solutions are efficiently findable?
Okay. And most of us would conjecture that the answer is no.
You know, I like to say that if we were physicists, we would have just declared
that to be a law of nature.
And, you know, maybe given ourselves Nobel prizes for it.
Okay. But, you know, by mathematical standards,
it has to be called an open problem.
Okay. So, so now, now a major role in this story is played by what are called
the NP complete problems.
Okay. So let me just put at the very top of NP,
drawing the line to not include factoring.
Okay.
These NP complete problems.
Informally, these are the hardest problems in NP.
Okay. And what that means is a problem is NP complete.
If number one, it's in NP.
And number two, an efficient algorithm for that problem could be efficiently
transformed into an efficient algorithm for any other NP problem.
Right.
And so, you know, that sounds like a weird concept the first time you hear it,
because it's like a priori, like, is it even clear that there are any NP
complete problems? Right.
But what turned out in the early 1970s was that not only do there
exist NP complete problems, okay, but the great majority of the problems
that people care about in like combinatorial optimization and, you know,
scheduling and all kinds of practical fields are NP complete.
Okay. So, you know, three coloring a graph, like, you know, color a map with
three colors so that no two neighboring countries are colored the same.
You know, I give you a map and I ask, can that be done?
That is an NP complete problem.
I give you the social network of Facebook and I ask you, are there, you know,
a thousand people who are all friends with each other, right?
Find the maximum clique in this graph.
That is an NP complete problem. Okay. I give you the dimensions of a bunch of
boxes and I ask, can all of these fit into the trunk of your car?
You know, that is called packet. That is an NP complete problem.
Yeah, some people might have experience with that being a, you know, a hard
combinatorial problem. Okay.
A mind sweeper, you know, if you've played that turned out to be NP complete,
right, Sudoku. Okay.
So, you know, in addition to, you know, much more significant things like
finding a proof of a theorem of bounded lengths, right?
Okay. And so if any NP complete problem were in P, then all of them would be.
And then, in fact, P would equal NP, right?
If any one of them is not in P, then P is not equal to NP.
Right. So those are the stakes.
And, you know, and these are not the only complexity classes.
So, for example, you know, just above NP, even above NP, we have this class called
P space, which is everything that a classical computer could do with a
polynomial and an amount of memory, but possibly an exponential amount of time.
Right.
And then even above P space, we have what's called X, which is what you can do
in an exponential amount of time and, you know, and possibly also exponential
amount of memory. Okay.
So, okay, now, now if you ask, like, which of these containments are strict,
right? So what we know is that P is contained in NP.
NP is contained in P space.
And P space is contained in X. Okay.
And now if you ask which of these are strict, well, we have known since the 1960s
that P is strictly contained in X. Okay.
This is called the time hierarchy theorem. Okay.
It was proved by Hartmanis and Stearns. Hartmanis was one of the founders of
computational complexity. He just passed away this year. Okay.
But since now knowing that P is not equal to X, of course, that tells us that
either P is not equal to NP, or NP is not equal to P space, or P space is not
equal to X, right? At least one of those three must be true.
Most people's guess is that all three of them are true, right?
That all of these containments are strict. But that is what, like, you know,
it will take a revolution in mathematics before we are able to prove statements
of that kind. Okay.
You know, these have all been open problems for more than half a century.
Okay. So, so now, you know, into this, you could say that there's already,
you know, incredibly, like, difficult and rich space comes waiting BQP, right?
Or, you know, quantum polynomial time. And so now, of course, the key question
of quantum complexity theory is, well, how does BQP fit in, right?
Like, or how does, you know, making things quantum actually, you know,
change this picture, right? And so, okay.
So, so, so the first, you know, this was exactly the question that Bernstein
and Vasarani studied in 1993, when they, you know, wrote their now seminal paper,
which defined the class BQP, right? And then kind of asked all the obvious
questions about, well, where does it fit in, right? And so, so some of the things
that they showed are that first of all, BQP contains classical P, right?
This is, this is not a great surprise, right? I already told you about how the
Topheligate can be used to simulate classical computation, right? So, okay.
So whatever a classical computer can do in principle, a quantum computer can do
as well. It might be ridiculous overkill to, you know, to use it for that.
It's not even in principle, it's an explicit algorithm to do it.
That's right. That's right. Yeah. Okay. Yeah. That's right. Okay. And then, now
another thing that they showed is that BQP is contained in P space.
Okay. So, so they showed that, that, you know, you can always take a, an efficient
quantum algorithm, and you can simulate it classically, possibly using exponential
time, but in any case, using a polynomial amount of memory.
I'm trying to think, I see, because I'm trying to think, if you did all these matrix
multiplications, you never need more than to store, you know, like maybe like one bit
at a time or something like this. Is that? Yeah, kind of like that. Right.
Okay. So, so maybe, maybe to step back, the first point I should make is that BQP
is contained in X, right? Okay. So, you know, so right, I mean, I mean, you know,
this could be the weaker result here. Okay. Right. So anything that a quantum
computer can do in polynomial time, a quick, a classical computer can also do
in exponential time. Right. Right. Which means that there is, you know, quantum
computers cannot change the theory of computability. Like, there cannot be a
quantum algorithm for the halting problem, for example, because if there were, then
there could be a classical algorithm, which is what Turing proved was impossible.
Right. And why do we know this? We know this because you could always just take a
quantum algorithm and simulate it classically by just writing out the entire
quantum state, writing out the entire wave function. Right. You know, and, and, and,
you know, there is one little observation that you need to make, which is that you
don't need to represent the amplitudes to infinite precision. Right. Just, you know,
because of the assumption of bounded error, you know, in the BQP, right, it is
enough to represent each amplitude to just, you know, a reasonable number of bits
of precision. Right. And then, you know, you can just in, in exponential
memory just write down the entire amplitude vector and then simulating the quantum
computation is a simple matter of doing a bunch of matrix vector multiplications.
Right. Okay. And, and so, okay, but then, then, you know, Bernstein and Vasarani
proved a stronger result. They showed that BQP is contained in P space. Now,
why is that true? Well, for anyone who has studied physics, I could say the answer
in one phrase. It's because of the Feynman path integral. Right.
It is because you can always, you know, in quantum mechanics, if you're trying to
calculate an amplitude, you can always write the amplitude as a sum over
exponentially many different contributions. I see. And so, since you have a cumulative
sum, you just need to keep track of a state at, at one state at a time, essentially.
Yeah, precisely. Yeah. You can then evaluate that sum by just reusing the same memory
over and over. Yeah. And I think explicitly what I said in terms like, you know, to keep
track of a matrix multiplication, you know, you can kind of do things like, you know,
by entry or something like that. You're scratching. Yeah, that's right. That's good.
That's right. That's that. That would be a different way of saying it. Yeah. Yeah.
Yeah. So, okay, now, now the fact that BQP is contained in P space tells us something
else that is very important. Okay, it tells us that in our current state of knowledge
of complexity theory, we have no hope of proving unconditionally that BQP is larger
than P. Right. So you could say like, like, you know, a central goal of quantum computing
ought to be just prove that you can do something in quantum polynomial time that you cannot do
in classical polynomial time. Right. So prove that P is strictly contained in BQP. Right.
I will put this as a conjecture. Right. Okay. Now, certainly, like, if you believe that
factoring, so, okay, so, so sure is great achievement was to show that the factoring problem is in BQP.
Right. Factoring has a polynomial time quantum algorithm. Okay, so if you believe that factoring
is not in P, then that would mean that, you know, BQP is larger than P. Right. Okay, but,
you know, we have no hope of proving unconditionally in our current state of knowledge that BQP is larger
than P. Why is that? Well, it's because we can't even prove that P space is larger than P.
You could say like, you know, it's not our fault as quantum computing people. Right.
It's like the progress is blocked by even just our lack of understanding of how to prove
separations in classical complexity. Got it. Yes. Okay. So, okay, so, okay, but now what else can we say about BQP?
So, so here is P. Here's NP. Here's P space.
Yeah, and I guess the way this is going to tie up is you're going to eventually point to what the quantum supremacy guys did and
Yeah. Yeah. Yeah. Okay, here's the NP complete problems. And now what does BQP look like? I like to draw it with a kind of wavy boundary since, you know, everything quantum is, you know, spooky and mysterious, of course.
So, so here's our kind of our picture of where BQP will go.
Let me let me put factor in here as just a big example of something that's in BQP, but not known to be NP.
Okay, now, you know, now you might be able to already see this from the picture, but a central open problem is what is the relationship between BQP and NP.
As far as we know today, they may be incomparable to each other.
Neither containing the other. Right. So on the one hand, we do not know of an efficient quantum algorithm for the NP complete problems, right, which is equivalent to asking, is NP contained in BQP, right.
Right. This is this is not known to be true and most of us don't believe that it's true.
Right. Okay. And this is this is this is the precise point where most of the popularizations of quantum computing go off the rails. Right.
They talk about Shor's algorithm as if it were just a simple matter of try all the possible solutions in parallel.
And if that were true, then that would not just be for factory. Right. That would also work for the NP complete problems. Right. But we don't think that it's general.
This is the NP complete problems. Right. Shor really had to take advantage of very, very special properties of factoring. Like I said, the fact that you can reduce it to finding the period of a periodic function.
Okay, so, okay, so so so that's that's one direction and then in the other direction we also don't know whether BQP is contained in NP.
Okay. So, so this is the question, like if a quantum computer can solve a problem then is there always at least a short classical proof of the answer. Right.
Even if it's hard to find or, or could quantum computers solve problems where the answer cannot even be efficiently checked by a classical computer let alone fail.
Actually, if this if this if BQP were dead P with that put quantum computing out of business.
No, no, no, no, no, it wouldn't if BQP were an NP like you could still have that factoring would be in BQP but not in pay, for example, right, as long as P is not.
Okay, okay, okay, okay, I see, I see. Okay, okay, so.
So, yeah, so, you know, since the question you're talking about is, is, is, is, you know, let me just write it explicitly.
Question of his BQP equal to pay. Okay.
So, yeah, but okay but now we're talking about the question of, can a classical computer always check the answer to a quantumly easy problem and we don't know and I would say we don't have very strong evidence one way or the other kind of in the real world, we
have in the Oracle or black box world we do know something about this question but you know I personally think that this could go either way. Okay. Okay.
So, so so that that was a little bit about BQP and where it fits in with classical complexity classes. Alright, so, so you know you could say like like the long term goal in quantum computing research would be build a scalable quantum
computer, you know that is able to run, you know, shores factoring algorithm or something like that right at that point, there is no more arguing with the skeptics who think that it's impossible or you just say to the skeptics,
okay, just give me your 10,000 digit number, you know, I will give you back you know the prime factors after a few minutes and then you know, you know, you must agree that either I have built a quantum computer, or else I've done something
else that is equally remarkable, right, you know, and you can and you can check the prime factors for yourself, right, you don't have to take my word for anything, right.
Okay, so we are clearly we are not there yet, right, and so we don't have, we don't yet have truly scalable quantum computers, you know that can scale up to millions of qubits, right, and you know we could, you know, the reasons why that's such a hard
engineering problem, that would be a whole further discussion that could you know we could easily spend another couple hours on that on the decoherence and quantum error correcting codes, you know, and that that's a whole nother story okay but suffice it to say,
there's been remarkable progress in the 20 years or so that I've been in this field, you know, toward, you know, getting qubits that you can control well enough, that then you can start using error correcting codes to simulate, you know, basically perfect qubits,
you know, that you could, that could maintain their superposition states for as long as you want, right, and then that's kind of what we ultimately want in order to run quantum algorithms like shores algorithm and you know and do factoring, and also to simulate quantum mechanics,
which is, you know, maybe you know even more important for, you know, industry for practice, right, and then reading other people's emails, right.
But, you know, we, we, we, as an engineering matter we are not yet at the point where we can build a scalable quantum computer with, you know, with thousands or millions of error corrected qubits.
No one knows exactly when we'll get there there are some people who are very optimistic that it will happen within the next decade. Okay, and, you know, and, and, and billions of dollars are now being invested in it by Google, Microsoft, Amazon, IBM, dozens of startup companies.
So, you know, if it fails, it's not going to be for lack of trying.
But you know what where, where, where people are now is that they can build devices with, let's say 50 or 60 relatively noisy qubits, right, that will not maintain their superposition state for arbitrary amounts of time in fact, they'll only
maintain it for, you know, let's say 20 or 30 microseconds, something like that. Okay, but, you know, that could be enough to do maybe a circuit with 1000 or so gates.
Okay. So now you start thinking like 50 qubits 1000 gates. Is that already enough to do something that would be hard to simulate for a classical computer.
And that would at least prove the point that yeah, we can exploit this like vector space, see to the two to the 50. Right. We can exploit this, you know, quadrillion dimensional complex vector space to solve some problem where a classical even a classical
computer would have a very hard time keeping up. Okay, so, so that brings us to this, this, this milestone of quantum supremacy. Right.
So, so, so, so not everyone likes the name. Okay, but the name was coined in.
Thank you. The name was coined in a decade ago by by John Preskell.
And, and, and he was trying to codify a set of possible experiments that I and others had proposed about a year before that. Okay, and so, so, you know, we had been thinking actually just about quantum complexity theory about, you know, things like BQP versus P, right,
about like, like, what would be the most straightforward demonstration that you could do that a quantum computer is doing something that is hard to simulate classically. Okay, and the key realization that we had, and this was.
So this was me and my student Alex named Alex Arkapov in 2011, and then independently of us Bremner, Joseph and Shepard. Okay, at around the same time.
We all kind of, you know, from different starting points kind of converge on this on the same idea, which is that it actually becomes much, much easier to see the advantages of a quantum computer, if you're willing to broaden your notion of what a computational
problem is. Okay, so we went when we talked about BQP we talked about decision problems. Right, which are just problems where the answer is always yes or no.
Right. And I said that a lot of other problems can be encoded as decision problems. Okay, but not quite all of them. Okay, so there were also another class of problems and computer science is what are called sampling problems.
I described to you in some way, a probability distribution. Let's say over and bit strings. And now your challenge is to output a sample from that distribution.
Okay, so an example might be, you know, I give you a graph, and I ask you to sample a random matching in that graph.
Right, or I described to you a convex body by like, you know, the equations of its bounding surfaces, and I asked you to sample a random point in the interior of that convex body.
Right. Now, you know, these kind of problems have a long history in computer science. Knuth, you know, talks about them and the art of computer programming, right.
But, but now what we realized is that if you're as soon as you talk about sampling problems, it could be much, much easier to see the advantages of a quantum computer over a classical one, both theoretically, like in the sense of separating the complexity
classes of, you know, quantum sampling versus classical sampling, and also in the practical sense that it might be much, much easier to, to actually realize those kind of quantum speed ups in the lab.
You might not have to build the full fault tolerant quantum computer that would be able to run Schwarz algorithm. 50 noisy qubits might already be enough to start seeing the advantages for some of these sampling problems.
Okay, so that was the key realization that some of us had 11 or 12 years ago. Okay.
So, so, Archipave and I, we had a proposal which we called Boson sampling. Okay, which was basically to solve a sampling problem that involved photonics.
So, you know, generate a bunch of photons, then pass them through some basically random, but polynomial size network of beam splitters, and then just measure to see where the photons.
Is this the same approach that the Google group use or did they use something different?
Okay, okay. They were they were inspired by it. But then they said, Okay, but now in order to do Boson sampling, we would have to spend $100 million to like re, you know, redesign our whole experiment.
So we're going to do something an analogous thing with superconducting qubits. And we will trust you the theorists to adapt your theory to our experiment. And we said, Okay, we can do that.
Okay, I see. So so so the thing that Google did is now called RCS or random circuit sampling. Okay. And so so so you could say this this Boson sampling, which is what Archipave and I proposed at this
time, what's called commuting Hamiltonians, which is the Bremner, Joseph and Shepard proposal, and the random circuit sampling, which is what Google ended up doing, right.
They're all like at a very high level, they're all kind of a similar idea, right that you you you sort of apply this kind of more or less random set of operations.
And kind of scramble up your, the state of your qubits, get a kind of random looking state of your, of your qubits, but which will have little inhomogeneities in it, like some output states will be somewhat likelier than others.
Right. Just because of, you know, some of them just by chance will suffer a little bit more destructive interference.
The other ones by chance will enjoy a little bit more constructive. Yeah. And I think the point is, if I understand right, basically the probability density, right, each of those terms are hard to compute classically.
And so you know that if you get samples that are within some threshold of your true probability density. And you, the other key thing is you also know that the classical problem approximation is also hard, or at least you believe it to be hard.
Then, yeah, then you, that's how you sort of know. Yeah, exactly.
Exactly. So the point is, look, you know, a, both a, you know, to actually calculate these, these, these final, you know, the probabilities of the final outputs in your, in your distribution that we expect to be an exponentially hard problem, both for a quantum computer and for a classical computer.
Right. But what the quantum computer can do just by construction is it can sample from the distribution. Right. And now what we did in the Boson sampling paper is we gave theoretical evidence that even that sampling problem should already be exponentially hard for a classical
computer under some reasonable complexity assumptions, right, which, you know, it would take time to explain the details of that. Okay, but so we gave some evidence that there is a separation between quantum and classical in terms of their ability to efficiently
sample from these kinds of probability distributions.
So then that, that is what kind of suggested this, you know, and we came at this purely from complexity theory, right, you know, we weren't even thinking about doing a practical experiment, but then we started talking to quantum optics people and they got very excited about it.
And so then, you know, we started realizing that, you know, maybe this could actually be done within like the next decade or so. What happened was that in 2014, Google hired John Martinez, who was maybe like the top superconducting qubits experimentalist in the
world. And they decided they're going to build like a 50 to 70 qubit chip that would be programmed, you know, programmable with using superconducting qubits. And, you know, and then they had the question, what do we do with that.
And, you know, it's not obvious what you do with 50 qubits, right. But then they said, okay, maybe we can do something like Boson sampling but for, you know, adapted to superconducting qubits.
And we had, we talked to them about that in 2015, we kind of helped hammer out the proposal of, you know, what exactly are they going to do. How do you verify it once you've done it, which is, you know, a major drawback of these experiments because it does take exponential
with a classical computer, even just to verify, you know, the results. Okay. But, you know, with 50 qubits, you can still just barely do it. Right. If you use a big super computer.
Right. Okay. And then, you know, and then like how do we know that the problem is hard for a classical computer, or, you know, under under, you know, are we are we sufficiently convinced.
And then, you know, Google worked on this experiment and in 2019, in late 2019, they announced that they had done it with a 53 qubit chip, which they called Sycamore, which sampled from this probability distribution over 53 bit strings, which we do not know how to sample, you know, they
estimated that it would take 10,000 years. Right. And this is where I got a little technically. Yeah.
From that same distribution, that turned out to be kind of wildly over optimistic or right because these are estimates right because what they have to do is because you have to because you still have to use a classical computer to check a hard problem.
And of course, you don't have 10,000 years to check what you do is you would extrapolate right so you could have a proxy you form a family of simpler and simpler problems and you sort of see what the trend is and of course, if you if you weren't so precise with your estimates
but that was not even the sticking point. That was that was not the sticking point. Okay, so, you know, like they with enough, I mean with enough computer power, they, you know, they could have done the full verification with with with 53 qubits, but it turned out that the reason
why they could have done it is that, you know, they also could have spoofed the results with 53 qubits. Right. So, so basically, it was just that their classical algorithm that they were that they had in mind to simulate the experiment was not the best one.
And people then came up with so so so the experiment, their experiment was fine. Right. The experiment, you know, sees the signal of, you know, where you are correlated with the, the, you know, the the outputs that you want to be right and it was an amazing experiment right and I think,
you know, from a, you know, truthfully, you know, scientifically, the most interesting thing that we learned from the experiment was not quantum supremacy itself.
It was just that the errors behave in just, you know, in according to the most naive possible model, right, where, where, you know, it's just the total fidelity of the circuit just goes like the fidelity of each individual gate raised to the power of how many gates there are.
I think. Okay. So, you know, and as long as that is true, then quantum error correction ultimately ought to work. I see.
Yeah, so supremacy in some sense is really just a subjective term in that there's a threshold. If they had just pushed it with a few more qubits then that everyone would be happy it sounds like.
No, because, because, because, okay, I mean, I mean, I mean, I mean, yes, more qubits would, would, you know, would help. But you know, the trouble right now is because of the exponential cost of verification.
Like if you go to so many qubits, like, you know, 80, let's say that a classical computer.
I see chance.
Classical computer can also can't verify the answers.
So right now you're kind of stuck with this cat and mouse game, where the difficulty of classical verification is linked to the difficulty of classical spoofing.
I see.
So that, so that kind of limits you. Right. But, but, but then, you know, the other issue is just that they're, you know, people, you know, even what while the classical simulation time is exponential, people can get very, very clever about it.
Right. And they can do all kinds of tricks to cut it down to a milder exponential. Okay. And that is exactly what we have seen in the past three years.
Right. The people have used what are called tensor network methods to get a faster simulation and nowadays.
We know that, you know, if you spent enough money on like AWS, right, or just buying enough, you know, classical computing time, then you could spoof the Google experiment, you know, in just a matter of seconds.
Faster than the thing itself, but you would still be using hundreds of times more electricity than the quantum computer.
And, you know, and the quantum computer is not exactly, you know, you know, I mean, it's already using a dilution refrigerator that's the size of a closet, right, which is using like, you know,
I think, you know, tens of kilowatts, right. But, you know, the classical supercomputer to simulate as far as we know that that could require megawatts.
Okay. So, so you are, you know, the so so so so in some sense you could say you still do have quantum supremacy, let's say, as measured by carbon footprint.
Right, I see, I measured by number of steps, right. But by by total number of operations, right. So,
that's not as measured by wall clock time and that's just because the classical simulations are so parallelizable, right, that like, you know, to do it faster and faster is just a question of cost.
The question of how many chips right so so there are, you know, you do get into kind of, you know, annoying finicky questions about what is the exact definition of supremacy or beating a classical computer.
That's right. Yeah.
You know, is ultimately, you know, maybe ultimately the question should be dollars. Right.
Sure.
But, but um, um, now, now the other key issue here is that there is a lot of noise in the in the circuit. So, each, each of their two qubit gates in the Google experiment, for example, has like 99.5% fidelity.
And meaning like only a one in 200 chance of an error, right, which is, you know, by the standards of like when I joined this field 20 years ago, right, you would have been thrilled to get 50% fidelity, right.
So that's like amazing. Okay, but it's still not good enough, like, if I have 1000 gates, I'm now taking point 995 and I'm raising it to the 1000 power, right, and then I end up with something that's rather small.
Right. And so this is exactly the issue with the Google experiment, right, that they just are able they're able to measure a signal that it's just a little bit distinguishable from purely uniform noise.
You know, if they take millions of samples, right, which, which they can do in a, in about three minutes. Okay, so, okay, but now there are classical simulations that can exploit the noise to run faster.
Right. So, so what the classical people say is, well, look, if the quantum computer, you know, itself is noisy, then it's perfectly fair for our simulation to also be noisy.
Right. And then it can run, you know, maybe run faster. Right. And so, so all of the, you know, we're still in the era, when we're going to see back and forth claims and counterclaims about, you know, like, to, to what extent has quantum supremacy been achieved.
The hope is that at some point, quantum computing just completely pulls away. Right. At least for those special problems where, you know, where, where it wins. Right.
And then, you know, and there's not even a comparison anymore. Right. Or, you know, the classical computers would have no hope of keeping up.
But now a huge question, which I personally do not know the answer to a huge question is, will the quantum computers be able to decisively pull away, you know, in the current era of these noisy, non error corrected devices.
Right. Or will pulling away only be possible once you have a fully error corrected cubits. Right. And that is a huge question where, you know, right now, for better or worse, billions of dollars are riding on the answer to that question.
Wow. Okay, well, great. Thank you for that great summary of the field that we spent so much time talking. I wanted to thank you so much for far.
Yeah, this is very sure. Yeah. Yeah, no, it was it was fun.
