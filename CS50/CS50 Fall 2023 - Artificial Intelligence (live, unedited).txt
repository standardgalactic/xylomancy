Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n g
gweithio, mae'n gweithio, mae'n gweithio.
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n g
gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio.
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Y Llywodraeth Y Llywodraeth
Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly, mae'n gweithio.
Felly mae'n gweithio.
Felly, mae'n gweithio.
Yes, mae'n gweithio.
Yes, mae mae'n gweithio.
Yn hoff i gael cwmwyb imposedssher Felly mae'n gweithio'g sydd gennych Cymru.
Mewn cofannaeth пес!
Maewl cyff yn amdod y coffanaeth interafeddaeth a greif.
так, mae wedi beth yw rhoi'n gwneud oes ar-faddiad,
yn rhoi bod sy'n dod arall a chynnyddio'r cefn oedd am yma fel unwg tas i fod ychwyn gy because
ond efallai a ffact i ddargen i늘wm.
Ond na ystod yw'r oed ar-s Crye cywethaf.
Cfyn foundydd awyr aunt wedi eraill.
Éw'r awyr an indenti gan refer mae hynny'n ddraith wedi ysta!
Felly sy'n gwylliant ddim, oed yn ei dygiad pwynt yr waith cyfo?
Dych chi draws o piwais e wrongswyn yn cael wych wedi ddullog o dyn nhw,
ond pan yw'r
dy'r pulled doncwch dy.
Rwyf yn iawn y bestio ar gyfer y ym connaisu,
bydwch y pethintoaining.
Yn rwynt i'n rhaid, on 원�land Waille,
erening, dwi'n iawn gw ThatsIn λwyd.
A sixtliacn unidig yr adenys y tribute that
ohonrodd toe ar gyfer y Rydych chi synthetic,
grafwyd argyff llai,
ond ond Rwys yn,
am高u amneud yerydd,
sprwodrachiall wneud sortiff
a ph parsoedol,
rhag y true rhagdal y pan ddes 489.
Rwy'n peth,
wrisz comfy ar eu byddwch gael
bod hefyd am ddidd problema
Ond ddyw cynthataint mewn gwah wych yn dda ni'r ganor sydd yn cael taeth go iaith.
Ond yr 하지 ar y gallurian,
reoltwr y cyfrifer o fynd i wedi gwylθ yma,
ond mae hynny yn ei bl mnie Babiu'r dudbyn.
Ond os ddim ei fahrenf أن datblygio gwybodaeth nad o'i fod yn unعمol'r taeth ei fod yn cael deul
2012, ben llawe etyn am cornyddau, a yna maes a ll cos i broaddlands dwydime ru
i chi arweithiau gyda wedi gweld cefn assumedb gyda ge musod draws,
neu iddo chiiór methylagau masidiol, felly am y helig fydd y gynrych cefnod eu
gw chi'n cerdd iawn a fy amgriffen eisiau, ychydig ni nhw'r eithaf am y llosaeth
o lengau cyf� 就是 i yda 1 neu 1.
Siwch pigeon gy reckless flu sgfa hanard
Rhyw hwn rydyn ni'n gw linerd o wybodaeth
Rhyw hwnnw'n700ml
Ion
sfyrwch
Diwe i
yn i
'n ddigon
E員iassa 1 llawer a i rywfodol, roedaeth er mwyn y bod procedureêr am y antyfael ar-i,
roedd i wedi cynnig sy'n elen Water Madden 1.
So mae hyd pipsi iddyn nhw dyma nad y mae hi strafisten a hyn storf winners metw'r uned
refuse i厦ion â'r hawes a'r hawes wedi'i misfysgoed a'r sgwrs yn ôl.
Mae beth gennym gan efudwyr rhai hyn y traf wanna ni allwn gyda own i newydd cer Pt a
amswn cyfly detectedh ac mae sy'nlaf yn rhaid yn y ll 살아eth beth mae'n myth i'r rhaid.
Ond rydym yn ה cancelled heb rhai ca blinking sy'n llienne,
etcarava resurrected by having been, but right now they have been,
we are not in that point as aware.
OK, so now the way the students are being persuaded here by now seen tried,
certainly heard of ChatGPT,
which is all about textual generation within CS50
and within academia more generally.
Have we been thinking about talking about forthhere,
how whether to use or not use these kinds of technologies?
And if the students in the room haven't told the family members already,
this year is an excerpt from CSFmentis own syllabus this year,
whereby we have dem tools like ChatGPT
Felly,タf neu ddodd ar gyfer y cy fueladwyrol methu
a'r software ar gyfer ar gyfer ymlaen,
sy'n cael ei ddweud, fel ydych chi'n ddweud,
a'r ddweud o'r ddweud o'r ddweud o'r ddweud,
chat GPT, ar gyfer OpenAI,
o'r ddweud o'r ddweud, ac yn cael ei ddweud.
A'r ddweud o'r ddweud o'r ddweud,
yn ymdill, mae'r ddweud o'r ddweud,
CS50 Duck, o'r DDB,
Duck Debuggar,
yn y website o'r ddweud o'r ddweud,
CS50.ai,
a'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddweud o'r ddwe
ddweud o'r ddirfynol ddweud o'r ddweud... Cs50.ai.
But we have built much of our own logic on top of third party services known as API's,
application programming interfaces, features that other companies provide that people like us can use
so as they are doing really a lot of the heavy lifting.
The so-called large language models are there,
but we too have information that is not in these models yet.
For instance, the words that came out of my mouth just last week when we had a lecture on some other topic,
neu gallans o mi i grywod sgol, a sgronawr sydd ondi o'r amserach yn fwy o bobl wneud.
A dysgu 발�odno'r honi i wneud yn ynynol o dda anywdd y CVL sought i gael cyfun ti'r wneud
ac yn innebwyr sy'n coild i iawn i gyd, a nad am si Felodra Cymru wedi'u wneud
dy corrupt造 is.
� yn architexureth i'r yng nghylch, wedi gydareu bought a daeth defnyddol itseg dda agent
tyUE ddoedd yn archwilar ac pa weithnos yn un aned guards.
So mae ddim ffocwsau ar y tama lanol blewiter oherwydd unedig brom Yu
rhan wath iawn, cyniol, achos r Estyn.
Ie ydw wedi dweud o to crypency inhaed llwysodol i rhaid.
Ac sydd gennym canolびad hynny enghraifft tyнеis.
Felly mae'r Arna 的 Yn.
Gwynicias wedi myfio ar bod lyfio,
gyfrifonau hefyd o bethau cyfra painau a blynyddiant?
Trud ydyn ni ddydd y bajr ymlaen yng nghi sauce y mae unedig.
Ieryd yr hyn o bu yn sp South,
rydych yn gawsio yr pubwyl ia Chll�f na cap llwysodol.
ych Adamsus Paul Ikam er yw'r bosagon maen nhw y gallu boeil,
a hwnau elecsen nhw'n gyfunio'r arwr.
Rydych chi'n g countless o LED-s o brifysác sy'n nhw,
ond gen nhw'n ad прекludi Tokyoيم
chi neid i Им unfyn fantastd ers fan을 dweudai carbs.
this would violate academic honesty.
And so in essence, and you can sort of do this manually with ChatGPT,
you can tell it or ask it how to behave,
we essentially are doing this automatically so that it doesn't just
hand answers out of the box and knows a little something more about us.
There's also in this world of AI right now,
the notion of a user prompt versus that system prompt.
And the user prompt in our case is essentially the students own question.
I have a question about X or I have a problem with my code here in Y.
So we passed to those same API students own questions as part of this so
called user prompt.
Just so you're familiar now with some of the vernacular of late.
Now the programming environment that students have been using this whole year
is known as Visual Studio Code, a popular open source free product
that most so many engineers around the world now use.
But we've instrumented it to be a little more course specific with some
course specific features that make learning within this environment
all the easier.
It lives at cs50.dev.
And as students in this room know that as of now,
the virtual duck lives within this environment
and can do things like explain highlighted lines of code.
So here, for instance, is a screenshot of this programming environment.
Here is some arcane looking code in a language called C
that we've just left behind us in the class.
And suppose that you don't understand what one or more of these lines of code
do students can now highlight those lines, right click or control click on it,
select explain highlighted code and voila.
They see a chat GPT like explanation of that very code within a second or so
that no human has typed out but that's been dynamically generated based on this code.
Other things that the duck can now do for students
is advise students on how to improve their code style, the aesthetics,
the formatting thereof.
And so for instance, here is similar code in a language called C
and I'll stipulate that it's very messy.
Everything is left aligned instead of nicely indented
so it looks a little more structured.
Students can now click a button.
They'll see at the right hand side in green how their code should ideally look
and if they're not quite sure what those changes are or why,
they can click on explain changes and similarly,
the duck advises them on how and why to turn their not great code
into greater code from left to right respectively.
More compellingly and more generalizable beyond CS50 and beyond computer science
is AI's ability to answer most of the questions that students might now ask online.
And we've been doing asynchronous Q&A for years via various mobile
or web applications and the like, but to date it has been humans,
myself included responding to all of those questions.
Now the duck has an opportunity to chime in generally within three seconds
because we've integrated into an online Q&A tool that students in CS50
and elsewhere across Harvard have long used.
So here's an anonymized screenshot of a question from an actual student
but written here as John Harvard who asked this summer in the summer version
of CS50, what is flask exactly?
So fairly definitional question.
And here is what the duck spit out thanks to that architecture I described before.
I'll stipulate that this is correct, but it is mostly a definition
akin to what Google or Bing could already give you last year.
But here's a more nuanced question, for instance,
from another anonymized students.
In this question here, the students including an error message
that they're seeing, they're asking about that
and they're asking a little more broadly and qualitatively
is there a more efficient way to write this code?
A question that really is best answered based on experience.
Here, I'll stipulate that the duck responded with this answer, which
is actually pretty darn good.
Not only responding in English, but with some sample starter code that
would make sense in this context.
And at the bottom, it's worth noting because none of this technology
is perfect just yet.
It's still indeed very bleeding edge.
And so what we have chosen to do within CS50 is include disclaimers like this.
I am an experimental bot, quack.
Do not assume that my reply is accurate unless you see that it's been
endorsed by humans, quack.
And in fact, at top right, the mechanism we've been using in this tool
is usually within minutes a human, whether it's a teaching fellow,
course assistant or myself.
We'll click on a button like this to signal to our human students
that yes, the duck is spot on here or we have an opportunity as always
to chime in with our own responses.
Frankly, that disclaimer, that button will soon, I do think,
go away as the software gets better and better.
But for now, that's how we're modulating exactly what students' expectations
might be when it comes to correctness or incorrectness.
It's common to in programming to see a lot of error messages, certainly
when you're learning first hand.
A lot of these error messages are cane, confusing, certainly to students
versus the people who wrote them.
Soon students will see a box like this.
Whenever one of their terminal window programs errs,
they'll be assisted too with English-like, TF-like support
when it comes to explaining what it is that went wrong with that command.
And ultimately, what this is really doing for students in our own experience
already is providing them really with virtual office hours and 24-7,
which is actually quite compelling in a university environment
where students' schedules are already tightly packed,
be it with academics, the curriculars, athletics, and the like.
And they might have enough time to dive into a homework assignment,
maybe eight hours even, for something sizable.
But if they hit that wall a couple of hours in, yeah, they can go to office hours
or they can ask a question asynchronously online.
But it's really not optimal in the moment support
that we can now provide all the more effectively we hope through software as well.
So if you're curious, even if you're not a technophile yourself,
anyone on the internet can go to cs50.ai and experiment with this user interface.
This one here actually resembles ChachiPT itself, but it's specific to CS50.
And here, again, is just a sequence of screenshots
that I'll stipulate for today's purposes are pretty darn good in akin to what I,
myself, or a teaching fellow would reply to in answer to a student's question,
in this case, about their particular code.
And ultimately, it's really aspirational.
The goal here ultimately is to really approximate a one-to-one teacher-to-student ratio,
which despite all of the resources we within CS50,
we within Harvard and places like Yale have,
we certainly have never had enough resources to approximate what might really be ideal,
which is more of an apprenticeship model, a mentorship,
whereby it's just you and that teacher working one on one.
Now we still have humans, and the goal is not to reduce that human support,
but to focus it all the more consciously on the students who would benefit most
from some impersonal one-to-one support versus students who would happily take it
at any hour of the day more digitally via online.
And in fact, we're still in the process of evaluating just how well or not well
all of this works, but based on our summer experiment alone with about 70 students
a few months back, one student wrote us at term's end,
it felt like having a personal tutor.
I love how AI bots will answer questions without ego and without judgment,
generally entertaining even the stupidest of questions
without treating them like they're stupid.
It has an, as one could expect ironically,
an inhuman level of patience.
And so I thought that's telling as to how even one student is perceiving
these new possibilities.
So let's consider now more academically what it is that's enabling those kinds of tools,
not just within CS50, within computer science,
but really the world more generally,
what the whole world's been talking about is generative artificial intelligence,
AI that can generate images, generate text,
and sort of mimic the behavior of what we think of as human.
So what does that really mean?
Well, let's start really at the beginning.
Artificial intelligence is actually a technique,
a technology, a subject that's actually been with us for some time,
but it really was the introduction of this very user friendly interface
known as chat GPT and some of the more recent academic work
over really just the past five or six years
that really allowed us to take a massive leap forward.
It would seem technologically as to what these things can now do.
So what is artificial intelligence?
It's been with us for some time,
and it's honestly so omnipresent that we sort of take it for granted nowadays.
A Gmail outlook had gotten really good at spam detection.
If you haven't checked your spam folder in a while,
that's testament to just how good they seem to be at getting it out of your inbox.
Handwriting recognition has been with us for some time.
I daresay it too is only getting better and better
the more the software is able to adapt to different handwriting styles such as this.
Recommendation histories and the like,
whether using Netflix or any other service,
have gotten better and better at recommending things you might like
based on things you have liked
and maybe based on things other people who like the same thing as you might have liked.
And suffice it to say, there's no one at Netflix,
akin to the old like VHS stores of yesteryear
who are recommending to you specifically what movie you might like.
And there's no code, no algorithm that says if they like X, then recommend Y.
Elts recommend Z because there's just too many movies,
too many people, too many different tastes in the world.
So AI is increasingly sort of looking for patterns
that might not even be obvious to us humans
and dynamically figuring out what might be good for me,
for you or you or anyone else.
Siri, Google Assistant, Alexa,
any of these voice recognition tools that are answering questions that too,
suffice it to say, is all powered by AI.
But let's start with something a little simpler than any of those applications.
And this is one of the first arcade games from yesteryear known as Pong.
And it's sort of like table tennis in person on the left
can move their paddle up and down.
Personal on the right can do the same.
And the goal is to get the ball past the other person
or conversely, make sure it hits your paddle and bounces back.
Well, somewhat simpler than this in so far as it can be one player
is another Atari game from yesteryear known as Breakout,
whereby you're essentially just trying to bang the ball against the bricks
to get more and more points and get rid of all of those bricks.
But all of us in this room probably have a human instinct
for how to win this game or at least how to play this game.
For instance, if the ball pictured here back in the 80s
as a single red dot just left the paddle pictured here is a red line,
where is the ball presumably going to go next?
And in turn, which direction should I slide my paddle to the left or to the right?
So presumably to the left.
And we all have an eye for what seemed to be the digital physics of that.
And indeed, that would then be an algorithm, sort of step by step
instructions for solving some problem.
So how can we now translate that human intuition to what we describe more
as artificial intelligence, not nearly as sophisticated
as those other applications, but will indeed start with some basics?
You might know from economics or strategic thinking or computer science
this idea of a decision tree that allows you to decide
should I go this way or this way when it comes to making a decision?
So let's consider how we could draw a picture to represent
even something simplistic like breakout.
Well, if the ball is left of the paddle is a question or a Boolean expression,
I might ask myself in code.
If yes, then I should move my paddle left, as most everyone just said.
Else, if the ball is not left of paddle, what do I want to do?
Well, I want to ask a question.
I don't want to just instinctively go right.
I want to check is the ball to the right of the paddle.
And if yes, well, then yes, go ahead and move the paddle right.
But there is a third situation, which is right.
Don't move.
It's coming right at you.
So that would be the third scenario here.
No, it's not to the right or to the left.
So just don't move the paddle.
You got lucky and it's coming, for instance, straight down.
So breakout is fairly straightforward when it comes to an algorithm.
And we can actually translate this, as any CS50 student now could,
to code or pseudocode, English-like code that's independent of Java, C, C++,
and all of the programming languages of today.
So in English, pseudocode, while a game is ongoing,
if the ball is left of paddle, I should move paddle left.
Else, if ball is right of the paddle, this should say paddle, that's a bug,
not intended today, move paddle right.
Else, don't move the paddle.
So that, too, represents a translation of this intuition
to code that's very deterministic.
You can sort of anticipate all possible scenarios, capture it in code.
And frankly, this should be the most boring game of breakout
because the paddle should just perfectly play this game,
assuming there's no variables or randomness when it comes to speed or angles
or the like, which real world games certainly try to introduce.
But let's consider another game from yesteryear that you might play with your kids today
or you did yourself growing up.
Here's tic-tac-toe.
And for those unfamiliar, the goal is to get three O's in a row
or three X's in a row vertically, horizontally, or diagonally.
So suppose it's now X's turn.
If you've played tic-tac-toe, most of you probably just
have an immediate instinct as to where X should probably go so that it doesn't
lose instantaneously.
But let's consider, in the more general case, how do you solve tic-tac-toe?
Frankly, if you're in the habit of losing tic-tac-toe,
but you're not trying to lose tic-tac-toe, you're actually playing it wrong.
Like you should minimally be able to always force a tie in tic-tac-toe.
And better yet, you should be able to beat the other person.
So hopefully, everyone now will soon walk away with this strategy.
So how can we borrow inspiration from those same decision trees
and do something similar here?
So if you, the player, ask yourself, can I get three in a row on this turn?
Well, if yes, then you should do that and play the X in that position.
Play in the square to get three in a row, straightforward.
If you can't get three in a row in this turn,
you should ask another question.
Can my opponent get three in a row in their next turn?
Because then you better preempt that by moving into that position.
Play in the square to block opponent three in a row.
What if, though, that's not the case?
What if there aren't even that many Xs and O's on the board?
If you're in the habit of just kind of playing randomly,
like your mate might not be playing optimally as a good AI could.
So if no, it's kind of a question mark.
In fact, there's probably more to this tree because we could think through,
what if I go there?
Wait a minute, what if I go there or there or there?
You can start to think a few steps ahead as a computer
could do much better even than us humans.
So suppose, for instance, it's O's turn.
Now, those of you who are very good at tic-tac-toe might have an instinct for where to go.
But this is an even harder problem, it would seem.
I could go in eight possible places if I'm O.
But let's try to break that down more algorithmically as an AI would.
And let's recognize, too, that with games in particular,
one of the reasons that AI was so early adopted in these games,
playing the CPU, is that games really lend themselves
to defining them if taking the fun out of it mathematically,
defining them in terms of inputs and outputs, maybe paddle moving left or right,
ball moving up or down.
You can really quantize it at a very boring low level,
but that lends itself then to solving it optimally.
And in fact, with most games, the goal
is to maximize or maybe minimize some math function.
Most games, if you have scores, the goal
is to maximize your score and indeed get a high score.
So games lend themselves to a nice translation to mathematics
and, in turn, here AI solutions.
So one of the first algorithms one might learn in a class on algorithms
and on artificial intelligence is something called Minimax, which
alludes to this idea of trying to minimize and or maximize something
as your function, your goal.
And it actually derives inspiration from these same decision trees
that we've been talking about, but first the definition.
Here are three representative tic-tac-toe boards.
Here is one in which O has clearly won per the green.
Here is one in which X has clearly won per the green.
And this one in the middle just represents a draw.
Now, there's a bunch of other ways that tic-tac-toe could end,
but here's just three representative ones.
But let's make tic-tac-toe even more boring
that it might have always struck you as.
Let's propose that this kind of configuration
should have a score of negative 1.
If O wins, it's a negative 1.
If X wins, it's a positive 1.
And if no one wins, we'll call it a 0.
We need some way of talking about and reasoning
about which of these outcomes is better than the other
and what's simpler than 0, 1, and negative 1.
So the goal, though, of X, it would seem, is to maximize its score,
but the goal of O is to minimize its score.
So X is really trying to get positive 1.
O is really trying to get negative 1.
And no one really wants 0, but that's better than losing
to the other person.
So we have now a way to define what it means to win or lose.
Well, now we can employ a strategy here.
Here, just as a quick check, what would the score be of this board?
Just so everyone's on the same page?
Or so 1, because X has won and we just stipulated arbitrarily,
this means that this board has a value of 1.
Now let's put it into one more interesting context.
Here, a game has been played for a few moves already.
There's two spots left.
No one has won just yet, and suppose that it's O's turn now.
Now everyone probably has an instinct already as to where to go,
but let's try to break this down more algorithmically.
So what is the value of this board?
Well, we don't know yet, because no one has won.
So let's consider what could happen next.
So we can draw this actually as a tree as before.
Here, for instance, is what might happen
if O goes into the top left-hand corner.
And here's what might happen if O goes into the bottom middle spot instead.
We should ask ourselves, what's the value of this board?
What's the value of this board?
Because if O's purpose in life is to minimize its score,
it's going to go left or right based on whichever
yields the smallest number, negative 1, ideally.
But we're still not sure yet, because we don't have definitions for boards
with holes in them like this.
So what could happen next here?
Well, it's obviously going to be X's turn next.
So if X moves, unfortunately, X has won in this configuration.
We can now conclude that the value of this board is what number?
So 1, and because there's only one way to reach this board by transitivity,
you might as well think of the value of this previous board as also 1,
because no matter what, it's going to lead to that same outcome.
And so the value of this board is actually still to be determined,
because we don't know if O's going to want to go with the 1,
and probably not, because that means X wins.
But let's see what the value of this board is.
Well, suppose that indeed X goes in that top left corner here.
What's the value of this board here?
Zero, because no one has won.
There's no X's or O's three in a row.
So the value of this board is zero.
There's only one way logically to get there.
So we might as well think of the value of this board as also zero.
And so now, what's the value of this board?
Well, if we started the story by thinking about O's turn,
O's purpose is the min in minimax, then which move is O going to make?
Go to the left or go to the right?
O's probably going to go to the right and make the move that leads to this board,
because even though O can't win in this configuration, at least X didn't win.
So it's minimized its score relatively, even though it's not a clean win.
Now, this is all fine and good for a configuration of the board that's almost done.
There's only two moves left, the game's about to end.
But if you kind of expand in your mind's eye,
how did we get to this branch of the decision tree?
If we rewind one step where there's three possible moves,
frankly, the decision tree is a lot bigger.
If we run further in your mind's eye and have four moves left or five moves
or all nine moves left, imagine just zooming out, out and out.
This is becoming a massive, massive tree of decisions.
Now, even so, here is that same sub tree, the same decision tree we just looked at.
This is the exact same thing, but I shrunk the font
so that it appears here on the screen here.
But over here, we have what could happen if instead, it's actually X's turn
because we're once moved prior, there's a bunch of different moves X could now make too.
So what is the implication of this?
Well, most humans are not thinking through tic-tac-toe to this extreme.
And frankly, most of us probably just don't have the mental capacity
to think about going left and then right and then left and then right.
This is not how people play tic-tac-toe.
We're not using that much memory, so to speak.
But a computer can handle that, and computers can play tic-tac-toe optimally.
So if you're beating a computer at tic-tac-toe, it's not implemented very well.
It's not following this very logical deterministic minimax algorithm.
But this is where now AI is no longer as simple as just doing what these decision trees say.
In the context of tic-tac-toe, here's how we might translate this to code, for instance.
If player is X, for each possible move, calculate a score for the board,
as we were doing verbally, and then choose the move with the highest score,
because X's goal is to maximize its score.
If the player is O, though, for each possible move,
calculate a score for the board, and then choose the move with the lowest score.
So that's a distillation of that verbal walkthrough into what CS50 students know now as code,
or at least pseudocode.
But the problem with games, not so much tic-tac-toe, but other more sophisticated games is this.
Does anyone want to ballpark how many possible ways there are to play tic-tac-toe?
Paper pencil, two human children, how long could you keep them occupied playing tic-tac-toe
in different ways?
If you actually think through how big does this tree get,
how many leaves are there on this decision tree?
Like how many different directions?
Well, if you're thinking 255,168, you are correct.
And now most of us in our lifetime have probably not played tic-tac-toe
that many times, so think about how many games you've been missing out on.
There are different decisions you could have been making all these years.
Now that's a big number, but honestly, that's not a big number for a computer.
That's a few megabytes of memory maybe to keep all of that in mind and implement
that kind of code in C, or Java, or C++, or something else.
But other games are much more complicated.
And the games that you and I, my play as we get older, include maybe chess.
And if you think about chess with only the first four moves, back and forth,
four times, so only four moves.
That's not even a very long game.
Anyone want to ballpark how many different ways there
are to begin a game of chess with four moves back and forth?
This is evidence as to why chess is apparently so hard.
288 million ways, which is why when you are really good at chess,
you are really good at chess, because apparently you either have an intuition for or a mind for thinking
it would seem so many more steps ahead than your opponent.
And don't get us started on something like Go.
266 quintillion ways to play Go's first four moves.
So at this point, we just can't pull out our Mac, our PC, certainly not our phone,
to solve optimally games like chess and Go, because we don't have big enough CPUs.
We don't have enough memory.
We don't have enough years in our lifetimes for the computers
to crunch all of those numbers, and thus was born a different form of AI
that's more inspired by finding patterns more dynamically,
learning from data, as opposed to being told by humans,
here is the code via which to solve this problem.
So machine learning is a subset of artificial intelligence
that tries instead to get machines to learn what they should do
without being so coached step by step by step by humans here.
Reinforcement learning, for instance, is one such example thereof,
wherein reinforcement learning, you sort of wait for the computer or maybe a robot
to maybe just get better and better and better at things.
And as it does, you reward it with a reward function.
Give it plus one every time it does something well, and maybe minus one.
You punish it any time it does something poorly.
And if you simply program this AI or this robot to maximize its score,
never mind minimizing, maximize its score, ideally it should repeat behaviors
that got it plus one.
It should decrease the frequency with which it does bad behaviors that got it
negative one, and you can reinforce this kind of learning.
In fact, I have here one demonstration.
Could a student come on up who does not think they are particularly coordinated?
OK, wow, you're being nominated by your friends.
Come on up, come on up.
Their hands went up instantly for you.
OK, what is your name?
My name is Amaka.
Amaka, do you want to introduce yourself to the world?
Hi, my name is Amaka.
I am a first year in Hallworthy, planning to concentrate in CS.
Wonderful.
Nice to see you.
Come on over here.
So, yes, oh no, it's sort of like a game show here.
We have a pan here with what appears to be something pancake-like.
And we'd like to teach you how to flip a pancake so that when you gesture upward,
the pancake should flip around so you cook the other side.
So we're going to reward you verbally with plus one or minus one.
Minus one.
Minus one.
OK, plus one.
Plus one, so do more of that.
Minus one.
Minus one.
Minus one.
Do less of that.
Minus one.
Do less of that.
All right, a big round of applause.
Thank you.
We've been in the habit of handing out Super Mario Brothers Oreos this year.
So thank you for participating.
So this is actually a good example of an opportunity for reinforcement learning
and wonderfully a researcher has posted a video that we thought we'd share.
It's about a minute and a half long where you can watch a robot now do exactly what our wonderful human volunteer here just attempted as well.
So let me go ahead and play this on the screen and give you a sense of what the human and the robot are doing together.
So their pancake looks a little similar there.
The human here is going to first sort of train the robot what to do by showing it some gestures.
But there's no one right way to do this.
But the human seems to know how to do it pretty well in this case.
And so it's trying to give the machine examples of how to flip a pancake successfully.
But now this is the very first trial.
OK, look for me.
You're in good company.
After three trials.
OK.
Now 10.
There's the human picking up the pancake.
After 11 trials.
And meanwhile there's presumably a human coding this in the sense that someone is saying good job or bad job plus one or minus one.
20 trials.
Here now we'll see how the computer knows what it's even doing.
There's just a mapping to some kind of like XYZ coordinate system so the robot can quantize what is it's doing.
Nice to do more of one thing less of another.
And you're just seeing a visualization in the background of those digitized movements.
And so now after 50 some odd trials the robot to has got its spot on and it should be able to repeat this again and again and again in order to keep flipping this pancake.
So our human volunteer wonderfully took you even fewer trials.
But this is an example then to be clear of what we'd call reinforcement learning whereby you're reinforcing a behavior you want or negatively reinforcing.
That is punishing a behavior that you don't.
Here's another example that brings us back into the realm of games a little bit.
But in a very abstract way if we were playing a game like the floor is lava where you're only supposed to step certain places so that you don't fall through in the lava pit or something like that and lose a point or lose a life.
Each of these squares might represent a position.
This yellow dot might represent the human player that can go up down left or right within this world.
I'm revealing to the whole audience where the lava pits are.
But the goal for this yellow dot is to get to green.
But the yellow dot as in any good game does not have this bird's eye view and knows from the get go exactly where to go.
It's going to have to try some trial and error.
But if we the programmers maybe reinforce good behavior or punish bad behavior we can sort of teach this yellow dot without giving it step by step up down left right instructions what behaviors to repeat and what behaviors not to repeat.
So for instance suppose the robot moves right.
That was bad.
You fell in the lava already.
So we'll use a bit of computer memory to sort of draw a thicker red line there.
Don't do that again.
So negative one so to speak.
Maybe the yellow dot moves up next time.
We can reward that behavior by not drawing any walls and allowing it to go again.
It's making pretty good progress.
But oh darn it.
It took a right turn and now fell into the lava.
But let's use a bit more of the computer's memory and keep track of that.
Okay.
Do not do that thing anymore.
Maybe the next time the human dot goes this way.
Oh we want to punish that behavior.
So we'll remember as much with that red line.
But now we're starting to make progress until now we hit this one.
And eventually even though the yellow dot much like our human much like our pancake flipping robot had to try again and again and again after enough trials it's going to start to realize what behaviors it should repeat and which ones it shouldn't.
And so in this case maybe it finally makes its way up to the green dot.
And just to recap once it finds that path now we can sort of remember it forever as with these green thicker lines.
Anytime you want to leave this map anytime you get really good at the Nintendo game you'll follow that same path again and again so you don't fall into the lava.
But an astute human observer might realize that yes this is correct.
It's getting out of this so-called maze.
But what is suboptimal or bad about this solution?
Sure.
Exactly it's taking a really long time and inefficient way to get there because I dare say if we just try to different path occasionally maybe we could get lucky and get to the out the exit quicker and maybe that means we get a higher score we get rewarded even more.
So within a lot of artificial intelligence algorithms there's this idea of exploring versus exploiting whereby you should occasionally yes exploit the knowledge you already have.
In fact frequently exploit that knowledge but occasionally you know what you should probably do is explore just a little bit.
Take a left instead of a right and see if it leads you to the solution even more quickly and you might find a better and better solution.
So here mathematically is how we might think of this.
10% of the time we might say that epsilon just some variable sort of a sprinkling of salt into the algorithm here epsilon will be like 10% of the time.
So if my robot or my player picks a random number that's less than 10% that's going to make a random move go left instead of right even if you really typically go right.
Otherwise make the move with the highest value as we've learned over time and what the robots might learn then is that we could actually go via this path which gets us to the output faster.
We get a higher score we do it in less time it's a win win.
Frankly this really resonates with me because I've been in the habit as maybe some of you are when you go to a restaurant maybe that you really like you find a dish you really like.
I will never again know what other dishes that restaurant offers because I'm sort of locally optimally happy with the dish I've chosen and I will never know if there's an even better dish at that restaurant.
Unless again I sort of sprinkle a little bit of epsilon a little bit of randomness into my game playing my dining out.
The catch of course though is that I might be punished I might therefore sort of be less happy if I pick something and I don't like it.
So there's this tension between exploring and exploiting but in general in computer science and especially in AI adding a little bit of randomness especially over time can in fact yield better and better outcomes.
But now there's this notion all the more of deep learning whereby you're trying to infer to detect patterns figure out how to solve problems even if the AI has never seen those problems before.
And even if there's no human there to reinforce positive or negatively behavior maybe it's just too complex of a problem for human to stand alongside the robot and say good or bad job.
So with deep learning they're actually very much related to what you might know as neural networks inspired by human physiology whereby inside of our brains and elsewhere in our brain there's lots of these neurons here that can send electrical signals to sort of make movements happen from brain to extremities.
You might have two of these via which signals can be transmitted over larger distance.
And so computer scientists for some time have drawn inspiration from these neurons to create in software what we call neural networks whereby there's inputs to these networks and there's outputs from these networks that represents inputs to problems and solutions there too.
So lemme abstract away the more biological diagrams with just circles that represent nodes or neurons in this case.
This would be would call in CS50 the input.
This is what we would call the output.
But this is very simplistic very simple neural network.
This might be more common whereby the network the AI takes two inputs to a problem and tries to give you one solution.
Well let's make this more real.
For instance suppose that just for the sake of discussion here is like a grid that you might see in math class with a y axis and an x axis vertically and horizontally respectively.
Suppose there's a couple of blue and red dots in that world and suppose that our goal computationally is to predict whether a dot is going to be blue or red based on its position within that coordinate system.
And maybe this represents some real world notion maybe it's something like rain that we're trying to predict but we're doing it more simply with colors right now.
So here's my y axis, here's my x axis and effectively my neural network you can think of conceptually as this.
It's some kind of implementation of software where there's two inputs to the problem.
Give me an x, give me a y value and this neural network will output red or blue as its prediction.
Well how does it know whether to predict red or blue especially if no human has painstakingly written code to say when you see a dot here conclude that it's red.
When you see a dot here conclude that it's blue how can an AI just learn dynamically to solve problems?
Well what might be a reasonable heuristic here?
Honestly this is probably a first approximation that's pretty good.
If anything's to the left of that line let the neural network conclude that it's going to be blue and if it's to the right of the line let it conclude that it's going to be red.
Until such time as there's more training data, more real world data that gets us to rethink our assumptions.
So for instance if there's a third dot there clearly a straight line is not sufficient.
So maybe it's more of a diagonal line that splits the blue from the red world here.
Meanwhile here's even more dots and it's actually getting harder now like this line is still pretty good.
Most of the blue is up here.
Most of the red is down here and this is why if we fast forward to today you know AI is often very good but not perfect.
At solving problems.
But what is it we're looking at here and what is this neural network really trying to figure out?
Well again at the risk of taking some fun out of red and blue dots you can think of this neural network as indeed having these neurons which represent inputs here and outputs here.
And then what's happening inside of the computer's memory is that it's trying to figure out what the weight of this arrow or edge should be.
What the weight of this arrow or edge should be and maybe there's another variable there like plus or minus C that just tweaks the prediction.
So X and Y are literally going to be numbers in this scenario and the output of this neural network ideally is just true or false.
Is it red or blue?
So it's sort of a binary state as we discuss a lot in CS50.
So here too to take this sort of fun out of the pretty picture it's really just like a high school math function with the neural network in this example is trying to figure out is what formula of the form AX plus C.
Plus by plus C is going to be arbitrarily greater than zero.
And if so let's conclude that the dot is red if you get back a positive result.
If you don't let's conclude that the dot is going to be blue instead.
So really what you're trying to do is figure out dynamically what numbers do we have to tweak these parameters inside of the neural network that just give us the answer we want based on all of this data.
More generally though this would be really meant representative of deep learning.
It's not as simple as input input output.
There's actually a lot of these nodes.
These neurons.
There's a lot of these edges.
There's a lot of numbers and math are going on that frankly even the computer scientists using these neural networks don't necessarily know what they even mean or represent.
It just happens to be that when you crunch the numbers with all of these parameters in place you get the answer that you want at least most of the time.
So that's essentially the intuition behind that.
And you can apply it to very real world if mundane applications given today's humidity given today's pressure yes or no should there be rainfall.
And maybe there is some mathematical function that based on years of training data we can infer what that prediction should be another one given this amount of advertising in this amount of month in this month.
What should our sales be for that year should they be up or should they be down sorry for that particular month.
So real world problems map readily when you can break them down into inputs and a binary output often or some kind of output where you want the thing to figure out based on past data what its prediction should be.
So that brings us back to generative artificial intelligence which isn't just about solving problems but really generating literally images texts even videos that again increasingly resemble what we humans might otherwise output ourselves.
And within the world of generative artificial intelligence do we have of course the same images that we saw before the same text that we saw before and more generally things like chat GPT which are really examples of what we now call large language models.
These sort of massive neural networks that have so many inputs and so many neurons implemented in software that essentially represent all of the patterns that the software has discovered by being fed massive amounts of input.
Think of it as like the entire textual content of the Internet.
Think of it as the entire content of courses like CS50 that may very well be out there on the Internet.
And even though these AIs these large language models haven't been told how to behave they're really inferring from all of these examples for better or for worse how to make predictions.
So here for instance from 2017 just a few years back is a seminal people from Google that introduced what we now known as a transformer architecture and this introduced this idea of attention values whereby they propose that given an English sentence for instance or really any human sentence.
You try to assign numbers not unlike our past exercises to each of the words each of the input that speaks to its relationship with other words.
There's a high relationship between two words in a sentence.
They would have high attention values and if maybe it's a preposition or an article like the or the like maybe those attention values are lower and by encoding the world in that way do we begin to detect patterns that allow us to predict things like words that is generate text.
So for instance up until a few years ago completing this sentence was actually pretty hard for a lot of AI.
So for instance here Massachusetts is a state in the New England region of the northeastern United States.
It borders on the Atlantic Ocean to the east.
The state's capital is dot dot dot.
Now you should think that this is relatively straightforward.
It's like just handing you a softball type question.
But historically within the world of AI this word state was so relatively far away from the proper noun that it's actually referring back to that we just didn't have computational models that sort of took in that holistic picture that frankly
we humans are much better at.
If you would ask this question a little more quickly a little more immediately you might have gotten a better response.
But this is dare say why chat bots in the past have been so bad in the form of customer service and the like because they're not really taking all of the context into account that we humans might be inclined to provide.
What's going on underneath the hood without escalating things too quickly.
What in what in artificial intelligence nowadays these large language models might do is sort of break down the user's input your input into chachi chachi pt into the individual words.
We might then encode.
We might then take into account the order of those words Massachusetts is first is is last.
We might further encode each of those words using a standard way and there's different algorithms for this but you come up with what are called embeddings.
That is to say you can use one of those apis I talked about earlier or even software running on your own computers to come up with a mathematical representation of the word Massachusetts.
And rungsyn kindly did this for us last night.
This is the 1536 floating point values that open AI uses to represent the word Massachusetts.
And this is to say and you should not understand anything you are looking at on the screen nor do I.
But this is now a mathematical representation of the input that can be compared against the mathematical representations of other inputs in order to find proximity semantically words that somehow have relationships or correlations with each other.
That helps the AI ultimately predict what should the next word out of its mouth be so to speak.
So in a case like this these values represent these lines represent all of those attention values and thicker lines means there's more attention given from one word to another.
Thinner lines mean the opposite and those inputs are ultimately fed into a large neural network where you have inputs on the left outputs on the right and in this particular case the hope is to get out a single word which is the capital of Boston itself.
Whereby somehow the neural network and the humans behind it at open AI, Microsoft, Google or elsewhere have sort of crunched so many numbers by training these models on so much data that it figured out what all of those weights are, what the biases are so as to influence mathematically the output there from.
So that is all underneath the hood of what students now perceive as this adorable rubber duck but underneath it all is certainly a lot of domain knowledge and CS50 by nature being open courseware for the past many years.
CS50 is fortunate to actually be part of the model as might be any other content that's freely available online and so that certainly helps benefit the answers when it comes to asking CS50 specific questions.
That said, it's not perfect and you might have heard of what are currently called hallucinations where chat GP chat GP and similar tools just make stuff up and it sounds very confident and you can sometimes call it on its whereby you can say no that's not right and it will playfully apologize.
Oh, I'm sorry, but it made up some statement because it was probabilistically something that could be said even if it's just not correct.
Now, I'll allow me to propose that this kind of problem is going to get less and less frequent.
And so as the models evolve and our techniques evolve, this will be less of an issue.
But I thought it would be fun to end on a note that a former colleague shared just the other day, which was this old poem by Shel Silverstein and other something from our past childhood perhaps.
And this was from 1981, a poem called Homework Machine, which is perhaps foretold where we are now in 2023.
The Homework Machine. Oh, the Homework Machine, most perfect contraption that's ever been seen.
Just put in your homework, then drop in a dime, snap on the switch and in 10 seconds time.
Your homework comes out quick and clean as can be.
Here it is nine plus four and the answer is three.
Three.
Oh, me.
I guess it's not as perfect as I thought it would be.
So quite foretelling, sure.
Quite foretelling indeed.
Though if for all this and more, the family members in the audience are welcome to take CS50 yourself online at CS50.edex.org for all of today and so much more.
Allow me to thank Brian Rungshin, Sophie Andrew Patrick, Charlie CS50's whole team.
If you are a family member here headed to lunch with CS50's team, please look for Cameron holding a rubber duck above her head.
Thank you so much for joining us today. This was CS50.
Thank you.
