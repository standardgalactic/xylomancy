And I think one of the reasons that chat GPT and stuff have been so hyped recently is because most people don't know what it is.
And so when you see it doing what it does, you think this thing must basically be a person, right?
Because it's acting like one.
And I should carry this by saying I'm not selling short these incredible technologies.
I'm just saying that it would be very silly to just completely use them blind and never check what they do, right?
Because we know they just make stuff up a lot of the time.
I'm glad you mentioned computer science.
Do you think it's time for more of us to learn computer science type stuff because of AI, like maths and all these computer science stuff or not really?
I've been saying that you need to learn artificial intelligence or AI.
Question that a lot of you have been asking me is, okay, so how do I learn that?
So let's ask another friend.
David.
Yes.
You've mentioned this before, but remind me which place do you recommend that I learn and others learn AI?
I really like Brilliant.
It's one of those places where you can go and a visual gamified way to learn concepts and mathematics behind AI machine learning.
You've recommended this a few times to me.
The way you said it was, David, if you want to learn AI, I need to learn like statistics and stuff like that, right?
Yes, they've got these roadmaps that actually helps you with calculus and learning statistics and linear algebra, all the stuff that you need to know for AI.
I'll say this.
David is on my team, really glad that he is.
David has strengths that I don't have, and I think that's what's really important in life.
You need to learn from others.
David, well, tell us, you've done a lot of maths.
You've done a lot of computer science.
You've actually worked with AI stuff, right?
I worked in the medical field for data science stuff.
So I really think like you need to know all the statistics and calculus and linear algebra and the discrete mathematics that you need to learn,
which actually makes a lot of coding a lot easier for you.
That's brilliant.
So I'm looking on their website now.
The one that you've recommended that I go through is the data science foundations, right?
That's like probability, applied probability, statistics, fundamentals, and then an introduction to neural networks.
And obviously, me being me, I just skipped all of that.
They went straight to learning neural networks.
But as David said, what I really like about this website is it's gamified, as he said.
So really great way to get started.
Really want to thank Brilliant for sponsoring this video.
Brilliant, as they say in the UK.
Thanks.
Everyone, it's David Bombal back with Dr. Mike Pound.
Mike, welcome.
Thanks for having me back again.
Mike, it feels like the sky is falling again.
You know, we had this interview previously and it was all this hype about AI,
but it seems to just be getting hotter and hotter.
So tell me, is the sky falling?
Am I going to lose my job?
Is the future bleak?
I think I think you'll be all right.
Chill, relax.
Relax.
Um, are you just bringing me into calm everything down a bit?
That's, that's, you know, I think that the last six months particularly have been, you know,
both unbelievable in terms of genuine hype,
like things that are really exciting appearing and also obviously totally overboard hype
that's just getting really quite silly and everyone needs to calm down, right?
So I think there's a bit of everything going on.
Chat and GPT is an incredibly impressive tool that works very, very well.
I've done some really fun tests of it where I push to see what it will do.
And some of the things it will do are quite amazing, right?
On the other hand, there are lots of things it doesn't do very well.
And one of the big problems we have at the moment is it won't always tell you it's one of those things.
And that's, I think, where we have something that needs addressing.
I've done some tests and I mean, a lot of people I know have done tests
and it's amazing what it seems to be able to produce.
I think the concern a lot of people have is like, Mike, I'm 18 years old or let's say I'm older.
I want to switch careers to become a programmer or I want to get into cybersecurity
or I want to be a network engineer, whatever, some technical role.
And it feels like I'm just going to waste my time
because Chat GPT is just going to obliterate jobs.
The first thing I would observe is that it's very nice for some of these big tech companies
if that's the perception because it makes them look very, very impressive, right?
And so I think that the cynic in me a little bit is like, this is, you know,
no pay hours, bad PR kind of a situation.
They like to, you know, these tools get dropped as incredibly impressive tech demos
and I'm not selling them short, right? Very impressive.
But maybe not quite as impressive as they first appear on a service when you start to dig in.
And I think that's what's really important.
You know, in science, we spend a lot of time checking things and rechecking them.
At least that's what we're supposed to do, right?
So I, you know, a PhD student comes to my office with some results
and they say, oh, we've got 95% accuracy on some tasks.
And I think, OK, let's talk about which data you used and whether that's really true
and whether when you use it on this new data, you're going to get that same result.
And we spend ages going over and over the data again
to make sure that when we actually publish it, it's really as accurate as possible.
Large language models are maybe not operating in quite that same way.
Yes, they release papers from time to time, but mostly they release these big websites
where you can try them out and they do incredibly impressive stuff
and they lie very impressively as well, right?
I think that's the thing that we haven't quite got around.
So, you know, suppose you're a programmer and you've been using co-pilot
and you've been using chat GPT also does code and you're a bit worried
because it's just producing pretty decent code.
Maybe you don't see it replacing you right now, but you could see in 10 years.
Maybe that's going to be a problem.
I think the problem is at the moment is it's very difficult to know where it's going.
I think a lot of researchers are suspicious of the idea
that we can just make it continually bigger and bigger and more impressive
and it will just get better and better.
You know, when we talked about how these models work,
they don't really have an internal model of what it is they're trying to do or anything, really.
They just map text to other texts.
You know, when I write a piece of computer code,
what I'm really hoping to do is, in my mind,
come up with an idea of the problem that needs to be solved
and what the variables and things that I'm going to need
start to get them down on paper and then start thinking about
how would I manipulate those variables using code to produce the result that I want?
Chat GPT doesn't really work that way, it just spits out code, right?
And it happens a lot of the time to look pretty good.
At the moment, it's a tool to be used quite carefully, particularly with code.
I wouldn't push anything Chat GPT has written straight into production
without, you know, quite a few tests.
Because at the moment, there's no grounding in reality, right?
The reality is for training data.
But once it's finished training, it's kind of random what it gets.
And these things actually, I don't know if you've noticed this, David,
but when you run it, it can produce different answers each time.
And that's because it uses something called temperature
to somewhat randomize its output.
So instead of saying, OK, the next word in my output is going to be there,
it will say, I think there's an 80% chance that it's there,
but there's a 20% chance that it's so.
And then what the machine will do is say, well, OK, 20% of a time,
then we'll pick a different word.
And that way, you can go in slightly different directions.
Because if you didn't do that, it will just produce the same output every time.
It's not a random object, it's not a random network in that sense.
And so you can imagine a situation where there is a really good version
of this program that it could write, but it randomly didn't
and produced one below the bugs.
So, you know, I've seen that's what I've experienced.
Yeah, and, you know, I suppose there's a question in my mind
about how is there an efficiency saving
if you have to order everything you're reading, right?
Is reading code as fast as writing code or slower or faster?
I don't know, I'm undecided.
I think sometimes the boilerplate code is probably pretty effective.
If it's a sort of code, you know, write me a for loop to do X, Y and Z,
probably works pretty well, as long as you're capable of quickly checking that.
But it didn't take me very long to write a for loop anyway.
I'm undecided, I suppose, as to how much of a game change that will be.
This said, I know there are developers that use it, right?
And I know that the developers who claim, or at least they think,
they're much more efficient.
I don't spend as much time coding as I'd like because I'm, you know,
as a professor in a university, I spend a lot of time teaching,
a lot of time mentoring others, right, and teaching people.
So they do the coding and I sit there and look at it.
So I haven't had as much experience as some.
Yeah, I mean, I think the concern is always, you know,
younger young people or people trying to switch careers is, you know,
I want to have a job for more than a year or five years.
Is it worth putting all the effort in to learn this stuff
if AI is just going to take it away?
My gut tells me that AI isn't going to take it away anytime soon, right?
Because I think that I would argue that you need something more fundamental
to understanding some of these problems.
If you're going to write code to solve them than just a text production mechanism.
That isn't to say that what it doesn't do, it's very impressive what it does.
But I think that as you start to build up, you know,
it's very, it's all very well saying, like me, a for loop to do this.
But if you want to write your class structure and a really complicated system,
that's such a more difficult, you know, it's like the difference
between lane assist and self-driving, right?
And that's why we can, we've seen lane assist exist,
but self-driving seems to be so hard to get to because of how much harder
that is as a problem.
And I think that it's very easy to fit a straight line upwards to these things, right?
You say, well, they didn't do anything and now they're doing this,
which means they're going to be doing this.
It may get a lot harder and plateau out, right?
We, you know, it's difficult to say for sure.
I think that there's going to be a very strong need for people in the loop
for a long, for a long time, right?
I mean, as an example, outside of programming in medical science,
AI is obviously used quite a lot to help with diagnosis and things.
But almost no AI systems are used just on their own with no human oversight
because for a start, because we don't trust them yet,
and also because patients don't trust them.
Patients don't want an AI, even if it's good, making their health decisions, right?
Like, not yet, you know?
And so I think also culturally, we're not quite ready.
And I know a few companies that are not using co-pilot
because they're not absolutely sure of the copyright on the code and think, you know,
there's questions that haven't been answered.
I think if you're looking for it to be a software developer,
you're looking for a career in security or career in AI,
there's still plenty of things to do.
So I wouldn't personally worry about that.
I think we mentioned this last time,
and I want to give people firstly, you know, a way to make themselves more valuable
and then a path to get there.
You mentioned that, you know, if you attach AI to any skill that you've got,
it's going to make you more valuable.
I assume that's still the case.
And then I want to ask you, Mike, how do I get there?
And it also makes you more experienced at dealing with things like this.
When something comes along, you can sit back and you can say,
OK, how impressive is this?
Let's think about what it's doing and how it works.
And, you know, some understanding of how these things work,
you don't have to understand deep down, transformer networks
if you want to understand roughly what they're doing and how they've been trained.
Yeah, I would say some knowledge of statistical analysis and data,
data processing in general is really, really important, right?
People mock Excel.
Excel is, I think, one of the best products ever written.
It's totally ubiquitous.
It's very powerful and it underpins the huge amounts of, you know,
financial systems and other systems.
I use it all the time for student marks, right?
So, you know, you get a table of data that comes in
and it doesn't make any sense what we're going to look at,
how we're going to deal with this, right?
And how we're going to make decisions based on this data.
And things like data science and machine learning
will help you deal with some of these problems.
People who want to become experts in AI,
obviously need to delve a bit deeper.
But I think for a lot of people,
AI can just solve small problems in your pipeline
that might make things a little bit easier.
Having that extra string in your bow is not a terrible idea.
So, in the previous videos, I told people you need to learn AI
and it's something that I want to really focus on this year.
And this is why I'm talking to you,
you know, right in the beginning of the year.
Have you got like courses, places that I can go to,
books that I can read, any recommendations of how do I go from like
where I am now, zero knowledge to at least, you know,
getting down that path to be able to put it on my resume.
There's loads of books and resources in Python
to learn machine learning and data science.
And that would be a great place to start.
You know, I've said it before many times,
I have a love-hate relationship with Python.
I like it sometimes and I don't like it other times.
At the end of the day, there are libraries in Python
that do quite incredible machine learning
and make your life a lot easier, right?
So we've got things like scikit-learn,
we've got TensorFlow and PyTorch, of course.
But there are tutorials and books written around these things
and they take you from, I don't know what this network is,
to I can actually get one of these networks running on a machine.
And it's often not that much code.
Because of these libraries do a lot of heavy lifting for you,
often it becomes more plug-in building books together
than it does writing neural network layers from scratch,
which we don't do anymore.
You know, so you can start by just plugging some things together
and I've got a rudimentary network
that I don't really understand that's doing this classification.
And before long, you've made your classification problem
a little bit more complicated
and you've got multi-class classification.
And then you've got a slightly different data set
and then you've solved a data augmentation problem
and you can add these things in
and slowly work towards a bit more experience.
You know, I have a number of undergraduate project students every year.
So in university, in the third year, you often do a dissertation,
which is like a focused project over a whole year.
Often most of my dissertation projects are going to be on AI
and something like this.
And these are students who've done some machine learning,
maybe a little bit in their modules throughout their undergraduate
and they know how to code.
But a lot of it's new, you know, we pick it up and we run with it
and we do some great stuff.
I've got some students in the second year solving Rubik's cubes,
using machine learning to detect where the colors are and things like this.
And this is from scratch, right?
So this is people who haven't done machine learning before
and I can point them in the right direction.
I think it is very doable and I think it's fun as well, right?
There's nothing more satisfying to me than you've trained a network
and it's just classifying really accurately whatever it was you wanted to do.
Basically, my job is looking at numbers go up and I like when they go up.
So Mike, I mean, I'd love to come to Nottingham University and attend your courses,
but obviously I can't and so can, you know, most of us can't.
Do you have any like resources or ideas that places I can go to to learn?
Often the first course I recommend for everyone is to take Andrew Ung's Coursera course, right?
Very popular.
I mean, I don't know how many times it's been taken now, millions of times.
It's Andrew Ung's course, a Coursera course on machine learning.
There is a deep learning follow-up to it, which I haven't done
because partly I actually already know deep learning,
but the machine learning course is really good.
It's a good understanding of some of the key concepts in machine learning
and not specifically about it.
Yes, a little bit about how new networks work and things like this
and it can be a little bit mathematical is my experience of it.
But if you watch it anyway, you're going to pick up a lot of tips and tricks.
So things like watching your network train over time
and reacting to how that works and doesn't work
and making decisions based on this.
These are the things really I think that people who want to do machine learning
in an applied way, in a business or in an industry,
that's what they need to be able to do.
A lot of them are not going to be writing new networks from scratch
or designing the number of layers in your network.
They're going to take a network that we know works and run it on some new data.
And if that works great the first time, then that's fabulous.
But if it doesn't, what do you do then?
And these are things that you're going to learn and start learning that Coursera course.
Joshua Bengio and others have written a book just called Deep Learning,
which is very popular.
Again, obviously it can go into a little bit of heavy math detail,
but it's very popular.
I would say don't read it end to end.
It's one to dip into while you're doing some tutorials
to understand a bit more about the theory.
And after that personally, I would do the PyTorps tutorials
or the psychic learn tutorials.
They can be directed at your own pace
and they will give you experience in all those different things.
There's tutorials on things like reinforcement learning,
but also just standard CNNs and transformers and things like this.
And don't worry about, you don't have to do all of those on day one.
On day one, we're talking about what is classification,
what is regression, maybe get something little going.
Really start yourself off nice and slow
and build up the complexity as we go.
It's the same with any subject in computer science.
You can't learn everything on the first day,
so you just have to take it a little bit at a time.
I'm glad you mentioned computer science.
Do you think it's time for more of us to learn computer science type stuff
because of AI like maths and all these computer science stuff and not really?
I think that it's not necessary for everyone to do that.
I think that I would encourage everyone to do computer science,
of course I would.
But I think that sometimes both computer science and industry
have a sort of reverse snobby about each other, right?
Which I don't really like very much.
So for example, computer scientists might say,
well, if someone didn't do a degree,
you know, what do we really know about computers, right?
Which is not true.
And someone who's got on fine without a degree might go,
why will I go and get student loans and do a degree?
And different paths are all valid.
I don't know why we're having this conversation, right?
And I think there are elements of maths and machine learning
which help, I suppose, me to understand it a bit better
when someone comes with a particularly weird problem
that they've added another layer and it's not training.
Why is that?
They also help me sometimes when I'm reading papers
because papers, they can have a lot of mathematical notation in
and sometimes that's not necessary and they've just added it in.
But often it's just to be absolutely clear
about what they've done.
And often the mathematical notation is necessary to achieve that
rather than writing it in sort of flavourful text.
But to begin with machine learning,
you don't necessarily need to know those things.
You know, you can train a network in PyTorch
with a knowledge, a rudimentary knowledge of Python
and following some tutorials
and you'll pick up the rest as you go.
The really complicated maths like back propagation,
which is how we train it,
that's all taken care of under the hood.
You don't see that.
It's not something, unless you're really interested,
it's not something to concern yourself with.
But I mean, the great thing is if I'm in industry
or I'm into cyber or dev or whatever,
I can really enhance my career prospects
and the future by just adding this on to my skills.
Yeah, and I also think that, and I mentioned it before,
I think the other thing is,
it makes you much more resistant to hype
and to concerns over things.
And also, when someone comes to you and says,
oh yeah, I've trained a neural network to do X, Y and Z,
you can start to think,
doesn't sound very likely, right?
That sounds like the sort of thing
that maybe is a bit fanciful, right?
Let's deal with, let's look at their data
and see if that's actually true, what they've done.
And I think one of the reasons
that chat GPT and stuff have been so hyped recently
is because most people don't know what it is.
And so when you see it doing what it does,
you think this thing must basically be a person, right?
Because it's acting like one.
But actually, it's only acting like one
in a very narrow thing.
And we know how it's trained
and how it's trained doesn't imply necessarily
that it's got any human qualities, right?
It might, but I don't, gut tells me not quite, right?
But the point is that I can,
I'm sort of more resistant to that in some sense
because I know how it works underneath.
And I sort of think, I've trained all these networks
and this is a bigger version of networks
that I've trained myself.
I don't see what's different about,
what's so different about that
that it would suddenly be unbelieveably intergent
compared to anything else if that makes sense.
Some knowledge of how, what some of your technologies are,
just like knowledge of, you know, some companies
trying to sell you a new firewall
with next generation antivirus on it
that has all kinds of machine learning.
Well, if you understand a bit about machine learning,
you'll know what it will and won't do, right?
And that will allow you to make
a better informed purchase decision.
And the answer is it'll work pretty well, right?
But nothing's perfect and machine learning
is only as good as the training data and so on.
So there's lots of things you can ask.
And you can ask really difficult questions
instead of people that come and try to sell it to you.
Especially with things like Twitter and the news,
it's very easy to get carried away in this hype cycle, right?
Lots of technologies have this.
It's in the interest of these companies
to make these massive models
of incredibly impressive performance.
I think we're a long way from full automation
of a lot of these tasks,
even if it might appear that way
at a sort of superficial level.
But on the other hand,
they're really promising in some other ways, right?
So one of the things that I found
that chat GPT is really good at
is paraphrasing text and vice versa.
So you have a text, you don't quite understand,
say, please can you read this and tell me what it means?
Or please can you summarize these bullet points
in an email or something like this?
These kind of functions, I think,
are actually working really well, right?
Because those are functions that rely on the,
they're meant for text to text, right?
They are, that's kind of what they're for.
And I think that those are ones that are really, really good.
I think code completion is useful when
you're asking limited things
that you can carefully check quite quickly.
Don't ask it to produce a thousand lines of code
that you expect them to all be perfect
because that's not what it will do, right?
And you'll end up with a lot of weird bugs.
Or, I mean, there was this huge paper
that's released just the other day, actually,
from Stanford that said that they audited code
from about 30 to 35 researchers
who some of them were using AI
to produce some of the code and some of them weren't.
And the AI produced code had more vulnerabilities in it.
And that's because when the AI produces code that works,
but let's say it uses ECB mode in AS
or it uses a slightly weak key derivation or something,
I don't know, something subtle,
if they don't know about that subject already,
they might accept that change, if that makes sense, right?
And actually, so you need,
this is why you need to still be an expert in your field
because you can't just rely on it to do it for you yet.
You've got to be there saying,
well, I think that's okay or I don't think that's okay
and make no decisions for yourself.
Yeah, I mean, it's a limited study,
but it's not that limited and it makes a very valid point.
I think the real danger is people who...
And I should carry out this by saying,
I'm not selling short these incredible technologies.
I'm just saying that it would be very silly
to just completely use them blind
and never check what they do, right?
Because we know they just make stuff up a lot of the time.
I think a bit of domain knowledge is always going to help.
I mean, it's interesting because I did some tests
with Cisco devices and it's amazing.
Like first time it got a perfect,
then I wanted to do it for a video and then it wasn't good
and I did like five or six attempts
and none of them were perfect.
Yeah, I think...
And if I didn't know what it was doing,
I would have accepted it.
Sorry, go on.
Yeah, and the other thing is that,
if you think about the data that it's trained on,
it's got some 40 plus billion tokens, right?
It's just internet text, we'll just leave it at that, right?
Loads and loads of text.
Cisco related text is only going to form
a very, very small fraction of that.
There is very little evidence
because it's not got a world model,
because it's not got an understanding of the world
where it can bring Cisco in and add it to its model.
It's just doing text completion.
And so when something is underrepresented in the training set,
it's going to probably be worse performing
when it comes to actually running it later, right?
So when you say,
write me something in the style of Shakespeare,
it's going to do really well
because there's Shakespeare all over the internet, right?
Some tasks are going to be very solvable
because they're hugely represented in the training set.
They work really well.
And some tasks are really niche.
And the problem is you don't know which ones are niche
because you haven't seen the training set.
I say write me a link expression
and it does it really well.
And when I say write me a link expression
using some other thing,
and that isn't in the training set
and it produces me a wrong answer.
And I don't know until I run it whether that's the case.
So I have to understand and be able to read that code
because otherwise I can't possibly put it into my system.
And it goes back to the exact same problem in medicine, right?
It might be that we're absolutely confident
that this AI will look at this image
and make the correct decision,
but we're not absolutely sure.
And while we're not absolutely sure,
do we want to completely take a human out of the loop there?
There's questions that we have to think about.
So do you think it'll become like the AI
might do a lot of the low-level donkey...
I think that's much closer to what will happen.
So I think there's a phrase in medicine
called CAD or computer aided diagnosis.
And the idea is that instead of the doctor not making a decision,
the doctor will be guided into a decision
by the AI saying,
we've noticed these spots over here in this image
is that relevant to you?
And it will speed them up, right?
And if we can make doctors or medics 50% more efficient,
that's a huge boost,
rather than try and put it all on the AI.
And similarly, it works in code.
If you can produce boilerplate code,
if you can get it to bootstrap, spring boot,
configuration fast for you, fabulous, do that, right?
And then that saves you a half an hour to an hour
of doing some actual code or making sure that it works.
But what I would avoid doing
is trying to have it write everything for you
and replace yourself because I don't think it will work.
I think you'll end up really frustrated
that your code doesn't get past any of your reviews
because it doesn't work, right?
I was going to say, I love what you said though,
because with that example at Stanford,
if people had just accepted the code,
there's hidden vulnerabilities in the code
that wouldn't have been picked up.
Yeah, and then there's a combination of issues,
right? Is it that the developer needs to know
more about these subjects?
Or is it that there's someone that would normally be
on that team that wasn't auditing that code,
that would have been auditing that code at that time?
You know, because you have security teams sometimes
who are specialists in this.
But I think it's that same argument.
In some ways, if someone has a small amount of knowledge
of computer security, that might allow them
to be more resistant when code appears that does this.
And that's the same thing with the AI.
If you know a little bit about AI,
maybe you can be, you can better deal with it
when something comes along.
So I think a little bit of knowledge
in lots of these things is often useful for that reason.
So how does this affect at like university life?
Because I've heard people talk about how students
can just get chat GPD to write their essays and stuff like that.
So you can't see the difference between a student
and like a human, sorry, and chat GPD.
Yeah, I think it's very subject dependent.
I think that's one thing.
So what we've done is we've done,
we've actually been running some tests, right?
Because so, you know, we've very kind of opened AI
to drop this tool on us just before exams.
Yeah, exactly.
Yeah, we've run some tests and like,
I think it depends on, if I show,
let's suppose we're doing a computer security exam,
which actually I teach, so, you know, right?
And I ask a very simple question, right?
A question like, what's a good encryption algorithm to use?
Chat GPD can answer that.
So it would be unwise of me to ask that question in an exam,
I suppose, what we say.
In some sense, I think it's another variant of a search engine.
So if a student could, you know,
can be, we call it academic risk conduct, right?
If a student was going to use a search engine to do that,
they could also have a go at using chat GPD.
It has the advantage for that student
that it's generating very plausible looking answers.
Sometimes they're completely wrong, right?
And those answers are going to get marked very far down
when they come in front of a convener.
So I think your mileage may vary
if you think you can get through a university degree
using just AI tools.
It's something we have to consider, right?
Now, some of our exams are face-to-face.
They aren't really affected, right?
You know, we're talking about coursework essays,
and I don't know, I haven't spoken too much
to other schools in university and other subject areas,
but obviously there are lots of essay-based subjects.
But they require very well-written essays.
Chat GPD has a habit of producing general answers to things,
right, which are sometimes very detailed,
but sometimes not quite so detailed.
Again, I think that your mileage would vary
if you tried this.
I suspect that it is possible to tell
that they're written by chat GPD to an extent
because it has a way of phrasing things
that's quite common I've noticed as I produce answers,
but that isn't necessarily all the time,
but that's going to be a problem.
It's something that every university on earth
is now looking at, so, yeah.
It's had a big impact.
And, you know, when you consider that,
this is just version one, right?
And, you know, there's going to be a chat GPD to probably,
and Microsoft might release one,
and Google release one, and so on and so forth.
There's always going to be one of these tools
floating about that we have to just be prepared
and think about how that's going to work.
I think, I mean, the examples I've seen
which have worked really well is like,
if I'm asked to write an essay about something,
I can get it to write something
that gives me a lot of ideas,
and then I can just rephrase it in my own voice.
But it helps you a lot from a study point of view.
Yeah, and I think it actually does.
And I think, so anyway, that's a big positive, right?
And there are some academics in this school, for example,
and across the world who operate
in a kind of human computer interaction area
who are very interested in,
could you end up writing a better essay
if you worked with a computer to help you out, right?
And in a way, is that not a win for the lecturers as well?
If that's the case.
Now, I agree with that to an extent.
I think that's absolutely right.
I think that maybe we can't solve
that whole discussion in a month, right?
Which is how long it is until our exams.
So, you know, the clock is ticking in somewhat,
somewhat in the short term for these issues.
But in the longer term,
I think they're going to be really transformative
in helping, you know, there are students who have,
who are very, very intelligent
and they know all the subject area,
but they're just not good at exams.
They really struggle to get their thoughts down on paper.
Maybe those students could really be helped
by something like this.
Because if you give really specific prompts to chat GPT,
you get much better answers.
If a student knows what they're doing
and can work with the AI,
I think that's going to be much better.
I mean, I suppose the,
you could have said the same thing for Google
or, you know, using search engines for...
Yeah, yeah, that's the point that's been made.
I mean, in some ways,
I see on Twitter a lot people compare these things to Google.
I would not because they're very different
and they don't have no source of actual data, right?
That's a really important thing to remember.
But they are a complementary tool in many ways
and they operate in a similar way.
If you were going to try and answer an exam,
you know, you would put the question in,
you'd rephrase it, you'd see what came out,
you'd see, does that look plausible?
I'm going to try again, I'm going to edit it and so on.
In the same way that you would if you were doing,
if you were using a search engine to write an essay as well.
And using a search engine to write an essay,
and I don't want to speak for every academic on the planet, right?
But it's not necessarily plagiarism or misconduct.
It depends on how you use it, right?
You know, looking up sources online
is absolutely to be encouraged.
It depends on how you're doing this.
I think in the long term,
we will get a nice balance actually
between using it too much and not using it enough.
And I think actually there's another thing,
there's another aspect which is,
I think this is plays into your,
this is relevant to your channel's viewers,
is that you shouldn't think of doing a degree
or writing a coursework as just about getting a mark, right?
That's very easy to think about that.
But actually it's about learning something
that you can then take and use in your career
or something like that, right?
We don't teach people to program,
so they pass the exams.
We teach them the program
so that they can go off and be software developers.
If you use AI to write all your work for you,
then you get out and you wouldn't be able to get a job
and you wouldn't be able to work in that job
because you wouldn't be able to do any of the computer science.
Actually, I think that if you've got a,
because I have quite a love of learning
and I love to learn about new topics,
particularly, you know, about computer science,
I would never use chat GPT to cheat
because I wouldn't know any of it then, right?
And you know, and I like to learn about these things.
Now, if you want to become an expert in something,
then you're going to need to learn it.
You can't read what chat GPT wrote.
A lot of it comes down to hoping that students
and trying to encourage students to think
that it's about the process of learning
and where they get to at the end,
rather than specifically about a series of kind of barriers
of exams that they have to get through, right?
Which I think is not a good way to look at a degree
or any course, really.
You know, it's much better to think about
where you'll be at the end, right?
And you'll be in that much better position
to do what you want to do next.
That's exactly right.
I mean, it's like certification exams, same thing.
You know, you can go and get all the answers
or the cheetah sites
or you can actually learn something.
And you haven't done yourself any favours if you get it off
because you might get a job based on that.
It's not going to go well, right?
Because you don't have any of the knowledge.
You'd always feel like you don't have any of the knowledge
as well, right?
You know, actually, you don't take that long
to learn these things if you really put yourself to it.
And you'll be in such a much better position afterwards.
Mike, as always, I really want to thank you for, you know,
sharing your knowledge and, you know,
separating the hype from, like,
the worries about people's futures.
Thanks so much for making a drill.
Yeah, it's no problem.
Glad to be on again.
It's been really, really, really good.
Brilliant. Thanks, Mike.
Thanks.
