Okay, yeah, talk to everyone, thanks for coming.
Well, it's a great pleasure to do this article today.
Take up a block.
Why are we going to block this meeting?
That's normal.
It's supposed to be at the end of the state, but people are still here.
They should be at the end of the state.
Well, I'm in an institutional contract.
I'm looking to block his career in the UK or the United States.
He got his beauty in Harvard University, and then he was in Cambridge.
And eventually he ended up as a professor in England.
He's a professor since 1987.
I would not talk to his very long career.
I'd like to know a lot of papers and models.
I'll just say he's a fellow of American Physical Society,
a man of the science, a society boy.
He's a writer of mathematics.
And he's also a tournament scouser in the University of Oxford here in Bruce,
a university who did comedy.
But, again, I don't know how to talk about this, but he is an extra-government boy.
I must say without any doubt that he's one of the people who know more about
visual dynamics.
He's probably a workaholic, so I go out.
And he's a great person to work with.
Today he's going to give a talk about general talk.
So I hope you will join him on the visual improvisation.
He's a topic that we've all learned a lot from.
And I'm a very busy person.
So I hope you'll stay.
Thank you, Damien.
So it's a great pleasure to be at IFISC again.
I was here some 12 years ago for an extended period invited by Manuel Matias.
And I enjoyed that visit, as well as this one, of course.
So thank you for hosting me.
So I was asked to give a general talk about spatial localization.
This is a topic that I started working on since my last visit to IFISC.
So this will not be a repetition in case there are any people who were here 12 years ago.
So I'm going to start by giving some examples of spatial localized structures
and explain the origins of these structures kind of in hand-waving terms.
And then I will describe a mathematical model which captures a lot of the behavior
that is seen in the experiment.
And then I will extend the theory a little bit to two dimensions and more.
And I'll mention in particular some examples from fluid mechanics,
which I think are very interesting.
And in fact, it was fluid mechanics that got me interested in spatial localization in the first place.
So let's start with some simple examples of localized structures.
So this is an example of buckling.
This is the kind of experiment that you can do in your bathroom.
It's not a very perfect experiment, but you get the idea is that you take a cylinder and you compress it.
And it doesn't, you know, if you don't compress it too much, it will just compress partially.
And in a numerical simulation of this process, you see that it buckles along the mid-secumference, as you can see here.
You can see these cellular structures form that resemble these kinds of structures that you see in the experiment.
So how does one think about these kinds of structures?
Well, here is the way that people who work in dynamical systems would think about this.
So on the vertical axis, I have a parameter that I'm varying.
This is the mode that I apply to the cylinder.
And on the horizontal axis is the response of the system to that load.
In other words, how much does it contract?
And what you see here is that the onset of linear instability occurs somewhere over here.
So this is where the perfect cylinder first starts to buckle.
And from this point, there is a branch of stationary, steady solutions, which are all partially buckled.
And they go along here and go through this kind of a curve.
So let me explain in a few words what happens along this curve.
So this blue curve represents an unstable equilibrium.
If I perturb the cylinder to the right of this blue curve, then it's just going to collapse.
So this is a marginal state.
But what is interesting about this marginal state, if I follow it as a function of the applied load that it turns around here,
and at this point I can increase the load and my partially buckled cylinder will support that load.
So it gains some strength up to some point where an increase in load makes it collapse a little more.
And then I can load it up some more like this and then it'll collapse again and so on.
So you get this sequence of partially collapsed states, and what they look like is something like this.
So this is the unrolled cylinder, so this is the vertical direction, this is the circumference.
What you see is this band of cells along the mid perimeter.
And when you go from A to this region, you will have four rows of these cells.
When you go from here to B, you will have six rows of these cells.
And these are examples of partially buckled states or spatial localized structures.
The reason they are spatial localized is because the cylinder here is not buckled.
It's not buckled here, it's just buckled in some region.
I'm going to give you some more examples with the same flavor.
So here is an example of a ferrofluid experiment.
You take a petri dish and you fill it with a suspension of very small magnetic dark holes held in suspension by surfactants.
And then you apply a normal vertical magnetic field, stationary, time-independent DC magnetic field.
And what happens is initially the surfaces just remain flat, modulo these end effects, which I'm not going to talk about.
But then when the strength of the magnetic field becomes too strong, the whole surface of the fluid buckles into a hexagonal pattern.
And that occurs at this value of the applied magnetic field.
So the system jumps to a new state. It's a state of hexagonal peaks.
And as you increase the magnetic field, then it defects here and up here you have a almost perfect hexagonal structure.
And then when you decrease the magnetic field, the hexagonal structure remains, the height of the peaks decreases.
And here they collapse back to the flat interface.
So you have a system here with a large hysteresis loop.
And it's these hysteresis loops that are very interesting to me, because within those hysteresis loops, in some range of parameters,
you can do the following experiment that's shown here.
What you can do is you can bring the bar magnet to the surface, you pull out a peak, the bar magnet pulls out a peak,
you remove the bar magnet, and the peak instead of falling back into the flat interface remains sitting there.
That's very counterintuitive.
So now that you've done it once, you can do it again.
You can bring the bar magnet to another region of the fluid, you pull out a peak, you remove the bar magnet and the peak remains.
And you can do this many times, and when you do that many times, you get a sequence of individual peaks that just sit there in equilibrium.
These are indicated by this sequence of dots, each dot corresponding to a different number of peaks.
So you have one peak, two peaks, etc.
And these peaks can form clumps, bound states, and this is from another experiment, the more recent experiment.
And you see these kind of patches of hexagons where the hexagons are confined to some region and outside there is no displacement,
essentially no displacement of the interface.
So I'm going to talk about these kinds of structures.
So a lot of people here are interested in vegetation patterns, so I can't resist showing some examples.
These are also associated with what's called a subcritical instability.
And the reason is the following.
If I imagine that I have a plant growing in some region, then the plant may have extended roots in the horizontal direction,
and the roots take up moisture, of course, and prevent the growth of the plant to the side.
So this is a mechanism for preferring the plant that's already there.
That's the notion of subcritical instability.
Alternatively, in various deserts, and we have these deserts in California,
you may have a situation where the surface of the desert is covered by a kind of biofilm, a crust, which is essentially impermeable.
And if it does happen to rain, then any water that's collected will run into regions where the crust is broken,
and it's broken exactly where plants are.
So this gives you another mechanism for positive feedback whereby the existence of plants leads to the collection of water,
and therefore enhances the growth of those plants.
So these are the basic mechanisms believed to be responsible for many types of vegetation structures,
including these remarkable so-called ferrous circles.
This is from Namibia area picture.
This is a region that's covered by bush, but the bush is broken by these little bare circles,
typically four kilometers across, and you can see that there's more growth around the boundary of the circle
because there is less competition for water.
Half of the region is dry, and there is no water collected.
So it's believed that these types of mechanisms are responsible for the presence of these kinds of localized structures.
Now localized structures can be dynamic, and this is from an old experiment from Harry Sweeney's lab in Austin, in Texas.
You take, again, a Petri dish, you fill it with various wool brass beads,
and then you vibrate the dish up and down with a certain frequency and a certain amplitude.
And if you do it in the right range of parameters, you can get structures which oscillate up and down.
So for a while it's a peak, and then one period of the forcing, it's a crater.
It's a subharmonic instability.
And the interesting thing about this structure is that it's localized, I'd say.
And this is created in the same sort of way as in that ferrofluid experiment that I mentioned earlier.
This is what it looks like in reflected light.
So this is the peak that I showed you at one period.
One period of the forcing later, it forms a crater, and then it goes back to a peak.
So it's an oscillation between these two states.
This is what it looks like from the side.
These things can also form bound structures, like these bound states of a peak and a crater.
One period later, the peak becomes a crater, the crater becomes a peak.
They oscillate out of phase like this and remain bound.
And you can get chains of these structures.
You can get these kind of molecules with one peak, three craters.
A period later, you have a crater surrounded by three peaks.
And so there are a lot of different structures, of course, that can be made in two dimensions.
This is a nice example from the lab of Hans Gore-Provence in Münster.
He takes two electrodes and partially evacuates the region between them.
It fills it with different types of gas.
And then he puts a voltage difference across the electrodes.
And if the voltage difference is large enough, you get electrical breakdown,
meaning that you get current filaments shorting the gap between the electrodes.
And of course, that radiates until you can see the current filaments.
And this is basically what the experiment is.
And what he finds is the same kinds of structures that we've been talking about.
You can get a stationary hexagonal pattern, like the pattern of peaks in the ferrofluid experiment that I mentioned.
You can get a structure of these current filaments where the current filaments are not stationary,
but move around in complicated ways.
And so the analogy might be that this is more like a liquid state as opposed to a crystalline state.
You can get a gas-like state where you have fewer of these structures that are in motion.
But you can also get the sort of change that we were talking about earlier, networks.
And you can get states where you have, for example, part of the region is solidified or crystallized,
and some of these current filaments are free to move around in any regular fashion.
Now, what is interesting about a lot of these problems is that, first of all, they behave in a similar way,
but also that we don't necessarily even know the right equations to describe it.
This is a very complicated problem.
The business of the granular media, you know, the brass beads moving up,
and now we don't have an aviastope equation for granular media.
And so what we would like to be able to do is describe a lot of these structures in some generic way,
which doesn't depend on the basic physics that's responsible for these different types of behavior that you see here,
and that captures the common behavior that's exhibited by all these different systems.
Now, there are examples of this in fluid mechanics.
Fluid mechanics is nice because I actually know what the equations are.
And so we can study the equations numerically, and I'll talk about some results that we've obtained.
So this is an example of what we call convectons.
These are localized regions of convection.
And what you see here is a two-dimensional layer of a binary mixture, a lighter and a heavier component that is heated from below.
And in response to the applied heating, the heavier component migrates towards the bottom boundary.
This is a cross-diffusion effect that's called the Sorai effect.
It's very well known in these types of problems.
And what you see here is the temperature fluctuations about the linear temperature gradient.
It's hot at the bottom, cold at the top, so there's a linear temperature gradient in the background.
But this shows the region of hot fluid rising and cold fluid resending.
But as you can see, the convection rolls that are set up.
And the interesting thing here is that the convection doesn't fill the whole domain.
It just fills part of the domain.
And what is interesting also, like in the examples we saw before,
is that for the same parameter values, I can get distinct states.
All nominal is stable.
So these states are obtained for the same parameter values, but they are different.
This one is an odd state.
I have a descending cold plume rising, hot plume on the opposite sides.
And here I have two rising plumes on the two sides.
So they're distinct states, simultaneously stable.
Just like in that buckling problem, you had lots of simultaneously stable, partially buckled states.
And you can get more complicated structures like these turbulent states in couette flow.
So what couette flow is, is a shear flow between two power plates,
the top plate moving towards you, the bottom plate moving away from you.
And you can get structures of localized turbulence,
which are inclined relative to the direction of motion of the plates.
So what do these states have in common?
Well, they can be found in one, two, and in three dimensions.
I'll talk about some three-dimensional structures at the end.
They may be stationary.
Most of the examples we've talked about were stationary.
They can propagate or they can oscillate in place, as we saw in the oscillon example.
They are generated by finite amplitude perturbations.
Like the bar magnet that I bring to the surface to pull out a peak,
that's a finite amplitude disturbance.
And therefore, the structures are fully nonlinear.
And they have to be described by methods which go beyond linear or weakly in nonlinear theory.
And they can, of course, experience a variety of instabilities
that lead to splitting, decay, disappearance, propagation,
or localized complex dynamics, in fact.
And they form these different types of bound structures that we looked at
and the gas-like state that you also saw in the previous slides.
Now, I want to emphasize these things are sometimes called dissipative solitons,
but they have nothing to do with solitons.
They are not solutions of integral PDEs.
They, in fact, have very different interaction rules,
and I'll talk about some of those in a moment.
So here is my kind of toll problem that I think is a very interesting equation.
It looks deceptively simple,
but it captures a lot of the behavior that we've seen.
And it explains why lots of systems with different physics behave in the same way.
So what is this equation?
It's an equation for a scalar field, u, here.
This is the time derivative of u with respect to time.
The field depends on space.
For example, in a plane, this would be x, this would be y.
It has its fourth order in space,
and that's important that it's fourth order in space.
There is a bifurcation parameter like the load, for example, when I was crushing my cylinder.
And then there is a bistable nonlinear term
with a destabilizing quadratic contribution and a stabilizing cubic contribution.
So I'm going to call this equation with this FSH23,
or I can maybe have a destabilizing cubic contribution
and a stabilizing fifth order contribution.
I'm going to call that equation SH35,
SH45 Hohenberg and the 35 for these systems.
So now we can play the same game that Reinhard Richter played in his ferrofluid experiment.
What I can do is I can go into a plane here
and I can generate the localized finite amplitude disturbance,
like bringing the bar magnet towards the surface.
And then if I'm in the right parameter regime,
and by right parameter regime I'm in the right range of s and the associated range of r,
an interesting thing happens that the localized perturbation that I've created
will relax to a nonzero localized state.
It won't fade away.
For example, here I created one perturbation and it created this target pattern.
Here I generated a different perturbation, created a spot.
Here I generated a third type of initial perturbation, created a hexagonal patch.
So the same idea, generating different initial finite amplitude disturbances
and they relax to different types of localized structures.
And they're all here sitting simultaneously stable.
So let's try to understand why this might be the case.
So here is my equation and just for simplicity I've written it in one dimension.
And I've also introduced this Qc, which is a length scale.
It's actually the intrinsic length scale of my crystal that you saw in the previous slides.
And it's important that it's foreshortened in space, that you have this intrinsic length scale,
that you have bistability that comes from this nonlinear term
that gives you that hysteresis loop that we saw at the beginning.
And it helps that it's spatially reversible, that you have the symmetry x goes to minus x.
And it also helps that it has gradient dynamics.
In other words, the dynamics is boring.
What this equation means is that the system just evolves always to steady solutions
and the steady solutions correspond to a local minima of this functional f
that I'm going to refer to as the free energy of the system, by analogy with phase transition.
So in a sense what I'm going to be talking about is the energy landscape of the system.
And if I'm going to have multiple localized solutions that are linearly stable,
all of those must correspond to local minima of f.
Of course there will be local maxima, there will be saddle points,
but the idea is to understand the energy landscape of this functional.
So this slide is, I guess, probably more for the students,
but I think it's actually a very important slide, probably my most important slide.
So what I want to do is explain to you the idea of the difference between temporal and spatial dynamics.
These are different ways of looking at the same problem.
Of course, when I'm interested in temporal dynamics, I want to know how things evolve in time.
And what I can do, for example, to find instability of a uniform state, u equals 0,
I can perturb that state with some time-dependent perturbation with a growth rate sigma and a spatial scale q.
That's the usual thing that we all do, and then when sigma of particular q is positive,
you say that q grows in time.
Now we're interested here in stationary solutions, steady solutions, independent of time,
and where are those? Where those solutions only exist on the curve sigma of q equals 0.
And I've drawn that curve here. Here is that curve.
So q is horizontally r, the parameter is on the vertical direction.
In this region, you have instability for some q.
Below the curve, you have no instability.
So steady solutions only exist on this curve.
And notice that if I pick this value of r, there are two types of steady solutions,
one's with wave number q minus and one's with wave number q plus.
And as I decrease r towards the onset of instability, those two solutions come together and merge.
It's a co-lessons of two distinct wave numbers at this critical wave number qc.
And this is what you would normally call the onset of temporal instability
because it's the minimum of this curve sigma of q.
And the way we think about this is this is a fourth order problem in space.
If I put this equal to 0, I have an ODE in four dimensional phase space.
And I can look at spatial eigenvalues of u equals 0.
And they're going to be 4 because it's a fourth order problem.
So when r is greater than this critical value, which is 0,
I actually have four eigenvalues on the imaginary axis.
This one corresponds to eigenvalue lambda is iq plus, iq minus, and then the negative, the complex function.
And the fact that the eigenvalues are on the imaginary axis is a consequence of the spatial versatility dimension.
As r decreases towards 0, these two come together at co-lessons.
You have eigenvalues of double multiplicity on the imaginary axis.
And then when I go below r equals 0, I have this quartet of eigenvalues,
a pair in the unstable positive real part of the complex plane
and a pair in the negative real part of the half plane.
And this is important because now I have a two-dimensional unstable manifold
whereby I can leave u equals 0.
But I can also return to u equals 0 along the stable manifold spanned by these two stable eigenvalues.
And what this looks like in a picture is something like this.
It's that here is u equals 0 as a function of x.
I'm leaving u equals 0 along those two directions, the unstable eigenvalue.
And I can also come back and all I have to make sure if I want to generate a nonlinear localized solution
is somehow that these curves connect in the nonlinear regime.
And without going into details, and you can do this using multiple scale methods,
you find that at r equals 0, there is a pair of solutions that appear from u equals 0.
The reason you have a pair of solutions, in fact more than two,
is that it's a multiple bifurcation because those spatial wave numbers
have coalesced and given you a multiple bifurcation in space.
Not in time, but in space.
And the two solutions are these.
You have a periodic pattern with some amplitude that goes like the square root of minus r,
because alpha is negative.
And then you also have a modulated solution where you have a periodic solution
that's modulated in envelope by this such like function.
And here the spatial phase phi is arbitrary.
You can just translate the pattern as you wish.
But here I cannot pick any phi because I cannot translate the periodic pattern
relative to the envelope by arbitrary amounts.
I have to pick certain values of phi and only 0 and pi are permitted.
So this is what we've learned.
So this is a bifurcation diagram like the ones we've seen before.
Now the parameter is shown horizontally and the response, the norm of the solutions,
is plotted in the vertical direction.
And at r equals 0 you see that there are lots of branches coming out of there.
There is the red branch that corresponds to periodic solutions.
It's a subcritical instability because that coefficient alpha was negative.
So solutions exist for r less than 0.
And so that solution is unstable initially and then it requires stability at the top.
But you also get the localized solutions.
They bifurcate simultaneously with the periodic solutions.
They're also subcritical and also unstable.
But when they reach this shaded region they start oscillating back and forth.
Here the heavy line indicates stable solutions.
And so you can see that in this region the localized solutions have acquired stability
and moreover that you can get a very large multiplicity of simultaneously stable states.
And of course the ones you will see will depend on how you do the experiment.
The word you put your mind at.
That depends on what kind of initial disturbance you are applying.
And what is the difference between these states?
So L0 have a peak in the middle and you can see that as I follow L0 like this
the structure gradually grows and extends, spatial extends.
L pi solutions are similar but they have a dip in the middle.
And so we call this kind of structure the snakes and ladder structure
of this region of localized states.
And the ladders or the rungs of the ladder are these states here.
They cause one to asymmetrical solutions.
For example, you know, if you start with a solution at the peak in the middle
on the L0 branch and you go to state two it becomes asymmetrical.
You can see then it becomes again more asymmetrical.
And then at the far end it emerges as a solution with a dip in the middle.
And so it lies on the L pi branch.
These states are all unstable.
Now if you do this for a single peak as I've just done
then you can also do it for pairs of peaks, right?
And you get the same sort of snaking until you fill the domain.
You can do it for these bound states.
So here is a bound state of two single peak structures.
And they lie on a figurate isola.
These lie in that shaded region.
If I have a two peak state they lie on this kind of figurate solution.
These ones lie on this figurate solution and so on.
The isolas depend on the separation of the structure.
So here I am changing the separation between these states.
And you can see that the isola depends on that separation.
There is a lot of possible solutions that you can get in the shaded region.
And in fact you can get more.
You can get solutions which are bound states of similar structures
like this structure with one peak, two peaks.
At this location by the time you get to here you have three peaks and two peaks.
So this one has grown, this one hasn't.
When you go from two to one this one remains the same.
This one grows and so on.
There is a huge variety of different solutions inside the shaded region.
So I would like now to tell you why this region might support this great variety of different solutions.
And I am going to do it by analogy with what you know about phase transitions.
So what I am drawing here is my parameter.
You can think of that as temperature.
And here is the response of the system.
And so this is the periodic state.
Remember it was unstable, it became stable at the fold.
And there is a parameter value here at which the periodic state actually has the same energy as the homogeneous state.
So this is what in thermodynamics you would call a Maxwell point.
And I want to make use of that analogy to understand why we can get lots of different structures in that shaded region of parameter space.
So imagine in the middle here that I am plotting the density as a function of space.
And I am doing it at the critical temperature.
For example think of this as a liquid and this as gas.
So the liquid has higher density, this has lower density.
Then in the absence of surface tension I can put any number of interfaces in there.
It doesn't cost me anything.
So I can get very complicated states.
Now if I change the temperature, for example, I increase the temperature above critical, what happens?
Then the liquid wants to evaporate and that means that this front is going to move in, this one is going to move in.
And eventually the drop is going to disappear.
So there is no steady solution.
No steady solution when I change the temperature away from critical temperature.
If I decrease the temperature then of course I have condensation and so the fronts are going to move in the opposite direction.
The drop is going to grow.
So that's the thing I want to, you know, bury mine.
But now I want to think about what happens if I don't have coexistence between two homogeneous phases like the gas and the liquid phases.
But instead let's say I have a liquid and I have a solid, a crystal, a structure, a medium.
Then things change and they change in an important way and that was originally recognized by Yves Pomont a long time ago.
You have a front here that you're trying to get to move but this front is pinned to the potential of the heterogeneity behind it and so it's not free to move.
You have to change the temperature by a finite amount before that front can move and for example the crystal can invade the liquid because of that crystallization.
And inside that region generated by this pinning potential that's where all the localized states exist that I'll be talking about.
There's a mathematical way of thinking about this and some of you may prefer that even though this is a physics institute, right?
So I mean four dimensions, right?
It's a spatial way of looking at things and it turns out that this equation has a spatial Hamiltonian.
So there's a conserved quantity so I can go from four to three and then I can look at the wavelength one map that takes me from three to two and so I can draw things in two dimensions.
And so here is the fixed point that corresponds to the homogeneous state.
Here is the fixed point that corresponds to the periodic state that corresponds to the fixed point under this wavelength one map.
And these are all associated with stable and unstable manifolds because as I showed you we have some stable eigenvalues, some unstable eigenvalues.
And what you see here for example at the fold here is that I have a tangency between the unstable manifold of this point and the stable manifold of this point.
And then when I cross inside the shaded region which is this region here I have transversal intersections as you can see here.
And the unstable manifold of the homogeneous state actually has to intersect the stable manifold of the homogeneous state along the line that corresponds to the fixed point subspace.
So the reflection symmetry x goes to minus.
And so this point here run backwards goes back to the homogeneous state, run this way goes to the homogeneous state.
So it's a localized solution.
And you can also see those asymmetric solutions they also have to form the same mechanism.
And they all accumulate as you see from this heterogene tango they all accumulate on the periodic orbit as this black dot over here.
So that's what happens in that shaded region is you have these transversal intersections of stable and stable.
And one way to think about this is in terms of fronts and this is a front that connects the homogeneous state to the periodic solution.
This is another front of the same time.
This one is stable.
This one is unstable.
You put two of these back to back.
You get state one.
It's an unstable state.
You put two of these back to back.
You get a stable state.
And if you do one of each you're going to get an unstable wrong state.
And I just want to say a couple words about the wavelength selection in that shaded region.
As I vary my parameter r the wavelength can change across that of the periodic oscillations.
The local atmospheric oscillation because there's no boundaries.
And the wavelength that is selected as you can see here is the wavelength determined by the requirement that this spatial Hamiltonian is conserved.
That spatial Hamiltonian contains the homogeneous state and the periodic solution.
And any connection between those two has to lie in the level set h equals zero of this Hamiltonian.
So we understand some things about this.
If I go outside of this pinning region right so the pinning region has to straddle the Maxwell point which is this dash dotted line.
I can either go this way or this way outside.
Then of course I have no localized stationary solutions and instead I have dynamical solutions.
And here is an example space time increasing upwards of what happens if I go to the right of the pinning region in the region to the right.
The state that has lowest energy is the periodic state and the system approaches a periodic state through a sequence of nucleations that generate new wavelengths on either side.
And so this is an example of a stable state, a periodic state invading another stable state, but the periodic state has lower energy so it's preferred.
And you can develop some theory to understand what is the frequency of nucleation events as a function of the parameter and so on.
The same sort of thing happens if you go to the other side where the preferred state is the homogeneous state.
And so the periodic structure eventually disappears through these annihilation events.
Now in 2D things are more interesting of course.
And so I just want to say a few words about, so this is now x and y, not time but y.
We had a localized structure, a localized region of stripes and the front here was unstable to a y-dependent perturbation and that deepened the front so that eventually the whole region is taken over by a hexagonal pattern.
But that doesn't have to happen in a different region.
The hexagons only invade inward and you generate a localized patch of hexagons like this.
All in another region you can get structures where the front's deepened and send out these fingers which then buckle because the wavelength that is selected by this kind of moving front is not the equilibrium wavelength.
And so the system then relaxes to what would be the equilibrium wavelength subsequent to the passage of the front.
And this is the same sort of thing for the 3.5K as you can get these kind of finger structures.
The labyrinthine pattern that is generated by this dynamical evolution, the moving front between the homogeneous and structured state.
A couple words about how these structures might be connected.
I think this is quite interesting.
So this dot here, mu is minus r.
So this red dot corresponds to a state like this, norm in the vertical direction.
If I follow this in one direction, it's going to follow the state up to this red dot here.
What you see here is that these fingers have grown out.
These are the steady solutions of the Swift-Homberg equation, 3.5.1.
If I follow the red dot in the opposite direction, it generates this kind of structure.
And what you see here is that these dots here or the spots reconnect horizontally and create these stripes as the front moves away from the central region.
So these kinds of structures and these kind of structures are actually on the same solution branch of the Swift-Homberg equation, which is quite interesting.
And then you get all these kinds of interconnections that I talked about.
There's many more of them in 2D.
You can get lots of isolas of these checkerboard structures.
You can get structures that have this kind of lozenge appearance.
You have fronts which are pinned because of the oscillation behind them.
And they're also pinned here because of the gradient in the wave number due to the curved interface.
And then you have these things which we've called worms, which are very strange things.
And if people here are interested in PDEs, you might ask, you know, what's happening here at that point?
It's not a singularity because the PDE doesn't permit.
Are those all steady solutions?
All steady? No.
Well, some are stable.
I don't know whether specifically these ones are stable, but as you go along here, the stability changes at folks in the same sort of way.
But I think it's very interesting that you form these kinds of structures that have these cusp behavior.
It's not understood at all why this might be possible.
I just want to say a few words.
So this is an attempt to draw in parameter space.
So this is R now, and this is the coefficient of the quadratic term for SH23 squared.
You know, where the different kinds of localized structures are.
I'm going to say a few words about the hexagons here.
So this shows the snaking branch of hexagonal structures.
And what you see that at point one here, what you see is a hexagonal patch like some of the things we saw in earlier pictures.
When I go from one to two, I've nucleated a cell in the middle of each phase.
When I go from two to three, I nucleate new solutions on either side, but I'm still missing the corners.
And when I get to four, I actually generated a full patch so the process can repeat.
So there's a very regular ordered way whereby these structures grow as you quasi-statically vary the parameter or temperature or whatever you want to call it.
And here is a situation with these kind of stripe-like states.
The small oscillations here correspond to adding cells along each row, and then each big row is associated with these large-scale excursions.
So let me go back to now fluid mechanics, because time is running.
So you've seen this picture, these odd and even convectons.
I want to show you how they're generated in the fluid problem.
So here is space, because I have a layer, so I'm just looking at what happens at mid-level.
I just want to see what the temperature looks like at mid-level, and I'm plotting it at a sequence of successive times.
And what you see here is that the initial state is a kind of spatial complex state, but that state undergoes a focusing instability you can see over here.
And after some further time, this solution is not a stationary solution of the system, but in fact it evolves by that same erosion of wavelengths that we saw in the Svith-Homburg equation.
It collapses back into the chaotic state, and then, of course, that's unstable to the focusing instability, and so the process repeats.
And it generates this kind of relaxation.
Time trace, where you have the chaotic state, here is the focusing instability, here is the erosion of the structure, and the process repeats.
And now you change the parameter from 1774 to 1775, and now the solution remains as far as you know forever.
Here is that focusing instability. It's generated the structure, suppressed oscillations outside, and all the heat now is transported through this hole, if you like, through this layer that's been self-generated by this focusing instability.
And so this is the bifurcation diagram. This is a measure of the temperature difference across the system.
Here is the response of the system. It's the heat transported.
Here was that primary instability that generated the chaotic state.
And here is the appearance of the localized solution, stationary stable, numerically stable localized solutions that I just showed you.
And notice they are inside this hysteresis loop. They coexist with spatially extended, more or less, standard convection.
I've separated the odd and even structures, just so you can see, and I'm going to compare the solutions at these successive points.
For the odd ones, you can see that I'm picking up heavier material from below like this, and then I'm picking up lighter material from above,
because the rolls at the two ends rotate in the same direction, and so I have actually like a little pump that picks up stuff from one side and deposits it on the other side.
And then the direction of the pump changes when I go from A to C, because I've added rolls in the opposite direction at each end, and so the pumping now is in the opposite direction.
And if I have an even state, then of course the rolls are in opposite directions at the two ends, so they either pick up the heavier stuff from the bottom, or they pick up the lighter stuff from above.
If I go outside that pinning region, I get behavior that's indistinguishable from the sweep-humber equation.
And yet this is Navier-Stokes.
The structure grows by the successive nucleation events that you saw earlier.
I want to say a few words about collisions of these things, because they are one of the things that distinguishes the local structures that we've been talking about from solitons.
And so the way we do that is as follows. We take the three-file sweep-humber equation, and we add a quadratic term.
Why do we do that? We do it for two reasons.
One is that the quadratic term breaks the gradient structure of the system, so structures can now move, but also that it breaks the symmetry U goes to minus U.
And that means that structures that were kept fixed stationary by diagonal reflection, you know, left, right, up, down, those solutions are no longer exist.
They won't exist anymore, and therefore whatever takes their place has to move.
Of course, it messes up my beautiful diagram, but you have lots of possible stable solutions that you can pick up that are now moving.
They have the solutions that were odd solutions, odd parity solutions, when epsilon was zero.
And so here I've taken two of those solutions back-to-back, and I collide them.
And notice that it's a very inelastic collision, right?
Stick and form a different localized solution.
I can take different solutions, you know, different structures that are moving and they stick.
Or I can get solutions that move in the same direction.
The skinny ones travel more rapidly than the fat ones, and so they catch up and eventually they form a moving, local solution over here.
Here I have a collision with a stationary, even solution.
And I call this an attractive solution because the fronts here are of opposite type, down here, up here.
And that leads to attraction between these structures.
If I have the same front on both sides that leads to repulsion, and you can see that this little guy hits this one, and then hopefully it moves to the right.
So we can do the same thing in fluid mechanics with these convectons.
And the way we do that is we have to change the boundary conditions at the top, so they are now different from those at the bottom.
For example, we can allow Newton's law of cooling to allow temperature, heat to escape from the top boundary.
That's a nice, physically realizable way of doing this.
And if we do that, the even solutions remain stationary, just as in the previous example.
And the solutions that were odd are now moving.
After all, Navier-Stokes is not a gradient system, right?
And so I can play the same game.
So I've taken two solutions with identical solutions with opposite speed, and I collide them, and they glue in the same sort of way as in the Sweden-Homberg equation.
It's a little more complicated because there are waves generated.
This is not a gradient system, as I mentioned.
But it behaves in a somewhat similar way.
Here I have a stationary solution that's being hit by a moving one.
And notice that the two fronts are opposite, so this is an attractive solution.
And you can see these are coming together.
It's an asymmetric collision, a lot of radiation, but eventually you get a local solution.
Here I have a repulsive interaction.
This was a stationary solution that's being pushed to the right by the proximity of this guy.
The two fronts are the same at both ends.
And eventually they glue again as in the Sweden-Homberg example.
How much time do I have?
Five more minutes.
Five more minutes?
Okay, I'll just show a little movie.
So we can do this also in three dimensions.
So this is an example of a convecting system in a porous medium.
Same sort of system, eaten from below.
You have a mixture of a lighter and a heavier component.
The Navier-Stokes equation is simplified because it's a porous medium, and then we solve these equations.
And of course the bifurcation diagram is a little worse, as you might imagine.
But basically what we do through dynamical simulations, we find the localized solution that is not a steady solution.
It's not an equilibrium solution, but the system poses at this kind of solution.
Then we can converge it, and then we can follow that solution in the parameter space.
And so this hopefully will work.
And what you should see here is a green dot.
March along here, and on this panel you see the structures that are following that correspond to the location of the green dot.
So this is not temporal evolution.
This is just a sequence of steady equilibrium solution of the PDE that I had on the previous slide.
And you can see these three-dimensional structures growing.
They form this kind of...
Periodic horizontal equation?
Periodic horizontal equation.
But of course non-travel in the vertical direction.
Periodic horizontal equation?
Yeah.
And vertical?
We have no mass flux and fixed temperature.
So the mass flux boundary condition is like a boundary condition of concentration.
And it's no slip.
So what's basically happening here is that the solution is trying to find that spatially extended state,
that fills the whole domain, but it's having a hard time.
And it's not actually clear in this problem that he ever finds a periodic solution that fills the whole domain.
Because you follow it and it just keeps moving in and out like this,
and it forms these bizarre shapes that people have never seen in convection, as far as I know.
But these are all steady solutions of that system.
And many are stable if you impose some reflection symmetry that we know.
Okay.
The last thing I want to mention is same things occur in plain coed flow.
Remember that shear flow that I showed you at the beginning with one plate going towards you,
one plate going away from you.
What you see here are periodic area vortices.
So this is a top view.
The periodic area vortices would fill the whole domain.
But they're also localized solutions.
They're localized in the transverse direction.
And this is what it looks like in a vertical cross section through that system.
You can see these vortices.
And there are two of them.
These ones travel because one of them closer to one of the boundary than to the other boundary.
So they travel partly with the boundary.
These ones have diagonal symmetries.
So they're stationary.
And they do the same kind of snaking, the same cross links that you saw in the Soviet homework equation.
And to me, this is really interesting because these kinds of shear flow problems have been studied for more than 100 years.
And it's only taken this way of looking at these problems to try to look for new types of solutions
and these very, very old problems that go back to Rayleigh and all the famous fluid machinations from the end of the 19th, early 20th century.
So here are my conclusions.
So I've shown you that the growth process of these stationary localized structures in dissipative systems have lots of rules.
They grow in size whereby there are stability changes and how they interact.
These things are independent of the physics, but they're captured by this Swift-Homberg model in a very effective way.
So much so that, for example, I could make predictions based on the Swift-Homberg model for the collision, for example.
And they worked out very well in a much more complicated Navier-Stokes system.
And you might ask, you know, how is that even possible? Because the Swift-Homberg has nothing to do with fluid mechanics, right?
And the reason this works is because the structures I'm talking about are robust in the sense that they are there because of transverse intersections between stable and unstable manifolds
in the spatial dynamics description of the system.
So, of course, if you have transverse intersections of stable and stable manifolds, you can't unhook those, right?
You can change parameters and they're still transverse intersections.
You can add an extra term and you still have a transverse intersection.
So you can change not just parameters, you can change equations and these structures are still there, right?
So that doesn't have anything to do with physics, per se, but it's a good mathematical model for understanding the robustness of the behavior that I described.
It was useful for me to use, you know, the variation of the gradient structure of the dynamics and the fact that it's a Hamiltonian in space in this case of the Swift-Homberg equation.
But because of what I've just said, those things are irrelevant, actually.
So it works for Navier-Stokes, which is neither a gradient system and it's also, of course, not a spatial Hamiltonian system, either.
Anyway, I wrote the review article about this if some people are interested.
So thank you for your attention.
Thank you very much.
So, yeah, I wanted to make you a question, precisely, about the very last thing that you were saying.
This thing that when you study this complex structure, this complex also, whatever, from the Navier-Stokes,
like you can capture it with a variation of the equation because, I mean,
what is the property of this thing that's allowing you to understand what a non-variational equation like Navier-Stokes is being understood by a variation equation?
Is it spatial reversibility?
Well, the spatial reversibility helps, but of course, if I have systems in a plane, you know, then it's, you know,
a spatial reversibility just in a single variable is very nice because it makes the spatial variable time-like.
That's why you get these quartets of eigenvalues.
It's more complicated if you are in a plane because, you know, what does it mean to have two time-like solutions?
You know, you have to think about that.
But really, the key thing is the dimension of the stable and unstable manifolds of, for example,
in the one-vector case of the conduction solution, right?
So I have a conduction solution, which is homogeneous, but there are some stable directions and there are some unstable directions.
And I need these manifolds to be of sufficiently high dimension so I get these structurally stable transverse intersections.
You know, if it's only one dimensional this way and one dimensional this way, they're going to miss each other
and, you know, you won't get these robust structures.
So the dimensions have to work out.
Sorry, but when you were giving the supplement, you were verifying R, the parameter, I know that you were verifying the contour parameter.
So the rest is all valid. The formation of this solution is all valid also when R is homogenous.
Yes, yes.
So the other part I said, but then you were making an argument, looking at these eigenvalues.
But to go from one to the other, we're actually changing R.
Yes, so what I was doing in that Swift-Homberg example was I was trying to find a region in R space in which these dimensions actually work out.
So in the case of the Swift-Homberg equation, I needed to have two-dimensional stable manifold and two-dimensional unstable manifold
in order for, you know, for these things to meet in the nonlinear regime.
Okay, and I did that by going into the subcritical regime, because in the supercritical regime, I had no stable unstable direction.
Right? That was the case R equals 0 with the eigenvalues on the imaginary axis.
But the way I got eigenvalues off the imaginary axis was by decreasing R below R equals 0.
That means I went into the subcritical regime where I had coexistence between the homogeneous solution and the periodic state.
Okay, so that's really what's behind, you know, and that's the kind of calculation you would have to do for each separate problem,
including the Navier-Stokes problem. The Navier-Stokes problem is much higher-dimensional of course,
because you have a Laplacian in the horizontal velocity component, you have a Laplacian in vertical velocity component,
you have two horizontal components, you have the temperature, you have the concentration, right?
So you have already five Laplacians, right? So it's in the spatial description, it's already in ten-dimensional phase space.
So it's a much more complicated situation than the Swift-Homberg.
Swift-Homberg is really nice because it's actually the minimal, it's the minimal size of the phase space,
the dimension of the phase space that allows this behavior to take place.
So in that sense it's the simplest model of this behavior.
Another non-expert question. Could you list the other different properties between localized structures and solutions?
So one is the collisions, and maybe there are other that can be, so differences between localized structures and solutions.
I mean, there are many differences. The collisions of course are the most important thing.
I mean, the main difference is that these structures physically only exist if I'm driving the system, right?
So what happens inside this convector is that I'm putting energy, I'm heating the system, and that energy is being dissipated inside the structure.
So the structure is an equilibrium state only in the sense that energy in goes out as dissipation.
But it's not a thermodynamically equilibrium structure, right?
Because it's only an equilibrium structure in the sense that I have a balance between energy in and energy out.
And of course, solitons are, you know, completely different structures.
There's no dissipation inside the structure. And of course, you're also not no energy input because it's a conservative system.
I'm not sure I answered your question, but...
Please.
You discussed the interaction of these sort of, you see, all of these structures.
When you have some, you introduce some of the activation numbers, we call them that, to introduce a sort of three.
But even without these structures, you interact by details.
So if you have two of such structures, they should show how to interact.
They do?
No, no need to force them with a bit.
So how much is general of this interaction?
I mean, I guess that some things should be similar to what we also have in the ring.
These two structures collide, they all rejoin and mess together.
It wasn't because of anything.
It's just a maintained focus.
Well, so the important thing about being in the subcritical regime is that you have these fronts.
You don't have oscillatory tails because the eigenvalues have a non-zero imaginary part.
And so if I have two of these structures, they will interact through these oscillatory tails and the tails lock.
And so by themselves, they will not start to drift because they're actually a stationary solution.
Because you can push on them and if you push hard enough, they will unlock.
So that would be one way to do what you say.
What I like about the way we do this is we're not actually putting any extra forces into the system.
We're actually just changing the boundary conditions to change the symmetry and then everything happens spontaneously.
You know, we don't have to reach in and push on these things.
But we could.
But basically you break the symmetry and then, of course, increase this proportion to the symmetry like that?
That's right.
So that would be an easy work transition for how?
Except in our case, the direction of motion is generated spontaneously by whatever initial perturbation there is.
Because breaking the symmetry at the top relative to the boundary condition at the bottom, that doesn't select left, over right.
The system selects that.
So it's spontaneous symmetry breaking as opposed to forced symmetry breaking, which is what you're referring to.
And absolutely we could do that.
I don't know the question.
Most of these structures would be considered for how symmetrical, except for this breaking at the end of.
So we are, what's called, is in the right structure.
Because point to is in front.
If they are symmetric, you're in two states, a group.
If one goes in a structure that arrives on a block of symmetry, in principle symmetry, they are tidal and all that.
How much is known in those structures?
Steward shape?
I mean, of course.
So is the knowledge at the extent that in this case also?
Well, I mean, less is known.
No surprise.
I mean, so you can think, if you're interested in reaction diffusion problems, for example, when you're interested in spiral waves and things like that.
And there are situations where you can get localized spirals, things like that.
In fact, and maybe that's not a good example.
I was trying to think of a chiral state.
You can certainly get localized spirals in these kind of field periods.
Absolutely.
But they won't have localized spirals.
And the reason is that it's not of high enough order.
So that's, but it's, yeah.
If you want to think in terms of Ginsburg-Landau, of course.
I mean, you know, there are equations like the complex Swift-Homberg equation, which we also worked on.
Which, you know, are better models of that kind of behavior.
Because the problem with Swift-Homberg is that except in certain very special circumstances, including some in optics, you can't derive them from the basic field equation.
In fact, there is no way to derive Swift-Homberg from Navier-Stokes, for example.
And you certainly can't derive the complexity of Hamburg from Navier-Stokes either.
So these have to be taken as mathematical models rather than physical models.
And it's really in that spirit, I think, that, you know, you should take what I've tried to describe in this talk.
Is that there are mathematical models, which in a sense supersede, you know, the details of the physics behind these phenomena.
But I'll lead you to understand something about the commonality of the mathematical behavior of these structures.
Okay, so I think you should stop here if I continue.
Eger will be here in a few days, so if you have anything, let's go.
Thank you.
Thank you.
