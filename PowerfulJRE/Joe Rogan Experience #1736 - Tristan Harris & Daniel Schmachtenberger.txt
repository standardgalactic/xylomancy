Joe Rogan Podcast, check it out!
The Joe Rogan Experience.
Showing by day, Joe Rogan Podcast by night, all day!
Gentlemen, thank you for being here.
I keep doing these podcasts where I just talk to people, so please introduce yourself and tell people what you do.
I am Tristan Harris and came on this show about a year ago after the social dilemma came out.
That's probably where most people know me.
I used to be a design ethicist at Google, studying how do you ethically influence people's attention and thoughts and behaviors.
I really enjoyed the conversation last year.
The reason that today I'm here with Daniel Schmackenberger, who is really a person I've learned so much from the last few years
and why I thought it would be a good through line,
is that the issues of social media, which I know we're going to talk about today,
are connected to a number of other issues that are going wrong in society that are all kind of interconnected.
I've learned a tremendous amount from Daniel and I thought it would help really clarify some of these issues for everyone.
Thank you, Daniel. Thanks for coming aboard.
Thanks for having me here.
What a daunting task, how to ethically influence people.
What a weird thing that this industry that didn't exist 20 years ago has such a...
Think about life on Earth.
And then 20 years ago, all of a sudden this social media thing sort of evolves
and now you have to wonder how much of an effect it has on our just day-to-day lives
and how to ethically influence people.
What the fuck does that even mean?
Well, first of all, I should say...
How do those thoughts even get worked out?
Actually, I should first say that there wasn't at Google a department that said how do we ethically influence people.
I actually sort of, as was shown in the film The Social Dilemma,
wrote this presentation worried about how technology was influencing people's thoughts, concerns, behaviors, etc.
And I studied persuasive technology at Stanford, which is a whole discipline and field,
the idea that technology can influence people.
And it was out of my own personal concern that when that presentation went viral at Google,
I kind of worked my way into this position that never existed before,
which was how could we create a framework for what it means to ethically influence other people?
And a lot of that has to do with asymmetries of power.
I mean, when I was a kid, I was a magician.
We talked about this before.
Magic is about an asymmetric relationship.
The magician knows something about your mind that you don't know about your own mind.
That's what makes the trick work.
And actually, across some of these things we're going to talk about today
are ways that there is an asymmetric relationship between what technology knows about us
and what we don't know about ourselves.
When you were studying at Stanford, what year was this?
This was 2002 to 2006.
I was an undergrad and then 2006 I got involved with Professor B.J. Fogdon,
who, again, actually studied ways that persuasive technology could be used for positive purpose.
Like, how do you help people be healthier?
How do you help people floss?
How do you help people work out more often?
Things like that.
It could be used in a positive way.
But I got concerned because it was all of this increasing arms race
to use persuasive tools to harvest and capture people's attention,
now known as the race to the bottom of the brainstem,
to go down the brainstem into more social validation,
more social narcissism, all of that.
And that's one of the arms races we see everywhere,
which is like in every single thing.
If one oil company doesn't drill for that oil well,
the other one will.
If one attention company doesn't add the beautification filter, the other one will.
If one company doesn't do narcissism, social validation hacking
and likes and variable rewards, the other one will.
And it's true across so many of the other issues that we're facing,
whether it's like if I don't build the drone for everyone,
then someone else is going to build the drone for everyone.
So that's how I think these things are connected.
Did you realize it back then?
I mean, 2002, 2006, you're talking about a completely different world
in terms of social media influence.
Totally. It's before the isone, actually.
Yeah.
2007, right?
iPhone came out in 2007.
We were studying persuasive technology.
And I've said in the past, partners with the co-founder of Instagram
in the persuasive technology class.
So we were actually studying how would you apply persuasive technology
to people before the iPhone even existed.
And what bothered me is that I think when people think about
how do you ethically persuade people,
you just get into a whole bunch of ethical cop-outs.
Like, well, we're just giving people what they want.
Or if they don't want to do this, they'll use something else.
There's these very simple ways that the minds of people in technology,
the tech industry, I think defend what they're doing.
And what concerned me was that the ethical framework wasn't really there.
Not that I had one at the time, by the way.
I studied at Google for three years to try to develop.
Like, what does it mean to ethically influence
three billion people who are jacked into the system?
And this is before Cambridge Analytica,
before the Facebook files, and Francis Haugen talking about,
we now have the receipts for all these things.
So we talked about all these things in the social dilemma,
but now there's the evidence with Francis Haugen's
also blowing that Instagram makes body image issues worse
for one in three teenage girls.
I know I'm going fast, but that's the broad strokes.
Do you know the conspiracy theory about her?
Tell me.
The conspiracy theory amongst the tinfoil hat folk
is, first of all, she started a Twitter account
like right before she went there and was immediately verified.
Right.
And then, instantaneously, was on all these major media outlets,
major network television shows and being interviewed.
And she was saying something that a lot of people felt like
was a call to authoritarian intervention into social media.
That it was government censorship was the solution,
and regulation was the solution to dealing with this problem,
and that it seemed like she was a sanctioned whistleblower.
She was saying all the things that they wanted to hear,
and that's why they put her in the position to make a big, loud noise.
What did you think about that when it came up?
Just curious.
I always have to do this.
You know, when something like that happens, like, hmm, maybe, maybe.
Because you know the government would do that.
Like, most certainly, they would love to have control over social media.
They would love to be able to censor things like the Hunter Biden laptop story.
They would love to be able to, you know, hide Joe Biden's medical records
or, you know, Kamala Harris's time as a prosecuting attorney.
Like, there's a lot of stuff they would like to do.
Yeah.
Or district attorney, rather.
There's a lot of stuff they would like to do with access to information.
I mean, you're seeing it right now in terms of one of the things
that's been fascinating about COVID is during this pandemic,
during this terrible time of, you know, paranoia and dealing with this disease
and fear and anxiety, you're seeing this narrative from social media networks
that absolutely walk step in step with the government.
Where if the government wants certain information censored,
it's being censored across major social media platforms.
That has to be coordinated.
There's no way it's not.
And there's no way they're incentivized to not have people discuss certain things
because we've said before, you know, it's one of the major points of the social dilemma
is that things that are controversial, whether they're true or not,
are the things that are the most clicked on, the most shared, the most,
and that's where the money is.
So there's got to be some sort of incentive for them to not do what they do
with every other subject, whether it's immigration or gun control
or abortion or anything.
The algorithm...
Did they censor on immigration?
Or you're seeing that as an example of something goes viral.
It's an example of something goes viral.
Yeah, yeah, not that censorship.
Right, they don't censor on immigration.
No.
I mean, the border crisis is a great example of that.
Right.
Like the government probably likes us to not see all those Haitian immigrants
storming across the border, but my God, those are shared like crazy.
Totally.
You know, so why was COVID information shared?
Well, because there was a narrative that they could say,
well, this is dangerous misinformation and we could protect people,
even though some of it turned out to actually be accurate,
like the lab leak hypothesis.
Well, at least that it's a hypothesis.
It's a hypothesis that at least is being considered by virologists.
Right.
But the point is that who the fuck are they to decide what can and can't be discussed
and when they're doing something step in step with the government, I get concerned.
So when someone comes along and this person who's a wishful blower says,
something needs to be done, you know, we're endangering young girls' lives.
We're doing this.
We're doing that.
We need some sort of government intervention.
I mean, this is essentially calling for censorship and calling for government control
of social media, which freaks people out.
So she's pretty clear that she's not calling for censorship.
But the reason I asked you, I was curious how it came across your radar,
because I happened to know and hear a little bit about this from her.
We interviewed her on our podcast.
And the story that goes viral about her saying that she's a psyop or that she's a plant,
that's an incendiary inflammatory controversial story.
So when that gets suggested, is it going to go, is it just going to fizzle out or is it going to go viral?
How ironic.
It's going to go viral.
Exactly.
And in fact, when you kind of realize, like, everything, I mean, there's some things that
are real conspiracy theories and there's some things that are real psyops.
That's a real thing.
But notice how many things we think of as psyops, conspiracies, et cetera, now.
And it's because anything that has that incendiary quality goes viral.
And I happened to know, for example, I think one of the things that claims in there is
that she's funded by this billionaire Pierre Omidyar.
But I happened to know from talking to her that that happened at the very, very end of
what she was doing, and it was a tiny grant of like $150,000 for us in the nonprofit world.
That's like a tiny amount of money basically just to support her flight costs.
And I happened to also sort of hear from her how, like, how much of the media was constructed
at the very last minute.
Like, she was working this one newspaper, The Wall Street Journal, to do this sort of
procedural rollout of specific stuff that she thought was concerning.
I guess what I'll just say is, like, what if she's just a good faith person who saw that
virality was driving people crazy and that it was harmful to teenage girls?
And it's true that the government would see some of that and say, hey, we could use that
for something else.
We could use that.
She could be a tool for us to do something else.
But I guess what, you know, in the aim of complexity and nuance and not jumping to conclusions
and this sort of thing, my perception from talking to her now extensively, she's a very
good faith actor who is concerned that this was going to drive the world apart.
I should be really clear that this is not my position.
This is just the conspiracy theory.
I literally don't have an opinion on her.
I do have an opinion on algorithms, and I do have an opinion on what it does do to young
girls' self-esteem.
But you have teenage daughters.
I just think, I mean, and young girls are a point of focus for why they're a point of
focus more than young boys.
I'm not entirely sure.
I guess it has to do with their emotional makeup.
And there's higher risk of self-harm due to social media.
And Jonathan Haight talked about that in his book, The Coddling of the American Mind.
It's very clear that it's very damaging.
And my kids, you know, my 13-year-old does have, like, interactions with her friends.
I do see how they bully each other and talk shit about each other, and they get so angry
and mad at each other.
It is a factor.
But it's an algorithm issue, right?
There's multiple things here.
So the first thing is, just to kind of set the stage a little bit, I always use E.O.
Wilson, the sociobiologist, who sort of defined what the problem statement for humanity is.
He said, the fundamental problem of humanity is we have paleolithic emotions and brains,
like easy brains that are hackable for magicians.
We have medieval institutions, you know, government that's not really good at seeing
the latest tech, whether it was railroads or now, social media or AI or deep fakes or whatever's coming next.
And then we have god-like technology.
So we have paleolithic emotions, medieval institutions, god-like technology.
You combine that fact, that's the fundamental problem statement.
How do we wield the power of gods without the love, prudence and wisdom of gods?
There's actually something that Daniel taught me.
And then you add to that the race to the bottom of the brainstem for attention.
What is their business model?
Just to review the basics, everybody knows this now, but it's engagement.
It's like, how do I get that attention at all costs?
So algorithms is one piece of that.
Meaning, when you're on a news feed, like, I don't want to just show you any news.
I want to show you the most viral, engaging, like, longest argumentative comment threads news, right?
So that's like pointing a trillion-dollar market cap AI at your brain,
saying, I'm going to show you the next perfect boogeyman for your nervous system.
The thing that's going to make you upset, angry, whether it's masks, vaccines, Francis Haugen, whatever the thing is,
it will just dry that over and over again and then repeat that thing.
And that's one of the tools in the arsenal to get attention.
Is that the algorithms?
Another one is technology making design decisions.
Like, how do we inflate people's sense of beautification filters?
In fact, just recently, since we talked last time, I think it's a MIT Tech review article showing that
they're all competing, first of all, to, like, inflate your sense of beauty.
So they're doing the filters.
People know this stuff. It's very obvious.
But they're competing for who can give you a nicer filter, right?
And then now, instead of waiting for you to actually add one, Tiktok was actually found to actually do, like, a 2%
like, just bare beautification filter on the no filter mode.
Because the thing is, once they do that, the other guys have to do it too.
So I just want to name that all of this is taking place in this race to capture human attention,
because if I don't do it, the other guy will.
And then it's happening with design decisions, like the beautification filters,
and, like, the follow you, and if you follow me, I'll follow you back, and the like button,
and the check poll to refresh, the dopamine stuff.
That's all design. Then there's the algorithms, which is I'm pointing a thing at your brain to figure out
how can I show you an infinite feed that just maximally enrages you.
And we should talk about that because that thing drives polarization, which breaks democracy.
But that's a, we can get into that.
Daniel, let's bring you in here. So how did you guys meet and how did this sort of dynamic duo come about?
Yeah, I was working on studying kind of catastrophic risks writ large.
You've had people on the show talking about risks associated with AI and with CRISPR and genetic engineering
and with climate change and environmental issues.
Pull up to the microphone there.
There you go.
And escalation pathways to war and all these kinds of things.
Basically how can you hit the pin?
Right.
And I think it's a pretty common question of, like, how long do we have on which of these?
And are we doing a good job of tending to them so that we get to solve the rest of them?
And then for me, it was, there were so many of them.
What was in common driving them?
Are there any kind of like societal generator functions of all of the catastrophic risks that we can address with
to make a more resilient civilization writ large?
Tristan was working on the social media issues.
And when you had Eric on, he talked about the twin nuclei problem of atomic energy and kind of genetic engineering
basically saying these are extremely powerful technologies that we don't have the wisdom to steward that power well.
Well, in addition to that is all things computation does, right?
There's a few other major categories.
And computation has the ability to, as you mentioned with Facebook, get to billions of people in a very, very short period of time
compared to how quickly the railroads expanded or any other type of tech.
Like how fast can TikTok get to a billion people, billion users, which they did in like a few years
versus before that it took software companies like Microsoft even longer than that
and before that took railroads even longer than that.
So the power of this tech is you can compress the timelines.
You're getting, you know, a scale of a billion people.
You're impacting a billion people in deeper ways much faster, which means that if you're blind to something,
if you don't know what you might be doing, the consequences show up faster than you can actually remediate them.
When we say exponential tech, we mean a number of things.
We mean tech that makes more powerful versions of itself so I can use computer chips to model how to make better computer chips
and then those better computer chips can recursively do that.
We also mean exponential speed of impact, exponential scale of impact, exponentially more capital returns,
exponentially smaller numbers of people capable of achieving a scale of impact.
And so when he's mentioning godlike powers and kind of medieval institutions,
the speed at which our tech is having influences in the world and not just first order influences,
the obvious stuff, but the second and third order ones.
Facebook isn't trying to polarize the population.
It's an externality.
It's a side effect of the thing they're trying to do, which is to optimize ad revenue.
But the speed at which new technologies are having effects on the world and the total amount of consequences
way faster than regulation can keep up with.
And just by that alone, we should be skeptical of any government's ability to regulate something that's moving faster than it.
Faster than it can appraise of what the hell is even happening in the first place.
Well, not only that, you need someone who really understands the technology
and you're not going to get that from elected officials.
You're going to need someone who's working on it and has a comprehensive understanding of how the stuff works,
how it's engineered, where it goes.
I mean, I'm skeptical of the government being able to regulate almost everything.
Right.
Well, and so there's maybe a few things to say about that.
So one is the complexity of all issues.
Like climate change is really complex.
Like where the nuclear pathways of escalation or the way a satellite or GPS could get knocked out triggers a nuke somewhere.
That's also really complex.
Social media is really complex.
CRISPR, you know, bio stuff is complex.
So in general, like one of the ways to summarize the kind of problem from our friend Zach Stein's kind of work
is that the complexity of humanities problems is going up like this.
But the capacity to meet them is like not really meeting it.
And then you add in social media and you polarize people and divide them into like they don't even know what's true
because everyone's got their own personalized version of reality.
Right.
And instead of even trying to try to meet that, it goes down.
And in fact, social media also rewards the most cynical take on anything.
So anytime a government institution has ever said something dumb like when the guy asked Zuckerberg,
how do you make money?
And he says, Senator, we sell ads.
That thing goes viral.
And when that goes viral, everybody saw that.
And they didn't see that, you know, the five senators who I talked to who actually do really get these things pretty decently.
And I'm not going to say like let's just like regulate it, but just to notice, right?
So the cynical take about every time an institution makes a mistake, that thing goes viral,
which means we lose trust in so many things because no matter what the issue is, do you want to?
You notice that you were bringing up the conspiracy theory of might the government have an incentive to make a plant like Francis.
And so it's plausible, but plausible doesn't automatically mean is.
One of the challenges is when someone has a confirmation bias, they hear something that's plausible
and they just assume that it is without doing the due diligence of saying what would I need to know?
And you do a good job of checking that.
We could also say would Facebook have an incentive to say that she's a plant and try to hire a bunch of PRs.
And they were helping to spread that story, by the way.
I'm not saying they're responsible for it.
I actually think that what happened is organically, again, the cynical take goes viral.
And then if you're Russia or China or your Facebook in this case, you can be like,
hmm, that's a really helpful cynical take from my perspective.
In fact, one of the things that Facebook does try to do is turn the social media debate into a censorship or free speech debate,
because they know that divides the political class because they know that the right doesn't want censorship, obviously.
And so they say the more they can spin whatever Francis is doing as she's claiming censorship, the more they can divide any possibility for actual action.
In fact, I'll tell you just a quick story, really quick, is during the three hour testimony that Francis gave,
if you watch the full three hours, she had both people on the left and the right.
And I've been working on this for eight years.
I have never seen someone create a bipartisan consensus the way that she did.
She actually did if you watch the video.
And there was a senator there on the right who typically had been very skeptical of these issues.
And the next day I talked to her, she was going to meet with that senator.
And he later said, I can't meet with you.
Why?
Because the story went viral saying that she was a democratic operative and he said,
my base will hate me if I meet with you.
So the very thing we're talking about, which is the ability to regulate anything is being broken and shattered because the incendiary controversial take on everything goes viral.
Now, again, I'm not saying that we're this like easy world we should therefore regulate.
It's just like, but noticing the mind warp.
Like part of what I wanted to do today is like, how do we reverse engineer this like bad trip we've been on for the last 10 years?
Like it's like a psychedelic trip where we've all fractured into this different reality where the controversial,
IOP interpretation of everything, the conspiracy minded interpretation of everything.
Again, some things are real.
Some of those things have deserved to be seen that way.
But just to understand how deep the mind warp has been the last 10 years.
It's so funny you say the right doesn't want censorship.
Isn't that a crazy statement?
Like, are we like shifted the polar, you know, the polar?
What do you mean?
It used to be the left didn't want censorship.
The ACLU used to defend Nazis.
I mean, what the fuck has happened?
Like our poles have shifted.
Like north is south and south is north.
It just shows you that so much of what ideology is is tribal.
It's like you find a group that agrees to a certain pattern of behavior and thought and you subscribe to that.
You know, I am a right wing conservative.
I am a left wing progressive and then you just follow the playbook.
And it makes it so much easier than having your own individual nuanced thoughts on complex and difficult issues like this.
But the fact that he couldn't talk to her because his base would somehow or other think that she actually is a democratic operative
and she does work for the government and is some sort of an attempt at censorship.
And I'm sure not only is Facebook amplifying that but all of the different Russian troll pages on Facebook are amplifying that which confuses the water.
Totally.
Well, also if I'm Russia or China, Facebook is like the best weapon I've ever had against the United States.
Yes.
Oh my God, you've got an F-35?
I don't need F-35.
I've got Facebook.
I can destroy your entire coherence as a society.
And they have.
And you won't get anything done.
And all of your energy will be spent on waste, infighting and heat.
We talked about this recently but I'm sure you saw the story.
There was 20, top 20 Christian sites on Facebook, 19 of them were run by a Russian troll farm.
I'm glad you actually mentioned that.
Excuse me, it was an Eastern European troll farm.
Macedonia, I think it was.
Totally.
This is an important stat actually.
I'm glad you brought it up.
This is as recent as October 2019.
140 million Americans per month were reached by essentially troll farms, actively.
There's three categories of pages in which, so for Christian pages, the top 15 out of
15 Christian pages were all run by troll farms.
So all of the Christians in the country were receiving content.
And 85%, this is a secondary point, 85% of the Christians who saw that stuff in their
feed, they didn't actually accept an invitation from the group or the page to say, yes, I
want to subscribe to you.
Because they're optimizing for growth, they change the way the system works so that if
a page invites you, that's enough for it to start putting the content in your feed.
So there's an example in Francis's work where there was a QAnon person who invited 300,000
people in one day, 300,000 people.
And because Facebook's optimizing for growth and engagement, those people didn't have to
say, yes, I want to join that group.
Just by being invited, it started testing.
We want to optimize for what sort of puts it in your feed.
And if you click on it, it auto adds you to the group.
Out of the top 15 pages for African Americans, two thirds of those top 15 pages were run
by troll farms.
Of the top 15 pages for Native Americans, one third of those pages were run by troll farms.
So we're not living in an authentic reality.
Reality, quote unquote, is getting more virtual.
If you read Chinese military doctrine, specifically look at the 36 stratagems, don't ever attack
a superior opponent directly.
Turn the enemy against themselves based on their existing fault lines.
Population-centric unconventional warfare, right?
Like that's kind of ancient doctrine.
It's just Facebook makes that amazingly easy because it automatically already puts people
into tribal groups that whatever the content is in that group is going to keep getting
up-regulated, optimizes for inflammation and tribal identity and those types of things.
And so you don't have to kinetically attack a country to make the country so turned against
itself that the polarized population supports a polarized representative class, which means
you get gridlock on everything, which means you can't do effective governance, which means
another country that does autocratic governance just wins geopolitically.
It seems absolutely insane that they could, through one page, inviting people instantaneously
start to distribute all of their information on those people that they invited.
So why would Facebook even allow that?
So if I'm designing Facebook, you would probably say...
Wait, wait, you just said the government should regulate social media.
It should be illegal as well.
It should be illegal.
Yeah, well, I don't think the government should regulate, but I do think there should be rules
in terms of like, if you're a regular person that, say, has a specific group of interests,
like say you only like motor cars, you like vehicles, you like hot rods or whatever, and
that's what you're interested in.
You use Facebook when you're off duty at work and you just want to just check some stuff
out and all of a sudden you get queuing on shit because they invited you into this queuing
on group and you start getting all this information, you start getting radicalized.
It seems like, and again, I don't know what we should do in terms of regulation, but I
don't think that social media groups should be able to just distribute information to
people based on this concept of universal growth.
Yeah, well, I mean, think about it.
If we were just designing...
We're on limited growth.
Yeah, exactly.
I mean, if we were designing Facebook with a feature called Groups and Groups had a feature
called Invitations and you could invite people, wouldn't you design it so that people have
to accept the invitation for the group before it shows up in your feed?
Why would Facebook not do it that way?
Right.
Because what happened is starting, I think it was like 2018, people stopped posting as
much on Facebook.
So you and I, and maybe we used to post a lot more in 2016, 2017, if we stopped posting
as much, oh shit, we can't harvest all that attention from people.
What was the cause?
You were doing all this labor.
What do you mean?
What caused it to slow down?
Oh, just like people being more skeptical maybe of Facebook or just realizing they don't
want to share as much or just usage burning out more people moving to Instagram or TikTok.
People are getting older as well, right?
It's like older user base.
Totally.
Yeah.
And so now if I'm Facebook, I want to find new sources of free unpaid content creators.
Where can I tap that pool of content?
Oh, I've got this thing called Facebook Groups where people are posting all the time.
So I'm going to start putting that stuff in people's feeds to just...
So now I'm fracking for attention.
I'm going lower into all these other places to backfill this attention harvesting.
We are the product machine.
And how do you know, since there isn't rigorous identity, if a user that says they're a user
is really who they are or if they're a troll farm or if pretty soon they're an AI GPT-3 algorithm?
You should explain what AI GPT-3 is.
The ability to generate text-based deep fakes.
So people know what a deep fake is.
Well, there's a whole Reddit thread with people arguing with each other that are all fake.
Do you know about that?
No, I don't actually.
Here, I'm going to send it to Jamie.
It's Duncan just sent this to me the other day and I was like, what in the fuck?
I could only look at it for a couple of moments before I start freaking out.
But the idea that it's not far off.
This ability that deep fake AI has to recreate is especially in text.
Yes, exactly.
That's specifically what GPT-3 is.
It's a text model that trains on trillions of parameters and basically the entire corpus
of the internet.
So you're basically ingesting everything everyone has ever said online ever, including stuff
in your voice or in my voice.
And then you could say GPT-3, write me an argument about why social media is great, written by
Tristan Harris, using his words and phrases.
And it'll do that.
It'll actually be able to take my style of speech and it'll generate text there.
You could also say, do you want to do the vaccine one?
The ability to say, make arguments for vaccines or against vaccines and say only use real
data and then be able to show the financial vested interests of anyone arguing on the
other side and just have it be able to create more data than people can parse in any reasonable
amount of time.
Like create like an academic looking paper that's 10 pages long saying why the vaccine
is not safe.
With citing real charts, real graphs, real statistics and the real vested interests of
people who are, say, positively pointing out that the vaccine is safe, who maybe they
have some connection to Pfizer or something like that.
And it'll generate that full 10-page or 20-page document and it'll take a team of statisticians
a while to decode that thing and you can flood the internet with that kind of text.
And it's already, we already have, through OpenAI and the GPT-3 algorithm, the ability
to pass the Turing test in many areas.
You should explain what the Turing test is.
Meaning that if you're reading the text, you can't tell that it wasn't produced by a
human.
Right.
Turing test is the idea that if you, that's how you find out if some, it's a very good
robot.
So you've already got an AI.
That's Machina, right?
Right.
So this is, this is the Reddit thread.
So this is, these are all, why do human babies cry?
These are all robots.
This is all bots arguing with each other.
This is what happens when you give birth to a human baby.
Oh, my bad.
I thought you were just trying to answer the question.
No worries.
No, I'm trying to answer the question of how babies cry.
YTA, I don't know what that means.
And you are discussing, I can't even fathom the level of toxicity in this post.
These are all bots.
I am disgusted that you are making fun of others.
Don't you know that people in this sub are supposed to be empathetic of other's feelings?
Question mark.
I'm sorry, but you're being a cunt.
These are all robots.
Yeah.
This is wild.
Because if you've just read this and you didn't know, I don't really care if you disagree
with my opinion.
Because you don't call me a pedophile.
If you were a real man, you would be with a young girl and take care of her and you
would be a sex offender.
This is wild shit.
Yeah.
One of the things people don't know, it actually was just developed over the summer.
They announced open AI, just a track since we came and talked about some of these things
last time.
In August 2020, open AI released a video of using the same technology of machines generating
stuff to actually write programming code.
You tell the GPT-3, I want an asteroid video game.
It writes all the code and then it puts a little graphic of a starship thing in the
middle and then there's rocks that are flying.
You say, I want the rocks to move faster and then the rocks move faster through the asteroid
game.
Only requiring natural language and no programming.
You're typing a natural text.
I want an asteroid video game that when I move left, it moves left.
I want this.
I want the asteroids to move faster, actually make the starship bigger and then it just
changes and it does it all for you.
It's not perfect, but this is AGI.
You're just typing it in text.
But also voice to text, so you could just say it.
You combine these things together.
Alexa, make me a Pong game.
Yeah.
Exactly.
Alexa, code me the Unreal Engine.
I mean, that one's going to be harder.
But the point is that's where we're headed, right?
And part of this is, again, we have the power of God.
This is actually it, right here.
Here it is.
This is the one.
Make the person 100 pixels and it's doing it all itself.
Yep.
Wow.
That's the code in the right-hand side.
So this video that Jamie pulled up on YouTube is OpenAI Codex Live Demo and you can see
this all happening while this person types in the data and they're actually explaining
it now.
Yeah.
How this is going to work.
Once you see it later, yeah, set its position to 500 pixels down and 400 pixels from the
left and then it just does that.
Oh, my God.
Look how quick it codes it.
Yeah.
Wow.
Now make it controllable with the left and right keys, the right arrows, right?
Boom and then now you can move it.
So it does it progressively, right?
It's adding the code in.
Yeah.
Wow.
Yeah.
And this is going to be accessible to more and more people, too.
Go ahead.
This is an example of a kind of deep point to think about for the state of the world as
a whole is one of the things that exponential tech means is exponentially more powerful.
I need to tell you this, but get this thing right up in your face.
Exponentially more powerful tech that's also exponentially cheaper, which also means more
distributed.
And so pretty soon, this level of tech will not only be getting better, but available
to everybody.
So what happens when you have an internet where not only do you have an AI that is curating
the Facebook feed for the most sticky stuff, which usually means the most toxic stuff,
and that's an AI that is curating human-made content, but now you have AIs that are creating
content that also get to maximize for stickiness.
And then you have the relationship between the curation and the creation AIs.
How does anyone ever know what is true about anything again?
So AI can create fake stories, and the fake stories can be boosted up by these troll farms.
Which themselves could be run by fake accounts and fake logic, I'd say.
Oh my God.
It goes one step further.
So that's just distributed AI, right?
But we also have drones making continuously better drones with continuously better ability
to swarm and weaponize them that also becomes easily accessible.
We also have CRISPR making biotech capability, something that you don't have to be a state
actor to have.
Small actors can have.
So there's this question of how do we make it through having decentralized exponential
tech, which means decentralized catastrophic capability?
God-like powers.
Decentralized.
Decentralized God-like powers in terms of biology, as well as in terms of technology.
So we don't need an instance.
Just gloss over the CRISPR thing.
For people that don't understand what CRISPR is, CRISPR is a gene editing tool.
I think it's on the second iteration now, or is it on the third?
Something like that.
They're getting better and better at it.
The idea is, eventually, it's going to get to the point where it's like a home computer.
Like where you are going to be able to edit genes.
So how do you stop that, or what do you do about that?
And if you wanted to have any kind of regulation about something like that, what is the regulation?
Is the regulation that you have to have some specific level of clearance before you have
access to it?
But if that's the case, then you put it in control of the government, and then also bad
actors and other governments are going to just distribute it wildly.
And how do you control that someone would have to have some kind of access to get it
if one of the it's is something that you just need internet access for, like open AI or
the ability for cyber weapons, right?
Cyber weapons hitting infrastructure targets, it's like now the only way to regulate that
is universal surveillance on everyone's use of their home computer.
And we don't want that future.
So in general, because this might sound like just a disaster point, which I want to be
really clear.
There is a way through this.
Our goal in coming on was to be able to talk about the framing the problem so we know what
we're trying to solve.
We're not trying to say, hey, we've just got this social media problem.
Let's frame it really clearly.
You've got your coding problem and you have this biology problem with CRISPR.
How does a civilization navigate this without killing itself?
Well, Daniel's going to be able to speak to a lot more of this.
I just wanted to connect it first to social media so people see the through line.
So I actually think that social media is its other kind of, it doesn't seem as dangerous,
right?
It just feels like this thing where people are sharing cat videos and their opinions
and their political ideas and sharing links, but it's actually just like this.
In the same way that that dangerous capacity, we're now seeing what that dangerous godlike
power was doing of steering three billion people's thoughts, personalized to them the
thing that would most outrage boogeyman their lizard brain and their nervous system, that's
a godlike power.
When you have a godlike power, there's two attractors with that power.
One is, think of it like a bowling alley.
You've got one gutter on the left and one gutter on the right.
On the left, you've got a dystopia, a centralized control saying, here's how we're going to
control that godlike power.
That's like China controlling its internet.
That's like Mark Zuckerberg having a total monopoly on what people can and can't say.
Those are both dystopias, that's centralized power.
The other gutter in the bowling alley is take your hand off the steering wheel and let
this thing go for everyone.
Anyone can make anything go viral.
Let's add the devious licks, which is by the way, a TikTok challenge for anybody to basically
trash their high school bathroom and it teaches you how to do it and these videos go viral
and it's just like everyone's-
What is this?
What is a devious licks?
It's a quickly-
Too late.
It's a high school teacher told me this, there's all these horrible things that are going viral
at the point.
Virality is a godlike power and devious licks is a challenge that basically you're challenging
your fellow high school aged friends around the world to trash their high school bathroom.
So you flush a Big Mac with all this horrible stuff down the toilet at the same time.
They put like pee, this is awful, they put like pee in the soap dispenser.
They do all this awful stuff and you're just spreading a disaster meme.
You're just teaching people how to create a decentralized catastrophe instead of a drone
hitting something-
And they do this just for TikTok likes?
They do it because it's getting attention and engagement.
There's another one that's a self-harm challenge for teenage girls.
They're saying basically this is teaching you who can do a cutting, it's like a cutting
challenge I think is what it's called.
So the point is that these decentralized-
Do we know where this comes from?
Are these things from troll farms?
I don't know.
Because some of them probably are, right?
Yeah.
There's a concept called stochastic terrorism.
There's a good article on Edge which basically is the idea, let's say there was a foreign
state actor that wanted to mess things up in the US population.
Trying to control a specific person to do a specific thing is hard, but trying to get
an already kind of disenfranchised group more radicalized that makes it more likely that
some of them do some harmful stuff is easy.
Think about, you last texted me, Joe, on January 6th.
We had a quick text exchange because I think that's an example of, and I'm not going to
claim that everyone, that's an example I think I would say, of I can basically go into a
group of the Boogaloo Boys or Stop the Steel groups or something like that and I can just
seed stuff that's like, hey, let's get our guns out, let's do this and I'm just hinting
at that idea.
I'm not telling one person to go do something, I'm not controlling anyone.
I'm just hinting and there's a wide enough group there that people can take action.
That's one of the other decentralized power tools, but I just wanted to close the thought
of on the bowling alley.
The bowling alley, one gutter is like, let's lock it down with surveillance, let's lock
it down with Mark Zuckerberg controls everything, let's lock it down with the government, tells
us what we can and can't do on computers.
The other gutter, which is the decentralized power for everyone, which without people having
the wisdom to wield that godlike power or at least not evidence in people's own usage
of it right now.
We've incentivized people to do destructive things just for likes.
In certain places there is an incentive for those things to happen, it's not just by accident,
it's by design and incentivized.
You just said it's super important.
It's a population that is getting continuously more radicalized on all sides, that simultaneously
has continuously more powerful tools available to them.
In a world that's increasingly fragile and so if you have an increasingly fragile world
meaning more interconnected global supply chains that have where a collapse somewhere
leads to collapse everywhere, more sensitive infrastructure, things like that, if you have
an increasingly fragile world, you have more and more radicalized people and you have those
radicalized people having access to more and more powerful tech, that's a just fragility
across lots of different dynamics.
This is why the social media thing is so central is it's a major part of the radicalization
process.
It's both a major part of the radicalization process and it's itself an example of the
centralized control censorship which we don't want and the decentralized viral memes for
everyone which radicalize and enrage people and polarize democracies into not working.
The thing is in those two gutters, the gutters are getting bigger every day, like on each
side.
You've got more potential for centralized control, you've got China basically doing
full control over its internet, doing a bunch of stuff to top down control and the other
side you have more and more decentralized power in more hands and that gutter is growing.
The question is how do you basically, we have to bowl a strike down the center of that
alley but it's getting thinner and thinner every day.
The goal is how do we actually, it's almost like a test, we are given these godlike powers
but we have to have the wisdom, love and prudence of gods to match that set of capacities.
You were just mentioning what China is doing to regulate its internet, that's what you're
worth speaking about.
Yeah, have you been following this?
Yeah, that's what terrifies me is that we have to become like China in order to deal
with what they're doing.
I feel like one step moving in that general direction is a social credit score system
and I'm terrified of that and I think that that is where vaccine passports lead to.
I really do and I think this idea that they're slowly working their way into our everyday
lives in this sort of inexorable way where you have to have some sort of paperwork or
some sort of a Q code or something on your phone or QR code, that scares the shit out
of me because you're never going to get that back.
Once the government has that kind of power and control, they're going to be able to exercise
it whenever they want with all sorts of reasons to institute it.
I'm worried about that too but I will say also, just to also notice that everywhere
there is a way in which a small move in a direction can be shown to lead to another
big boogeyman and that boogeyman makes us angry, social media is up regulating the meaning
of everything to be its worst possible conclusion.
A small move by the government to do X might be seen as this is the first step in this
total thing.
I'm not saying that they're not going to go do that, I'm worried about that too but
to also just notice the way that social media amplifies the degree to which we all get kind
of reactive and triggered by that.
The thing I think is worth mentioning is what China is doing regarding its internet because
it's seeing real problems and we might not like their solution.
We might want to implement a solution that has more civil liberties than we should.
Let's explain what they're doing.
Yeah.
I'll do it quickly.
It's almost, it's quite literally as if Xi Jinping saw the social dilemma because they've
in the last two months rolled out a bunch of sweeping reforms that include things like,
if you're under the age of 14 and you use Douyin, which is their version of TikTok,
when you swipe the videos, instead of getting like the influencer dancing videos and soft
pornography, you get science experiments you can do at home, museum exhibits and patriotism
videos.
Wow.
And you're getting stuff that's educating because they want their kids to grow up and
want to be astronauts and scientists.
Yeah.
They don't want them to grow up and be influencers.
And I'm not, when I say this, by the way, I'm not just to be clear, I'm not praising
that model.
Just noticing all the things that they're doing.
Right.
Well, I'll praise it.
If you can influence people, that's a great way to do it.
They also limit it to three hours, sorry, 40 minutes a day on TikTok for gaming.
Let me actually do the TikTok example.
So they do 40 minutes a day for TikTok.
They also, when you scroll a few times, they actually do a mandatory five-second delay
saying, hey, do you want to get up and do something else?
Like because when people sit there infinitely scroll, even Tim Cook recently said mindless
scrolling, which is actually invented by my co-founder of the Center for Humane Technology,
Azaraskan.
He invented, he was in the social dilemma.
He's the one who invented that infinite scroll thing.
China said, hey, we don't want people mindlessly scrolling.
So after you scroll a few videos, it does a mandatory five-second like interlude.
They also have opening hours and closing hours.
So from 10 p.m. until 6 in the morning, if you're under 14, it's closed, meaning one
of the problems of social media for teenagers is if I'm not on at one in the morning but
all my friends are on and they're still commenting on my stuff, I feel the social pressure.
I'm going to be ostracized if I don't participate.
And if your notifications are on, your phone keeps buzzing.
Totally.
And even if they're not on, it's like, oh, but I want to see if they said something about
my thing.
So it's a, we call it a multi-polar trap.
If I don't participate but the other guys are, I'm going to lose out.
And Facebook and these companies, they know that by the way.
Even Netflix said their biggest competitor is sleep.
So one of the, because they're all competing for attention.
So when you do this mandatory thing where you say we're going to close from 10 p.m.
to 6 in the morning, suddenly everyone, if you're in the same time zone, it's another
important side effect, can't use it at the same time.
So these are some examples.
For their military, by the way, when you, if you're a member of the Chinese PLA army,
you get a locked down smartphone.
It's like a light phone.
It's like hyperlocked down.
You can't do anything.
By contrast, we know that Russia and China go into our veterans groups on Facebook and
they actually try to sow disinformation, try to radicalize veterans.
Hey, Afghanistan happened.
Don't you really piss?
Let me show you 10 videos, right?
And this is like dosing people with more mental health problems.
So in a bunch of different ways, we see that-
Specifically, if you want to drive civil war in a meaningful way in the U.S., take the
people who have real tactical capability and radicalize them.
And so target those groups in particular.
And that's like, it makes sense why their military wants to lock down the ability for
external influence.
Of course, yeah.
So while we're spending all this money building physical borders, building walls, or spending
$50 billion a year on the passport controls and the Department of Homeland Security and
the physical...
If Russia are trying to try to fly a plane in the United States, we've got Patriot Missiles
to shoot it down.
But when they try to fly an information, like precision-guided information bomb, instead
of responding with Patriot Missiles, we respond with, here's a white glove Facebook algorithm
that says, which zip code or Facebook group would you like to target?
So it changes the asymmetries.
Typically what made the U.S. powerful was the geographic, we had these huge oceans on
both sides.
It gives us a unique place in the world.
When you move to the digital world, it erases that geographic asymmetry of power.
So this is a imminent national security threat.
This is not just like, hey, social media is adding some subtle pollution in the form of
mental health or, hey, it's adding a little bit of polarization, but we can still get
things done.
It's an imminent national security threat to our continuity of our model of governance,
which we want to keep.
Spoken to people in power, have you spoken to Congress people about this?
Yes, but I'm hoping many more of them watch this because I think people need to see the
full scope.
I really do want to make sure we're not sounding like just full disaster porn because we want
to get to the point.
Don't worry about that.
Go full disaster porn.
Well, it just ...
Better that than not.
It's not meant to scare people just to get an appraisal of what is the situation that
we're in.
It's going to scare.
The reality is going to scare people.
Reality is scary.
It should scare people because we're so far behind the A-ball.
There's a really important point Tristan was just at that we actually need to double-click
on, which is that democracies are more affected by what's happening with social media than
authoritarian nations are and for a number of reasons, but do you want to ...
Well, and we sort of hinted at it earlier, but when social media's business model is
showing each tribe their boogeyman, their extreme reality, it forces a more polarized
political base, which means to get elected, you have to say something that's going to
appeal to a base that's more divided.
In the Facebook files that Francis Haugen put out, they showed that when Facebook changed
the way its ranking system worked in 2018 to something called Meaningful Social Interactions.
I won't go into details.
They talked to political parties in Europe.
Here we are.
It's 2018.
They do an interview with political parties in Poland, in Hungary, in Taiwan, in India,
and these political parties say, Facebook, we know you changed your ranking system.
Facebook smugly responds, yeah, everyone has a conspiracy theory about how we change our
ranking system because those stories go viral, and they're like, no, no, no.
We know that you changed how your ranking system works because we used to be able to
publish, here's a white paper on our agriculture policy to deal with soil degradation, and
now when we publish the white paper, we get crickets.
We don't get any response.
We tested it, and the only thing that we get traffic and attention on is when we say negative
things about the other political parties, and they say, we know that's bad.
We don't want to do that.
We don't want to run our campaign that's about saying negative things about the other
party, but when you change the algorithm, that's the only thing we can do to get attention.
It shows how central the algorithm is to everything else.
If I'm Tucker Carlson or Rachel Maddow or anybody who's a political personality, are
they really saying things just for their TV audience?
Are they also appealing to the algorithm because more and more of their attention is going
to happen downstream in these little clips that get filtered around, so they also need
to appeal to how the algorithm is rewarding saying negative things about the other party.
What that does is it means you elect a more representative class that's based on disagreeing
with the other side and being divided about the other side, which means that it throws
a wrench into the gears of democracy and means that democracy stops delivering results.
In a time where we have more crisis, we have more supply chain stuff and inflation and
all these other things to respond to, instead of responding effectively, it's just division
all the way down.
But it's been division from the jump even long before there was social media, so all
social media is doing-
It's putting gasoline on it.
Yeah, it's taking advantage of a trend that already existed.
My opponent is reasonable.
I feel like I'm just a better choice.
You could disagree because he's a great guy, but this is how I feel.
No one's doing that.
Totally.
Again, but notice, though, in this 2018 example how specific the change was.
Those political parties before 2018, they could get elected in those countries because
they hadn't gone as partisan maybe as we were yet.
They could have gotten elected in getting attention by saying, here's a white paper
about agriculture policy, but after 2018, the algorithm has the master say, everyone has
to appeal the algorithm.
If I'm a small business, I have to appeal to the algorithm.
If I'm a newspaper, do I just write the articles I want to write or the investigative stories,
the Fourth Estate that we need for democracy to work?
No, I have to write the clickbait title that's going to get attention.
So I have to exaggerate and say, Joe Rogan just takes horse dewarmer because that's
going to get more attention than saying he took ibermectin.
Particularly in this world where no one's buying paper anymore, everyone's buying everything,
clicking online, so very few people are even subscribing, so you have to give them these
articles and then have these ads in the articles.
Those publishers, and that's also driven by the business models of these central tech
companies, Facebook, Twitter, and Google.
There's two feedback loops that he just mentioned politically.
If you have Facebook and other platforms like this polarizing the population, then the population
supports a more polarized representative class, but the representatives to be elected are
doing political ads, and so the political ads then further polarize the population.
And so now you have this feedback loop, and then the same is also true with media.
The media has to, meaning newspapers, television, still has to do well on the Facebook algorithm
because more and more there's a monopoly of attention happening there, and it's someone
seeing a clip there that has them decide to subscribe to that paper or keep subscribing
to it or whatever it is.
So you end up having the algorithm radicalizing what people want to pay attention to, where
then the sources of broadcast have to appeal to that, which then, in turn, further radicalizes
the population.
So these are runaway feedback loops.
And what's the solution?
Well, actually, you asked me this last time, and I dodged the question, and part of it is
because it's connected to a set of broader issues that I think is actually really deep
in Daniel's line, which is actually the reason I wanted us to do this together at this time.
There's obviously many steps to this, right?
So once you've kind of let this cancer sort of spread, if you take out the thing that
was causing the cancer, we've now already pre-polarized everyone's beliefs.
Like when you say, what's the solution to all this?
All of our minds are running malware, like we're all running bad code, we're all running
confirmation bias.
Except no one thinks that they are running bad code.
Everything's the other ones are, but not me.
The point is that all of us, people on all sides of the political aisles and all tribes,
we've all been shown our version of the boogeyman, our version of the inflated thing that got
our attention and then made us focus on that and then make us double down and go into those
habits of those topics being the most important.
And so we have to realize that.
I almost think we need a shared moment for that.
I wish the social dilemma was a little bit more of a, it was a shared moment, but I think
there's almost like a truth and reconciliation moment that we need to unwind our minds from
the cult factory.
Because it's a cult factory that found each of the little tribes and then just sucked
them in together and made them in a self-reinforcing chamber.
So let's say we take any issue that some people care about and think is central, whether we
take social justice or climate change or U.S.-China relations, if half of the population thinks
that whatever half of half the population has a solution they want to implement, carbon
taxes or whatever, other half of the population is polarized to think that that is bad and
terrible and going to mess everything up.
So that other half are still political actors and they're going to escalate how they counter
that.
How do you get enough cooperation to get anything done, especially where there are real issues
and not just have all the energy become waste heat?
In autocracy, let's take China as an example where you don't have to, where you don't have
so much internal dissent.
You don't have that issue, so you can actually do long-term planning.
So one of the things that we see is we have decreasing ability to make shared sense of
the world.
And in any kind of democratic society, if you can't make shared sense of the world,
you can't act effectively on issues.
But the types of tech that are decreasing our ability to make shared sense of the world
are also increasing the speed at which tech is changing the world and the total consequentiality
of it.
That's one way to start to think about this bowling alley example is we're having faster
and faster, more and more profound consequential effects and less and less ability to make
sense of it or do anything about it.
So underneath the AI issue, the CRISPR issue, the US-China issue, the how do we regulate
markets issue, the how do we fix the financial crisis issue is can we make sense of anything
collectively, adequately, to be able to make choices effectively in the environment we're
in?
Underlying it, Tristan was laying out that you got these two gutters, right?
You've got decentralized catastrophe weapons for everyone if we don't try to regulate the
tech in some ways.
And that world breaks.
Or to say if we don't want decentralized catastrophe weapons for everyone, maybe we do something
like the China model, but where you have ubiquitous surveillance and that's a dystopia
of some kind.
And so either you centralize the power and you get dystopias or it's decentralized and
you get catastrophes.
And right now, the future looks like one of those two attractor states most likely.
Catastrophes are dystopias.
We want a third attractor.
How do you have a world that has exponential tech that doesn't go catastrophic where the
control mechanisms to keep it from going catastrophic aren't dystopic?
And by the way, we're not here saying like, go buy our thing or we've got a new platform.
This is not about, this is just about describing what is that center of that bowling alley
that's not the gutters that we can skate down.
The closest manifesting example of this so far, although when you do one more construction,
I think which is this, but is Taiwan because Taiwan, actually I think I talked about it
last time we were here, is a, they've got this digital minister, Audrey Tang, who has
been saying, how do you take a democracy and then use technology to make a stronger democracy?
So you can look right now at the landscape, you say okay, we can notice that China, countries
like China, autocratic countries are employing the full suite of tech to make a stronger
authoritarian autocratic society.
They're adding surveillance, they're doing cameras everywhere, they're doing sesame credit
scores, they're using TikTok to educate their people instead of turn them into influencers.
They're using the full suite of tech to create their kind of autocracy that they want to
see.
By contrast, open societies, democracies, Western democracies, are not consciously saying,
hey, how do we take all of this tech and make a stronger democracy?
How do we have tech plus democracy equals stronger democracy?
One of the other reasons I wanted to talk to you is so far I think the tech reform conversation
is like, how do we make social media like 20% less toxic and then call it a day or like
take a mallet and break it up and then call it a day.
That's not enough when you understand the full situation assessment that we're kind
of laying out here of the skating down the middle of the bowling alley.
The thing that we need that competes with that thing, because we can't just also allow,
that thing is going to outperform.
The China autocratic bottle is going to outcompete a democracy plus social media that is 20%
less toxic, isn't going to outcompete that thing.
Ultimately, in long runs going to, but what's fascinating is they're willing to forego any
sort of profits that they would have from these children from 10 p.m. to 6 a.m. in order
to make a more potent society of more influential, not influencer, but influential, more educated,
more positive people that are going to contribute to society.
This is something that I think you can only do if you have this inexorable connection
between the government and business, and that's something that they have with corporations
and with the CCP over there.
They have this ability because they're completely connected.
The government is-
What did the senator tell us about China's-
Oh yeah, this is a great point.
We were talking with a sitting senator who was saying, or at some national security conference,
talking to a foreign minister of a major EU country and said, who do you think the CCP,
the Chinese Communist Party, considers to be the greatest rival to its power?
You would say, United States, right?
Right.
He said, it's not the United States.
They consider their own technology companies to be the greatest threat to their power.
So that's why when someone like Jack Ma steps out of the line, they lock them up in the
brig for a few months and shut his mouth.
Cryptocurrency, oh, that's a threat to our financial system.
Oh, Bitcoin specifically.
Oh, TikTok, that's a threat to the mental health of our kids.
Oh, Facebook, we don't want that in our country.
That would open up our military to foreign hacking.
So they see correctly that technology is the new source of power of basically what guides
society.
It is the pen that is writing human history.
It doesn't have-
If you let just for-profit motives, again, coupled with how do I get as much attention
out of people as possible in the race to the bottom of the brainstem to suck it out
of people, that thing doesn't work with society.
That breaks it.
So they see that appropriately and then say, let's do something about it.
Now, the cynical view is obviously they're a communist country that's just doing their
thing.
That's a cynical perspective, but a post-cynical perspective is they're also appropriately
recognizing that there's a certain threat that comes with allowing unregulated technology.
So one way to think about this, Tristan was just saying that they recognize the power
of new technologies and the need to be able to employ them if they want to be effective.
We can see how much the world responded, how much the U.S. responded to the possibility
of a nuclear bomb with the Manhattan Project, just even the possibility that the Germans
would get it and how that would change everything asymmetrically.
And so we make basically an indefinite black budget, find all the smartest scientists in
the world, because that much asymmetry of tech will determine who runs the world.
It's important to also say there are some people who will have just like a knee-jerk
reaction that says, oh, you guys are just being catastrophic.
Yeah, you guys are just trying to scare us, disaster porn.
There have always been these risks.
We always come through them.
Really until World War II and the bomb, there was no way for us to actually mess up the
habitability of the world writ large.
We could mess up little local things.
And in fact, that happened.
Most previous civilizations did go extinct for different reasons.
But World War II was the first time we had truly globally catastrophic tech, and we had
to build an entire world system, mutually assured destruction, the Bretton Woods world,
the IGO world, to basically not use that tech.
Well now, that was basically the first catastrophe weapon, and then we had only two superpowers
that had it, so you could do mutually assured destruction, and it's really hard to enrich
uranium and make nukes.
It's not hard to do these types of tech, right?
That's the whole point.
We have now dozens of catastrophe weapons, many dozens of actors, including non-state
actors who have them, and so we're like, oh, we're in a truly new phase.
This isn't the same as it's always been.
We're in a novel time of risk, and the exponential technologies, with kind of computation at
the center, AI, and these other ones we're talking about, are so much more powerful than
all forms of legacy power that only the groups that are developing and deploying exponential
tech will influence the future.
That's like the big story.
And then we would say, well, which groups are developing and deploying exponential tech?
Well, China is, autocratic nations are.
Facebook is, Google is, like major corporations that are also top-down non-democratic systems
are, and they're becoming, like, Facebook has 3 billion people, the U.S. has 300 million
people, right?
We're talking about something that has a global scale of influence, but is really a top-down
system.
The corporation, though.
So you either have corporations that are wielding the power of all this technology for mass
behavior modification, surveillance of everyone, perfect sort of understanding of their psychological
traits, and then moving them that scale.
But in the tech corporation model, they're doing it for a for-profit motive.
Whereas in the CCP model, they're doing it for their ideological goals.
But neither of them are democratic.
Neither of them have some kind of participatory governance, jurisprudence of, for and by the
people.
And the open societies are not innovating.
And how do we develop and deploy exponential tech in an open society way?
And that's fundamentally what we're saying has to be, like, the central imperative of
the world right now, is you're not going to be able to compete with groups that are developing
and deploying exponential tech if you are not also.
But how do we do that in a way that preserves the civil liberties that we care about, actually
advances them, and can advance participatory governance and collective intelligence?
And that's not even...
Well, the simple way is you don't, right?
The simple way is you lock things down and you become an autocratic, yeah.
So you either beat China by becoming China, or you figure out a third way, and you'd like
to see there be a third way.
I'd like to see a third way, too, but I don't see it.
That's what's terrifying to me.
A little more about Taiwan is actually worthwhile.
We're moving in the direction of China more than we're moving in the direction of some
new utopia.
Currently, yes.
Yes.
Right.
So what about Taiwan?
Well, so you can't even mention that.
See what happened with John Cena?
No, what happened?
You didn't see that?
Yeah.
There was an opening weekend for Fast and the Furious 9, I believe.
And John Cena, accidentally or inadvertently, said that Taiwan is going to be the first
country that sees the movie.
Well, China doesn't recognize Taiwan as a country.
And if you want to do business with China, you can't say that.
That was on full display, and it made people very skeptical of the World Health Organization
when one of their spokespeople was having a conversation with a journalist, and when
she brought up Taiwan's response, and other countries have done it like this, but Taiwan's
response, and he disconnected his line.
Oh, I did see that.
Did you see that?
Yeah.
And then came back on and glossed over very quickly.
He said, China's doing a wonderful job.
Let's move on.
And she was like, but Taiwan, and he's like, China is amazing, and China this, and China
that.
Well, John Cena, by saying that Taiwan was the first country that was going to see Fast
and Furious, pissed off China, and then John Cena made a video where he spoke Mandarin,
and in it is like this weird video.
You should watch it, because you haven't seen it.
Let's show it to him.
Show it to him, because he's apologizing to China in the weirdest way, saying, I really,
really respect China, and I'm so sorry, and I made a mistake.
I was very, very tired.
So this is the perfect example of a kind of dystopia, that we don't want to go to a future
where people are all accommodating or can't feel or think their actual thoughts because
they have to appeal to some source of power.
Exactly.
And the source of power is financial, because $160 million was the opening weekend for Fast
and Furious 9, and 134 million of it came from China.
I have to say, in the current situation, I have made a lot of interviews, and in one
of them, I made a mistake.
Everyone asked me if I could use Chinese, people at Fast and Furious 9, gave me lots
of interview information.
I made a mistake.
I have to say right now, it's so, so, so, so, so, so important.
I love and respect China and Chinese people.
I'm so, so sorry for my mistake.
I'm sorry, I'm sorry, I'm very sorry.
You have to understand, I love and respect China and Chinese people.
I'm sorry.
That's it.
I have to say what he's sorry about, and this is wild shit.
When you see this guy who is one of our big major action movie stars, just on his knees
apologizing to China.
Who hadn't said anything bad about China?
Not at all.
All he did was say Taiwan is a country, which you can't say.
And if someone talks about something that's not the mainstream narrative in the tech
companies currently...
I can't believe they ever saw that.
I think I'd seen it in a John Oliver video or something briefly, so I would add taste
of it.
But yeah.
That's hilarious.
That's where you get your news?
I don't know, but I was working out sometime.
So this is a good example of we don't want to live in dystopias where our thought and
our ideas and our free expression and our ability to figure out what's true in an open
and way because we don't know what's true.
We need to protect that.
But we also remember the last time I ended our conversation talking about Orwellian dystopias
and Huxley in dystopias, that quote about amusing ourselves to death, Orwell feared a
world where we would ban books and censor information, Huxley feared a world where we'd
be drowned in irrelevance and distraction.
So that's kind of another version of the two gutters.
Brighton and we're kind of getting a little bit of both.
We're getting a little bit of, hey, we don't like the way that the companies are doing
this sort of censorship or platforming, de-platforming of people.
We also don't want the unregulated like virality machines where the craziest stuff and the most
controversial stuff that confirms our biases goes viral because both those things break
society.
Right.
So let's get back to that again.
What's the solution?
Well, let me just make one narrow solution for that one because it's funny because Frances
in her own testimony says Facebook wants you to believe in false choices between free
speech and censorship.
There is a solution that Facebook themselves knows about for this particular problem, which
is actually just to remove the reshare button, basically the retweet button, the reshare
button.
What they found in their own research, Facebook sent something like a billion dollars or something,
multi-billion dollars on integrity, content moderation, all that stuff.
And they said in their own research, it would be more effective than the billions of dollars
they spent on content moderation to just remove the reshare button after people click it twice.
So in other words, you can hit reshare on a thing and it goes to all your friends.
And all those friends, they still see a reshare button and they can click reshare and then
it goes to all their friends.
After that, there's no reshare button.
If you just remove the instant frictionless, like make my nervous system twitch and then
boom, I'm resharing it to everybody, if you just remove that one thing, you keep freedom
of speech, but you kill an irresponsible reach, just like instant reach for everyone.
But you also kill the ability to retweet something or share something that's interesting.
You could still copy and paste a thing and share it.
You can still do that.
Yeah.
But I think that we have to ask, there's a story about Steve Jobs that I've referenced
to several times.
Someone, you'd appreciate this because it's about podcasts, someone showed him the latest
version of the podcast app and someone wanted to make on the iPhone, this is on the iPhone
early days.
And they're like, what if we made it so in the podcast app, we had a reshare button and
you could see a feed of all the stuff that your friends were looking at.
I mean, it sounds like it's just like social media and it would be really engaging and
people would get sucked into podcasts.
But Steve Jobs' response was, no, if something is truly that important and truly that meaningful,
someone will copy and paste it as a link and be like, you got to check out this interview
with Joe Rogan, which I hope people do with this episode, because it's crossing a threshold
of significance of what is truly worth our undivided attention, which is also the name
of our podcast.
We call it that.
As opposed to just publicizing something and spending a bunch of money or doing a bunch
of PR work.
Or creating influence or culture or just rewarding, again, the controversy and the conspiracy
theory and the thing.
And again, I shouldn't use that phrase because it sounds like you're always one-sided on
it, but just the most kind of aggressive take on anything, the most cynical take on everything
being rewarded.
It's nowhere is it written that a virality-based information ecosystem, where you have the...
People are familiar now with the metaphor of a lab that's doing gain-of-function research
and the idea that something can get leaked out of the lab, just like that is a metaphor.
But today, we have the TikTok Institute of Virology, we have the Zuckerberg Institute
of Virology, and they're testing what makes the memes go as viral as possible, right?
They're like, hey, if we make it have this photo, if we present it this way, and if we
have these reshare buttons, except their goal is to create these mimetic pandemics.
Their goal is to have every idea, especially the ones that most excite your nervous system
and your lizard brain, go as viral as possible.
And then what you can even say that the Zuckerberg Institute of Virology released this mimetic
virus, and it shut down the global democracy world, because now we don't have shared sense
making on anything.
But we do, if everyone's intelligent and objective, and they just don't use the reshare button
for nonsense.
The problem is that people are...
We were impulsive, and we also don't spend a lot of time researching a lot of the things
that we read.
We prefer to be smug and be right.
They know that, and they prey on that, right?
They prey on, hey, you're right.
You should totally reshare that thing.
You should feel creative about it.
Well, it's also, things are, if true, spectacular, and it takes oftentimes hours to find out
something is true or not true.
And we can't even trust...
Or we don't even know, right?
Right.
It's very difficult to even trust...
Talk about how social media kills science.
You want to do that with construction?
Well, scientific bias, right?
We talked about that.
If someone has kind of an emotional bias towards what they already generally think is true,
even if they're following the scientific method, well, what experiment they decide to do, what
they go looking for, will be influenced, because there's a lot of things to look at, right?
Am I trying to do science on natural supplements versus on drugs versus on vaccines versus...
Like, I'll have an intuition that is the basis of a hypothesis or a conjecture that then
I'll do the scientific method on.
Everything can be biased.
So a point that Tristan was saying earlier that I think is really important is that this
model of Facebook, and it is not just Facebook, it's TikTok, it's all of the things that do
this kind of attention harvesting, which ends up, it doesn't intend to polarize.
It's a byproduct.
It's not trying to do...
Right.
It's a second-order effect.
An unintended consequence.
In the way that the unintended consequence of cigarettes had an externality, which was
lung cancer, and oil companies had oil spills and so then government had to regulate it,
these companies are fundamentally different because their externality is a polarized population,
which in a democracy decreases the capacity of government directly.
So the big oil companies and big pharma companies and whatever can do lobbying and campaign
budget support and whatever they can to affect government, but their mode of operation is
not directly decreasing the effectiveness of government.
The mode of Facebook's operation directly polarizes the population, which polarizes
the representative class, which creates more gridlock, which decreases the capacity of
government, both relative to other nations that don't have that issue and relative to
their own internal tech issues, right, and their own internal domestic issues.
So it can't even regulate Facebook.
In the example I gave at the beginning of the senator who was going to meet with Francis,
but then couldn't because these stories that polarized them went viral.
She should have shamed that senator.
That's what she should have done.
So that would have gone viral.
And that would have gone viral and then he would have backed down because then his constituents
would have been mad at him and go, hey man, what's interesting is that Instagram doesn't
have a share feature.
Yeah.
I just realized that.
The share feature isn't actually the key.
TikTok is not really emphasizing shares.
But Facebook is.
Facebook is, but the key is virality, right?
Virality.
Here is one way to get virality.
Yeah.
TikTok is just looking at engagement and upregulating the things that get most engagement.
This is actually a key point because let's say that we tried to make a piece of legislation
based on thinking it was about shares, then Facebook would just move to the TikTok algorithm.
Just by what you look at the most, that thing gets reshared to other people.
And you get viral based on unconscious signals as opposed to explicit click signals.
So there's a deeper point here, which is not, is there a piece of regulation that we can
put in, even if we trust the government to do that?
Let's even say we had a very trustworthy government.
It's can the government regulate at the speed that tech can outmaneuver it?
Well, and here's the other question.
If you didn't have any algorithms whatsoever, wouldn't you be now open to being manipulated
by troll farms, just simply by volume, you know, if they have 100,000 accounts at each
individual location, they have 100,000 locations and they're just pumping out different Instagram
pages and TikTok pay, and we don't even really even know how many they actually have because
they discover them.
Facebook shuts down 2 billion fake accounts per quarter.
I'm sure they get all of them.
Holy shit.
And this is before AI, before the GPT.
You're obviously being sarcastic by saying they get all of them.
They don't.
Exactly.
Yeah.
Just to let people know that I'm totally paying attention.
That's insane.
2 billion per quarter, fake accounts.
Is there a centralized area where these are coming from?
Is it all Russian troll farms?
Are they some of them political ones that are used against opponents?
Well, one of the problems is that we don't know because actually that's not true.
Facebook has been...
I really want to celebrate all the positive moves they make, by the way.
This is not just so I'm clear and we're clear.
This is about finding what's an earnest solution to these problems.
All the times they make great decisions that are moving in the positive direction.
We need to celebrate that.
They do these quarterly reports, I think, called information quality reports or they
publish every quarter how many accounts they take down.
But it's just like a PDF, they're just putting out a post as opposed to letting external
researchers know, for example, in each country, what are the top 10 stories that go viral?
How do they find out that someone's a troll post?
I don't know.
I mean, there's classifiers that they build, there's activity.
You can tell.
Usually, if you've ever had this happen, you use Facebook and you click around a bunch
and then it says, you look like you're clicking around too much.
Have you ever gotten one of those messages?
No.
There's occasionally a person can trigger a thing that makes it, they're like, are
you real?
They're trying to figure out if you're real.
If you click around a lot, you're not real?
Because these bots, a lot of what they're doing is they're going around harvesting
information so they want to click around various profiles and they download the information
and there's ways that people try to use.
More than a person could be able to do just by clicking.
Yeah.
It's a hard problem, right?
Yeah.
Because the tech is getting better at simulating the behavior of a human and then simulating
social media.
People who are proposing that social media and the internet as a whole needs rigorous
identity layer.
I would say that's a requisite need for where we're going.
I was thinking that about Twitter a long time ago.
We kind of have that with Facebook, but it's not rigorous, obviously.
But Twitter, you can have jack me off 69 and that's your Twitter handle and with some
weird Gmail account and then just post nonsense.
There's no ability to, for justice in that system, there's also no accountability, there's
also no ability for the user reading somebody else's thing to know who they are, right?
For the veterans group or the whichever group to know, is this a Russian troll farm that
is pretending to be a Christian or whatever.
Especially, is this even a human or is this an AI in the very near future?
The ability to be able to know this is a human and this is actually the human that they say
they are is not an adequate solution, but it's an example of a solution.
This, of course, then creates other issues.
One of the things we've liked about the internet is anonymity, because if there's rigorous
identity, who has access to that information and am I now centralizing data?
How do you become a whistleblower, which is huge, or how does something like Arab Spring
happen without anonymity?
There's a whole decentralized community.
There's a great movement called Radical Exchange by Glen Weil and they're trying to create
part of this third attractor, what's the center of the bowling alley that's a digital version
of democracy?
What are decentralized ways of proof of personhood?
There's a project called IDENA.
There's a bunch of things you can look up by Radical Exchange's work.
It's part of a whole movement of which Taiwan is included, which is that, I don't know if
we really got to the Taiwan example, but...
We didn't.
Okay.
We showed John Cena instead.
Oh, that's right.
That's right.
People need to get it because it's an example of what is working.
It's a solution.
It's a direction of how we can go, which is you can only fit so many people into a town
hall to deliberate.
There's a limit to our idea of democracy is guided by ideas from 200 years ago.
They've created a system called POLIS, which is a way of gathering opinions about various
ideas and then seeking who wants more funding for various things, less funding for various
things.
Whenever there's an unlikely agreement, so they sample a bunch of people, say, you sit
over here, you sit over here, they get these clusters.
These people kind of like this, these people kind of like these other things.
Whenever there's an unlikely agreement between those clusters, in other words, consensus,
rough consensus, that's what they sort of boost to the top of that system.
Everyone's seeing areas of common ground, common ground, common ground, as opposed to fault
line of society, fault line of society, be more angry, join the common thread, et cetera.
Then you're invited into a civic design process where you actually say, hey, I don't like
the tax system.
They're like, great.
We're going to invite 30 of the people who were part of that rough consensus who are
like, let's improve the tax system.
Let's talk about how we're going to do it.
They do a combination of in-person stuff, this is a little bit before COVID, and Zoom
calls, and then do these mechanisms to kind of get an idea of where do people agree and
then how do we make it better.
They've done this with air pollution.
They have a huge air pollution problem because of the lithography that they do with chips
and things like this.
They do it with budgeting.
They also have a transparent budget for the entire Taiwan government so people can see.
Imagine if the US federal budget, you don't know if you want to do this, but lived on
a blockchain where you had transparency into all the what was getting funding, and that
would create more trust in government because you could see essentially who's getting the
big contracts and for how much, and that was more accessible, and there was a civic participatory
process where more people could contribute and participate in identifying areas of inefficiency.
You could even imagine a place where citizens could get rewarded by saying, hey, this is
inefficient.
We could do it better this way.
If you identify places where it could get more efficient, you could get money or resources
by making the whole system work better for everyone.
If you ran a current audit of the US government through blockchain, you'd have a goddamn
revolt.
They would go, holy shit, this whole thing is corrupt.
This is infested down to the roots, and that would be a real problem, and I think the Nancy
Pelosi's of the world would really have a hard time with that.
I heard some clip that you did where you were talking about your pot thoughts of people
being in big buildings and the pipes everywhere, and just how weird some aspects of civilization
are.
Think about how weird democracy is.
As an idea, the idea that you can have some huge number of people who don't know each
other, who all believe different stuff and want different stuff, figure out how to actually
agree and work together, as opposed to just tribalize against each other and do their
own thing.
It's actually a wild idea to think that that would be possible at any scale, maybe a tiny
scale where they can all talk.
That's when it started.
It was a tiny scale.
We've always had a scale issue.
In 1776, you could all go into the town hall and fit, and so I wasn't just hearing a proposition
that a special interest group had created and I get a vote yes or no, which will inherently
polarize the population.
Very few propositions get 99% of the vote.
They get 51% of the vote because they benefit something and they harm some other things,
and the people who care about what gets harmed are fighting against it.
That polarizes the population against each other.
Social media then just drives that like crazy.
Just like Facebook saying, hey, this is a conversation about censorship or free speech,
and boom, you just split the population in half.
As opposed to, hey, we all agree we could do a little bit less virality.
We could stop the teenager use in these ways and we'd be better for everyone.
The proposition creation isn't designed to polarize the population.
It just does because as soon as you get beyond the scale, if we can all actually inform what
a good proposition would be by being in the town hall having a conversation.
Just to define a proposition.
I mean, not everybody knows what a proposition is.
Something you would vote on.
What's a good way to go forward?
Before we make a choice on what a good way to go forward is, we have to do some sense
making of what is even going on here.
What are the values?
What's going on here?
That was, to the point, was a conversation.
That happened at a smaller scale.
Also, if you had a representative, the level of tech at the time was something that a very
well-educated person could understand most of.
They could understand a lot of the tech landscape.
Obviously, we're in a situation now where the scale issue of democracy has been completely
broken.
Almost nobody.
We're supposed to have a government of form by the people, but nobody really understands
the energy grid issues or first strike nuclear policy or monetary policy or anything like
that.
Everyone's voice can't be heard.
What Taiwan was working on is, is the tech that is particularly in the West breaking
democracy, could that same tech be employed differently to actually make 21st century
democracy more real?
The same AI that can mess up the information landscape for everyone, could we use that
type of AI that understands language to be able to see what does everyone think and feel
and actually be able to parse that into something we can understand?
There's an online environment that says, here's the distribution of people's values.
Here's the various values people care about.
Here's the emotions they have.
Here are the kind of facts about it.
Then, is there a place where we can actually craft propositions together?
There's a way to be able to utilize these same tools to make democracy more realized,
to make collective intelligence more realized, but right now, as we were saying, autocracies
are working on employing these tools, corporations are working on it, both of which are top down.
Democracies really aren't.
They're outside of Taiwan and Estonia and a few small examples.
What would be the incentive?
Who would be incentivized to use that other than the people?
It's pretty clear that the people don't have control over Facebook, don't have control
over Twitter, certainly don't have real control over the government.
They have control over elected officials who, it's almost universally agreed, will
lie to you to get into office and then not do what they said they were going to do, which
is the standard operational procedure.
What's the incentive and how would these get implemented?
Again, at a small scale, 1776, your representative couldn't lie all that much because everybody,
they lived in the same town, and you could all go see what was going on.
Can we recreate things like, as you were mentioning, people would freak out if they
could actually see how government spending worked.
Can we create transparency at scale?
Can we, in a way, that could create accountability at scale?
We could.
Could we have places where there's direct democracy and people can actually engage in
the formation of what a good proposition is, not just voting yes or no on a proposition
or yes or no on a representative?
Can I stop you there?
How would you say we could?
How would you do that?
How would you have that transparency?
Who would be incentivized to allow this transparency?
If the transparency has not existed up until now, why would they ever allow some sort of
blockchain-type, deep understanding of where everything's going?
I don't think they are incentivized, which is actually why this show is interesting,
because if we're really talking about a government of foreign by the people, where the consent
of the governed is where the power of government comes from, ultimately, and the founding fathers
said a lot of things about that the government will decay at a certain point, particularly
when people stop taking the responsibility to actively engage.
If tech has incentives to produce things that are catastrophically problematic for the
world, and we need to regulate that somehow, and the issues are too complex for individuals
to understand, so you need institutions, but how do you make sure the institutions are
trustworthy?
We have to create new 21st century institutions, but they have to arise of foreign by the people,
which means there's a cultural enlightenment that has to happen.
People actually taking responsibility to say, we want institutions we can trust, and we
want to engage in processes of recreating those.
How do you get people to be enthusiastic about some sort of a radical change like that, other
than some sort of catastrophic event, like a 9-11?
This is why we're talking about all the impending catastrophic events, is to say we don't want
to wait until after they happen.
Maybe we have to do it before something happens.
It would be, but it seems like that's the only way people really change the way they
think about things.
Some almost cultural near-death experience has to take place.
It's like the problem of humanity is paleolithic emotions, medieval institutions, and godlike
tech.
One of the paleolithic emotions is it can't be real until, oh shit, it actually happened.
The test is, we are the one species who has the capacity to know this about ourselves,
to know our paleolithic emotions are limited in that way, and say we're going to take the
action, the leap of faith that we know we need to do.
We're the only species that can do that.
If a lion was in this situation or a gazelle, they can't understand their own mind and realize
they have the one marshmallow mind or the short-term bias or recency bias, they're trapped inside
of their meat suit.
This is a beautiful idealistic notion.
However, in real-world application, most people are just fucking lazy and they're not going
to look into this and they're not going to follow through.
And this is why most people that really study tech-mediated catastrophic risk are not very
optimistic, and they think things like we have to chip human brains to be able to interface
with the inevitable AIs or we have to have an AI overlord that runs everything because
we're too irrational and nasty.
And the question is, there's always been a distribution of how rational people are and
how benevolent they are.
And we have never, with that distribution, been very good stewards of our power.
We've always used our power for war and for environmental destruction and for class subjugation.
But with the amount of power we have now, those issues become truly globally catastrophic.
And this is what almost every ancient prophecy kind of speaks to.
As you get so much power that you can't keep being bad stewards of it, either the experiment
self-terminates or you are forced to step up into being adequate stewards of it.
So the question is, what would the wisdom to steward the power of exponential tech,
what would the minimum required level be?
And that's like the experiment right now.
That's the opportunity for us.
The opportunity, but you're talking about a radical shift in human nature.
Well, it's a possibility.
In human conditioning.
Why don't you give some examples?
Okay.
So, we can look at some cultures that have certain traits quite different than other
cultures as a result of the conditioning of those cultures more than as a result of the
genetics.
We can see that if you look at Jains, the Jains are a religion that is highly emphasizing
nonviolence, even more than the Buddhists.
Where are they?
Asia.
They won't kill plants.
They only eat fruits and things that come from plants.
So you can see a whole population that won't hurt bugs based on conditioning across the
whole scope of human nature, the genetics in it.
You go to a larger culture like the Buddhists and you can see that for the most part, you've
got like 10 million plus people over 3,000 years in lots of different environments that
mostly don't hurt anybody, including bugs as a result of the way they condition people.
You can see that.
Education, conditioning, culture.
You can see that Jews have had historically a level of education that is higher than the
embedding society that most everyone around them has as a result of investing in that.
And so, we're like, can cultures value certain things and invest in developing those in people?
It doesn't mean that everyone is suddenly has the wisdom of gods to match the power
of gods, but can we create a gradient that's like, this is where there used to be this
concept.
I'm building.
What's that?
I'm sorry, I'm hearing what you're saying.
Yeah.
I'm hearing what you're saying, like, idealistically, yes.
But I don't see the motivation for the shift.
I feel like this is, it's a big ask.
It's a big ask.
And a big ask has to come with some sort of a master plan to get people to shift their
perspective.
If you take a look at the like, attractor of catastrophes and the attractor of dystopias,
those are the likely ones.
Right.
But we don't see it.
Like people don't give a shit until it's happening.
Which is why one of those two will probably happen.
Yeah.
Well, and with social media, they do see it.
I think there's a unique moment and the reason I thought it would be an interesting conversation
with the three of us is that social media has become the case.
Like we can now all see it.
We can now, I mean, it took, unfortunately for some people seeing the receipts, which
is what France has provided to things that we all predicted back, you know, eight years
ago.
Mm-hmm.
We understand that that is a consequence of unregulated exponential technologies that
are steering people at scale, making things go viral at scale and dangerous at scale.
So that's a case we can now see that thing.
Can we leverage the understanding of that to realize what bigger thing needs to happen?
That doesn't mean, yeah.
Before we get to the incentive, just imagine as a thought experiment for a minute that
Facebook changed what it was optimizing for.
Because Facebook is this three billion person AI optimized behavior mode machine, right?
It's not like normal companies, and it's important to understand that.
And it's optimizing for engagement, which usually ends up looking like outrage, desire,
addiction, all those types of things.
But let's say that we, could we assess for are people being exposed to different ideas
than the ones they're used to?
Are they actually up taking those ideas?
Are people expressing ideas that have more nuance and complexity?
And you were actually up regulating for those things.
There's a lot of actually quite constructive content on the internet.
And imagine that you could actually personalize development and education.
This is why you started to say, when Tristan was saying what China is doing, where the
kids are seeing museum and science experiments and patriotism, you're like, yeah, that actually
kind of makes sense.
And it makes sense, but it only makes sense when you have an autocratic government that
has complete control of the corporations and their motivations.
Like if the corporations motivations were specifically designed to rake in the most
amount of profit, like Facebook says, you'd never be able to trick them into doing that.
There's no way.
They'd be like, fuck you.
We're not going to do it.
That infringes upon our rights as a business to maximize our profits.
We have an obligation to our stakeholders.
They would never do it.
And we can see how the government took major corporations that had such an effect on society
and made them public utilities or regulated them in the past.
Now could we have a situation where because of conversations like this, there was enough
bipartisan public demand that rather than being totally polarized as a representative
class, the representative class had to unify to say, actually, these platforms are so powerful
that they can't be harming our citizens and harming our democracy.
We actually have to put some regulation not on who gets to speak, but what gets radically
upregulated.
Right, but the problem is the way they would do it is the same way they do like the Build
Back Better bill, where it's 40,000 pages and no one can read the whole thing.
And inside of it, there's a bunch of shit about how they can spy on your bank account.
And locked you down if you spend more than $600 and you have to go to a committee to
decide whether or not you get your money back and make everybody scared and paranoid.
I mean, this is the kind of behavior that our government engages in on a regular basis.
This is not just a big ask for us to get people to be motivated to make this radical change,
but it's a big ask to the government is like, hey, you fucks have to start being honest
now.
And that's not going to happen.
Yeah, it's a tricky proposition.
It's not just tricky.
It changes the way the government has been treating human beings through every single
day of our lifetime.
So do you trust Facebook to hold this power?
Do you trust the government to hold it?
No.
Do you trust individuals to be resilient against all of this power pointed at them that is
so radically asymmetric?
More that.
More I trust people to wake up to the fact that you do have control over your news feed.
You don't have to look at it.
You do have control over what you share and retweet.
You should be more objective about the information that you consume.
You should try to find fact checkers that are independent and are unbiased and are not
motivated by financial means.
There's fact checkers that are clearly connected to parties.
We know this.
So I could similarly argue you're trying to ask too much of human nature.
It's way easier than ask that of the government and ask that of corporations, at least human
beings don't have a personal understanding of the consequences of what they're doing
and they don't have this diffusion of responsibility that both government and corporations have.
The thing about the diffusion of responsibility is one person in a corporation doesn't feel
evil when the corporation dumps pollutants into some South American river.
But that is happening and it is a part of it, but when an individual takes responsibility
for their own actions and if we can somehow or another coach or explain or educate individuals
about their consumption and what kind of impact their consumption has on their psychology,
on their future, on the way they view and interface with the world, that could change.
The reason why these algorithms are effective is because they play to a part of human nature
that we don't necessarily have control over.
What we like to argue over, what we like to engage with.
You know, I brought this up on your podcast before, but I'll bring it up again.
I have a good friend, Ari Shafir, and he ran an experiment on YouTube where he only looked
up puppy videos and that's all he recommended to him.
The problem with the algorithm, except for what you were talking about before with the
QAnon thing, that's fucked.
The problem with the algorithm on YouTube is it accentuates the things that people are
actually interested in.
But when Facebook, those fucks, when they do something like that where someone just invites
people into a group and you can mass invite, I'm assuming through some sort of a program,
right, they're not doing it individually one by one.
So if some QAnon group mass invites a million people and then it's all of a sudden distributing
disinformation to that million people, then you've got a problem with the company.
There's a problem with the way that company distributes information because you're not
allowing people to make the decisions that they could make to clean up their algorithm,
to clean up what they get influenced by, to clean up what their newsfeed looks like.
That's a problem.
That's a problem because it's not as simple as you're giving people choices, this is what
they choose.
You're allowing someone to radicalize, like intentionally radicalize people with either
willing or unbeknownst to them disinformation.
Yeah, and we don't want the Nestle Coca-Cola vending machine in the preschools because
do the kids actually have the ability to win the two-marshmallow experiment in the presence
of that much advertising and the other thing getting it?
Do they understand advertising?
Do they understand marketing?
We want to spot asymmetries of power and the challenge here is the asymmetry is I've
got a trillion-dollar market cap company that has observed 3 billion people's behaviors
and click patterns.
I know more about people before they even know about themselves.
Yuval Harari gives this example, his partner Isaac, he's gay.
His partner Isaac makes two clicks on TikTok and he knows exactly what he wants.
When you have that degree of asymmetry and it's designed with that much power on one
side of the table, a system is inhumane if that symmetry of power is so asymmetrical.
If it's influencing me more than I understand my own brain like a magician, we're not going
to be able to get out of that because if it's playing to my confirmation bias and I don't
know that I have confirmation bias, I'm just run by confirmation bias, that's a form in
which I'm essentially a foot soldier in someone else's culture war.
If it's playing to my social validation and I don't know that it's playing to my social
validation, I don't even know I have a thing called social validation that that's an exploitable
part of me, that's an asymmetric interaction.
By the way, as a part of an ecosystem of solutions, we do need a cultural, Daniel calls it a cultural
enlightenment, but you can just simply say we need a mass education about how technology
influences us that matches.
Everyone who uses social media deserves to know how it works.
In the Carnegie Endowment, they did a sort of meta-analysis for the problem of misinformation.
If you look at 100 organizations serving, how do we deal with this problem?
I think 98% of them said the number two result was at least do digital literacy education
for everyone.
Everyone should understand more about how this stuff works.
To your point about we should be educating everyone to be better stewards of their own
attention, their own information consumption.
When you have bad actors that are manipulating this stuff at scales and at levels that people
don't understand and we're about to have GPT-3 and printing basically full research papers
that justify everything you've ever believed, that's not going to be an adequate solution.
We have to change something at the systemic level.
The question is just how do we get that to happen?
Yeah, no solutions, right?
Well, if we're willing to, I mean...
You know what I'm saying?
We have these ideas of what needs to happen, but this is like what we need to do is get
everybody to stop eating processed food and exercise regularly and only drink water.
You can get like 10 people to do that.
You can get like highly motivated people to do that.
You can get really intelligent, really conscientious people that are considering the impact that
their choices have on their future, but that's not normal human nature.
Also you're dealing with the fact that most people are very unhappy with what they do
for a living.
They're very unhappy with their lives, their personal lives.
There's like a good percentage of people that are not happy with most aspects of their
existence.
Well, they seek distractions.
They seek distractions that might be the only comfort that they have is arguing about global
warming with people online or arguing about second amendment rights.
We've got to take into consideration the motivation for people to engage in these acts in the
first place.
A lot of it is just they're very, very unhappy with their existence.
That's why they get trapped doing this.
When you talk to someone who is like, hey, I realize that I got to get off of social
media.
I don't do anything anymore.
I wake up in the morning.
I have fresh squeezed vegetable juice and then I go on a nice long hike and those are rare
fucking humans.
They do exist, but the idea that we're going to change the course of the vast majority
of our civilization and have most people behave in that manner is very unrealistic.
This is why now add increasing technological automation and the radical technological unemployment
to that.
Meaning automating more of our jobs, et cetera.
Right.
Is that good or bad?
Does that make people less happy or more happy?
For the most part, it makes a radically unemployable underclass, a huge radically unemployable underclass
where at least in feudalism, you still needed the people to do labor.
Now you won't need the people to do labor.
This is why there are a number of people in the upper wealth class who believe in universal
basic income because it's at least the cheapest way to deal with those people.
Now you add the metaverse to that and this is the entry into the matrix world.
Right.
Now this is where we have to get to because that's what I'm really worried about.
What I'm really worried about is the solution will be to disengage with the actual material
world and the solution would be to find yourself almost completely immersed and do whatever
you can to just feed yourself and pay for the metaverse or whatever it is, whether it's
Zuckerberg's version of it, which by the way, I saw in fucking commercial, which is
so strange or is a bunch of like incredibly diverse multiracial kids and they're sitting
around bobbing their heads to a fucking a lot or a tiger that's talking to them and
dancing.
Have you seen that?
I didn't see that.
Please find that.
Because it's like, what are you selling?
The fuck are you selling?
Like it doesn't even show what you're selling.
It's like this weird change from Facebook to meta, right?
And so it's showing this ad.
It's very attractive.
It's interesting.
You see all these people, they look cool and they're all bobbing their head and then like
the tigers talking to them, telling them anything is possible.
You're like, oh, cool, anything's possible.
But you're watching like, what are you saying?
Like I don't even know what you're saying.
Like what is this?
Like watch this, because it's so fucking weird.
It's not molding.
Of course not.
Too many people are connected to the metaverse.
It's failing.
So it's the same thing, but different message.
I just thought when the audience started that was weird.
Go ahead.
But see the same thing.
It's like cultivated, multiracial, multiethnic groups.
This is the dimension of imagination.
So the toucans are dancing, pelicans are dancing, the tiger let's go to the buffalo.
Look, look, everybody's bobbing their head and no one's going, what the fuck is going
on?
They're all bobbing their heads, right?
But what is this?
This is going to be fun.
No it's not.
We're fucked.
This is not going to be fun.
This is a trap.
This is a trap.
They're going to lure you into this and you're not going to give a shit about your regular
life anymore because it's going to be so much more exciting.
And next thing you know, they're going to say, listen, they'd be much more involving
if you put a gasket in the back of your head and they could just connect you straight to
a pipe and then you're in the matrix.
A few things to say.
The competition for attention and the attention economy was always about the metaverse.
We've been living in the metaverse for a long time because it's about how do you capture
and own and control people's personal reality.
That's what Instagram, Facebook, TikTok, YouTube, the whole thing, that's what these
things are.
One of the things that this makes me think about, that's subtle actually and I know you've
had Jonathan Haidt on the show talking about teenage mental health problems.
When you look at when self-harm and depression starts ticking up in the graph for the kids,
13 to 17 year olds, there's a subtle point, a specific year period where that ticks up
and you know what happened with that year was it was like 2009, 2011.
What changed in that period?
The iPhone.
The iPhone.
And then social media.
We had social media before that.
Right.
But it changed.
What changed is when it went on mobile.
Right.
Now what changes when it's on mobile?
Because it goes from, what's that?
You have it all the time.
You have it all the time.
What's your new 24-7 metaverse?
I would say that it's the, when you virtualize people's experience so fully and that virtual
world doesn't care about protecting and nurturing the real world.
When you virtualize people's relationships in a way that they don't protect, they don't
care about nurturing your offline relationships when they virtualize your online relationships.
In the same way that, you know, we have a techno sphere that doesn't care about nurturing
the regenerative capacity of the biosphere, we have a virtual reality that's not trying
to protect and nurture the real reality that's underneath that.
And it depends on that real reality.
So if the economy depends on the earth working in a fundamental way, and it's not trying
to protect and make sure those fundamental capacities keep going through deforestation
and so on, that's very similar to a virtual reality that's not protecting the social fabric
that it depends on.
It depends on that thing for it being hired or if you want to say anything to that.
Yeah.
So why did Facebook buy Instagram and buy WhatsApp and the various things they did is
because a monopoly of attention is the play.
And a monopoly of attention is a really big deal to be able to get, but as soon as new
devices come out, you're going to get attention in different ways.
So AR and VR as new platforms, obviously you've got to lead the way in having the monopoly
of attention there and increasingly hypernormal stimuli.
And the cell phone took us up to something like 50% screen time from say 25% screen time
on the laptop.
The AR can take us up to like approaching 100% screen time or, you know, engagement
time and then persistent tracking of reality across all those domains.
So we can see why this is super problematic and pernicious.
That was just speaking to how the metaverse is a natural extension of what they've already
been doing.
Right.
Where's the middle lane?
We've got, you know, we've got the gutters on each side.
What's the middle lane?
There is.
Oh, I remember.
What Tristan was just saying about if the...
Then you'll get on that microphone.
If I have virtual relationships online, but they're actually debasing the integrity of
my in-person relationship.
So when we're talking, we're actually looking at our phones.
We would say from the Center for Humane Technology kind of perspective, what is humane tech?
One of the definitions would have to be, and he was mentioning earlier, that tech plus
democracy makes a better democracy.
Similarly, if you want to think about what does humane tech mean?
Tech plus any of the foundations of what it means to live a meaningful human life and
a sustainable civilization, tech has to make those things better.
So tech plus families has to actually increase the integrity of families, otherwise it's
fundamentally not humane.
It's misaligned with what is foundational to being human.
Tech plus democracy has to make better democracy.
Tech plus individual human mental well-being.
Right.
But it's not, right?
Tech plus democracy is...
Debasing it fundamentally.
Yeah.
But there are ways of actually, first of all, aligning and choosing your business models
to be in alignment with that thing.
So I mean, not to give Apple too much praise, but when it says, hey, we're going to, you
know, if they just added the Johnson & Johnson guide of their board, and they're choosing
to go into health, because they could just say, hey, we're going to build our own, maximize
engagement machine, metaverse thing.
I'm sure they're working on one, but the choosing business models, their business model isn't
maximizing attention.
That's why when you use FaceTime, it doesn't have like, here's comments, here's notifications,
here's the hearts and likes and thumbs up floating across the screen as you're using
FaceTime, because you're the customer, not the product.
Well, Apple's a fantastic example of what is possible when a company does have the most
superior product in the market, right?
Like, it's kind of widely acknowledged that when it comes to the phones, when it comes
to the operating system that exists in the phones, and when it comes to the operating
system that exists on the computers, and then the fact that Apple controls all of the hard
ware.
So, the problem that Windows has is, you got Lenovo and Dell, and there's all these different
companies that are making Razor, they're all making different hardware, and then you have
the operating system that engages with that hardware, but there's all these different
drivers, you've got different video cards, you have different, there's so many different
things that it's very difficult for them to make this one perfect experience, whereas
Apple's like, you know what, what we're going to do is we're going to control all of the
hardware, so they make the best laptop they can possibly make, they make the best phone
they can possibly make, and they've done such a good job with it that they have this massive
loyal fan base, and then through that, they decided, you know what, we're going to give
you the option to not have advertisers track you, and apps track you everywhere, that is
a wonderful solution.
And when Tim Cook announced that, he said, we cannot let a social dilemma become a social
catastrophe.
Going after the social media business model of surveillance advertising, and that's one
of the steps, and that's a good example of it.
Maybe they can do something with the social media, like maybe Apple can use the same idea
that they have, and the same ethics, and create a social media app, and we can all jump on
it, something with no algorithms, something that doesn't accentuate certain likes or
hates.
A stronger mode is if, I mean, they're never going to do this, but imagine that they said,
hey, we now know how to diagnose what the problem is.
It's these sort of engagement-based business models that have infinite virality that treat
us as the product and not the customer, and we know it's toxic for democracy.
We could just take it off the shelf.
We could say those things don't exist in our shelf.
Here's a crazy move for you.
It's a good time to do that now.
They could do that.
Now, here's the thing.
If they did that, people would be cynical.
They would say, wait, hold on, Apple's doing that only so they can basically keep a bigger
monopoly on their app store.
Notice there's this whole lawsuit right now with Epic Games, and Facebook is trying to
dial up that because they don't want Apple to be this big top-down, take control with
their app store.
But these social media apps are free apps.
If they decided to say, listen, we think there's a real problem with these apps, so
we're not going to make them available, they could simply do that.
They could simply do that and say, we're going to have something that's available that we
don't have any kind of control over what your feed is.
We were just talking about this last night.
One of the things we talk about is that there's always a cynical take when someone takes an
action, and there's an optimistic good faith take.
The cynical take on Francis is a whistleblower who's a secret operative.
The cynical take on the government wanting to regulate social media is it's just because
they want to take control, or if the media is ever criticizing social media, it's just
because the media is upset that they don't have a monopoly on truth anymore.
There's a partial truth in each of these things.
If Apple takes a strong move against these social media companies, and the privacy thing
that you just mentioned, they're now protecting people's privacy, they prevent cross-app tracking,
there's an article that they make an extra billion per year out of that change.
They make a billion per year.
The cynical person says, oh, they're just doing that so they can get more money for
them.
How do they make an extra billion per year off of that?
Because somehow the extra advertising goes through their network or something like that
because you're not using cross-app tracking through the other companies.
Somehow people start spending more money on their system.
There's a cynical take there, but here's the move.
If they wanted to prove that they're actually a good faith actor, this was your idea last
night.
They could take the billion dollars or even just a large chunk of it that's not legal
fees and say, we're going to spend that billion dollars on solving the rest of the social
dilemma.
We're going to fund nonprofits that are doing digital literacy education.
We're going to put 500 million dollars into nonprofits that are doing digital literacy
education and other sort of humane tech.
We're also going to put another 500 million dollars into R&D to do more features that
help address the social dilemma and actually move our whole product ecosystem further in
the direction of protecting society and not manipulating society.
That might be the only solution.
If a company that's as massive as Apple that has so much capital, they are literally one
of the most wealthy corporations that's ever existed.
We would need a mass.
If not the, right?
Yeah.
I think they're up there with Saudi Aramca.
They may be the most now.
They keep going up and down, but they would need a public will and support base of people.
That's why your audience is really interesting also because as Daniel said, this is a we
the people type moment.
We have to actually ask what is the best way out of this thing?
There isn't an easy answer.
It's not like, hey, we're going to just tell you, let's just do X and it's just all over.
We fix it all.
We have to navigate through this thing.
We have to find levers that are at least a little bit more attractive than other levers.
This is one of them.
Taiwan is another one.
It's an example that works.
Biden could invite Audrey Tang to come to the United States and actually say, we're going
to build a civic tech ecosystem.
The decentralized web community that's building these Ethereum based like new web three things
could actually say, we're going to take the central design imperative.
We're going to do digital democracy that helps us do the bowling alley and get that thin
tightrope that we've got to walk.
These are the kinds of things that could happen, but we would need there to be a public zeitgeist
that this has to happen.
I know it sounds dystopian if we don't do that.
It's not an easy problem.
It's not an easy problem, but one thing we can show is if people are happier and more
successful if they follow this path than the path of want and destruction because we know
that about alcoholics and gambling addicts.
If you have an uncle that is an alcoholic and you see him, you're like, wow, I don't want
to be like that guy.
You learn.
If you see someone just ruin their life with gambling, you go, wow, that's scary.
I know a lot of people that are ruining their lives with social media.
I know people that it's radically exacerbated their mental health problems.
I personally have had a great increase in my peace of mind by never engaging with people
online.
You told me that.
I don't look at any comments.
I really don't.
It's so much healthier for you.
Oh, my God.
I'm so much happier.
It's incredible.
I've told that to friends and occasionally they dip their toes back in the water and
then they go, fuck, why did I do that?
They'll do an episode or maybe they don't like something that they said and then they
go read and I'm like, my God, man, get out of there.
I don't engage on Twitter.
I don't engage in the comments of Instagram or I don't even look at Facebook.
Because of that, what I take in is my choice.
I look at things that I'm interested in and most of my social media, it's not really social
media consumption, but most of it is YouTube and most of it is educational stuff or complete
distractions.
What was the Thanksgiving study?
I was going to say, I was just thinking the same thing.
There's a Thanksgiving study that after 2016, the more per, they looked at zip codes that
had the most media advertising, political advertising, and the more of that media you
had, the shorter the Thanksgiving dinners you were.
They did this mass study looking at tracking people's locations and how long they were
in their Thanksgiving dinner location and basically the places that were most bombarded
with polarizing media, Thanksgiving dinner was shorter.
Because they argued.
Yeah, and people, I think, stood further apart or something like this.
It actually had the geolocation on their phones too, right?
Yeah.
The people who had right versus left views interacted less at dinner.
Exactly.
It's people with right versus left views interacted less at dinner.
We're about to head into Thanksgiving.
I actually would say that Facebook and Twitter, their business model has been ruining Thanksgiving
dinner because their business model is personalizing confirmation bias for everyone so that when
you show up, in the same way that that's an epitome of the problem, that's your personal
version of the social dilemma, we could also say, what would be the first step for each
person listening to this that we can do during Thanksgiving dinner that's putting our phones
at the door and actually trying to have a conversation about the mind work that's taken
place.
Yeah, it's hard because when people get together and they haven't seen each other for a while,
they want to argue about things that they feel the other person's wrong about.
Because they've got so much of their time invested in these echo chambers.
But you just mentioned something that was so interesting, which was if people started
to understand that the echo chamber was affecting them and affecting the integrity of their family,
so rather than try to save everybody on the other side from Trump or Biden or whatever
it was that they thought, they did this other thing, which is they actually tried to save
people from excessive social media exposure.
I want to save people from excessive exposure to everything that's harmful and damaging,
but it's very difficult.
And I think it's got to be an across-the-board decision that you make.
And it's got to be with your own health, it's got to be with relationships, it's got to
be with honesty, there's got to be a lot of things that you do that you change.
If we can influence people in any way that's positive, it's to understand where the pitfalls
are, where's the traps, there's a lot of them out there.
Now when we think about the social media issue to a degree, we can take the solution that
you propose and just say maybe the individual can just remove themselves from it.
We would argue that this is actually impossible population-wide currently because there are
companies that just can't succeed if they don't mark it on there compared to their
competitors.
I'm not saying remove yourself from it, that's not what I said.
What I said is don't engage in anything personal.
You can read people's thoughts on things.
You can go and watch a YouTube video, you can stare people's butts on Instagram, but
if you get involved in engagement, that's when things get fucked up.
The problem is that is the only formal self-expression that a lot of people have when you deal with
... If you're talking about something that people think is a critical issue, how do you
express yourself?
How do you get your point of view?
If you think your point of view is significant, how do you get it across?
Well, you have to engage.
That's a problem.
One thing I wanted to share, we interviewed Dan Valone from an organization called More
In Common on our podcast, and he does this work on what he calls the perception gap.
What they found in their work is the more time someone spends on social media, the more
likely they are to actually misperceive what the other tribes believe.
First of all, we get hit by a double whammy, because you're talking about participation
on social media, and you could sit there looking at stuff but not participating.
Well, it turns out the people who participate the most, the extreme voices participate more
often than the moderate voices.
That's what they find in their work.
When they participate, they share more extreme views, so their stuff goes more viral.
We're looking at this weird funhouse mirror when we think, oh, we're getting a sample
of what everybody believes.
We're not getting a sample of what everybody believes.
We're getting a sample of what the most extreme people believe.
If you actually ask in their research, how many Democrats believe that ... What would
you ask for Democrats?
What percentage of Republicans believe racism is still a problem in the US?
I think they estimate 40% or something like that, and the answer is closer to 65% or 70%.
We are misperceiving because we're seeing through the stereotypes and the strawmen and
the bad faith examples of everyone.
One of this mind warp is we have to actually, again, understand that we're seeing a very
specific view, and even if very few ... As a result of this podcast, if 50% of people on
Facebook stopped participating per what you just said earlier, the problem is that the
small remaining group, the most extreme voices there, they would be identified by the algorithm
and they would just maximally up-regulate them.
We just have to realize what game we're in, what unfair fight we're in, so that we can
unplug ourselves from the matrix.
You called me Morpheus last time, I think it was here.
There's also a problem with tribal identity, and it's fucking silly that we only have two
groups in this country, and because of the fact that we really have broken it down to
two political groups, we are so polarized.
We don't have this broad spectrum of choices that we can ... Well, I like a little bit
of this, I like a little bit of that, and to be in the center is to be a fanceter and
to inspire the ire of both sides.
But there's many more people who are in the center than we think.
Most people are in the center.
That's why the show works.
Exactly, but most people don't think that, because when they look on social media, they
just see people at the extremes, and they're like, am I going crazy?
Is the world gone crazy?
The answer is, you're mammalian instincts that things are upside down, that's not wrong,
but it's not because of some master global conspiracies, because social media is just
showing us the craziest of the craziest voices on all sides.
I just realized how much you look like Terrence Paterna.
Look at that.
For real.
It's kind of creepy.
We both got the white and the beard.
Right?
You got the glasses?
Yeah.
For real.
It's a real problem.
You like Terrence if he's a little more buff.
Sorry.
Go ahead.
So let's say that we could have a bunch of people get off social media.
Yes.
That's one of the exponential tech risks that we've talked about, but that doesn't actually
do much about the fragility of decentralized drones.
It doesn't do much about the fragility of decentralized cyberweapons.
Right.
Oh, you're a bummer, man.
You've got a little bit of a solution.
Debbie Downer over here.
Well, no, the reason I'm bringing it up is because an individualistic only answer doesn't
work when other individuals and other small groups have the capacity to, the small and
large groups, to affect everything so significantly.
Right, but it does significantly impact the health of the overall population.
If we're more healthy mentally and physically, we can make better choices.
The next step is not just that we make better individual choices, but that those who can
work to make new, better systems.
And so when you think about the founders of this country, they didn't just remove themselves
from believing in whatever the dominant British empire thought at the time was.
They removed themselves from that and then said, we actually need to build a more perfect
union and they invested themselves radically to do so.
And it wasn't a huge percentage of the population, but it was working to build something that
could apply to a much larger percentage of the population.
So we need some sort of a radical solution in terms of the way we interface with each
other, the way we do business, the way we govern, the way we do everything.
Yes.
And so let's say you have people who start pulling themselves off social media and saying,
I actually want to engage with other people where I really seek to understand their ideas.
Before I just jump in criticism, I want to make sure I get their values and what it's
like to be them.
And so they first, they remove themselves from the toxicity.
Second, they work to actually start making sense of the world better and being in better
relationship with each other.
Next they say, I want to make a platform that facilitates this for other people.
And then I want to come on Joe's podcast and talk about the platform and get a lot of people
on there.
So we start to actually get the beginning of a new attractor, a new possibility.
Don't you put that out there.
Don't you do it.
There's a lot of people that think they have the solution.
What this sounds like is kind of a radical reboot of the US, but there's the January
6th version of that, which we don't want.
There's a different version.
What I wanted us to tell you in the Taiwan example, the way that that happened is actually
it was a bunch of activists stormed the parliament, except they didn't try to break the glass
and the windows and break through everything.
They sat outside the parliament.
They created, they brought in all these ethernet cables and they set up a Wi-Fi network and
they had a bunch of hackers build this alternative civic engagement platform where people could
debate ideas right there using technology.
So they did storm the parliament, but they didn't storm it to take it to hurt people.
They did it to create the better form of government.
But to debate ideas where you have things like where unlikely consensus is found, that's
what gets up-regulated.
So they were designing that the better angels of our nature are appealed to rather than
the lower angels of our nature.
And it's possible to do that.
That's a real working example.
I want people to really check that out.
It's a real thing.
We're not just pointing at a random idea.
People do say it's obviously a much smaller country.
It's not as homogenous as people think.
They think Taiwan, they think everyone's the same.
There's 20, I think, indigenous cultures or languages there.
So they actually have quite a lot of plurality.
The democracy has plurality, deliberation, and compromise.
You have to have those three things work.
Are you aware of the agent provocateur aspect of January 6th?
Say more.
I don't exactly know what the reality is.
But what people insinuating is that there was federal agents that were involved in instigating
the violence, instigating the entering into the capital, and that there's this one guy
in specific that they've got him isolated on video.
They've shown him over and over again.
He's faced no legal consequences.
They know this guy's name.
They know exactly who he is.
All these other guys are in jail.
All these other guys who got into the capital, I mean, so many of them are facing these
massive federal charges in four years plus in jail.
This one guy is like, we have to go in there.
We have to take back.
We have to get inside there.
And people start calling him a fed in one of these videos, and I think he takes off
and runs away, but this is what it seems like.
It seems like, and this is something that governments have done forever.
You take a peaceful protest.
What's the best way to break up a peaceful protest?
You bring in agent provocateurs to turn it into a non-peaceful, a violent protest, smash
windows, light things on fire.
You can send in the troops and you can clean up the mess, and then you don't have any protest
anymore.
This was the World Trade Organization in Seattle in 1999 or whatever it was.
That's what they did.
It's been documented that that is what happened.
I mean, like literal government agents went in wearing Antifa outfits and started, this
is pre-Antifa, right?
Smashing windows, lighting things on fire, and they were all eventually released conveniently.
This guy, do you know about this, Jamie?
Do you know?
See if you can find it.
Because it's a curious case of this one particular individual who's yelling in these various
groups that we have to get in there, and he did it pre-January 6th, he did it during
the January 6th thing, and then this guy's faced no legal charges whatsoever.
People are like, well, what the fuck is going on here?
Then you see some kind of organized debacle like that, and then you see people insisting
that we have to take this further, and we have to go inside, and then if you find out
that those people are actually federal agents that are doing that, you're like, well, what
is happening here, and how is that possible, and how is this legal?
That's a problem.
Yeah.
I mean.
I haven't seen this one.
I remember the umbrella man who was breaking windows at the George Floyd riots.
I think they found out that that guy was a cop, and that I think that was like a rogue
human, but I'm not sure if that's true.
So, this is where it's interesting in this case.
I don't know the case at all, but is it that somebody in government actually initiated
him doing it as an agent provocateur to shut down the protest, or was he someone who happened
to be in government who was himself radicalized, who acting on his own because of radicalization
did the thing?
Or is he an agent provocateur, but he's doing so independently just because he's a fucking
psycho?
You know, some firemen start fires.
Right.
But notice that whichever view you have, you probably had a motivated interest to see
it that way.
Yeah.
I didn't have any view on it.
Right.
That's the thing.
I'm looking at it like this.
Like, what is this video?
Yeah.
I'm watching this guy, this one big, beefy-looking federal agent guy telling them they got to
go inside, and I think he was wearing a MAGA hat, and you know, he's like a guy in his
50s, and he's like, I'll tell you what we got to do.
We got to get inside there.
We got to go inside the Capitol.
And these people are like, inside?
Like, isn't that illegal?
Like, what the fuck?
This guy's taking it to the next level.
But he's doing it like multiple times.
That's, there is a real problem with intelligence agencies doing that kind of shit.
Totally.
Because they do do it.
And I think they do it thinking that this is like, these group of fucking psychos, like,
we got to stop this from escalating, so here's the way.
We get them to do something really stupid, then we can put fences up and create a green
zone, and then we lock this down.
Meet Ray Epps.
Yep.
Fucking, if you had a place.
Meet Ray Epps, the Fed-protected provocateur who appears to have led the very first January
6th attack on the U.S. Capitol.
So let's watch some of this, because it's fucking crazy.
It's really weird.
This guy is doing this like over and over and over again.
There's a video of it, but this is an article about probably wasn't a video.
Oh, so this is an article that's in Revolver.
Hold on, I'll get the video.
We'll find the video, because the video is fucking strange.
Ray Epps video.
Here it is.
Like this?
Well, that's 20 minutes long.
Well, just watch.
We'll see some of it.
Oh, these are guys that are watching it.
What about that one?
It goes to a website.
These are on Twitter.
Arrest Ray Epps says, so some people are hip to it, but most people, like including you
guys, have no idea that this is a person, right?
You never heard of this before.
I don't know why it's not playing a video.
Oh, these fucks with their clicks.
Oh, my God.
Please log in.
Log in.
I want you to log in.
Thank you.
God.
One of the things that was so cool about C-SPAN was the idea of being able to actually see
what was happening inside of proceedings.
And we know that the idea of a modern liberal democracy is that we want to leave markets
to do most of the innovation and provisioning of resources because they do a good job, but
we still want rule of law, because there are places where markets will have a financial
incentive for things that really harm everybody, like complete destruction of environments
or organ trades or whatever it is.
And so rule of law is intended to be a way that if you have a government that is up for
and by the people, and it's given a monopoly of violence, that it can check the predatory
aspects of markets where the basis of the law, because of voting, is the collective
values of the people.
But the state only has integrity and can check the markets if the people check the state.
And this was where, again, at a much smaller scale, it was easier to have transparency
and being able to see what was happening.
The larger scale messed that up, and also having so many things that were issues of
national security where it just can't be talked about, then it becomes very hard to
say, well, how do we have enough transparency that the people, even if they wanted to, could
engage in being able to see what was going on so that we could have trustworthy institutions?
What terrifies me is the solution of this is an autocratic government that controls
all aspects of society, so none of this ever happens.
That scares the shit out of me, because that seems to be where, there's that fuck.
Let's play this.
The Capitol.
Tomorrow.
Do it from the beginning.
I don't even like to say it.
Tomorrow.
We need to go into the Capitol.
Into the Capitol.
Tomorrow.
What?
I don't even like to say it, because I'll be arrested.
Well, let's not say it.
We need, we need to go, I'll say it.
All right.
We need to go in.
Shut the fuck up, Boomer.
To the Capitol.
We are going to the Capitol where our problems are.
It's that direction.
We spread the word.
All right.
No, David.
One more thing.
Yes, sir.
Can we go up there?
Okay, I think we've seen that there's a lot of instances it goes on for quite a while
there's a lot of videos of this guy which is really fascinating because I think these
methods that they've used forever are kind of subverted by social media because you have
a hundred thousand different cameras pointed at this guy from all these and when someone
starts screaming loudly people start filming it and then you get a conglomeration the collection
of these rather and you can go what is happening here like like I don't think they've realized
that people would be so cynical that they would go over all these various videos and
find this one guy is not being prosecuted or arrested he's not being prosecuted or
arrested congratulations no he's not look at that guy yeah I mean if you had a guess if
you had like 50 bucks what are you gonna put your chips on red or black I might put my chips
on the result of stochastic terrorism like if I was China I would have wanted to infiltrate the
Facebook group that guys like him were in and just feel and just radicalize as much as possible
so that some of them were motivated to do it earnestly all right it was like some patsy but I
don't even know who it is for sure there's some of that going on there right there's a lot of
stuff going on with January 6th right and it's a lot of sad humans who don't have a lot of going
a lot going on in their life did you see the what is it the into the storm that what it was the
HBO documentary on QAnon did you see it no fascinating it's really good and it's a multi-part
documentary series about QAnon and the people that are involved and one thing you get out of it is
these people found meaning in this nonsense they found meaning and they really thought they were
part of something bigger than them and it gave them hope and happiness and what I got out of that
is well these are this is exactly what we're talking about earlier the people that are getting
sucked into this totally distraction life is that most people don't feel like they live a
meaningful existence so when something like this comes up and you get radicalized whether it's by
China or Russia or that guy and he's saying you know that guy's just basically in cindia right he's
just throwing gasoline on the fire but you're saying is is there something out there that you
can connect to that's bigger than you and they're saying yes there is you can be a part of this group
you can be a patriot are you a patriot do you want to storm the capital and then you got the
fucking president who's saying you know we have to make a big movement we ought to do a big thing
they stole this election like holy shit you know we have to go there and it's a show of force and
then they pull them off a twitter and like oh my god it's a the conspiracy is even bigger than I
thought twitter's involved and it becomes something that is all encompassing it involves every aspect
of their life they wake up in the middle of the night to check twitter they take a leak and they
check it and make sure that you know we move it in the right have has q released a new drop and
these fucking people get completely locked into it yeah and at the end of this this documentary
on h-rail which is really excellent I can't recommend it enough you see a lot of them are like
realizing like this is all bullshit and they're like what have I done with my life there's a reddit
channel called QAnon casualties which is like people especially who struggle with family members
who've fallen down different rabbit holes and I guess that's that's one of them and as people
come out of it just what happens I have a friend who just reached out about that is about his own
wife he asked me like what can he do yeah well I mean I think what you're pointing to our friend
Jamie wheel who's here in Austin we had him on our podcast to talk about this when we think about
social media a lot of times people think about it as a as an information problem misinformation
disinformation it's actually about meaning and identity which is what you're pointing to people
are getting meaning and purpose from a thing and it's therefore it's not a matter of like well let's
just like tell people the true thing or the fact check thing there's a sense of meaning purpose
narrative what I'm participating in that's that's bigger than myself that people are seeking and
part of that which is exacerbated by social media because it's mass alienation and loneliness
and those are exactly the kinds of people that can be you know pulled in various directions which
includes also some of the decentralized ways that they can they can use those tools to cause
havoc something I was thinking is in the founding of this country it was understood that both high
quality education and a fourth estate right of kind of free and open press were considered
prerequisite institutions for democracy to work you had that's what a fourth estate is
journalism right some kind of and but at that time so both both education and newspaper were the
result of a printing press where you didn't just have a nobility class who had access to books
when books were really hard to get but we could print a newspaper so everybody could know what
was going on we could print textbooks so everyone could get educated if you could have a at least
that was the idea right if we have a population where everyone can make sense of the world like
they've they've learned how to make sense of the world they've got history and civics and science
and like that and they know what's going on currently then they can all go to the town hall
and participate in government so it was acknowledged that without something like a fourth estate a
shared way to make sense of the world together democracy doesn't work facebook in particular
is not just a destruction of the fourth estate it's like an anti fourth estate rather than share
something where everybody gets the same information to then be able to go debate right now two different
people will have facebook feeds that have almost nothing in common and polarized right and are
identifying your fellow countrymen as your most significant enemy and that everything they think
is wrong and a conspiracy and lie or something like that right but how do you how do you rectify
that and still have independent media right so one of the things I didn't say that's interesting is
as we started to scale more one of the things at newspaper and then with tv and broadcast became
able to do was scaled propaganda give the same message to everybody and there was this whole
big debate in world war one and then going into world war two that democracy requires propaganda
because people are too dumb to make sense of the world adequately so we have to propagandize them so
they aren't fighting the war effort while we're in war and one of the things that is interesting
and just from a potential and you'll say yeah but how do we get there because how do you incentivize
the zuckerbergs or whatever and that's the the enactment is a real tricky thing but
you could use the tools of social media which is the ability to personalize a huge amount of
content to the individual to actually not to make real democracy possible where you don't need to
give everyone propaganda because they're dumb you can actually help people understand the issue
progressively better in a personalized way how are they already leaning expose them to the other
ideas see that they're understanding it and you can imagine that like real democracy could actually
be possible at scale if you could personalize the kinds of education and civic virtue that
would be necessary for people to engage in a democracy let me add on to that because this
example you just showed me right with this this guy I had never seen that video imagine a Thanksgiving
dinner happening a few weeks from now where one set of people have been all exposed to this guy
and this is like the central way that they see January 6th is through the lens of that guy
if you're in one of the other filter bubbles all you see is just the violent crazy whatever the
you you are not even operating on a shared reality so when you talk about January 6th
normally if we have a shared printing press or we have a shared fourth estate we've at least
been exposed to some of the same things yeah but when you show up at that Thanksgiving dinner table
when we argue about January 6th and you haven't seen something you haven't seen but you you assume
our brains are not built our part of our payload of the commotions is that we were built to assume
with my my brain constructs reality from my eyeballs so like I have to assume I was built
evolutionarily to assume that your brain is constructing reality from some of the shared
stuff that I'm seeing with my eyeballs so all my biases are to assume other people are talking
about the same reality and there's a little bit of a magic trick optical illusion because we both
saw quote-unquote January 6th but we were exposed to completely different media sets so now when
we get in a conversation it completely breaks down not because we're actually even talking about
the same thing but because we don't even get to that lever layer of detail and one of the things
in a humane technology world the current I think I mentioned to you in the more in common research
they found that the more you use social media the more likely it is that you that you are not able
to predict what someone else's views are in its topic you think all republicans are racist or
something like that if you're on the democrat side or if you're on the republican side you believe
that all democrats are LGBTQ and only six percent of democrats are LGBTQ so we are far off in terms
of our estimations of other people's beliefs and in the current world the more you social media the
worse your estimations are in a humane future the more you social media the better our shared
understanding and my understanding of your understanding would be and so you can imagine
there's some sense maker out there who's showing both sides of these different filter bubbles and
helping us bridge build so we're actually even able to have a shared conversation those are the
kinds of people that Daniel was just talking about would get kind of up-regulated to be at the
center of our shared undivided attention let's say I wanted to say how do I increase trust in
our institutions that are processing things too complex for an individual to figure out on their
own like the reality of climate change or covid well let's say that c-span like I had debates
happen inside those institutions where people who had real expertise but had conflicting views
had a long-form facilitated debate but not the type of debate that is just
oriented towards rhetoric and gotchas to try to win but that is earnestly trying to
seek better understanding and there's a facilitated process and the people agree to it
one of the things they agree to is what would I need to change my mind about this if the answer
is nothing then you don't even engage in the debate if we can't even say what would change
our mind we're not really responsible participants of a democracy and we're not really open to and
each of the debaters has to read each other's content first and agree to a facilitation process
that's long form and we start with what do we all agree on say we're looking at climate change what
do we all agree on that means now both around the values that are relevant and the facts of the
matter that where we go to what we disagree on we know what our shared basis to derive a solution
looks like then we try to formalize our disagreement I believe x I believe not x and we say what would
it take to solve this do we need to do a new piece of science do we disagree because of an
intuitive hunch or a different value we could do a much finds a private plane or you know that
there's these common cynical narratives also that get in the way right because we're all just like oh
well it's just this one thing or you know pensioners oh the media doesn't like social media because
it's losing its monopoly on truth partial truth but not complete but we could have people who had
different views but were earnest and wanted to know what was true more than hold their own view
be able to engage in a process that could bring us to what is shared knowledge where are their
disagreements what is the basis of the disagreement what would it take to solve that and actually
have that be what is informing the institutions and all of that be transparently oversighted
that would be a huge step in the right direction there are groups like braver angels search for
common ground in fact so my organization we actually are standing up this thing called the
social cohesion and technology council I think I got the name right taking these groups like brave
angels search for common ground that this is what they do they actually run these civic processes
with people who come from very different perspectives and it takes like multiple hours they bring
them together for facilitated conversations but what we're doing with this council we're putting
together is actually matching them with technology designers so they can actually take the lessons
of like how do you do conflict mediation how do you get shared reality from like very different
identity held different realities and then also apply that to how you design technology because
you can imagine a world where facebook's like oh do you want to see more bridge building between
January 6th do you want to see more bridge building stuff on climate change and you could
imagine sorting for that thing right they could design it very differently right but you would
have to change people's intuitions and change human nature because human nature is a conflict
there's most people seek conflict this is a fundamental question about how we view human
nature it is true that the worser vices and worser devils or whatever you what do you call them
worser angels of human nature are are there within us right but if that's what we assume
is true that that is the full story of who we are when we look in the mirror then this story is over
and we should just go do something no no drink margaritas no no no i just think for most people
live these sort of unrealized lives it's a you have a giant percentage of the population that is
disenfranchised and totally they're angry yeah and they look for things that make them angry yes
so well i think we have to address it at the root level before we address it even at a social
media level that's why you had johann harion saying the opposite of addiction is not sobriety it's
connection yes people need meaning purpose connection and you'd imagine a world where social
media is like hey here's some drum circles or dance events or obviously post-covid or whatever but just
social media could be steering us we're making life choices every day right now when you look at a
screen it's just like it's basically allocating decisions of where time blocks are going to
land in your calendar right most of those time blocks are like spend another five seconds doing
this with your phone right but imagine social media becomes a gps router for life choices where
it's actually directing you to the kinds of things that create more meaning now of course the the
deeper thing is work inequality meaning not existing and a lot of the work that people do
agreed but like relationships yeah absolutely right i mean who's the angriest people in cells
right when people get really angry use accuse them of being in cells but we can imagine a world
that facilitates ways for people to you know go to dance events together where they meet other
people in a more like facilitated environment as opposed to you're going to sit there at home and
like let's just get you swiping and tinder's profiting from the attention casino so you
match and then you never message for someone right like they profit from just like that machine
working that way right and then we also have the emergence of the metaverse where people are just
going to be more incentivized going to that because it's going to be very exciting which is why a
humane future is the online world has to care about actually like regenerating the connective
tissues of the offline world if it doesn't do that it's not going to work apple could be in a
position to do that you take it back to similar to people exercising and not eating too much sugar
because those are the too much sugar is a hypernormal stimuli right remove the sugar fat and
salt from evolutionary food which are the parts that create the dopamine hit and just make fast
food out of it and in the same way of like what is fast food to real food is just the
hypernormal stimuli that's what porn is to real intimacy that's what dating apps are to actually
meeting people it's what social media is to real human relationships is kind of just the
hypernormal stimuli right we know that gdp is not a good metric of the health of a society
because gdp goes up when war goes up it goes up when addiction goes up the question of what is a
good measure of the health of a society one metric that i like no one's applying the metric just as a
thought experiment is the inverse of the addiction in the society as a whole is a good measure of
the health a healthy society produces less addiction meaning more sovereign individuals
because addiction creates a spike in pleasure and then an erosion of their baseline of pleasure
and baseline of health fulfillment in general one of the reasons we're so susceptible to
hypernormal stimuli is what you're saying is because we live in environments that are hyponormal
like not enough of the type of stimuli that we really need which is mostly human connection
creativity and meaning right and so at the basis of it is like how do we actually increase those
is the only way that we become unsusceptible to the supply side marketing that appeals to yes
and it's interesting to think about if apple were to take the you know the small percentage of
people who opt into tracking their usage statistics and they could actually measure for a given country
hey this is the percentage of people that are addicted based on usage patterns again it's privacy
respecting and everything and reporting that back to society so there's a better feedback loop between
how healthy the society was and its use of technology and then actually have ways of saying
how do we make i mean again apples in this really unique position where their business model is not
addicting people polarizing people you know they could actually make their their whole system about
how do we have deeper choices in the real world well there is a movement in society currently
to try to get people to recognize through uh radically induced introspective thought brought
on by psychedelics what the problems of our society and not necessarily the problems of
these choices but the problems in you're talking about like indulging primarily in these choices
whether it's porn or fast food or gambling or alcohol or whatever whatever these problems are
that people have is that there are certain psychedelic compounds that allow you to see
yourself in an incredibly ruthlessly introspective way that'll allow you to make radical changes
and those are all illegal right now and there's a lot of great work being done right now with maps
where Rick Doblin's organization has worked to try to introduce these compounds to help specifically
help soldiers deal with PTSD it's a big one and i think through that and through their advocacy
and the understanding that this stuff is very effective whether it's through MDMA or whether
it's through psilocybin through some of the research they're doing with that that there's
a way to get a view outside of the pattern this this like deeply cut groove that you're stuck in
the default mode yes and i think if we're dealing with anything that is a possible potential real
solution for radically re-engaging thought for changing the way we interface with each other
and with with society in general i think that's it and i think the the fact that that is illegal
currently is one of the big it's one of the big problems one of the big barriers between us changing
the way uh our our culture operates and what we find to be important yeah i mean you remember
so many of the like founding writings of the country said we need freedom of religion but
we actually need a religious people and what they were saying is like we don't care if it's
Confucianism or whatever but you need a people that have some transcendent values and morals that
bind them to more than just their own self-interest yes and that give them something like love thy
neighbor and give the benefit of the doubt and things like that so it was acknowledged that
this democracy only worked with a comprehensively educated people where they've meant both a kind
of moral education and development of people as well as being able to understand the issues right
both they need to understand science and economics and like that they also need to understand the
importance of compromise over culture wars of seeking to understand each other's perspectives
so the psychedelic renaissance kind of religion has has decreased in its overall influence on
society a lot and the psychedelic renaissance is the beginning of like a new way that people are
starting to access transcendent experiences and then reflection i would say that by itself
i have seen narcissists and sociopaths get more severely that way using psychedelics because
it just creates reinforcement yeah and gurus so it has to be like psychedelics in a community of
practice where there is uh checks and balances on each other and ethics yeah and i i think also it
can move us away from this concept to use uh terrence mackenna's words a dominator culture
you know and that you can have advancement without having a dominator culture and you
can have advancement where you seek to engage in the greater good of the whole and you know and
the choices can be made that way and i think in many ways it's one of the things that apple does
when when apple is talking about this this world where they're creating less impact of
advertisement by not having you track amongst all apps and and allowing you to choose whether
or not apps track you that's a bold move in this world where everybody is trying to accentuate the
influence that apps have and the the amount of engagement they have and that these uh to be
able to use advertiser money and to to be able to generate more of it through them is so attractive
to people i mean that's what look android is just a big data scooping machine right i mean they're
tracking everything in anything and it's one of the things they said about tiktok
when the first uh when software engineers first looked at it they're like jesus christ this is
like tracking everything and it's you know one of the most invasive of the applications
why tiktok is not considered a major immediate national security threat i still don't understand
i mean if if russia and the night in the cold war was running the media programming for the united
states for all of its youth like that's insane there's actually a specific strategy china uses
called the ccp uses called the borrowing mouths to speak so you can imagine when anyone says
at any western voice in the u.s speaks positively of the ccp you just add a little inflation they
just get a little bit more boost than someone because you you're more trusting of someone who's
a western voice than of a you know someone who's from you know ccp or china and so there's that's
one of the invisible ways you can steer a culture but going on back to the apple point we all sound
like we're promoting apple in this blood guess and i just want to say but we're kind of promoting
good faith companies they're moving in the right direction yeah and you had john mackey on whole
foods we went to whole foods last night and talked about how that that's creating an environment for
health and trying to at least couple better yeah it's not perfect just coupling better towards
we can make money by helping things be healthier right apple could say we're going to couple our
business model put on the johnson and johnson put everything at johnson and johnson but you can
say we're going to orient our business towards long-term health of people we're going to do apple
fitness we're going to do things like that we're going to change the app stores to you know
put down in the shelf space all the toxic social media stuff if not take it off completely
and put back on like what are the things that help people connect with each other yeah and connect
with each other in person i mean part of that is it's actually kind of hard to host there's
these certain people in a community who are kind of the event hosters they're the people that bring
people together and right now i mean they're good at it but imagine that was just like a hundred
times easier i'm not trying to sell anything i don't have any product or anything like here
and thinking about this but there are people who who are work on how do we make it easier to bring
people together in the physical world and if we made that a lot easier than it is today so that
was happening more often so that when you thought about what you wanted to do instead of i could
open up this app or that app i i felt in my own community in my physical community more opportunities
a more populated menu of life choices where i can you know do dancing connect with people drums
or whatever the things sewing clubs book clubs just the things that bring people together um and you
can even have you know all the public spaces libraries and town halls and squares and things
like that have better instrumentation so that that was easier to book for communities right
again this is part of a a longer term trend and transition of how you get out of this but i do
think that we have to make the choices that are fulfilling as as easy to make as the choices that
are not fulfilling but have the hypernormal stimuli instant hit i was thinking about something joe
and you're asking like what are the solutions and jumping quickly two-way uh some proposed
solutions don't work which is true it's like you think about what are the nutrients the body needs
you can die just from a vitamin c deficiency even if you have all the b vitamins vitamin d etc
and so it's like the body doesn't need a nutrient it needs at minimum levels of lots of nutrients
the same as like how do you get buff which muscle do you work well that's you have to work all the
muscles and you have to work them in lots of different ways how do you make a functional
civilization do you do that through culture do you do it through kind of collective efforts or
individual efforts do you do it through technology do you do it through changing markets or states
we'd propose that there's some stuff in all those areas that has to happen simultaneously
that drives virtuous cycles and otherwise it's kind of like answering the question of like
which nutrient do you need or which muscle do you need to work out like the problems are complex
they have many different causes and all of the kind of single solutions might do something but end
up failing and so we have to also and this is again something that's very hard to do when attention
spans are getting shorter and shorter is how do we actually look at a whole ecosystem of solutions
that collectively can start to address it even though any of them individually can't
yeah so we're gonna hit the brakes and go backwards or go in a completely different
direction than the culture seems to be going in so we you know what i mean we we have to not just
stop our forward or not it's not even forward momentum the general direction that we're going in
well i think with things like the social dilemma which was seen by a hundred and fifty million
helps a lot help and and Francis is stuff coming out and people having a negative reaction to the
metaverse i don't know that many people who saw him was like yeah that's totally do that obviously
there they have asymmetric marketing power they're going to put billions of dollars into funding
this thing they're hiring ten thousand let's talk about that what are they doing because
that commercial where the little the tiger's talking to the buffalo and then all the kids
are dancing i don't know what the fuck's happening i mean i don't know what's happening in that example
but the it's it's a race to control the whole experience i mean the reason that facebook is
doing the metaverse Zuckerberg doesn't like the fact that apple has controlled his destiny by
controlling the operating system inside of which facebook has to sit and then all the various ways
that whether they make advertising like they did recently the privacy tracking stuff it makes him
not have control over his destiny and so if you own the whole platform bottom to top it's a classic
vertical and integration if i own the entire stack i can control the entire thing and then i
own my own destiny that's what this is really about and it's going to become a land grab between
these companies for who can sort of own the next metaverse platform it's a fascinating
sorry to interrupt but it's a fascinating observation to a fascinating thing to observe
when you're watching someone who has ungodly amounts of wealth clearly ambitiously pursuing more
in a very transparent way what's interesting to psychoanalyze him a bit is that he has 55% of
the ownership and voting structure shares of facebook he's a very unique position there's
never been i don't think a company as massively powerful as his and the sort of close to a trillion
dollar market cap range where it's all basically controlled by his psychology i mean i talk to
facebook insiders you know occasionally and they'll tell me that at the end of the day
with a lot of these decisions it really does come down to mark in a way young guy yeah how old is
he he is even actually the same age uh so he's must be 37 so he and then i think what he cares the
most about is being seen as an innovator like if i had to name it's not like you said it's not the
money i think people will always say oh it's just he's greedy he just wants the money it's no i think
it's he wants to be seen as an innovator and if the world said the way you can be an innovator
is not by uh building more stuff that that basically hollows out the physical world so
we can make this unsustainable virtual world that collapses society you can be an innovator
by actually fixing and helping to support the planet that we're on the actual world that we're
living in the social fabric that needs to be strengthened but obviously he's been trapped
by a set of incentives i mean one of the most interesting things is if he came out and said
post all these facebook files said like i'm actually trapped by the shareholder model
and of the corporate form like i i am trapped by the fact that i have a fiduciary obligation to
shareholders but he doesn't say that so in a way he has a fiduciary duty to lie to himself about
that the gap between what his incentives are and what the world needs for basically sustaining
also imagine if you've created something that says whether or not he created is a different debate
but you're the controller of something that's so massively influential on a global scale
and maybe he thinks that at least he's not evil like he may be trying to make money and he may
may be trying to come off as an innovator but it's not an evil person okay i don't get an evil sense
off of mark zuckerberg i get a kind of robotic he's a lot he's odd he's odd in the way he communicates
but maybe that's like a social awkwardness in dealing with his own public image being broadcast
to the world and comes off clunky you know people come off clunky when they're concerned with how
people view them right maybe that's it but imagine just giving that up i'm gonna back out now like
you know jeff bezos is leaving amazon and he's gonna like hand it over to another ceo what imagine
him handing over facebook to some other person and watching them fuck it up or watching them
take this insanely powerful thing and actually make it more evil or make it more destructive but
more profitable that's that's a total possibility right i mean if they just went full capitalist
and some really ruthless ceo got a hold of facebook and they said listen our bottom line is like
we're trying to increase the amount of money that our shareholders get off of this and what we're
going to do is we're going to make these choices and these choices might not be that popular with
analysts and with people that are you know sort of trying to uh examine culture and the impact
that social media has on it but for us it's going to be a windfall we were speaking with a friend
who is in a senior position at google working on ai and has come to the conclusion that a lot of
people in senior positions in ai have come to that something like artificial general intelligence
is inevitable and inevitable near term and near term like how many years depends upon who you're
talking to but this was forms that are inevitable in the like five-year time period jesus well how
come that's debatable because some really intelligent people think it's off by like 50 years partly it
has to do with how you define artificial general intelligence are you defining it as something
that is truly sentient and self-aware or simply that can beat us at all games okay and this at all
games is already here isn't it well pretty much and so then let's say you start applying that to
beating us at the games of how to remove how to concentrate all the capital right because ultimately
market is a game and most of the market is high frequency trading run by ai now already right
do the super one then you concentrate all capital into one thing yeah it's actually worth noting
it's a chess game and you could you can outcompete if you can see more moves ahead in the chess
board against the other ai as you win the other ai's and then you just move faster i know but
i mean that that's what's terrifying is that it moves completely into the realm of ai and it's
outside of human comprehension it's not weak we're not even in the game anymore so specifically his
thinking was it's inevitable that that will happen it will be dystopic there's no way for it to not
be dystopic we at least think the google dystopia is less bad than the china dystopia oh my god so
we're in a full-blown race right to get there and there are many people actually who understand and
other people like well actually the only answer is to jack jack our brains in so that the uh
meat suit is somewhat useful to the agi so now we're in a race to do that when people understand
the catastrophic risks and they don't see any good possibility out then oftentimes they will actually
accelerate some version of a catastrophe as the only reasonable solution and this is why
it's so important to actually define the design criteria right and have people
committed to find solutions even though they're really hard and it's why i think something like
this is interesting is truly a belief that a lot more people focused on what we need to be trying
to solve is actually useful we think there's a lot of super smart people at a lot of universities
and in institutions and in their garage who care care about these things who could be working on
solutions more with the entire blockchain ethereum community of these are some very smart people
but they're very very smart not necessarily working so let's start with the right design criteria
right the design criteria of if you're adding tech that affects society it has to actually be
increasing the quality of democracy it has to be increasing the integrity of markets has to be
increasing the quality of families and mental health you look at what are the foundational
things if it's not doing that it filled the design criteria similarly the idea that we have these
dystopias and these catastrophes we need and the dystopia the catastrophes come from not being able
to create order in the presence of the success of tech the dystopias come from top-down order
that so what that means is rather than have imposed order or no order we need emergent order
which is what democracies and markets are supposed to do but they haven't what we want they have to
be upregulated a new more perfect union that's upregulated to the level of tech we have because
the tech is advanced so far we need new versions of it so how do we bring about emergent order
of four by the people that can direct the tech to not be catastrophic but it isn't dystopic
i just want a lot more people thinking about that i want a lot more smart people at mit and
stanford and the state department and wherever and in ethereum working on those issues proposing
things finding out what's wrong with them so that the collective intelligence of the world is
centrally focused on how do we make it through the metacrisis how do we how do we make it through
the fact that we are emerging into the power of gods without the ability to steward that well
what would it take to steward it well what will it take well a lot of people working on what it
will take and coming up with partial answers is part of the answer right that's what we're kind
of started the Manhattan project we didn't know all the ways that it was going to come together
right so there there is a leap of faith we have to be comfortable with the uncertainty it's one of
the developmental qualities that's needed it's like we don't know how to make it through this
like got it step into that reality take a breath into that yeah and we have to figure out how we're
going to do this we have to refresh um the way people felt after they saw the social dilemma
yeah because the problem is they waited about two weeks and then they got right back to their
normal consumption maybe not even two weeks one hundred percent and i think that we have a very
short memory when it comes to things that are impactful and really sort of jog your view of
reality you know it's so easy to slide right back into it and i think there has to be an effort
where we remind people we remind each other we remind ourselves whether it's a hashtag
whether it's a some sort of an ethic a movement an understanding like we're moving in the wrong
direction and we need to like establish that as as a a real clear parameter like we've got a problem
here yeah and i think people do get that a lot of they do the social element people got it a lot of
friends at the facebook file stuff people's negative reaction to the metaverse yes you know
yes there's a lot of power on the other side of the table right we've got trillions of dollars of
market power the question is is are we the people the culture going to be able to identify what we
don't want and then steer ourselves in the direction of what we do but are we operating in an echo
chamber where we're talking to a lot of people that are aware of it so when you say people are
aware of it like what percentage are we talking about is it even 20 most people who watch the
social dilemma walked away with something like tech is a problem it's kind of generally scary it then
seems to be bad for teenagers and i use my phone too much yeah they didn't get is fundamentally
incompatible with democracy because it polarizes the population polarizes the representative
class creates gridlock and makes it less effective relative to other forms of government this is
also like here we are we're at the like the three hour mark here so we've been having this conversation
and even though we're doing our best to try to pin down solutions and it's like this is a very
ethereal thing it's a very uh it's just like it almost seems uh
ungraspable you know it just seems like you you can nail down all these problem issues but then
when it comes to real world application like what the fuck do you do that well this show
is going to air by bouncing off of satellites that are in outer space to be able to go to
people's phones and computers using the most unbelievably like advanced technology like
that's pretty ethereal it's actually very hard for people to grasp the whole scope of the technological
complexity when you have that much technological complexity and that much technological power
we also have to be able to work on complex social systems that can make us able to wield it and we
just haven't had the incentive and motive to do that but hopefully recognizing where it goes if we
don't is incentive for enough people to start working on innovation more but this technology
this fascinating and super complex technology is disconnected from human nature from these thousands
and thousands of years of human reward systems that are baked into our dna that's part of the
problems that all these well only because we have a whole system trillion dollar market cap system
dependent on hacking and mining from those human vulnerabilities because they've already done that
if we subtract that thing and we've instead reflect back in the mirror not the worst angels of our
nature but the better angels of our nature we see examples of people doing the hard thing for the
easy thing we see examples of people hosting events for each other and being better to each
other rather than being nasty to each other we're just not reflecting the right things back in the
mirror we do we do reward when people do those things right occasionally but the social algorithms
don't reward them by and large right they take a couple examples where the positive thing happens
but mostly we see the most engaging outrageous controversial thing and so that we have to reflect
back something else in the mirror i think it's like if you remember the 1984 ad to bring it back to
apple and if you remember the ad for the macintosh the famous thing where there was a woman like
running down the uh the like there's the booming big brother on the screen and the woman's running
down and she takes this hammer and she's wearing a macintosh t-shirt and she takes his hammer and
she throws the hammer at the screen and it blows up and it says on january 24th uh 1984 apple will
introduce macintosh and you will see why 1984 won't be like 1984 was it 1984 that apple came up
with that computer yeah it was actually and the reference was we have to defeat orwell we have to
defeat that fiction that can't come true and we i mean it's a it was specifically against i don't
think i've seen that oh you haven't it's worth seeing for people to check it out this is pre-internet
this is it okay let's see let's watch this is it
we are one
on january 24th apple computer will introduce macintosh and you'll see why 1984 won't be
like 1984 wow it's powerful that is powerful and i you know we ended our last conversation with me
giving you yeah i was i was actually born that year which is crazy that's nuts um and you know
you can imagine that was air during the super bowl by the way so that was seen by like it was
actually the it was rated the most successful television advertisement in tv history wow you
know steve jobs had a direct role in it and um you can imagine like we have to not let the
orwell huxley two gutters thing happen we have to throw a hammer down the middle down the middle
and and create a future where technology is actually humane and cares about protecting
the things that matter to us one thing that gives me hope is that these kind of conversations are
very popular right you know like uh the social dilemma is very popular so we did got like
nine million views yeah this one will probably be similar it's like people are interested in this
conversation because they know it's a real issue at least the kind of people that are
tuned into this podcast yeah and i think it's gonna be like little baby steps into the the
correct direction and you know what i said about psychedelics is it's it's one of those
seemingly frivolous discussions people that don't have any psychedelic experiences they don't
realize the dramatic transformative impact that those things can have on cultures but
we don't have much time no one has much time not a fucking human that's ever lived has a hundred
years ain't shit and in during this time of of this lifespan that we've experienced we've seen
so much change and so much almost unstoppable momentum in the general direction and it doesn't
seem good um but recognizing it discussing it and having documentaries like the social dilemma
having folks like you guys come on and discuss like what is really going on and we didn't even
really get into a lot of the real technological dilemmas that we have you know when we basically
glossed over the idea of drones and the idea of um crisper and many of these other problems that
are just watching that with text to code then going oh my god the barrier of entry has been
eliminated but it's can you type now you know and you can code it's wild but hopefully through
conversations like this and and you putting attention on it i mean you are part of the
sense making world you are helping people make sense of the world and when you put your attention
on it i mean i'm grateful for you creating this opportunity to talk about these things because
you know they're heavy conversations and they're hard to to look at and well and it's it's actually
important that you have these long form podcasts right that are two plus hours as opposed to it
five second clips or tweets is uh when we talk about tech has to enhance the fundamentally
important things so we saw how tech kind of uh specifically social media tech with the
polarization algorithms messed up the fourth estate also messing up education it doesn't
matter what you learn if you can't remember anything and you have no control of your attention
and so one of the things is the tech has to actually be increasing people's attention
right their attention span their control over their own attention and their memory if we were
to be able to measure those things and say let's up regulate that if you want a democracy to work
the tech should up regulate people's perspective seeking how much are they actually seeking other
people's perspective and if i have a short attention span i can't hold multiple perspectives
simultaneously because you just can't fit that in it you just say one cynical perspective and
i'm right and that's the only thing i'm going to think and so imagine that like instead of the
short clickbait thing because otherwise i'll bounce if i actually read the longer thing and if my
post had more nuance that actually got up regulated so it created an incentive to take in other
perspectives to try to parse them and synthesize them that would be really different we've got to
incentivize kindness too yes you know this uh willingness to engage in nonsensical arguments
it's just so common twitter is the best example that it's like it's a mental institution people
just throwing shit at each other yeah it's it's so wild to watch when you you don't see examples
like this in real life it's like accentuating the worst examples of the way people can communicate
but doing so in this weird public square itself is a virtual reality if you think about just what
it does it's it's ranked by what's the most engaging so it's like every dramatic event that
happened with anyone anywhere like little drive-by like oh you just you just you just like cut me
off in the freeway and i'm upset for a second anywhere that happens anywhere it just collects it
all into this one efficient feed and then people are responding as if it's all like happening at
the same time it's already this weird chronologically distorted reality because it's pulling from all
these different moments yes and making it seem as if it's all one moment so already people need to
just see i mean it's just twitter is just bad and it affects people's minds yeah it's horrible
i think that this is the world that they live in yeah where is this concentrated form of it it's
like um you know i have my friend peter atia was on the other day and he was talking about
how bad juice is for you like people think the juice is good for like orange juice he's like
it is such a sugar with your liver that your your liver is like what the fuck is all this
like you're drinking like 11 oranges worth of juice and it's just going straight to your liver
and your liver has a really hard time processing this is almost like that the social media version
of that like your brain gets all these impactful moments without all the like regular life space
in between them if you live a normal existence instead it concentrates it from billions of
people all around the world and shoves it right through your fucking brain and we're not designed
for that i had a period where i intentionally went and curated my facebook algorithm where i
followed all of the groups that look at police violence comp block and those ones and so my
feed just became filled with cops killing black guys and killing uh you know escalating violence
in ways that didn't look useful now of course those videos also didn't show what happened beforehand
to possibly justify it or not so like they were selected for a reason but even where they were
egregiously wrong they might be a very small statistical percentage of all police interactions
but it if even though i knew i was curating my feet for this purpose it emotionally affected me
intensively just watching that many in a row but by the time i've watched 12 it feels like this is
everything that's happening right right that's the whole world and then i i got rid of those and i
curated ones that were like um pro police thin blue line kind of ones and you saw people
aggressing against cops and you saw what they have to deal with and i was like man these guys
are heroes now and again it was only took like 12 videos and even though i was knowingly doing it to
myself it was that emotionally compelling because we are used to evolutionarily seeing a world that
is representative of the world but when there's so much data that point zero one percent of it
is uh more information than i can possibly take in and it can be totally statistically
unrepresentative but it still affects what i feel the world is you can see how earnest people can
get completely polarized that's such a good point and it is earnest people and the fact that you
are consciously curating it and still having this effect on you but you at least can objectively
express it to other people yeah and you know hopefully that gets in to some people's brains
and they they they see how dangerous this stuff is and this is also why these troll farms exist
because they they can really influence the way our culture moves and behaves and the way it
thinks about itself yeah gentlemen thank you very much for being here this was uh terrifying
and uh daunting i mean i feel good but i also don't you know it's hard i get it i i feel like we
should another time come back and talk about more concrete pathways for yeah let's do it let's do it
let's give it a couple of months and hope things don't turn to nuclear war i'll tell you why it
feels inspiring to me and thank you for having us here is there's a lot of people who are focused on
systemic injustice or climate change or economics or ai issues but how do all these issues fit
together and how do we actually deal with the fact that we've created so much technological power
and we've had such a huge impact on our environment through the whole industrial use of technology
that the world's increasingly fragile these aren't just separate issues they are related there is a
kind of global metacrisis and there is a need for real innovative solutions and how we think about it
and i think because of this more people just at least be thinking about that and then be talking
about it and that means more of the collective intelligence of the world hopefully being able
to start to work on solutions and i am hopeful about that i'm hopeful about that too let's end
in a positive no gentlemen thank you very much thank you really appreciate you thank you thank you
bye everybody
