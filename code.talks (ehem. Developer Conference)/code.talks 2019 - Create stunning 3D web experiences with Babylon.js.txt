Hi, everyone! I'm very glad to be here, even though I am fighting against the jet lag.
There is none our difference between here and Seattle, so back with me. I'm gonna try to not
sleep on stage. Yeah, we're gonna, I'm gonna present Babylon.js. It's an engine I created
six years ago, and it's an engine that I am pretty proud of, because now it's very, it's used in a
lot of important places. For instance, that's PowerPoint, but this little guy here is a 3D
object animated by Babylon.js inside PowerPoint. And actually, at Microsoft, every time you're
gonna see 3D, it's probably a 99% sure that it's actually based on Babylon.js. A Babylon.js,
it's something that I'm gonna present right now. It's an open source framework. It's entirely free.
It's based on Apache 2 or do the heck you want with the code. There is no license, no nothing.
It's brand new at Microsoft. We are using our own technology here, but this technology is entirely
free for you to use in any place you want. It's based on any, in a lot of web open standards and
web open frameworks like WebGL 1 and 2, WebGPU. So WebGPU, are you aware of what WebGPU is?
Who knows? Okay, quite a few. It's the evolution of WebGL, actually. It's
metal slash Vulkan slash DirectX 12 for the web. It's a new technology that we are working on with
Apple and Google to support. The interesting point here of using Babylon.js is that if you want to
use 3D today, you do not have to worry about that. We will take care for you of all the
underlying frameworks like WebGL 1, 2 or WebGPU. We also support WebExam. I'm gonna do a quick
demo later. It's a full-fledged game engine and rendering engine. So we support physics,
animation, VR, particle, high-casting. I don't like this image, but that's the best I can have.
It's kind of the unity for the web, if I may. We're gonna provide you tools to create 3D on the
web without the burden of understanding shaders and math and stuff like that. We also support
physically-based rendering. It's an advanced technique created by Disney, starting with,
I don't know, Untangle, the name of the movie. I am not sure it's the right translation anyway.
The lady with the long hairs. They created PBR for this cartoon. And this PBR, and thanks to the
power of our computer now, can be now rendered in real-time on the web. I'm gonna get back to that
later as well. We have principles, and I'm very glad to have my talk after John's one, because
we have exactly the same principle. Like bug first. We create tools before the engine and stuff like
that. And we are also backward compatible. That's something that just pissed me off a lot when I
have to update to a new version of a framework and I have to rewrite everything. That's something
I do not want for Babylon.js. If you're using Babylon.js, you will be able to run it up until
the next version without having to change anything on your code. We do not break backward
compatibility. And we are also supporting GLTF. Who is aware of what GLTF is? Okay. So, GLTF stands
for Graphic Library Transport Format, and that's the JPEG of 3D. You think about JPEG. If I give you
a JPEG image, you will be able to display it on your computer, right? Because everyone's understand
JPEG or PNG. For 3D objects, like the file format itself, it was a mess up until now, because they
were like 10,000 millions different file format, all incompatible, obviously, and all proprietary.
So, we sit down with the Kronos group, the group who is standardizing WebGL, and we define all
together, and by all, I mean Google, Facebook, Microsoft, NVIDIA, et cetera, et cetera, we define
a file format. And this file format is GLTF here. So, if you want to render 3D objects, like the
dinosaur I was rendering before, it's a GLTF file format. And so, by supporting this file format,
we ensure that your object will be displayed and compatible. It's an open source project.
Since the very beginning, it was started as an open source project. It's still an open source project.
We have around like 100,000 posts on the forum. It's a very active forum. Most of the users,
when they come to us, the number one reason they come to use Babylon.js is because of the forum.
We have a very lovely community. It's very helpful. There is no shame. It's definitely
a place where you can ask any question, and you will get a response in a matter of a few days.
We also have a pretty large number of active supporters, like people contributing to the
forum and to the engine itself. So, it's used in a very, it's funny because I started it six
years ago, and I was the only developer, and it was only for me. And now, it's used across the
web. Adobe is using it for their product. Being Microsoft apps, obviously, I mentioned SharePoint,
but it's also used by Dolby, by Minecraft. If you go to classic.minecraft.net,
you're going to play the Minecraft game, and it's using Babylon.js to do the rendering, etc.
We work with a lot of small, high, very large companies, and my favorites are probably the
enthusiasts, like students of people that just do that because they want to learn
how to create a game or to create 3D. And that's why we created the engine. And so, also,
I want to underline and second what John said just before. We created the engine,
but we also created a lot of tools. And I'm going to get back and demonstrate these tools.
Just name-dropping here, I'm going to get back to that later. The goal for me is to mention that
it's not just an engine. It's actually a small portion of it. The tools that let you create
what you want to create in 3D are really the important point here.
Okay. So, I have a quick video because I wanted to capture what the community was creating with
Babylon.js. So, instead of going through a demo manually, I created a quick video for you to see.
So,
right.
It was an example of in real-time, obviously, running on any computer what can be done with the
framework itself. So, instead of spending too much time just talking, I would like to
show you in action what you can do with Babylon.js. I'm going to start with a first presentation of
one of the tools that I have. No, it's not here. The playground. So,
Babylon.js-playground.com is a place where you can go to learn the engine. So, I spend a lot of
time writing documentation and that's a pity because no one's read it, right? You don't read
documentation. No one's read them. So, I decided to take the problem the other way, like,
how do I learn? I learned by trying, right? And so, that's why we created the Babylon playground.
Here, you have on the left a full-fledged editor and on the right, you have the real-time rendering
of what you just typed on the left. The editor comes with IntelliSense. So, if you type here,
you can get help while you type. So, instead of reading documentation, again, you can just
experiment, okay? And I'm going to just show you what can be done in a matter of a few seconds here.
So, here, I have a scene that I created. I create a camera, which is the point of view that I can
manipulate with touch or with my mouse. I set the target of my camera and I attach it to the events
by calling attach control. I attach to the mouse events, the pointer events and stuff like that.
So, I can play with my finger here or just with my mouse if I want to, or the keyboard.
That's all coming from this line. Then, I create a light, okay? Like in real-world, you have a light.
I set the intensity of that light and the sphere. So, if I run that, I just have my sphere in the
center of my screen, okay? As a user, now, what you can do is to experiment. And we use the playground
for experimentation, but also for bug fixing. When a user comes to us and says, hey, I have a bug,
most of the time, we ask them to reproduce the bug here because it's easier to discuss.
So, I'm going to create, actually, a material. The material here will be a PBR, sorry,
Babylon.PBR, metallic roughness material. It's a specific kind of material that simulates metal,
okay? I'm going to give it a name. And as you can see, there is, while I type, help
on the parameters. So, for instance, I want the name here like foo and the scene where I want to
have my material. Then, I set my sphere.material to that material, okay? And I'm going to just
quickly set some values like metallic. It will be fully metallic between zero and one. And
is that a little bit too small, maybe, right? Let me change the font size to something bigger,
okay? Sorry about that. And I want also to set my material to be the roughness of it,
like brushed metal, if you prefer, will be zero dot five, again, between zero and one. If I run it,
you have a sense of something change. Like, it's a bit a metallic, but the power of a metal,
like in your car, is because you see the reflection of the environment, right? A car, by itself,
with no reflection, looks rough. So, what I'm going to do here, I'm going to just ask the scene
to create a default environment for me. And by doing that, now, here, I have a sphere,
which is like brushed metal, okay? So, I can play with the parameters, but I told you,
it's all about tools. So, here, I have the playground, but we also have a second tool that
I would like to show you, which is the inspector. Here, I can invoke the inspector by calling
debuglayer.show. And if I do that, zoop, I'm going to have an additional UI that will be
on top of my scene here, where I can see the tree view. So, I have my glide, my camera,
my sphere, and the background that was generated by the created environment. And I can take my
material here, and I have all the properties of that material. And, for instance, I can play with
the levels here and change the opacity or the roughness. So, fully metallic, fully rough.
Okay. Let me just get closer. So, that's the Chinese theater in Los Angeles. And you can play
with the parameter here. Also, we introduce a lot of options that you can change, like I want to
render in wireframe and stuff like that. You can play with it here, okay? That's the inspector.
The inspector is extremely useful to debug or just develop your scene, so you can,
visually, instead of just typing the code in the playground or in your application,
you can just visually debug the scene itself. Right. Another tool I wanted to show you is the
documentation itself. Yes, I know. People won't go there, but still, I would like to show them
the documentation for one reason. Here, we have a regular documentation with code practice,
example, regular documentation you should be looking for. But we also have the playground here.
And the playground is actually a tool that's going to search through all the examples that were
created in the playground here. Because in the playground, if I hit save, it will generate for
me a unique URL that I can share with my friend with this code running, okay? And that is stored
in our database. And if I want to learn something, I could just search for the documentation or I
could just search for examples showing me how to do something. Like, I want to do shadows.
And I can search for shadows inside our database. And here, you're going to see, like,
just lost my mouse. Okay. Thank you. I can find any example here where people just do
something with shadows. And I can click on the playground button here. It's completely random.
I have no idea what's inside this playground. Hopefully, it's not something stupid. Okay.
There is shadows. Cool. Someone was doing that with shadows. Okay. And so I can lurk the code here
and say, okay, what did you do with this code? And maybe that's going to help me learn or understand
how the shadows work. Right. Among new features that are going to be available soon, there is the
Node Material Editor. I created here a material, but this material is actually me setting some
parameters to an existing material. We have a couple of materials. We have what we call the
standard material, which is the fastest and the simpler one. And we have the pretty advanced
physically-based renderer, which is used here, the PBR. But if you want to do something different,
you have to use what we call the shader material. The shader material is up to you
to code using shader languages, your own material. Okay. That's a friction point. Definitely. A lot
of people say, hey, I would love to create my own material, but I don't want to learn
how to create shaders. So we introduce with the very new version here the Node Material Editor.
The Node Material Editor is a way for you to create your material. So who is aware of what a shader
is? Quite a few. Okay. A shader is made actually of a C-like language that's going to explain to
the GPU how to create your own rendering. Okay, here. Here I have a pretty simple one and I will
just focus on the second part here. A shader is made of a vertex shader and a fragment shader.
The vertex shader explains how the geometry is drawn on the screen and the fragment shader
explains how to compute the color. And here my color is just, I want to set a color to the
output. Okay. This tool will let me actually create my own shader without having to develop them.
For instance, here I'm going to open and look for the light. I want to add lightning support. Here
my object is just flat. It's just gray. Okay. To support lightning, I need to add light support
here. And the light supports here will expect me to provide a few parameters that you can see on
the left here. I'm going to just quickly connect them. So the world position, which is the position
of my mesh in the world, and the world normal, which is a normal, is a perpendicular vector
defining the surface of every object. Okay. If I just click them here and do that,
then boom, I have support for light. A shader was developed for me by the system. I can export the
shader here. So instead of coding the shader, which is quite big, if you look at it,
all of that is required to do a lightning shader. You just have to wire some stuff, right? And that
can go even better than that. Instead of having just plain color, I want to have a texture. So
think about your game, your character, and you want to have lightning, okay, done. And I want
also to have a texture, okay? So let me just load the texture here. The texture will require me to
give it a texture, perfect, like a crate. And what I want to do is actually take the light color,
the texture color, merge them, and to merge them, I will remove this link here. Just multiply them.
Boom. Taking the light output, multiply it by the texture output, plug that into, oops,
the output here. And boom, I have a crate with light. Isn't that cool?
Again, you can save your wonderful shader, and it will generate for you a unique URL here. And
let me just fast forward to a complicated shader that I created for you. This one is pretty advanced.
It's not that good-looking, but it's just me as a developer trying to play the designer.
So I have a shader, and you can see here, there is what we call bump or normal. You feel like
there is not a smooth surface. We feel like there is something defining a bump here, and actually
just coming from a texture. And also at some places here, there are reflections. So it's a
complex shader because the reflection is defined by a second texture here. We are using reflection
texture to do the reflection here. We have a perturbed normal object that will change the
normal. And by the way, Doom 3, created by John Carmich, by the way, introduced this
notion of bump. Bump is using a texture to simulate the volume. Anyway, we don't care.
Here, it's just that I want to use that code. So the shader here will generate for me code,
like literal code that I can save here. I'm going to open the file, and this code is
regular TypeScript code that you can use directly in your own environment.
Okay, so let me remove all of that. Dump here. What was generated for me by the node generator?
So the node generator, it's actually a node model where you create a node material,
and then you have blocks, transform block, whatever block, texture block, etc. You connect
all of them, like you connect the output with the input. So this code is just literally what I did
visually. And then it gives you a node material object that you can plug with your sphere here.
That material is equal to node material object. Let me close this guy here, close that,
run that again, and boom! In my code, I have my wonderful reflection, bump, whatever scene.
Yes, it's ugly, but it's about technical and development, right? It's not the designer track.
All right, so all of that, it's pretty cool. I can save it again. So I can save that,
and it will generate for me a new version of my unique URL here soon. It's a big one because
we dump the entire texture, so we just need to wait for the server to come back without an error,
hopefully. In the meantime, oh yeah, it's fine, it's done. Okay. In the meantime here,
let me show you a third tool. So Babylon.js is developed to be easy to use. You do not have to
understand shader, math, whatever. You just drop object, you create a light scene, a camera,
an object, you load a gltf file, and you're done. But if you want to, there is no problem for you
to just look under the hood and see how it works. And for that, we have a third object,
which is used by even our competitors. The name of this object is a browser extension,
the name is Spector.js. Spector.js is a tool that will let me inspect WebGL, like a profiler for
WebGL. So at the first thought, you could think that it should be a tool developed by the browser
vendor, but unfortunately, the browser vendor are not investing a lot into WebGL. So we did it.
So here, when I click here, I have a record button, and the record button will just
analyze the current frame and generate for me here a simple view of the orders that were sent
directly to WebGL. So you can see here, directly the bind, vertex array, the viewport,
all this command, our WebGL command, and every time you can see here, I am clearing the screen,
and here, I am using this shader that I can edit live here to send the data. And so you can see
precisely what's happening in your code. And you can even edit the code here, and it will
dynamically change the rendering. All right? So this one is pretty advanced. Not a lot of people
use it, but you should know that from the very beginning up to the end, like directly to WebGL,
you have the control. All right. Then let me get back to my other demo. So that's a new feature
that we are adding with the upcoming release for one, and this one is one that I love. I am part of
the W3C and Kronos working groups, and what I try to do with JavaScript is to make it
equivalent to what you can do with native. And one of the main problems of JavaScript
is that it's running on one unique thread. There is a notion of web workers, but web workers are
like process. To communicate between the main thread and the web worker, you have to send string
or share just array of memory. We recently had a victory by having the validation of the off-screen
canvas here, and let me show you the code. It's going to be even easier to understand. If I look
at my code, which is here, trying to make it bigger enough for you guys to see it, can I zoom here?
Yes. So I actually have
here two scripts. Okay. If I find the off-screen canvas API in the Windows object,
I will get a canvas. So there is two canvases, one on the left, one on the right. Okay. The one
on the left is just initialized by Babylon. Yes. So here you can see I create the canvas. I create
my engine, my scene. I say execute the code, render the scene. Done. And so it just loads the subject
and rotates it. Okay. It's done on the main UI. All right? The second one, it's exactly the same
thing, but using not a canvas, but an off-screen canvas. And so when there is off-screen canvas
support on your browser, so far only Chromium-based browser, meaning Edge, Opera and Chrome,
then you can call a new API called transfer control to off-screen, meaning that I will let
a second thread control the canvas and render to it. And that's utterly cool. Why? Because now
here it's a worker that runs this one, meaning that if I slow things down, when I'm going to
click on this button, I will do something stupid like computing this random scene, of course,
10 million times, just to simulate that you are doing something easy on the main thread.
And we do that, for instance, when you are on SharePoint or on PowerPoint, let's say PowerPoint,
when you display the current slide, PowerPoint is using the main thread to prepare the next slide.
Okay? So the thread, the main thread, the main UI is already pretty easily occupied to do something.
So by using off-screen canvas, we can have stuff that definitely are slowing down the main thread,
but still, because a second thread is running and doing all your 3D rendering,
the experience for the user is pretty good. Before, it was only that. And now,
we have access to the worker render. Yes, I know. I'm excited, but for a good reason.
Other stuff we are working on, I wanted to show you, like, GLTF support. Here, I have my
halion head. And if you look at my code, loading GLTF files, it's just one line of code here.
Sorry, I forgot to zoom it again.
And we have options to load it once and then duplicate it. If you are familiar with Unity,
I just can't remember now the name of that feature, but you can load an object, an asset,
and then introduce it multiple times in your scene. They are replicated, and it's a clone.
So it's a smart clone. The geometry and all the shader are reused. So here, the entire code to
run these three guys with, just for the sake of it, skeletal animation, meaning that the head
is moving with the neck. And also, there is a morph target. So the alien is smiling and
closing the move. All of that is loaded from the GLTF and then duplicated. And it's what? It's 20
line of code. This one, we don't care. Let's go next one. Webexar. So this demo, you know it?
Yes. We are in Hill Valley about to go back in time. And it's running in the browser. Yes,
I know. That's very cool. I like that. And there is a little button here. I don't have a headset
connected. So when I'm going to click on this button, Babylon.js will automatically
consider that you want to use some cardboard stuff, like running on your phone and setting
that in a cardboard. It will switch to cardboard mode, just to give you the experience here.
So if you have Oculus Quest, a Oculus VR, a Microsoft Mixerality headset, thanks to Webexar,
we just click on this button and we will take care of everything for you. And it's literally
one line of code. There is one line of code to switch. We have an object named the VR
experience helper. You just need to instantiate it. And it will automatically detect everything for
you, provide the button. And the scene that was not VR before then become a VR scene.
Up to a point where you can... I need to reload. Sadly. It should be fine.
We also support collision. I mentioned that. So here it's a kind of doom.
In a museum. And I walk like in a game, meaning that I can't go through the wall.
But I can go upstairs by just walking like in doom or quake. Exactly the same
the way I play it with my keyboard and my mouse. And that's running in your browser,
obviously. And at some point, you want to switch into VR. Just click the button.
And then you can teleport with the controller. Right.
Last but not least, I wanted also to mention this guy. You saw the video. That's physics.
Real-time physics using WebAssembly. Here you have a complicated mesh, this marble tower.
And we have a code here on the left that just drops marbles at the top of the tower.
And then we let the physics engine deal with that. And to just drop a marble, let me show you
where is that? When we call create marble here, let me zoom again.
The only thing you have to do is to say, okay, my marble has a physics and post-or. So
there is an imposter representing in the physics engine my marble here. And it's going to be a
sphere with a mass of two and a friction of whatever. And just with that, you let the system
drop and it will control for you the entire emulation up to a point where we have a complicated
scene here with this object, this scale. Also, when they reach this point, I should have a
smaller window. Here, they go into the wheel. And that's also physics engine just applying
real-time constraint on it. Right. Let me get back to my slide.
So, you should try it. Everything is entirely free. There is no hidden line or whatever.
Or you have all the links here, BabylonJS.com, doc.boblin, et cetera, the forum, the playground,
enemy, the dot-material editor if you want to play with shaders. That's it. Right on time.
Super cool, right? Okay. Thanks for the talk. My pleasure. And we have some questions. So
what's the advantage of BabylonJS over 3JS? What's the advantage? First, we are a team of
ten people paid by Microsoft to maintain it. We have a 24-hour bug turned around. So you declare
a bug, it's fixed in less than 24 hours. We do not have backward compatibility issues.
I know 3JS for that. And we have tools. 3JS is a good tool. I don't want to say it's a bad tool.
It's we just have a different philosophy. BabylonJS is more aimed for professional
products in the sense that there is support. And there is this turnaround for the bugs. Like,
we fix bugs very, very fast. Like, definitely, when I saw John Romero mentioning that you should
fix bugs first, that's exactly us. We stop everything we are working on to just fix bugs.
We do not have bugs. And we have a link on our GitHub. If you go to the GitHub, there is a mention
the average time to fix a bug on our repo. And so far, it's less than 24 hours. I guess it's 20
hours. Okay. Just from my side, I've used 3JS before. And it usually took me like quite a few
hours to get started with any project. And with BabylonJS, I started using it. And maybe because
I came from 3JS and the basics are almost the same. But I developed something like a VR,
just a shooter, where you can shoot balls just into empty space or something within like one hour
and headed running on my Oculus Quest in the browser, which was super cool. So I think like the
just getting started is way easier. At least for me it was. That's why we have a documentation.
No, I'm kidding. No one's here about documentation.
What's in it? What's in for it for Microsoft? Do you mean what the reason of Microsoft to
support the product? I guess, yes. I created BabylonJS on my spare time. And Microsoft was
interested to use it. So we use it in SharePoint, Dynamics and other products. We have 12 products
in Microsoft using it. And I was also working for Microsoft. It was not correlated at the beginning.
And they asked me if I wanted to keep working on BabylonJS and I asked them,
I will provide you support for all the 12 products that you have. But as a compensation,
you give me a team and we keep it open source and people can use it. So it was a win-win situation
where Microsoft get a fully fledged team supporting the product, whereas I wanted to be open and for
everyone. So it was a win-win situation. I have a question. So you told me earlier that you
developed another game engine before you came to Microsoft. Can you tell us about that a little
bit? Actually, I was almost emotional when I saw John Romero because I was a big fan of him and
John Carmack and I created my own engine when I was 17. It was a C using an engine developed with
C on DOS using Whatcom and I ported it back to DirectX and then I joined Microsoft and so I stopped
and I sold the company I created because it was a 3D engine for architecture and I sold my company,
I moved to Microsoft. And when I was a Microsoft, I was like, oh, my gosh, I still want to do 3D,
right? So at that specific time, six years ago, we shipped IE 10 and IE 10 came with the very
first version of WebGL for Microsoft. It was here since 8G for Chrome, but Microsoft entered
a 3D game on the browser like six years ago. And so I was like, okay, I want to do 3D stuff.
There is this WebGL support now everywhere thanks to IE. Okay, let's create a port of my old engine
which was now Babylon.js. That's really cool. Like with 17. Okay, I have another fun question
at the end, but how do you pass data between other JS code and the 3D application? Are there any
restrictions? So your 3D application will be JavaScript as well. So there is no restriction
at all. Like literally, Babylon.js is like jQuery or any other framework or React or whatever.
You're going to use it the same way. We have ES6 version of it and ES5 depending on if you want
to use it with module or without module. And there is no restriction. Like literally, all the
application using Babylon.js just communicate through JavaScript. Okay, there's one on performance.
What about performance and compatibility with mobile devices? Another good reason to use Babylon.js.
One of our motto is to make sure that it works everywhere. So we have a full list of devices
that we test on. And I would say like 20% of Babylon.js core code is about compatibility.
So we know that on specific version of iOS or Safari of Firefox or whatever, we have
hack because WebGL is a spec. And human implementing a spec, you know, it works, right? So everyone
understands things a little bit differently. So we make sure that it works everywhere. And then we
have thousands of countermeasures for performance. So we support WebGL 2 by default. If you don't
have WebGL 2, we have a fallback for WebGL 1. If you are supporting WebGL 1 with extension, we're
going to use the extension for you. So it's transparent in the sense that we try to reach out
the best performance. We know that in mobile, the CPU is the problem. So we try to move everything
to the GPUs. Even collision should be done by the GPU if you can. So we run on Chromebooks,
for instance. Flipgrid, if you know it, is an application Microsoft acquired recently. They
were just using JavaScript. But they were not able to run on Chromebooks because it's an application
that do screen capture for students. The way they did screen capture was very easy on the CPU. And
by using Babylon.js, they were able to move a bit of this code onto the GPU. And they were able
to reach out users using Chromebooks. So that's very important focus for us. So you have full
support already for WebGPU? We are the only engine that I know of supporting WebGPU. Yeah,
that's also what my last step was. Okay. What are the next steps for Babylon.js? Features,
etc. Number one is we're going to ship for one in February. February will be about what I show
you today, like finishing the not material editor. It's number one key feature. And number two is
supporting WebGPU. WebGPU is not even a draft spec so far. It's an evolving version. So every week,
I have one of my engineers just changing all the code we had to adapt to the new spec. Like, oh,
yeah, they reversed the viewport. It's now up or down anyway. So that's going to also be the main
portion of 4.1. And WebExar just hit the draft spec standard recently. So we plan to make sure
that everything works for 4.1 as well. And WebExar, which is an evolution of WebVR is complicated
because it's not just about VR. It's also about AR. So we are also working with the HoloLens team
to make sure that you can do AR with the web. So it's WebExar on the AR context, supporting
fingers instead of controller stuff like that. So that's the third big bucket of 4.1.
And then you still need the 3,000 euros for the HoloLens.
Yes, but I'm not responsible for that. I would have given that to everyone else.
I like this one. What do you recommend Babylon.js for 2.0 or 2.5D development?
Honestly, if you compare to Pixi or other 2D framework, it depends on what you want to do.
For 2.5, yes, definitely. And we have a lot of people using it. We recently came across a company
creating games for Las Vegas. What's the name? You know, the slot machines, exactly. It's
purely 2D, but they are using 3D to move the cards and stuff like that. So if there is a
sense of at least layers, yes, Babylon.js is a good example. Else, you should stick with pure 2D
framework tools. Unless you're interested by the backward compatibility issue and the
turnaround of bug, then we also have a 2D version of Babylon.js, so it could be useful.
Okay, I have another question. Did you actually have to support
at Internet Explorer with Babylon.js when you're working to 4.5%?
We still support it. You should take my demos. They run on Internet Explorer. The playground won't
work because I am in love with the arrow function. You know the new arrow function of JavaScript?
That sucks. But I was like, okay, the playground will not work on IE. That's not a big deal,
but every rendering stuff will work because, yeah, it's important for us.
One more. Okay. One more question. And I'm just going to look through here. I saw one that I can
quickly support. Which browser do we support all? Can you import models, maps, materials you
build in other software if so, what formats are supported? So, yes, part of the Babylon.js tools
I did not share today. We have exporters for 3ds Max, Maya, Unity, Blender 3D, a few others,
and we also developed transcoders. And the goal is to have everything in GLTF file format. So,
as long as your tool that you are using is exporting into GLTF, then we will be able to load it.
And we are also supporting tools that generate GLTF into the tools I mentioned before, like
Maya, 3ds Max, Blender and stuff. Okay. Let me see if I find one more. There's some over AI. I don't
get the AI. How accessible is Babylon to designers? We have users that are purely
designers. They use another tool that I did not name on straight here. It's the sandbox.
The sandbox is a place where you drag and drop a GLTF model and the inspector pops,
and you can edit everything just visually. And they use that a lot to create. We have a viewer
as well. It's a tool that you can plug in a page and just one line of HTML, you say display this
object, and there is no code, just a HTML tag. So, they use that to display controls and 3D objects,
for instance. Okay. Last one. Is it possible to stream 3D geometry between server and client
for an open world level? Yes. We have users doing that. Super cool. We just do the client
huntering, to be honest. We don't do the backend, for instance. And the streaming, you have to
stream something compatible with Babylon. Yes, but yes, we are doing that. Okay. If you have any
other questions, feel free. I'm going to stay here. Trying not to sleep. So, it should be fine.
If someone talks to me, it's going to be fine. First, you can have lunch now. There's going to be
lunch. Okay. So, everyone, have a good lunch. And, yeah. Thank you very much. See you after the break.
