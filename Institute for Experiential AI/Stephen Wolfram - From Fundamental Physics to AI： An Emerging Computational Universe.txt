So, welcome everybody, I have the pleasure to introduce Stephen Wolfram, I know him many,
many years because I was involved at some point in a different computer algebra system,
you know he's the creator of Mathematica, he's the founder and CEO of Wolfram Research,
he also created this semantic search engine Wolfram Alpha that you may be well aware of
and now he's using language models, he's author of many books like A New Kind of Sciences
and a very recent book on everything about physics and we are very happy that he accepted
to come today to do the last distinguished lecture of the semester.
So all right, let's talk about, so as far as I'm concerned the kind of the big idea
that is kind of a defining idea probably of our century is this idea of computation and
I kind of view it as being part of a long sequence of efforts that kind of span the
history of our species I suppose in trying to formalize things.
So you know the probably the first step in that was the creation of human language and
the idea that one could instead of just sort of pointing at different rocks and so on one
could have a kind of symbolic term rock that represents the general category of things
that are rocks.
That was kind of a big step in being able to explain, in being able to abstract things
from the world as it is to something that we can describe in a formal way and kind of
I would say the next another big step in that was the creation of logic the idea that one
could take you know a collection of sentences that had the particular forms of particular
forms and say there's something that we can abstract from all these sentences that is
a representation of something that is formal that we can deduce from these sentences and
it's kind of interesting that when we look at you know the chat GPT's of this world
and people are sort of amazed oh wow it manages to do logic well it's been trained from a you
know trillion words of stuff that we humans have put out there on the web and that contains
the same kind of forms of speech that you know Aristotle and folks like that used to
originally construct logic it's able it's one is abstracting from the specifics of language
to something that is a more formal representation of what's going on and I suppose in the in
the kind of long arc of history the next big thing that's sort of an example of formalization
of things in the world is mathematics that's another kind of way of formalizing what happens
in the world describing things in in terms of numbers and algebra and those sorts of
things and mathematics when it comes to science kind of the last 300 years sort of mathematics
had been the kind of dominant form of formalization used in science logic was not particularly
successful for as a formalization for science mathematics is sort of the winning one and that's
something that has had continued it for until quite recently the big thing that is sort of new
last 100 years is this idea of computation the idea that you can what is computation as far as
I'm concerned it's you specify sort of precise rules and then you understand their consequences
in mathematics there are particular kinds of rules that are represented by I don't know algebra
and integrals and calculus and things like that there are particular kinds of rules that we study
in mathematics computation is about the most general case of studying sort of given rules what
are their consequences and by the way there's sort of a difference in the way that particularly
time is handled when we think about computation as compared to when we think about for example
mathematics in mathematics we might have some equation that has time as a parameter but we
kind of expect we're going to get an answer but we get some formula where time appears in the
formula but we can set that time to be any value we want when we think about computation we're
thinking about we're given these rules and now we're going to run these rules and we're going
to see what happens we don't we don't we don't get to say oh I'm going to sort of set the value
of time to be this we have to just run the rules and see what happens maybe I should explain some
things that this is from the from the 1980s actually the kind of a big effort of the the question
a the this I've been talking about kind of computation as a as a way of kind of of formalizing
what happens in the world so one of the things I got interested in back at the beginning of the
1980s actually was if one is going to make models of nature what raw material one might one use to
do that and kind of the traditional view had been used mathematical equations and so on my
interest was to kind of generalize that and to see what happens if you use not equations but
programs to represent things in the world and I have to say it's kind of a spoiler for for the
path of history but in the last play 25 years or so the there's been after 300 years of complete
dominance of kind of mathematical equations as ways to model the world computation has become
and programs and so on have kind of become the when new models are created that's almost always
what new models get made with so but the question that I got interested in years ago is when you
look at just simple if you just ask what what kinds of programs might nature use to do the things
that it does and a particular category of such programs that I found convenient to look at are
things that get called cellular automata this is an example of them it's just a line of cells
each one is either black or white and in a series of steps you set the the new color of the cell
to be determined by rule that depends on the previous color of that cell and the previous
colors of its two neighbors so if we take that we just say run run that let's let's let's run
that for a few steps here let's show this mesh okay so this is this is using that rule and at
every at every cell at every step we're just applying that rule to determine what the color of
the next step cell will be so we have a very simple rule we get very simple behavior it's kind of
like you kind of it might expect that's what's going to happen well let's let's change this rule a
bit let's say we have something like this we can change it see what it does that's what it does
then let's change it again let's say we do this now we use that rule instead well now we get a
slightly more complicated pattern if we keep it running a little bit longer we'll find that it
makes a nice some kind of elaborate intricate but very nested structure and we might again say at
this point oh you know if the rule is simple then even if the behavior is somehow intricate there
will be some easy regularity to identify in that behavior okay so now you can ask the question if
you're just sort of studying these things from a sort of science point of view you can ask the
question well why don't I just do an experiment why don't I just point sort of a computational
telescope out into this computational universe of possible programs just find out what's out there
so we can try doing that and let's just make a table of these with any rule number here
and let's do let's say the first 64 of these and this is the result we get so much of the time so
every one of these pictures is a different rule that we're using a much of the time you see what
happens is really pretty simple maybe there's stripes from alternating stripes but there's some
fairly simple structure that's produced and here are some nice nested patterns and then this is my
all-time favorite science discovery here's rule 30 in that numbering scheme it does something a bit
different let's take a look at that in a bit more detail let's say let's look at the rule for it here
it is and let's look at what it actually does and that's the result so what's really remarkable about
this is the rule is simple starts off from just one black cell yet the behavior you get when you
actually run this rule is something complicated in fact if you look at the center column of cells
here for all practical purposes they seem completely random and this is this is kind of a big surprise
to one's intuition because this idea that to make something complicated you have to go lots of effort
that's what we kind of learn intuitively from doing engineering if you want to make a complicated
thing you have to go to a lot of effort to build up this whole structure that's going to make that
complicated thing but here we've got something where in a sense effortlessly from this very simple rule
we're making a very complicated thing well back in the 1980s what I was excited about was what that
means for understanding what happens in nature what happens in in in kind of the understanding
how sort of complexity arises in systems in nature and realizing that this kind of phenomenon that
we see in the computational universe seems to be the secret that nature has that lets it makes
so many complicated things that in fact out in the computational universe of possible programs
it's actually pretty common to find that even very simple rules can generate what appears starts
to be very complicated behavior well maybe it's worthwhile to understand kind of what how we can
understand this phenomenon that very simple rules can produce very complicated behavior what's
sort of going on what are the broader scientific implications of that and the I suppose one of
the one of the the big the underlying principle that I kind of came up with in the 1990s now
is this thing I call the principle of computational equivalence so here's how this works we think
about what what is this thing doing we can think of it as doing a computation it's been given some
input it's been given a rule it runs that that that rule with that input it generates some output
it's it's a computation like a computer might run a a computation the question is how sophisticated
is that computation is that computation one that is somehow quite straightforward we could just
jump ahead and we could do a better computation figure out the answer or is it the case that this
computation is is is a sophisticated one so the big thing that was discovered about 100 years ago
now is this idea of universal computation the idea that there exist systems like Turing machines
and so on that have the property that you can just have a fixed piece of hardware so to speak a fixed
rule and yet by changing the initial conditions for the system you can make that system behave like
any other computational system and that's sort of an important idea because it's the idea that
makes software possible it's kind of the idea that drove essentially modern technology as it is
but that idea is says there is there exists a system that you can build it's maybe it's a
microprocessor with a billion transistors on it that is capable of universal computation
what the principle of computational equivalence says is something much more extreme than that
it says whenever you look at these systems in the computational universe when they're not doing
things that are in a sense obviously trivial then they will tend to be doing things which are
as sophisticated computations as anything can do so it's kind of saying that that something like
this system here should be capable of for example universal computation but more to the point
it's the computation you're seeing here is as sophisticated as the computation that any system
can do so what are the consequences of this well one consequence is if we're trying to predict what
this system does then we're doing that by doing a computation so if we expect that we can sort of
jump ahead and say this system after a billion steps is going to do this what we have to believe
is that the computation we can do is somehow more sophisticated than the computation the system can do
so that we can kind of do that jumping ahead and seeing what the answer is going to be but the
principle of computational equivalence says you're not going to be able to do that it says that the
computation you get to do with your brain your computer your mathematics whatever else is just
the same sophistication as the computation that this little system can do so you can't expect to
be able to jump ahead like that and that leads to this phenomenon i call computational irreducibility
which is this idea that there are things that happen computations that happen which are irreducible
in the sense that to know what's going to get what consequences they're going to have you basically
just have to run that computation and see what happens you can't expect to jump ahead
and figure out the answer with with less steps than actually running essentially with less steps
than actually running the system so here's an example let me show you an example of another one
where it's kind of interesting to see what happens here let's say rule 110 so this one actually
happens to grow only on one side but you see it makes this little structure let's run it for
a thousand steps let's say and the question will be we have that little structure there is that
structure going to die out or is that structure going to keep going forever well if we said if
there wasn't computational irreducibility we could say well we expect there's just some some
sophisticated formula we can make that can jump ahead and say that's what's going to happen in the
end to this but with computational irreducibility the only way we can work out what's going to
happen is essentially to follow the steps and see what happens and if we don't know how many
steps we have to follow it's going to be in general a question which is sort of undecidable to us
what's going to happen in the end well let's see you can run it I think there's 3000 steps
enough yeah 3000 steps was enough because if you can just about see it you'll see that it
pretty much died out maybe it's still got some possible life to it but what's interesting is
that we can't predict that without essentially running the rule and just seeing what happens
so okay so this so we have that we've discovered this phenomenon that even very simple rules in the
computational universe can produce very complicated behavior can produce behavior that is uh is it
turns out to often be similar to the kinds of behavior we see in the in the natural world
also has this feature that even though we might have thought you know the big thing about science
is you can always jump ahead and predict things computational irreducibility shows us that
that's not true there's sort of a fundamental limitation it's kind of from within science we see
there's sort of a fundamental limitation that prevents that from happening and makes it it's
so that we kind of just have to simulate things to see what's going to happen okay so one question
you might ask is we found out that very simple rules can produce very complicated behavior
how far does that go what kinds of things can that do can it make you know can it make brain like
things can it make universe like things what can it make let's talk about the universe first
because it's sort of the biggest thing we can talk about um and uh the um so the question is if we
look at the physical world what what's underneath what's the underlying structure of how the physical
world gets made could the physical world in fact be something which can be represented by some simple
computational process and people have wondered you know what what's the sort of fundamental
theory of physics for a long time and people have different views of that and there's been kind of a
bunch of well it's going waves of optimism and pessimism but about a hundred years ago a lot
of progress was made in the invention of kind of the the core theories of modern physics which are
basically statistical mechanics the theory of kind of what you know things like gases with lots of
molecules how that works the second law of thermodynamics things like that that's one bucket
the second bucket uh is general relativity the theory of gravity and the structure of spacetime
and the third bucket is quantum mechanics and the theory of very small things so to speak so
those are the sort of the um the main uh uh there was sort of a big big advance a hundred years ago
or so now in those kinds of areas um the question is okay so what's for example what's underneath
those things are those just sort of arbitrary wheeling features of the universe or are they
derivable in some way so this kind of seeing things like rule 30 makes one think well maybe
there might be some very simple rule that might be able to to explain what's going on well back
in the 1990s I started thinking about this made quite a bit of progress actually um but uh the
time I suppose physics was in a very um high self-esteem state and it was like string theory is
going to solve it you don't need anything else so um uh I worked on other things which turned out
to be rather productive and um then about four years ago now came back to this question having
figured out a lot of other things in the intervening years and having built this big stack of technology
I mean in in the the kind of rough summary of my life is that I've kind of alternated between
doing basic science and developing tools and technology and it's been a pretty pretty good
journey I would say because you know you do basic science it shows you what is conceivable to
build in technology you then build the technology that creates tools that let you do more basic
science and I managed to iterate this about five times so far in my life and it's built a pretty
big tower and from the top of that tower we can now see some pretty neat basic science that's been
really exciting to me in the last few years and let me let me tell you a little bit about that and
then I'm going to tell you a bit about sort of how that connects to the practical world of
of kind of computational x for all x and we'll talk about ai and uh and whatever else we can we
can fit in there all right so let's talk about the fundamental theory of physics and what what's
underneath the stuff that we experience in the world let's see I probably have a nice visual
summary here which I can perhaps use um so this is sort of a visual summary of our physics project
and as is often the case in science the first thing you have to do to make progress is to
realize what was wrong before and one thing that's been assumed the last couple of thousand years
is that space is something continuous that you can just sort of space is just this thing where
you can say I'm going to put something at this particular coordinate position in space I'm going
to put it at some arbitrary position in space turns out that seems to be wrong that space is
not a continuous thing space is made of something and a hundred years ago people thought this might
be the case actually because a hundred years ago there was a big a little bit more than a hundred
years ago so the big argument was is matter continuous or discrete are there discrete molecules
or is matter a continuous kind of thing same question for light well it turned out round 1900
people realized no molecules really exist matter is discrete and turns out and light by 1905
so people realized photons really exist light is also discrete so you know matters discrete light
is discrete what about space at that time and actually I just recently uh I just last few days
actually learned even another uh place where sort of most of the physicists so to speak back in the
early part of the 20th century thought that space was discrete but they couldn't make it work in fact
Einstein has a nice quote from 1916 that basically says in the end space will turn out to be discrete
but we don't have the tools necessary to see how that works now a hundred years later it turns out
we do so the sort of the first first sort of starting point is the realization that space is
discrete space is made of discrete atoms of space an atom of space has nothing that there's nothing
you can say about it other than it's this it's this idealized point this idealized element
the only thing that one can say about it is that it exists and it's unique and distinct from other
atoms of space and then what can you say about the atoms of space well all you can say is how
they're related to each other you can kind of think of the friend network of the atoms of space
so you're kind of saying what and that's all you know about these things there's not they're not
placed in any kind of you know you're not saying it's in three dimensions and you're placing this
particular atom here and so on all you know is there's this giant network that represents the
relations between the atoms of space and it's convenient to technically it's convenient to
think about it as a hypergraph and an ordinary graph you have two nodes of the graph and they're
they're connected by an edge and a hypergraph you can have any number of nodes connected by a
hyper edge so it's just technically convenient to think about it as a hypergraph so the structure of
space is this hypergraph of atoms of space and basically everything in the universe is just
part of this giant hypergraph so all the things that we experienced the you know the the electrons
the black holes whatever else they're all just features of this giant hypergraph it's kind of
like when you if you think about something like water there's a bunch of molecules bouncing around
but you can have things like eddies vortices in the water which are structures that have some
persistence and it's those kinds of structures that are like the things that we experience like
electrons and so on so okay so the the sort of underlying data structure of the universe is this
giant hypergraph made of atoms of space and by the way it's a it's a feature of doing very
foundational things that there are many equivalent versions of this statement you can talk about it
in terms of higher category theory you can talk about it in different terms but I think the most
concrete version is it's this giant network that is this hypergraph so then what that's sort of the
structure of space the structure of what how does time work by the way one of the things that sort
of a wrong turn in the 100 years ago was this idea that space and time are the same kind of thing
it was a kind of idea that was introduced sort of as a mathematical convenience and then it
became a thing that everybody explained oh space time is you know space and time are all connected
together like that I don't think it's true time is actually something very different from space it
turns out that the features of relativity theory that connect space and time emerge from the kind
of large-scale properties of the system but they're not the intrinsic way to think about it so what
is time well time is this kind of process of computation just like in that rule 30 cellular
automaton we've got the series of steps those represent the progress of time and computational
irreducibility kind of tells us there's some kind of irreducible thing achieved by the passage of
time and so it is in the system instead of it being updating these cells with neighbors and so on
it's you say we've got this we've got this graph and we have these rules that just say whenever
you see a little piece of graph that looks like this rewrite it to a piece of graph that looks
like that and so you keep doing that over and over again and you build up more and more elaborate
kinds of graphs you get all kinds of complicated structures like this and one question is when
you do that enough times what is the what what you know when you have a graph that has 10 to the 100
nodes or something in it you've built up this way what is the structure of that graph well it's a
similar question to asking the question if you have a bunch of molecules bouncing around and they each
interact according to some force law and so on what is the large-scale behavior of a whole
collection of molecules and the answer we know in that case is it's like fluid dynamics that's what
happens in something like water you've got these discrete molecules bouncing around the emergent
kind of behavior of the system follows the laws of fluid mechanics okay so what's the analogous
thing here well it's pretty neat because it turns out the analogous thing here is the thing follows
the Einstein equations which are the the the corresponding laws for the structure of spacetime
and so you can then derive from this very simple underlying set of rules that are about the
rewriting of networks the large-scale limit of that with a bunch of footnotes that are a complicated
story you can derive the fact that the you get the structure of spacetime that that we observe
now actually one of the things that's tricky is this thing doesn't have any space in it at the
beginning it doesn't even know that it's in three dimensions for instance dimension is something
that's an emergent property of the system where you're basically saying if you start from a given
node in this in this graph and you say what how many nodes do you get to by going a certain distance
on the graph a certain number of steps in the graph let's say you get to some number of nodes
and that number of nodes grows like r the distance to the power d then you can identify that d as
the dimension the effective dimension of the space so one of the consequences of this model
is that space won't be precisely three-dimensional there'll actually be dimension fluctuations
probably the the beginning of the universe will be infinite dimensional gradually the universe kind
of cools down to being the three dimensions we observe today and they're probably dimension
fluctuations left over from the other universe and an interesting kind of current sort of can we
figure out how this works question is what actual experimental signatures there are from such a
phenomenon but anyway so so by the way let me just show you um let me let me just show you in this
model um this is kind of the uh what the the a version of the beginning of the universe in
this kind of model where so we're we're seeing here the progressive rewriting of uh kind of this
network of atoms of space and uh this is the first very small amount of time in at least one branch
of the beginning of the universe um you have to keep going a long way to get to our current
universe and because of computational irreducibility that's not something i'm going to be able to
do on my laptop however the um uh the thing that um you can set things up to kind of see
what would it be like if you had a much bigger chunk of space and this is an example yes here we go
okay so this is much later in the history of the universe these are two little black holes
and what you'll see here is the the um that sort of the background here is the structure of space
and space is kind of knitted together by all these little rewrites that are happening if it
wasn't for all these rewrites space would fall apart the space the the fact that there is this
this thing we can think of as space that is kind of it has extent as a consequence of the of the
progression through time of all these rewrites but anyway here are two little black holes and you
can see what they do the space is uh is wiggling around a lot these two little black holes actually
feel the force of gravity um that's just a consequence of these rewrites and then those
black holes merge well that's something that we observe in uh that's gravitational wave detectors
have observed the merger of black holes these are incredibly tiny black holes turns out very
conveniently the behavior of a very tiny black hole is pretty much the same as the behavior of a
very big black hole so we can actually start to see and when when these black holes merge in this
little simulation here um turns out they emit gravitational radiation and we can start seeing
the properties of their gravitational radiation and one of the current frontier questions is
whether there are features of that gravitational radiation that reveal the discreteness of space
and uh I think I think it's it's fairly promising that there are although whether the magnitude
of the the things is such that we can detect it now versus 100 years from now we don't know yet
that yet but anyway that's kind of how the the structure of space works in in these these kinds
of models another thing to to mention is uh another so I mentioned this um um the uh um the the
question of um these sort of three big theories of of 20th century physics statistical mechanics
general relativity and quantum mechanics so we've got what I've been describing is the
derivation of general relativity people didn't think general relativity was something you could
derive from something lower level it looks like it is so the another piece to this is quantum
mechanics and sort of the big idea of quantum mechanics is in classical physics you imagine
that definite things happen in the world in quantum mechanics the big idea is that you know
you throw a ball and it doesn't just follow a single trajectory it follows many possible
trajectories and you just get to figure out what the probability of different things happening is
well in our models we actually have no choice but to have quantum mechanics because what happens is
that I talked about the rewriting of these the hypergraphs that represent the structure of the
space and everything in it there are many possible ways these rewritings can happen
and the result of that is that you get what we call a multi-way graph that represents all the
different possible paths of history there can be different rewritings that happen there can be that
can cause these paths of history to branch they can merge and so on so kind of the the big thing
that happens that you get these multi-way graphs multi-way graphs are something pretty interesting
that that sort of related to nondeterministic computation but in nondeterministic computation
you tend to just say we're going to pick the one winning branch in multi-way computation you're
interested in sort of all the possible things that can happen and so you know you can kind of
think about lots of different kinds of problems in these terms you know you've got a game like tic
tacto or something there are many possible paths you can follow to in the in the doing of that game
and you can kind of look at the complete graph that you get let's see if I can just pull up a
picture of that so you know a typical kind of thing would be here we go um it's kind of a
multi-way graph that just shows given that you're starting with a blank tic tacto simplified tic
tacto board you get this kind of graph of all these possibilities you keep going somewhere here
probably there's a picture of the actual game and and what it takes to win the game and so on
but that that's an example of a multi-way graph in that particular case for just the game of tic
tacto but the the whole point is there is also a multi-way graph for the whole structure of our
universe and the fact that there are these different paths is is the reason that we get quantum
mechanics since it's slightly more complicated story we have when you when you kind of take a
slice across all those paths you form this kind of space we call it branch real space the space of
quantum branches which is kind of its own kind of space and just as you can think about kind of
motion in physical space you can also think about motion in branch real space just as you can think
about observing physical space we we notice that in physical space well okay the the the we we are
at a scale much larger than the atoms of space and so we aggregate when we observe what physical
space is like what we're observing is this this vast aggregation of atoms of space and that's why
space seems to us continuous well something a bit similar happens in quantum mechanics what happens
is that just as we are extended in physical space we are also extended in branch real space and so
a rather strange thing it has to do with the fact that an observer like us that has that is part of
this universe that's branching and merging and so on the question of quantum mechanics becomes how
does a branching brain perceive a branching universe and turns out that when you untangle
those things the answer is quantum mechanics so okay just to finish on this in this branch for a
second the the thing so one of the one of the questions would be okay so we've got this model
for physics and we can say there's an underlying rule which if we run it for long enough we'll make
our universe so the next question is well why did we get that rule and not another rule and that's
sort of a you know that's a kind of the the Copernican thing would be to think there can't be
anything special about the rule we got we just have to have some sort of very arbitrary rule well
the the thing that I wondered about this for for a while and then we realized that actually here's
what's going on the the structure I mentioned that given a particular rule you apply to no possible
ways and that's what gives you quantum mechanics but why do you have just one particular rule
what happens if you apply all possible rules and you make something which is the result of taking
all possible computational rules and running them and you can see that different rules will produce
different results but then those results might converge again because when you run different
rules again they'll converge to the same results and so on you get this big complicated entangled mess
that is the the result of running all possible computations so you it's kind of you make this
thing which is the entangled limit of all possible computations it's the thing we call the rule ad
and it's kind of the it's an encapsulated object that represents everything that is
computationally possible and it's a it's a kind of an interesting object because it's a very it's
a necessary object it's not an object that you say oh it happens to exist in this way in that way
it's just given the idea of computation there is just a single object that is this rule ad that
represents all possible the entangled limit of all possible computations okay so so what so how do
you make how do you take that and understand sort of how we we perceive physics and things like this
well the key thing is this realization that we are a certain kind of observer of this rule
ad we are it's a little bit of a brain twisting kind of thing because we are embedded within
this rule ad we are part of this rule ad and we are observing what happens in the rule ad and
turns out that there are we might say well well what we observe to be happening in the rule
ad depends on what we are like as observers so the question is do we how much do we have to
know about what we're like as observers to conclude what about what we will perceive happens in the
rule ad okay so it turns out there are two key assumptions about us as observers both of which
are pretty uncontroversial one is that we are computationally bounded we we can only and our
sort of finite minds we can only fit a certain amount of computational effort point one point
two is we believe we are persistent in time even though at every moment in time we might be made
of different atoms of space we believe that we have a single thread of experience that continues
throughout time so those are two assumptions so it turns out this is sort of the big result of
the last few years it turns out those two assumptions are sufficient to derive the three big theories
of 20th century physics so given this idea of the rule ad if you say what does an observer with
those characteristics perceive in this big messy rule ad of all possible computations
it turns out that an observer with those characteristics necessarily perceives
actually the second rule of thermodynamics general relativity and quantum mechanics
that's kind of a very interesting kind of I suppose philosophical moment that these are
things which seemed like they were just features of the universe that happen to be the way they are
but it isn't true that there instead there is this kind of necessary formal structure
which for observers like us if we were not like we are if we were some kind of alien observers
with different characteristics we would perceive a different physics but given that we are observers
of the kind that we are we necessarily perceive these features of the physical world so that's
kind of a that's a that's a sort of a big deal in thinking about physics it also turns out to
have implications about mathematics and the kind of nature of mathematics and so on can talk about
those but let me let me talk about some more practical kinds of things so so we've kind of
understood something about this idea of computation that ends up sort of going all the way down it
gives us the machine code for the universe it seems and it tells us things about sort of the
sort of the big picture of what's computationally possible well so okay so here we are as just
humans hanging out in this really add and and and the question is how do we access this kind of
this the the how do we what can we access of computation and so then we have the kind of
interesting situation we are humans who think about things in certain ways and what do we you
know how can we make use of this kind of power of computation that sort of is the intrinsic thing
that runs the universe and so on and and what you start realizing is that you need some kind of
bridge between the way we think about things and the sort of ocean of computational possibilities
much of what's out there in the computational universe is stuff that is completely incomprehensible
to us it's stuff where we can run all these cellular automata they make all these patterns we say we
don't really know what the significance of this is they're not really connected to anything we know
about most of the computational universe is completely alien to us and so the question really
becomes sort of how do we characterize the parts of the computational universe that we humans can
connect to his sort of perhaps an interesting experiment I can show you something here this is
looking with genitive AI just looking at the yeah this is this is looking at sort of a very tiny
slice of the rule yard that has been set up to be aligned with the way we humans think about things
because it's been it's a genitive AI trained on a few billion images and so what we're asking is
if we look out into that sort of space of possible possible things that we can think of as a tiny
slice of the rule yard what's out there and so we we said okay let's let's make a we initially say
we're we're going to look for a cat and a party hat and somewhere at the beginning there was was
a part of of this of the space that has a nice cat there the question is what else is out there in
the space if you go away from the cat and the party hat you go out and you're going out into
sort of this space of computational possibilities and what you find is there's sort of a cat island
where things are sort of identifiably cat-like but then most of sort of this space consists of
things that well there's some definite structure there but it's not clear what we humans would say
about that structure we don't really have a a way of thinking about that we think about so we can
kind of think about think about these sort of blobs of of possibility that our concepts are
things we've given human names to we've given words to their concepts we know about and then
there's this vast area of kind of inter concept space kind of analogous to interstellar space
where it's something that we haven't you know we humans have not conceived we don't have a way to
that we brought that into our kind of world and so you might ask well what fraction of space is
inter concept space in this very simple example that's a very sort of optimistic case one part
in ten to the six hundred of the space is space that we understand the rest of it is all inter
concept space concepts that we humans have not yet reached so you can kind of think about the
progress of of our intellect and science and so on as being this kind of colonization of what we
call rural space of kind of gradually expanding in the domain of what we consider what we have
concepts to describe it's some kind of a okay to make a slightly bizarre comment but but one thing
you might wonder about is okay in the future of science and everything maybe the future of
science is we expand in rural space and we we eventually expand so that we fill all of rural
space it turns out one should be careful what one wishes for because one feature of that is that
in in a sense when by the time you have a mind that is that big it is not a coherent mind anymore
and for it to coherently exist it has to be something that is limited in rural space by the
time it fills the whole rulliard in no meaningful sense does it coherently exist so in a sense when
you when you if you expand too far you you you no longer can can describe yourself as as coherently
existing so okay so so there's there's this um uh this is kind of what what it looks like out in
this sort of human aligned uh into concept space this is this is kind of what what it looks like
just in sort of out in the rulliard looking at different possible behaviors these are just cellular
automata um but we can say well when we look at these things what are these things how do we
describe them are they things that are relevant to to us yet do we yet have words for these things
and the answer is typically no we've we've explored only this tiny slice okay but so what can we do
with the slice that we're exploring well the big thing that i spent much of my life actually doing
is trying to build kind of a a a thing that is a bridge between the way we think about things
and what's computationally possible and the way that uh what we what we need to do is to take the
things that we care about that we think about and formalize them so we represent them computationally
so that we can make use of kind of the power that exists in this computational universe
and so that has been the the big effort to build what we call wolfman language um
and uh sort of the goal there is is to be able to represent sort of everything in the world
in a computational kind of way so i mean if i take um uh well let's just let's just say you know i have
um i don't know some uh let's let's say i make some graph uh we can we can represent some random
graph as as a a computational kind of thing we could say i don't know let's work out um
let's just do some computation on that and the um uh um well we could take um uh we could take
some let's see if i can um take an image here ah what if i do that um let's see there we go
well terrible image but um we could we could say something like um uh well let's just say
something like edge detect that image um or we could say if we wanted to be a little bit more
optimistic let's see um how about we do this how about we say uh let's do this um
um let's take that image and let's say we want to just say identify what's in that image but
let's let's run it this way so we're running some neural net we can look at um uh we may have to
load in oh what on earth is that i have no idea what that is um it's the back it's the backdrop
okay okay let's see well let's let's see what happens if we say what's the word definition
of that thing okay um but it's kind of interesting to um we can look here if we say uh well that
that thing will just be some neural net that um uh we can look at it's all the all the all the nasty
innards of it uh we could for example just say let's just take the first uh five levels of the
neural net or something and apply that to this picture um and uh and then maybe we can say
make images out of those okay so that's kind of the the uh inside the mind of the neural net
what it's thinking about maybe we can just say let's let's just do this let's say
make a feature space plot of those let's see if we can not very exciting it just decided that there
were two clumps of things that was thinking about one seemed like they're mostly white one seemed
like mostly black so it goes um but but anyway the kind of the concept here is to make a computational
language that can formalize the things we like to think about in computational terms so that we can
do things uh so that we can use sort of the power of computation to operate on those kinds of things
so for example there's the part of the the story is just knowing a lot about the world so we might
say you know that's there's a list of words in English maybe we can say let's just take
the first letter of each word and let's make a word cloud of those first letters and um
this will give us oops what did I just do word list oh that's not what I want to do I wanted to say
take just the first letters there okay there we go and so that gives us for for English the uh the
sort of word cloud of first letters maybe we can just for fun let's try doing Spanish for example
I don't know whether anybody knows what the what what part of a dictionary is most
thumbed in the Spanish dictionary this predicts it will be c um the uh so um in any case the the
kind of the goal here is to is to is to know things about the world so for example we could say um
I don't know what we let's see what um uh let's see what we what we know about Northeastern
University as a as a thing let's see let's look at what properties we might know about Northeastern
University okay let's say somebody was just telling me this number so let me just see what
what it thinks that number is um okay let's see whether we know what that is as a function of
time uh I don't know whether we will but um okay we have something some information here um okay
so that claims to be the um the plot of the number of students as a function of time at
Northeastern um but uh we could we could say something like let's let's make a um uh I don't
know where it thinks the computer is right now but maybe is that plausibly here I don't know
we'll find out um let's say uh um the somebody's figuring out why the why the plot looks like that
I um it's um um the uh so let's see whether this um okay so that's just showing us a geodesk of 10
miles around where we are let's maybe maybe we can just make something just for fun that um has a uh
uh let's say 10 to the 10 to the n miles and let's make a table of these with um
n going from let's say 10th of a mile to let's let's try this so this should make a series of
of kind of um there we go so this is um that's from from very nearby where it thinks the computer is
to very far away where the um the the disk extends to most of the earth actually we
can make that look better by saying let's say geoprojection um would be I don't know what's
a good example lambadas might be a good one so we're making a difference to the local so what
we get locally but it will make a difference when we get to um a larger part of the earth we should
see something more sensible here it's probably it has to recompute all these projections of the
earth so it might take it a little while but in any case the the kind of the big idea is just
to be able to there we go um so that's kind of interesting the the um uh so you know the big
idea is just to know about and to represent the kinds of things that we humans care about
to represent them in computational terms and kind of this has been my effort over the last
40 years or so is to progressively represent more and more things about the world in this
formal computational way so that we can compute from about them and this is something that's
pretty important because it's something that it gives you this we have now this language
for representing things computationally and if you think about sort of history
the um the the a thing a bit like this that happened before maybe 500 years ago
people had the idea of making notation for mathematics there had been kind of mathematics
just described in words and then there started to be notation for mathematics plus signs and equal
signs and things like that and then people started to be able to just talk about mathematics in a
streamlined way and then algebra got invented and then calculus and so on and that kind of spawned
the possibility of all of the modern mathematical sciences and so kind of the question for today
is what can we do with this idea of computation how can we use that in the world and what we
realize is for any field x in the archaeology to zoology to whatever else there is a computational
x that you could build which essentially takes the questions of that field and presents them
thinks about them in a kind of formalized computational way and kind of my goal over
the last 40 years has been to build kind of the notation the language to represent
things computationally in the world and and that's um uh it's kind of I think the the thing that
we've achieved at this point is this sort of having made this kind of full-scale computational
language that allows us to represent things in the world computationally and I see you
you have a microphone there and that this is a I could I could talk about I I didn't even talk
really about AI yet but I can talk a little bit about let me let me just say a couple of things
about that and then then we'll then we'll move on to then maybe we can we can chat about it some
more I mean I think the the um one of the things that's been an interesting thing the last year
or so is that um uh the um uh we used to just have human users mostly um you know millions of
people every day use many millions of people use our stuff as humans but now we have a new kind
of user we also have AIs as users we also have LLMs that are writing um uh that are that are um
are um using our technology here's an example this is a chat notebook and we can say something
like um this is a you can say well let's make um I don't know make a circle that's half green and
half blue and that this is now um let's see what happens here I have no idea what this is going to
do but um this might write some more from language code it might uh you know what I thought it was
going to do usually tries to do is to actually run that code and see what happens well we can we can
run it ourselves and see what it did right okay not so bad um in that case it happened to get it
right what's interesting actually is is what you see happening in these chat notebooks um you know
we have this we made this plugin for for uh chat gpt back in what was it that must have been in march
I think um and uh uh that gets pretty widely used but but what's perhaps more interesting is the kind
of the the sort of collaboration that goes on between the human who has some idea what they're
trying to do who try to types it in you get a piece of wealth and language code our language is
kind of unique in that it's a language that's intended to be read as well as to be written
by humans so it's so the kind of the loop is typically you the the the thing that is difficult
and this is the the part that is sort of the the education moment is how do you take the thing you
might be thinking about and think about it computationally once you can do that you can begin to explain
to the LLM oh this is roughly what I want to do you explain it in in in human language words
it will make a piece of computational language you can then take that piece of computational
language is that what I wanted I run it I build on it I make it this sort of brick that I start
building my whole tower out of so this is kind of the but the the piece of this that is critical is
how do you start thinking about the world computationally there's not something people teach
typically they they should but they don't it's not what computer science is about computer science
a wonderful field but it's not about that it's you know the thing that is the challenge to reach
kind of computational x for all x which is kind of the future of pretty much every every field at
this point because as I said sort of computation is the formalism is the formalization that we got
to figure out how to do in the last century and it is the thing that is sort of driving the future
of these intellectual areas and so then the question is what you know how do you get to the
point where people can actually sort of conceptualize what they want to do in computational terms how do
you how do you teach this kind of the how to think about things computationally it's not what people
have usually done and actually I guess my project that I'm in the process of doing right now is
actually just about to get started on is because it seems like I'm I'm in the strange position of
being sort of having a responsibility to do this to sort of define what does it look like what is
this kind of basic course that the people should teach very broadly about sort of how to think about
the world computationally the mechanics of how you actually do computation well if people like
like us have done our job most of that has been automated away the LLMs automate even another
stage of that away but what's what's really at issue is how do you think about the world
computationally and and sort of how do you how do you conceptualize that one last thing about AI
the the we can talk about I wrote this whole explainer of chat GPT that some of you might have seen
that that sort of led me to kind of a theory about what's actually going on in LLMs we can talk
about that if people are interested in it but I think one of the things is sort of the future of AI
and people say you know our AI is going to take over the world and what's going to happen and so on
the the the question of what does an AI want to do well you know an AI that's been aligned with
what humans you know it's been trained from what humans do that's one thing but sort of an AI left
to its own devices what does it do what you realize is AI's are creatures of the computational
universe and there's just a lot of computational universe out there that AI sort of could explore
and so the question then becomes well where do you want to go and that's not a question that the AI
can there's no theoretical answer to that question there's this whole computational universe out
there that you can explore the question that is the key question for us humans is well where do we
want to explore what what is the what what direction do we want to go in this computational
universe of possibilities and you know when it comes to sort of things that get automated by AI
the kind of jobs that get automated by AI there are lots of things where we know where we want to go
it's a question of the mechanism of how we get there and that's automatable but the question of
where we actually want to go which of the choices we want to make that's almost by definition not
automatable because that's something that we humans can arbitrarily choose so anyway that that's a
there's much more to say about this this topic and and so on but that that's some just a few
a few things maybe we can chat about all right well I should stop there thank you very much
and and now we will go to the fireside chat with Steven and Sam Fayad the
secretary director of the institute and at the end we will have a Q&A with all the audience
well welcome everyone to this portion where we are going to take audience questions and what
we'll try to do is alternate between audience and some fireside chat questions that I prepared
Steven and Sam we also agreed there was a session with faculty and a session with our
students that we can help different to some of the issues that that came up late so let me
let me start maybe with a question from me which is you know pretty practical over a decade ago
maybe almost 15 years ago you launched Wolfram Alpha and it was a I mean in my opinion it was a
very effective amazing semantic search based you know approach that's much more knowledge based
than what we see today with with the LLMs and the autocomplete and all of that
I would say one thing it's not about searching what Wolfram Alpha does is it takes you know the
natural language people the weird natural language people set up as questions and it converts that
into computational language and then it tries to compute answers so there's no you know what one
might think is there's the web out there and there's stuff to search for that's not what we're
doing right what we've what we've tried to do is to sort of collect and curate all of this knowledge
implement the actual algorithms and methods and so on and then compute and the thing that is
sort of the interface to the humans is take that piece of natural language somebody types in
and or says to a phone or whatever else it is and convert that into this precise computational
language and then compute answers so that's that's kind of that's the way I right no and that's fair
but there you used kind of what what we would consider concepts that are familiar to humans the
way we think about the world yes versus today's LLMs are just building building weights now
what happened for the autocomplete but what happened is somehow Chad GPT took off much more
than Wolfram Alpha any any kind of thinking or explanation as to why they're not
but 14 years later the world's a bit different but I think also you know the set of people who want
to write essays is a different set from the set of people who want to answer factual questions
I mean you know Wolfram Alpha pretty widely used an intelligent assistant the thing that's more
interesting is why did the intelligence assistants die just before LLMs happened and that's really
more of a business question than it is a question of a business and execution question more than it
is a question of technology I think but I think the you know what's what's the goal of Wolfram Alpha
has been to to you know to take the question the things that questions that are answerable
from factual questions about the world that are answerable that we can compute answers to
and make it automatic to make those to do those computations and that's been a very successful
thing now the combination of that LLMs are doing something different LLMs are doing things like
writing essays and summarizing text and so on and I think it's worth remembering that you know
LLMs took four billion web pages and you know what an LLM is doing is to give you something
is to continue up from a prompt in a way that is typical of what the LLM read from the web
and that's and now what's interesting is that a certain you know that things like logic were
sort of extracted by the LLMs there's a certain amount of factual information that the LLM sort
of thinks it knows now the LLM will will regularly just make up stuff that's kind of roughly like
what's out there might be like what some student might write as a as a well I'm going to write
something as roughly right but it's actually total nonsense the the combination of the LLMs
with computational system with Wolfram Alpha for example is pretty interesting the challenge is you
know so back in well in last December actually talking to the open AI guys and so on we figured
out yes you know Wolfram Alpha has this is very convenient because there's this interface language
and that interface language is English that both the LLMs understand and Wolfram Alpha understands
and so if you can get the LLM to formulate its question in a way that is sort of a a crisp
question it can just go ask Wolfram Alpha and so we built that capability interestingly we also
built the capability of having the LLM synthesize Wolfram language code because it had read and we
got a big chunk of training data of kind of you know pieces of Wolfram language code it had read
a bunch of Wolfram language code and it was able to synthesize those things so now if you look at
the the plug-in for chat gpt at least as of a few weeks ago I haven't looked more recently
sort of interesting that about half of the what the LLM constructs is Wolfram Alpha queries
and half of it is Wolfram language code and so and then it's running those things and it gives back
the answer and often it does a good job I mean I would say that it's kind of it's kind of terrible
because you know things like math word problems have been a long time kind of interesting AI test
and there's a case where you know you give it this math word problem and the LLM correctly
decodes it into this lovely piece of Wolfram language code we run the code we get an answer
and I was writing something about this a few months ago and I'm about to put this thing in
and I think I better actually check that the LLM you know correctly took the thing from the internal
computation and gave the right answer and it didn't so at the very last stage the thing just you
know went crazy I mean it's interesting you know we've been building an AI tutor for for education
purposes it's an interesting problem the number one thing to know about building AI tutors is
it's not easy yes and and that's them but we've been building this and it's sort of interesting
to see these um this whole interface between sort of the computation this hard computation
and the layer of kind of linguistic interface that exists that you know we think we're able
I don't know we don't know yet but but it looks promising that we're able to actually
provide that interfaces kind of in a personalized way to students and so on but I think I I think
I diverted your question actually you you give a good answer and you anticipated half my next
question I want to switch over to the audience but because you anticipated half my question so using
using the LLM or the chat GPT as kind of an alternative input interface to prompt alpha is
one way to think about them working together is there another way do you think there's a way to
leverage a lot of the knowledge encoded in alpha to help LLMs perform better
well look the the fact that you have a few hundred billion weights that encode three things three
kinds of things kind of the structure of language a certain amount of common sense and the third
thing which is facts about the world facts about the world don't belong there they're an incredibly
inefficient way to encode facts about the world and what will happen but it's not an easy research
problem is to factor out facts about the world from the linguistic interface in the common sense
now you know the fact is that the very interesting thing that's happened is that LLMs have discovered
something that we probably should have discovered a couple thousand years ago which is that human
language has that there's you know we've known about the syntactic structure of human language kind
of the things like you know sentences have noun verb noun in them but what we what we haven't known
is the more sophisticated construction kit that says the sentence you know the moon
eight happiness or something that that sentence isn't a plausibly meaningful sentence except in
some percent of poetic sense and so there's this kind of construction kit that goes beyond the mere
sort of the syntactic grammar of language there's kind of a semantic grammar of language I think
that the LLMs kind of show us exists and so one question is if you say well can we extract that
semantic grammar of language and if we do extract that how much has that actually removed the you
know the LLMs are still useful as a thing to kind of you know right now we say okay well let's go
from LLM you know human language to LLM to computational language but that's further than
going from human language to a semantic grammar to to computational language and so in fact one
thing we've been working on I long wanted to build this kind of what I've called in the past a
semantic discourse language although I hate that name and if somebody can come up with a better one
I'd like it but that it's kind of a there's been sort of this idea that's existed well certainly
since the 1600s since people like Leibniz and so on of making a kind of he used to call it the
characteristic a universalist kind of universal language to represent things in some sort of formal
way I'd been long interested in building such a thing and and now with help from LLMs it's
looking to be actually possible to do that and how that will interface with LLMs what it will
look like in the end my guess is there'll be a layer of kind of neural netty kind of linguistic
user interface going to computation and a semantic language that that then is the place where kind
of the the more where the crunchy computational stuff happens I mean the thing to realize about
LLMs one thing to realize about LLMs is you know back in the day before we had any idea of
formalization what humans figured out was just what they could figure out sort of off the top of
their head then we got these ideas of formalization and we started building these kind of bigger
towers what LLMs are naturally able to do is the same kind of stuff we can do sort of off the top
of our head and that's you know the architecture of an LLM is right now mostly you just say there's
this you know you've you've given a set of tokens that is what you've said so far you say to the
network what should the next token be and it ripples through a few hundred layers of neural
net and out comes the probabilities for what the next token should be and that's that's the whole
story it's just rippling through that that and the only way that it ever gets to do sort of a more
sophisticated computation is is kind of that that the next token it makes depends on all the previous
tokens it made and that's a very thin way I mean there a little bit you can you can kind of a one
fun thing we've been playing with recently it's what you might call quantum LLMs where instead of
just looking at one path of what comes next you look at this whole whole network of what comes
next and you can do things like path finding and that network so you can say I want to get to this
particular thing at the end what is the path that gets me to that thing at the end and you can kind
of think about that in a slightly different way but but fundamentally that they're just dealing with
kind of they're these different things there's this invention of computation last last hundred
years few hundred years which is this kind of different prong that we can build that is that's
different from what sort of ordinary human thinking let's one do so any questions from the audience
let's start with you thank you for the very interesting talk um my question is about the um
the part of your talk that had to do with deriving simple computational rules to explain
essentially all the physics um so I guess my my question has to do with the fact that um
you know we have these I guess you call them math right physical principles things like
Schrodinger's equation and things like this that uh or you know quantum mechanics they allow us to
make predictions about outcomes of experiments or you know the procession of a planet or something
like this you know it allows us to make useful predictions about the world and if we have a
computational set of rules that allow us to explain all of physics is there some way to go from
those computational rules to mathematical principles or other sorts of principles that allow us to make
useful predictions about the world that don't require running the computation um and and how
does that clash with this notion of computational irreducibility that you mentioned good question
okay so slightly complicated I mean so so first thing to say is sort of the main way that we
validate that we know what we're talking about is that we can derive the existing mathematical
laws if it wasn't for the fact that we could derive general relativity we wouldn't imagine
that we have a good idea of what the sort of low-level machine code of space time is okay so
the first thing to say second thing is there are for example that black hole simulation that I showed
actually is it's the method of going from this underlying discrete space time to deduce what
happens seems to be at best competitive with and possibly much better than what people have done
in the past which is to start from the mathematical equations and then kind of discretize them so
that they can put them on a computer this is a you can think about it as a sort of an alternative
way to by simulation figure out what's going to happen in the world and because in fact when you
do it sort of mathematically people when people work out black hole mergers they don't work out
the pure algebraic math I mean they typically use Mathematica to do a big pile of reduction
of the original mathematical structure and then they turn it into something which is a bunch of
partial differential equations which they discretize and run on a computer so this is this is kind of
going the other way so that's that's one thing to say the the next thing is that the okay the
remarkable thing about the universe is that anything in it is predictable what you might think is
given computational irreducibility the whole universe is going to be unpredictable one thing
about computational irreducibility is whenever there's computational irreducibility there is
always there are an always an infinite number of slices of computational reducibility that exists
so in other words when the whole thing is computationally irreducible you can always find
some sub piece that is computationally reducible and it's those sub pieces that make up the laws
that we find useful to be narratives about how the world works and that we kind of exist in
and so the really the story of what's happened with our physics project is there's underlying
computational irreducibility and for observers like us we pick out certain slices of computational
reducibility those slices of computational reducibility correspond to the physical laws
we know so one interesting question would be will there be a time when we found all physical
laws or when we've made all inventions we figured out all of technology the answer is no and the
reason for that is because of computational irreducibility that we found a particular slice
but there will be an infinite number of other slices and these are other views of the world
other things we can say about the world that aren't that that are different from what we've said so
far and in fact you can think of technology as being these little places where there's this whole
amount of computational irreducibility but there's this little place where we discovered this thing
where we could jump ahead this little little piece of reducibility and that's sort of a piece of
technology in a sense that's kind of the the economic value that we're providing it's kind of
like you could take all the components of an iPhone and they would have a certain value where you
can put them all together into this iPhone and you've got this thing that you can think of as sort
of a little piece of computational reducibility that that provides value economic or or sort of
the ability to kind of do something we wouldn't otherwise be able to do so so the thing to
realize is there's this sort of infinite set of possible laws to discover there's a and that's
some uh that's the big question is which things do we humans care about there's an infinite set
of things out there that could be discovered as an infinite set of kind of things we can deduce
about the world some of them we find useful we turn into technology and so on and some we just
sort of shrug our shoulders and say we don't know what we're going to do with that like fluid
turbulence is a good example of that for some purposes at least it's like the fluid behaves
randomly what do we do with this it's not um uh so i mean in in terms of our um so i mean i think
our models provide some kind of almost philosophical framework for thinking about this kind of uh
this kind of interplay between computational reducibility computational irreducibility
the challenge right now with our models is there are things where they reproduce existing physics
and there are places where they don't there are places where maybe there's a little corner
where you see something that isn't existing physics and that's obviously really interesting
because you can do experiments and find out if that's really true or not and uh that's that's it's
it's a big it's it's a challenge because it's just a lot of technical detail of figuring out okay a
photon is propagating through a piece of fractional dimensional space what does that actually do how
does it affect this or that thing that you can measure but that's you know that's the challenge and
and um uh you know i think the um uh as i say the the the way to compute things that we have here
it's a bit different from the existing way so for example in this case with general relativity
we're able to actually do a bit better than existing methods same with quantum circuit
optimization actually there's uh uh using our multi-way system technology uh somebody who's been
working on our project sort of takes quantum circuits compiles them into multi-way systems
does optimization at that level and then turns them back into traditional quantum circuits
and that won a competition a few months ago for the best sort of quantum circuit optimization
which was kind of fun we actually usama have a bunch of questions coming in from our virtual
attendees so i will we'll alternate okay so uh let me and and what you said basically i mean
an interesting observation you made which is how interesting is that universe of
computationally reducible things and how far can we get but my question is let's get a bit more
pedantic a bit so before sam altman had his uh misfortunate incident with his board
open ai was talking about a very near term big breakthrough in ai whether that's truth or rumor
or whatever it doesn't matter i would like to ask you do you think there's an interesting kind of
breakthrough class thing that could happen in the near term for ai at least in your intuition
well i mean okay so look at the history of the hi okay so we've got you know mccullocham pits
wrote that paper in 1943 you know now we've got chat gbt it's actually pretty similar in architecture
to what mccullocham pit i was just looking at the mcculloch pit's paper uh just a couple of days
ago it's that they had this idea of what they called psychons they didn't make it but uh a lot
else in that paper did make it um the uh psychons were units of psychological activity basically
um the uh in any case the the you know i i personally have been a little bit
involved in this business since probably about 1980 i first sort of tried to make neural nets do
something around 1980 and i couldn't get them to do anything very interesting so and then
you know in this you know a neural nets were always kind of a sideshow type thing oh there
might be models of brains we don't really know maybe brains don't work that way you know a neural
net's useful as algorithms well they've been used for ocr but you know not clear how useful
they are for other things they were always sort of a mysterious kind of sideshow type type thing
and then 2011 kind of the uh the sort of deep learning breakthrough and image recognition
happened almost by accident and there was this jump in the ability to recognize not just the
letters of the alphabet but also a few thousand other kinds of things in the world of cats and dogs
and things like this and you know if you look at that time i think it reached like 85 success
from that particular sort of jump in in capability in the in the years since then there's been sort
of gradual incremental sort of improvement in object recognition using neural nets you know
the big breakthrough happened and then there's gradual improvement same things happen in a
bunch of other areas whether it's speech to text um other kinds of things the big breakthrough with
LLM's that nobody expected um was that one went from language models to just babbled rather
uninterestingly to language models that made essays that seemed human like and that was a um you
know it's a big big breakthrough and i think we still don't understand why that really happened
how that happened um and uh you know it probably well it can speculate on on it's a science question
it's a very interesting science question we've studied it a bit i can tell you a few i think
this field of LLM science is a really important area it should be more populated by physicists
actually because that's the that's the domain that has a lot of the the kind of relevant expertise
i mean you know i've been i've been pointing out for a while you know there's like you increase
the temperature you know the the chance that you pick a word that isn't the the most most
highest probability word to come next increase the temperature it looks like some student at
our summer school this last year found there are two distinct phase transitions one where the LLM
increase the temperature the LLM stops making sense second it stops making syntactic sentences
the two distinct transitions at definite temperatures why does that happen there's
got to be an answer to that and it has some combination of physics question and a question
about kind of the structure of knowledge and the structure of the way we think about things it's a
it's a it's a thing that's out there and sort of LLM science but anyway what seems to have happened
is there are these moments where there these kind of you know rapid you know these breakthroughs
where things things change and then it's kind of an incremental process and this is typical of
technology and science you know some methodology is you know is comes in some something happens
the way i see what's what's happened right now with LLMs the you know they have created the
possibility of having rich linguistic interfaces to things and there are many applications for that
and the question of what will be successful and what will not has to do with how you put a harness
around that capability because it's like saying you know it's it's um uh the the you know the
raw capability kind of i think is what it is it will get incrementally better but it is what it
is it's like a lot of things in machine learning people say oh i'm going to use machine learning
for this or that there's a very simple heuristic machine learning is going to get you 80% maybe
it's 90% maybe it's 93% you know in Wolfmalfa we've now got to 98% success and in recognizing
our you know natural language understanding but you know it's some percentage and some
perfection of the time is going to fail if you've got a use case where getting 85 success is a win
like you're saying here are possible search results are any of these what you're interested in
then it's a win to have 85 success if you're trying to you know launch a rocket to the moon and it's
got to actually go in the right trajectory 85 success is probably not going to be good enough
and so it's a bad use case and this is the kind of interplay between what's sort of computational
and what's sort of LLM AI style and i think in terms of sort of the breakthroughs that will
happen i mean i think you know there is more to be done this kind of quantum LLM thing there's
more to be done with kind of where you can where you can go you know that the planning aspects of
sort of interfacing what amounts to sort of theorem proving techniques with kind of LLM
techniques i'm not sure how well that's going to work the you know one of the lessons of kind
of the developments of neural nets particularly has been anytime you think you can be clever
turns out you it's not worthwhile and and that's a it goes along with what i've found in the
computational universe you say oh i know i've got this particular kind of system i know it can't
do anything interesting i can just foresee it can't do anything interesting you run the experiment
my little statement to myself and people who work with me is you know the computational
animals are always smarter than we are we you always it will do something that is completely
unexpected and and that's been so you know i'm not sure whether sort of you know carefully
orchestrating these things is ultimately going to make a difference as a practical matter you know
video uh you know what we've done with text will be doable with video you can learn a lot
on video there's a large corpus of video there'll be a bunch of there'll be a breakthrough as you
know it manages to learn sort of intuitive physics from videos and things like this certain amount
of human behavior stuff from videos probably um and that will be you know that's another thing
and and that's but i think what you'll see is these set of discrete sort of jumps as as different
things become possible and and you know the training data in the world is is you know we're
kind of running out of that um there's i mean there's a there's about a hundred billion not
yet tapped actually we're involved in an in possibility of tapping some more of that of
other kinds of uh material that exists in textual form that hasn't yet been used for training i don't
know how useful that will be i don't know at what point you saturate in terms of yes we know human
language and yes we know common sense but my my feeling is that the big value is coming in the
application of uh of LLMs and so on and figuring out how you put the right harness around them to
make them useful and and that's um and it's kind of in fact the the kind of you know we've built
into our language now a bunch of LLM functions where you can from the computational language
you can access the LLM and that's a pretty useful way to sort of understand and and set up kind of
the harness around the LLM to make the LLM do what it does well and then sort of the the computational
structure go around that cool shall we take a question from online sure so a few a couple
hundred people are still here with you till the very end um i'm going to take a question from
michael karell what's so great about computation as a metaphor structuring principle for physics
or cognition we've been wrong about metaphors for cognition in the past parentheses the brain as
watch telegraph switchboard or even metaphors within computational views what makes us think
we've gotten the right one this time okay so it's a good question i mean i think that the the
thing that's interesting is that this idea of rules for specifying things that idea is pretty
much as old as civilization and it's you know the question of well is it this particular kind of
rule is it the rule that runs with you know that makes a watch work is it the rule that wakes
you know integrals work and so on those particulars yes those particulars are are specific possibilities
the general idea that something follows some set of rules seems to be a you know a pretty
fundamental idea i mean we're we're kind of stuck with that idea that's a that's a thing
if we want to have a theory about how the world works then the idea that there are rules that
determine what happens is something that we're pretty much stuck with but i think it's a it's a
good uh you know did we did we finally make it well you know if it turns out the experiments get
done and this theory of physics that we built is validated um it's you know frankly it it
seems at this point to me at least quite impossible that it could not be true because too much has
fit together for it to you know for it to be off track but if that happens then we can say well we
reached you know in some direction we reached the end we know our universe is set up this way we
can know that we can so another thing to explain whenever what is natural science you know natural
science is this bridge between the universe as it is and our attempt to have a narrative in
our minds for how the universe works so in other words the universe does what it does
and the question is can we have a way of thinking about that that we can understand and so there
may be many ways of thinking about it that that that is more on us than it is on the universe
there may be many ways that aliens could understand the universe that are not the ways we understand
the universe but i think that this idea of operating according to rules is this thing that
has been you know a feature of the way we have thought about things from the beginning of our
of our history and that that seems like a pretty solid thing if we're trying to do this thing
abridging between the universe and and the way that um the way that we think about things i want
to say one thing about cognition and LLMs okay so so people had wondered for a long time how do
brains work and people said well brains do things that are so sophisticated that even laws of physics
as we know them aren't sufficient to cover what brains do there must be some funky extra stuff
quantum mechanics whatever else that's going on in brains LLMs are a very good data point
that isn't true because people had said you know in order to do all these things that we do in all
the language and everything like this we got to have all kinds of stuff we don't understand
turns out just this neural net this simple rule-based neural net it pretty much does it and so you
can and in fact what's happened in neuroscience for instance is back in the day my my friends in
neuroscience always said well we got these neural nets but they're not really models of brains
they're really some idealization that may be useful for technology etc etc etc now that neural
nets clearly do things that are very brain-like that that that narrative has reversed and now it's
a question of well you know we've got we know what the core mechanisms are now let's see how we map
those into what we can see biologically is your question quick all right so I don't know if you
have a mic but you can I'll repeat your question just stated for example if we want to learn new
interesting structures how can we use AI to discover them without you know doing simulation
and then looking for patterns in those can we actually use it to find yeah that's a good question
right so the question is using AI go ahead yeah you know can AI solve science this is a this is a
very current question and that's not a short question but anyway actually we have a project
right now that is you know day by day is is making progress on this question so here's
here's what we seem to be finding not not this this thing hasn't fully landed yet so I don't
know the full story but so a question is what can you predict with another lamp what can another
lamp predict I show it pictures of cellular automata things like this can it you know can
it just say this is what's going to happen can it to what extent can it at least find the pockets
of reducibility we don't know fully the answer to this but there's clearly a boundary we can see
there are cases where it just doesn't work and there are cases where it definitely does work
and so the you know this question of can it notice patterns that we haven't noticed so in protein
folding for example there's been a fair degree of success a little bit less success perhaps
than people sometimes imagine but there's been some success in taking I mean when you if you
feed a random sequence of amino acids and say how does this fold the answer probably won't be right
but in things that are at least somewhat close to proteins that have already been
whose structure is already known there's there's a lot that can be said and the question is why
does that work and the general belief is that it works because there are aspects of protein structure
which are features that we humans have not noticed that the that the system noticed okay and and so
this idea that it's noticing things that we didn't notice is is going to be a very common thing I
mean even even an image identifier that's telling cats from dogs how does it tell cats from dogs
well it's found some feature of those pictures maybe it's the pointiness of the ears or something
it's found some feature that allows it to make that distinction we don't you know that's not
necessarily a feature that we know about it's also very hard for us to tell what feature it found
because we don't have a way to kind of go inside its mind and convert its way of thinking about
things to our ways of thinking about things so you know in terms of of what can we learn about
science so first question is can the LLM when there is some sort of feature that allows prediction
to happen can the LLM find that and be able to make predictions my guess is that that will be
generally somewhat successful but I think computational irreducibility is kind of a big
sort of you know it's a big monster at the gates there that will prevent certain kinds of things
from from being possible but some things where a human could go and find these these rules yes
the LLM might be able to do that more efficiently more automatically first point so second point is
in well another point is can the LLM invent something that is a way of explaining to us humans
how something works that's essentially the problem of the AI tutor can the can the system learn enough
about us humans that it can give us an explanation that is useful for us as humans and my guess is
there'll be some success in that in other words if I want to learn some new thing you know how
difficult is it to learn something well you know if I had an AI that knows everything I know for me
personally I happen to be a enthusiast of personal data so there's 50 million words
that I've said or written that are out there so I can train an LLM to be a pretty good you know
simulation of me and given that what you know if I then if I know if the LLM knows or the AI
knows what I know and then I say well I'm today I'm trying to learn about macroeconomics you know
I want to you know how do I understand this there's a reasonable chance that the LLM is going to say
well you can relate that to this thing you know and that thing you know and I have a much easier path
to be able to learn those things it's another thing another thing to say about about what
LLM's potentially do one of the interesting things that LLM's do is they essentially do
what one might call sort of a generalization of statistics that relates to text so normally you
know you have a bunch of numbers you say what's the mean what's the variance of these numbers
these kinds of numerical sorts of things but if you've just got a big lump of text and you say
what was the most popular hat style in the 1950s that's a textual question and that's a question
where there's not you know turning that into numbers is not so easy but LLM's can actually go
purely at the textual level and answer a question like that and so there's this pure sort of textual
statistics you might call it it's not really statistics in the ordinary sense of numbers
it's some new kind of thing that can be sort of deduced textually and I think the the other
one thing that will happen is there are these you know one way that science advances is through
these kind of analogies between one field and another to notice that oh what happens in meta
mathematics is like what happens in general activity well that's something that you know I'm
very proud of being able to notice that as a human because I know something about those two
fields and I can kind of connect them up but I suspect LLM's are going to be able to figure
those kinds of things out too because they're going to be able to see that the structure just
like they can they can kind of extract logic from just the patterns of sentences so they'll
extract principles from from kind of the noticing that these two different areas work the way they
work but I mean this question of can the LLM invent a formalism that is useful for us humans
that's a that's an interesting good question I'll tell you one little micro data point so you know
I spend a lot of my life doing computational language design and you know we quite often
livestream these things and so on but one of the things that's new in the version of
Wolfman language is just about to come out is there are new functions that are in there
that were suggested by an LLM so in other words the LLM has looked at all this code it knows what
people are asking about it's seen what's out there on the web it said oh there's a function you
should have a function called digit sum and I think it even suggested that name and it's a pretty good
idea it's taken sort of the average of what people out there want and yes you can you can digit
sum is something that's a trivial kind of idiom and more from language but it's noticed that that's
an idiom that's a repeated idiom and that's kind of the essence of language design and so we're able
to take that suggestion from LLM by the way in terms of how LLM's will be used I think compiling
the wisdom of the crowds basically yes yes and to I mean one thing to say about how LLM's will be
used I have a feeling one of the big uses of LLM's will be offline uses people a lot of constant
people are concentrating on I've got an LLM in the loop and I'm typing something and an LLM is
responding to that for example for our purposes when we do data curation LLM's have basically
speeded up many parts of our data curation pipeline by a matter of fact of two not a hundred
but two and two is worth having but it's not um but I think that these these offline uses where
you use the wisdom of the LLM and then you burn it into a piece of technology that's going to
be a an important thing given given that we'll well over time and before we I'm very bad at
short answers I apologize I'll ask you one last question given your amazing optimism about the
capabilities of LLM's now and you alluded to some of this in your talk many have claimed that AI
poses a future existential threat to humanity others disagree vehemently uh what's your view on
this and what do you think are kind of the main AI threats of today but let's let's talk about the
existential right I mean okay so you know more and more things in the world will be delegated to
AIs that's just just as a matter of convenience because things have to happen quickly you know
it's we're going to delegate stuff to AIs and then the question is okay so you know does something
terrible happen as a result of that the thing to understand is there's all this stuff going on in
the in the world of the AIs and the kind of underworld of the AIs the world is being run by
AIs let's say and we say well we don't understand what these AIs are doing that's terrible how can
we possibly exist in a situation where the world is being run by forces we don't understand
actually we've been there before because that's the situation we're in with nature
nature is doing a lot of stuff we don't understand and we have managed to find ways to exist we find
found niches where we can sort of carve out our existence you know within nature and it works just
fine I mean occasionally bad things happen you know hurricanes develop and bad things happen
and we don't understand quite why those happen and you know we gradually maybe can do a science of
you know the atmosphere or something and figure that out with AIs the same is going to happen
there's going to be lots of stuff that goes on and mostly it's going to be just fine and we understand
how to live in that niche and occasionally some crazy thing will happen and we'll say we better
build more science that allows us to understand sort of what's happening in the underworld of the
AIs so to speak so the first thing to say another thing to say is well is there going to be anything
anything left for the humans to do or we have automated everything it's by definition we will
not automate everything because a lot of what has to be done is to figure out what we want to do
and there is no sort of intrinsic way that the AI does that now there's a practical matter I looked
at the last 150 years or so of what people have done as occupations so to speak and here's what you
see in you know in the 150 years ago agriculture was the biggest chunk of of sort of U.S. occupations
and then it got automated and so that chunk shrunk and you see the same thing happening over and
what happened to that chunk what happened to those people well the answer is they went into
lots of different occupations many of which were enabled by the automation of agriculture
and the same thing has happened over and over again that's something that takes a lot of people
to do it it ends up getting automated that thing goes to almost zero people but those that the very
automation of that thing enables a bunch of new capabilities which then provide a more fragmented
kind of story and it's a pretty common thing you see in economies around the world more developed
economies are more fragmented in terms of the occupations people do and that's that seems to be
you know as as you automate more you and what's really happening there what's really happening
there is the fragmented occupations are sort of the frontiers where it's still like what are we
going to do in this area and that's something that takes humans and it's just like you know right now
it's kind of fun to see the new occupations I'm always I you know at a company I I often I'm
entertained by the fact that I'll invent some new job category of a thing that people have never heard
of before like LLM scientist or or you know AI psychologist or you know engineer or prompt
magician yes yes right exactly and these are things that you know it's gosh those have never been and
by the way prompt engineering is a great use for the you know people say well you're going to be
computer programmer you're going to do stem type stuff the best prompt engineers are the best
expository writers so it's a different skill set that and that happens because the LLMs were trained
on you know the LLMs understand just like other humans understand and so it's sort of not surprising
that it's expository writing that turns out to be the important skill there so by the way the combination
of expository writing and computation is writing good computational language that that in itself is
another occupational area is is computation editors so to speak who can turn bad computational
language into good computational language and so on there are there are just these many different
opportunities that that get opened up so I'm you know I think us humans you know it's worth
realizing if you look at the sort of long arc of history and you say what do people do a thousand
years ago what do we do what do people even think was worth doing a thousand years ago
and then what do we do now many of the things we do today didn't look like they were worth doing a
thousand years ago I mean you know I walk on a treadmill why do you do that it's you know what
a crazy thing to do it's it so you know I think that's what we'll see and one of the things that's
funny about understanding history in the future and so on is that you might say oh you know everybody's
just going to be playing video games that's a terrible outcome looks to be a terrible outcome to me
right now from from my viewpoint and you know the you know in 2023 or whatever but it's you know to
the internal impression of the humans so to speak may be a very different story in terms of
of you know what will happen in terms of of sort of when the ai's run central banks when the ai's
do all these kinds of things and and many of those things will happen and and at a practical level
there's a question of what can you do with this how can we make the ai's do things we want to have
them do and not do the things we don't want to have them do so first question is well what do we
want to have them do and so you know I've thought a bit I will say this is a for me it's it's an
unfinished question I mean this first question is okay you're making constitution for the world
for a country let's say hopefully not for the whole world hopefully for individual countries
you're making constitution in modern times you've got ai's what do you what are the provisions for
example can an ai own things does an ai have to have an owner you know how do you decide what to
do do you have a democracy where people vote and and check boxes or do you have a prompt
autocracy where everybody writes you know a prompt and it gets fed into an ai and the ai
kind of decides what to do what do you do how do you think about what's possible and the first
question is what you know is there a you know what do people want and the answer is obviously not
everybody's going to want the same thing and that's you know so the idea that you know there's the
global view this is this is a very bad idea I mean this is you know this is you know this this won't
work just as you know it hasn't it just not a not a thing that works in the way that humans who
believe in free will and things like that set the world up but so so first point is I think
that you know I've thought quite a bit about this kind of ai constitution question and what
sorts of provisions you might imagine in wanting to set up it's not easy to understand how those
constraints get applied etc etc etc and certainly there's not going to be one kind of this is the
constitution of the world we're finished type thing um but even figuring out those provisions
is surprisingly hard and and I've I've you know it's surprisingly little has been done on this
second thing the thing that I've now come to think more about because I think it's it's a
more promising direction is if one ai if there's just one ai in the world I think it's a very brittle
situation the reality is there's not going to be one ai in the world there's going to be a whole
society of ai's and the society of ai's will operate in some way that probably has many of
the same dynamics as human society and the society there will be some inexorable features of the ai
society just as presumably there are inexorable features of human society and economics and
things like this so there's a science question about what are those inexorable features what
does the society of the ai's look like and how do we you know are there dynamics for the society
of ai's let me give you one example it's unthought out okay so but let me make a
meta comment the meta comment is if you look at the history of things like governance and democracy
and so on you know big things happened a few hundred years ago that was a time when there was a lot
of political philosophy was being thought about and people figured stuff out in political philosophy
and that turned into actual governance systems that have been reasonably successful over the last
few hundred years and you know now is the moment this is the great moment for political philosophy
again it's you know and I don't know that there are very many people who've stepped up to figuring
this out but there will be ideas that will be and they it won't be promptocracies probably
but it'll be something and there'll be ideas that are different new ideas enabled by the fact that
we live in an ai technological society so to speak that that become possible I'll give you
one example of a kind of thinking and we will end on that example okay fine but maybe this is a
this is maybe not an upper okay so here's the question question is in human society people
sort of to some sense do the right thing because if they don't do the right thing they suffer
for ai's that's a more complicated issue because so far as we know ai's don't suffer
so how do you get an ai to do the right thing if it won't suffer by doing the wrong thing
and and so but now what you realize is actually you already have this issue with humans because
you know internally to you how you feel but anything else is an extrapolation it's just
you're guessing that you have empathy for some other thing so okay so you can you start thinking
about the ai's and what is the operational again I'd say I haven't figured this out but I just I
give this as an example of the type of thinking like everyone has to do is is you know if there's
an ai and it did the wrong thing and it is then removed from ai society okay whether the ai
internally suffered or not who cares because what matters to the world is that it was removed from
ai society so to speak and so what you realize is that that this kind of the societal you know
is there a dynamics of that society that causes the ai that did the wrong thing to not be trusted
by the other ai's etc etc etc that be to be sort of removed from ai society having no kind of
imagined not imagining that you're you know the ai itself is making this you know making this decision
it's as I say not properly thought out but that's just as a people are interested in philosophy of
these things that's just sort of a you know the beginnings of a thought about how to think through
you know sort of responsibility personal responsibility in the time of ai
interesting okay with that please join me in thanking steven for this extra long edition
of our distinguished lecture thank you thank you everyone and see you next semester with the
distinguished lecture series
