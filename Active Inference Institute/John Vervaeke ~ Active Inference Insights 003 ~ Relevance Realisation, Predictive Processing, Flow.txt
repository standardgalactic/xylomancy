Okay, and we're away. Welcome, everybody, to the third episode of Active Inference Insights,
brought to you by the Active Inference Institute. I'm your host, Darius Parvizi-Wayne, and today
I am absolutely thrilled to be able to speak to John Viveke. John is an award-winning professor
of psychology, cognitive science, and Buddhist philosophy at the University of Toronto. He
is also the presenter of the renowned YouTube series Awakening from the Meaning Crisis, as
well as the newer After Socrates. His work focuses on 4e cognitive science, which holds
that cognition is embodied, embedded, enacted, and extended beyond the brain. In particular,
John explores relevance realization, our adaptive ability to zero in on salient information
in a world of near-infinite complexity. Last year, he, Mark Miller, and Brett Anderson
wrote the paper Predictive Processing and Relevance Realization, Exploring Convergent
Solutions to the Frame Problem, which proposes that trade-offs in precision waiting, a key
second order dynamic in predictive processing hierarchies, are at the heart of our ability
to be intelligently ignorant. And that alignment of predictive processing and relevance realization
is exactly what we're going to be talking about today. John, welcome to the show. Thank
you so much for joining us. It's an absolute treat.
Thank you. There is a great pleasure. I'm hoping that Mark does make it on in December.
That'll be great. Yeah, absolutely. But in his absence, because Mark was meant to be
here today, but it's unfortunate, he's not unfortunately able to make it. Perhaps, so
this podcast is acting as a kind of primer and introduction for our audience to the critical
themes in cognitive science and psychology and biology, as well as maths and physics,
as they are right now. So I think it would be a worthwhile place to start if you could
just unpick what relevance realization is, and then we'll come to how it aligns with
predictive processing. Sure. So relevance realization is sort of
inverts the way common sense works. Common sense is there's a lot that is obvious to
us, and you know what it's obvious what you should pay attention to. We're sometimes mistaken,
but it's obvious what we should be remembering and what we should be doing. And that's all
obvious and we just run from that. Our job as cognitive scientists is to explain how
the brain generates that obviousness that salience landscapes that makes the right things stand
out as relevant to us so that we can do what is astonishing solve a wide variety of problems
and a wide variety of domains. You're a general problem solver, which is just astonishing.
I mean, you can learn Albanian history, you could learn about swimming or rock climbing,
you can take up the study of dinosaurs in the Jurassic period, like it's just, you know,
it's just amazing and astonishing. And there is good empirical evidence you have something
like a general intelligence. There seems to be a general capacity. There's individual
variation and talent. Some people are better at learning this domain than other domains.
But they're way back from Spearman. We know there's some sort of general ability. I'm
going to propose that the general ability are two interlocking things, the anticipation
and relevance realization. What I mean by a general ability is these are kind of meta
problems. These are the two big problems you have to solve when you're doing any other
specific problem solving. And what makes relevance realization so hard, generating that obviousness
so mysterious, actually. That's what Scott Attrin says. He says that what science does
is it makes what's common sense to take, takes to be obvious, mysterious. Here's a table
in front of me, but physics says, well, what is that really? And they're mysterious and
it's made out of quarks and all this sort of stuff. It's the same sort of thing here.
When you think about it outside of common sense, you realize that there's just an overwhelming
amount of information that's constantly, as you said, dynamically changing in the environment.
There's an overwhelming amount of information in your long-term memory that's constantly
changing and being readjusted to the reconstructive nature of memory. There is an overwhelming
number of combinations of actions you can perform, sequences of action. And yet you ignore that
overwhelming, almost all of that overwhelming information and zero in on the relevant information
so that you are oriented right in the world, finding things obvious, salient, standing out,
and it's not just a single thing. There's like a salient's landscape. Some things stand out
more than others. Some things are more foreground, background. You have all this happening so that
you are capable of solving so many problems in a messy, complex world in which there's
constant novelty because of an emergent phenomena. And trying to give this ability to machines has
been overwhelmingly difficult and one of the hard, hard problems. We're actually bumping up right
into it now as we've finally taken up the AGI project, the project of trying to create artificial
intelligence. Excellent. It may be worth digging a little bit deeper into that exposition
because people might be thinking, well, don't we just have a module for relevance or salience?
Don't we just kind of, we're born and we know, oh, I should not fall off cliffs and I should,
but actually what happened yesterday might be quite irrelevant. You have a wonderful
explanation in your sort of keynote paper, Explicating Relevance Realization, where you say
that leads to an infinite regress. Perhaps you could explain that argument.
So the magic module, not to be confused with predictive processing's reported problem of
the magic modulators. So let's keep those two distinct from each other. But the magic module
is, well, I have a relevance realization thing in my head that just does it. And then I can just
say, well, how does it do it? And the mistake people can make is, well, evolution made it. And
that's right. Evolution tells me how it got here. That's not telling me how it functions.
Evolution tells me how my eye got here and how my ear got here. And that's not telling me how
my eye and my ear function. I'm trying to take what's called the design stance. How could,
tell me what I need to do to give that module the ability to realize relevance. All you've
done is said it has that ability. But it faces the problem of, okay, now it has to know what to
pay attention to, and so on and so forth. Now what you might say is, well, evolution totally
prepared us for it. The problem with that is that doesn't work. Evolution can only pick up on things
that are long-term invariant and that make an ongoing continuous difference to your reproductive
status. And that's not how relevance works. Relevance is really fast and changing. If I say
left big toe, it suddenly becomes relevant to you and it wasn't relevant a minute ago. And what's
the Darwinian difference there? And there's nothing that's intrinsically relevant. Well, my own life
is intrinsically relevant. Is it? You'll sacrifice your life for your kids. Well, my life and my kids
were under all circumstances. You know, what if, you know, saving your kid means that 10 million
people. Oh, well, and so on. And we get into all these philosophical arguments because we realize,
no, no, there isn't any hard, fast thing that is always relevant. Relevance is not something
for which we can generate a scientific theory. It's not stable. It's not intrinsic to the phenomena.
And there's nothing, other than being relevant, there's nothing that all the events or objects
or feelings have in common. Like, what is it that, what do they all have that makes them,
other than saying, well, they're, you'll give me synonyms, they're important to me,
or they help me solve my problems? Yes, that's exactly it. But how? But how? Exactly. Perfect.
And it's, it's so nice to see how the apparently disparate strands of cognitive science, so
Gibsonian affordances for a cognitive science, predict a processing and processing an act of
inference, align at this path, which is that everything is dynamical. Everything is about
this mutual unfolding. There is no reified static existence. It's what's relevant to you might not
be relevant to me. And there are these dynamic relationships, which govern that. It's, yeah,
so that's, that's a, that's a great place to start. I think, let's now go into the solution,
if there is such such a solution. And let's start with opponent processing. So this is a term that
you use frequently. And to a layman audience, it's not clear exactly what it means. So what
what is opponent processing? And how does it help shed light on this complex problem?
Sure. And maybe along the way, I can point out how relevance realization really gives some specific
teeth to claims of embodiment from for ecog side, because I like the point you made. And
maybe we don't have to do it right now, but I'd like to come back to it how relevance realization
is kind of a glue, the glues together, predictive processing, and for ecog side in powerful way
and makes them all, including itself, mutually stronger from that integration. But yeah, the
opponent process. And so let's just note something at many different levels of analysis in your
biology, you will find opponent processing at work. I'll take one that's very easy to explain,
and people have a ready experience of it. So we are all constantly, mostly unconsciously,
although it's affected by conscious factors, we're constantly recalibrating and adjusting
dare I say it, we're even evolving our level of metabolic arousal. I don't mean just sexual
arousal, don't be Freud here. I mean arousal how much how much how much how sort of activated are
you how sort of energized are you. And the problem is there isn't there isn't some state
in homeostatic state you're looking for with that, because if there's a tiger in the room,
I need to go to maximal right arousal. And if I'm going to sleep, I need to go to minimal
arousal. And I can't just be sort of Canadian and keep sort of average arousal at all times,
because then I don't fall asleep and I get killed by tigers. And so it constantly has to be
like we're talking about has to constantly be adjusting. So what what has evolved in your
biology is your autonomic meaning self governing, it's a self organizing system. Like you said,
it's a dynamical entity, your autonomic nervous system. And what it does is it couples together
two subsystems that are have opposite biases from each other. So your sympathetic system is
biased to speak anthropomorphically just because it speeds things up. Your sympathetic system is
biased to seeing as much of it can of the world as threat or opportunity and arousing you as much as
it can. And your parasympathetic system is biased the opposite way it's biased to seeing as much of
the world as secure safe, a place where you can rest and recover. And then these subsystems are
not independent from each other, they're locked together. And they're they're also they're continually
trying to shut each other off. And they're constantly competing that way. But they're
cooperatively competing. It's not adversarial. They're cooperatively competing. And what happens
is that constant trade off between those process between those processes constantly right in very
dynamic manner constantly recalibrate to your level of arousal to the world. And that's opponent
processing. And what you find is you got that, you know, there's other is opponent processing
between your focal vision and your peripheral vision. There's opponent processing plausibly
between your left and right hemispheres. The number of these things, right,
is huge. And I say at many different levels of analysis. And so I think opponent processing
is a clue to how relevance realization is actually undertaken by your embodied cognition.
Wonderful. And immediately to anyone interested in active inference, or its manifestation in
continuous state spaces as predictive processing, or what will be screaming out is this notion of
an attractor set or our homeostatic equilibrium, which Karl has spoken about a length, obviously,
and as has many other researchers. But this idea that what this we are, we suffer, but we also
embody in a kind of positive way this itinerancy, we never we're never stuck in a single
mode. We, we are endowed with the capacity to go beyond our homeostasis and return back to it,
but we're always, in a sense, being drawn without ever residing without ever having stopped
at that homeostatic set point. So let's now fold in active inference to the picture.
What does it provide relevance realization? And the formulation of relevance realization
that couldn't be done purely with four e cognitive science. So, I mean, I'm going to talk about it
in terms of predictive processing, because that's the one that's the formulation of it that
lines up most cleanly with the theoretical integration. As you said, there's there's
clear derivation relations between active inference and predictive processing, and also between them
and the Bayesian math, but the Bayesian math, if you were to actually strictly apply it would be
computationally intractable. So we're doing some approximation function. So I'm just going to take
it that everybody sort of shall knows that I'm playing fair with this, right? I'm not, I'm not
trying to be dodgy. And so relevance realization is grounded in the idea of problem solving.
And problem solving actually assumed a fundamental thing, which again is so obvious to us, which is
the state you're in and the state you want to be in are not the same state. That's the defining
feature of a problem. If I'm in a state I want to be in, I want to be sitting in this chair. I am.
I don't have a problem, right? And now what that means is you're all you're immediately into something
very interesting. The organism is trying to actually predict a possible state in the world
and prepare itself alter. So it's an agent. It doesn't just behave. It alters its behavior to
alter the states in the world, right? And so it is trying to, I would say, predictively
prepare for the world. It's trying to predict the world, but prepare itself for that world,
but also prepare the world so it's more likely to come out in the prediction that it seeks,
right? And so I put those two together and I talk about anticipation. And so whenever you're
problem solving, you're anticipating a goal, meaning that prediction and preparation. Now,
40 cog site doesn't directly talk about that as as clear as it needs to. It talks about coupling
and it talks about affordances. And I think there's a deep connection between a point of
processing, optimal gripping and affordances. And maybe we can explore that at some point.
But typically one of the things where 40 cog site has some challenges is in more distal relations
to the environment, because it tends to rely primarily on coupling. And this is a long-standing
critique that one of my colleagues, Brian Cantwell Smith, at the University of Toronto,
because that is where all knowledge is flowing from, right? Has made. He said, you can be
predictively coupled to things that you're in direct causal contact with, but dynamically
coupled, not predictively coupled, my apologies. But how do you do things that are much more distal?
And for me, that is key. And here's why I do this. I think when we evaluate, even intuitively,
so I'm not using that as an authority and just showing how readily this works for us,
when we evaluate an organism for its intelligence, we tend to do it in two interlocking ways. We do
it in terms of, I think, how well does it zero in on relevant information? How well does it pay
attention to what it means? We look at an animal and go, wow, that's really good. Notice how it's
noting subtle differences. But we also evaluate the intelligence of an organism, and Michael Levin
talks about this with his cognitive light cone idea, is how deeply into the world they can
anticipate. And I don't mean just spatio-temporally, I also mean modally, possibility. Like when I
talk to my cat and I say, you know, you know, where's your toy? The cat looks at me and I go, no,
well, I say to my puppy, where's your ball? And she goes into the other room, looks for the ball,
finds it under the couch, and brings it all the way back to me. I go, wow, you're really smart,
right? And so we get this because we know how just moment by moment that adaptive ability
is built on. How distally can we pursue goals? We tend to evaluate people, wow, you pursued a
long-term goal when you brought it up. So that's what's missing. And I think that's what's really
afforded. Now, I want to make one more point, and then I'll shut up so you can ask me another question,
which is these two issues, anticipating more deeply, and remember, I don't just mean spatio-temporally,
I mean modally, and relevance realization are deeply interconnected. The more you anticipate,
the more the problem of relevance realization goes up exponentially. And so these two things,
right, they, I would argue, because they're interlocking, they have to be solved together. And
I think that's why we use both of them as evaluations of the intelligence of an organism.
Okay, I'd like to backtrack to that second argument after this, after what I say here.
Yeah, it strikes me that what predictive processing can give, perhaps where
4e cognitive science doesn't, but I'm happy to be schooled on this. And I know Varela and
Autoporesis in some sense pre-shadowed and prefigured what I'm about to say, is that it kind of gives
a ground to our action and to our perception, which is that we have to have a model of the world
and a model of ourselves, which is not only descriptively viable, but also normatively viable.
Insofar as it's all like, it's very important for me to be able to predict the world. But as you
said, we aren't just at the behest of the world's dynamics, we can change the world according to
our preferences. Exactly. And I think what predictive processing gives us is, although
to be fair, I think Carl might say that this is a bit of an overshoot, is a telos,
is a fundamental attractor set to which our perception and action is governed. So I think
that's kind of the way that I see the added benefit of this convergence between predictive
processing and relevant to realisation. What I was also going to say there is that it's
fantastically, you're mentioning this kind of deep temporal modelling, because from my eyes,
that's really where a lot of the work is being done right now, which is that
selfhood, consciousness, even perhaps space itself is downstream on the fact that we can
downstream on the degree to which we can model the slower dynamics and the faster dynamics in a
generative hierarchy. So that's, I think that's a complete agreement with that. I think that's
an extension of the argument I made. And so what I wanted to pick up there is you said,
if I heard correctly, that the deeper your temporal model, the more you can model slower
fluctuations in the environment, the more critical relevance realisation becomes,
the higher the stakes in some sense. I'm interested in unpicking that argument,
because from my eyes, there are plenty of things out there that don't have deep temporal models.
So a virus, for example, would just be reacting to very
coarse-grained features of the environment. But for them, relevance realisation,
at least in my eyes, appears as critical as it would for a human.
It is, it is. And so I think it's, I'm going to put it, I think it's always a demanding problem.
So I'm not, I'm not denying that even the paramecium has to do salience landscaping. It has to,
I'm going to use a word very neutrally here. I'm not connoting anything about consciousness,
but it has to recognise this molecule as food and that molecule as poison and swim reliably
towards the one and away from the other. I'm not, so I think the problem is always there,
as I was trying to indicate, as soon as you have problems, as soon as your goal states are
distinct. And I think the space opens up very quickly exponentially. I just meant that it
exponentially gets worse. This is why you see across species, hyperbolic discounting,
temporal discounting, because that's a, that's a huge relevance realisation machine. It's about
salience discounting, right? And the point of that is, is because as you opened into the future,
the number of possibilities goes up exponentially. And so you need to have this attenuation function
so you don't get overwhelmed by the possibilities as you extend your cognition into the future.
That's why we have hyperbolic discounting and we pay a huge price for it. It makes us procrastinate.
It makes us difficult to give up, to pursue our long-term goals. So there's even a trade-off
relationship in there, but I won't get into it, but that's an example. There's a good reason why we
must have something like temporal discounting across species. That's what Ainsley showed,
is because the relevance realisation issue just, it gets even worse. It starts out bad and gets even
worse. Right, wonderful. And yeah, I mean, a lot of your work will come to affordances now because
a lot of your work is centred on the notion of affordances. So affordances are the possibilities
for action afforded, actually circular, possibilities for action granted by the environment. I mean,
afforded was a verb and then Gibson made it now. How much has the predicted processing
framework supplemented your understanding of affordances and perhaps the way that
what we perceive in the world is not necessarily a feature list of objects, but they are fundamentally
affordances. I see my glass of water as grippable rather than being glass this dimension. And I
only ask that because, as I said, as conscious, animate cognisers, we are blessed with the
capacity to change the world in accordance with our priors, which makes action really the fundamental
currency for auto-poesis, for self-organisation. So has predicted processing ramped up the
importance that you give to Gibsonian affordances? I don't know if it ramped up because I always
thought, I literally learned this stuff from John Kennedy when it gives him his greatest
protease. So very early on, I was very much impressed by this. And it occurred to me that
relevance realisation, the realisation of relevance, and I mean realisation in both
senses, actualising a possibility and becoming aware of it, or at least detecting it in some
fashion, that it's a prototypical kind of affordance. The thing about affordances is they're not
found in the object or in the organism. The grippability of the glass is not in the glass,
can't be gripped by a paramecium, and it's not in my, you know, in my hand. My hand can't grasp
Africa or the sun. It's in a fitted relation between them. And that's exactly what relevance is.
It's a fitted relationship between. So I always, before I came into a deep dialogue with predicted
processing, I already saw a deep relationship between relevance, realisation, and affordances.
And I think part of my work has been to really explore the deep ontological significance of
that, that we have a category that sort of falls outside. This was Gibson's intent, too.
This is what 4eCogSide is really talking about. Falls outside are our belief that we have a
complete exhaustive dichotomy between the subjective and the objective, between the inner world and
the outer world. And so there's this other important, I call it the transjective, this
betweenness, this connectedness that you see in adeptivity, you see in relevance, but you also
see it, like you said. Now, what do I think the predictive processing did? If you'll allow me,
I want to talk back and forth symmetrical, not just linear. So I think what the predictive
processing does is emphasise the need to try and explain, rather than just...
I don't want to be cruel. So I'm being a little bit oversimplistic. I'm doing that just for speed.
Generally, it's like, yeah, but how do affordances get actualised in the 4eCogSide?
Like, there's a lot of affordances all the time. And what I'm interested is,
how do those affordances become, well, salient and obvious to me so they become binding on my
sensory motor behaviour? And that was always something of, not that there's Redfield and
others who are doing some work on it, but typically they start to invoke predictive processing to try
and explain that mechanism of like, okay, there's a huge affordance network, but I'm not like,
how do I, here we go again, how do I select and actualise the ones that actually go into
my salient's landscaping? And I think predictive processing, especially with the notion of precision
weighting, there's a good job of that. And what I think relevance realisation helps to do the
predictive processing, a bunch of other things. But one thing is, predictive processing basically,
there's subtlety to this, and I know there's lots of mouth, but just to keep going. Well,
what attention is, is the precision weighting, it's this meta function. And I think that's a
very good argument, but there's a conceptual analysis that's been needed, but it's like,
but what is salience? And one of the arguments I can make is, well, what the precision weighting
is doing is relevance realisation. And relevance realisation, when relevance realisation does
a higher order finding relevant of an affordance that has been generated by lower order relevance
realisation, that's when something becomes salient to us. And so we can actually give a
conceptual explanation that goes with the theoretical identity claim in predictive processing,
the precision weighting is attention, and what it gives you is salience. So they can unpack
each other. I think what, another thing that happens is, relevance realisation is deeply
connected to foreecogside, because relevance is grounded, I would argue, in auto-polisis.
Relevance, relevance is always relevant to an organism, right? And so that means,
relevance realisation isn't called calculation, it's how the organism cares about some
information rather than all the other information, because it is constantly taking care of itself.
There are literally, and I mean this physically, things that matter to it, and things that it
must import into itself, important things, and some of that's also information. And so
why that, if you can glue foreecogside and predictive processing together, I think you
can answer some of the questions, maybe even challenges, that some people in foreecogside
are making of predictive processing and saying, well it's not really connected to embodiment.
I think, no, no, if you show a deep theoretical integration of predictive processing and
relevance realisation, and then relevance realisation and auto-polisis, then you've
really strongly glued predictive processing and foreecogside together.
So that's some of the important theoretical work that can be done.
Yeah, absolutely. I would love to jump into the critiques that certain foreecognitive research,
cognition researchers have leveraged at predictive processing, but let's leave that for a second.
This is exactly what I was talking about in terms of telos, which is that,
exactly, this notion of care, and when I spoke to Mara Barasin, an active inference researcher
last week, we kind of actually ended up concluding that this is almost a Heideggerian sense of care
that we took on our existence. Can I just interrupt there? Right, a Heideggerian sense
of care was exactly what I was invoking, and I was deeply influenced by Dreyfus and the
frame problem. You got this from Heidegger, so the connection you just drew is very,
yeah, I explicitly argue for that. Excellent. So yeah, I mean, I personally think that the
Heideggerian, Dreyfus, Merleau-Ponte lineage needs to be integrated more into active inference,
and I'm speaking to Dr. Marilyn Stendera, who has done work on Heidegger and auto-polisis,
so that will be really fun in the upcoming weeks. This is exactly what I was talking about in terms
of telos, which is that taking a stance on your own existence can be computationally modeled as having
these kind of high precision priors. So our homeostatic set point will be different from
the snakes, and that actually gives a really solid explication of why we act differently in
certain contexts than snakes. And so that was my kind, but then that said, I will have to make
clear that Carl himself, although he has spoken about existential imperative, says that there
actually is no imperative. All that you're really saying is if a thing like us is to persist over
time, this is what it needs to do, and it's just a, it's just cast as a minimization of free energy.
So I think there's an interesting question there that maybe you could have a go at, which is
to what degree do you see this as a genuine imperative versus just what things do to self-organize
over time? Yeah. And so I mean, and Carl's no slope, so he's welcome. I sometimes don't like
it when people who are physicists or something start commenting on philosophical normative
questions with an authority they don't properly possess. But I know Carl's a great theorist,
and I know he's philosophically educated. I have not yet to talk to him, but I hope I do
get to do so. We can do ahead. So, yeah, I mean, so I'm going to argue later if I get a chance
that what relevance realization doing is strongly analogous, obviously a very different timescale
to what evolution does about constantly redesigning the adapted fittedness of the
organisms to the environment and allowing organisms to fit their environments to them.
Because as you keep emphasizing, and I keep agreeing with, it's not passive. It's not right.
The organism is shaping the environment as the environment is shaping the organism,
niche construction and all that sort of thing. And I think that's all right. And then there again,
that's a very clear connection to 40 talks again. But this deeper question, I do want to do it. I
want to pause and I want to slow down because it is a really important question because it gets us
beyond what we might call scientific explanations of how and into properly, but not useless,
philosophical reflection of sort of why and why does this matter to me? Because as you've mentioned,
I'm deeply concerned with, you know, issues of meaning in life. This largely metaphorical,
nebulous notion that humans seek meaningful lives, lives that are worth living,
even given all of our failures and our faults and our flaws and our foolishness and our frustration,
right? And pretty clear empirical evidence that it's not reducible to just subjective well-being
or pleasure and pretty good conceptual philosophical argument, because that's where it's relevant,
that it's not reducible to just living a moral existence. You could live a very moral existence
in which you're sort of experiencing the pleasure of food and other things. And, you know,
certain stability in your environment, but you could be very, very lonely. You could be very lonely.
So, and what that loneliness points to, I'm just making an intuitive gesture. That's not a tight
argument. I have tight arguments, but the gesture is people are seeking a kind of connectedness,
and now you see where I'm getting to. Relevance realization and what we're talking about this
niche construction, the fittedness, the belonging togetherness, this mutually shaping, like this
is this, I argue that that's exactly the connectedness human beings are seeking the meaning in life.
Now, you can then ask the question and I'm going to play with two terms of phrase here to play with
that. I think we clearly seek meaning in life. I think the evidence for that is growing and it
converges with the psychological work on meaning in life and on what Karen Allen calls belongingness.
If you don't feel that you belong, you're in trouble and you're in trouble across all these
measures, cognitive, emotional, social, financial, blah, like you're in trouble, physiologically
you're in trouble. That's why solitary confinement is such a punishment, right? So,
is there a meaning of life to the meaning in life? The meaning of life is that is there some sort of
cosmic destiny, cosmic order to which we are ultimately trying to find.
And here's the thing, I don't think I have enough evidence for that. I think there's lots of evidence
for meaning in life and if I'm right that it's relevance realization and if that's something
very much like evolution, right? Evolution is constantly redesigning adeptivity,
but there isn't a final thing that evolution is aiming towards. There isn't a final form of life.
There isn't some, like what we're doing is like the sculptor, we're constantly refining and then
finally one day we will have the final form of life and I think this is fundamentally flawed.
And I think this matters philosophically. I don't think previous forms of life were in some,
in any kind of moral sense, superior to us. So, I don't believe in any nostalgias. Some of the
previous things that people found important and relevant and sacred, those were the true ones
and we just have to get back there. Nope. And I don't believe the utopia. We are working towards
the final ultimate thing that will all agree for all time is the most relevant, most salient.
I don't believe that's how this works. So, I reject nostalgias. I reject utopias. The idea that
there's a telos can either mean, there's a telos to meaning in life, which is, it's like Carl says,
it's necessary, it's constitutive necessary for living things to have this. But does that mean
there's any metaphysical necessity to their being living things? That's a different question.
Now, here's my weak answer at that one. Sorry. Long question, but you asked like,
this is like almost up there with like God, right? I note that I'm in a very difficult
situation. I can't see any evidence for, and I'm not attacking God here. And as you know,
I'm very respectful and even appreciative of religious frameworks and religious lives.
But I can't see any evidence for that. However, if you were to ask me,
which is a better universe, one with life in it and one without life in it,
even if you couldn't exist in either one, I would say the one with life in it.
There's some primordial judgment going on there that has some kind of metaphysical import. Now,
it's weak. I admitted that ahead of time. And so I'm giving you a very, I'm sorry,
very long, but wishy-washy answer. I don't really think, I believe in anything like the
meaning of life, but I do think there's a metaphysical import to being connected to reality.
We find reality, being connected to reality, inherently valuable for its own sake. And we
find worlds in which things can realize reality, better worlds than ones that don't have that
that's my answer. No, it's a wonderful answer. And it, it's really helped me and hopefully our
audience clarify exactly what I mean by an existential imperative, which is that the free
energy principle doesn't tell you what you're here for. No, it tells you if you're here,
what are you doing? And given your phenotype and given your culture and et cetera, et cetera.
So that's a really useful sort of explanation of exactly what I was going for there.
And actually it points to something I said to Carl right at the end of our podcast,
which at the time of recording this came out yesterday. So people should definitely check
it out because he's for sure, he's on top form, which is that I asked him, I mentioned Thomas
Nagel. So Thomas Nagel has this very romantic philosophical notion that life is death is bad
because life is fundamentally good. And it points to kind of your thought experiment. If
we have two worlds, one with life and one without life, I think we would all intuitively
say the one with life is better. Whether that has any metaphysical importance, you say, is up for
grabs. I was gonna, I'm gonna ask sort of jumping on the back of the initial thing you said, which
was about connectedness and belongingness. So if we take this from a theoretical computational
stance in active inference, what this looks like to me is we embody a model of the world which
we can, so we can make fundamentally sound predictions about how the world will unfold
and how about we will, and how we will act to make that world more compatible with our preferences.
Now, when that was formalized initially in the active inference literature,
immediately a response to this came in the form of what's called the dark room problem.
So this is sort of papers in 2011, 2012, and they've been rebutted in multiple ways,
but the basic idea is why don't humans just seek out dark rooms where maybe they have access to
food and water, but they don't really seek out, but in a state where they don't go and explore,
and they're not curious, because what you're saying there is actually a perfect coupling between
your predictions of the world and the way the world is unfolding to your eyes. So I was wondering
whether you had pondered the dark room problem and where you see exploration and epistemic
affordances coming into play here? Yeah, I think that the dark room problem, I'm not,
I'm happy with all the other rebuttals, and I don't know, I don't know, I don't know them
also, I may be stepping on somebody else's toes, so if I am, whoever you are, I apologize.
Yeah, I think this is a, you know, a Lockean individualist model of cognition and how we work,
and I think it is therefore the presupposition, well, is that no, that's actually, I don't agree
with that presupposition, that our cognition is fundamentally individualistic in that way.
I think we are, you know, we are sociocultural mammals, and let me point to one thing, you know,
yes, measures of G are very robustly predictive, but you know, it's also really a very powerful
way of predicting your behavior, your attachment style. This is also very robust. Now, that means,
think about what that actually means, and this goes into the heart of religious traditions,
like agopic love, right? When you have a child, you have to invert your relevance arrow. It's not
how that being is relevant to you. You invert everything around. This is agopic love, and
it's how it's different from erotic love, or philea love. You invert everything around you,
right? And so that it's, how am I relevant to this being? How am I relevant to this being,
and how can I be relevant in a way that turns it into a person, turns it into an intelligent,
rational, self-reflective, relevance-realizer, predictive processor, meaning maker, right?
And so, well, first of all, where are my attachment relationships in the dark room? Well,
there's other people in the dark room. As soon as there's other people in the dark room, all the
problems that you thought you got away from by putting me in a dark room return. Other people
have different goals than me. They have different needs. They're going to move around differently,
right? That we're going to have to decide about when and where and how we gain access,
blah, blah, blah, blah, blah, blah, all of that immediately unfolds. Secondly, and this is part
of 4E Cognizant, I think the evidence for extended cognition, distributed cognition,
that we evolve to work in groups, and the collective intelligence of that is actually
our superpower, and other people are making this argument. I think that's clear. The standard thing,
take the waste and selection task, put it an individual person, highly educated, highly
intelligent, second year psychology and top tier university from the 1960s on, you put them in
the waste and selection task and only 10% get it right, right? You replace that same task with
four people who are allowed to talk to each other, and the success rate goes from 10% to
82% reliably. Why? Because we do opponent processing between each other. You have biases
different from mine, and if we work in opponent processing, not adversarial, but if I say,
you're probably a good source for correcting my bias, and I'm probably a good source for correcting
yours, we get the best dynamical self-correction possible. When you add in the fact of the reality,
and there's actually evidence, empirical and formal, for the power of collective intelligence,
the reality of attachment, well then the dark room becomes filled with other people
who are trying to band together to solve problems that they can't solve individually.
And then to me, everything that the dark room thought it had as an absurdity, like a reductio
out of absurdum, disappears. That would be my response. Yeah, I think eventually the dark room
just becomes the world once you start asking the things you need eventually, it becomes a civilization.
Yeah, I love all this stuff on distributed cognition. I spent the first six months of
this year working at UCL on finding experimental ground for what's called social baseline theory.
Social baseline theory is this idea that humans, like to study a human being in a lab by itself is
to study a human being at deficit. Yes. Actually, it's physiological arousal to take one factor
is at its baseline when it's with other people, and it will fluctuate according to stuff like
attachment style or the relationship the one has with that person, which is really beautiful,
but inverts are kind of, well, maybe not common sense bar institutionalized notion of what it is
to be a person, which is kind of alone. Yeah, wonderful. Well, I'm going to take this argument
a little bit further if you let me, because this is something that we spoke about a couple of months
ago. And I think Mark might have a different opinion. So it'd be cool to sort of unpickle this.
I have this slightly fuzzy, wishy washy idea that the notion that, okay, so I always think about a
climber climbing a rock face or a climbing wall. And the climbing wall is a kind of beautiful,
canonical example of an affordance based landscape. It's rich for affordances. It's got the
toe holes, the finger holes. So in many ways, what the rock in terms of active influence,
what it allows the rock climber to do is to self evidence or find evidence for its own model about
itself as a successful rock climber. Yeah. Now that's relatively well established in the literature.
What isn't established is my kind of, again, slightly wishy washy idea, which is that the
rock climber is offering affordances to the wall. And so this, this is why I about, you know, right
at the beginning of our conversation, I spoke about mutual coupling. So what dynamical systems
theory gives us, what all type races gives us, what active inference gives us is this idea that
to exist is not to be this kind of reified self that takes a objective stance on the world.
And actually what it is, is this really the fundamental unit of analysis should be this
dynamic mutual coupling between agent and arena to use your terminology. Yeah, you think it's an
over. I mean, I've spoken to Mark about this and he uses, he said it's something like an overextension
of the term affordances to say that the human being is offering affordances to the climbing wall.
I know Mark isn't here to defend himself. So again, I'm not going to put one, but I will
definitely raise this with him again. But just to your own ears, how does that argument sound to you?
I like the argument. And yeah, I don't want to speak to Mark. I'll only speak to the propositions
that you spoke on his behalf. And I'm very happy to, I mean, Mark and I work close together. Mark
is one of the best people I know. Mark's a former student of mine. I'm very proud of Mark. So,
but I actually agree with you. Now that goes to another connection I make in my work that
would probably be a little bit stranger to the ears of many of your listeners. They might say,
oh, I get why he wants to connect predictive processing to relevance realization and the
40 card side. But now what you're doing, and this is where I do a lot of what I call my deeper
ontological work. And this is where the Heideggerian stuff really comes to bear, is this is all the
work I do on neoplatonism, which may sound like something very arcane, but it again,
here's the proposal that once we really profoundly accept affordances, and once we accept that they
are reciprocally realizing, I agree with you, the Ford's not only discloses things about me,
it discloses things about the world. And that's a way in which things like Heidegger's notion of
truth is ala Thea as the as an event as the disclosure, rather than a static property of our
propositions. I think that bang on now, as filler argues, and I've been arguing for a while and
john russen, filler's book is called Neoplatonism Heidegger the history of being relation is
ontological ground that relationality is actually the ultimate nature of reality.
Heidegger is actually turning back towards this because what does that give you if you have that
and I think this is a fair way to put it, if you have that alathetic notion of affordance,
then you are getting back to the neoplatonic theory of knowing by conformity, knowing by
participation, and the deeper argument goes something like this, that if the fundamental
grammar of your cognition, I don't mean the content, your content can go wrong, but if the
fundamental grammar, the bottom up, top down, all this stuff we're talking about, if it's not
picking up on something fundamental about how reality is structured, right, then you face a
kind of profound solipsism, a profound kind of skepticism. And I think that is ultimately
leads you into all kinds of performative contradictions that I, and I agree with Whitehead,
there is devastating as a propositional contradiction. There's a longer argument there,
and I could point to, please check out some of my talks on YouTube about this longer argument,
Pickstock's Aspects of Truth, where she said, you know, all the things we used to decodamize
this, right, we had the analytic, synthetic distinction, that is broken down under
philosophical criticism. We had the theory fact distinction, that is broken down. We had the,
right, it is odd, that has broken down. Think about relevance, it is or not, well,
blah, right, it's sort of both, right, and so her point is all the things that were used to cleave,
and then what we tried to do is we tried to make the logical world, the thing that sort of stuck
the two worlds together, and that collapsed under Godel and other people. And so we're back to the
idea that we either, we either, we either go into the Lockean cabinet in which we're locked inside
of our heads, we're somehow getting postcards sent to us, we think they might be from an outside
world that we think might be out there, and we're trying to build it from the postcards,
and we're doomed, that's never going to get us there. And so I think if you have an allothetic
notion of affordance, you start to make the argument that how reality is realizing,
and how we are doing relevance realization, are fundamentally participating in the same
principles in a profound way. And I think, yeah, I have no doubt that Mark might not
want to do this. I think Mark would be, I would agree with Mark that this is not a direct derivation
from sort of classic Christonian presentations of active inference and predicted processing
Bayesian brain, we should settle on a name. But I think if you make the connections through
deeper into Gibson, deeper into Foricog side, deeper into Heidegger, you get back to this notion
that with the prevalent notion of knowing, that when we know something, what we're doing is
our structural functional organization is identifying with the structural functional
organization of the thing. And we are, we are both participating in that same form,
that same principle, that same grammar. And that has all kinds of metaphysical and ontological
consequences, even ethical consequences. It means talking about the true, the good, the beautiful
becomes something very relevant to them. Yeah. Yeah. No, this is, this is exactly where I wanted
to go and exactly aligns with the way I'm thinking about the free energy principle at the moment,
which is I have a skepticism between the internal and the external distinction. Yes. It's something
I spoke about with. So a classic problem when one starts reading active inference, as I spoke
about with Carl, is whether one would consider the, the agent or the internal dynamics as having
having a model of the external world or instantiating a model of the external model. Excellent,
excellent. And since it comes back to cyber cybernetic formulations, what it is to be a
good regulator. So kind of Ashby and all of that stuff from the 50s and 60s. So I have an inherent
skepticism because I would, I kind of take the stance that actually all of the internal dynamics
are doing is instantiating a particularized form of the external dynamics. And this is very easy
once you take out the picture of a homunculized ego. Just if you look at it in terms of just the
particle physics, we're just a instantiation of some of the physics that defines everything else.
But we just, we just actually seem to have a kind of complexified Markov blanket or Markov blanket
form of that. But there's nothing particularly distinct about that and we'll come to consciousness
because maybe there is. And that I guess is the big elephant in the room here. But it's funny
that you mentioned Heidegger because Heidegger to my, to my eyes and in my opinion, and then
obviously Dreyfus and Merleau Ponty and the phenomenologists followed Heidegger. Really,
he's the one who strikes at this established distinction between a subject and an object.
So the Cartesian distinction. And then this is where his kind of gripes of Sartre came in.
Now, my question is, is that, yes, if you read Heidegger, Darzine, the ground of Darzine is this
kind of interrelationality. Alephéa is the disclosure of truth in an interrelational
relationship, so to speak. But there still seems to be some kind of subject who,
you know, the, the hammerer who is hammering away at the nail. Now, from the perspective of the
hammerer, he's not some reified ego who is objectifying the nail that all that is really being
witnessed there from the level of consciousness is the disclosure of activity.
But still, we can give a description of a hammerer and a nail. So to what degree in your
thinking do you completely eradicate the subject-object distinction?
And is there anything that you think predictive processing has to say about that?
I think, well, second question.
I'm happy to think about it with you. I have put a lot of thought into the first question.
And so, I mean, I think Filler is right in his book that our subjective objective divide is our
version of the appearance-reality distinction. And it's just our version. In the ancient world,
they had a different version. So ours is an in-out metaphor. How is the inner and the outer
connected? And the ancient world is the problem of the one in the midi. How is the lower and the
upper connected? And once you see that, you realize that there's a deeper structural problem that
isn't bound to the inner outer or the emergence and the emanation. It's this, it's the connectivity
issue. And what Filler argues, and there's a lot of other people converging on this, is like,
if you try to, if you go with an Aristotelian metaphysics, or that what's most real are
substances in the Aristotelian sense, which are things that can independently exist,
then this becomes a deep problem for you. And that kind of ontology, I would argue,
and I can make the argument, drives you towards a nominalistic epistemology. And then you get,
you know, Occam's version of it or Kant's version of it, where all of the patterns and all the
information are just in the mind, which means the mind is radically other, because it is the only
place that the information intelligibility actually exists, and the world is profoundly absurd in a
deep, deep way. And I think that leads you into, well, first of all, it makes science impossible,
and it leads you into all kinds of existential and moral dilemmas. And if you then take a look
at the logic of trying to get, you can't actually, and this is what Philip does very carefully,
you can't actually get relations out of properties that belong to the Relata. The relation have to
precede the Relata in a very important way. So I think there's a deep, at a very deep level,
I do want to call it into question. I do want to challenge that, that, first of all, it's
historical, it's cultural. We pretend as if that is the only way in which human beings have
related to the world. Like I said, even in the West, that's not their problem in the ancient
world. Their problem is the problem of the one and the many. It's not the problem of the enemy.
Now, what does this all ground in? I think this grounds in the common problem of the relationship
between appearance and reality. And here's where I could now say something that aligns with my
previous argument about relationality. See, so, and I'm going to bore a term from rapport here,
the hermeneutics of suspicion. The hermeneutics of suspicion is that appearance, and we got it
because of Freud and Nietzsche and blah, blah, blah. There's historical reasons, and those are
valuable critiques, by the way. But the hermeneutics of suspicion says appearances are distorting,
they're deceptive, they're destructive, right, they're disruptive. And what we should do is always
question whether or not they are leading us into reality. Now, Marlo Ponti has a great argument
against that, that he gets from, maybe he doesn't get, but it's in Plato, which is, wait,
you're treating real like red. Like you could just say, you could look at an isolated thing and say
that's real. But real is a comparative term. So, of course, is illusion. To say this is an illusion
is to say this is an illusion in comparison, in relation to something that is more real. And
that thing is in relation, so on and so forth, right? And what that means is, first of all,
you have to see that those judgments are inherently relational. And secondly, you have to call into
question the hermeneutics, the independence of the hermeneutics of suspicion. The hermeneutics of
suspicion is actually parasitic on the hermeneutics of beauty. It depends on there being things that
we agree on by saying that's where appearance discloses reality rather than distorting it,
right? And then as soon as you do that, that undercuts the deep divide, because you ultimately
make these divisions between the one and the many or the subject and the object, by getting a hermeneutics
of suspicion into the appearance reality distinction. That's at least the argument I would make.
Interesting. Yeah, I like the suspicion of binariness inherent in all of this. It speaks to me,
and I think it speaks to people who are interested in active inference and the notion of sort of
philosophical vagueness as well. At what point is something real? It's fundamentally a comparative
term in the web of things that could be considered real. Yeah, that's right. Yeah. I'm trying to
do this without invoking a binary. But you mentioned earlier that 4e cognitive scientists do have their
critiques of active inference and predictive processing. And I will stick with active inference
actually for now, and I will explain why later. It's not that interesting. So this is people like
Tony Camaro or Ed Bags, who are radical inactivists. And what they're critiquing, in a sense, is an
internalist picture of active inference. So this is some, again, I'm not putting words into people's
mouths, but if you read Jacob Howie's 2016 paper about self-evidenting, some of the language may,
to some people, imply that there is a homunculus that has a representational picture of the world.
And this, to the ears of an inactivist, is deeply worrying. I would love to, as a 4e cognitive
scientist, with obviously a vested interest in predictive processing as well, I'd love to just
hear your take on that debate. And again, without striking up binaries, and whether you think those
critiques are legitimate. Well, I mean, it depends what you mean by legitimate. I mean, you know,
there's also the ones that Evan Thompson made, and I hold Evan in a very high regard. I mean,
they're legitimate in that they're well-made arguments in peer-reviewed journals. And so
we have no right to be dismissive of them. Well, if I was to say that let's take as an
axiom of active inference, like this is just, this isn't the case, but let's just say for
sake of argument, that you have some internalist representations of a statistical model, right?
So you are, in a sense, you're not just embodying a model, you actually have a model. So again,
it comes back to that distinction we're talking about. Would an activist critique of that internalism
be justified?
So the reason why I'm hesitating is this is landing on the swamp of what do we mean by
representation, which I mean, so does the thermostat represent the temperature in the
environment? And where, and everything I'm going to say is controversial because of the swamp,
so I want that understood, please, right? I would say no, because what's needed is,
right, there might be some, there might be co-variation, but what I think the critiques
of the co-variation model of representation locks ultimately model. So we had the idea that
representations have to be similar to what they represent, that's how they represent, and then
you have all the problems with similarity and Aristotle even could bring that down. And then
lock replaced it with the co-variation model to have a representation is I have something in my
head that reliably co-varies with something in the world, and that's how it represents it.
And then the problem with the co-variations is they don't give you the specificity, for example,
of thought, right? So this is co-variant with a bottle, with a tool, with a man made up, which
is it? Those are not the same things, those are not the same ideas, but this is co-variant causally
with all of that. And you have the problem then of aspectualization, and the Lockian answer of
course is we get aspects by doing representation, but I agree with Searle that that's the wrong way
around, that any representation is inherently aspectual. When I represent this as a bottle,
I'm only picking up on some of its properties insofar as they are relevant to each other,
insofar as they are relevant to me. So representation depends on aspectualization,
which depends on relevance realization. And this is not what you do with relevance realization,
you do not represent all the facts, judge them to be irrelevant, and then zero in. So it's ultimately
non-representational. So what I would say is, I don't know that some level there's something
like representations, but if I agree with many arguments that representations are more than
co-variation, but there's this kind of caretness and aspectualization through them, then they
depend on relevance realization, which grounds an autopolicist and is deeply intertwined with
predictive processing. That would be my response. Splendid. And I guess what intuitively supports
a more representationist picture is consciousness. I think consciousness is going to become a
recurring theme in this podcast. Well, it's the Holy Grail, right? It is the Holy Grail.
And so I guess my question here is, is that if one was to adopt a radically inactivist view,
there's nothing in that picture which needs consciousness. So why couldn't my mutual
coupling with the world just happen with the lights off? So this is an argument, I guess,
that's rooted in Chalmers 1995 paper, which is, you can give me the function, but you can't give
me the why. Why are the lights on? And so I guess in other words, my question too is, yes,
we may have relevance realization preceding perception or grounding perception. Then why
do we have perception in the first place? So again, I'm going to give it just of an argument
that I've spoken about at length elsewhere and I'm trying to get published on and presented at
conferences and so forth. So I don't think you can separate the function and the nature questions,
which is what Chalmers Hard Problem relies on. Yeah, you've given me the function,
but you've told me nothing about the nature. I don't think function works ontologically
like that. I think function has to be plugged into the ontology. And I think as soon as we're
talking about the ontology of anything within a living organism, we're talking about something
functional. So I think the questions have to be answered interconnected. So let's go back.
Let's say that you give me that any cognitive agent has to be doing anticipatory relevance
realization or it's not going to be a general problem solver. And then when it's doing that,
it has to be aspectualizing its world. It's not doing all of this, but this as a bottle
or the molecule as food, the molecule. And then if you then start to pay attention to,
let's look at the continuum of consciousness. Let's look at the possibility, which I have
experienced. That's not even the right sentence. Many people have, and this is Foreman's idea,
of something like the Pure Consciousness event. And the Pure Consciousness event doesn't have,
well, actually I need a distinction here. I'm going to claim it doesn't have one type of
qualia, but it has another type of qualia in it. It doesn't have aspectable qualia. There's no red.
There's no blue. There's no cap. There's no dot. You're not even conscious of consciousness. You're
just conscious. But what it still has, is it still has the adverbial qualia. It still has
a sense of here-ness. And the here-ness is profound presence. That's the language with you.
The now-ness, eternity, the integration, the together-ness, everything is one. So all the
adverbial qualia are still there, and you still have consciousness. That shows that the adjunctival
qualia are not necessary to consciousness. Now, I have the other arguments to show they're probably
not sufficient, because if I give you sort of atomic blips of blue-ness and green-ness, and
they're not bound together, and there's not a here-ness and a now-ness, so you can anyway
orient on them, I don't think you have consciousness either. So I'm not saying that
adjunctival qualia don't exist. I'm saying that we've held consciousness hostage to them.
And what I'm proposing to you is that what consciousness is doing is these adverbial qualia,
which are just salience, which is just relevance realization, which is, as far as we can tell,
tied to the best evidence we have, it's all controversial, about the function of consciousness.
It's tied up with working memory and attention, which are both doing higher-order relevance
realization. We seem to need consciousness for situations of complexity, novelty, or ill-defined
in this, ones that are really demanding on relevance realization. So you can make a pretty,
and there's a lot of convergence, actually, on what the function of consciousness is,
relevance realization. And I think if you plug in relevance realization, you can at least get all
the adverbial qualia. And that, I think, gives you a lot of what consciousness actually is.
Cool. Yeah, let's stay on adverbial qualia, because I'd like to integrate what you've just
said with a more active inference account of consciousness, which there are, and then they're
also diverse. But one, well, I have to ask a question before, does foreman say that
mind-ness, so feeling that this experience is mine, does he, is that one of his verbal qualia
that persists in the pure consciousness event? So that has another thicket, because the debate
about, this is a raging debate, Evan Thompson actually has a good anthology on this, on the
self-no-self debate. Right. And I think it's reasonable and complies with most of the evidence,
which of course is self-report after the fact, which is problematic, blah, blah, blah, blah.
I agree with all of that. I'm not dismissing that. But that's what we basically have to go on right
now, that the ego narrative sense of mine and me and I goes away. Whether or not that is a complete
loss of the self as where relevance realization is happening or something like that, I'm not
convinced that that second thing is the case. So if you would allow me, and this is a torture
distinction, a distinction between the ego and the self, I think these experiences very much,
the ego goes away. I'm very suspicious of the claim that the self goes away, because people
are readily able to recall these experiences, this is what foreman does report, and I would report to
you, and seamlessly integrate them into their auto-noetic, autobiographical memory. There isn't
any weird disjarring. Where was I during that? The reason I asked that is because
a lot of self-modeling in active inference is based on the work of Thomas Metzinga.
Thomas Metzinga is such a wonderful addition to this conversation. I had a wonderful conversation
with him not that long ago. I love him. I think he's such an underrated and important philosopher.
I totally agree. He makes a distinction between phenomenal self-modeling and an ontological
self. So people intuitively, even everyone listening to this podcast, even the way we
act on a day-to-day basis is in lieu of an ontological self. So we can't help but really
think of ourselves as being this soul, this Cartesian soul. But anyway, Metzinga invokes this
notion of phenomenal self-modeling, how the system appears to itself. He's got this minimal
phenomenal self, which has been unpicked in other ways, but he normally speaks generally of
presentness, minus, and perspectivalness. Exactly what I've been talking about. He gets fleshed out
in some of the active inference work. People like Jakob Howie, Carl, and Jakob Limonowski have used
Metzinga's work for several papers. And then on the other end of that, we have what Carl turned
as an epistemic agent model, which is the system that sees itself as epistemic in the sense that
it can retrieve past memories to inform future decisions, and agentive in the fact that it can
conduct allostatic action, i.e. action to retain some homeostatic equilibrium, given what it knows
about the future. So me putting on a jumper before I go outside, because I know it's going to be
colder outside than it is inside. The reason why I invoke the minimal phenomenal self is because
and Carl actually outlines this in the podcast we did together. The consciousness may be downstream,
in a sense, on one, a deep temporal model. And from that, the sense of agency. And he has an argument
from referring to dimensions, not in terms of sort of millimeter size, but in terms of the degree
to which you have embedded Markov blankets, that when we're distant from our actuators, what we end
up doing is we have to have a way of distinguishing what's my action from what's your action or from
what the world is, how the world has acted on us. And in doing that, we come up with a self other
distinction, but also the notion of an agentive self, the idea that I can change the world in
the corners to my preferences, as I mentioned beforehand. So to paraphrase Carl, what that
seems to be suggesting is that consciousness is actually rooted in selfhood. And I know there's
this whole argument in Metzinger about whether that's the case. That's why I asked whether
mindness is also part of these pure consciousness events or whether it's kind of a post hoc inference.
Just wondering whether you had any ideas about that notion, and whether we can truly have
consciousness without at least a sense of self. Right. Okay. So
let me try a few things. First of all,
I don't think it's inevitable that human beings model themselves as souls. I think that's a
Western post Cartesian way of, and that's even, and then the soul as a
monadic single substance, I can put it that way. You know, that's not even the case in the ancient
world of the West, certainly not the case in other parts of the world, etc. So I hesitate that
that's the claim that's part of how the machinery must unfold. And then secondly,
I worry about saying, you know, that that that because it isn't a soul, there isn't a self.
This is a weird notion of again, of a substance ontology being just presupposed in an unquestioned
manner. I mean, look, we've discovered most things aren't substances. This table, which would be a
classic, it was the two in substance is not a substance. It's a dynamical system of atoms and
quarks and blah, and we don't go, Oh, well, because tables aren't substances, they aren't real,
like that. We don't do that. And so I, like, I, I, I, I just, I want to just note that I'm worried
that there's a substance ontology creeping in here and leading to certain conclusions. Now,
that idea about this, there's, I can't remember the name of the people. And I apologize for that.
There is a fairly recent theory of consciousness that we're trying to respond to all the lipid
experiments and things like that, arguing that, well, consciousness is sort of after the fact,
but consciousness is actually for the future. Yeah. So the idea here is consciousness is
emerges out of the evolution of episodic memory. And so the function of consciousness is to allow
us to create an episodic memory of something we have already done. Right. And the point about
the episodic memory is, as soon as you get into episodic memory, you get into perspective,
tribal knowing, that's what an episode is. Right. You have a perspective, right, on a situation,
what you found salient and relevant, how your actions and right in the arena, coupled or didn't
couple the affect that are all of that, all of that that's so bound up with consciousness. And
then the, and the point that they make, and I totally agree with this is, as soon as you agree
that there are multiple kinds of knowing, not just propositional and procedural, but also
perspectival and participatory, you get the argument that episodic memory affords,
perspectival, knowing, which allows you to solve problems that you can't solve without
perspectival knowing. You can pick up on the world, the world discloses itself in ways that it is not
otherwise disposable to you. And then consciousness emerges as an optimization on the formation
of episodic memory. So it is optimally transfer appropriate for the future. Right. And then you
get, it is a sense of agency, but it's not a billiard ball agency. It's the it's this kind of
longitudinal agency. And to tell you the truth, given the human critiques, that's actually the
kind of agency the cell has. It has this kind of longitudinal, right, agency around episodes.
It doesn't have this. I'm an sometimes sort of uncaused cause. I moved mover within myself,
which I think is both a ridiculous proposal ontologically and an ethically undesired. Why
would I want such a thing? Right. It's like it's completely arbitrary. I think my life is being
lived. I'm trying to change myself so that I am my thoughts as determined by what is true,
my action as determined by what is good. And my perception is determined by what is beautiful
as I possibly can. I would like to lose all my freedom in that sense. And so I think if we move
to the right level of analysis, and Gallagher makes a convergent argument about this, that when
we're talking about agency and selfhood, we're not talking at that limit scale. We're not talking
at where's the first movement of the billiard ball chain. We're talking more about no, no, no,
how are we building this long-term virtual engine that enhances our predictive agency in the world?
Yeah, absolutely. And Gallagher's work is very convergent with Thomas Metzinger's,
of course. And so this, just for our audience, these arguments and this notion of the narrativized
self is well fleshed out in active inference literature. So I could point you, yeah, I would
probably start with the Fritz and the Limonowski papers. There are two wonderful papers about
self-construction under active inference. And then I have a convergent argument coming out of
Daniel Huda, who is also in the 4E, right, the narrative practice hypothesis. And he argues that
any mindsight ability, any ability to see in other people's minds into other people's mental
states, you know, attributing beliefs and desires to them, requires, well, for example,
if I'm going to attribute a belief and desire, I need to know something about your character.
Are you lying or not? I need to know something about the context, the setting. What's going
on in this situation? Are you tired? Is that a small child? So you're not really lying? And
when you tell them at Christmas time that there's a Santa Claus, right? And I need to know what the
conflict is, what the problem, notice what I'm talking about here. I need to know all the elements
of narrative. Daniel Huda points out, we practice narrative incessantly. And I'm like many of the
other things, including language, which we scaffold for children, we scaffold narrative
for our kids. I had to sit through the teletubbies twice, in which you have to sit through these
really impoverished narratives, because we're scaffolding this up, because narrative ability
gives us the right gives us the set of skills, the sets of states of mind with the perspectives
taking therein, and the traits of character that allow us to pick up on other people's mental
states. And I think that is also a function of this. The function of selves is to make us
agentically predictive to each other. Right, exactly, exactly. And there's another,
there's another convergent argument in active inference, which is that only in the context of
other people like you, would you ever come to the inference that there is something that is like to
be you? Yeah, if you were low, that converges with the Vagotsky approach to the development
of metacognition and self-awareness, which I think is right. Right, right, right. And of course,
your colleague at, just pointed people in different directions, your colleague at Toronto,
or former colleague John Peterson, as a whole literature on literature and narrative. And
he has a conversation with Carl on his podcast, which is deeply intriguing about these kind of
alignments of the free energy principle and narrative. John, I wanted to also speak about
flow states. You've written about flow as the sort of locus of implicit learning. As you know,
I've just been writing up a paper on flow from an active inference perspective. So I'd love to
be able to sort of see maybe where we align, where we don't align, and try and sort of unpick that,
just as a forewarning, my paper, the paper that I've written with my wonderful co-authors is not
out yet, but it should be coming out soon. So I want to, I have not yet read your paper because
you suggest waiting. Yes, the paper has gone through modifications as papers are want to do.
It's in the final stages. So you have access to it. So please feel free to read it. I will read
a question. I can give a very brief overview. So to not disadvantage you.
The basic perspective that we take on the paper is about self-modeling under flow states.
So that's the main thing that we're looking at and the attenuation of an epistemic agent model
because what we're arguing is that certain precision waiting mechanisms are lending,
it's leading the organism to undertake pragmatic action, seeking out pragmatic affordances,
rather than engaging in what Carl or other authors would call epistemic foraging.
Now, I think where we might have a point of difference is that I have a section on flow
states and learning. And I think this is a really interesting point because your paper speaks about
implicit learning. To make it transparent, I've had different perspectives on this.
But my current opinion is that in flow states what you're getting is a reinforcement of the skills
that you actually picked up through epistemic work. So I have the example of a violinist.
The violinist must undergo a certain period of exploration, of epistemic foraging,
which comes with this self-talk, this real prominence of myself as a knowing thing.
And then what it does is, over time through learning, you get high precision
over the beliefs about that action in terms of the technical detail.
And then that becomes the foundation on which you can then go and do
more epistemic work. And then that expertise development is stepwise, in a sense.
I mean, you can picture it either way. But critically, where we differ is that I'm arguing
that actually in the moment of flow itself, you're just garnering more evidence for the
capacities and the policies that you already have. So I'd like to start there and see what
you think of that claim. So we, as you point out, Leo Ferraro,
Erin Herobenadi, we argue something different, which is why you're bringing it up.
We argue that learning is inevitably occurring even in the flow situation.
And so there's improvement. And that's why if the environment doesn't have the capacity to renew
its challenges on you, you will very quickly fall out of the flow state.
So the argument is, well, why don't you just stay in the flow state? Well, the argument is,
because eventually you get a mastery over the environment,
which means your skills start to exceed the demands. And so, phenomenologically, when I'm
in the flow state, like inspiring or lecturing, I'm finding tremendous amount of insight and
innovation coming out. Now, this is where it might get tricky, because is procedural innovation
a restructuring of, especially, is that a restructuring of your information and therefore
have new capacities in it, new emergent abilities? Or is it just a reinforcement? And I don't,
we might get into the thesis of the ship here, which is going to be problematic.
One of the defining phenomenological features of the flow state, and I want to be clear,
I'm not pinning you down on this, but I do think it's relevant evidence,
is the ongoing sense of discovery. There's a sense of discovery there. There's a sense of
coming to know things you did not know before. And of course, when the flow state is in much
more comprehensive expertise, not like the plain tennis, or maybe like just your optimal gripping
on the world, people come to think they have learned something deeply profound about reality.
So I tend to think that there's evidence for transformative learning happening,
up and beyond just reinforcement learning. Okay. Yeah, I like the return to the phenomena.
You know, Dreyfus has this phrase, which I will definitely use over and over again in this podcast,
which is when in doubt return to the phenomena. The way that we have cast it is that there's
this idea in the literature about a hyper prior that the world is changing so that we have a
prior that the world is changing. And that is adaptive for us because we don't get stuck in
the same free energy minima. Now, if that requires always a play, what ends up happening downstream
on that is that my inference about my own abilities deteriorates over time. And we experienced that,
I guess. I mean, like if I play tennis today, and then I played tennis in a week's time, I'm
probably going to have less fidelity in my own capacities in the week's time. And I do, if I
play tomorrow, having followed today. And so our argument is that the positive affect that's part
of the flow state is downstream on the surprise that's generated when you actually violate that
hyper prior that the world is changing. Because what you're getting evidence for is that your
policy still work in the world that you would have thought didn't lend itself to your policies
working. And there's this idea, Casper Hesp's paper and his co-authors in 2021, that affect
an active inference is about basically your model doing better than you thought it would do.
And this actually comes a lot into what Mark talks about in terms of aerodynamics.
So I'm wondering. Yeah. Well, see, I think that's right. I think, and the problem, of course,
is you can get an infinite regress of, well, I'll say, well, the things here, and you'll say,
well, there needs to be something a hyper prior behind that. And then we can, that's what I mean
about thesis is shit. Yeah. So again, I would say, well, what are you getting better at? And what
you're getting better at, I would argue, is not stand like so expertise is generally built around
giving you a well, like a specific domain. We can talk about the possibility of sort of meta
expertise if you want. But what I mean by that is, once you've got expertise, you've gotten really
good at within a certain domain at formulating the problems you're fronting as for you, well-defined
problems. That's one way in which an expert is sort of reliably different from a novice. A novice
goes in, this is no defined problem. The expert goes, it goes in, it's, no, it's this problem. And
this is the right way to do this and this and this and this. Okay. So we agree with that. But I think
what's happening, right? And maybe this is the gray area between your position in mind. I think
what's happening is we're discovering new ways in which we can turn well-defined problem, sorry,
ill-defined states into well-defined problems. But something's like, I didn't realize I could
adapt to that situation, but I can. And that sounds similar. But for me, that's an insight
experience. And that's what, like it's an insight flow because you're getting an extension of your
cognitive capacity because you have restructured what you take to be like your problem formulation
of the world. Yeah. I mean, to supplement that, I actually, I don't disagree on that note, but
the way I would formulate that, and this actually isn't in the paper. It's in the paper in some
sense, but it's not a fully fleshed out argument because it wasn't hyper relevant. I'm glad there's
another really quality paper on flow. There's really nothing. When we published the paper,
we were literally the only paper talking about the cognitive processes that work in flow.
Yeah. It's a bizarre one. There's very little on skillful coping generally within cognitive
science. But as I said, I think that's why I said there should be more phenomenology
active or cognitive science convergence. What we mentioned in brief is that flow,
if we take the sort of macro perspective on flow, it can also be this humming between the
pragmatic and the epistemic boundary. Yeah. So maybe when you're realizing, oh, I can reframe
this kind of perplexing problem as actually something manageable, what you're doing there is
maybe just slightly exiting the flow, doing some epistemic foraging, returning, because
something I want to make really clear to everyone listening as well. When we talk about epistemic
action and pragmatic action in terms of expected free energy or active inference,
it's not like the agent goes, I'm doing pragmatic action right now and
it's part of the actual maths. If you look at the maths, it's like, firstly, you can do a bit of
both at the same time. That's the thing. But it's also like the action policies that we're talking
about here, John and I, these are not protracted seven hours of just pragmatic action. No,
these have to be very temporally thin because the world is volatile, right? The world is constantly
changing. And so you have to be able to not just pin all your hopes or pull your eggs in one basket
in terms of an action policy. And so actually fundamentally, our divergence might well be
a semantic thing, which is that I'm very much about the synchronic nature of being in flow
right now. And like, I have for simplicity, I have that boundary between pragmatic and epistemic,
whereas if you take a kind of more macro perspective, as that flow state, as the concerto
unfolds, you could be humming at that boundary and doing learning as well.
Yeah, I really look forward to your paper, because I think that sounds like actually
a powerful way in which the theories could be integrated together. I'm also interested in
a question that's emerging out of this, well, I've already been interested in the question,
but it emerges out of what we're talking about. Because I'm interested, because I think there's,
there might be an additional thing. Because there's, you can flow in a situation and it
doesn't transfer. It doesn't transfer to other domains. Video game addiction is the classic
model. You can flow in the game, you can't flow in the world. So you get depressed in the world,
you can flow in the game, and so you want to stay in the game more and more and more.
That's very different than how I flow in Tai Chi Chuan. Tai Chi Chuan, in fact,
other people pointed this out in me, though the flow states that I cultivate in Tai Chi Chuan,
I can, they're cultivated in such a way that they transfer broadly and deeply to many other domains.
And I'm interested in this sort of ritual framework, because what you get is this ritual and
this philosophical framework, Taoism, and other practices and ecology of practices around,
so that it broadens, like it transfers in powerful ways. And I'm wondering what the
differences are. And also if, how does that show up? Is there a phenomenological difference?
I mean, so now really, really, really, really weakly, anecdotally, right, in terms of phenomenological
practice, I do get a sense of a difference between what I'm just flowing and what I'm
flowing in a ritual context. So if I enter into a violin hall, and let's say I'm an expert in
playing the violin, and I see a crowd and I see my violin and I see the whole stage, what I end up
getting is this, so habits are quite well codified within active inference, you get this kind of
contextual cue that like in layman's touch, although we're saying this isn't happening
propositionally, it's time for me to play the violin. And this can look like precision over
beliefs about your own action. So what this is, again, not something I've thought about
necessarily with any depth, because this is just something that you've brought up. I'm wondering
whether that contextual cue, what you're happening when you're doing Tai Chi, and then maybe what
you're doing when you're lecturing is that your system is seeing similarities in the context,
and doing similar precision weighting in a separate domain.
Yeah, I think that's right. And I think what philosophical frameworks do is they reverse
engineer that. They try to find out what might be similar or maybe even invariant across many
contexts, and then build that back into the specific context in which you are doing the
practice to exactly afford that transfer appropriate processing. I think that's right.
I think there's something else also going on with the queuing, and this goes into
after metamotivational theory. We can be broadly speaking, we frame our arousal in two different
ways. When we're in italic mode and we're working towards where the reward is found in the external
goal, then increased effort is experienced as frustration, and then it increases too much
of getting anxiety. But if I'm doing something where the goal is the behavior itself, like making
love or doing poetry, then the increased, not infinitely obviously, but the increased arousal
is framed as positive, as excitement. And so I think also, and so after talks about safety
framing, let's call the first italic mode work and the peritolic mode
a play. I think ritual has to do with serious play, and I've got a whole argument about that.
But I think also what you're doing in the context is you're trying to cue people into the play mode,
because the play mode allows them to model themselves, their arousal, as positive,
rather than as negative, and that allows them, and I think there's a deep connection between
this peritolic framing and Chick-Sat-Mohais, I think accurate claim that flow is autotelic,
doing it for its own sake. Right. Yeah, cool. Yeah, I like the notion of effort here.
Recognize that one of the fundamental factors or fundamental characteristics of flow is
perceived effortlessness. Yes, even though you can have sort of very peripheral cues that you
might be expending a lot of metabolic energy. Exactly. And just for the, given this is the
Active Inference Institute's podcast, just for those interested in the computational framing of
that within Active Inference, Thomas Parr has got a paper out this year on cognitive effort and
active inference. So that gives a kind of nice computational modeling picture of that, which
actually leads me to a much broader question, because I know we haven't got too much more time,
which is, I've noticed in myself to be totally candid that I've started, I learned about flow
and Chick-Sat-Mohais through you and through other people, but mainly as a philosophical notion.
And now I'm viewing it as a computational notion. Yes. Do you worry about that? Do you worry that
if we rely too much on computation, not just computational models, but maths, physics, we in
some ways reduce the phenomena in a way that's detrimental, not just because it's not romantic
or that it's, but like that we're missing something fundamentally?
Well, it depends. I mean, that's a really important question. We could do two hours on just that
question. But if you think that a leveled ontology is actually the way ontology is,
that the level at which we do science is as ontologically real as the quantum level we
discover when we're doing science. And I think you have to come to that conclusion,
and I have extended arguments for that elsewhere, then you can make a clean philosophical distinction
between explaining a way in a reductive fashion and explaining that actually enriches your
appreciation for the phenomena. Now, if the computational stuff, the computational stuff to
my mind, well, let's say what the argument we were just exploring has merit, then notice what
we're saying. We're saying, well, what the computational modeling actually does is actually
shows why this sometimes very obscure philosophical framework is really important. It's actually
doing some really important work. And you can't get rid of it. You can't dispense with it. And
that would mean that kind of some of the stuff we're doing, where we're trying to commodify flow
and take it out of those frameworks and do the thing we do and sell books.
And it's actually misrepresenting the phenomena in a way that we can philosophically
and scientifically critique. It's like, wait, wait, this phenomena has the power it has because
Chick-Mat St. Mahai said it's an evolutionary marker for adaptivity. And then, well, making
it adaptive is how broadly and deeply is it transferring out of the situation? And then
the philosophical framework really matters to what it is and how it functions. And so if you
can make a distinction and you need an ontological distinction to make this distinction, but if you
can make a distinction between explaining and explaining away, then I think it's possible to
say, no, no, when I do these things. And to be fair to me, there's, I got a lot of people who,
you know, from various religious and spiritual backgrounds, and they come in and they say,
thank you so much for your work. I now, I much better appreciate this, this experience or that
experience or the flow state or this mystical state because you didn't try and tell me it's
nothing, but you tried to say, this is what it's doing and this is why you like it and value it
so much. But do you think your work to kind of, yeah, to look at that personal vantage point,
do you think you've managed to keep, like, because if I, without being sort of embarrassingly
lording, people should watch Awakening from the Meaning Crisis, not only for the content,
but also just the way you present it, which is just so magical. So thanks. I mean, it's really
inspired a lot of the way that I think science should be done and philosophy should be done.
What, what is it about? I think, you know, anyone who watches that recognizes there's
something kind of special going on there. The ideas are living through you, you're,
they're breathing through you, you're breathing through them. There's this really beautiful
coupling. Again, we'll come back to that between you and the ideas.
What, what is it about that kind of synthesis of the philosophy and the sort of
more hard cognitive science? Do you think made that project so successful?
I suppose it's a view of the role of cognitive science, what cognitive science is doing.
I think what cognitive science does is it's,
well, I'll try and do it sort of narratively. And I do this in the series. I think, you know,
there's even the notion of mind that we've been evoking mind and cognition is equivocal,
because it means one thing to the neuroscientists who's studying the brain and looking at
neurons and anatomical networks and perhaps functional networks. It means a different
thing to the artificial intelligence person who's building algorithms and heuristics
and doing reinforcement learning and blah, blah. It means a different thing to the
psychologists who study human behavior with experiments and running stats. And
they talk about working memory. They don't talk so much. Right. And it means a different thing
to the linguists and a different thing to the cultural anthropologists. By the way,
I include them because they were the people that have been studying distributed cognition
and collective intelligence. They matter. Yeah. If you think about it on this analogy,
it's like they're different countries speaking different languages. And here's the thing.
That has great value. Specialization has great value. I'm not dismissing that. I am not dismissing
that. But each one of these is talking about a different level. And here's what I think
I would state as a very plausible claim. I think it's unlikely that these levels in reality,
the brain information processing, behavioral, linguistic, sociocultural levels are independent
from each other. I think they causal influence and constrain each other. So we are missing
something important about the mind by not getting clear about the relationship between
these levels. We can be equivocating. And we have a fragmented notion if we don't capture
the relations of constraint and causation between these different levels of cognition and mind.
And so I think the proper function of cognitive science is to use philosophy's skills of
creating bridging discourses, creating bridging conceptual, right, vocabulary, theoretical
grammar, so that these different disciplines can talk to each other in reciprocally reconstructive
ways as a way of converging on the causal and constraint relationships between the levels,
rather than trying to compete or say the bottom level is the only real level. So that, for me,
they all live together. They are doing, and I'm sorry to evoke it again, they're doing
opponent processing between each other. And that's what that's what that's what inhabits me
when I'm doing cognitive science, that vision. I call it synoptic integration.
Yeah, it's, well, it's wonderful to see. So, so, I mean, like, I think we,
that's the cognitive scientists that I'm aspiring to be. I think you've called it a big picture
cognitive scientists as well. Yes. And one of the things, one of the, and I felt very lonely for a
while, you know, I was doing relevance realization, which is a big picture. And then, to my great
delight, another big picture for ecocide down the road. And then to my even greater happiness,
another big picture came down the road, which is, you know, the predictive processing framework.
And I think they are more convergent than adversarial. And I, well, you've heard me arguing
about how we can integrate them together. Excellent. Yeah, I would say maybe it's just
bias. Active inferences or physics processing is a big picture cognitive scientists from the
physics and the maths, all the way, well, what we're trying to do to the phenomena,
to what it is like to be a, to be a human being, to have conversations like this.
John, it's, I, it was, you know, I can't say it was better than I expected because I knew
it was going to be wonderful, but you're full of just thrilling insights and speaking to you,
listening to you is always such a wonderful learning experience where that happens in flow
without flow. But I just wanted to thank you so very much for, I know you're extremely busy,
but for giving us your time. Where can people find you? What have you got coming up? I'm sure
people are curious. So the most immediate thing for this conversation is the talk I gave at Leiden
on the predictive processing symposium. It's up on my channel. I think it's the second most recent
video on my channel on YouTube. Where I try to go into the nuts and bolts of how you could
integrate predictive processing and relevance realisation theory together. So people might
find that and I've got a lot of good feedback on that for being sort of clear and a good argument.
So I would recommend that when people are interested in the broader implications of this,
awakening for the meeting crisis and then after Socrates also. After Socrates is where I take
all of this stuff and how do you turn it into practices in order to overcome self-deception
and enhance relevance realisation, become more wise and virtuous. And so they can take a look there.
The arguments around neoplatonism, there are several videos around that. I try to connect
neoplatonism to foreecogsci and relevance realisation and predictive processing as we saw it in this
podcast. But in the neoplatonism, I'm working on my third big series, walking the philosophical
Silk Road, which will be on Zen neoplatonism, trying to see if we can bring an integration,
an opponent processing, not an adversarial one, an opponent processing between Zen and
neoplatonism to give us a rich philosophical framework by which, like the philosophical road,
we can trade ideas and move between worlds without having to descend into, well, tribalism
and other such things. Wonderful, wonderful. Well, again, it was absolutely my pleasure.
I apologise. I've got a slight cold. So if I've been a little sniffly or nasal,
we can blame it on the London weather. But I'd love to have you back on at some point.
Your work is truly inspiring. So thank you so much, John, for me and the Institute.
Thank you, Darius. I'm happy to come back on. And if it turns out that Mark and I
come on together, that would be thrilling as well.
Great. We will definitely get that sorted. All right. Thank you.
Thank you.
