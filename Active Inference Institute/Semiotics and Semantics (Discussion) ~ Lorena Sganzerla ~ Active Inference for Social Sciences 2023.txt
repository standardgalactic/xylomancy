Hello and welcome. It is September 12, 2023. We're here in the Active Inference for the
Social Sciences course at the Active Inference Institute, and having a discussion section
on semiotics and semantics here with Lorena Ganzerla. We're going to be having a fun discussion,
I hope. If you're watching live, please feel free to write any questions in the live chat.
If you thought about joining and you weren't sure, it's not too late. Otherwise,
we're going to pick up on some key points from the lecture and on the topic and see where we go.
So, Lorena, welcome back, and however you want to begin, let's go from there.
Okay. Hello. Thank you, Daniel. So, let's try to recap a little bit where we left off during the
lecture, just to remind us where we were. Like, my point, what I was trying to articulate was the
idea of what does it mean to talk about formal semantics in a way that is not really loaded,
because it's an interesting thought to have a semantics that is actually only formal. In
principle, it would be relative to meaning. In the notion that Active Inference is trying to cash it
out, it's more like an idea or a way of modeling how we deal with meaningful situations. And she
understand that in a more interesting, more embodied and more concrete way I was suggesting that we
could use bio-semiotics as a model and as a theory for living creatures, like language users, to
navigate the realm of symbols and give one example, which came from James Scott, which is the European
forestry that comes with a practice, understanding this scientific understanding of forests as a
practice that allows us to refer to meaningful things in the environment in terms of what is
valuable, what's interesting and what is not. And interestingly, what is more important also
from what becomes valuable, it is what is cropped out from the meaningful perspective. So things
natural parts of nature becomes left out or understood as something that is not desirable. And you
just understand what you don't want in your articulating principle as weeds or something that
you should get rid of in respect to what is more desirable in terms of crops and how you understand
nature in a more commoditized way. And I find like this example from Scott kind of very, very
elucidating. In the book he creates this, in the book he's talking about states, how we articulate
life around one specific notion of state. But in this specific example, he has the idea of one
official observer. And this official observer establishes a principle of meaning in a way you have
to have a handle of nature. And that also articulates how villages and how practices around
agriculture and how people relate to each other within these practices gets organized.
Specifically for one interesting point that he makes that is to appreciate the constriction of
that is like a vision that notices not what within the meaningful crops, but which is left
outside the field of vision. And I bring that specifically to understand how the fragmented
principle can or could be connected to a generalized synchronization over time in relation to those
symbols and those practices in terms of niche construction and how those how this niche
construction brings along with the symbolic use of language predictive value.
Thank you. Brinn want to bring up any thoughts on that or any other pieces or I'm happy to add a
comment. Okay, guess not. A lot to say there. There was a little bit of a double play with what
is cropped on one hand what is cropped is the industrial crop that is being prepared. And then
the other side of that coin is what is cropped out. And what we crop in is the part that we're
paying attention to. And we can't pay attention to everything. So it's it's like two sides of the
same coin, what we pay attention to, what we include in attention in our cognitive awareness
leaves the shadow, which is what we exclude. And that could be like the weeds or the other
ecosystem services. So by highlighting the meaning, or one dimension of meaning or one stance on
meaning, that only it's like a seesaw, that becomes salient to the extent that something else
must be de prioritized. So that's how we accentuate these distributions of meaning. And what do we get
from active inference and free energy principle beyond, for example, what's provided in seeing
like a state? I think there's a lot we can say on that. But one piece is we get a process theory,
a real procedural approach to how different systems come to do sense making and cognition and
action. So just describing the lay of the land, or the history of forestry in Europe, or any other
state of affairs in the world, merely describing it may not even help us determine what's going to
happen a short time later, let alone a long time later, or what might happen in a very different
ecology. Whereas if we understand the processes of sense making and decision making that different
kinds of cognitive agents do, certainly humans, also those states as cognitive entities, which
is what seeing like a state or thinking like a state entails, we get a process based view
on what otherwise might be merely descriptive. And along with that process based view,
we gain an increased ability to make unique explanations, predictions, accounts, and so on.
Yeah, we can. We can also understand it in a different perspective in terms of realizing what
becomes sensitized and what becomes desensitized along the process. So you can possibly model
that using this kind of tools and understanding how that happens over time, right? I don't know how
much in terms of prediction of things that we're not foreseen in these descriptions, we can
achieve in fact, you can achieve some level for sure, but like that system should be this side,
how that delivers a very all-encompassing prediction in this kind of, in this case,
is they don't believe it can, right? I don't think that's the purpose as well.
But we can at least have, which is might not be as positive as we want, but I think we can
understand how we can gain some understanding in this process of being more sensitive or less
sensitive to specific primes and how this organizational principles, how powerful they
become over time. Yeah, I'll read some comments in the chat and then Lorena or Brent feel free to
just give any thoughts. Just upcycle club wrote, hello, biomimicry can enhance biosemiotics by
showing us how nature solves problems and creates beauty through signs and codes and by encouraging
us to apply these principles to our own creations. Yeah, the idea of coding is an interesting idea,
but to talk about codes, I don't think we, that's my take, right? I don't understand like you have,
we haven't coded any type of principles within our cognitive ability, but
biologically speaking. However, you can understand these encodings in terms of becoming more or less
sensitive over time to environmental cues. As the example in terms of, I use the example of
forestry, right? So in that specific case, this, what becomes more, what you become more sensitive
and the more you organize your life or social life is organized around specific principles,
then you can make sense of these relational stories instead of just leveraging one full
difficult to explain notion of encoding in terms of social cognition, because it will be hard to
explain how the brain will be encoding these specific symbols, but it can be cashed out
in the environment, relationally, in terms of those organizational principles.
And then you have this idea of biomimicry, like this reiterations and how that comes along with
to explain what this mimic or this mean will be then,
of it's not so straightforward, I think.
Well, certainly decompiling the source code of nature is somewhere between challenging and
misguided or impossible, but that notion of a code script for biology has animated discussions of
life going back to, for example, Schr√∂dinger's What is Life? He basically says there's two
aspects of living systems. There's their organizational capacity, their negentropic
capacity, and then there's their code script, their aperiodic crystalline informational
repository. And then another place that coding comes up a little bit less in the source code
space is predictive coding. And that's, in a way, highly compatible with active inference
and gives a deflationary account on how the semiotics are encoded, rather than saying,
well, this is what this variable in the source code means, or this is what this codes for,
or here's a code switch. Predictive coding is like saying, we're not even going to touch the
semantics of what the sign is itself. We're just going to hypothesize that the way that
information about the sign is transferred is through this maximum information signaling approach
called predictive coding, because predictive coding arose out of video compression algorithms.
And only at the end of the 90s was found to be increasingly relevant for neural circuitry
and so on. So it's another example of where like a process based approach
ends up deflating or reframing the otherwise semantically loaded question.
It's like switching out the question of like where we're going to be with how we're going to get
there. And instead of only focusing on the meaning of the signs, first off, as if the meaning of the
signs could be discussed outside of their implementation. And then even if we could
figure out what the signs were, we would then just turn around and want to know how they were
transmitted. And so predictive coding or predictive processing, in a way, short circuits that or
inverse it by first looking to explain how information is transmitted that could support
semiotics. And then in the context of biological systems, we naturally have biosemiotics.
Yeah, I would ask the question when you talk about information being transmitted,
right, what that actually means. And I think that's a very, very big
topic and a very large discussion in terms of information theory when specifically applying
that into biological systems. I think there are some interesting people working on information
that makes the case that Shannon has a point. And he's really interested, not in the semantics
or in the meaning or anything else, it's kind of interested in the problem of transmission.
And when you talk about transmission, it's worth to ask what is being transmitted exactly in the
terms of signals, even if you're capturing specific patterns and you think that the
pattern is this thing that will be transmitted in that sense. But that would be a worse
question to understand this notion of what is actually being transmitted in that sense.
This information theory is focusing on this notion of the problem of transmission,
and then all the concepts that come along to explain that in terms of uncertainty or noise
and everything that impacts this transmission of processes. And
if you're saying like we're transmitting information in this sense that is breaking this
semantic code apart, yes, it is, because like the problem is not focused on that.
It's focusing on the specific correlations that we have that we call it.
They are mentioning as information and how these correlations are an issue from the cat go
from what is being picked up in one side, being correlated to what comes into the other side.
How do you lose or gain more information in that?
The deeper question here is how can you say that you are actually gaining or losing that
information because you are defining this correlation that could be transmitted or not
from the cat go? If you don't have that, you don't have anything being actually communicated.
So with that in mind, you can explain these concepts in terms of function and then there's
a bunch of theories that navigate this sense of signaling that is specifically only functional.
And then predictive coding tries to push that a little further maybe,
but then you have to explain in a deep sense how this information is being actually transmitted
and processed. And I don't think that is really, really as obvious and as clear as we think it is.
Specifically, when we're talking about this biological
way of nature navigating this process, this signaling,
we have to talk about here because the correlation, if it's defined,
are initially like from the beginning, you can only have this kind of transmission for
someone specific that can be able to understand that in the other side.
Well, certainly whether we're talking about a chemical pheromone that requires some type of
receptor or something more ephemeral like language that requires more of a semantic reference frame,
there's no receiving the message without the sender. It's like they're kind of the two sides of
the phone call. I'll ask a question from the chat. Love Evolve. How about cultural encoding
and principles in contrast to organizational? So how do we think about
cultural meaning and is that similar or different than organizational?
Yeah, that's a good point. I think if you take very seriously the example from
the forestry is a practice, then I think it has to be organizational in that sense.
There are many navigates this organizational practice, this organizational story that
that impacts not only communication between agents, but also how
the environment will be interpreted. So in this sense, it will be transmitted and repeated over
time because it has a history and cannot ignore the history of these practices being pushed
further and replicated through generations. So
the way the villages will be organized in terms of that specific practice, for instance,
can be understood in a meaningful and cultural way that organizes life in virtue of
some specific principles that sensitizes agents towards specific directions.
And I think
I don't know if you get my point. For instance, you can talk about
if you think about archaeological findings and how archaeological
descriptions of specific villages and how they navigate this mapping out these archaeological
sites. They usually know exactly if you have some kind of history already from these communities,
how that city will be likely to be organized. First off, where is the water? And if the water
is in certain directions, probably there will be certain kinds of relationships with housing and
communal housings. And where are they going to place their dead? In relation to this kind of
specific organization principle, the water is here, so plantations will be not so far away from that.
And this city organizes, like the village organizes a little bit in this sense,
and that builds up cultural practices. At least archaeologically can be explained as such.
I thought of something similar, organization being the logistical or the operational
structural aspects. So those would be the roads that connect the forestry outposts or
the circulatory system that connects the different organs of organization. And then the culture is
a cause and a consequence of organization. Organization is the enabling conditions for
culture to arise. Okay, so given this road network, what cultures arise? How similar or different are
they convergingly? What are their practices or their narratives that are shared amongst these
different outposts? Or in the bodily example, okay, given the organization of the organs,
literally the organizing process or principle, then what biosemiotics can arise with glucose and
insulin and glucagon? And what culturally can arise, maybe even in terms of the generative model of
encultured agents as a function of organization? And then what do those encultured agents do
to the extent that they can modify organization? And so these kinds of
unrolling cause and consequence relationships can be hard to disentangle because there's not
like a clean single starting point that can be separated out. Or because it unfolds historically,
it's not exactly a reaction in a test tube. So how does active inference give us an entry
point into thinking about this? Yeah, I think that's one interesting thing about active inference
that you don't really need one, you don't really need an origin point, right? You can start modeling,
you start understanding that at any given point and build up from that story and see how it unfolds
over time. I think that's the most beautiful idea that you define your parameters and then you see
from that parameter that can be arbitrarily defined and you can navigate how things change
within those parameters in the generative model, right? When you have your like dynamical systems,
for instance, you have your state space, they have some specific range of defining
parameters that set the limits of the possible states that you're going to navigate. And if you
use this notion that these two densities brings about in terms of Bayesian modeling, you can use
these kinds of tools to understand how from that specific parameters updates,
what we narrate in active inference as if belief updating can change over time in these terms.
That's a very nice point. It reminds me of Bruno Latour's actor network theory or ANTS,
which kind of advocates a similar approach to what you described, which is like enter
anywhere open-mindedly because in an iterated modeling or iterated analysis setting,
the first proposal or the first trace detected, we know that's not the whole picture. There may
not be a whole or only picture, so we need to enter and iterate. And then with active inference
specifically, because of the compositionality that we get within a layer, collective behavior,
and then also the kind of nesting smaller things inside of bigger things,
we can always build something and then we can go, oh, wow, it's like there's a lot of top-down
influence. Maybe there's a higher order factor or slower factor or a contextual factor we should
consider or, oh, we were abstracting across these smaller things inside, but for a later day or
if relevant, we can dive in. And so then it allows a light hold or a grasp on the proposed
generative model. Obviously, it's map not territory, but even beyond that, we always know
that we can expand laterally and across scales starting from anywhere in an iterated modeling
process without our first or even 11th model being proposed as like the accounts of some
complex cultural phenomena, which we're always going to only ever have our own perspectives on.
Yeah, I think you don't really find that you'd be so all-encompassing like you have one model that
will model them all. You can navigate those models in these more instrumental terms. It raises
different questions when you put things like that in terms of the ontology of models and
models and theories and sciences, but they can be also described as
tools for grasping and describing phenomena in a more non-committal way.
How much that smuggles in philosophical or more ontological problems, it still I think under
like debate, but it is still a tool to bring insights to think about specific cultural
collective phenomena, which is not. It's complicated because I think what I'm getting at,
I'm kind of like going back and forth, but when you talk about social sciences and modeling,
usually you have like ways of modeling agents or ways of modeling collectives and active
inference is trying to come up with a modeling in which you can understand agency and collectives
within the same modeling schema. And I think specifically for these cases, if you're interested
in understanding types of cultural phenomena among language users in specific contexts,
you can at least partially understand or gain some insight in this agent-collective relationship
that that is a little bit more interesting than we have found so far in the social sciences,
because you can have like or specific understandings of means, but then how the agent, where is the
agency in that? You lose a little bit of agency. When you're trying to understand
only agents, then you don't know how that kind of scales up, because active inference tries
and offers these scale-free modeling tools that facilitates this conversion into agents
and collectives. I would be interested in asking you, actually, how do you navigate that when you
talk about social phenomena in ants or termites? Because then, yeah, you have very specific
coding limitations, I guess, for these social environments.
Yeah, it's a great question. It's also, whether it's a open wounds or a dirty closet that's just
shut, there's actually a lot of ambiguity and unresolved tension around, well,
is the ant colony social? Are they social insects? That reifies the nest mate as the individual,
and then what they're doing is like when we hang out and talk. So reifying the nest mate as individual
makes the colony social, but if the colony is individual, then what nest mates are doing with
each other is not social any more than we would describe the liver and the kidney as having like
a social single cellular interaction, but we know that would be missing the point.
And so there definitely is a tension with some of these evolutionary lineages like ants being
monophiletically obligate you social, all and only ants are you social, they all live in the
colonies, there's no free living nest mate, whereas other parts of the evolutionary tree,
there are life histories that do look a little bit more like social collaboration that can then
dissolve. And so knowing what level of lock in makes something social, when are we socializing,
and what level of lock in goes beyond social, and it kind of like makes when the blanket is so
strong around the social that, like for multicellularity, that it's kind of losing the social
feature again. Because if we just use social to mean the connective tissue or the kind of lubricant
or the spaces between everything, then it means nothing. So a real tension is what
space does the social account for? And is this going to be a
concept with a lot of creep? Well, it's a social relationship between the roots of the tree and
the fungus. And it's a social relationship amongst the molecules in the test tube. Is that too
broad of a social conception? Are there downsides? Or are there tradeoffs associated with a broader
social concept? Do we dilute what the social means? And then on the other side, might we exclude
phenomena that could importantly be considered social? Well, that's not social, they're just
talking on a train. It's like, well, that's the other side, if we were to have carving out
encounters that we do want to include as social. And is there a true social? Does active inference
help us sidestep or at least negotiate this territory? Because we could develop
a generative model or an ecosystem of shared intelligence with one person and
two Internet of Things devices and a bird and a metronome. And just say we made what we made
and then leave it as a second order interpretation, whether that is a social setting?
I mean, I think you are pointing at like how the granularity of those scales, right? If you have
a model that you want to want to everything that you already have, it's probably not interesting
and uninformative, because you cannot define those limits of what you're trying to understand.
And in the other hand, when you do that, when you define those limits, if you're too narrow or
you're going to leave out, you're going to idealize also in a way, right? And leave out many other
parts of the system that you're interested in. But if you don't do that,
if you don't make this decision when modeling, I think, then how
you can have any access to the phenomenon, right? And to connect this to the forestry.
So in the forestry example, the disirata was lumber. Now, that may have been a very narrowly
scoped desire, but it's a relevant thing to want this resource. And then industrialization,
science as a process, professionalization, those allow the description and the handling and ultimately
the kind of top down legibility and control thinking like a forestry company. Now,
with respect to the social sciences by analogy to forestry science. So now we're entering an
era of increased legibility and control of social systems and human natural capital and attention
as a resource, trust as a resource in a way is being cropped analogous to produce the content
of lumber, but now there are social content. So as the social goes from being just only simply the
water we swim in, not something that's even compared counterfactually to alternative cultural
possibilities per se, but falls under the scope of the professional management like forestry.
Then that's when this discussion of well, what's the lumber and what is the weeds that are being
pruned and what ecosystem services when we pay attention to certain parts of human social culture
and when we seek to make more of this kind of lumber, what else does that come along with
and what decisions come into play.
And that comes along when you see the process
of
Instagram, I don't know Twitter after what happened to Twitter, but
But yeah, in terms of attention pruning, you do have that very effectively already happening,
you can see how that happens efficiently in elections, for instance. It can be very,
very easily manipulated. And we saw what happened in elections, for instance, in Brazil or in the U.S.
And well, all over.
You navigate a system of attention organization that selects in only what he thinks that you're
interested in. In the effects of that, in terms of decision making and in terms of trust, in terms of
diversity of discourse, we have seen that it can be devastating.
So the question would be like, how can you make this a little bit, how can you use active imprints
and these tools that we have to make this kind of technology a little bit more inclusive
without being super disruptive? Is it even like a possibility? I really don't know. I think it's
an ethical problem that we have when we talk about social systems and these principles of
attention exclusion leaving things out.
A lot to say on that with modeling and interpolating and models, whether it's
large language model type or linear regression type, it is able to
interpolate to put data points within an enclosure of what has already been described.
And Bayesian statistics and other types of prediction algorithms are not immune to that either.
If we have some prior distribution belief, we believe it's possible for it to be between 20
and 30 degrees outside. Then when we get data inside of our bounds, we can converge and that
actually tightens our beliefs. Not always a bad thing, of course. And then outside of the scope
of the possible, those data are just seen as noise and they may not even be integrated. So
then that can lead to a reinforcing process, not necessarily an adaptive one either, where information
that's confirmatory is used to ratchet and increase precision. And then information that is not
confirmatory is discarded as not useful. In this case it doesn't even enter the landscape of attention
of the user. What I was thinking in relation to this idea of
forestry is because we have now organizational principles that are more populated with
information and attention grabbing kinds of prompts. We just form the same principle into
a harder to grasp process. It becomes more complex. It becomes harder to describe.
This is the process of understanding that in terms of forestry is kind of way more grounded
when you apply that socially to this kind of environment that we're talking like internet or
this highly volatile and virtual in principle environment. It becomes much harder to assess
what is being pruned out or not. You just don't know. It makes it more clear that
there is a process of pruning. You have no control of what is being taken out.
You have no idea what's being left away from your perspective of attention.
So to this topic of intended or unintended semantic pruning I think
this has helped me identify attention. If we want to talk about the semantics or semiautics,
biosemiautics, whatever we want to call it of the letter E in relationship to letter A,
we're looking for an account that might convey letterness, but we're generalized above enus
or anus. So in some ways we've erased or abstractly generalized away from the particulars
of the sign's meaning by taking a semiotic perspective. And so it's like we got into the game
to have a semantic account of biological phenomena or of any phenomena for biological entity,
yet this process in a sense distances us from the particulars that actually do
grant it that meaning in the actuality. Like if we walk into a sacred space and it's like,
oh well that is just doing that over there and this architecture is doing this.
And because of the layout people must use the room this way.
That's removed from the actual meaning which is the cause and consequence with the organization
and culture that we discussed. But that prima facia account
doesn't generalize. You get any generalization that we make so that we can talk about multiple
places or multiple letters on a common accounting framework is going to remove those particularities.
So it's a very challenging catch 22 whether we want to really
account for the n equals one and maybe even live and act and play and work in the n equals one
versus develop something that might be satisfying and cut and dry, but it's always going to be on
the sidelines with respect to what it actually means. But what do you mean like is I don't
understand what you're what you're getting at like is it you mean like it's generalized or
not generalized I didn't get that. Like when we have a general when we generalize
when we ask what words mean what what words mean beyond any given word we've lost touch
with what any given word means. But words are what they actually mean in a situation.
So it's just in this scientific approach to meaning semiotics and semantics.
We have these two tensions or a tension to reconcile between actually giving an account
of the meaningfulness of the specific thing versus taking a more scientific approach which would
be gathering a group of similar things and finding their shared attributes
which out of necessity must abstract must crop out features that are are empirically or
anecdotally taken to not matter like we abstract whether it was a Monday or Tuesday that we did
the experiments we just combine all of our replicates together when we do the scientific analysis.
You mean you mean if you generalize the practice you lose
what you're being if you generalize it too much you lose everything that's meaningful to you
in terms of like for you formalize it and then you have no you have an empty semantics you have
a semantics with no meaning that can only be meaningful in terms of how you apply that in
terms of specific practices. Yeah it's like I have a framework for you know the formal meaning of
letters within words within sentences within paragraphs and then it's like well but
now what's your next n equals one word that you're actually going to bring
it's not just about building some abstract scaffold for bigger and bigger boulders of meaning
at some point through our embodied thought and action
in our experience it is going to come down into the particulars
and it doesn't immediately seem clear that simply generalizing further
brings us there. Yeah yeah I don't really believe you can have that
kind of generalization I think we attempt to build whatever what I see that's the
interesting aspect of the formal semantics you try to build this more general
understanding that's just formalizes to model but for that to be meaningful it has to be embedded
in a way of practicing it like in a forestry practice you have to be embedded in a cultural
environment in which that can be actually observed in terms of what happens when a
generative model is being updated or not. Is that what you mean because otherwise I don't
really understand how it becomes too formal it becomes too abstract in terms of some I would
not understand what that is. I'll think of a little more. Bryn or TJ do you want to add any thoughts or
any questions? Yeah sorry I think like I don't have a lot of context I've been like following
some of the discussion but not attended a lot of these calls I'm like yeah yeah I don't know I think
yeah I'm in general just sort of interested in trying to understand the relationship between
yeah like sorts of like constructionist epistemologies and yeah like generative models
and active inference style stuff and how active inference style like yeah what are the philosophical
commitments that active inference involves with respect to knowledge and epistemology and
there's a sense in which like rational choice models often assume a certain sort of like
objectivity to beliefs and then desires are where most of the degrees of freedom lie or something
whereas there's a lot of like issue like there's a lot of things that come up once you start talking
about reflexivities where concepts themselves become self-fulfilling prophecies what you believe
about what your beliefs about society ends up shaping the society itself so there's a sense in
which there's a score dependence between the object of knowledge and knowledge about that
object itself and I think yeah like I'm sort of interested in like how the active entrance
ways of thinking about this offers what perspectives on those questions and stuff like that um yeah
thank you great questions yeah so when you talk about the object of knowledge and the knowledge
itself and active inference
I think you can think of in terms of this
well there's a few ways to think about that I guess
uh the knowledge itself it has to come epistemically from where your agent
is actually embedded and situated in specifically an active inference it's embodied
it kind of needs to have a model the model is modeling a body is modeling a body that is in
the world and it's all the time uh situated is never disconnected to its environment and its
history and how the history of that environment right yeah uh but if you think if you push that
to the object of that knowledge I don't know how how different
that will
how different how can you differ differentiate that so sharply when you talk about active inference
because
if you think of uh in terms of alternative model did what would be updated comes is updated from
a prior that is always directed in this body in this situated realm so they sort of conflated
as I see maybe a maybe a mistaken but they sort of correlate in how you're gonna update your
generative model which will be at the same time in at the same time what you know and what you the
object of this knowledge still I sorry if I can just like uh raise a question to that yeah so I
think like I think that there is a sense in which like with respect to something that in
epistemology would be called self knowledge there is there is a question here that the the active
inference agent has this model of that is like situated in the body or like in in its like
like structure and is also modeling that structure itself and there is like this issue of like
where where yeah like the belief is not unidirectionally dependent on the object sort of a thing
but has this feedback loop thing comes up there but there's another way in which I think like
where this sort of thing comes where even if the object is outside of the body of the knowledge
I think that that could still come up so for instance if I live in it if an active inference
agent lives in a society of other active inference agents where currently all of
them defect on prisoner's dilemma but maybe like on further reflection they would want to
like again like I don't know what further reflection would mean in the active inference
sense but I'm like just saying in the intuitive sense like that what would it mean for them to
like go from one fixed point to another fixed point where they're all cooperating or or something
like that and that that I think is not clear to me like how that shift can happen in active inference
where it's not just purely using the empirical information to keep running the the the middle of
the of your like free energy equation but also recognizing the contingencies and then identifying
those contingencies to make something like shifts from one state to another like if if I model that
the society is a cruel space and if everyone models the society is a cruel space then we will end up
creating a society that is a cruel space but if only we could recognize that our belief or our
model that society is a cool space is a contingent belief and we could all somehow negotiate or
communicate and shift to a different belief about what society is and society is a kind
place then we will end up creating that kind of society or something and that sort of like a belief
about the thing that society is it's not entirely within the agent like it's sort of it has a weird
intersubjective character so it's not entirely outside of the agent either but it's not entirely
like internal to the agent either or something yeah yeah you can think of that like you're talking
about active inference action comes first right you have to you don't have the knowledge like
inside your head waiting for you to to push that out of the way action has to come first so if you
if you take that as a principle an organizing principle it depends on the contingency of your
actions the possibilities might be limited by your situated condition but they are limited it
doesn't mean that you don't have like a range of options from that state space in which you
can go you can navigate so you can navigate it for the good or for the bad but it starts with the
action perception loop it starts with the action a lot of few other pieces on that tj very good
point like when we see the pragmatic component of action as self fulfilling epistemic component
of action having to do with gaining knowledge and the salience of information but the pragmatic
component is about bringing our observations into alignment with our preferences and then you identified
two related settings one of them is like pure intra subjectivity like i expect myself or i find
myself or i habitually think about x well that's kind of a trivial self fulfillment because
thinking about something is its own fulfillment and then when we're in this second person or
social space we can agree on little performance are or on a game and games give evidence to that
that when people are able to perform communication or message passing such that new expectations
or preferences are set whether more top down like more seeing like a state or more laterally
more like collective behavior then those regimes can be embodied and then you brought up a very
important point about the awareness of the contingencies or where awareness is of adjacent
possible or of counterfactuals so the body might be we could model its morphology as doing some
computation but that doesn't mean that the the morphology has an awareness or can explore a
counterfactual like bodies are not always exploring every counterfactual because skin is in the game
but again mentally it's very cheap and easy to consider counterfactuals and situational
awareness of social settings especially if it can be not understood but communicated
opens up a space where we're all playing prisoner's dilemma now there's parameterizations of
prisoners multi-agent prisoner's dilemma where tragically we just all defect all day and never
learn there's also parameterizations where you just start all cooperating and never defect and then
the interesting settings are where there might be like phase transitions or where a perturbation
moves the system from one attractor into another attractor so there's just a lot of richness and
that's the work of building generative models in that iterated modeling process
to to unpack and refine and active inference isn't going to have a stance on the prisoner's
dilemma we can use active inference to describe the prisoner's dilemma but active inference isn't
going to come down on on literally even a little two by two game theory matrix so we can then
extrapolate that active inference is not going to come down with an opinion on something significantly
more rich and real than a two by two game theory matrix and so that work is what people enact
in applying active inference
right and i think like my question is something like but insofar as like humans try to constantly
improve their social games how can we model that sort of a prior or your actions or policies
that enables that sort of like progressive
improvements or something well
you can we are assuming that we're trying to improve right we we don't know that but you
can model them as improving but like following Daniel's lead you we're talking about this specific
games and contingencies they they did this this transitions from one state to another
specifically if you're talking about this modeling of social actors and talking about
several actors if your model involves several of them will not be really linear right you don't
have like a easy smooth transition of improvement you can capture over time as modeling how they
might tend to go towards a direction and understand that as improvement but that takes
specific iterations that will not be fully linear i guess specifically if you want to understand
error and improvement instead of try an error but try and adding up into this error like
error improvement but when you're modeling specifically with dynamical systems for instance
you you you're not going to see a full linear story and i don't think you're going to see that
if you're modeling using active inference and multiple agents agents
i'll add one piece there so how can we go about modeling multi-scale social goals
so we could think about different citizens in a region and they the modeler is going to choose
what knowledge to realize in the generative model like what you put into the calculator it's going
to calculate upon now this happens to be a elaborate stochastic method but if we only
tell people yeah there's just your personal income optimized for that your preference is to have that
be higher well then the simulation is going to unfold a certain way if we say well there's your
personal financial income and then there's your city and then there's your region then
that opens up through through different mechanisms you know maybe an individual
goes flat or neutral on the personal in service of a larger win at a higher level well now what
if the modeler says it's not just about the financial income now we're also going to have
the secondary criterion well now different agents could attend differently to those two
difference outcome variables and maybe there's one simulation where 50% only care about this and
50% care about that and it works perfect or it doesn't work it's like a broad surveying you know
or lego set or or grammar or or active inference ontology for scoping very broadly and very
inclusively but all the work is in the real simulation developments and sweeping because
very little could be said about a game theory game if you didn't know what the parameters were in
the matrix you wouldn't know whether this prisoner's dilemma was going to be like an always cooperate
or which agents with which strategies would or wouldn't cooperate if you don't know what the
matrix looks like so before the values have kind of been filled in it's just like actually describing
the adjacencies and the counterfactuals and the contingencies of our scientific model
but that's still prior to having the model in hand and the model you know so now we're looking at that
tree in the european forest and it's like well if i had this tool then i could cut it down this way
if i had this tool i could cut it down this way or i could wait it's like that's
that's alternative actions about that tree now in the social science setting discussion of different
scientific methodologies are like counterfactuals about that social tree
yeah and specifically if you're navigating these kinds of game theoretical models if that's what
you're interested in you can even define in terms of prisoner's dilemma for instance
specific values just see what happens when everybody deflects and you know how frequent
modulate those frequencies in terms of specific in multiple iterations how how how are you gonna
build up the weight or the tendency of deflecting again if your neighbor deflected once and
deflected twice or three times or and see how that will accommodate over time how many times
this agent will change its behavior until it stops changing the behavior but that you don't really
know but that's that that again you use you might use a bayesian understanding a bayesian
model for that but it not necessarily explain uh um
it does not necessarily explain the action fully i mean social work you just you're modeling only
interest of that specific actor i i have a slightly meta question if i can ask both of you uh i'm
not sure how these calls usually go uh i'm curious what are your interests in active inference what
do you think like what brings you to active inference and like what do you think what do you
think active inference adds to our theoretical understanding and in what ways or something
right now go for it
well i think i was trying to touch upon that before and how we can
if you're if you're navigating for instance behavior in terms of game theory this kind of
modeling if you're talking about like trust games for instance you're gonna understand how this
is duadic interactions if over time specifically over interactions but you don't have an account
of change because i have very limited options of actions and
you don't have an account also on scales and i think active inference tries to add a little
bit an account on how you can scale that and how uh how you can add more parameters into the game
and see how they evolve with a more clear uh understanding a richer understanding that for
instance when you talk about specific interactions in game theory
so when that's one one aspect that active inference kind of contributes another point is
because we have this parameterization that is specifically in terms of belief updating and
also in terms of dynamics we are always talking about agents that will be situated and embodied
and have a very specific
synchronization with the environment all the time because when you talk about active inference
the action comes always first so you have a less you try to have a less reductive model
specific and when you want to model cultural agents and collective action i think that's
kind of desirable that's what you're looking for is it also your area of interest sorry is it also
your area of interest mine or is that Lorena's area of interest what do you mean oh sorry like my
question was also like what brings you to active inference and i think you answered a lot of ways
and which active inference adds theoretical value but i wasn't sure like if that was also
your subjective interest or motivation oh it's my subjective interest yeah i'm curious to see
how that pans out right i'm interested in how that helps us to to think of this type of
phenomena and i'm very interested in how this relationship for agents to collectives and back
again work like and i think you might give us some well you give us some very insightful way of
modeling these relationships in navigating is as you want because this this uh feature of being
scale free is kind of helpful in to looking things you can you can define your uh mark of blanket
in terms of what you're interested in right and see what happens
i don't know yeah i'll i'll just give a few thoughts even though also surely some of these
thoughts are are scattered um you asked tj what does active inference add to our theoretical
accounts of the social it does many things in in my view and that's what makes it so valuable
epistemically and pragmatically it gives us the expressivity within a scale to describe
collective behavior and across scales to describe nested systems so that brings continuity to
discussions of the social with broader discussions of the biological ecological
computational physical and so on so that's a multi-scale transdisciplinary element active
inference provides us with legible first principles which can either be taken instrumentally as just
heuristics and also in certain situations can be viewed empirically as justifiable first principles
and then from those legible first principles which are not english specific they're already
in a space that has a lot more
possibility and promise than for example a mere enumeration of important adjectives or nouns
we can develop lists of important adjectives and nouns when we have a broader cognitive
modeling framework and so this methodological turn then supports just a tremendous diversity of
thought and work instead of asking us to kind of go through the eye of the needle and you know get
on board with this one ranking of features and then try to apply it more broadly that's like an
overfit before the cart situation with active we can expand the methodological discussion
connect it to theoretical physics and mathematics in ways that really haven't been seen before
and then that opens up more than it closes down it brings up more questions than it resolves in
and of itself but it opens the questions that can be resolved like what generative model can I make
that will keep the temperature in this building livable but active inference isn't going to
have a stance on what you should do for that building so we need to in a way take a step
in the methodological direction which I see as moving towards active inference
to enable a million steps in different directions
I have a bunch of questions here I think one is probably just a reference question
there are three topics that I'll say if you guys have any papers or articles on those things I would
love to like get a reference one is in what ways can we model a collection or an aggregation of
active inference asians as a like super agent or like super like active inference super agent or
something and like how does this like decomposition and aggregation uh like flexibility work in
different contexts like if there's like work that tries to either make informal commentary or
formal modeling either ways I would love to see that secondly just quick on the first just on the
first check out the previous section of this course on collective behavior where I reviewed
many such works great thanks okay is it on the same notion is it linked from the same notion
things all in the same places and in the same playlist with this course same syllabus yes
got it okay um the second is is there an active inference account of
say markets or economic interaction wherein like your prices act as some sorts of like information
signals and like like can can use active inference to then talk about aggregation in
of market entities or something I'm guessing this would also be covered in the same list
indeed people have explored cognitive economics and people are working on it but that doesn't mean
it's a done deal theoretically or especially in practice so keep going it's quite experimental
still but there are a bunch of people working on that I guess I don't remember any specific
paper right now but I can I can look it up and forward to you but yeah yeah it would be great
I can drop my email address here yeah sure the third is probably more tricky than both of these
which is is there an active inference account of natural language um
yes thankfully colleagues like Elliot Murphy and others have explored specifically the
linguistic aspects of natural speech I think Lorena's lecture and area of focus generalizes
a bit beyond specific natural language because we're talking about semiotics and semantics
right in a more intermodal sense however yes there's been limited work from a computational
linguistics and neurobiology perspective on speech okay so then
okay so you said something like first principles stuff when you're making a commentary on what active
inference brings I have still I have I'm still often like struggling what is active inference
offering and I like try to encounter different things I think I enjoy a lot of philosophical
questions at the conversation opens up but like I'm still like very ambivalent about the theory
and when I read like this new book which Friston has not written but like is unco-author I don't
remember the name of the book I don't yeah I don't exactly remember there's a book right which is
like supposedly like supposed to be the canon and like Friston is a co-author but in the
preface he says so so that's the 2022 par Friston Pazula textbook right par yeah yeah I wouldn't
quite say it's the canon since it's a short book but certainly it is a landmark moment for the field
right and when I read that the one thing that bothered me was
it brings up the Helmholtz free energy thing but it sort of argues that by fiat like okay this is a
simple principle it can model a lot of things but that doesn't tell me why I should why I should
trust it like what what is the reason to act why why does this principally to cognition like
what like sure you're positive a very simple principle and then said hey look this simple
principle can explain so many things but well it can it also explain things that don't look
like cognition and like like I'm not sure like there's an I got an account of why that principle is
like uh works or something Lorraine I go for it I'll I'll think of some other ways to say it
yeah you can think of like modeling by construction and modeling by first principles and if
modeling by first principles you have you have some limitations in which you cannot fully explain
some things but the virtue of the model and how the first principle organizes everything that
comes along with the model usually might be sufficient or might be a useful a useful tool
to help you explain that phenomena that based on the first principle that you were bringing along
and that's one way of one part of answering this question I think it might be a big question
for the for the few yeah here here's some short little threads on that yeah we can describe
maladaptive cognitive systems or adaptive cognitive systems whether something's adaptive
or not is always in relationship to its niche like the foraging algorithm that works in the
desert doesn't necessarily work in the rainforest so these systems are not like intrinsically
adaptive or not we want to have natural language that allows sentences that are valid and invalid
and have different kinds of semantics so again this is just an expressivity framework
that enables people to build cognitive models of high reliability or important settings or you
could make something that looks just like a beautiful circuit board and not even worry about
what the outcome is so yeah for sure you can describe all kinds of systems that would be like
having a less than functional methodological system if we said well we're doing the linear
regression framework but we only want positive regressions it's like well no at the methodological
level we want it to be able to do any slope so here in the cognitive modeling setting we want
more expressivity so that we can actually construct the ones that we're interested in
and then how does this really do cognition how is it that a first principles like surprise
minimization or the bounding of surprise through free energy how can that really cover
so many cognitive phenomena that's the question and the play but how is it that
Newton's laws of motion can describe so many objects being dropped off a tower
how is it that Bayesian mechanics can describe so many different priors being updated
and so by understanding cognitive paths as paths of least action which is the free energy principle
a wide variety of models become of a of a similar kind now yeah whether that's useful to a given
person in a given setting like if you make an active inference model of your business it doesn't
mean you're gonna succeed if you make a self-driving car with active inference it doesn't mean it's
gonna work this isn't a guarantee of success but it's a method that can be utilized and we know
that the method reaches different kinds of modeling outcomes and supports subsequent
perspectives and models from where it reaches but we can't a priori limit where the method reaches
to like only the successful ones are only biological systems then we wouldn't even have the
expressivity to talk about cognitive ecosystems with synthetic intelligences
um and when you talk about cognition also we can use this kind of first principles
to model aspects of cognition but you might not necessarily think that cognition is all encompassing
like that everywhere all the same but you can use that to model specific things that you're
interested in in cognitive behavior like adaptivity does it give me any insight to understand what is
adaptive adaptive behavior for instance in which kind of insights do i get are they interesting
are they useful so that's what the availability that this kind of model bring along so you can
you don't have to believe in in the whole story but it gives you a lot of leverage
to ask ask questions and what kind of questions you'll be asking
okay so let's say that like free like active inference and free energy allows me to talk about
systems uh but does it give also give me vocabulary to then classify those systems
in terms of let's say adaptivity would be one property but like there could be other properties
in terms of like how much how rich the world model is or stuff like that or yeah um if you have
a portfolio of generative models you could summarize them according to the tj statistic
you could summarize them according to the number of nodes you could put them into a common environment
or different environments and summarize their activity in any number of ways but we can't
talk about a ranking or a summarization of a portfolio of generative models that's not in hand
this is a framework that lets us build those diverse generative models
and then in a very open-ended way do model comparison model selection model adequacy
all the kinds of complex systems engineering methods that we want
and also I would ask you where do you see a peer or a comparison first principle
you know active inference has legible first principles which are reflected in the active
inference ontology and expressions using it which can be represented in natural language so that's
the talking about it but it's not only represented in natural language other frameworks have other
first principles that may or may not be legible and people may choose different paths to go down
for whichever number of reasons well models like they have the virtue to can compare them and see
which one gives you the best insight that you're looking for well so yeah I think like something
that I could compare to active inference is like say the Bayesian utility maximization thing and
which has a different ontology I'm not a fan of that either like that also I'll just note that
Bayesian utility maximization is a special case of free energy where there's no epistemic value
all you have is pragmatic value and so a special diminished case not necessarily not necessarily
you have value of information and you have explore exploit tradeoffs in Bayesian utility
maximization as well like you like like if you load into your utility function if you can
beg the question and load epistem into pragma you're right then all you need is pragma but
in expected free energy we have epistemic and pragmatic value which is what enables us this
expressivity but I think we're aligned on that right I think like I'm somewhat like also slightly
confused because in the Bayesian utility like between the languages comparing the languages are
such like in the Bayesian utility maximization the exploration parts that are prioritized based on
your x anti estimation on the value of information whereas I'm not sure that
holds true for the active inference model as well that the epistemic exploration
is prioritized or valued in terms of some of the same pragmatic thing as well
you'll have a lot to explore and learn you can make a model that is 80 20 or 20 80 or 100
zero between epistemic and pragmatic there's nothing we can say across generative models
about whether active inference prioritizes epistem or not because you can make a model that's 100
percent or zero sorry I meant more like does active inference allow us to talk about systems
that the Bayesian utility maximization doesn't allow us to talk about yes I'm talking particularly
about expressive power of the language yeah like is it like are the things that the Bayesian utility
maximization can talk about that active inference cannot other things that active inference
talk about that basically maximization cannot two short answers one short answer utility maximization
must cram epistemic value into pragmatic value we gain more expressivity when we can articulate
out pragmatic value which is the alignment of preferences with observations from epistemic
value which is information gain so that's a huge articulation and the second thing is
when you're in a anything maximization framework when you're in a utility function now again
begging the question how you constructed this function that you're trying to maximize
when you're in a maximization framework we have a well-known set of approaches for finding local
and global maxima using optimization or maximization frameworks what active inference uniquely provides
is it describes the path that that cognitive thing takes as a path of least action that
minimizes surprise so instead of climbing to the top of the hill up are we on a foothill or are
we on the biggest hill we're like a ball rolling to the bottom of the hill finding the least
surprising path now that least surprising path can still include novelty and information gain
but it turns out to be a lot more tractable and connected with statistical physics and
quantum mechanics when we talk about the path of least action ball rolling down the hill
rather than this sort of question bag on top of a mountain climbing adventure
Bayesian utility approach but it's up to each person to feel how they want to feel
yeah and I think it's a little a little bit what's in the book as well when you take the
low and high road for free energy principle right because how much you want to have your utility
maximization function being uh disconnected to the pragma to do to the action
because when you're modeling behavior it will be hard to do that independently like you have a lot
of you have way more assumptions you are committing too much to a greater level of assumptions
for your utility function if you don't do that
because with the pragma with with the action first that pragmatizes you you you have reasons
to describe have reasons to believe why that information gain works the way that it does
you can leverage some explanations on that without it you have you have you have a model
that has more assumptions and I think if you have a model with less assumptions it's always
healthier let's say so yeah so I think like that that that does talk about the compare
compared to analysis of the expressivity but I would also say as a meta point that like
I'm not happy with either of those languages so I'm like I'm suspect that both of those languages
claim certain ontological assumptions and I'm like always suspicious but wait but like where are
these ontological assumptions coming from a few other points we tap into an absolutely
meaningful nexus of statistical methods and message passing schemes with active inference if you
can state something in the active inference ontology and construct a generative model then
message passing algorithms can be deployed that contractively compute that model so that's
absolutely non-trivial otherwise it's possible just to get wrapped up in some analytical formalism
but then once you want to do that on a 4k video now you're on square zero with a computer
engineering this is not that way and then I will respond to your meta point with a meta point which
is when we've enumerated the alternatives the one that we like best personally I feel happy with
I'm also open to new alternatives arising but being unhappy when all things considered is in play
why right what bothers you it's specifically on the ontology of
the active inference yeah like I I think like I'm still looking for I don't know what exactly
I'm looking for but I'm I feel dissatisfied with the account given for why Helmholtz free energy
least action thing like
is the central thing here or something like why does it work like why does this principle yeah
there's a lot of funny answers I could give there yeah that that delta that discrepancy
that's curiosity and that's the space of the open and that's learning and that's your unique
contribution to make and that's everything so that's not just a thorn in your shoe that's like
our experience of action amidst uncertainty which is the water we're in and so whether we
take a higher order narrative perspective on that discrepancy being dissatisfying or that
discrepancy being satisfying I think it's pretty good to minimize my surprise there
yeah and you can choose to minimize your surprise through your attention you can choose to minimize
surprise at a higher narrative order like I'm satisfied and complacent that I don't understand
number theory but I use numbers to count objects around me so that discrepancy and understanding
knowing that there's a thousand years of research that could be done on numbers it doesn't unsettle
me but for someone else that might be unsettling and that might lead them to ruminate it also might
lead them to do a PhD in number theory so just different paths for different individuals and
contexts but there's always so many technical and meta levels with active huh
okay so I don't want to like keep you guys over time uh but I would ask one last reference
based thing which is um are there active inference accounts of seeing like a state phenomena uh in
any literature I think I heard you mention it once so I was like you know like this
yeah check out livestream 33 series but also this course that we're literally actually enacting in
with Avel is where these accounts come to roost and where we're creating a space to develop it
and it's not a cathedral for us just to spectate at today but if you want to make an active
inference generative model of whatever social setting when you have the model in hand a lot
of your questions will be sidestepped okay where is the 33 thing that you mentioned if you go to
the page with all of our institute live streams and look in the live stream series like the paper
discussions in the 33 series there's a dot zero video with background and context and then we have
a dot one and a dot two conversation with the authors but Avel who's also the course coordinator
for this course and kairos research like Avel's and and colleagues work has heavily built on the
seeing like a state thinking like a state optimal grasp all these different topics
yeah I'm yeah I'm on your youtube channel I'm slightly finding it hard to find the thing
um if you look up live stream 033.0 or if you go to in the video description of any video
where it says all live streams here go there and search for but you'll you'll find it and you can
always email us or get in contact but yeah and I think Avel's paper like thinking like a state also
can help you a lot to understand how how active inference modeling is useful for the social sciences
in comparison to other types of modeling he makes an comprehensive description interesting
great thanks uh yeah and this is this is our first iteration on this course we are going to
continue bringing new information to the table and supporting individuals who want to build
generative models you know around this area whether it's part of an internship program or part of a
course credit or different kinds of programs that we'll be able to develop but this is the real
thing and we're able to work with people who want to think and do make sense
indeed any closing thoughts on tj then I will go and then Lorena with the last word
um no that this was great thanks thanks for the conversation
thank you well thank you for Brandon tj for joining Lorena for the lecture this was a fun
discussion we never really know where how it's gonna go but I'm glad that we could cover
so many of these topics and probably raise more questions and footholds than door slams so thank
you again Lorena yeah thank you for inviting me and I think active inference like holds a lot of
space for experimenting as well some things you try to see if they make sense and they're gonna hold
up and open new questions and that might be an interesting aspect of uh of the framework itself
thank you everybody thank you everybody for the great live chat comments there's a lot
there I couldn't read it all so till next time bye
you
