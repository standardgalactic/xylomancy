Cool?
Yep.
All right, thanks Daniel for having me,
everyone at the Active Inference Lab.
Sorry for canceling twice.
Life's been kind of crazy with finishing this book
that this talk will be about and having a kid
I'm six months old and I got sick like a week ago,
like right leading up to like, you know,
didn't want to cancel a third time and look crazy.
So this is a very rushed presentation.
It'll be better if it's more of like a conversation
since I haven't even gone through the slides myself once.
And it's gonna get into a lot of things
like immediately like open up bags of worms,
like there's just philosophical issues,
things that people won't agree about like immediately.
But yeah, so this is just gonna be like a small introduction
to the thesis in the book.
And yeah, I'll explain more I guess after I begin.
So yeah, it's called this the integrated evolutionary
synthesis compared to like the modern synthesis
or even the extended evolutionary synthesis.
This is integrated because it kind of
reconceptualizes evolution, biology and evolution
in terms of thermodynamics and information theory
or energy flows, energy and information flows
takes from cybernetics.
So yeah, it's a non-reductive theory of everything
that includes emergent phenomena
like life, mind and civilization.
I say that because most theories of everything
we're used to are fundamental physics theories
that don't have anything to say about life and consciousness.
They ignore them and I don't think those
should be called theories of everything
because theories of everything should be
an explanation for everything.
And if you leave the things that we care about most out
then it's not much of a theory of everything.
So this is the book I've spent the last two to three years
writing obsessively and it's available for pre-order now.
So if you wanna check that out
you can find it with a Google search.
Here's the table of contents.
So the book is broken into three sections.
Part one talks about the origins of life
and part two about evolution while part three focuses
on consciousness and free will
and the fate of life in the universe.
So these like really big questions
that we're gonna focus on part two
and give a pretty like a superficial overview of part two
but you can feel free to ask me any questions
about any of the other topics that are related
and I'll try to see what I can answer
without going into like all of the information
that I would need to explain those things.
So Thomas Huxley known as Darwin's bulldog
because he was such a strong advocate for Darwin's theory
said that the question of questions for mankind,
a problem which underlies all others
is more deeply interesting than any other
is the ascertainment and of the place
which man occupies in nature
and of his relations to the universe of things.
So where do we fit into the grand cosmic scheme?
Most scientists in the 20th century
and I would even say now believe that we are an accident.
So Jacques Manot, French biochemist
who won the Nobel Prize for Physiology and Medicine
wrote a book called Chance and the Sesty
which was really influential
and he was just as reductionist as you can get.
Man at last knows that he is alone
in the unfeeling immensity of the universe
out of which he emerged only by chance neither.
So some of the words are covered by Daniel.
So either it's his destiny spelled out
nor his duty have been written down.
I think there's something wrong with that quote
but so if there are times where I'm trying to read something
where the picture's over, I might have to skip.
You can move that because it looks different on my side.
It looks fine.
Perfect.
Thank you.
Great, yeah.
Neither his destiny nor his duty have been written down.
So that was kind of based on this old idea
that the emergence of life was a product of chance assembly.
So like this just statistical fluctuation
that brought together all the molecules needed
to create the first cell.
We now know that that's probably not what happened.
It's this gradual process of self-organization.
Jeremy England has been in the media a lot
about his theory of dissipative adaptation.
So let's see.
So we will see this is kind of like a different point of view.
Not everybody was convinced by Amano.
Carl Sagan said the origin of life must be
a highly probable affair as soon as conditions permit
up it pops.
So this is an important question.
Whether life was improbable or inevitable.
So if life is highly improbable,
we're likely to be alone in the universe.
But if the emergence of life is inevitable,
given a certain set of common physical conditions,
then it's likely that we have life,
at least on planets that are sufficiently earth-like,
specifically have geochemistry like the earths
have a star, some like the earths,
because that's what provides the energy
that pushes it far from equilibrium.
So we're going to get into all that stuff pretty soon.
Christian DeDeu, this quote is kind of a response
to Stephen Jay Gould, who just really emphasized
to both Amano and Stephen Jay Gould,
the importance of chance in nature
and that everything is basically a contingency
that came from a chance process,
where DeDeu says that you can have this inevitability
that some philosophers would see as teleology,
but it doesn't mean that this inevitable progress
is being driven by a supernatural force.
He explains that the natural constraints
within which chance operates are such that evolution
in the direction of increasing complexity
was virtually bound to take place
if given the opportunity chance
does not exclude inevitability.
So he was also an Nobel Prize winning biologist,
the same category as Amano,
but had the complete opposite opinion.
And we can talk about that too,
basically when systems are open systems
and they're pushed far from equilibrium,
by a flow of energy,
you basically get something like a statistical bias
away from what we would expect with isolated systems,
closed systems that aren't open to energy
will relax the thermodynamic equilibrium.
And when a system is being pushed far from equilibrium,
it will naturally organize
because organization happens under the flow of energy
and we're gonna see exactly why it's a Darwinian process,
but basically you get inevitability
if you have the right ingredients.
So we'll talk about, to kind of frame this,
we already kind of mentioned those two worldviews.
So the first worldview would be the reductionist worldview
and I should be clear that reductionism is also
it's a method and an ideology
and we shouldn't confuse those two things.
And Daniel, I guess just so I know where I'm at maybe
when I've gone 30 minutes, you can let me know.
Okay, I'll hoot.
Okay, great.
So reductionism, the method basically says
that reality can be understood by breaking down
all physical phenomena into their simplest parts
so that we may observe the basic behavior
of the fundamental constituents of nature.
So, I'm just gonna plug in this charger.
I might need to do that in a bit,
but basically the method is how science works.
If we wanna understand emergence,
we also have to understand how the components
that systems are made of work in isolation.
So it's an essential part of the story,
but it's not the whole part we'll see.
So the method inspired an ideology
and the ideology is just that.
It's an ideology and it's rigid
and basically the method doesn't really imply
that the ideology is true.
So when I'm attacking reductionism,
I'm not attacking the method, I'm attacking the worldview.
And so that worldview, we can say that basically,
so hard to determine is part of the reductionist worldview.
So thought experiment that some people are familiar with,
I'm sure Laplace's demon,
but basically Laplace was a French mathematician
that took Newton's kind of model of reality
and applied it to everything.
Newton himself was kind of a mystic
when it comes to life,
he didn't really think that physics apply to organisms
or at least to humans,
but Laplace really came up with the idea
that basically the evolution of the universe
is just this clockwork universe
where it's like a machine with cogs that are just turning.
So there's no room for agency and free will in that picture.
When Boltzmann came along in the 19th century
and came up with statistical mechanics,
the clockwork universe kind of became the billiard ball universe,
but it's just the idea that everything in the universe
is made of atoms and that these atoms are interacting
and that's the whole picture.
So the ideology says we're nothing more than our atoms.
So we don't make decisions.
Consciousness is just an epiphenomenon
and it feels to us like we are,
but actually this trajectory was determined basically,
not basically from the moment of the Big Bang
and there's kind of no freedom in anything
and no future other than what was determined from the beginning.
So the second law of thermodynamics
also sort of shaped the reductionists were abused
as the universe is becoming increasingly disordered.
There's actually kind of two different interpretations
of the second law.
The first one kind of emerged from the work of Carnot
and Clausius, the kind of original thermodynamics work
where entropy was about a measure of energy
that can't be used for work.
So the kind of measure of like useless energy
where later with Boltzmann he tried to put the second law
on like a statistical basis based on like atomic theory.
So basically people applied Boltzmann's statistical
interpretation of the second law to the universe
and came up with this notion that the universe
is becoming increasingly disordered,
which isn't great for life because it means
that life is transient and likely cosmically insignificant
and this worldview is associated with materialism,
which doesn't recognize consciousness as real,
certainly doesn't recognize it as having causal power
and historically it often ignored apparently
in material phenomena like energy and information
mental processes.
I am just going to grab my charger.
So, sounds good.
This doesn't die, but I will be right back.
Take your time.
So those who are watching live,
please feel free to leave a comment or a question.
I'm writing some things down.
We'll look forward to the return of electrical power
to Bobby.
All right, my first live stream,
I will be more prepared in my return to part two.
That's something else I've told Daniels
that this is kind of like part one
that I come back and talk about the ideas that come after.
So, we'll have 15.2.
It'll be awesome.
It's an infinite sequence.
It's the sequence is always yours.
Great, okay.
So, reductionist worldview says that all life forms
including humans are nothing more than collections
of atoms obligatorily following fixed
and arbitrary mechanical trajectories
determined solely by math and not by mine.
So, this worldview, if you convince someone
that they don't have free will
because you tell them about the reductionist worldview,
there was actually a study where they did this
and they read participants passage from Francis Crick
explaining that it appears that we don't have any free will.
The participants actually on subsequent tests
were more likely to cheat on the test
because they felt like they didn't have
any personal responsibility.
They weren't making the decisions,
therefore they could cheat.
That's kind of funny because they are actually,
you can see that by what they're being told
that they are changing their behavior.
So, it is having some kind of effect.
If we do in fact have agency or free will
and we're kind of talking about agency,
we don't really get into free will
but those are related topics.
But if that's not true, then that's really bad
that the majority of scientists are telling people
we don't have free will because the people
that believe this, it's having negative effects
on, for example, mental health.
Other studies have shown that belief in no free will
can lead to depression and belief in free will
can have all these positive effects.
Of course, as soon as I start talking about free will,
I'm sure a lot of people have objections,
might think that there's no way
that we can have room for free will in a physical worldview.
But that's exactly what we're gonna begin
to talk about today, the causal power of information
and that basically organisms are agents
that are cybernetic control units.
So, as controllers, we do have agency.
So, and the belief that we're accidents of nature
rather than natural manifestations of physical laws,
I'm sure also impacts our sense of wellbeing.
Just so I'm not making this up,
I'll give you some quotes from really famous physicists
who are kind of militant reductionists.
So, Brian Green says, I think it's very important
to face up to the truth of reality,
which is in fact that life and consciousness
is a fleeting phenomenon on the entire cosmological timeline.
Brian Green just came out with a book
and he's like going on interviews just saying this
and it's really interesting
because some other famous physicists don't agree at all
and he's stating it like it's a complete fact.
So, for example, David Deutsch would not agree with this
and we'll get into that.
Sabine Haustenfelder is another person.
I know some of my friends in the community
who are these people working on emergence
and causation stuff get bothered by her statements
because she is also very ultra-reductionistic.
So, I wish people would stop insisting they have free will.
It's terribly annoying insisting that free will exist
as bad science, like insisting that horoscopes tell you
something about the future.
It's not compatible with our knowledge about nature.
So, I'm saying that's wrong.
We won't get into free will that much,
but if you have questions at the end,
we will talk about how adaptive information
gets built up by evolution in adaptive systems,
complex adaptive systems,
and you will see how these systems
actually do control their own future.
So, Sam Harris is another anti-free will person
who says you're not controlling the storm
and you are not lost in it, you are the storm.
So, it's kind of funny because he's using a metaphor here
what this story kind of reveals is that yes,
we are a storm, that's right.
We are a dissipative structure,
like a storm emerges to dissipate an energy gradient
and we're not really gonna talk about that.
That's what the first part of the book is about,
the origins part, but I'm just pointing it out
because it's interesting because we are like a storm
in that aspect, but we also differ from a storm
because a storm does not have agency,
a storm does not have the ability
to seek out new energy gradients.
It's just kind of being pushed around
by these gradients in nature
where organisms are actually controllers
and so you are a storm,
but you do have control over the storm.
So, these people are kind of have the opposite view.
So, Julio Tinoni, creator of Integrated Information Theory
says there is true free will.
Great lecture that just popped up I think months ago
where he gives a two hour talk
on basically integrated information
and how it shows that systems do have causal power
and in a way have free will.
So, depending on your definition of free will,
we do have free will according to his model.
David Deutsch said in an interview with John Horgan
just a year ago or so, I'm sure we have free will.
Christoph Koch says, explains how,
there are a lot of experiments, the LeBet experiments
which we will talk about next time
that basically some people interpret it
as not having free will,
but actually we will see later when you deliberate,
that's actually an act of free will.
These choices where we're actually,
where you bring your entire conscious being
to that question and try to analyze it
under all the various conditions.
And actually there was a study Koch did
that kind of showed that the LeBet study
was kind of interpreted wrong.
And for anyone who understands that stuff,
the readiness potential that was supposed to be proof
that there was no free will disappeared
when the decisions involved deliberation.
So yeah, that's kind of meandering,
but I'm sure a lot of people are interested
in this bigger picture of why this emergence paradigm
is so radically different from the reductionist paradigm.
It kind of puts information front and center
and systems that process information,
complex adaptive systems are computational systems
and the systems with these systems,
information actually does have causal power.
We're gonna explain what we mean by that.
So paradigm of emergence,
the collective says the collective behavior
of interacting parts,
not simply how they function in isolation
is key to understanding the emergence and evolution
of all the fascinating organisms and ecosystems
that make up the biosphere.
So it's really not about just like particles,
it's about the patterns that emerge
when these systems find these certain configurations
through basically Darwinian mechanisms.
And we'll see that self-organization too
has a Darwinian dynamic.
Each emergence in the cosmic self-organization process
is brought about by higher order phase transition
that moves life ever further away
from a state of thermodynamic equilibrium and total disorder.
I'm assuming the audience knows
that what thermodynamic equilibrium is.
It's basically if you have, for example,
Boltzmann took a model of an ideal gas
and explained that, for example,
if the gas molecules are bunched up in the corner,
naturally it's going, the gas is going to spread out
until there's no pattern.
And basically it's like a completely mixed up state.
So equilibrium is associated with death and disorder
because systems naturally tend toward this more
mixed up, un-patterned, completely chaotic state.
Of course, later we're gonna talk about
why open systems that rule doesn't apply,
basically systems that are open to the flow of energy
can resist this tendency towards a disorder.
And that's really what the whole story is kind of based on.
So through a nested series of such phase transitions,
these are also called, these higher order phase transitions
are major evolutionary transitions.
John Maynard Smith talked about them
and meta system transitions
by the cyber net assist Valentin Turchin,
basically the same concept with some subtle differences.
So the idea is that cosmic self-organization
is a series of these transitions where functional things
come together to make larger functional ones,
which come together to even make even larger ones
and so on.
And through this process, adaptive complexity or life,
so that's a more general way to talk about life,
becomes better equipped to dominate the cosmos.
Life requires an organization
that is increasingly hierarchical and integrated
and therefore more resilient and computationally powerful.
So here are just a couple of figures.
You see this hierarchy in this structural hierarchy
of matter and life.
This was adapted from a big physics journal.
I can't remember which one it was,
but basically, physicists are recognizing this hierarchy
even when it extends to life.
So Jeffrey West's book scale comes to mind.
And so we see the hierarchy of science
kind of naturally mirror this hierarchy of matter and life.
And the reductionist picture would say
that these things at the top here
are kind of insignificant parts of the story transient,
but we will see that this, the more we go up,
the more influence on cosmic evolution,
the phenomena have.
So Thomas Huxley's question about man's place in the cosmos
is basically the emergence of the paradigm of emergence.
I'm going to discuss, and actually this is kind of maybe
like a specific or a new paradigm of emergence
because it includes all this stuff
about thermodynamics and information theory
since that the emergence and evolution of life,
minds, societies and technology
are all part of one thermodynamic process,
one evolutionary process, one computational process,
unified by the concept of knowledge.
So this theory is a theory of knowledge creation.
And so knowledge is going to be the unifying theme
and we'll briefly talk about epistemology.
I wanted to talk about it more,
but it just would have been too long.
Cosmic evolution in this paradigm
is a universal process of becoming as opposed to being.
So the universe isn't this static thing.
It's actually evolving very much like an organism
or a complex adaptive system.
So it's not a panpsychic theory
and this theory consciousness emerges.
That's very important,
but you might call it emergent panpsychism
because as this evolutionary process proceeds,
an animate matter as life spreads
gets converted into animate matter.
So in this picture,
humans are neither a cosmic accident
nor the end goal of evolution.
So we are instead a step on the evolutionary ladder
of becoming and we are also potentially
an essential driver of increasing cosmic complexity.
So this big idea is that the universe is undergoing
this majestic self-organizing process.
And at this moment of time,
at least in this corner of the universe,
we are the stars of the show.
This picture is from the first episode
this picture is from Eric Chasen's book,
The Rise of Complexity,
Cosmic Evolution, The Rise of Complexity.
He's a Harvard astrophysicist,
but I just used Freeman Dyson code here
because it seemed irrelevant.
It's conceivable that life may have a larger role to play
than we have yet imagined.
Life may succeed against all odds
in molding the universe to its own purpose.
So I guess Brian Greene doesn't buy that at all,
but if that's true,
then as cosmologists have to think about the role of life.
There's a lot of people who have said similar things
like cephaloid and famously Raker as well.
So just a couple quotes here.
So you know, when people hear these terms progress,
there's just the stigma.
Immediately they thought like,
oh, someone's trying to sneak in religion
or some intelligent design theory.
So you see these trusted names of physics here.
David Orch has narrowly conceived evolutionary theory,
considers us mere vehicles
for the replication of our genes or memes.
And it refuses to address the question of why evolution
has tended to create ever greater adaptive complexity
or the role that such complexity plays
in the wider scheme of things.
So there's clearly implying that adaptive complexity
does have this larger role to play.
We now see how it is possible for the universe
to increase both organization and entropy at the same time.
The optimistic and pessimistic arrows of time
can coexist, the universe can display
creative unidirectional progress
even in the face of the second law.
Physicist Paul Davies says that.
So that's really kind of a key point in this,
is that the second law actually is in a sense
driving this increase in progress.
So not only can we have unidirectional progress
in the face of the second law,
it seems that this progress requires the second law
because we'll see that the second law is the,
basically the natural selection pressure
for self-organizing systems.
So in a sense, the second law is both
Shiva the destroyer and Brahma the creator.
So a goal of this unifying theory of reality,
I've been calling the Great Consilience,
it was actually a name suggested by Marco Lin
who is a Fristonian and influenced some of this talk.
So basically the unifying theory of reality
illuminates the connection between complexity,
cognition, consciousness and cosmic evolution
or matter of mind and cosmos.
And it's really based on complexity science,
it's a lot broader than complexity science,
but I guess that name kind of includes everything.
So it's a unification of major sciences of our time,
including but not limited to physics,
biology, neuroscience, computer science,
evolutionary theory and statistics.
And basically it describes complex adaptive systems
of all scales in terms of energy and information flows.
So it uses statistical thermodynamics,
information theory and cybernetics.
So we will talk about those a bit
coming up.
So if you wanna see kind of like a map
of what sort of informs this non-reductive theory
of everything, here you go.
So I know there's a lot of information,
so I'll kind of try to simplify this for everyone.
There are some unifying paradigms that have emerged.
So basically this theory is nothing new,
it's basically evolutionary epistemology.
After that came universal Darwinism,
and later right now we're seeing this kind of revolution
with like Bayesian inference
and these ideas being applied to everything.
So being informed by these paradigms
and combining those paradigms or updating them,
I should say with information
from non-equilibrium thermodynamics.
So we're talking about the thermodynamics
of open systems, information theory.
So Shannon's theory, some of you will know
that information theory is related very closely
to non-equilibrium thermodynamics.
And basically Boltzmann's statistical entropy
is mathematically the same as Shannon entropy
or information entropy, which is a measure of uncertainty.
If I had more time, I would go through thermodynamics
and the different types of entropy,
but we don't have time for that.
But if anyone has any questions, I can clarify.
Cybernetics was basically information theory
applied to biology, adaptive systems.
It was the first science of adaptive systems really.
And it's funny, while writing this,
I found out, because I had heard the name Cybernetics,
but it wasn't clear how important it was.
And a talk by Jim Crutchfeld of Santa Fe Institute
basically revealed that because cybernetics
got associated with the Russian,
during the Cold War, kind of like the Russian agenda,
Cybernetics was used to design heat seeking missiles.
And Norbert Wiener's theory was almost immediately applied
for military uses.
And because of that, it stopped being taught
in American colleges.
So yeah, it's really important.
And it was actually emerging at the same time
as information theory.
People were already thinking about systems
in terms of information flows,
but it's more than information theory
because it's a science of feedback.
So dynamical systems theory are complex adaptive systems.
It's kind of like an offshoot of that.
All of these inform what I've called universal Bayesianism.
Not the only person to call it that.
I had searched that term and found Adam Saffron's paper
on integrated world modeling theory
that used that same term.
But John Campbell has been a researcher
who has done a lot to show this equivalence
between evolutionary processes
and processes of Bayesian inference.
We're gonna talk about that in a little bit.
So yeah, if anybody has any questions about that,
but really all of these things,
origin of life research,
integrated evolutionary theory,
if you haven't checked out the work of these people,
like everybody here's worth reading their work.
So from that, we get the Unifying Theory of Reality
that is based on what I call
the evolutionary epistemology, universal Darwinism,
universal Bayesianism framework, that's a long name.
I'm aware of that, but it's just to show
that these three theories are basically the same theory.
So universal Darwinism says that the universe
is evolving at every scale through both competitive
evolution and through self-organization,
which is cooperative evolution among agents
that have formed a collective unit.
So it started with Richard Dawkins
and his concept of the meme and the selfish gene,
that memes were these cultural units
that were equivalent to genes.
And so we started to see how information was this paradigm
that could be extended beyond biology.
And then we had Dan Dennett and Darwin's Dangerous Idea,
that really extend this to everything,
to self-organizing systems,
to cultural and technological systems.
Evolutionary epistemology came before that.
It was based on Karl Popper's philosophy,
but it was actually invented by
cognitive psychologist, Donald Campbell.
And basically that said that the evolutionary process
is a problem-solving procedure that creates knowledge.
So the information stored in genomes and in brains
and cultural memory, basically,
that all that knowledge accumulates
from an evolutionary process.
And it's really helpful to think of it as knowledge,
especially when we start to talk about this
in the context of thermodynamics and information,
because basically this knowledge is what allows
life adaptive systems to stay far from equilibrium.
They can resist this tendency towards decay.
Life can continue to persist
if it can acquire the knowledge that it needs
to essentially to find free energy
that will allow it to sustain itself.
So we'll talk about that in a second more.
So universal Bayesianism is a Bayesian update
of the first two paradigms, knowledge is encoded.
So the knowledge that evolutionary epistemology described,
it's actually encoded in biological systems
in the form of a world model.
So this model is an internal representation
and statistical mapping of the environment,
which gets updated through adaptation
and adaptive learning.
I'm gonna talk about that process.
Really the whole Bayesian brain hypothesis
and free energy principle is inspired by cybernetics heavily.
So Ross Ashby's Good Regulator Theorem
and Law of Requisite Variety, which we'll talk about
was kind of the first talk of systems having models
and having to model the environment.
So Crawford-Riston says inference is actually quite close
to a theory of everything,
including evolution, consciousness and life itself.
We're not gonna go into those bigger implications
that would be at the end of the book in the last chapter,
but basically this isn't just a theory about evolution.
Well, it is evolution, but evolution applied
way more broadly.
So quantum mechanics has an interpretation
that's consistent with this and bigger problems
like the fine-tuning of the constants and parameters
that allow for the emergence of life in the universe.
We can actually probably have the best explanation
for the fine-tuning problem
and the measurement problem of quantum mechanics
with this theory.
We won't talk about it, but just so you know, next time,
cosmological natural selection by Lee Smolin
is the theory that kind of addresses the fine-tuning problem
from a universal Darwinism perspective
while quantum Darwinism addresses the measurement problem.
So we will save that for next time,
but feel free to ask questions about any of those.
So what does this do?
I have this name, poetic metanaturalism,
I meant to take that out,
but next time we'll get into why I chose that name.
It's actually, it sounds kind of like, you know,
like complex or buzzword or jargony,
but there's actually very practical reasons
for having that name.
So this unifying theory bridges matter with mine.
So universal Darwinism gives us a picture
of the open-ended complexity growth.
That this whole idea is based on the idea
that evolution keeps producing
increasingly complex and intelligent forms of life.
Excuse me.
So yeah, universal Bayesianism is the link
that kind of connects those paradigms with consciousness.
So again, we won't get into that today,
but when you understand that knowledge is stored
in the form of a world model,
that the system that models itself can experience,
then we start to get a better understanding
of like what consciousness is, it's a mental model.
So it's not a traditional panpsychic theory,
even though I know first in and Levin
some of his colleagues have kind of been flirting
with panpsychism, this theory would say that's wrong
and it's kind of reduces consciousness
to something trivial by saying that it's an everything
like a proton is conscious because it's a triad of quarks
that have to be in a certain configuration.
So there is some minimal level of integrated information.
That's not enough to get a conscious experience
again, observer.
So Saffron's integrated world modern theory says
that you need a model with spatial temporal
and causal coherence.
I would also argue that it requires self modeling capacity.
Talk about that a little bit at the end
if anyone's interested, but this theory is supposed
to bridge mine with cosmic evolution.
So the story starts with the second law.
Daniel, if there's any questions about that like intro,
let me know, I can just proceed.
Could I ask two questions from the chat?
Sure.
Okay, the first question is from Blue.
Blue wrote, do you think that non-living autonomous agents
with multiple competing priorities
such as self-driving cars have free will?
If not, what is the defining difference
between these systems and humans?
No, I don't think they have free will.
So adaptive information is a special type of information.
I do think those things, and this is kind of following
Sarah Walker's lead who's at Arizona State.
I think she's also SFI faculty now,
but basically to have self-driving cars,
you first need life.
So anything like a self-driving car
that's like this information processing system,
if you were to come across a broken down self-driving car
on some planet and you saw that,
you would have to infer that there was also life there
because life is part of the trajectory to get to that.
But I wouldn't say that it has free will
because it's just this input output machine
with a defined set of algorithms
and adaptive systems are more flexible.
And there, okay, so in the next time,
we'll talk about actually the emergence of agency,
which occurs with the origin of life or a biogenesis.
And you basically, because this self-organized system
that would be kind of like the proto-cell
is evolving through a mechanism
that Darwinian dynamic for self-organization
that we'll explain in a bit, it builds up information.
And at some point, there's a phase transition
where the information that's getting built up
in the system basically gains
what Sarah Walker and Paul Davies call informational control.
So there's a point where information
actually starts calling the shots.
And you can see the difference between systems
that where there is informational control.
So living systems and inanimate systems
because for example, inanimate systems,
their movement can be predicted with Newton's laws.
So anyone who's taken first year physics
probably had to do an exercise
where you're trying to predict the movement
of some macroscopic system like a ball
that gets kicked or pushed by a gust of wind.
And what you do is you have to draw out
all the forces acting on the system.
And then you can understand where the system's gonna go.
With life, you don't need an external force for it
to start, for example, climbing up hill.
That's internally generated, of course, it's not magic.
The adaptive system that agent has stored energy
that it's extracted from the environment.
So for example, humans that have eaten food
and there's a metabolic process that's driving this.
But still, yeah, with living systems
that where information has causal power,
basically the trajectory of the system
can't be predicted by these fundamental laws of physics.
Philip Ball, a journalist that has been talking about this,
his recent article, which caused a lot of controversy
between like the reductionists,
like talking about free will and agency.
And there's a lot of confusion around that.
So people like Jerry Coyne were like trying to shoot it down.
Yeah, hopefully I can talk about that.
I guess we'll talk about that next time
because there's a lot of confusion
about what we're saying when we say something has agency
or free will.
But his example is if you throw a ball and a bird off a tower
and you can predict what one is gonna do,
you can't predict what the other is gonna do.
Interestingly though, I would say that
the bird's not completely unpredictable.
You can predict that it's not gonna hit the ground.
It's not gonna splat on the ground.
It's gonna fly away.
You have to understand the bird in terms of its goals.
So you have to understand the bird and its environment
and the information that got built up through evolution.
And then we can start to predict the bird,
its statistical behavior.
So in animate systems,
you can pretty much precisely predict the movement
unless they're chaotic systems, which is another story.
But with life, yeah, it's not predictable in that same way
with like low level laws of physics,
but I'm arguing that actually life
is more predictable than we thought,
but you need things like non-equilibrium statistical mechanics
and for example, free energy principle.
So you can say that, you know,
an organism will try to minimize free energy
or minimize the difference between its models,
prediction and reality.
So it'll try to minimize prediction error.
And that's a way that we can start to describe behaviors
statistically.
So, you have, is there another one?
Yep, can I ask the second question?
Yeah, I know I didn't completely answer that,
but that will require like all of the points
that I would get into in the second talk.
But it's a great question, yeah.
I would have written in a larger margin if I had more time.
The second question is from Joseph Clark, who wrote,
first complimented your talk and let you knew
that you were an interesting guy.
So then the question was,
how far do you think the universe can organize itself
and what does that look like?
Okay, great.
That's a perfect question to lead into the next part.
And hopefully by the end of this,
we will have some sort of answer for that,
which is good because when I started making
the beginning of the presentation,
I was going to get to consciousness and free will
and I ran out of time.
So there's been a lot of talk about things
that I won't get to, but that we will get to.
So, the story starts with the second law.
So the second law of thermodynamics as popularly understood
says that systems naturally become increasingly
disordered, that's really just because
of the large scale effects of chance.
So there are many ways to be disordered
and there are relatively fewer ways to be patterned.
So a system that's this collective of particles,
so this evolving ensemble of particles
will naturally tend to move towards a configuration
that's completely spread out and mixed up.
There are no energy gradient,
so no work can be extracted.
That's a state of equilibrium.
So we are going to use this word, thermodynamic equilibrium
to mean death and disorder.
So life wants to resist the tendency towards equilibrium
and wants to stay ordered.
What's interesting about this is that it applies to all,
this is kind of like where the free energy principle
in first sense, Bayesian brain hypothesis,
it frames everything this way.
So I thought it was a good way to kind of frame it here
is that you start with the second law
and any conceivable system, any ordered system
for it to continue to persist has to resist this tendency.
So basically Schrodinger, the guy I mentioned earlier,
everybody knows from quantum mechanics
in the cat thought experiment,
he wrote a book called What is Life in the 40s
and basically kind of solved this paradox.
Like if there's a second law and things become more disordered
than what's with life and what's with the biosphere
and all of this complexity that we see around us.
And he explained, actually Boltzmann explained this
before him, but Boltzmann said a lot to contradict this
as well or just didn't follow this to its implications.
But Schrodinger explained that open systems
by feeding off free energy in the environment.
So free energy is just energy that you can extract work from.
So it's ordered energy as opposed to energy
that's been dissipated in the form of heat.
You can't extract energy, useful energy from that energy.
It's still there, it's just spread out
and you can't harness it, collecting it
would cost more than you'd get out of it.
So Schrodinger explained that if a system can get free energy
which he called negative entropy or energy,
negative entropy was called by someone later.
So to understand how ordered systems stay ordered,
you basically need to understand
that they have to constantly be extracting free energy
from the environment.
The moment that they can't extract more free energy
is the moment that the system dies
and decays to equilibrium.
So basically the second law is not violated by life
because in this effort to stay far from equilibrium,
life, it keeps extracting that ordered free energy
and keeps dissipating it as heat.
So it's basically exporting entropy into the environment.
So the order that is maintained is paid for
by the dissipated energy which becomes thermal entropy.
So there are multiple definitions of entropy.
So you have thermal entropy which is heat entropy
and then statistical entropy
which explains thermal entropy
but it has a broader domain of application.
So you can talk about a shuffling a deck of cards
and you can talk about like the statistical entropy
increasing if the deck is ordered
and it starts becoming mixed up through the shuffling
but the deck of cards, the thermal entropy
isn't changing much at all.
So there's different types of entropy.
There's also information entropy which has to do
with the number of messages that can be sent across the channel
instead of the number of states that a system can be in,
the number of microstates without changing the macro state
or the kind of collective properties of the system.
There's a really neat relationship
between statistical entropy and information entropy
which I won't talk about here.
It was really fleshed out by E.T. Jains
but yeah, so information and entropy go hand in hand.
Just to give a little more context
before we get into the details,
David Deutch in this great TED Talk
called after billions of years of monotony
the universe is waking up says
if one can speak of a cosmic war,
it's a war between monotony and novelty
between stasis and creativity
and in this war, our side is not destined to lose.
If we choose to apply our unique capacity
to create explanatory knowledge, we could win.
So that's very different than Brian Green's story
and it kind of gets at the second question
that was asked there, how far can this complexity increase go?
And so this kind of foreshadows
that maybe it doesn't have a limit
and that seems, most people think
that would go against the second law of thermodynamics.
We're gonna see why that's not necessarily true
but you can also see this cosmic war
as this fight between order versus disorder,
life versus entropy and knowledge
versus uncertainty or ignorance.
But is life's battle against disorder good versus evil
or yin and yang?
So I'm gonna kind of argue that these two things
kind of have this, you can describe their relationship
as causally dependent.
And it's kind of like this dialectic between life
and disorder and it is through this sort of interaction
that creates progress.
So we have some Eastern ideas mentioned again
but when I was writing the book of friend
that practices Buddhism called me
and told me about this interdependent co-arising idea
which I thought was really cool.
So we're gonna come up with this,
what we call Popper's principle
which is problems create progress.
We're gonna see that this problem of entropy
that this tendency towards decay
is what actually forces systems to evolve.
Basically it forces them to search
what's called the configuration space
or the phase space or the state space
to find configurations that are good at extracting energy.
And that allows it to stay far from equilibrium.
So we're gonna have some figures soon.
So this stuff that's kind of abstract
becomes a little bit more concrete.
Just out of respect to the earlier request,
how about you check the time and feel then how fast
you'd like to continue however much you wanna present
and then if you wanna take any questions
but first just check the time and let just.
I didn't notice when we started
so about how long have I been going?
I would say five, zero minutes.
Really?
Okay, how long can we go?
We can go another 99 minutes.
Okay, I'll try to go through it a little bit faster.
But yeah, so but if we use all the time
I told you yesterday that I was feeling
oh, I had a sore throat and the sore throat's better today.
I'm hopped up on cold medicine.
I'm sure I'm gonna pay for tomorrow
but yeah, if we use all the time
with questions that would be good.
So in our everyday experience,
things don't naturally become ordered
unless someone intervenes, rooms get messier,
buildings erode.
So we already talked about this Schrodinger's solution.
So we can think of life as a game.
So life has always been playing a game
against the second law of thermodynamics.
There is another narrative that I won't go into
but life is also an energy flow channel.
So life by existing and computing
and trying to stay far from equilibrium
is also increasing entropy.
Actually, the universe of life will increase entropy
at a faster rate than the universe without life
which is pretty interesting.
So it's again, not necessarily that life
is like battling against entropy
and in many ways it increases entropy
but there's also this story,
I guess what it's trying to battle
is the tendency towards disorder.
So it depends on what type of entropy you're talking about.
So the challenge in the game of life
which applies to you as well
as other simpler adaptive systems
is to resist that tendency.
So this gives life a goal for a teleology.
So teleology was associated with kind of this mystical thing
but basically we're seeing that teleology is just agency.
It's just a result, goal-oriented behavior
as a result of the information
that's been accumulated over evolution.
So teleology, the book tries to naturalize teleology
and just say that there are these goal-oriented systems
that behave different
because they are acquiring information
through Darwinian evolution.
So life has to extract free energy,
that's how it stays in the game of life
and to extract free energy, it's not a simple task.
So the computational task of extracting free energy
requires that the system acquire information
about its environment, otherwise it can't find energy.
It also requires that the system model its environment.
So the information is creating this predictive model,
this generative model
and it is that model that allows it
to continuously find free energy.
So we will explain that life strategy,
is it searches through a configuration space
for solutions to the problem of survival
through trial and error search, variation in selection.
So we know about evolution,
there's this genetic variation in natural selection
and we're gonna argue that that process,
that mechanism is much broader.
The evolutionary mechanism is actually the mechanism
of the scientific method and of adaptive learning
and that mechanism is also a process
that accumulates evidence-based knowledge.
So it's also a process of Bayesian inference,
we're gonna explain why.
So here we have those different mechanisms
of different names.
So it's not included here,
but so if life is a game, there are levels to this game
and the levels we're gonna see
are these evolutionary transitions,
every time life graduates to this more complex,
hierarchical system, like when single-celled organisms
come together to form a multicellular organism
and multicellular organisms come together
to form communities like societies
that you can view these evolutionary transitions
as life graduating to a new level.
So we're gonna talk about how adaptive information
gets built up through evolution
and we're calling that knowledge.
It's nice to have that word knowledge
because this process of an adaptive system
acquiring this information
is actually reducing its uncertainty about the environment.
So it's reducing its ignorance
about all the ways the surrounding world
could potentially surprise it.
So knowledge is a nice word,
some philosophers like old-school philosophers
might have issue with that
because in some teachings like knowledge
is something that like conscious beings
with like awareness have,
but we're calling any adaptive information knowledge
and it's got more of a technical definition
because knowledge is that information
which reduces uncertainty
and you could actually quantify this process of evolution.
Terence Deacon has talked a lot about
how you can do that with information measures.
So just to explain this,
why is knowledge something that matters?
So like does it have causal power
or is it all just this billiard ball universe
where it's like these particles bumping into each other
and you can basically use fundamental laws of physics
to describe like the trajectory
of all the particles in the universe.
This is saying no,
that the information that gets built up through evolution
has causal power such that these systems start to behave
in ways that are different
in what would be predicted from something like Newton's laws.
So we also have this process of anti-accretion
that Sarah Walker likes to talk about.
But anti-accretion is basically we're familiar
with planets pulling in matter.
So bodies like asteroids
because gravity pulls matter in naturally,
but anti-accretion is when a planet is ejecting matter.
And in many cases, well,
so the only time we really see anti-accretion
is when you have a planet with a life on it.
So right now, bits of biosphere,
so humans and space rockets
are being sent to other celestial bodies.
So that's a form of anti-accretion sending up satellites.
You won't see a satellite get sent out.
If you see that in the universe,
like you're looking at some other solar system
and you see a body sent out
and put into orbit from a planet,
that's an indication that life is there.
That's a biosignature.
So she says that anti-accretion requires comprehenders,
specifically the existence of physical systems
with knowledge of Newton's laws.
So what does it all mean?
It means we need knowledge
to keep us out of thermodynamic equilibrium.
So how do we acquire knowledge?
Science is the most salient example
of the causal power of knowledge.
So science has eradicated lethal diseases,
built a global communication network called the internet
and created weapons of apocalyptic power.
It's not always good, this power of knowledge,
but we see that there's something
about the scientific method,
which is efficient at accumulating knowledge.
So we're gonna talk about why
and that's where we get into Karl Popper
and evolutionary epistemology.
So we know knowledge is important.
Karl Popper says we're always faced with practical problems
and out of these grow sometimes theoretical problems
for we try to solve some of our problems
by proposing theories.
So Popper stresses that all of science
starts with a problem, either theoretical or practical
and it is that problem that forces us
to seek out a solution.
So we can already see why this principle
that I've called Popper's principle
says that problems create progress.
So some of these theories that we make
to try to solve our problems will be wrong,
they'll be errors, but the idea with science
is that those errors get filtered out
by a process of testing your theories
and a peer review process, which gives criticism.
So knowledge is really, for us to know
that some piece of information is knowledge,
it really needs to be tested
and we call that evidence-based knowledge
or evidence-based information.
So it's really the only true kind of knowledge
because you don't know if something's true until you test it.
For example, the world doesn't look round
from a naive perspective, it looks flat.
So for example, someone who had the first idea
and I'm sure it was before anybody famous,
we knew someone had this idea and probably people blew it off.
But some things that are true about reality
are not immediately apparent
from sensory observation from since data.
So we really need to test our theories
if we are gonna be sure about them.
So what Popper found out was the scientific method
is an algorithm, he called that algorithm
conjecture and refutation.
And basically this is the method of hypothesis testing.
So you have a problem you believe can be solved,
you make an informed guess or conjecture
to see if your theory can be refuted,
prove false by testing its predictions.
So people have pointed out like John Campbell,
Carl Friston that science is a process of inference.
So he recognizes statistical patterns and trends in nature
that we can use to make increasingly accurate predictions.
It would not be inaccurate than to say
that the function or purpose of science
is to generate predictive knowledge.
And we can characterize that as process of inference,
which basically means that scientists
draw logical conclusions about the way the world works
based on evidence based information acquired in the past.
But with never present awareness that the information can
and will lead to new conclusions
and deeper understanding.
So when we recognize this,
we also have to recognize that all of our models
will have uncertainty.
So we should never think that our models right.
Every model is going to be proved wrong in some way,
but through the scientific process,
the idea is that we get closer and closer to truth.
So we can never reach perfect truth,
but in this model, you can actually get closer to it.
So in some senses it's different
in like post-modernist philosophy
that says there is no objective truth.
There is an objective truth,
but we can never know it, but we can get closer to it.
So once Papa understood that knowledge,
the knowledge generating mechanism behind science success
was conjectural refutation,
he realized that human learning,
which begins at birth and continues to death,
uses the same problem solving algorithm,
although the developmental psychology literature
called the method trial and error.
So because life is constantly presenting us
with new challenges, such as the need to get
from one place to another,
a problem that inspires babies to learn to walk,
we must constantly try out new behavioral solutions.
We can think of these actions as guesses about how to survive
or if you prefer experiments innovating equilibrium
or predictions for persistence, and they will often fail.
So this is Dan Dennett's idea of life exploring
this design space.
We're going to talk about how it does so through evolution,
but we're still talking about science here
and adaptive learning on an abstract level.
We can imagine a certain practical problem as a challenge,
one with a solution that exists somewhere out there
in the space of possibilities,
just waiting to be found by someone's
sufficiently motivated and clever.
It may take some time, but if the possibility space,
the space of possible solutions is continuously explored
in an efficient way, eventually a solution
will be discovered.
So, excuse me, trial and error learning
explores the solution space.
So, just to give you a clear example
of how adaptive learning is kind of this form
of hypothesis testing.
So whenever we have a problem in life
and we don't know the correct solution
to a problem in advance,
we naturally begin with those potential solutions
that are closer to our starting point
in the solution space for sampling.
So for example, if a baby reaches for its bottle
and barely misses, it'll adjust its behavior slightly,
which minimizes the chances of making an error.
So our instincts may nudges in the general direction
of a solution, but the instinct alone is not enough.
We have to try out what you could call
a behavioral conjecture, and when it fails,
we try something new.
So that's kind of like a new theory.
And it's essentially the old one, but with a little twist.
And if that behavioral solution is remembered,
then it gets stored for future use,
ready to be repeated, but also adapted if necessary.
But in humans, so the baby example,
reaching for the bottle, let's say it misses the bottle,
it won't get a reward signal.
It won't get a little surge of dopamine.
So if it corrects and it gets closer,
it gets a little reward signal.
This is reinforcement learning.
But basically this adaptive learning process
is a process of making theories
and eliminating those theories that are errors.
So Popper saw that scientific knowledge
and the evolutionary process were also connected.
So not only is science adaptive learning,
both of those things are extensions
of the evolutionary process.
So he says in science, theories are highly competitive.
We discuss them critically, we test them,
and we eliminate those theories,
which we judge to be less good in solving the problems
which we wish to solve.
So only the best theories,
those which are most fit, survive in the struggle.
This is the way science grows.
So that's kind of nice, like showing you really
how this is an evolutionary process.
Not only is science an evolutionary process,
the converse is true, evolution is a scientific process.
So it is clear, this is another quote,
it is clear that this view of the progress of science
is very similar to Darwin's view of natural selection
by the way of the elimination of the unfit
of the errors in the evolution of life,
the errors in the attempts at adaptation,
which is a trial and error process.
Analogously, science works by trial, theory making,
and by the elimination of errors.
I might pause in a second just to see
if everybody understands this,
but I have a few more slides.
So evolutionary algorithms also use this mechanism,
but it's called generate and test.
So I didn't mention this,
the mechanism of evolution is variation and selection.
So we have these algorithms that are equivalent,
conjecture and error mutation, trial and error,
variation and selection.
We also have generate and test.
So in machine learning, evolutionary algorithms
have this method, generate and test.
Possible solutions are generated
into an actual solution as found,
and these solutions accumulate in some memory store
while the errors are filtered out and forgotten.
In science solutions, our theories are modeled
to accurately predict some natural phenomena,
and the successful ones accumulate
in peer review journals and textbooks.
So we see that these processes are equivalent,
and we're actually gonna see that it's this Bayesian process.
That adaptation is also a process of the model
of the organism becoming optimized,
decreasing its prediction error
so that it can more efficiently extract free energy
from an itch to stay ordered.
So we get this principle that all evolutionary processes
are learning processes,
and all learning processes are evolutionary processes.
Conrad Lorenz, a Nobel Prize winning zoologist,
was also a pioneer of evolutionary epistemology,
and he made this statement,
life is a cognitive process.
So if this is true and there's this functional equivalence
between the mechanisms driving evolution,
learning and science,
then that implies that adaptation
or the genetic information that corresponds
to those physical adaptations are equivalent,
is equivalent to scientific knowledge.
They're actually the same thing.
So to kind of make this relationship clear,
biological adaptation represents knowledge of the environment
and the knowledge we acquire through learning and science
reflects adaptation to the environment.
So we see that there's no meaningful distinction
between adaptive information and scientific knowledge,
both allow life to predict an uncertain world,
control matter, constrained chaos,
and we construct order from disorder.
So the very same property that is responsible
for organic matter, leaving the planet in spaceships,
so this anti-accretion is the same property
that allows organisms to climb uphill,
seemingly defying the force of gravity.
Of course, the laws of physics aren't violated in any way,
but living systems are not constrained
by the laws of physics the way inanimate systems are.
So some examples, Adolph and Stringmoren design,
which is a product of the information stored in its genome,
contains the knowledge of hydrodynamics
and Eagle's wing design contains the knowledge
of aerodynamics, not only can we be certain
that engineers see knowledge in these functional structures,
there should be little doubt that they inspired
our machines and without that information,
I don't think we would have come to those inventions
at least not any time soon.
Camouflage on an organism
represents knowledge of the environment.
So kind of bridging this idea of evolutionary epistemology,
that evolution builds up knowledge
and that science is an extension of the evolutionary process,
making a bridge between that and Bayesian inference
requires this relationship
between adaptation and statistical correlation.
So physicist Carlo Revelli,
which who has gotten really interested
in explaining how this information
that underlies agency that behavior
that we see with living systems
gets built up through evolution.
He wrote a great essay,
won the Foundational Questions Institute essay contest
a few years ago, but this work was based on the work
of David Wolpert and Artem Kolchinsky, Artem Kolchinsky
and basically shows how this adaptation
builds up information in the system.
That information is really statistical correlation
between the organism and its environment.
So here's the simplest example.
It's a bacterium performing chemotaxis.
So a bacterium, so chemotaxis is basically
a bacterium will swim in the direction of food
and swim away from toxins.
So basically it's detecting this chemical gradient
that it follows.
But so we can see in this example,
and this isn't the case for all species,
but you can imagine that a bacterium
that swims to the left when nutrients
are on the left,
prospers compared to a bacterium that swims at random.
So with this behavior where it's swimming towards food,
that is the product of a chance mutation.
So in some sense it's an accident,
but when it discovers that solution,
that organism is more likely to reproduce.
So that solution gets retained in the population.
It gets sort of frozen, hardwired in.
And so the process of adaptation is a process
that builds up a statistical correlation
between the system, the agent, and its environment.
And so that shared correlation represents mutual information.
So mutual information is information
that's shared between the environment
and the organism.
And just to explain that a little bit more,
this correlation, basically as this correlation
gets built up, it's creating predictive knowledge.
So John Maydard Smith cites Fred Dretsky
who did kind of the pioneering work
applying Shannon's information theory
to try to quantify evolution.
So Dretsky argues that if some variable A
is correlated with the second variable B,
then we can say that B carries information about A.
For example, if the occurrence of rain
is correlated with a particular cloud,
then the type of cloud tells us whether it would rain.
So that's from a great essay called
the concept of information biology.
So we can see that you have this little
rhyming equation here.
Adaptation equals statistical correlation,
equals mutual information.
And because that shared information
allows the organism to predict its environment better,
this process is also a process of model optimization.
So the predictive model of the organism as it adapts
starts to become more accurate.
And so this whole process can be seen
as a free energy minimization process.
Of course, that's information theoretic free energy.
It's the free energy of Friston's principle.
We're not talking about thermodynamic free energy.
Anyone wants to ask a question or gets confused about that?
Let me know.
But it's basically, those things are related
and it's something that's not mentioned enough.
Minimizing information theoretic free energy,
which is just minimizing the prediction error of your model
is what allows the organism to minimize
environmental free energy.
So by acquiring information,
reducing the information theoretic free energy
allows the organism to extract energy
and reduce thermodynamic free energy.
It minimizes the free energy in the environment
and converts it into entropy.
So we kind of see how this is getting into universal Bayesianism
as it becomes more correlated.
It gains information about its niche
and therefore becomes a better predictor of that niche.
So that's what adaptation is.
It's the genome of the species accumulating information
that reduces the average organism's uncertainty
regarding the environment.
So the genome is a knowledge repository
of solutions to environmental challenges.
That allows an organism with no brain
and no mind to anticipate events in the environment.
So in this theory, as I mentioned before,
consciousness comes later.
It comes with self-modeling capacity
and a bacterium would be kind of a zombie agent.
It would have agency and it would move with purpose,
but that is not enough for mind,
or at least mind defined as consciousness.
If you wanna say that mind is just information processing,
then yes, there is mind in these systems.
That's very different than saying
that the system has a subjective experience
in a first-person perspective.
That will come in the next talk, but it's harder.
So that information stored in memory
is integrated into a statistical or predictive model
that determines the causal control systems behavioral repertoire
or the full range of behaviors an organism is capable of.
And it is this mapping of sensory inputs to motor outputs
that makes the organism move in ways
that we normally associate with mind or consciousness.
Carl Friston in a great Eon article
says all biological processes can be construed
as performing some form of inference.
I think I already read that.
But the free energy principle for those aren't familiar.
We've already explained it,
but the Bayesian brain hypothesis
and the free energy principle are the same thing.
The difference is that the free energy principle
applies to all other adaptive systems
where the other one is just focusing on brains,
but Friston realized that this is a model
and a process that applies to any system
that's trying to resist the tendency towards disorder.
So any system to stay to continue persisting
longer than we would expect naturally,
it must engage in Bayesian learning
to deal with environment uncertainty.
How much time do I have left roughly?
Still more than enough.
Okay, keep going.
I'm definitely more than half through,
I'd say I'm two thirds of the way through.
So John Campbell has this great paper
called Universal Darwinism as a process of Bayesian inference
that I kept coming across
as I was trying to understand
non-equilibrium thermodynamics and information theory.
I should say actually,
I should have gotten the books showed you each book,
but there's a great book called
The Origin and Nature of Life on Earth
by Santa Fe Institute's Eric Smith and Harold Morowitz.
Morowitz was a professor of mine.
Eric is a friend that we would have these foundations
of the mine guild.
It was like a consciousness club
that would meet at the Krasnow Institute
where I got my PhD.
And so their book, The Origin of Life on The Origin of Life
in chapter eight actually gets into this information theory
and this Bayesian inference
and describes the origin of life
and the evolution of life
as a process of Bayesian model selection.
And so that was kind of what connected
non-equilibrium statistical mechanics
to this Bayesian brain hypothesis.
And I realized that these theories
were kind of converging on the same ideas.
So John Campbell wrote this paper in 2016.
He says, Bayesian inference is an algorithm
for the accumulation of evidence-based knowledge.
This algorithm is now seen to operate
over a wide range of evolutionary processes
including natural selection,
the evolution of mental models
and cultural evolutionary processes,
notably including science itself.
So when we say that evolution is a process
of Bayesian model selection,
in the book I mentioned with Eric Morowitz
actually characterize evolution as an inference engine,
we're basically saying that when organisms
that aren't fit get weeded out,
that's basically models that aren't predictive
getting eliminated.
So the organisms that persist are the models
that were able to predict the environment best.
So inference and prediction are kind of the same thing
since the word inference is a little obscure, I guess.
So just to make this point a little more clear,
since nature is complex and intrinsically unpredictable,
the model of an organism is at some point guaranteed
to fail when reality surprises it with the unexpected.
So that's what the free energy principle is about.
Minimizing surprise is the same thing
as minimizing prediction error.
So an organism gets eaten by a predator,
a baby fails to reach his bottle,
a scientific theory fails to explain new data.
Basically when any of these things happens,
it means that the model used to predict reality
is not completely accurate.
It contains a certain amount of prediction error,
needs to be corrected, so what's the solution?
Try something new.
The old model worked well enough up to that point,
so don't ditch it, just vary it a bit
and see if it performs better.
If it does not reduce surprise,
eliminate that variant and try again.
If prediction error is reduced,
replace the old model with the new one
so that it becomes the reigning theory
and the design template for new variants to be based upon.
When a model has been updated in this way
due to natural selection, adaptive learning
or experimental testing, we can say that knowledge
has been acquired and environmental uncertainty reduced.
So here we have an image.
I should say that Infinity Maps,
German software mapping company,
helped me create these images.
Oliver Wan, I have to do a big thanks to him.
This image has a little bit more going on
than I would want right now, but you could see that
basically this represents two different mechanisms
for learning and adaptation.
So this one on the top that we're gonna talk about first
is the normal competitive evolution,
sort of Darwinian survival of the fittest.
While this mechanism over here
is the mechanism of self-organization.
So let's first talk about the normal type of evolution
we're familiar with and show that how this process
of evolution that works through variation and selection
actually generates predictive information
and creates a model which encodes knowledge
of the biologically relevant regularities
in the environment.
So first we have this, this is a bacterium over here
and so this is the simplest model.
You have an organism that's an embodied theory
or a best guess about how to stay far from equilibrium.
So evolutionary epistemology sees organisms themselves
as embodied theories.
So evolution is basically testing these different models.
So it basically reproduces and we know that
because there are going to be errors in that process,
the genome will get changed slightly
and you will get a generation of progeny
that all are slightly different.
They have slightly different configurations.
Some of these configurations will be better
at extracting energy and predicting the environment
than others and the ones that aren't good
at predicting the environment,
they get filtered out by natural selection.
So here we see design four is the winning design
because it's the best predictor and it's the best predictor
because it's the best extractor of energy.
And so that design, that organism gets to reproduce
and then you have another generation of designs
that are slightly different
and this process is an iterative process
just like science and hypothesis testing.
So over generations, you will start to get designs
that are better adapted to the environment
which we've explained means that they will be more correlated
with the environment and being more correlated
means being a better predictor.
So the knowledge that's left over after this process
is the adaptive information stored in genetic material
that reduces environmental uncertainty
and you see that this process will ultimately lead
to the evolution towards the best possible design.
So it's an optimization.
A lot of people don't think that evolution
is optimizing anything.
There's been this kind of philosophy
that evolution does just good enough
but we actually see that in terms of the computation
that it does to stay far from equilibrium
that it's actually optimized for being almost
maximally efficient with its use of energy.
It approaches something close to what's called
the land hour limit which David Wolpert at SFIs
written about but life is much more efficient
with computation in terms of energy supply needed
compared to all of our technology.
So the human brain can do solve problems
that even our best like AI systems can't solve
and it does so running on the equivalent
of one household light bulb.
So we'll come back to this self-organization process.
Oh, well, actually we'll get into that right now.
So this is the normal process that we think about
when we think about evolution generating knowledge,
predictive knowledge.
And so that's called phylogenetic learning.
Phylogenetic refers to these like generations.
So the learning is generational.
The organisms don't really learn
because they don't have brains.
They're not able to update their model in real time.
So learning is at the level of the population
and for learning to occur, organisms have to die.
Before brains, basically you have to have this competition
for there to be a learning process.
However, there's also self-organization
when these organisms don't compete
but actually find a configuration,
find it, discover a collective configuration
through their somewhat random interactions with each other.
And when they find this collective configuration
through trial and error,
basically the configurations
that are better at extracting energy
will be the ones that are retained.
So Donald Campbell, father of evolutionary epistemology,
explained this process, this evolutionary process
by which self-organization works
has blind variation and selective retention.
Or we can think of it as selection for persistence
or stability.
So fitness kind of, there's a Dawkins quote,
I think I could come out where Richard Dawkins said,
Darwin's survival of the fittest is really
just a more specific instance of a more general law
of survival of the stable.
So when we think about being fit,
at the beginning, we're talking about
just being stable, being able to find energy.
If you can't do that, it doesn't matter
whether you have agents that you're competing with or not
because if you can't get energy,
it doesn't matter if there are other people competing for it
that you won't survive.
So you don't need replication with variation to evolve.
That's what this model is saying.
And Stuart Kauffman from the Santa Fe Institute
has been talking about the importance of this marriage
between Darwinian evolution and self-organization.
But basically, because there's not this replication process,
this is how evolution occurs.
So you have a system that's a collection of components,
parts, these parts can be molecules or they could be agents.
And when these molecules are pushed far from equilibrium
by a flow of energy, of course,
humans are eating food and metabolizing energy.
So they're being powered by energy flows as well.
The system blindly explores various configurations
in the space of possible designs via trial and error.
So this system will move through a series of configurations
and those configurations that allow the system
to extract sufficient energy to stay out of equilibrium
will get retained while the configurations
that don't allow for energy extraction will get filtered out.
Either the system will collapse
and have to try a new configuration
or it'll just revert to the previous stable configuration
and it will continue trying to explore
that configuration space.
I should have said like, here's a good example,
like here's a depiction of this configuration space.
We're talking about life exploring the design space.
So basically you have a designer configuration
and then you get these different,
this exploration of different configurations
that are very close to the configuration you started out with.
So I was thinking about giving a talk on the origin of life
but I couldn't get into all this cool Bayesian stuff.
That's what the first part of the book is about.
What's really interesting is that we're finding
that self-organization as mentioned is a Darwinian process.
So there's actually a name for this dissipative adaptation
and it shows that this evolution towards
these more stable configurations dissipate more energy.
When this happens at the level of organisms
that we're talking about,
it shouldn't be surprising that it dissipates more energy
because basically as the organism evolves
to be better at extracting energy,
all that energy it's extracting
to maintain far from equilibrium
is being converted into thermal entropy.
So all self-organizing processes
are really dissipative adaptation processes
at different levels.
So this process, philosophers would say
is multiply realizable.
So this process can happen at different scales
and that's exactly what we see like right here,
the same process.
So you would have a society
like exploring different governance systems
and it doesn't know which government system is gonna work.
The best beforehand, it tries it.
If it doesn't work well, like the fall of Rome,
it will collapse and then it will reassemble.
Just to wrap up the origin of life,
so we have this process of dissipative adaptation
and if it's being pushed by the flow of energy
and it's doing this process here
where it's finding increasingly stable configurations,
collective configurations,
then basically what will emerge is an autocatalytic set.
We'll define that later, but basically,
I'm losing a lot of terms from philosophy,
I was gonna say like,
it's the beginning of an auto-poetic agent.
So like a self-maintaining agent
and it's simplest form is a chemical system
that produces outputs,
which are then fed back into the system
so that the system can self-amplify.
It's basically creating all of the molecules
that it needs to grow
and it's thought that this process occurred,
the autocatalytic set is kind of the precursor
for the first cell.
So it's kind of like a proto-cell
and it was thought to occur around hydrothermal vents
which are underwater volcanoes.
There's all this energy flowing up from the hot core,
running through geochemical energy
and there's these rocky pores
in the rocks around hydrothermal vents
which provides something like a membrane,
like a lipid membrane to hold the components in,
a Markov blanket.
So the pores in the rocks were the Markov blanket
for the autocatalytic set
and Eric Smith and Morowitz showed
that basically feeding off inorganic inputs
like carbon molecules,
like not anything, not organic chemistry where it's like life
but just like simple like carbon, hydrogen and oxygen
feeding off those inputs.
Basically the metabolic process,
it's called the reverse crab cycle.
So that process allowed the first autocatalytic set
to continuously self-amplify through this process.
So if this process is allowed to continue,
further self-organization may eventually lead
to the emergence of an organic computer
that can process, integrate and store information
about the world.
So what dissipative adaptation is doing
is as it's doing this blind variation
and selective retention process
and it's finding more stable configurations,
those more stable configurations are also predictive
of the environment.
So this dissipative adaptation process
is this autocatalytic set,
modeling the surrounding energy landscape.
So I'm arguing that this is where modeling begins.
It even begins before what we call life,
like self-replicating life
and it's dissipative adaptation,
which is a process of modeling the energy
in the environment, the energy sources.
So this isn't just one continuous process.
There are these leaps that are phase transitions,
basically we've heard of phase transitions
in physics and chemistry courses
where you have like water being heated up
and then transitioning into a gas
or the reverse when a gas becomes frozen,
you get a state of order that emerges.
These transitions towards these configurations
that are good at extracting energy,
those have also been characterized as phase transitions.
So Eric Smith, who I mentioned before
and he heard more about this phase transition theory of life,
which basically explains how information gains control
in these systems and Sarah Walker
and Paul Davies work on this basically show
that through this process,
the blind variation and selective retention,
information gets built up in this autocatalytic set
and at some point there's what they call
algorithmic takeover or informational control
and the system becomes an agent
that can start to steer and control itself
in ways that wouldn't be predicted by physics.
So living system is very much like,
we didn't talk about dissipative structures,
but like tornadoes, whirlpools, those things emerge
to dissipate an energy gradient.
Living things, because of the process of metabolism,
we are this cycling system,
this thermodynamic energetic loop.
But I wasn't gonna say about that.
So yeah, we are like the storm,
but we do have control over the storm.
We're a storm with control.
So it doesn't really make sense going back
to Sam Harris's quote that you are the storm,
you do not control it.
It's literally the information that gets built up
through evolution that allows us being this dissipative
structure like a storm to start controlling its own behavior.
So the last part is just an argument
for that second question.
Why should complexity increase?
We know that this evolutionary process
where you build up this model.
So we would think that this,
after these generations of evolution,
this organism is gonna be well adapted to its environment,
but we know that adaptation doesn't mean
becoming more complex always.
So sharks and crocodiles are sighted
as species that haven't evolved much at all
in many millions of years.
Cave fish actually evolved to become more simple.
So basically fish with eyes got isolated
in like an underground environment
where there was no need for sunlight.
And so basically fish processing light,
like eyes didn't have any survival advantage.
So basically fish lost their eyes
over many generations of evolution becoming simpler.
So if that's true,
why should evolution increase complexity?
The answer to that comes from this understanding
that evolutionary epistemology says
that a species adapting to a niche
is like a scientific theory being tested for viability.
Species will evolve not to become increasingly complex,
but to match the complexity of the environment.
A sort of simplest solution
to the thermodynamic problem
of staying far from equilibrium.
So Einstein famously said a theory should be
as simple as possible, but no simpler.
The same could be said about an organism.
You want it to be as simple as possible
while it accomplishes its task of extracting energy.
It has to be complex enough to be able
to extract energy in a competitive environment,
but a bacterium doesn't have to do,
it doesn't need intelligence.
Any extra information processing,
higher level cognition would be energy wasted
that could be energy that allows it to stay far
from equilibrium for longer and replicate more.
So it's not the case that everything will evolve
towards higher complexity,
but the reason that we do get increasingly complex species
over evolutionary time in a way
that I'm saying is inevitable.
So there is a progressive evolutionary process
that leads to higher forms.
It has to do with niche emergence.
So basically a species will evolve
to become as complex as its niche,
as its environmental niche,
but there will be increasingly complex niches
that emerge for reasons that will be explained,
but I will pause there before I get to that,
which will be what we end on.
There are no other questions right now.
So if anyone does have questions,
how about they can feel free to ask it
during this last section,
give you a second to catch your breath.
I know it's been a ton of information.
My goal is that, since this is being recorded,
it'll be something that's up.
Hopefully I've cited enough literature
that people can explore this stuff themselves
and see that like, okay, it's not this guy
that's like claiming to have like a theory of everything.
This isn't my theory.
It's a synthesis that's emerging.
And really the story has been there for quite some time.
And the cybernetics pioneers,
actually a lot of them were,
you could call them like cosmic teleologists.
A lot of them did see this continual increase in complexity.
Of course, there's nothing mystical about it
or supernatural about it.
It's a mechanistic process.
That doesn't change the fact that nature seems
to have these built-in goals that emerge
from the fundamental laws and constants,
the parameters, the fine-tuning,
but it's a completely natural, progressive,
teleological evolutionary process.
And so I'll just end up,
this is just finishing up.
It's along the same line.
So that's good.
Questions can come after this.
I know it's been quite a lot.
So I will just try to sum this up simply.
So two important principles from cybernetics.
These came from Ross Ashby,
who also created the principle of self-organization,
which was really the first time
people took self-organization seriously.
So we think of complexity science
as being the science of self-organization,
but it really goes back to cybernetics.
I think the term, I think Kant might have talked about it,
but it was Ross Ashby who tried to make it a principle
and a formalized concept.
So there are these two concepts that really,
I think anybody interested in like Carl Friston's
Bayesian brain hypothesis free energy principle
should be aware of,
because all of the way he talks about like evolution
comes from this Ashby's work,
the Good Regulator Theorem.
It was also updated,
there was the internal model principle,
which came like a decade later.
Good Regulator Theorem came,
he's both these laws,
I think came in the 50s and the 40s or 50s.
And then I think in the 70s,
the internal model principle was created.
But it basically says that any system
that regulates or controls another system
must have a model of that system.
Otherwise it can't regulate it.
So it seems pretty obvious,
but this talk of models kind of starts here
that is very familiar to like anyone interested
in like the free energy principle.
So this can be applied to inanimate systems.
I mean, controllers are like house,
like thermostats and stuff,
but Ashby was really interested in adaptive systems.
So he was thinking about evolution.
So applied to evolution,
an organism must model its environment
if it's going to extract free energy.
And an organism is a model of its niche,
like a key is a model of the lock it opens.
So when we talk about these models,
it can be kind of abstract,
but I think this model,
like a key is a model of the lock it opens,
really explains how an organism fits into a niche.
You could also say like a hand fits into a glove,
but it really,
the organism is a model of its environment.
So natural selection is essentially an information channel
that through evolution is pumping in information
from the external world, from the environment
into the organism,
such that the organism is encoding the structure of reality,
encoding the structure of the world.
And its design includes information
about the outside world.
So it's kind of a new way to think about evolution
as this process of basically the universe is modeling itself
and waking up through this process.
It's pretty interesting, kind of psychedelic.
So the law of requisite variety
is just telling you about the sophistication of that model.
So how complex does the model have to be
for the organisms to stay far from equilibrium?
Ross Ashby's law says,
so John Norton researcher at Cambridge
kind of summed it up this way in colloquial terms,
Ashby's law has come to be understood
as a simple proposition.
If the system is to be able to deal successfully
with the diversity of challenges
that its environment produces,
then it needs to have a repertoire of responses,
which is at least as nuanced as the problems
thrown up by the environment.
So a viable system is one that can handle
the variability of its environment,
or as Ashby put it, only variety can absorb variety.
So what we said before with evolutionary epistemology,
an organism evolves to become as complex
as its environmental niche requires.
It has to specifically have enough behavioral responses,
which map onto internal states.
So it has to have enough cognitive states
to respond to the number of challenges
that the environment presents challenges
in its ability to extract energy.
And when you get organisms and you get other,
you get other agents, other organisms,
then of course, what the organism has to model
is much more complicated,
because it doesn't have to just model
the energy source in its environment,
like to get food, it also has to model other modelers,
other cognitive agents.
So yeah, basically any adaptive system
has a behavioral repertoire
and a repertoire of accessible mental states
or for things without brains, computational states.
And the number of states that the organism can access
should match the number of challenges,
the number of states that could surprise
the organism by the environment.
So a cat must have at least as many states
as the ways the mouse can evade it
and the mouse has to have enough behavioral states
to get away.
So they model each other.
A swordsman, like a fincer must have many blocks
as his opponent has attacks.
And as we said, because behavioral responses map onto
unique internal states, the loss of an organism
must have as many accessible states
as required by the complexity of the niche.
So we already said this,
organism is some simplest solution
to the thermodynamic problem of staying far from equilibrium.
So a well-adapted species represents biological solution
to an existential thermodynamic dilemma.
It's a sort of living, evolving scientific theory
about how to most efficiently extract the free energy,
the lifeblood of existence out of a particular niche.
Some niches present a changing variety of challenges
that must be adapted to you
while others present hardly any at all.
So almost done here.
I know it's a lot.
Hopefully this can kind of wrap up the ideas
and kind of show how they're all connected.
But this is still on this question of how complex
is the universe?
How complex can it get?
So Olivia Judson wrote this,
published this paper called The Energy Expansions
of Evolution.
It's really nice.
People should check it out.
So she says the history of the life earth system
can be divided into five energetic epochs,
each featuring the evolution of life forms
that can exploit a new source of energy.
These sources are geochemical energy sunlight,
oxygen, flesh, and fire.
The first two were present at the start,
but oxygen, flesh, and fire are all consequences
of evolutionary events.
And then she makes this statement.
By the way, red is quotes
if people haven't figured that out.
So these are her words.
I forgot to put quote marks.
So no category of energy sources disappeared.
This has over time resulted in an expanding realm
of the sources of energy available to living organisms
and a commitment increase in diversity
and complexity of ecosystems.
So here's the way to think about it.
So taking the thermodynamic perspective
and looking at organisms as energy flow channels,
we can think of each niche on earth
as a sort of energy slot for a given species.
And an evolving population of organisms
efficiently searching the solution space
will eventually just by chance,
discover a solution to a thermodynamic problem
that it didn't know existed.
The discovery of a novel energy source
or energy extraction technique is both how a new niche
and a new species come into existence.
So phylogenetic learning, which we saw in that chart
will naturally lead to speciation
because organisms will stumble upon new ways
to exploit thermodynamic niches
that were previously inaccessible to life
purely for design reasons.
We're gonna give examples on the next slide.
So as the biosphere accumulates knowledge
through phylogenetic learning,
not only is the solution space
corresponding to one kind of thermodynamic problem
being explored, there's a growing problem space
each with its own unique solution space.
So there's an evolutionary trajectory
that's not determined in the strict sense
envisioned by Laplace where like there's no freedom
and the future is like set in stone,
but there is a sort of statistical determinism,
what I've been calling a non-equilibrium
statistical determinism that guarantees
basically the inevitability of this emergence
of a distribution of far from equilibrium attractors,
a varying degrees of complexity.
So each species can be seen as an attractor
that's exploiting this niche
and you get this basically this diversity
where you have organisms exploiting like the energy niches
that were kind of the easy ones to exploit on earth,
like the geochemical free energy we mentioned
with the origin of life.
And then sunlight was a little bit
of a more difficult challenge to extract sunlight.
It took some time for evolution to be able to do that.
So extracting energy from the hydrothermal vents
source of energy is really simple
because the energy is already like flowing
through the system, it doesn't have to do much work.
To extract sunlight, you have a moving sun,
it's a little bit more complicated,
but not nearly as complicated as organisms
that eat other organisms, so heterotrophic organisms,
because they will have to model not just like a sun
moving predictably through the air,
but have to model all these other agents,
many of which are trying to eat them to kill you.
Eat them to kill you.
So basically, answering this question,
why increasingly intelligent species emerge,
we started off with reductive autotrophs,
those organisms around hydrothermal vents,
they were a solution to the problem
of how to extract free energy from geochemical gradients,
photosynthetic bacteria, the ancestors of plants
were the solution to extract,
of how to extract all the solar energy
that was flowing through the planetary system.
So that was a big discovery made by life,
is that they can get energy directly from sunlight.
Heterotrophic organisms, organisms that eat other organisms
were the solution to the problem
of how to extract energy from life itself.
Once life starts having to model life,
other agents with causal power and adaptive behavior,
the computational task of extracting free energy
gets increasingly difficult
as increasingly complex species arise.
So by virtue of having to model each other,
the complexity of some species gets ratcheted up
by what's known as an evolutionary arms race.
So the lion is evolving,
while lions are producing offspring,
some of those lions will be better
at predicting the gazelle's movements.
The gazelle will also be creating offspring
and some of those will be better
at predicting the lion's attack.
The ones that are better at predicting
are the ones that get to stick around.
So you see how you have this ratcheting mechanism
that ratchets up complexity.
There's actually a principle called the red queen principle
that says that for an organism
to simply stay in the game of existence,
certain organisms, a certain species,
they will have to become increasingly complex.
And that comes from Alice in Wonderland.
Basically, there's a scene with the red queen
and Alice is, they're all running as fast as they can.
And Alice is like, I'm running fast as I keep running,
but I'm going nowhere.
So they're all running,
but they're not making any distance.
They're staying in place.
And the queen says something like,
oh, you see here for that, to go somewhere,
you'll have to run much faster than that.
So the idea is that for a species
that has to deal with this complex environment,
just to stay where it is,
just to stay in the game of existence,
it has to become increasingly complex.
It has to keep adapting.
So one thing that I wanted to get into more,
but I'm not going to, is this idea of empowerment.
It comes from the computational neuroscience literature.
It's similar.
It comes from Daniel Polanyi,
but it's very similar to Harvard's Alex Wissner,
Wissner Gross.
He has an idea called causal entropic forcing,
but basically these people are arguing that,
well, Wissner Gross is arguing
that a causal entropic force means that,
like basically with like evolution,
you'll get systems that are trying to maximize
the number of states they can respond to.
So the number of states they can respond to
is mirrored by their internal diversity.
So systems naturally try to increase the number of states.
And it's this ability that allows for intelligence,
because if you have more states
going back to this law of requisite variety,
you can respond to more challenges.
So not every species is increasing empowerment,
but you will get the emergence of increasingly complex
species because each species serves as food
for a potential new species.
You will get increasingly complex species
that emerge over time,
and they will be increasingly empowered,
meaning that they can respond to more environmental states
and that they have more accessible mental
or cognitive states.
I explained some of this in the last slide,
but I'll just explain a little more.
So open-ended niche emergence,
why has the evolutionary records shown
a trend of the emergence of increasingly complex forms?
Because when all conceivable niches on earth were filled,
that wasn't the end.
New species created new niches
because the free energy slot they provide
is themselves, their food.
So cybernetics guy, he's kind of like the last living
cybernetisist kind of,
I'm sure there are other people that call themselves that,
but he's kind of kept that title
even when it like wasn't trendy.
He says, is well-documented by evolutionary biologists
that ecosystems tend to become more complex.
The number of different species increases
and the number of dependencies
and other linkages between species increases.
He cites E.L. Wilson, who recently passed away,
who did a lot of work that kind of inspired
a lot of the concepts in the book,
not just this niche emergence,
but also talking about super organisms,
so collectives like ant colonies,
self-organizing systems at all scales.
But he said, not only do ecosystems
contain typically lots of niches
that will eventually be filled by new species,
but there is a self-reinforcing tendency
to create new niches.
What does that mean?
It means the biosphere, certainly ecosystems,
are themselves auto-catalytic sets.
So, Seth Lloyd, he's talking about
these chemical auto-catalytic sets,
but I should have had this on the earlier slide,
but it'll be a good way to kind of show
the equivalence between ecosystems.
Seth Lloyd says auto-catalytic sets of reactions
are powerful systems.
In addition to computing,
they can produce a wide variety of chemical outputs.
In effect, an auto-catalytic set of reactions
is like a tiny computer-controlled factory
for producing chemicals.
Some of these chemicals are the constituents of life.
Now, Stuart Kaufman,
big, you know, one of the main names
who's kind of this whole talk,
he's kind of put these ideas out there
since like the early 90s,
well, actually going back farther than that,
but he started writing books in the 90s
and really gaining exposure for the Santa Fe Institute.
He's written a recent paper, a semi-recent,
about niche emergence as an auto-catalytic process.
So ecosystems are auto-catalytically closed,
self-sustaining reaction networks.
So they're auto-poetic agents
that reliably drive up biological diversity and complexity
as they self-amplify and evolve.
So when you think about it,
really all integrated networks
of adaptive systems function as auto-catalytic sets.
There's been a lot of papers showing this,
economies, in a sense, are auto-catalytic sets,
including the social organisms we call societies
or civilizations.
So these networks are common
because they emerge spontaneously
when many organisms repeatedly interact with one another
and discover synergistic collective configurations
as nature often pressures them to do.
So we're at the end.
Almost, we've explained why complexity increases.
Evolution will not increase the complexity of every species.
They will become adapted to their niche.
They will match the complexity of the niche.
However, because new niches are always emerging
because species act as food for a potential new species.
Because of that process, you will get this increase.
You will get species that emerge
that have a higher number of,
a larger repertoire of mental and behavioral states.
So the law of requisite variety really explains
why more complex environments
create more complex niches, and this is open-ended.
There's really no limit to how far this process can go,
especially since humans who are the pinnacle
of this process, we're not, you know,
a lot of people have been against these kinds of views
because it seems like it's saying
that humans are superior.
We're superior maybe computationally,
but not superior in any other sense.
We're actually part of the biosphere,
which is this integrated interconnected system.
So it's really, you know, it doesn't make sense to think
of us as like superior to nature
because the whole biosphere is an organism
that we're just sort of an organ for.
We're basically the nervous system of the planet,
the cybernetic global system that people have called Gaia.
Some people don't like that name.
I think it's a perfectly good name.
But that's why complexity gets ratcheted up
that the final, I guess, part of this complexity
increased story is that not only do you get
increasingly complex species,
those species will interact naturally
to form higher level adaptive systems,
which are collectives.
So I call this the principle of recursive self-organization
based on Ashby's principle of self-organization.
What I'm arguing is that when you have a biosphere
with these agents and you have some are simple
and some are complex, naturally those agents will interact.
When they interact, they will, in many cases,
discover synergistic collective configurations.
So configurations that make it easier for each agent
to extract the energy they need to stay far from equilibrium.
So why do interacting agents link up to form stable holes?
The exact same reason that molecules
with the right chemical diversity
will form stable autocatalytic reaction sets
when pushed by a flow of energy.
Working collectively allows the whole system
to extract more free energy with less work.
We can, that's the whole point of synergy,
is that working together makes your workload easier
because there's a distribution of labor.
And it's really nice that this distribution of species
with some simple and some complex,
that's really what you need to create
this cybernetic adaptive system at the level of a planet
because a system needs diversity among its components
in structure and function for there to be
this distribution of labor,
which makes it this collective hole,
this synergistic holistic unit.
So it's actually good that evolution and adaptation
isn't increasing the complexity of each species.
Like each species isn't becoming intelligent,
like roaches aren't becoming more and more intelligent
over time with no limit.
The biosphere wouldn't be stable if that were the case.
It's really ecosystems need this diversity
among components just as a car with made of all engines
isn't gonna be functional or our organism made of all brains.
You need a variety of parts, some simple, some complex
because they all do different functions.
So nature promotes cooperation, collaboration and synergy
because it is thermodynamically beneficial for all parties.
Synergistic collective configurations
will eventually be discovered by many component systems
that are exploring various states or configurations
through the blind variation and selective retention mechanism
mentioned organisms only compete
until they finally figure out
what that working together makes everyone's task easier.
And that goes for humans too.
So it's kind of a moral lesson for everybody.
The nations have to work together.
We shouldn't get rid of the nations.
There shouldn't just be this evolution
into this like global government
because the nations are actually provide this diversity
that we're saying is important
because you need this diversity of component parts
to create a division of labor.
So there's strength and diversity.
This is different than the evolutionary picture
of survival of the fittest.
Whereas there's like this idea
that the stronger the most intelligent survive.
This is saying that that's not true.
It's the most adaptive that survive
has nothing to do with strength or intelligence.
Sloths have been around for many millions of years
despite being sloths, being slow
because they exploit a source of free energy.
That's not being exploited by another species.
So going back to this kind of global message
you want nations to retain their identities
but you also want them at the same time
to come together and to work synergistically.
So you basically want something like a global system
but there has to be the optimal balance
between centralization and decentralization.
Neither approach will be good on its own.
There needs to be this balance.
So as long as the biosphere is creating
a growing variety of complex adaptive systems
some of those will interact
to produce higher level complex adaptive systems
which will come together to form even larger ones.
This process continues at higher scales.
So I didn't go into this.
Left out a kind of a neat picture
that shows a brain and then the planet
and it's like information networks
but I hope that talk about Gaia and global brain
will be taken as seriously as it should be.
They really only weren't taken seriously
because there were mystical notions
associated with this word Gaia
which wasn't even James Lovelock's fault.
The name Gaia came from his neighbor
who is actually the author of Lord of the Flies,
William Golding.
So blame him for the flowery metaphor with Gaia
but yeah, the biosphere is a cybernetic organism
and we are forming something like the global brain
and a self replicating biosphere
is essentially the next step
and when we are trying to care for planets like Mars
that can be seen as the biosphere replicating.
For humans to at this point in our stage of development
we would have to kind of convert Mars
to like something like a biosphere to have like oxygen.
And so you can see how it's replication with variation.
You get the same sort of thing
but because it's a different planet
there's gonna be a variation.
It's not gonna be exactly the same
but that's how the evolutionary process continues.
I should have showed this earlier.
This is just showing how like eukaryotic single celled
organisms like amoebas will come together
to form communities like a slime mold.
These multi cellular organisms come together
to form colonies.
You see this ant colony ants actually really do
form a super organism.
You can see here they actually build a bridge
out of their bodies so that some ants
can like climb across that bridge.
So it really makes sense to call it a super organism
or at least like a super adaptive system
or like a meta system because without it
we can't make sense of this collective behavior.
That's functional.
Of course, human civilization.
We again see this hierarchy.
Now it makes more sense.
We see that these evolutionary transitions.
Oh yeah, these are called evolutionary transitions.
Sometimes I use the name meta system transition
because if we were talking about the brain
I would also talk about like the emergence
of a prefrontal cortex which is like a high level controller.
That's also like a meta system transition.
So meta system transitions are a little extend this
where it's not talking necessarily
about evolutionary transitions
but these other transitions where systems
start to model themselves.
So here we see how evolution has created
these different memory systems,
these knowledge repositories.
So it's that process of recursive self-organization
that creates new memory systems.
When you get go from single cell life
to multi-cellular life to life with brains
these are revolutions in information storage machinery.
So you can see how the information in the biosphere
gets accumulated through an evolutionary process.
These are the final points.
Yeah, so knowledge is powers
not just the hollow buzz phrase of the digital age
but it's true in the most fundamental way.
Uncertainty reducing information
is life's first and last weapon
in ongoing war with disorder.
Without knowledge life cannot exist for more than a moment
much less colonize the galaxy and beyond.
This suggests it's sitting out in the path
toward cosmic superiority.
It's not a choice that intelligent agents
like homo sapiens make upon careful reflection
nor is it just some quirky ambition
we somewhat answered by chance.
This is the main point humanities collective desire
to transcend mortality and expand outward into space.
So apparent from our current scientific
and technological endeavors SpaceX
this doesn't emerge as an accident.
This is inevitable consequence
of the fact that continual knowledge acquisition
is a fundamental biological imperative.
If life wants to persist and stay far from equilibrium
at some point it has to get off the planet
because the sun is going to die.
And it's these sorts of problems
these existential problems which create progress
because it's our awareness of this problem
which forces us to search the configuration space
for the solutions that solve the problem.
So as natural selection pumps information
from the inanimate world into life
nature begins modeling itself
and coding its own structure
and the universe begins to wake up.
We are the cosmos come alive
not metaphorically but literally.
This is Ray Kurzweil's image
from his book, This Hilarity is Near.
You can see that he sees this
he calls this the destiny of life in the universe
and he's not shy about using that word.
Again, it's not determined in a strict sense of a place
this is kind of a statistical determinism
that creates these series of attractors.
And you've seen famous people.
So some people see that idea
and they'll have been reading Brian Green
and listening to all these reductionists
and think that's not a scientific view.
Well, that's not true.
And I hope to see more of these people speaking out about it.
So Christoph Koch in Confessions of a Romantic Reductionist
says the rise of sentient life
within times wide circuit was inevitable.
Keelhar Deshardin, who really came up with this
don't have time to talk about him
French philosopher in Jesuit you should look into.
Is correct in his view that the islands within the universe
if not the whole cosmos are evolving
toward ever greater complexity and self-knowledge.
To be clear, he's not saying that earth had to bear life
that primates had to walk the African glass lands.
But he says, I do believe that the laws of physics
overwhelmingly favored the emergence of consciousness.
The universe is a work in progress.
Such a belief evokes Jeremy, I don't know
the same word for many biologists and philosophers
but the evidence from cosmology, biology
and history is compelling.
So there's some advanced blurbs for this book.
If you want to pre-order it, it comes out in June
but every order that I get from now
until then we'll count towards my first week sales total.
So that will help me get on best sellers list.
If you want to pre-order it now and you email me
I will send you a copy soon of this novel.
I also wrote called Road to Omega.
I was pretty busy in the last five years.
Yeah, I went into a cave for like four or five years
but this is a vehicle for the science and philosophy
in the book kind of like an anti-Iron Rand
at the shrug maybe the opposite philosophy.
And the Road to Omega sub-stack kind of turns this philosophy
into kind of an effort to save the world
with science, epistemology and blockchain technology.
Blockchains are part of this self-organization process.
And that's the longest talk I've ever given.
That's the longest I ever talked at one time probably
my wife will probably say that's not true
but I'm tired so let's open it up to questions
and thank you for your immense patience.
It's awesome to hear and think about it.
So there are two questions in the chat.
First is from Dean.
Dean asks, how would we explain caring
through a lens of free will or no free will?
Would free will deniers say there's no caring
when it appears that agents can or do fully care?
Yeah, so great question.
Unfortunately, I don't have much to say
without saying the things that I was going to bring up
in the next talk really explaining what free will is.
I guess I should just say right now
kind of a brief explanation of what I mean by free will.
So I hope I've made the argument that agency emerges
in adaptive systems that start off as biological organisms
and to the person that's self-driving car thing
I just to mention that real quick.
I don't think they're agents
but I do think it's possible to create systems with agency
for reasons that I haven't gone into.
It seems important that the systems
have a certain type of architecture.
So not like standard computer as a von Neumann architecture
and it's not distributed or integrated
in the way the brain is.
So it's not integrating much information.
So these systems won't have causal power.
They won't be agents.
So neuromorphic hardware has been a lot of people think
that's going to allow machines that can think
and perhaps even be conscious.
I think maybe that's a way to go.
It's probably a lot more complicated than that
that's a step in the right direction.
So agency is real.
It's due to information, gain, causal power in a system
and it starts steering the system.
So you'll see like a bacterium performing chemotaxis
but does it make sense to say
that the bacterium has free will
when it's going this way and that
just because it's not predictable
in the way an inanimate system is.
So I would say that they have agency
but they don't have free will.
What free will is and it's not my idea.
Other people have kind of been talking in this way.
Kevin Mitchell has a book, Neurogeneticist.
He's coming out with a book called Agents
which is all about agency and free will.
But the idea is that we are agents with causal power
but we're sort of where our responses
like are basically programmed responses
that are responses that occur automatically
that are informed by this information
that's been built up through evolution
and adaptive learning.
So a lot of the time we go through the day
and we're not really thinking about things like driving
or like waking up and like going to the fridge.
We're not putting conscious thought into that.
So that wouldn't seem to be free will.
To me you're kind of acting on autopilot.
So what free will is is a higher level of control
that emerges with something like a prefrontal cortex
in a global workspace.
Basically free will allow a prefrontal cortex
allows an agent to override its instinctive
and automatic behaviors.
And so free will is something that we have
but only if we're exercising this higher level of control
it's associated with cognitive control
or executive control, effortful control.
And basically if you have a healthy functioning
prefrontal cortex you're going to basically
the conscious mind is monitoring.
Consciousness is a monitor.
So it's monitoring your behaviors.
And if it detects that there's suboptimal behavior
for whatever reason like it's just automatic
kind of instinctual.
Let's say someone says something that makes us angry
and we respond immediately with like pushing them
or something that's not a wise move.
And that maybe may happen when we're fearful
because of the amygdala response
and we just have this automatic behavior.
But free will would be when the conscious mind
overrides that process.
And LeBet actually the free will studies
that everybody cites as saying that we don't have free will
he actually never said that.
He said free will is in this veto power.
Like maybe some of our voluntary movements occur
without conscious thought, but it's our ability
to override those movements that is the source of free will.
But there was more problems with that.
Actually the studies have coped to the study
showing that basically that free will readiness potential
which is like a spike in electrical activity
that occurs before you do this voluntary movement.
We think is voluntary and everyone thought that this meant
that you're not really making a conscious decision
that you could see this spike in brain activity earlier
than the person thought they made the voluntary decision.
But a new study has shown that that's only the case
when we're making like arbitrary decisions.
And when they had people making a decision about
when to donate like a large amount of money to a charity
you actually saw this readiness potential disappear.
And so it seems like deliberate thinking
which is still this like prefrontal cortex
and there's this distinction between access consciousness
and phenomenal consciousness that I didn't go into
that I would in the next talk that Adam Saffron
and integrated world modern theory really gets at.
But the idea is that the prefrontal cortex
does allow us to override automatic behaviors
and that is a sort of freedom that we have
and we also lose it.
In case of schizophrenia you see impaired
prefrontal cortex activity and drug addicts
you see impaired activity and drug addicts
you see they do repetitive behavior
even when they know that it's not beneficial to them
they will still engage in that.
So they're kind of stuck in this loop
or this unhealthy attractor with schizophrenia
there's patients that report being pushed around
by forces that are beyond their control.
I think that's because when the prefrontal cortex
is basically deactivated
people lose this sense, this ability to override
their automatic behaviors.
And I think that's what those people are experiencing
is sort of loss of this higher level agency
that we've called free will.
Another interesting just the final interesting thing
to mention about that is a Cotard's syndrome
a Cotard's delusion is this delusion
where people think they're dead
they think they're like ghost or just not alive
it's really weird.
A lot of people die from starvation
because they think they don't have to eat
because they think they're already dead.
You actually see from neuroimaging studies
they've showed like impaired activity
in the prefrontal cortex.
So maybe these people who think they're dead
have lost this high level agency
and they feel like they're ghosts or something.
As far as caring
so caring is a part of like
emerged through evolution
because you do have this benefit
to cooperating with each other
this self-organization process that we talked about
that happens naturally because basically you find
that when you work together you minimize conflicts
and align it you align interests.
And so caring altruism empathy
all of those things are as natural
and as Darwinian as anything else
but you have to add on to evolutionary theory
all of this stuff about self-organization
and cooperative evolution.
As far as he said something about why people
who don't believe in free will
I forget the exact point about the caring
what was that?
When it appears that agents can or do fully care.
I'm sorry what was the first part of it?
How would you explain caring through a lens of free will
or no free will?
Would free will deniers say there is no caring
when it appears that agents can or do fully care?
Yeah, no it flies in the face of like our everyday experience.
So like yeah, the amount of contradictions
and like logic that doesn't make sense
when you go down that path of there being no free will
or agency you just get into absurd territory.
I think when we look back it's gonna look quaint
that for so long that we thought
that everything was determined in a strict sense
and it's really a big issue
because these people who believe that
if they believe it, if they take it to heart
they're experiencing cognitive dissonance at every moment
and the people who argue against agency
they talk about religious people having to compartmentalize
to deal with the real world
but anybody who believes that we don't have agency
has to compartmentalize in the same way.
Funny little conversation between Sam Harris
and his wife Anika Harris
who wrote a book called Conscious
that is a great accessible book
but it leaves out like everything that I've discussed
and that I would discuss about like
the Bayesian brain hypothesis, global workspace theory
doesn't really go into integrate information theory
in any depth.
So like all of the things that they're missing
that do explain a lot of this stuff
can be found in like modern neuroscience.
So we are making a lot of progress
towards understanding the hard problem of consciousness
so subjective experience but also a free will and agency
but it's funny because they're having this conversation
in the podcast and they're discussing whether
since a belief in no free will as mentioned
that New York Times article, I think 2011 showed
that they have less moral behavior
and it can cause depression.
They're discussing whether they should tell their daughter
about free will or not that she doesn't have any free will.
The discussion is like should we tell our daughter
that she doesn't have free will
but the actual discussion implies that they believe
that they have some choice whether to tell her or not
they're having a discussion about whether
they should do this or not.
So there's a contradiction in their conversation
that contradicts what they believe.
What's interesting is that if they do tell her
that she has no free will and she believes it
she's actually gonna have negative mental effects.
Like it will be harmful assuming that she really believes it.
I don't know if it has that in everyone
but you do see studies that show that.
So if we do have free will it's a very bad thing
to be telling people and the last thing
I'll say about that is well it's interesting
because if she's familiar with epistemology
and they tell her that she doesn't have free will
but she goes okay that's based on a model
that has uncertainty and that model may be disproved
then she might not have the negative effects of free will.
So I think everyone should practice being a good Bayesian
and understand that our models, our theories
even the one that I just talked about will have errors
and will be shown to be wrong and if reductionists do that
they won't call free will, belief in free will
like comparing them to horoscopes
which is just I think a horrible statement
and kind of funny that physicists don't like it
when like neuroscientists start
and biologists start like talking about physics.
It's kind of strange that physicists are so sure
that we don't have free will when they're not familiar
at all with the neuroscience behind agency and free will.
So would you like me to just read a comment in the chat?
Otherwise, I think we can kind of come to a close.
If there's anything, yeah, I can do one more question.
Yeah, well, Marco and Dave and others,
thanks a lot for the great comments
and commentary in the chat.
I hope that Bobby I hope you check the live chat replay
and Sean O'Connor wrote thanks for the good
and informative talk.
Dr. Azarian mentioned the idea of evolutionary arms race.
I was hoping to recommend that he consider
if he hasn't, how an intraspecific evolutionary arms race
may relate.
I'm not familiar with the intraspecific.
So perhaps like a game theory,
Red Queen not between two species but within one species.
Yes, so you would have an evolutionary arms race there too.
Yeah, certainly, because you're competing
with other organisms and John Maynard Smith,
who I mentioned earlier, talking about like this causal power
of information in biology, he was the person
to bring Von Neumann's game theory to biological evolution.
So he did, he based on the theory of evolutionary arms race
of biological evolution.
So he basically showed that there is this game theory
sort of process being played out.
I think his examples use different species,
but I think within species,
you would see the same sort of thing.
Of course, if it's not humans,
if you have other species, people are competing,
organisms are competing, you will get increased complexity,
but there are limits.
So just because there's these evolutionary arm races
within and between species, there will still be a limit
because they have to model the environment
and just modeling all these unnecessary variables
is wasteful.
So it will ratchet up complexity in species,
but I think at least with the planet Earth
and our biosphere that humans are this sort of leading envelope
of complexity.
And so it really just is open-ended
with the most complex species.
So the most complex species is the one
that will evolve toward higher complexity.
And really there might be a limit.
There are reasons to think there are limits
to how far human biological intelligence can emerge.
I mean, can evolve towards,
there's something called a cephalization limit,
which is like how big our brain can get
because of reasons like having to do with like the skull.
But what's interesting is part of this process,
this evolutionary process as Popper and newer people
like Dennett have mentioned continues with science
and culture and technology.
So humans really have open-ended complexity
because we're augmenting ourselves with technology.
So while biological complexity may have limits,
there's no limits once we start merging with our technology.
And we shouldn't see technology as separate from life.
It's an extension of biology.
So the extended phenotype Richard Balkans explains
like beaver dams considers like the dam
that the beaver instinctually builds
as part of the whole phenotype.
So the ecosystem, the organism,
there's really no clear division
between the organism and the ecosystem.
And David Chalmers has the extended mind hypothesis,
which says that our phones are extensions of our minds
and all of our devices are.
And for that reason, we need to be worried about privacy,
but we also need to not be scared of technology.
We just need to use technology to become more human.
So we're not transcending like humanity and biology.
Technology will allow us to become hyperbiological.
Very interesting note, perhaps to close it on.
Anytime you want the dot two, we can make it happen.
It can be any format.
We can invite anyone else on.
Really awesome and interesting to think about.
Do you want any last words?
If I come back to talk about free one agency,
it'd be great to have like Kevin Mitchell
or maybe Eric Well, who's done a lot of work
on a top down causation and causal emergence
that was really influential in the book.
If you know people, you can Twitter tag them
or email them and CC us or just contact us
and we'll do that on our side.
Thanks, been super fun.
Thanks, Daniel.
I really appreciate it.
I appreciate you reading a draft of the manuscript
just like in a few days to give me some feedback
that actually helps clear up little mistakes in the book.
I heard you mentioned Marco.
Thanks to Marco and anybody else who's been watching
and chiming in with questions.
Really appreciate it.
Sorry for the information overload.
Maybe watch this again.
Maybe micro dose.
Or maybe some legal stuff.
Delta eight or weed for micro dose one.
Stay hydrated.
For people who are illegal, stay hydrated.
