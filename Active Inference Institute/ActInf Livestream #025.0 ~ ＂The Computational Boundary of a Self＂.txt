ᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠᶠ�
ɑɧᶟᶠᶠᶠ second
Cowort Hello, everyone.
Welcomes to acting Funab Live Stream, Series 24.
chrome Number 25.
Today is July 1, 2021 and we're going to be talking about this paper,
The Computational Boundary of a Self, Developmental Bioelectricity
drives multicellularity in peeled free cognition i'm blue and I'm here with Daniel
awesome.
Whoo!
Welcome to the Active Inference Lab, everyone!
We are a participatory online lab that is communicating, learning and practising
applied active inference.
You can find us at the links here on this page.
This is a recorded and archived live stream, so please provide us with feedback
so that we can improve our work.
All backgrounds and perspectives are welcome here.
We will be following good video etiquette for live streams.
Here at the short link, you'll find all of the livestreams and different series that we do in the communications unit of the Active Inference Lab, and today we're doing the contextualizing paper, the .0 video for two upcoming discussions in the first half of July 2021 on the 6th and the 13th, when we have discussions 25.1 and 25.2 on this paper and hopefully the author joining.
Today in the Active Lab livestream number 25.0, we're going to be trying to set some context and give an introduction to the following paper, the computational boundary of a self, developmental bioelectricity drives multi-cellularity and scale-free cognition by Mike Levin.
And this video is just an introduction to some of the ideas, it's not a review or a final word, it's kind of like a three-way intersection where we have people who might be within the Active Inference community looking to be exposed to some different areas like developmental biology or cognitive science.
And then another group of people who are coming from the developmental biology or cognitive science background and curious about active inference.
And then also we hope that this is exciting and interesting even for people who are not familiar with active inference or developmental biology or cognitive science.
We will hopefully try to connect it with some broader questions.
So we're going to walk through some of the aims and claims of the paper, the abstract and the roadmap and bring a few big questions and some key points of the paper so that whether you read the paper or not,
you'll hopefully be in a good spot to ask questions and learn more.
And of course in the .1 and .2 videos in the coming weeks we'll be discussing the same paper.
So save and submit your questions and let us know if you'd like to participate or contribute in any way.
So here we are on the paper itself, that's a screenshot of the cover and the aims and claims and I'll read them so that then Daniel you can give a first thought on what you thought was cool or what you thought was important about the paper.
So the aims and claims of the paper.
First, they define individuals and selves in a way that facilitates taxonomy, comparison and communication with evolved, created, biological, artificial and exobiological agents.
He says I propose a fundamental definition of an individual based on the ability to pursue goals at an appropriate level of scale and organization and suggest a formalism for defining and comparing the cognitive capacities of highly diverse types of agents.
Second, he proposes a plausible naturalistic framework for the evolutionary scale-up of cognition from the earliest origins of life, hypothesizing about the forces that drove it and the major transitions along the continuum.
And the goal of this research program is to show how complex agency and goal-directedness evolves naturally from ancient mechanisms.
So Daniel, what do you think about that?
Nice work.
Well, I thought the paper was pretty exciting because it touches on just so many big topics like goal-setting and agency, cognition and natural and artificial systems, multi-scale systems.
And then it links it in a way that people might not expect, which is through developmental biology and bioelectricity, which are kind of like processes that these life forms or other forms engage in.
So to be able to connect things that are awesome about systems that matter, like again, their goal-seeking nature, their ability to do cognition, and then connect that to a process theory, it's kind of what we're all about in active inference, connecting the cool features of the world to process theories that are tractable.
Cool.
So moving on to the abstract, I'll read the first part and then you can read the next slide.
So all epistemic agents physically consist of parts that must somehow comprise an integrated cognitive self.
Biological individuals consist of subunits, organs, cells and molecular networks that are themselves complex and competent in their own native contexts.
How do coherent biological individuals result from the activity of smaller subagents?
To understand the evolution and function of metazone creatures, bodies and minds, it is essential to conceptually explore the origin of multicellularity and the scaling of basal cognition of individual cells into a coherent, larger organism.
So I find this line of research truly fascinating and really a burning question for me is how information is consolidated or prioritized across scales, whether it's coarse-graining or salience or something else.
So do you want to read the next part?
Yep, just one thought on that and it's going to be a theme that's returned to.
It's that cognition or agency doesn't just blink into existence at a larger level of analysis.
It's actually composed of smaller cognitive units and so it's kind of like cognition all the way down.
That helps us integrate across scales but also recognize what's special about larger levels of organization like culture.
So part two of the abstract.
In this article, I synthesize ideas in cognitive science, evolutionary biology and developmental physiology towards a hypothesis about the origin of individuality, scale-free cognition.
I propose a fundamental definition of an individual based upon the ability to pursue goals at an appropriate level of scale and organization and suggest a formalism for defining and comparing the cognitive capacities of highly diverse types of agents.
Any self is demarcated by a computational surface, the spatial temporal boundary of events that it can measure, model and try to affect.
The surface sets a functional boundary, a cognitive light cone which defines the scale and limits of its cognition.
I hypothesize that higher level goal-directed activity in agency resulting in larger cognitive boundaries evolves from the primal homeostatic drive of living things to reduce stress.
The difference between current conditions and life-optimal conditions.
So I like this goal-directed aspect of this and it really kind of implies to me that it's biological. Cognition has to be biological.
But I wonder about what is the goal of molecules in their organization.
Is that a goal-directed activity?
The protons and neutrons and electrons want to reduce their uncertainty about where they are in space?
Or how does it work at a non-biological level?
Makes me wonder that.
Or strain and stress?
Those are things we psychologically experience but then you can have a ring with four carbons that's under strain and the carbons they seek to do what?
Well, get into a less stressed position, like an unstrained arrangement?
For sure.
The next part.
The mechanisms of developmental bioelectricity, the ability of all cells to form electrical networks to process information, suggest a plausible set of gradual evolutionary steps that naturally lead from physiological homeostasis in single cells to memory prediction and ultimately complex cognitive agents via scale-up of the basic drive of infotaxis.
Recent data on the molecular mechanisms of preneuro bioelectricity suggests a model of how increasingly sophisticated cognitive functions emerge smoothly from cell-to-cell communication used to guide embryogenesis and regeneration.
This set of hypotheses provides a novel perspective on numerous phenomena such as cancer and makes several unique testable predictions for interdisciplinary research that have implications not only for evolutionary developmental biology but also for biomedicine and perhaps artificial intelligence and exobiology.
Do you have any thoughts on that, Daniel?
I guess it's just cool to see development and cognition come onto equal grounding because there was ecology, evolution and development, eco-evo-devo and then it's sort of that's natural things happening and then often cognition and especially computational perspectives on cognition are seen as unnatural or designed.
And so again, all of these pieces are going to be woven together with a few pieces like bioelectricity and light cones that maybe people aren't expecting.
Cool. So the roadmap of the paper, we're going to go through the introduction, then the paper is broken up into lots of different parts.
What is a self? How do you define an individual? Body patterning, cognition, multicellularity versus cancer, defining individuation from a cognitive perspective, the agent's evolutionary backstory, conclusion, future outlook, discussion, and then some predictions and research program.
And then in the end, what does it feel like to be a pancreas? Which I renamed that part but maybe you changed it back. So we'll see. Do you want to read over the keywords?
So here's the provided keywords were development, bioelectricity and the related gap junctions, primitive cognition and our favorite active inference.
So development. I like this quote from Seth Smith, Seth Mary and Maynard Smith, which I can never say yours is last name. I feel bad. Sorry yours.
Developmental biology can be seen as the study of how information in the genome is translated into the adult structure and evolutionary biology of how the information came to be there in the first place.
So that's a kind of cool definition of development. Do you have any thoughts on that?
It reminds me of earlier discussions we had about Tim Bergen's Four Wise, which are kind of related to Aristotle's Four Wise. It's like, why is there a foot?
Well, the easy sort of material answer is because there's matter in the shape of a foot. But maybe you want to know something that's historical and over really long periods of time, it's a story about evolution, how the foot came to be selected on through time.
But development is just right there in the middle where it's the story for that individual, how that foot came to be.
Thanks, Seth. Blue, could you turn down my mic? Apparently it's a little louder to start it.
Thank you for the feedback. Yeah, if anybody has comments on the audio, Blue is doing an awesome job of first broadcaster role. So thanks, Seth.
Cool. All right, hopefully that's a little bit better.
Bioelectricity, so this is a quote from the paper.
Developmental bioelectricity is the ubiquitous exchange of slowly changing ion-based voltage signals within and among cells.
All cells are electrically active and modern neurons evolved from pre-neural precursors that were already reaping the benefits of ionic signaling for computation.
So there's some ion channels. I like that cool digital image of ion channels and cells.
And of course, this painting by Alex Gray isn't officially bioelectricity, but whenever I think of the word bioelectricity, I always think of this picture.
Do you have any thoughts, Seth?
And to connect the developmental aspect to what is mentioned here about the cells being electrically active, the neural tissue arises during development from neuroectoderm.
So before there was sort of an inner layer of these electrically specialized cells, the ones that we call neurons, there was an outer layer.
And we see that recapitulated in embryogenesis when the neural tube is closed.
So that's combining sort of ontogeny recapitulates phylogeny, which is just to say that the development of the organism carries some resonance with the way that the organism evolved through time.
And then just to remind that every cell has those pumps that maintain charge.
Maybe not all of them are involved in rapid fire signaling, but to maintain ionic gradients and therefore bioelectric gradients is essentially what cells do with their membranes.
Cool. And awesome segue into talking about gap junctions.
So this is like something that's near and dear to my heart with my like neuroscience background.
So gap junctions like were originally attributed to like neurons.
Like that's it.
Like gap junctions are there at the synapse and, you know, they facilitate the electrical signaling between neural cells, but really they're channels that permit cell to cell transfer of ions directly.
And they were originally described in nerve and muscle, but they're really found in virtually all cells that are present in solid tissues.
And then I just did a quick like brief look up of a recent review of gap junctions and it's cool like they're involved in all kinds of things, right?
Like so cell proliferation, immune response, migration, optosis, carcinogenesis, hyper hyper hyper proliferative skin disorders, lymphatic vessel diseases, inflammatory lung diseases that's like asthma, liver injury and neoplastic disorders.
That's also cancer.
So I thought that that was kind of a neat thing.
Any thoughts on this one, Daniel?
Just that active inference helps us think about how agents communicate and interact.
So if there's two cells and they have totally disjoint membranes, then they can both modify a niche in common so they could pump ions in and out of the fluid like the extracellular matrix that's surrounding the cells.
So there's a common niche that they're sharing.
That's like the least connected they could be.
And then there are also ways in which they can have a long term connection with a higher throughput.
So we're seeing a lot of these ideas of communication where we can talk about these two agents now directly exchanging information with each other as their electrochemical niche rather than just jointly modifying the shared fluid that they're in.
Cool.
Okay.
Next.
All right, primitive cognition.
See if I can play this video.
Did you want me to play it?
Sure.
If it works on your side.
Let's see it.
Perfect.
Role of actin and cell motility.
Stunning 3D animation.
Maybe we don't need the sound.
Nice.
Well, what is written in the paper is the emerging field known as basal cognition tracks the evolutionary history of learning and decision making processes beginning from the dynamic problem solving capacities of cellular and subcellular forms.
Of memory anticipation context dependent decision making and learning are exhibited by organisms from yeast and bacteria to plants and somatic cells.
Cool.
So down at the bottom what does cognition or intelligent behavior look like across scales.
Where and how does cognition arise and how does it develop or evolve convergent and divergent features and where does active inference come into play.
I think that first question is fun because it's a little easy to off the cuff just say well, I don't recognize the intelligence of a cell, because it's not, you know, doing an undergrad course, or it's not doing skillful performance like we talked about in a previous discussion.
So will we have a human centric conception of intelligence tied up with all of our cultural understandings, or is there something about intelligent behavior that might help us recognize it across scales.
And that's what turns us to these fundamentals like memory anticipation context dependent decision making.
And then once we open up to that functional level of intelligent behavior and cognition, we start seeing it everywhere.
And so instead of just seeing these cells and their behavior as taking part of an intelligent system that again only blinks into existence at the top level, they're in and of themselves intelligent actors.
Awesome.
Video got me locked in here sorry.
How about that. You want to take a see that slide Daniel.
Yep. So it's written in the paper.
I propose will come back to home use cases in a second.
At the top, it's written developmental bio electricity is the ubiquitous exchange of slowly changing island based voltage signals within and among cells.
All cells are electric electrically active and we talked about that just a few slides ago.
How ancient are these mechanisms how early was bio electric coordination exploited by evolution.
So this is raising the notion that early cognition was biomechanical is bio physical.
It involves morphological computation like we saw on the previous slide with the movie of cells, but also electrical affordances existed from the beginning.
So if bio physical affordances existed from the beginning and allowed for cognition to arise, then it makes just as much sense to say that electrical affordances for cells to communicate and do these types of cognitive processes also were exploited very early in evolution.
So primitive, meaning at a smaller level but also earlier on, and suggesting that it's bio electric was one of the earlier mechanisms of cognition is pretty cool.
And I like this quote from the paper that says the ability to operate toward a region and state space may be the primitive origin of complex cognitive systems that can entertain counterfactuals, which is to remember or anticipate events that are not occurring right now.
So we'll touch back on homeostasis but how are the goals related to homeostasis. How does bio electricity play a role in homeostasis and I think we come back around to that.
I wanted to give an example about where bio electricity and development came together with cognition.
And for some people genetic reductionism makes it so that you know the story is not complete until we know what gene is involved.
And I think that they'd find this recent 2021 paper from Drosophila fruit flies to be really interesting because what they do with a series of experiments is actually demonstrate the importance of membrane depolarization, which is to say bio electric capacity in gene regulatory networks.
So like H H and PTC are proteins that are produced by loci and the DNA, and they're part of feedback loops involving the depolarization of membranes.
So they show that regulation of that membrane potential has an important role in signaling hedgehog, and that there's a mutually reinforcing relationship between these two processes.
And then what does that allow? Well, it allows morphological computation of this developing disk of the fly that later turns into the wing.
And so there's advantages and disadvantages like with diffusible molecules, there's a tremendous amount of expressivity with what that molecule is like you have an infinite number of hormone possibilities.
But on the other hand, it's very slowly diffusing. And maybe you can only signal a short range. On the other hand, there's only like one electricity.
There's not like the blue membrane potential and you know the pink membrane potential as parallel membrane potentials, there's only one membrane potential.
So it's kind of a big knob to turn.
However, as shown here, it really does play a functional role in stabilizing gene regulatory networks.
If you were missing that part of the puzzle, it would be as incomplete as if you were missing a critical signaling molecule.
So I suspect that as advances, the kind that are going to be referenced in this paper, advances in being able to visualize and track and manipulate bioelectric fields become more accessible,
that more and more systems that were thought to be purely chemical or purely mechanical, I think that they'll be a more important role for bioelectricity.
Right, it is like one big surface, one membrane potential. So you have one membrane and that's like the differentiator right between that's the boundary right is what is enclosed or encapsulated in the membrane versus what is not.
Okay, so here we are active inference. This is the final keyword and I pulled this image out from the active inference lab.
A previous live stream that we did with Ness and Thomas.
So this is the free energy principle computation and computationalism and realism and tragedy.
And so this is just the basic action perception loop.
So you have active states, external states, sensory states and internal states.
And so the both of the active states and the sensory states are the blanket states right so you have the the internal connect on the external via these two blanket states.
So this is all of the sensory perception of the organism and the degree on which they're able to act on the environment.
Do you want to add any thoughts here, Daniel.
Just that active inference is a unifying framework for thinking about perception cognition and action, and it does that in a scale free way that's grounded in Bayesian statistics and physics.
So it's going to be deployed as a way to help us look for different kinds of behavior across scales, because the internal state could be internal to a cell.
It could be internal to a tissue, internal to the organism, etc.
And it's that expressivity of the active inference framework that is going to come into play in the paper.
Awesome, and it's a process, a scale free process.
Okay, active inference as brought up in this paper.
The author says agents scaled up by evolving from basic homeostatic loops driven by active inference, surprise minimization via addition of delays, which are memory anticipation, which is inference and networks,
which is a spatially distributed processing that enables learning and progressive abstraction or generalization from the data.
Gathering into larger collectives with optimal information structure also improves the computational i.e. predictive capabilities,
and gives rise to functional relationships such as memories and coded goal states, test operate, test exit loops that exist over and above any individual member.
These levels coexist, enabling numerous coherent selves of different scales to be implemented by any collection of living matter.
That's intense.
One of the other pieces about active inference that differentiates it from a framework like reinforcement learning is right there that there's the minimization of surprise.
And in order to minimize surprise through time, you kind of have to be doing two things that at first pass don't seem like they're going to facilitate each other,
which is the pursuit of what you already know is going to be useful.
That's called pragmatic value, as well as the pursuit of sampling things that will be informative.
That's epistemic value.
So in active inference, the way that agents through deep time minimize their surprise about perception, that's what's referenced in the top paragraph about perceptual control theory,
the way that the agents minimize their surprise about their future expectations of perception is going to be by jointly working on pragmatic and epistemic aspects of their behavior
and thinking about what behavior is going to be minimizing free energy in terms of kind of existing on the optimal trade off where you're performing, but also learning.
So these are a few features of active inference that differentiate it.
And then if we think about like a growth cone of a neuron, is it doing reinforcement learning?
Is it doing reward maximization?
It just barely makes sense.
But once we start to think about surprise minimization, like it's endowed with an evolutionary prior, it expects to connect to a neuromuscular junction.
And then maybe some of its searching behavior makes more sense.
And in the top section, also the author, you know, states that the sensory input layer is what enables active inference to operate.
So because there's receptors and channels that that's the perception, the perception for a cell.
Yeah, anyway, just thought I'd add that in.
Okay.
Greetings, Sarah.
Hi, Sarah.
Dan, do you want to read these core assumptions and I'll fix the thing. Thank you.
Classic.
So I'm only going to read the two highlighted parts here because these are paragraphs that people want more detail on.
They can definitely read the paper to learn more about.
There's three core assumptions that are laid out really clearly.
I appreciated that about this paper that it makes clear assumptions and shows how those assumptions come into play.
And then basically there's two avenues for disagreeing.
I guess one would be, I think those are invalid assumptions, but they're properly applied or one can think that they're valid assumptions but improperly applied.
And so that helps structure discussion with the contents of the paper.
So the first core assumption is a commitment to evolution.
Every capacity has a natural history and emerged from simpler variants.
I guess also evolution can proceed through a reduction of complexity.
So eventually it had to have emerged from simpler variants, but in the short time I guess it could have emerged from more complex variants.
But the commitment to evolution means the commitment to the dispelling of magical thinking and not looking for some sort of a metaphysical answer to our physical questions.
And the second assumption of the three is it is assumed that all metaphors are to be judged by their utility in driving scientific progress.
And there is not a binary categorization of scientific pictures which should be taken literally or not, which can be decided a priori.
So we're not going around with post-it notes saying what's real or what's not.
We're using utility as a guiding metric.
We can actually just take a quick visualization and then Sarah, you can say hello and give any thoughts if you'd like.
But we previously in livestream 15 and 20 talked a lot about this continuum from realism to instrumentalism.
Like is active inference the territory itself? That's realism.
We're really describing what's really there when we make an active inference model.
Or instrumentalism on the right side here is like active inference as a map.
We're just using it as something that could be used to capture some features of a system and then used instrumentally like a model.
And then here we've introduced sort of this third vector of utility, which is like, okay, whether it's the map or the territory or diagonal to that is, is it useful?
And so this is a space that's describing not just where we can think about active inference existing, but also ways to evaluate different models.
Not that one is better than the other, but these are just different dimensions that models exist on.
Yeah, I thought that was a focus.
Okay, maybe go to the third core assumption.
Onto the third one.
So much of the discussion centers around goals related to teleology, a hotly debated topic.
Here goal directedness is taken in the non magical cybernetic engineering and control theory sense of a feedback system that operates to maximize some specific state of affairs which could be modeled as a dynamical system with the tractors in its state space.
So to reiterate these three assumptions, the first one is evolution, the second one is utility, and the third one is a non magical sense of goal directedness.
So these three assumptions play nice with each other.
And then they also lead directly to this final statement that except for a few brief remarks at the end.
No claims about consciousness defined rapidly as first person experience or sense of self as qualia are made.
All the examples concerned functional third person objective capacities, computation and behaviors.
So we're kind of like outside of systems looking at them as an investigator.
This isn't about the first person perspective.
And there's always so much fascination and interest in what consciousness is.
But in a way, these three assumptions go really long distance towards just saying, hey, let's look at the systems behavior as we observe it rather than as we imagine it to be like.
So that's at least a starting point for a great discussion.
Before we jump into the figures, Sarah, do you want to give any thoughts or say hello?
Sure. Yeah, I am.
I'm kind of coming in pretty different, but I've tried to follow Michael's work quite a bit and I'm enjoying discussing it from whatever angle comes up.
And, oh, I don't know background who cares.
I'm in philosophy right now.
Yeah, that's all.
Nice.
Well, any slide you want to chime in on is great.
So.
I have to find the slides.
Okay, there.
Yeah, anyway.
Okay.
Go for figure one blue if you want.
Sure.
So this is a continuum of cognitive powers.
So this is just the first part of the figure.
We'll show the next part in the next slide.
So this is a tote, which is test operate test exit loop, which is a schema of a basic homeostatic cycle.
So the author says that by continuously taking action to minimize the distance, the difference in error between the current state of affairs and a set point describing a different possible future state of affairs,
it enables a system to pursue goals despite perturbations from the outside world and intrinsic noise.
So this is, I thought, cool, like, you know, the first, like possible counterfactual.
Like, yes, it's 75 degrees and I have plenty of sodium and potassium and, you know, calcium.
But what if I don't always, what if it's not always this way, right?
What if what if it, my state changes.
So like that, the first counterfactual may be enabled this kind of homeostatic feedback loop.
I thought that that was a neat idea put forward in the paper.
So how is this related to active inference or systems engineering, Daniel?
Well, the terminology reminded me a lot more of engineering than we often see, like sensors and actuators.
It makes it sound like it's going to be a robot.
And also this like test exit sounds like we're going to be doing sort of software evaluation.
But we can pretty clearly see the skeleton of action perception loops, whether it's framed as it was a couple slides ago with internal external states and then blanket states.
Or here where you had basically have the difference between the desired and expected value leading to policy selection, not shown here, leading to action.
Actions cause events in the environment on the yonder side of the blanket.
And then the state of the external environment influences the measurements on the inbound side, which are again contrasted with the idealized state.
And that leads to another round of action selection.
So this is an engineering way of laying out the tote test operate test exit loop.
But who knows, we're able to jump from active inference pretty nicely into a more engineering frame.
And so perhaps engineering could be integrated closely into active inference.
Yeah, it seems like the blanket states like the sensors and actuators like our, you know, the action perception part are here in the middle.
And so it kind of reminds me of the active inference loop like diagram that we showed earlier.
So it's interesting.
Next part. Do you want to go through this one Daniel?
Yep. So in figure one B, the caption reads that the scale is showing how different types of activity and systems can be ranked according to their degree of purposeness.
So again, think about purpose in the third person, not the first person, not the sense of purpose, but more what I believe Hofstetter called the anti-spectus niche.
I'm not sort of pronounce it, but it was like, think about the most mindless behavior and then push away from that.
And that's what you can call purposeful rather than imagining that there's like this pure crystallized purposeful behavior.
And it sort of goes from bottom to top in terms of the degree of purpose ability.
And on the bottom, we see basically just action that doesn't appear to have any kind of sense or purpose to it, like maybe gas molecules bumping around.
And then we progress through higher and higher levels of feedback loops.
And then each one of these brackets, it's kind of like a distinction.
So like starting the left behavior, you can take the right branch or bottom branch passive behavior, like a ball that's being thrown or active behavior.
Okay, active behavior. Is it going to be non random or random?
Like many things are random, but you know, is it a windup toy that's just doing something that is not appearing to be too purposeful?
And you continue up and up the branch choosing the higher branch each time till you get to these first and second order predictions and higher order recursive logics, which are seen as higher and higher levels of purpose.
Cool. Do you have any thoughts, Sarah?
Okay.
Daniel, do you want to take this one?
What is an individual? Well, there's so many ways to go about this, and as an ant researcher, that's always the debate.
Like, okay, is the individual the six legged next mate, and then that makes the colony like a society or a super individual, or is the colony the individual and then the nest mate is like the tissue.
So there's a lot of discussion around what constitutes an individual and how would you determine where the boundaries of individual individuality are.
And that piece I just referenced about establishing the bounds can be done in a few different ways.
One of them would be looking at where information theory is strongest or where information flows are occurring, that's the information theory of individuality.
And here we're going to take a cognitive perspective on individuation.
And McCulloch is quoted so early in the neural network days.
The definition of the paper is I propose a definition of an individual based upon its information processing structure, the scales and types of goals that a system can pursue to find slash determines the boundaries and contents of the putative agent.
So it's an informational lens on what constitutes an individual, like we can say that individual people become maybe an individual mob, just one mob, not multiple mobs, when they start integrating information differently, or when they start pursuing different kinds of goals in a different way.
And it touches on these big questions like why does it matter how we define individual as well as what other ways of thinking about individuality exists.
Yeah, it's intense right so not only like in the information theory of individuality is it like the the most concentrated information but it's also like that bi-directional information flow.
Right was is how crack hour and that group the defined individuality in that paper and so that's super interesting to me like at what point is there downward causation in an aggregate like so it's at that point that is that is like the the the crux for how they talked about individuality which is
I mean it makes sense to me right like you know my my brain tells my foot to kick the ball or I decide I want to kick the ball and so my body then acts accordingly but it's
it's really interesting to think about when that when that ha emerges that downward causation in a system anyway something I think a lot about probably too much.
Yeah, that is actually one of the few papers I actually have read and I like went with a highlighter and everything.
And I always wonder on on I was looking through the math on that and actually learned a lot about like that I didn't even think was was possible yet, but it was it was binary in a sense it was digital and and I'm never clear about when that matters and when it doesn't in these kinds of models.
So that's one thing that came up for me.
Sounds good.
No, no, it's not the Sims.
It's a cone of individuation and in to a is this sort of like colon based representation of individuality that's going to be returning in a few different guys is in the paper.
And on the plane going out in different directions from a central point is like the zone of influence or the extent of the systems ability to perceive act plan.
And then piercing that coming up and down in the C dimension is going from the past to the future.
And so this is a cool way to look at how multi scale systems or what are called compound intelligence compound intelligences down there on the bottom right exist.
So we can use this kind of a cone representation or to look at single cognitive agents and potentially contrast them like in part B, where we have a tick with what's hypothesized to be like a smaller scope spatially in the now, as well as a shorter temporal scope in the past and
with a human and then also ask maybe about what kinds of other cognitive forms exist.
And then these cones can be composed really nicely.
So like on the example on the bottom right with an ant colony, again, controversial to say that the ant is the organism when potentially the colonies the organism.
That's why I usually call them an estimate.
But we can see how the estimates are inside of the colony within this cone.
And so the colony pushes out the boundaries of what these ants can do.
So they're kind of like on different parts of the spatial plane in the current moments.
And then the colony is something that is cognitively able to move beyond the time horizon of an individual estimate by virtue of its collective organization and information processing.
This is cool and something that we like talked about a lot like offline in preparation for this and preparing the slides is like the inversion of the the typical like light cone.
So maybe Daniel, you want to walk us through this light cone and then we can maybe go back to the other one.
Yeah, so this is a similar light cone notion.
And it's just that instead of having the two cups, you know, meeting mouth to mouth and then coming pinch off in a small time.
Another way that light cones have been represented is actually with the current moments like the eye of the needle, you know, like an hourglass, the pinch point.
And then in the past and in the future are the set of states that influence a given point and then the set of states it influences.
So let's like think about that butterfly flapping its wings in the here and now.
So if you go back one time step, the air molecules that might influence it are like one layer of air molecule away.
And as you go back and back and back, more and more spatial extents matters for the state of the butterfly in the moment.
And then similarly one time step in the future, the butterflies flapping is only able to influence a small zone proximal to the insect.
Whereas further and further out into the future, more and more spatial extents might be modified because of the actions that happen in the here and now.
And then this is a Lee Kors cabinet, you know, joke on a liquor cabinet.
But it's a paper that actually uses this kind of an approach to do modeling of empirical data and to fit machine learning models, which we can talk about going forward.
Like why and how do you get a speed up of certain kinds of simulations or data fitting by approaching it like a light come.
So it's just interesting the axes here like and this is kind of how I'm used to seeing these represented our time and space right so like in physical space I am physically in this space that I am at right now.
And it's interesting as like, you know, as you go forward in time, like, you know, given enough like hours, I could theoretically like fly from New Mexico to Singapore.
But like for right now, I mean, I'm kind of limited to like my house or my block or, you know, like I don't have like point to point transport.
So I always like the way that Mike represents this light cone like in this way like in the inverse.
It's like time and space and and you know, it gets it starts in a very broad space and it proceeds to a very narrow space.
And it's like, of course, in the past, like if I go to my distant past, like I came out of an egg that was in my mother's uterus, right?
Like so in my mother's womb, like that's where I came from. I was in that one point.
And I've gone all kinds of places, I guess until now, but I'm not.
I don't feel like I'm many places now.
And I also don't feel like I'm going to be many places in the future.
So I'm interested to talk to Mike when he comes on to the live stream about the way that this is represented because it's very different.
Do you guys have any more thoughts on that?
Yeah, I have one.
I mean, it seems to me he's almost trying to do, he's almost trying to take the case of the light cone and look at a particular ambition that you might have at this point in time.
And then, and then can you carry out that ambition through time and as you get further and further, you realize there's all these impediments, you know, that come in your way.
So it's just like one axis is the ability to envision what it is you want to do.
And the other axis is the ability to enact that is the ability to, well, even control or whatever your environment, any number of things that are required to enact this vision that you have.
And that's an interesting, interesting axis transformation.
I've agreed the light cone where the that looks more like an hourglass is kind of related to our limited degrees of freedom in the current moment.
But it, you know, expanding out into the future of what we can influence.
And then the diamond shape that we see in figure two is more like our zone of what can be cognized, which goes beyond what we can influence in the current moment.
Because there's some future time when you won't be able to imagine, you know, as as the curtains close on life, and it narrows in and it's like smaller and smaller.
And then there's some point where your capacity to influence is actually kind of toned out.
And so they're two complementary ways to look at the same thing.
So it's interesting, I want to say, because I, you know, like, you look at, like there could be some inner supervening or intervening thing where it actually helps you that you never considered in this in this cone of possibility.
So you become wider, like really it's just the winding road, right?
For sure.
All right, moving on.
This is sort of taking the light cone.
This is just one and a half more slides that take the light cone and a little bit of a different, more physical direction.
But again, it's all part of a continued conversation.
So we can look at the now.
That's the middle of those three layers where there's two different like individuals, you know, Sally and, you know, friend and so it's like two of those are at different points now.
And so then we look over on the time cone on the right.
And so agent N is, you know, Nick, that's the one that we're focusing on.
And now the same time, they're at the same moment, but they're in different points in space.
And so from the point of view of N, S is a space like point.
But then in the same spot in the future or the past F or P in the same location, you know, the same address 20 minutes ago is time like and the same address 20 minutes in the future is also time like.
But then on the edges of this cone is like light, which I don't know the physics behind, but I think it's kind of a cool idea that space and time have this boundary nature.
And that there's things that are more space like, like things that are instantaneously at the same moment, but in different spaces, and more time like the pure case being the same location at a different time.
But then it's like, I'll meet you in 20 minutes to blocks away.
That's like moving through both space and time, and maybe light does that in a kind of unique way.
So that was just one way that in relativity that they talk about light cones and indeed the light cone concept is a is a physicists concept.
That's really cool to think about like that light is the boundary between space and time.
It's kind of a neat thought.
Yes.
And then on 29, I just wanted to pull one again, the details going beyond me and this discussion.
But here in a recent paper that explored how you could do simulations using light cones.
And so this is not just like sort of a metaphor or cognitive heuristic.
This is something that you can use for large scale data analysis.
And so the way which I alluded to earlier in which you can speak up a simulation potentially by using the light cone is by having a point that you're focusing on.
And then you only need to consider one time point in the past at a radius of one spatially two time points in the past radius of two spatially three three out.
And so it helps you reduce the space of what you need to calculate from all versus all to the idea of calculating more and more out in more and more past steps and more and more out as you go into the future.
So that's because in the physical interpretation, there's a speed of propagation through a media.
So things don't happen instantaneously.
So that's like light moving through a media at speed of light.
And then in the case of information propagation, it's similar.
Like if you wanted to focus on a given person and their role on an informational network, you would maybe make like an informational cone instead of needing to calculate all by all at every single time steps.
So just made us curious about how active inference related to light cones.
So how can we apply this to some of the simulation models that we've already seen.
And then just, you know, what does the past of the light cone represent?
What is the current moment?
What's the future?
Just fun, eternal questions.
Cool.
So I made this slide.
This is funny.
This light cone I actually showed when I gave a seminar at Mike Levin's lab a couple of years ago.
It's from Andrew Gallimore's paper, restructuring consciousness, the psychedelic state in the light of integrated information theory.
But I was thinking about this in terms of shrinking and expanding the boundary of the self, which the author discusses a lot in the paper here.
And just like how that would change your effective light cone, right?
Like so if you have your, your self boundary, it's like a limited light cone, like the darker one that's shown in this figure on the right.
And if you expand the boundary of yourself, it expands your light cone.
So it made me think of that as we were talking, as he was talking, as Mike was talking about the shrinking and expanding the boundary of the self in the paper.
And so I'm really curious.
Here's a couple of quotes from the paper about boundary establishment and maintenance.
So he says, the surrounding body becomes an informational shield or Markov blanket for the stem cell.
And this is, he references Carl Friston's 2013 paper.
And so I wonder about like the Markov blanket.
And I think that, you know, Daniel, this is something you and I have talked about as well about the Markov blanket, like being the defining boundary for the individual.
And like how, I mean, things must pop in and out of a Markov blanket, right?
Like if I think about the cells that are in my skin layer, right?
Like, I mean, I'm losing them all the time and new ones are constantly being added.
So there's no distinct hard line to be drawn.
So like under, like how do things pop in and out of a Markov blanket?
Like, and what do you, can you like just have like peripheral boundary nodes on the edges there?
Like I've talked before also about like the difference between like your fingernail and your cuticle.
Like there's like a small tiny layer that doesn't know whether it's a fingernail or a cuticle.
So it's like, how do you like have these like boundaries, right?
Anyway, another quote from the paper.
Crucially, by organizing into a partial electrochemical and informational pool or synctetium.
Somebody say that for me, please.
Syncytium.
Syncytium. There we go.
All of the cells are able to measure and detect events occurring within the same boundary,
creating a larger individual that emerges from the collective.
And I think this quote was like in reference to the gap junctions and how they expand that electrochemical pool by like they open up like some,
like they pull the plug on the electrochemical gradient and so it kind of enables this like cell linkage.
So that's one way that, you know, boundaries are maybe established, but any thoughts on this guys?
We'll come back to it.
I think I have a few thoughts on where the Markov blankets come into play through time.
Cool.
All right.
So homeostasis, which we promised to come back to.
So what evolutionary pressures led cognitive boundaries to the to expand?
This is from the paper.
And the author proposes that the atom of this cognitive hierarchy is homeostasis.
So reactive homeostasis evolves into predictive allostasis under the pressure to predict signals from the environment and other elements of the biosphere.
And that's like what I was talking about earlier about the first like counterfactual about, you know, what if it's not always 76 degrees and full of nutrients in my environment?
How can I regulate that reduce my uncertainty about future availability of the supplies that I need?
And also there's this nice progression from homeostasis.
So that's sort of like similar, you know, same homeostasis.
Winter is trying to get within the bound, but the best way to stay within the bounds when the environment is changing is actually to not just be reactive, but to be proactive or predictive.
And then what's the best way to be proactive?
Well, it's to have increasingly rich generative models of the niche.
If you know that nighttime is coming, you're going to be able to take really good predictive behavior right now for tonight.
If you know that winter is coming at a larger time scale, it's another level of you being able to make adaptive decisions.
So what looks like homeostasis sometimes can actually just be very skillful predictive allostasis.
Do you have any thoughts Sarah on that?
Cool.
Okay, so this one is memory in scale free cognition and active inference.
So, I don't know.
I just had some thoughts here like memory in as a gene regulatory network and this is kind of something that not really was stated in this paper but really like, you know, it's our evolutionary memory of like where we've been before and how we've come to regulate and, you know, work within our environmental condition
and like also memory as a process.
Like, I don't know.
I think about that, like where is it stored?
Is it externalized into the niche?
Like we do a lot of niche modification and so, I don't know.
It's interesting to think about our RAM and our ROM in like a biological sense.
So it's the author says, a second step in the simplest homeostatic loop is the inclusion of a richer set of hidden layers in the neural network sense.
So these are additional biochemical nodes between sensors and effectors of a given system that enable a degree of memory.
And importantly, memory can serve as the beginning of modularity because learning essentially groups diverse stimuli into compressed representations.
Complex states of affairs become remembered as compact biophysical and grams.
This is the essence of the kind of modularity when a simple biophysical event kicks off the formation of a complex morphogenetic cascade such as building a hand in embryogenesis.
One nice point there is the difference between modularity and memory about how they enable each other.
It's sort of like if everything is being mixed in one cup, there can't be a memory of different colors.
Well, if you have two separated cups, you can remember two different colors and so on.
So memory can serve as the beginning of modularity is saying that it's this relationship between things becoming distinct and being remembered through time.
Distinctness carried through time is memory.
You can remember a longer number when you have more modularity that's being propagated through time.
And then the paper on the right is an older first in paper talking about memory attention and salience and active inference where they described memory working memory as a process of evidence accumulation in a temporarily structured hierarchy.
So I guess like going back through deep time like that's where the gene regulatory network kind of comes in as a process right like the process of evolution as and that's like the working memory there anyway.
And just one note there on the multi-scale active inference models.
Sometimes the way that memory is being modeled in active inference is as a state variable that changes at a slower rate.
And so within the longer timescale model, we have a shorter timescale model and then that can be modeled from setting to setting as memory carrying over.
And so it relates to this idea that the larger cognitive system is able to also act over longer timescales as well as reach back with a deeper memory.
Because if you have the kind of short term model that's just standalone, it's like a memory list process.
But if that has inherited from a hierarchical model, the state from a previous click of the model, it's memory.
And then if it's able to imagine one more click out into the future, it's goal planning, it's anticipation.
And so in active inference, one of the ways that we integrate memory and planning together is by thinking about hierarchically nested models.
So also I wonder what role memory plays in policy selection.
Like I remember every summer when I go to Scotland, it is cold.
Like I mean, I live in New Mexico, it's like 120 degrees Fahrenheit.
So every summer I remember that when I go to Scotland, it's cold.
So now it's my policy to bring a jacket when I go, right?
So even though it's the summertime and I wouldn't normally do that.
So is that memory also ever modeled in the policy selection, Daniel?
It's a good question.
Like I wonder if you can plan to forget or, you know, I'll make a note, I'll plan to remember.
I'd say active inference just gives us a way to think about all those different affordances that real cognitive systems have like offloading memory to the niche through external computation or in terms of what you just described.
But that's a good question we can ask.
I don't actually even need to remember that it's cold in Scotland because, you know, I can just ask Google.
They will tell me the weather and it will be cold in Scotland.
So if I just remember to, you know, check my cognitive offloading device, then I don't even need to remember to bring a jacket when I go.
So, yep.
Okay, next.
So figure three.
I have one random thought, maybe it comes up in another slide, but is this question that Michael Levin has about how does it know when to stop in terms of
cell growth and what for Genesis, if it's the case that it's connected to memory in the way that he's suggesting then.
Yeah, you know, like maybe it's really the information flow.
I guess that's maybe obvious given the focus of this.
But it is interesting, you know, it's like the cell is just like, oh, we've got it.
We've got it now become multi body, you know, or become social rather than individual in order to store memory like there's a funny like break point.
Yeah, I didn't see the stop mechanism really brought up in this paper, but I have seen it.
So I'm not really sure where it ties in here.
Figure three.
I mean, I mean, it's because of the morphogenic cascade, you know, it's like, well, we're, we were born, we grow, we grow to a certain point, and then we shrivel and die.
So it's like, how does that connect to memory and information?
Wow, it's kind of suggested.
Yep.
So figure three is looking at sort of cells I view of that time cone.
And now we're going to step away from, you know, is it a time diamond or is a time cone?
And we're going to just think about the trajectory of a given cell.
Go back to the assumptions of the paper, though.
This isn't about whether the cell is experiencing things.
It's not what it's like to be a cell.
It's about how the cell has a given spatial extent in a it has given spatial extent that can be thought of as having a memory.
It inherits a history through time and then also has an anticipation zone in the future.
Then it can do anticipation of memory as a soul agent, or it can interact socially.
So what happens when it interacts socially with other agents like itself?
Well, it expands the spatial dimension in the now.
That's what's being called integrated spatial perception.
And that allows it to have expanded memory in the past.
Like if each of your five friends have a book, then there's more memory as a group because there's more books.
And then also the ability to extend the anticipation into the future.
And then this part I just highlighted in blue is joining into communication networks allows the cell to have temporarily delayed access to the information obtained by neighboring cells.
This is where the time cone comes into play.
It's not that when something is perceived by one of these cells off on the fringe, the focal cell doesn't instantly hear about it.
They hear about it one time step later.
So that's where the time the time cone comes into play.
Because from the point of view of this focal cell, just assuming that information moves one cell per unit of time.
Then at zero time points, its radius is one.
One time point away, its ability to integrate sense is one more radius away.
And so you can keep on clicking back and that's reflecting a broader and broader zone of memory.
Or you can carry it forward with a broader and broader zone of influences or states that it can affect.
And so the resulting larger individual, and again individual is being used cognitively here, not like evolutionarily,
is formed with a cognitive world that's unified by the cells sharing of information across time and space.
So no teleportation and no time travel, the limitations of propagation of information in our physical universe
means that from the point of any given cell or agents, it's existing in this time cone like structure.
Yeah, that was like the expanding the boundary of the cell and like kind of like what happens like the time cone is expanded.
And you know what this just makes me think of well first, I just want to remind everyone that this like cell cell communication is like what is what gap junctions facilitate because they're really connecting all cells and solid tissues.
But but really I thought about you know the old adage that you are your company.
And like if you think about you know your five like closest friends and that like communication like network that you have like you hear about you know world events or events that are relevant to their lives.
It might be relevant to you like you hear about it one time step later and just how like, you know your cognitive like boundary is expanded by like your inner circle.
I don't know.
Maybe think about.
Yep.
Can you just can you just re highlight or talk about the cell dimension that you're just mentioning.
Oh yeah, so that was earlier in the talk it was one of the keywords.
So let me just go back to that slide.
So here, these gap junctions.
So they are, they were originally, you know, categorized in like neural tissue and in muscle, you know, to facilitate like rapid communication.
But they're really present in every cell and solid tissue and they just perform not ion exchange but it's like passive diffusion of ions, so that it's like almost a shared intercellular space.
So what did you say to call that a kind of a information bottleneck.
I just wonder.
So maybe not as much of a bottleneck as it is like it pokes a hole in informational boundary.
So that it's the more rapidly.
Let's just say that the gap junction.
So the no gap junction.
It moves like takes three time steps for the signal, you know, one time steps to release the molecule one for it to diffuse one for it to be perceived.
So every three units of time, you're getting a radius expanding out by one.
Now let's just say that a gap junction allows one time step the direct diffusion.
So then the time cone is expanding wider because the diffusion from the target cell is able to sweep out a larger time cone.
Whereas if again if it took three units of time for every one of diffusion, it'd be like a narrower time cone.
So rapid communication, which is never instant, allows that time cone to access more memory into the presence and then influence more broadly.
And so bottleneck is sort of like thinking like a bottleneck is a constraint relative to the width of the bottle.
But in the context of a gap junction, it's actually like a channel or an opening for information transmission.
If you think about it in terms of like your inner circle of friends, imagine like you can wait for your friend to call you up and tell you this exciting new event or like you can have a wire tap into their house.
So like the gap junction is like having a wire tap into their house.
So like you always know like what is going on.
I'm also searching for another analogy that's just saying to the stuff I've been looking at lately.
Do you think it's fair that analysis is to compression function?
Like if you picture the classic neural net, a bunch of notes here, just a few in the center of the hidden layer and then expand it out.
Would that be a fair analogy for a gap junction?
Yeah, I'm not seeing it.
Sorry.
Okay, I would just to recover it.
I would just say the transmission is like a compressed form of it's like a little sampling of the chemical milieu from one cell being passed to the other.
If there was no bottleneck, no compression of information, they would be just in one unit.
They'd be in one Markov blanket.
And so there's this trade off where if you totally isolate the rate of information propagation is low, the modularity is very high though.
On the other hand, with total integration, you can't have memory because you don't have modularity.
However, you do have instantaneous or close to that transmission.
And then the gap junction exists at this kind of sweet spot that allows for modularity with narrow channels of communication, which is what Shannon was studying in the first place.
Cool.
So figure, okay.
So figure three, I think we just put popped on the cone.
Is that true?
Yeah, that's just to draw the connection between the figure two with the time diamonds time cone and then just this figure.
Cool.
Okay, figure four.
So figure three.
Yeah, well, the figure three, the slide that we just had was like, as things build out.
So that was the point of view of the agent building out.
And now it's like things fall apart.
So figure four, we see a sort of rehearsal in B of what we saw previously, which is that that target cell, it's combining sensory information.
That's able enabling it to detect patterns more rapidly, getting a big picture.
That's what it says in B.
And therefore missing information can be anticipated by this pattern seeking drive.
But what happens when things go wrong?
That's in C where this bottom right cell, the green one has gone rogue.
It has stopped communicating in a way that was participating in this broader sense making, and it has shrunk its sensory radius down.
And so in doing so, it reduced the cognitive capacity of the other four cells.
It has reduced its own sphere of influence.
And it's also introduced this adversarial dynamic potentially over evolutionary or developmental timescales.
Cool.
Any more thoughts on that one?
Yeah, it reminds me of a friend I know, but no, otherwise.
It also reminds me about how cancer research is starting to think more about the niche and the signaling between cancer and non-cancer cells.
Like cancer cells need to call down healthy blood vessels.
They need to prevent healthy immune response from taking them out.
And so it's like cancer as a dialectic or as a relationship between agents with different goals.
Again, not the experience of the goal, but acting as if it has a goal, that third person cybernetic teleology.
And so that helps us make sense of all these disparate features of cancer by thinking about internal and external states, information propagation, etc.
Do you think it would be right or off to think about the one possible place where that could go wrong happening at the gap junction?
Like the gap junction would no longer function as a good sampler compression thing, which I know you don't agree with the analogy, but something like that.
I don't know what's happening in that research area, but does that make any sense?
Yeah, we talked about gap junctions earlier and their involvement in neoplasticity and all kinds of other disorders, so definitely.
I just found this really nice paper called gap junctions in cancer communicating for 50 years.
The abstract starts with 50 years ago tumor cells were found to lack electrical coupling, leading to the hypothesis that loss of direct intracellular communication is commonly associated with cancer progression and onset.
So that's pretty interesting.
It's like when you shut down the lines of communication, like between two countries, are those two countries having an improving relationship?
Or is that like the last time that they spoke before war?
The closing down the embassy, shutting down the gap junction, it doesn't bode well for a sort of amicable resolution to conflict or communication.
That's why it's so important to maintain the avenues of communication, even when there is an adversarial relationship, because things can always get worse.
You can always shut down the communication, which will make the generative models and the incentives and the goals diverge even more.
Cool.
I don't know.
I'll send you into politics and I'm like, yeah, but wait a minute anyway.
No, but we should shut down.
They're bad.
We should shut down.
If you keep the channel open, you also stand more chance of injury by way of keeping the channel open.
Keep the channel open until you shouldn't.
This is just a fun discussion for a little bit on the evolutionary anachronism, which means just something that's happening at a different time than it's expected, like a feature from the past that gets brought back.
An evolutionary reversion.
And so in the paper, it's described that this is a breakdown of multicellularity and highlights the fact that the scale of the structure which sells work to maintain can change rapidly for cooperation towards an entire organ system or body.
That's a healthy organism to the level of a single cell.
So instead of seeing cancer just mechanistically as a derangement of signaling or derangement of replication and DNA reproduction of a cell, we can think about it informationally and cognitively and cybernetically.
Like the cell has changed its cybernetic horizon from the goals of the organism to its own local goals.
And so this concept of an evolutionary anachronism and how even in the current day, we can study anachronism in examples with avocados, a tasty fruit.
And as per the Wikipedia, it says avocados are exceptionally fatty fruits with seeds far too large to be successfully dispersed by any wild animal presently alive in the Americas.
And so that is a paper of Janssen and Martin in the 80s, which was actually talking about the ecology of large animal plant interactions of animals that we've never directly seen.
But it's like if you know that there is a really large seed and you know that there's seed dispersing mammals, then it can lead you to hypothesize that there was a seed disperser that was large enough to eat avocados whole.
And so we can look at anachronism in the current moments and help us, you know, retrace the past.
So just like the avocado is an anachronistic trait with such large seed given to the current ecology, past ecology, we can see cancer as this anachronistic reversion to a previous mode of information integration and goal setting.
That it's like it's inappropriate in the context of the goals of the body, but not necessarily within the goals of a single cell that just wakes up one day.
It's like, wow, I'm bathed in glucose. I should replicate. So can't blame that.
Also, like the cancer, a lot of the markers in cancer cells are really like it's like a developmental reversion.
So not sure if you guys are aware of that or not, but it's like they, they revert to like a more immature cellular phenotype.
And so that, I mean, it's literally like going back to the past. So it's interesting.
Yep. Steminess.
Yes. Steminess.
I don't have degrees of reversion. Like, is there something to be learned from the degree of reversion?
I'm not sure.
There's one thing that comes to mind there is there's some cancers where it goes back to like a stem cell of that tissue.
So like it's like a white blood cell cancer that like replicates a lot of white blood cells.
But when there is a cancer in a reproductive organ, sometimes it's like called a teratoma because it can have like hair and nails and stuff like that.
Because it's actually pulled back so far that it can then differentiate on all the pathways of the totipotent cell rather than a reversion up from being like a healthy reproducing white blood cell precursor to just a higher white blood cell stem lineage.
But it doesn't pull back all the way to including ectoderm.
Whereas if it was in a reproductive cell, then it could do that.
Cool. Biofilms. Do you want to take this one, Daniel?
Yep. So I think the key point here is that bacteria have ion channels just like metazones do.
You know, dopamine, GPCRs, the proteins that signal between neurons.
Those are not innovations of mammals. They're not innovations of vertebrates.
Those kinds of channels and diffusible molecules are cellular.
And so what's being shown here is just like in previous figures, we saw one kind of eukaryotic cell, right?
You knew because it had a nucleus.
We had one eukaryote connecting with a few other eukaryotes.
Well, here we have one prokaryote connecting with other prokaryotes to do the exact same thing, which is increase its sensory capacity.
Again, not instantaneously, but think time-phone, light-phone.
And so in the same way that the eukaryotic cells form a cognitive individual through their associations and affordances such as the gap junctions,
bacteria, when they form a biofilm, can also form a larger cognitive integrated individual.
And you can still say, well, but from an evolutionary point of view, the unit of selection is the single bacteria.
Okay, that's the evolutionary individuality definition.
And when we use the cognitive individuality definition, we see a lot of similarities between a multicellular organism's tissue and then a multicellular biofilm tissue.
Even not in a biofilm, I mean, bacteria have an incredible ability to like, I mean, it's like antibiotic resistance, right?
Like they do plasma exchange, which isn't like their chromosomal DNA, but it's like small little snips of DNA.
Like they just like have a handshake, like it's like a bacterial handshake.
Like now I'm going to give you some antibiotic resistance too.
Like we spread germs like COVID and bacteria to one another.
They spread plasmids to one another, which confer different properties.
And then we select for this antibiotic resistance through the use of all of our antibacterials.
And so only bacteria that have these little plasmids survive.
It's really interesting.
So even outside of a biofilm, they do some some kind of, you know, communication and like cognitive expansion of their self in like the way that we do with our inner circle of friends.
Cool. All right. Key ideas.
I just highlighted a few of these like points, but there's a huge box in the paper.
So we'll just read through the highlighted parts here.
I'll take this one.
So first, a unified integrated cognitive self or individual can be defined with respect to the integrated ability to pursue specific goals via a homeostatic process that resists perturbations.
Second, an agent's cognitive world can be quantified and characterized enabling comparison with others regardless of their material implementation by estimating the spatio temporal boundaries of its area of concern.
The volume and space and time over which the agent is able to take measurements, exert influence and functionally link disparate events, learning and association.
Three, the borders of the temporal and spatial events of which a given system is capable of measuring and acting map out a cognitive light cone, a boundary in the informational space of a mind.
So estimating the spatio temporal boundaries of an agent is something I find particularly interesting.
So I just put that in as a question at the bottom to read some of the next ones, Daniel.
Yep. So these are some key ideas for five, six, four cancer is reversible shrinking of the computational boundary of a biosystem pretty tantalizing there with the reversible.
I'm sure that's something that a lot of people would like to see.
Maybe the idea is you remind the rogue agents about bigger goal.
Like, hey, you know, I know you're hungry, but we wait in line at this restaurant so that everybody gets what takes care of them.
And maybe that helps remove the cancerous restaurant tour.
Five, agents scaled up by evolving from basic homeostatic loops driven by active inference, which is surprise minimization.
By the addition of delays, which are memory anticipation, which is inference inference has planning as inference and networks, which is spatially distributed processing enabling learning and progressive abstraction generalization data.
That's pretty cool to see active inference and elaborations of active inference at the heart of this future electrical Evo eco Evo.
It's like saying you start with action and perception, and then you can carry that forward in time planning anticipation have an extended trail of memory.
That's, you know, the past, and then you can also expand spatially.
But again, the spatial isn't instantaneous.
There's a propagation speed in the media.
And so even laterally, similar agents interact through this light cone way.
So nice to see where active inference plays into light cones there.
And then six, info taxes, the drive for better actionable intelligence about the regularities and patterns in the world.
And in the agents own mechanisms encourages cells to connect in groups via signaling.
This is another area where active inference has a lot to say and is a value add relative to a reward only framework like reinforcement learning.
Because again, what drives the bacteria to cover less into work together.
So maybe it's reward, but then you have to appeal to this idea that they're maximizing reward with their behavior, the state or leave and all this kind of stuff.
Infotaxis helps us understand that the way to get good actionable intelligence, which is kind of like active inference AI right there is to make your actions exist on the trade off frontier
but the Pareto optimal trade off between getting it done right now and expanding your epistemic boundaries.
Sometimes the right move is to contact somebody who knows better or to go to a website that might inform you better.
And so it's actually a useful action in the moment to arrange to get better information later.
And so active inference helps us think about how these different needs are traded off by organisms.
All right, so 7 collecting into, oh, I can't do it sync see him syncytium syncytium.
Do I do it? Okay, collecting into syncytium enables all of the cells to share the same data and access the same memories.
That's pretty awesome. You must assimilate. It's like the Borg.
Okay, also greed eight greed at the single cell level for information info taxes drives cooperativity as each unit expands its measurement boundary communication with neighbors and thus inevitably becomes part of a bigger self with bigger set points serving as homeostatic attractors.
So I think active inference also has a role to play here in this cooperativity so like I can reduce my uncertainty about my environment by cooperating with people who have the same goal that I have right like or cooperating becoming part of a group, you know and and therefore our efforts make a bigger effort or bigger.
Anyway, less surprise when I'm in a bigger group, because it expands that that light cone right, and then nine. There's a fundamental symmetry between anatomical control mechanisms and cognitive mechanisms.
And I think that this was discussed in terms of bio electricity in the paper.
So you guys have anything to add one thought on that is cooperation arising at a higher level.
So that just reminds me of like if you're looking through a microscope and you saw cell A eats cell B you go I mean adversarial relationship right could there be anything more directly adversarial and then you pull back and it's a white blood cell, you know, that's attacking a cancer cell.
So it's cooperative at a higher level, but it can look adversarial at a low level.
And so what does that map on to in different systems?
Can we reimagine conflict and tension as actually playing a stabilizing or cooperative role at a larger scale?
Can interpersonal differences in perspective or disagreements lead to a cooperative or regenerative collective?
This is what we hopefully move towards.
I saw some pigeons procreating yesterday while I was out walking around in my neighborhood and it definitely looked adversarial.
It looked very, very adversarial, but they're cooperating at a higher level.
Looks can be deceiving.
Okay, definitely.
I was thinking of a case where like if a tiger attacked me, I should just assume that it's like an information transfer that needs to happen.
I don't know.
Come get peace with it.
I was thinking one on that sir.
Oh, it's like in the selfish gene by Dawkins.
He says, yeah, why would you go beyond the gene doesn't make any sense?
You know, would you have mammals like doing kind acts for each other?
Just look at the lion eating the gazelle and how could that possibly be a collaborative relationship?
And then I thought, what if those two populations stabilize each other through a deep time and they can't coexist and then they actually persist better both because of that one act?
So who's to say?
But just one thing like if that is all the case, you know, if this is all like whatever man, the universe becoming like why?
Would it be that that we have such a hard time with it?
Like shouldn't it?
Shouldn't there be some mechanism that allows me to just be like, oh, okay, cool.
You know, I don't get that.
I think the mechanism is narrative.
Cognitively.
It might play out differently in different systems, but agree to disagree.
It's a narrative that we can both agree on.
We're cooperating at that narrative level.
Doesn't mean that we don't disagree.
In fact, we entrench that we disagree.
But we're agreeing at a higher level.
Cool.
Do you want to read the next one?
So yeah, just a few of the key points from 101112.
10.
Bioelectric integration helped evolve control strategies and cognitive content across the continuum from chemical networks to human minds.
11.
The key points here were that there's a scale in variance with how different systems make decisions and that we can across different systems study how the cybernetic processes of learning and parameter optimization are implemented by a large number of units pursuing
infotaxis and homeostatic goals, a.k.a. pragmatic value and epicenter value.
And 12.
A conceptual unification is proposed in this paper as scale free cognition.
And then it's talked about how these boundaries between different subunits are a major control mob between itself and the world.
Like the sound is doing the same stuff, whether it's part of an organism or part of a cancer.
But it's actually this control knob, like what are the limits of the cognitive individual that sets the cell up to act a certain way or another.
And then a reminder at the very end, from a utilitarian perspective, that the most appropriate level of analysis is to be determined empirically.
Aha, but was empiricism determined empirically.
And that is said to be the level that facilitates prediction control with the least effort by the experimenter or by the system itself.
What if they disagree and gives rise to a unified understanding that drives the most novel, robust research programs at the bench.
Nice, you know, if it doesn't advance your career as a scientist.
And it's not the case.
This was you, Daniel, active inference and multi scale communication.
Just wanted to capture a little bit about multi scale systems and active.
So here we have nested systems on top left, you know, that's an answering.
That's a picture that Sasha took of an answering that came from a Pogo ants.
And then there's the colony with a bunch of nest mates driving food around and then the colony is embedded within the ecosystem.
So within one nested system, you know, within these time diamonds that are sort of nested inside of each other.
We can think about how the internal state of one is linked to the external state being the next level up like the internal state is the brain and the external niche to the brain is the body.
Okay, now the body and the brain are the internal state for what the colony and then the colony is like the internal state for the ecological niche.
So that's something that we've seen before with how active inference helps us understand and model and simulate hierarchically nested systems.
But also we can think about interactions at the same scale like collective behavior, collective intelligence as occurring when at the same type of agents, they're interacting like laterally.
And so that's the steel arrow.
That's where you have two agents there are there each other's external state.
So active inference helps us zoom up and out and down and in and then also helps us go laterally and then not to repeat it too many times, but the lateral transmission isn't instantaneous.
It's dynamic.
It happens through time, which means that we don't need to look at all lateral interactions just the time cone.
Cool.
Predictions and research program.
There was a big list here, so I just pulled a few of them out.
I'll read some of these off, which are a lot of them questions.
So is there a quantifiable sense in which biological systems model themselves?
Can an in silico evolutionary system be built containing both genetic and physiological components, which simulates the scheme described above homeostasis and infotaxis and illustrates the emergence of different scales of cognitive horizons over time?
Can we directly observe the evolution of multicellular goals from networking of agents with single cell homeostatic goals?
Might there be higher level effects on the physiological boundaries of the cognitive sub agents within the body from exposure to psychedelics, which have long been claimed to expand transpersonal boundaries or induce ego death?
The analogies between geometric spaces and cognitive ones need to be explored further as is beginning to be done via geometric information theory.
Time diamond anyone?
Definitely. I think that there's a lot of room to go here.
Will complex engineered systems set novel goals and if so how?
It is a prediction of this view that adaptive useful robotics will require components that are themselves competent and goal seeking.
That is super interesting also because really as an intelligent being capable of cognition so are all of my parts.
So if we're going to really import give rise to intelligent life, intelligent artificial life, we have to start with intelligent artificial components.
I think that's super cool.
And also goals.
We can't just say well let's just build a bigger car or a bigger computer.
I mean what do we want this intelligence design system to be intelligence in the service of or in the way of and it's a disaster waiting to build capacity without goal.
For sure. Do you want to read some more of these?
Yep. So the second set of predictions.
So this is where Mike is setting out a little bit of his agenda.
The next work in this subfield.
Each of the fields.
They're modular. They have their own disciplinary histories, their own disciplinary anticipation.
But this subfield should focus on the discovery of bioelectric communication inducing technology.
So just like once we had chemical biology, people were really excited about finding drugs that bound to proteins.
Well, now that we're aware of bioelectricity, let's think about manipulations and measurements of bioelectricity.
Two, it's a prediction that it's possible to induce the formation of metazoan like bodies in an otherwise unicellular organism by forcing the expression of appropriate
Electrogenic proteins and gap junctions.
So he's trying to get towards some unique predictions and experiments.
A prediction that transcriptomic, which means gene expression analysis of regeneration events from bacterial biofilms plants and metazoan models of limb regeneration should so show consistent use of
Electrogenic proteins in the events that enable cooperation towards self limiting morphogenetic cascades.
So it's kind of like the structure informational or cognitive structure of recovery and repair might have some similarities across systems that wouldn't immediately be seen as similar otherwise.
Scale free cognition hypothesis suggests that multi human systems.
Kafka remote teams could have their own degree of cognition.
So as we always say, you know, things that the brain knows that the neuron doesn't things that the colony knows that the ants nest mate doesn't.
There's got to be things that remote teams or any other kind of team know that individual participants don't know.
And then the exobiology question is given a novel life form or just a novel form.
How does one know when successful communication has taken place and that's an interesting question for a lot of you.
Zeno slash exobiologists said anyone.
Cool.
Next slide.
So this is in the section what it feels like to be a pancreas, but I really pulled the point that kind of hit home for me the most out of the section and the final point that Mike makes in the paper.
So I'll just read this off.
It is striking that the process which Zen practice is meant to reverse attachment to past memories and high valence for future expectations or fears is precisely the process suggested to be responsible for the creation of complex cells with a capital s.
It is unclear whether it is beneficial or even possible to truly live in the moment and let go of past memories and future expectations, but anyone who succeeded in doing this would achieve precisely what Zen promises, the dissolution of the self.
And the final sentence of the paper which I just love recreating the unification into and liberation from larger scale unifying unifying cells with a capital s would be a true pinnacle of synthetic biology and artificial intelligence.
Engineering.
Wow.
This is a good paper.
So just keep questions at the end.
What might a good understanding of this work enable?
What are the unique predictions and implications of this work?
What are the next steps for FEP and active inference in relation to this work?
What are the goals of this research and what are you still curious about?
So we will be thinking of all of these things as we get ready to do 25.1 and 25.2 over the next couple of weeks.
So thank you for participating.
There is a feedback form for feedback and you can get in touch with active inference lab at all of these links on this slide.
Nice work, Lou.
Great job with your first broadcasting and facilitating on this one.
It was really fun.
So yeah.
And let's welcome to participate or contribute to our lab activities.
Insynchronously, synchronously, we'll figure out the right importance for you.
So thanks, Sarah, also for joining.
Thanks again, Lou.
Cool.
