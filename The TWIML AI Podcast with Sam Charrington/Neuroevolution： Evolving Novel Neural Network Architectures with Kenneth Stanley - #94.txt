Hello, and welcome to another episode of TwimbleTalk, the podcast where I interview interesting
people doing interesting things in machine learning and artificial intelligence.
I'm your host, Sam Charrington.
Just a couple of quick announcements today related to the Twimble Online Meetup.
First, the video from our December Meetup has been posted and it's now available on
our YouTube channel and at twimbleai.com slash meetup.
It was a great meetup, so if you missed it, you'll definitely want to check it out.
But you definitely don't want to miss our next meetup either.
On Tuesday, January 16th, at 3 o'clock Pacific, we'll be joined by Microsoft Research's Timnit
Gebru, who will be presenting her paper Using Deep Learning and Google Street View to estimate
the demographic makeup of neighborhoods across the United States, which has received national
media attention for some of its findings.
Timnit will be digging into those results, as well as the pipeline she used to identify
22 million cars and 50 million Google Street View images.
I'm anticipating a very lively discussion segment as well to kick off the session, so
make sure to bring your AI resolutions and predictions for 2018.
For links to the paper or to join the meetup group, visit twimbleai.com slash meetup.
Alright, on to today's show.
In this episode, we hear from Kenneth Stanley, Professor in the Department of Computer Science
at the University of Central Florida and Senior Research Scientist at UberAI Labs.
Kenneth studied under twimble talk number 47 guest Risto Mikulainen at UT Austin after
Geometric Intelligence, the company he co-founded with Gary Marcus and others, was acquired
in late 2016.
Kenneth's research focus is Neuroevolution, which applies the idea of genetic algorithms
to the challenge of evolving neural network architectures.
In this conversation, we discuss the Neuroevolution of Augmenting Topologies, or NEET, paper that
Kenneth authored along with Risto, which won the 2017 International Society for Artificial
Life's Award for Outstanding Paper of the Decade 2002 to 2012.
We also cover some of the extensions to that approach he's created since, including Hyperneat,
which can efficiently evolve very large neural networks with connectivity patterns that look
more like those of the human brain and that are generally much larger than what prior
approaches to neural learning could produce, as well as novelty search, an approach that,
unlike most evolutionary algorithms, has no defined objective, but rather simply searches
for novel behaviors.
We also cover concepts like complexification and deception, biology versus computation,
and some of his other work, including his book and Nero, a video game complete with
real-time Neuroevolution.
This is a meaty nerd alert interview that I think you'll really enjoy.
And now, on to the show.
All right, everyone, I am on the line with Kenneth Stanley.
Kenneth is a professor in the Department of Computer Science at the University of Central
Florida, as well as a senior research scientist at Uber AI Labs.
Kenneth, welcome to This Week in Machine Learning and AI.
Thanks very much.
Real happy to be here.
Fantastic.
Why don't we get started by having you tell us a little bit about your background?
Sure.
I've been interested in artificial intelligence since I was a little kid, maybe around eight
years old.
I went on to major in computer science because of that and carried that interest into graduate
school where I was at the University of Texas at Austin where I did my PhD.
There I became interested in neural networks, artificial neural networks, which are now
the basis of deep learning, which everybody's talking about, and also what's called evolutionary
computation, which means kind of Darwinian type of principles being applied inside of
computer algorithms.
And so the intersection of those two things is what's called today Neuroevolution, which
means evolving neural networks or evolving brains, you could think of it as, in a computer.
And I guess my particular interest is just how brains evolved, these amazing astronomically
complex things that are in our heads.
I was always fascinated by how an unguided process, seemingly an intelligent process like
evolution could just produce something so astronomically complex and amazing as our
own brains.
And so as a Neuroevolution researcher, I've been trying to figure out how can you actually
make algorithms that would evolve something of similar scale and complexity.
Was there anything in particular that you came across at the age of eight or so that
got you interested in AI?
Yeah, yeah.
So at the age of eight, that's when my family bought a computer.
It was like a Commodore 64.
Yes.
And it was also, my parents put me in a programming class and that was on a TRS-80.
It was a very old computer system.
Flash 80.
Yeah, exactly.
And I guess for some reason, as a little kid, it just really made an impression on me that
I could tell the computer to do anything.
Like I had this feeling like there was infinite freedom in the things that I could get the
computer to do.
If only I could just figure out how to tell it what I wanted.
And I felt like if I could just tell it how to have a conversation with me, then it would
basically be my friend or talk to me.
And I was really, really interested in just getting the computer to have a conversation
with me.
Like a casual conversation, like how are you doing, what's your name, that kind of thing.
And at first, I would write really simple programs in basic, the basic computer language
that would have like little conversations like this.
Like I'd say, what's your name?
I'd say Ken.
Like basically in typing.
And they would say hi, Ken.
And I was very impressed that we could have this kind of conversation and that I got it
to do that.
But I quickly hit a wall where I couldn't get it to like really do anything interesting.
You know, it was just a very stock scripted thing.
And at the time, like around age eight, I thought, there's some way to do this that
I just need to read a book or something like there's something that would just tell me
how to get it to have a real conversation with me.
And I didn't realize that this is like one of the greatest problems like facing humankind,
like how to get a computer to actually be intelligent, like a real person.
It took me a while actually for it to strike me that this is actually like an extremely
hard problem and there's not just like some manual you can read that can get the computer
to do that.
So probably within a couple of years, I realized this is like a huge problem and then I was
really interested and hooked and like, wow, this is actually hard and like there's got
to be a way to do this.
And I guess I would just stay captivated by that problem like forever.
But I guess I changed the shift a bit in my interest because if you look at that and
you look at it from the lens of like today's subfields of artificial intelligence, you'd
probably call that natural language processing or something like that.
And I kind of shifted away from that over time to more like lower level stuff like control,
like neural stuff.
But that was like what initially hooked me into it and got me interested in the AI.
Interesting.
And you mentioned that you studied at UT Austin.
I did an interview with Aristo, Michelin and did you study with him there?
Yeah.
So I guess it's just a coincidence that Risto is my advisor, was my advisor during the PhD.
I worked with him for years there.
Yeah.
Awesome.
Awesome.
Can you tell me a little bit about your primary research focus?
Sure.
So my primary research focus is in an area called neuroevolution and it's an area that
is probably less well known in the general public.
Like you hear tons of stuff about deep learning today, but you don't hear so much about neuroevolution.
It's certainly related to deep learning because both of them are about in effect neural networks.
But neuroevolution has this twist, which is that we're interested in neural networks,
which are for those who don't know basically these rough abstractions of what happens in
brains.
Like you know the word neural comes from neurons and neurons are in our brains.
So neural networks are roughly motivated or inspired by brains in nature, although they're
not at all accurate models of them.
But then in neuroevolution, we're combining that with evolutionary principles, which really
means kind of like breeding.
Like if you think about it, like it's like if you had a neural network that does something
good, like say drives a robot and makes it able to do attacks, like say walk, like it
gets your biped robot to walk, then like neuroevolution is kind of like you're breeding those brains.
You're saying, okay, I have a bunch of brains.
These are artificial brains.
We'll call them neural networks though because artificial brains exaggerates like how cool
they are.
They're artificial neural networks.
And we would then look at like, well, how well do they get the robot to walk, like a
whole bunch of them.
And they call that a population.
And then like we choose the ones that do better.
Some will do worse and some will do better.
And the ones that do better will have children, which basically means like new neural networks
will be born as offspring of the old ones that we chose, or we call that selection.
We selected those.
And our hope is that the offspring of those better ones will sometimes be even better
than their parents.
We keep on playing this game, which is just breeding.
So like it's not hard to understand, like some areas of AI are kind of complex and hard
to understand at first.
But intuitively this is easy because this is just like breeding horses or breeding dogs.
Just choose the ones that are better in respect to whatever criteria you have and then just
breed them and hope that like things get better over time.
And so neuroevolution is basically about breeding these artificial things rather than
real organisms, which are these artificial neural networks, and thereby getting them
to get better over generations.
And what is interesting about it to me is that like while it's like a simple concept
and principle, at least like the initial outline that I gave is quite simple just in terms
of breeding, like under the hood there's like real mysteries here because this is really
the process that produced you and me and like the high level of intelligence that we have
going all the way back to singled cells organisms.
And it's quite amazing to believe that like there is some kind of path through that space
just through breeding that can lead to something like us from something so humble and simple.
And to get algorithms to do that is an enormous challenge and not fully understood right now.
And that's where kind of the research comes in in the field.
Interesting, interesting.
And then you're also again a senior research scientist at Uber AI Labs.
What can you tell us about Uber AI Labs and how that came about and what the charter is
there?
Right.
I know Uber AI Labs around nine months ago, but I was one of the co-founders of a startup
company called Geometric Intelligence.
My co-founders were included Gary Marcus, Zubin Garmani, and Doug Bemis.
Some of them are really quite well known and have very respected researchers themselves.
And we were doing in Geometric Intelligence proprietary machine learning research and developing
new technologies and building a team that we were hoping to be a world-class research
team.
And what happened was that Uber acquired us nine months ago in December.
And when Uber acquired us, they had partly one of their aspirations was to start an AI
lab, like a real research lab in industry that researchers the cutting edge of artificial
intelligence because Uber believes and believed at the time that artificial intelligence is
a critical competitive component of the industry where Uber needs to be staying at the cutting
edge.
And Uber has and had before a lot of competence already in machine learning.
So it's not like there was nobody here.
There were plenty of people here who were very qualified in the field, but they didn't
have something that was really a fundamental research lab where they're sort of just really
pushing on the cutting edge of AI itself as opposed to just applying it to internal problems.
For example, Uber has a team focused already that was focused on autonomous driving.
And so they already had that in place, but that's an applied aspect of artificial intelligence.
And so the AI lab that was founded off of the company that we started, which we founded,
was really intended to be focused more on advancing the algorithms themselves.
And so what Uber got was basically all at once, like all of these researchers who had
this capacity to push forward the field of AI.
And so you can kind of think about it roughly in analogy with similar types of research
labs at big tech companies, like maybe like something like DeepMind, which was originally
acquired by Google or something like Facebook AI Research or Google Brain and Google.
So there's some rough analogy there between us and them.
We're much smaller, though, because we're newer, but we have the kind of similar mandates
in terms of researching the cutting edge of AI.
I should say that actually we're going to we are going to engage with the outside world
in the academic community, so you'll be hearing from Uber AI Labs.
We're going to be publishing and we understand that, like, just we cannot be a successful
AI lab if we are not engaged with the outside world.
So we will be publicizing and publishing some of our work so people can see what we're doing
and so that we can communicate with other other researchers and scientists across the world.
OK, great. Great.
Can you talk a little bit about the intersection between your work
in evolutionary AI and the kind of things that Uber is doing around self-driving cars?
Yeah, so I can't get into specifics about what Uber is doing with their self-driving cars
for an obvious reason, but I can say that that Uber AI Labs is diverse.
I mean, and that was one of the original inspirations behind geometric intelligence
or the predecessor of Uber AI Labs was to have a diverse a diverse group that isn't
just in one particular fad, which you might say deep learning is,
although it's obviously an important one that's making a lot of important contributions.
But our philosophy was that, you know, we need to not have all our eggs in one basket.
And so Uber AI Labs itself is like that, too, in that we have a lot of diversity
in terms of the expertise and areas that we cover.
And so among those, we clearly are world class in neuro evolution,
which is the field that I just described where I've focused at most of my career.
And so this is a particular direction within AI and machine learning that offers
some unique insights and angles on certain types of problems that other areas
might have a different take on.
So in terms of like autonomous driving, I mean, it's clear that the idea of the
evolution of complexity and how really high level intelligence can be evolved in
terms of complex, large, deep artificial neural networks has a connection in principle
to how you could get a really sophisticated controller for a vehicle or something
like that. And so the insights of the field of neuro evolution both directly,
which means like using neuro evolution itself as an algorithm and indirectly in
terms of insights that we gain as a side effect of doing experiments in that
area can impact how we would create algorithms that might control things like
autonomous vehicles. But I should also note that it's not the case that the only
application or even necessarily the main application of AI at Uber is in that area.
I mean, Uber has AI problems across the gamut of all of their business components.
So there's a lot of different applications that are under consideration when it
comes to like AI labs and what AI labs does.
Sure. So can you talk a little bit about how your research focus kind of
compares in contrast with what Risto is doing down at UT Austin?
Yeah, sure. So I mean, actually, there's a lot of overlap because I mean, I'm his
advisee. So I've taken a lot of the original teachings that he gave me as a
basis of my career and obviously collaborated with him for years to publish
some of the in the end, it turned out to be some of the seminal papers in the
area, both together. And so, you know, I think we're not actually so different
in terms of like the fields that we're interested in where we may differ is more
just in like what particular algorithms have we contributed to inventing since
we parted ways when I basically graduated with the PhD. And so, you know,
he's focused on his own set of innovations and I've focused on my own.
And there's some divergence there. But, you know, we really ultimately tend to
be very close because like when I've invented new things, like I don't know
is it and I'm still at the University of Central Florida as a professor, Risto
would would sometimes build on those things and vice versa. So we're very
intertwined and it's not a surprise since we started out in the same area.
Absolutely. Absolutely. And so folks that are interested in maybe some of the
background on, you know, you talked about the kind of breeding process that are
really high level, Risto and I spent quite a bit of time digging into that
in more detail, you know, so folks that are interested in that might want to
refer back to to that podcast since you've graduated. And now that you're
kind of driving your own research agenda, like what are some of the specific
algorithms that you've published research on? And, you know, how do they build on
kind of that the core ideas of genetic or evolutionary computing or algorithms?
Yeah, sure. So so in neuro evolution, which is this idea of evolving neural
networks, like one of the interesting things is that when what we're at least
for me, what I find really interesting is not just optimization, like a lot of
people in machine learning think in terms of optimization, which means just
like, how do you get this this structure to get better and better and better
with respect to a task? But I'm also interested in what you might call
complexification, which means like how do we get increasing complexity? Like the
thing that really fascinates me is like how in nature things got more complex,
like insanely more complex, not just like a little bit of incremental
increases in complexity, but like from a single cell to organism to something
that has in our brain 100 trillion connections among 100 billion cells
approximately or 100 billion neurons. And that's just amazing to me that like
some kind of unguided process could build something like that. This is not
something that was engineered. And so I'm sort of always have my eye on like
what is it that allows really high level astronomical levels of complexity to
emerge from this kind of process, kind of automated process. And so the
interesting thing in our evolution is that every time it seems like we have an
advance where we kind of figure out something about how do you get increasing
complexity to happen inside of an algorithm? And we've made some advances
including the first thing that I did in grad school, which was this algorithm
called NEET, or Neuroevolution of Augmented Apologies, which I did with
Risto, which was basically an algorithm about how can we have the neural
networks that are evolving in the computer increasing complexity over the
course of the algorithm running in the computer. And it was because I had this
real fascination with increasing complexity that it led to us introducing
this algorithm that increases complexity. But then what's interesting is that
every time we make an advance like that, it sort of uncovers some like deeper
underlying question. Because it turns out that like the explanation for why it
was possible to get from one cell to trillions is really, really subtle and
nuanced and complicated.
And when you say that, are you speaking biologically or from a in a
computational context?
Right. Good question. Yeah. So actually, those things constantly get intertwined
in my mind, like whether I'm thinking biologically or computationally.
Because, you know, the way I look at it is kind of like that biology and
computation aren't really necessarily different things. Like, in effect,
like if you read a biology textbook, you know, you feel like you're reading
about biology. But in effect, it's also about computers because, or at least
algorithms, you know, because you're talking about a principled process that
basically follows some some certain kinds of rules. And just these analog
computers that we really don't understand very well.
Yeah, you could think of like the universe as a big analog computer. We
don't really understand. And so like, I mean, but like evolution is a very
algorithmic thing, you know, you're talking about there are individuals and
those individuals reproduce. And then the thing that and who gets to reproduce is
based on a formula, which is which is obviously complicated, but basically
some some individuals reproduce some some don't. And this can be formalized as
basically like a program you could imagine writing the rules of the system.
And this is what inspired the field of evolutionary computation. I mean, people
saw the theories of evolution and biology and thought like, you know what,
this is actually not that hard to write down as a program and actually make
evolution happen artificially inside of a computer. And it turned out though
that like, if you just read a textbook and then, you know, learn these
principles that sound like good explanatory principles for like how
evolution work. Like if you read a biology text was like, well, they know
how it worked. That's an explanation. It turns out that explaining something is
easier than actually implementing it, which is basically something that we
found across the field of artificial intelligence. You know, you can read
about, you can read a neuroscience textbook and say, this is how brains
work. Of course, biologists will acknowledge we don't know everything,
but this is what we understand now. And it's a comprehensive explanation, but
it's far, far away from like telling you how to actually build a brain. So you
don't know how to build a brain just because we have some understanding of
how brains work. It's the same with evolution. Like we don't know how to
build a true evolutionary system at the scale and magnitude of what happens on
Earth, even though we know a lot of the details about what goes on. And the
missing details, like the gap between what we understand and what we can
actually build, that's where the research is. And that's where like a lot of
fascinating insights occur. And like, to me, I think that to some extent, like
when we make advances in artificial intelligence, we're actually learning
something about biology in a sense because we're realizing that there are,
that the gaps in our knowledge, like what we didn't understand, are actually
filled by something that we didn't expect, or that wasn't in the textbook
about how things work. And it's true that sometimes we may be doing things that
are not actually the same as biology, but at least they're revealing gaps in our
knowledge of biology. Because like if, in some sense, if we actually knew
everything about how things work, then we could just program it in, but we
clearly don't. And so it's kind of like, I think AI has like a higher bar in a
way than biology, where in biology, like you can explain something or
statistically analyze it, but in AI actually actually have to build it, which is
much, much harder. So it sort of forces us to grapple with the problems of the
gaps in our knowledge and biology. Now, some people in AI would just sort of
like say, not like that, that way of looking at things, because some people in
AI don't care about the biology and they just want to build intelligent things
and they don't really care, do these things correspond or not with biology.
Like that's not the goal. The goal is just to build intelligent things. We
aren't like adherent to biology or not. I tend to be more biologically
inspired, but I also agree that like, I don't really, I don't really ultimately
care whether what I build is exactly the way it works in biology or not, but I
just find it interesting and inspiring that biology has achieved things that
are just so amazing. I mean, like human level intelligence. And I find it
fascinating that we just don't know how. And like trying to probe those gaps in
my understanding, I find leads to over and over again, really deep insights in
artificial intelligence, because it's like we suddenly realize, oh, wait a
second, actually there's an explanation here, which is much different than what
we thought it might be. And so after graduate school, like there were a
succession of those that I went through, we would realize that, you know,
there's something missing still after like, for example, the need algorithm,
which actually became the most used algorithm in this sort of niche field of
neuro evolution. But we realized, you know, there's limitations on what need can
ever do. And so there's like, well, how can we get around those limitations? How
did nature get around those limitations? So like one example is that like, in
need, there's this artificial DNA, which encodes the neural network. So we have to
do evolutions, we have like an artificial DNA, which we call a genome. Well, it
would have one gene per connection in this brain that's evolving. And like, this
is clearly not going to scale, even though like this, this brain can keep
expanding. But like, if you wanted to get 100 trillion connections, which is what
we have in our brain right now in biology, we would need 100 trillion genes
in need. And there is no way that's ever going to happen. 100 trillion genes is
just astronomically insanely large. And like, for example, our genome in
biology only has 30,000 genes or 3 billion base pairs. Another way of thinking
about it. So we had to invent new algorithms. And this is after after
grad school and after need that could encode much, much larger structures. We
called these indirect encodings. And this led to something called hyperneed
event eventually, which is a new kind of genetic encoding that is much more
compact than the original need. And so hyperneed was something that I did after
I left UT Austin. And so we're where I did that independently of Risto and
led to the ability to evolve much bigger in effect neural networks. And then I
think one of the biggest things probably that that has had a lot of impact in the
field after that was something called novelty search, which is a result of
discovering that in some cases, the best way to get something in a search
process and evolution is a kind of a search process, like you're searching
through a space of possibilities is to not be trying to get it. And this was a
really counterintuitive and paradoxical insight, but really important, I think,
for realizing how things are achieved. So in other words, if you say that
you're trying to breed for something, let's say we want to get human level
intelligence, then that actually may doom you from the start. Like sometimes the
only way to get to something is to not be trying to get it. And this is a hard
kind of a bitter pill to swallow, but something that what is the mechanism of
trying that keeps you from being able to get it? Yes. So the mechanism there is
something called deception. And actually, this is something that applies way, way
outside just neural evolution. This is a general principle for everything in life.
Is that deception? It's called deception, yeah. It's basically the situation when if you are
observing that things are getting better. So it's like you have some metric for
what it means to be doing well, like a performance metric, like let's say how
well are you able to walk? And so you have some metric that says, well, how well am I
walking? And so normally, like if I was trying to get something to walk, I would
select things, meaning I would breed things that are apparently better at
walking compared to their predecessors. And I would call that their fitness. And so
that's what I mean by trying. Like I keep on intentionally picking things that
seem to be better. And this is a very intuitive idea. Like everybody for a
long time felt like this is obviously the way to get things to evolve is to
pick things that are better. But it turns out that if you're in a deceptive
situation, which it turns out, unfortunately, you often are in, that you can be
moving in the wrong direction, even though your metric for performance is going
up. And that's because like the world is really, really complicated. So it can
appear that you're improving in some way when you're actually not. And so for
example, like when it comes to walking, like lunging forward like a maniac and
falling down like a few feet from where you started may appear to actually be an
improvement in your ability to travel, you know, because basically you're getting
farther than your predecessors by throwing yourself on your head, like five
feet in front of you. But this is actually not a good stepping stone towards
really good walking behavior. In fact, like a good stepping stone might be
discovering the concept of oscillation. Like that's what your legs do. They kind
of oscillate when you walk. Well, it could be that when you initially discover
oscillation, you fall on your face. And so it actually looks like you're not
improving. And so but because your metric is basically how far did you go? It
causes you to basically be blind to the underlying discovery that's actually
essential to making the progress that you need to make in the long term. And this
problem of deception is just like universal across all kinds of endeavors,
not just in our evolution. It's like,
Is this analogous to almost like a kind of a local maxima kind of issue? Yeah,
I mean, it's basically the same thing. It's related to local maxima, local
optima, or premature convergence. Sometimes people would call it so getting
stuck on a local optimum. But I think that the insight that we have that's
different from just saying, okay, well, we just rediscovered local optima because
we already knew about local optima. Exactly. It's just how utterly profound
the problem is that like you cannot just like, I mean, people think, well,
there's ways of getting around local optima. You know, I mean, there you can
there's tricks. We have diversity. We have randomness, stochasticity. There are
things we can do to kind of jiggle things around a little so we don't just get
stuck on a peak, which is what kind of we think of local optima is like getting
stuck on a peak in a big space that like that's just not going to cut it in
certain types of problems because they are just so absolutely complex.
That almost no matter what you do, deception is going to kill you. And we
showed this when we introduced this algorithm called novelty search that in
some problems that it was like shockingly terrible what deception could do to
you in these spaces. And what was profound was that we showed that in certain
problems like this where deception is a really big problem. And I would claim
that deception is a really big problem in like almost any interesting problem.
And I can kind of demonstrate that later if we want to get into it. But when
it is a serious problem, then we showed that with this novelty search algorithm
that we introduced, which was basically not trying to solve a problem, but rather
it was just driven by selecting things that are more novel. So not things that
are better, but just more novel, that this would actually be better at
solving a problem that was deceptive than an algorithm that was actually
explicitly being driven by selecting things that were better. So like the
lesson it showed is it can be better sometimes to not be trying to solve the
problem than to actually try to solve the problem in terms of getting a better
solution. And this obviously really counterintuitive and paradoxical and
upsetting maybe even, you know, because it's like embarrassing in a way for
anybody who's like saying, okay, I've got this really good optimization algorithm
to lose to an algorithm doesn't even know what kind of problem it's trying to
solve. And that's sort of what novelty search is. Novel research is a
divergent search algorithm. So basically, it's just trying to find things that are
different than what it's found before.
It sounds a little bit like, you know, explore exploit where your explore is
kind of optimizing for newness.
Yeah, yeah, it is. It is related to this kind of exploration exploitation
dichotomy that a lot of people talk about machine learning. But it's also
different, I think. So like there's an additional element of insight here
beyond that, which is really important, which is that when we think of
exploitation versus exploration, like often we think of exploitation as
following some gradient, which means information towards something that we
are trying to get to. So in other words, we're using information to move in a
direction that's intelligent. But interestingly, exploration, we tend to
think of as sort of random moves that are sort of ignoring the informed
gradient. So it's like, let's just go somewhere and see what happens. And
that's what we think of exploration. But what novelty search showed is that
there is a principled kind of exploration that is not random, that
actually exploration is something that's also very informed. And so in the
novelty search case, you're informed by where you've been because novelty is
basically a comparison between where I am and where I've been before. So it's
anything but random. It's a very informed gradient. It's just that it's the
gradient of novelty instead of the gradient of the objective. And this is
actually a very information rich gradient because if you think about it, you
know a lot about where you've been. In fact, you know more about where you've
been than you know about where you're trying to go. Because the whole problem
with where you're trying to go is you don't know about it. Otherwise, you
would just go there. So novelty is actually more informed, I'd say, than
the objective gradient. And for this reason, it's an extremely interesting
gradient to follow, like the gradient of novelty. Because you're being pushed
away from where you've been before. And it turns out that you will be
inevitably pushed towards higher complexity. So it's really tied into this
idea of increasing complexity. Because if you think about it, like as soon as you
exhaust all the simple things you can do in the world, like the only choice you
have if you want to continue to create novelty is to do something more
complex. And so ultimately, there's an inevitability that like with novelty
search that you're going to be pushed towards increasing complexity. So I think
of it as almost like an information accumulator. Like in order to continue to
do novel things in the world, you have to accumulate information about the world.
So for example, like you could imagine if you were trapped in a room, and I
told you like to just do novel stuff. Like for a while, you could just run
around randomly and you'd like bump into walls and everything you do would be
novel. But eventually, you'd bump into all the walls in the room. And so at
some point, you're gonna have to learn how to not bump into walls. And when you
do that, you're gonna have to learn what a wall is and how to sense a wall and
how to navigate walls. And eventually, you have to learn how to open a door
because you have to get out of the room eventually to do something new. And
eventually, you're gonna have to get off planet Earth and go to Mars. And
clearly like doing that requires like learning extremely deep and
complicated facets of how the universe works, like physics. And so you're gonna
be forced to become an expert on the domain where you find yourself if you're
gonna be pushed towards doing more and more novel things. And so knowledge
actually is a very deep and interesting kind of a process. And that's why
sometimes it alone will do better than actually trying to solve the problem
you're trying to solve. If you think like evolutionarily, like if you think
about like how could we get to human intelligence from a single cell, it'd be
crazy to do selection based on the intelligence of single-celled organisms.
Like we wouldn't start out by applying IQ tests to single-celled organisms.
That would just kill the population. I mean because none of them are
intelligent at all. And so it's funny, but in a sense the reason that we got to
where we are today is because we were not trying to get there. Like if we had
started out where selection was based on intelligence, then everything would have
died or we would have gone nowhere and we wouldn't have gotten to where we are
today. So we see this issue of deception come up over and over again.
Like it turns out that like there was a turning point long ago,
eons ago, where symmetry, bilateral symmetry was discovered.
These are our ancestors. There's these bilaterally symmetric flatworms.
There's no indication that it's had anything to do with being more intelligent.
But actually it does in some kind of like really really long-term sense. Like that
was an important discovery that led ultimately, or a stepping stone that
leads ultimately to human level intelligence. But you wouldn't be able
to predict that on the basis of doing an IQ test.
And yet we needed to lock that in. So in some sense we could recognize that was
interesting from a novelty perspective because it was a very new innovation.
But we cannot recognize it from a performance perspective because at that
long long ago point in time, it's not an indicator at all from the point of
view of performance. Like if the ultimate indicator is intelligence.
And this is another kind of example of deception and why many things are not
going to be possible to discover if we just set them as a goal and just select
based on those things. And this is a principle not just for
evolution but for life too. You know like there are many inventions
that like would not have been invented if they had been our goal to invent them.
Which is again the paradox coming up. Like computers for example where the
first computers were based on vacuum tubes. But the people who invented
vacuum tubes were not trying to invent computers.
Like if you had gone back to the 1800s and told all the researchers working on
vacuum tubes who were interested in electricity.
That like actually there's something more interesting like a computer.
And maybe you should just invent that. Like forget this boring vacuum tube stuff.
You would neither have vacuum tubes nor computers.
So like once again we needed people to be exploring very diverse ideas
without having their eyes on the prize. If you think of the prize as like a
computer in order to eventually get the prize. And so there's a paradox there.
And so this concept is so general and connected to this novelty search idea
that we wrote this whole book about it called Why Greatness Cannot Be Planned.
After a long time researching novelty search and a long time for me talking
in various forums and venues about novelty search.
And I realized that like the principles are really general about this paradox.
This is what I call the objective paradox. That like it's actually relevant to
all society. Like how we run our institutions. Like you know we give
money to people based on them making progress with respect to an objective.
Like this is what granting agencies do like in the sciences.
And it's actually not principled in the long run. Like we have
there are other processes that need to be recognized and respected if we really
want to be able to achieve really really ambitious ends.
And so that's why we wrote this book basically to introduce these principles
of deception and divergent search and the objective paradox
to the general public. We were hoping that maybe this would actually
provoke a discussion of these things in a larger sense
because of the fact that it affects many of the kind of attempts at innovation
that we as a society are engaged in. So it turned out to have really broad
implications across culture and society. Interesting. And then one of the
papers that I noticed is one called Galactic Arms Race. Is that an extension
of this work or is that a different direction?
It's related. Yeah it's related. So like we as we started to understand
this idea of we call it sometimes divergent search. Like searches that are
not aimed at a particular goal but rather which are diverging through
the space of what's possible. They're kind of searches that like
show you all the cool stuff that you could find. Like not just one thing.
Like Evolution on Earth is kind of like that. It's like they're not like one
thing it's trying to do. It wasn't like trying to get human level intelligence.
It's kind of like illuminated all of the possible cool stuff that's out there
in nature. Like all of the you know diversity of nature.
And so we started to realize these algorithms are really cool
that do stuff like that perhaps for applications in the real world.
Like in Galactic Arms Race the application is a video game.
And our idea there was like maybe we could put one of these divergent search
algorithms in a video game so it would generate the content in the game.
And you'd get more and more cool content just like flowing into the game from
nowhere. Like no human has to actually design or
invent it. And in the case of Galactic Arms Race it was the weapons of the ships
that you fly. Like people are familiar in video games like with
playing games where like you have to pick up new types of lasers or weapons or
guns or something like that. So we said let's let Evolution invent the weapons.
But with a kind of a novelty search like process where it's not like aiming for
like the optimal weapon. It's just diverging through the space of weapons.
But with some information about how humans are actually using them.
So it's informed by the humans in the game and in real time inventing new
weapons for the humans to try. And so there's an interaction we call
interactive evolution between what humans do and what evolution does.
And it caused like all these cool weapons to be invented. Things that I don't
have never seen in any other game that were just invented by the computer itself.
And it's kind of I think a really nice exposition of like the potential of like
divergent search or novelty like searches to create kind of open worlds where
things are just continually generated. And sometimes we call this open ended
evolution that are interesting and hopefully without end.
What's an example of a type of weapon that was invented in this game.
Okay. Yeah. There's a couple of good ones. So like one was I so there's funny we
started naming these things after the fact because they don't actually have names
because they're invented by the computer. But like one we called a tunnel maker
which would basically generate like two streams of particles. These are all
particle weapons that would sort of like very slowly shoot on the left and right
side of your spaceship. So basically it created a protective tunnel that you
could fly through. Okay. And then in the middle of that tunnel there was another
faster stream that was actually used for shooting things. So you would be
creating basically like a shield that would like shoot out from your sides
that you could then fly through. Okay. There was another one that we called a
lasso which it just looked like it looked like a cowboy's lasso. You know it's
just like shot out and like created like this spiral around the enemy and then
like closed in on it. And it was really surprising that this thing was
invented and it was kind of interesting because I actually it's not a great
weapon in an objective sense like the lasso one because like I think it's much
better probably just to shoot straight at something and kill it. But like the
players loved it because of the aesthetics. It's just so interesting and fun like to
have the lasso weapon and to kind of show off because it was a multiplayer game
so people could see each other's lassoes that it became popular. And the game
just kind of went with it. You know the game didn't say this is objectively worse
or objectively better. It just saw that people were interested in lassoes who
created more lassoes and diverse lassoes and we had all these lasso weapons
proliferating in the world because people like them whether they're
optimal in some objective sense or not.
Is there an argument that says that the issues around that you identified in
novelty search and getting led down the wrong path. The example I guess you gave
was with a robot trying to learn how to walk and kind of using a motion that
kind of allows it that kind of doesn't lead it towards walking and eventually
let it fall on its face. I guess the thought is are you know can all this be
boiled down to just not being able to express enough sophistication in our
objective function or not being able to express our objective function in the
right time frame or something like that. Yeah actually there's an element of
truth to that view that like yeah like if we knew enough about the world we could
just write the objective function to take into account how the world actually
works. But the problem is that like in practice that's just impossible because
like you ultimately would have to know every single thing about all the
stepping stones that you would have to go through to write the objective function
to take that into account. So it's like say there's like you know a million steps
between here and a human level AI. So well obviously if I wrote a fitness
function where your score is literally how far you are along that path then of
course this is like the ideal objective function is going to work out fine.
But the whole point the whole problem that we're facing just begs the question of
how are we going to figure out what the stepping stones are so we're back to
square one again. And so in practice like you're probably not going to be able to
do that in even like a relatively simple problem because the whole problem of
searches we don't know the stepping stones if we did we wouldn't be doing
search because we would just build the thing because we would know all the
steps towards how to get it. Right right. So this paradox is basically
unavoidable you know like if the problem's not interesting then we do
know the stepping stones then we don't need to do these things but the problem's
not interesting. But if the problem is interesting it's interesting because we
don't know the stepping stones like that's what makes it an interesting problem.
And so almost any interesting problem is going to be confronting this paradox.
Now that doesn't mean that there aren't some cases where search will work. Obviously it will
with an objective sometimes. There's no doubt about it. In fact deep learning has
exposed that like in really high dimensional spaces between spaces of many
many parameters like many weights in a neural network that there's less
deception than we thought. Like and this has been a surprise for everybody
including me. And so sometimes we still can just push sort of a brute force
through the objective function because high dimensional spaces have some very
odd properties and succeed at solving some problems. So we shouldn't conclude
from what I'm saying that like oh well objectives are completely useless they
do work in some cases. But I think that it's still the case that in very very
complex problems we are going to be facing deception. We are not going to
know how to write the correct objective function to go through all those
stepping stones which are basically reflecting eons of progress to get to
some of these really ambitious ends that we have. And so it's an element it's not
like everything should be done this way but it's an ingredient that's added to
our toolbox now which is going to be important in concert with sometimes
explicit objectives. And so it gives us kind of a powerful new tool and this has
actually led to a field called quality diversity where we combine quality
measures with kind of diversity measures and try to do both at once in
order to make a principled attempt to leverage what we know about both of
those kinds of searches. Super interesting stuff. Kenneth I
really appreciate you taking the time to speak with us about
neuroevolution and your research is there anything else that you'd like to
leave us with? Well I just I guess just to say that take a look at neuroevolution
like it's it's actually becoming now more recognized in deep learning that you
know we have actually a lot of synergy with deep learning because we're also
doing neural networks and so both fields I think are realizing today
that we have something to offer each other perhaps you know like neuroevolution
can evolve architectures and deep learning can apply really powerful
learning algorithms to those new complicated architectures for just as
one example neuroevolution can can contribute to reinforcement learning
in new ways because of the way that fitness can be a different kind of driver
of progress than say the typical gradient based approach
and so in the end we get a possible really powerful synergy and so I think
it's worth looking at how these two things can possibly feed into each other
going forward. Awesome and what's the best way for folks to
learn more about what you're doing? I'd point people to I mean I'm guessing
you probably have some links associated with the interface. Yeah we can include a link
and I know you've got a page on the UCF site is that the best one?
Yeah I'd point people to my homepage and my research group homepage both are at
UCF and also I can provide a link to Uber iLabs where we actually are hiring too
so if people are just interested in jobs in general that's another opportunity
there so I'll also point to that. Fantastic well thanks so much Kenneth.
Yeah thanks it's been a pleasure thank you.
All right everyone that's our show for today thanks so much for listening and
for your continued feedback and support. Thanks to your support this podcast finished
the year as a top 40 technology podcast on Apple podcasts my producer says that one of
his goals this year is to crack the top 10 and to do that we need you to head over to your podcast
app rate the show hopefully we've earned your five stars and leave us a glowing review and
more importantly share the podcast with your friends family co-workers the Starbucks barista
your uber driver everyone who might be interested every review rating and share goes a long way
so thanks in advance. For more information on Kenneth or any of the topics covered in this
episode head on over to twimlai.com slash talk slash 94 of course we would love to hear from you
either via a comment on the show notes page or via twitter to at sam charrington or at twimlai
or at twimlai thanks once again for listening and catch you next time
