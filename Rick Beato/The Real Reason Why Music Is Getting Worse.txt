Hey everybody, I'm Rick Biotto. We're going to try something new today. This video is on the
history of the music business and technology in two acts. Act one. Music is too easy to make.
What do I mean by music is too easy to make? Let's just go back to the 1940s and 50s. Frank Sinatra
used to get up in front of an orchestra and sing a vocal take and they had one microphone and they
would get it balanced just right. Frank would say, okay, I'm ready to do it and he'd sing.
Then you get into the 1960s or so and then you have things where you have multi-track machines.
You could go in if you had a mistake in a vocal part or any instrument and you do a punch in.
Oh, I don't like that word. I sang out of tune or I want to change this lyric. You go in and you just
punch in, fix the line, punch out. Fast forward to 1998 with Cher the Believe Son. They invented
this thing, autotune. I've talked about this a million times in a year, but autotune was a plugin
that would go into these DAWs, digital audio workstations. So you'd have something like Pro Tools
or Logic or Ableton. What you do is you take the vocal, let's say the song's in C major. Any note
in the key of C major, it would tune the note too. Well, T-Pain and people like that realize if you
put it on a really hard tuning, it would make it sound like a keyboard and that's what they did in
the Believe song. Well, then the same thing starts happening with drum parts. Guys play it in drum
part and you're like, you know what? This would be a great take of this first verse. If this one
hi-hat wasn't a little dragged, well, let's move it back a little bit or let's move it forward,
whatever. Then you move that and you're like, well, the snare after it kind of sounds weird
because we move that forward. Now the snare sounds like it's dragged. We do that. Then you're like,
well, you know what? Let's just look at the grid lines, the bar lines, and we'll just move them
to that. Then you start cutting out, moving them. Then they give you this tool called beat detective.
Then you can actually quantize an entire part. So then it becomes like a drum machine. So it's not
human-like. Here's an example of a quantized drum part. It's John Bonham's drum performance from
Fool in the Rain that's a shuffle. Here's what it sounds like as a machine.
Now here's the actual human performance of John Bonham. Notice the swing in it.
Once you've quantized the drum part, it's a drum machine. It's just like superior drums.
So what started happening in the year 2000 or so is that everyone started quantizing their drums
because the budgets, the higher session guys like Josh Freese and Kenny Aronoff went away and you'd
have to use the crappy drummers. I mean, some bands would have good enough drummers to play,
but you typically have these crappy drummers that you'd have to fix their parts and once you fix
their parts, you start moving the bass around, you start moving the guitars around, and then you
pretty much have sterile, generic, quantized rock music that has no vibe at all. The other thing
that people realize is that it's really difficult and time-consuming to record a drum set. You need
a studio and a lot of gear. Look at all these mics. Now you can put up three mics and get a drum
sound. You can put up two mics and get a drum sound, but to get a professional drum sound,
you tend to mic up the different instruments. I got two mics on the bass drum. I got a mic on
this time, mic on that time, mic on the ride, two mics on the overheads, two mics on the snare here.
I actually have three mics on the snare and a mic on the hi-hat and I have a couple of room mics.
It's hard to record it well. Not only is it hard to play the drums well, but it's hard to record
the drums well and you have to have training. It's not easy to do. You have a great ear. You've
got to know how to tune them. You've got to know what is a good snare sound from a bad sound. You
got to know if the toms are ringing too much. You've got to know if they're in the right pitches,
all this kind of stuff. There's so many decisions to make. Now some of you are out there thinking,
what are you talking about, Rick? You don't need to have a good sounding room. You can have a
crappy sounding room. You don't even need good mics because you're going to just replace everything
with samples. Well, where do you think samples come from? They come from people that know how to
record them. That one was for free. It's difficult to get a good guitar sound. You have to have a
good sounding amp. You have to have good sounding speakers, good microphones that work well. Most
people now just use amp modelers. They plug into their computer. They pull up their program. Everything
is done for them. They've already been pre-mic, pre-selected. They're all using the same algorithms.
They can create great sounds. They're so easy to use. It doesn't take any skill at all, but it
doesn't take any creativity either. Then of course you have the MIDI packs that you can buy
if you can't play keyboards. It'll just have pre-programmed chord progressions because for
some reason people can't just kind of space their fingers out and learn to play a few chords like
that or maybe just experiment. Huh, what is this? What is this? In the early 2000s labels stopped
signing rock bands essentially because it was way too resource intensive. It was far easier to sign
artists that could make their own music using a laptop and a microphone. Why is this a bad thing?
Well, let's start with the creative dependency on technology limits the ability of people to
innovate, I believe. Could be wrong about that. Maybe it helps them innovate. I don't think so,
though. The homogenization of music. The overreliance on similar tools as I just brought up with the
amp models creates a lack of diversity. I think that leads to music becoming more formulaic and
people just following trends of using certain types of sounds. This is why these trap beats
have been in vogue for the last 20 years. People just, they know they work, so they just keep using
them all the time. Quality versus quantity. This is a big, big thing. Okay, so the easier
production makes the process go faster, which creates an oversaturation of music, making it
harder to find really exceptional things as Ted Joya talks about in this clip. This is Spotify's
way of using AI. They have AI songs. They attribute them to people that don't exist,
and this allows them to take royalties that would go to musicians and keep them for themselves.
On the AI front related to music is too easy to make. I made a video last week called, I told
you this was going to happen, and I played some songs off Udio, and I was saying how my kids
could detect that they were AI songs, but other people could not. Well, it just came out. All
three major labels are suing AI startups for copyright infringement. Universal Music Group,
Sony Music, and Warner Music are suing Suno and Udio for copyright infringement, because guess
what? They're using all their music to train these AI models. Well, of course they are. How else
do they get to train it? Now, companies like Universal are not doing it for the good of their
music to protect their copyright owners. What's going on here is they just announced that they're
partnering with a company called Sound Lab to make AI models of their artists for themselves.
They can use this Sound Lab plugin in Pro Tools or Logic, and you can sing your own voice and
replace it with one of their artists like Drake or Taylor Swift or Billie Eilish or whoever agrees
to this, and I guarantee you all these labels are going to do that because they want to own the AI
versions of these songs. Whether you create it or whether they create it, they're going to own it.
And just to show you how easy it is to model someone's voice with AI, I'm speaking to you
through a voice modeling program called 11 Labs that was trained on my voice over a four-week
period. So for those of you that keep writing to me every day, I get about 20 of these a day,
and they always start, Rick, I wrote a song that I think can be a hit. I used AI to hear it because
I know nothing about making music. That's literally from an email I got yesterday. This reminds me of
the best AI critique I've seen. Creative AI tools can be seen as sophisticated plagiarism software
as they do not produce genuinely original content, but rather emulate and modify existing works by
artists subtly enough to circumvent copyright laws. Well, what's funny about that is that was
actually written by Chad GPT. Act two, music is too easy to consume. So this is the water faucet
in my kitchen, but imagine this is streaming on Spotify or Apple Music. You can turn it on,
you can turn it off, but what's going on in this stream of water is all of the music that's on these
platforms. Now imagine this is one artist's entire output. Their entire catalog might be the police,
could be Billie Eilish, could be Led Zeppelin, the Beatles, and then this dropper is each of their
songs. One, two, three, four. Oh, I just did a whole record there, and eventually you exhaust
their whole catalog. When I hit this and I start the stream, the music has very little
importance if you think about it this way. It goes from the faucet down the drain, out to the sewer,
where it's recycled again. Except in this case, the music is not recycled like it is through the
sewer. There were 100,000 new songs added every day in 2023 to streaming platforms. That's more
than one song per second for the entire year. By comparison, when I was a kid, if I wanted to buy
this Led Zeppelin II record, I had to get a job or borrow money from my parents to buy it, because
I wanted to own it. I wanted it to be in my collection. This album here, Pat Matheny,
New Chautauqua, I paid eight bucks for, brand new, with the money that I made by bagging groceries
at Topps grocery store in Fairport, New York. You actually had to expend energy riding your bike
or walking to your job, working your shift, getting your paycheck at the end of the week,
depositing it in the bank, getting money out, going to the record store, buying the record,
bringing it home, playing it, listening to it a bunch of times, going over to your friend's house,
sharing it with them. When a kid opens Spotify and clicks on on a song, they can just skip to
the next one if they don't like it. Think about this. All of the music that exists, or at least
has been uploaded to Spotify or Apple Music, is available for $10.99 a month. I'm talking about
all of Michael Jackson's music, all of ACDC, Pink Floyd, Whitney Houston, Tupac, Kendrick Lamar,
Juice World, Eminem, Dr. Dre, all the works of Beethoven, of Bach, of Mozart, of Stravinsky,
of Shostakovich, of Charlie Parker, of John Coltrane, of Miles Davis, Brad Maldo, of Pat
Methini, Keith Jarrett, all of that. $10.99 a month for the price of what we used to pay for one
album. It's all available on these streaming platforms, which is why music is not as valued
by young people. There is no sweat equity put into obtaining it, having it be part of your
collection, having it be part of your identity of who you are. These are the bands I believe in.
These are the artists that I love. And I'm going to share it with my friends. I'm going to bring
that record to school. I'm going to play it for my friends after school. We're all hanging out
reading the back cover of it and seeing who played on it. These things meant something.
What was on here meant something produced by John Burns and Genesis.
It was important. What I'm saying is that music is basically become
valueless. If you only have to pay $10.99 a month to have access to anything, what is one's song
worth? People tell me that they want me to make certain kinds of videos. They have these aspirational
ideas, as my friend Todd calls them. But then they ultimately vote with their attention. Rick,
make more of what makes this song great videos. Make this kind of video. Or I wish that people would
write songs in odd meters or use these more complex chord changes. But ultimately,
people will do that and then they don't listen to them because you vote with your attention.
So try this. Try to sit down just a couple of times a week. Play just a few songs.
Don't look at your phone or as I call it the thought deletion device because it empties your
mind out. Don't look at tic-tac. Don't look at YouTube or Twitter. Don't look at Instagram.
Just listen to the music. Let it flow over you. Think about the lyrics. Think about the melody.
And try to experience music like you used to. Or if you're young, try to experience music
in the way that we used to. Love to know your thoughts. Hit the subscribe button. Leave a comment.
Thanks for watching.
