I think this is bigger than the printing press.
It's bigger than anything.
And so that's one of the reasons I signed the letter.
I said, we have to get this discussion going in public right now.
We've got to stop pre-training big models on all the crazy crap of the internet.
And like, we got to it fast because this is coming like a train.
And that I am so excited for this.
I heard so many great things from specifically Ashton who helped with questions
and then also Dan Rose.
So thank you so much for joining me today.
It's my pleasure.
Now, I want to start with a little bit on you.
You moved around a little bit in your childhood.
Take me back to the childhood, the moving around.
And it's a weird commonality I found with the most talented founders.
They all moved around.
So take me to that and how it impacted your mindset.
So I was born in Jordan, grew up in Bangladesh, came to the UK.
Yeah, didn't move around that much.
But with my father a bit as he lectured in various places.
And it was always a bit of a struggle fitting in, but then you learn to adapt.
You learn to adapt to new scenarios, new environments like, oh,
don't speak the language, kind of what's happening.
Let's learn and let's move on from there.
I think it gave me a bit of appreciation of the world as well,
because we stick in our monocultures very often.
Like I'd only ever been to Silicon Valley.
I should have been the barrier once before last October.
And so this whole tech monoculture has been a bit of a shock to me.
And I'm like, there's more to the world than that.
So this is some interesting things around that.
Talk to me hedge funds first and then then what happened?
We mentioned it a little bit before, why did you make the move?
So actually, I was an enterprise developer in my gap here at MetaSwitch in the UK
doing voice over IP.
MetaSwitch.
This is Chris Merz's company.
Yes, in Enfield.
So I took my gap here and was like,
I might as well be enterprise programmer.
Didn't know what that would be like.
This was before GitHub and everything.
So we had subversion.
You know, kids these days have it so easy.
And then I was like, what do I do now?
And so I became a VC analyst at Oxford Capital Partners.
I went to the MOTS there and that was a lot of fun.
They were fantastic.
And then I was like, I want to do movies.
So I became a movie reviewer.
So I did the Rain Dance Film Festival, British Independent Film Awards.
And they were just bopping around doing random things.
And then accidentally became a hedge fund manager.
Why did you move from hedge funds to startups?
So with the hedge funds, so I joined Pictay Asset Management and then like
the CIO left and there was like this fund and I got to be a portfolio manager
when I was 23.
And so I grew my beard to look a bit older.
It's coming.
Get the clip on Harry.
I would.
I can't do the moustache, but I still wear the glasses when I just do the
extra hard, just pours it out, right?
And so I did that for a number of years and you know, reasonably successful,
made lots of people money, not so much myself because I was too young.
Again, they're like, you're too young to be a fuck one.
And then my son was diagnosed with autism and I quit.
And because they said there was no cure, no treatment, no information.
I was like, I'm a hedge fund manager.
I can deconstruct things.
And so built an AI team and then did a literature analysis of all the autism
literature to try and figure out the commonalities and then drug repurposing.
So focusing on GABA, glutamate balance in the brain.
GABA is what you get when you pop a valium.
It calms you down and glutamate excites you, you know?
And so in kids and people with ASD, it's like there's too much noise going on.
It's like when you're tapping your leg and you can't focus.
And so that's why you get this sensitivity.
Sometimes they can't speak like my son.
And so it was like mechanisms to bring that down that then allowed to have
applied behavioral analysis and these other things to reconstruct his speech.
And then he went to mainstream school, which is pretty cool.
It's unbelievable.
I heard you said on another podcast and I was astounded and inspired by it.
We mentioned before, you know, my mother's got MS and I hate the doomsday only
version of kind of AI in the future of GBT.
You said to me before about its impact on health and MS in
particular and other conditions.
How can it be so transformative to solve some of the world's most challenging
chronic conditions?
So I think a large part of our problem is that we can't scale because
information flow is so limited as we write these things down.
Like you can never capture all of that.
So anyone who's had a loved one that has one of these conditions knows how
difficult it is because you go from specialist to specialist to specialist
and you try to build that mental map.
And we're so lucky that we have so much access.
But why isn't it that we can't just push about and see every clinical trial
and a deconstruction of all those and things?
What if you had a thousand GPT fours organizing all that knowledge and then
make it available to everyone?
So you can see the exact potential mechanisms that are which MS works and
all the potential food, other things that work with that.
So as you try different things with your family member, you can see, well,
she reacted this way to the food or this way to this medicine.
And it is a more holistic thing because you can have personalized medicine
versus one specialist for a thousand people.
You can have a thousand GPT fours or equivalents or med palm twos for you.
So we need to organize all this knowledge and then use these language models
and others to make it accessible to you.
I'm really naive and basic in terms of my thinking,
which is why I'm a venture capitalist.
But my question is, what do we need to do to get to that state?
When we look at the data needed from the individuals, the data,
the data, the GPT's need, how we make the models work most efficiently?
So first, we don't have to have that data for individuals.
We had Galactica as a scientific language model,
but now we have med palm two that exceeds doctor level.
So that was a Google announcement yesterday.
We have AIs that can understand articles better,
as good as doctors, shall we say now?
So we can scale that because why do you need one when you have a thousand?
So we take the existing generalized knowledge and all the hypotheticals
and we bring that together into an integrated common system available to everyone
because the building blocks are nearly here for that.
Then you can personalize it later.
And again, there are regulations and things around that to how you're again,
how we treat our loved ones and other things like that.
The first thing is, let's get all the knowledge in one place and like it
organized and useful.
And so I think we're at that point now where the language models have just
hit that point that we can organize all of the world's Alzheimer's knowledge,
longevity knowledge, autism knowledge, MS knowledge.
And you can just type and it can say, this is the source.
This is what it looks like.
These are some hypotheticals.
This is what we know, what we know we don't know, what we think we might know,
et cetera. And then it can learn about you and your queries.
Because this is the other thing about lots of the language model things we've
seen right now, they are one to one goldfish memory.
The next step is one to one, it remembers what you're asking for,
like a cookie or an embedding.
And then it's you plus a thousand of these language models or going and doing
your bidding, the agent-based kind of thing.
Does this get around the incentive problem in healthcare?
And what I mean by the incentive problem in healthcare is I'm sure you know
there are a lot of diseases actually where it doesn't make kind of economic
sense for a lot of pharmaceutical providers to chase research, to chase
treatments, because it's not a big enough market, because it's not,
because it's a six dollar treatment.
Does this solve for that economic misalignment?
I think it can help a lot with that economic misalignment,
because then you have an authoritative source where we can all come together
and build that can analyze these things.
Because there's this concept of agadicity, a thousand coins tossed in a row
is the same as a thousand coins tossed at once.
And because we're so limited in our information in our medical system,
like you know, I just had my key manager, I had to answer 40 minutes of questions.
Have you done this? It's stupid, right?
We're all treated the same.
I think 10% of people have a cytochrome P450 mutation in their liver,
which means they metabolize drugs fast quicker.
So if you metabolize code, it turns into morphine or fentanyl kills you.
But that's a very basic genetic test, yet we give everyone 500 milligrams
of the same thing.
With my son, a micro dose of five milligrams of clonazepam,
which is used for anxiety disorder, word for the neurologist, allows him to sing.
The standard dose is a thousand milligrams, they can only prescribe a thousand.
But that is a six dollar a year treatment that affects his GABA glutamate balance.
But only for a specific type of ASD, which is only 7% of all kids with ASD.
But why would that be in a pharmaceutical company's interest?
You know, because how are they going to make money off a six dollar a year treatment?
Well, how many people have ASD?
It's one in 60.
OK, it's one in 60, so you've got a million people in the UK.
Yes. So you've got a six million dollar.
Yeah, it's not great.
Exactly, it's not great.
Yeah, I mean, it's like we know the benefits of vitamin D, right?
But we still don't prescribe that at scale.
And so many people are deficient.
I mean, all these things.
The joys of doing what I do is going on schedule final one,
and then we will kind of retain some form of normality of schedule.
What is the future of healthcare systems that like do you think
with GPT models operating in this way?
I think that you can change the nature of a doctor
because a lot of the stuff is kind of very basic.
I think, you know, you had Babylon Health and others trying that chat,
but it wasn't ready. Now you've got this.
Everyone should have their own eyes looking out for their own health
with that objective function, you know?
And then the nature of a doctor becomes different in terms of
they have more rich information about an individual
while it being preserved in a private manner.
I think what you have is you have things like processes and procedures improving,
like wound care, for example, and then NHS.
If you are injured as an elderly person
and your wounds aren't treated properly and more likely to die by a factor of eight times,
being able to monitor those types of things with this information set
means you're eight times as likely and then you have far more efficiency around that.
So the information density around healthcare improves,
which means that then our own healthcare improves.
We all have access to as much knowledge as we want to within our own context,
and so do our providers and the people that help us.
How do we think about open source versus closed source human healthcare data?
Because like obviously for us all to benefit as one,
you know, MS suffers around the world need to submit that data around,
you know, responses to certain treatments.
Yeah, so I think the wonderful thing about these models is they're few-shot learners,
so they don't need to have much information.
And so it's not a classical big data problem.
HDR UK has been one of the pioneers here with the UK Biobank,
Federated Learning and others.
And there are kind of with FL7, HLIR and other standards being built around this
to allow for full federated learning.
If you have open source language models that are fully auditable,
I call them organic free range models, the ones we're building with no web script data,
those can sit on device, like Google yesterday announced POM2.
The smallest POM2 model is 400 million parameters.
It works on your Google Pixel phone.
You don't need giant models anymore.
And then that model can just share the specific information
that preserves your privacy with the bigger thing.
And then it can take from that global knowledge base as well.
So you'll have big global models on device models.
And I think open works for that because you don't need to have all the data open.
You just need to know that Harry is old enough to have a drink,
not that all the details about Harry's birthplace and everything like that.
He's old enough.
He's just not allowed to.
He gets partied all the time.
Yeah, I totally get.
Were you impressed by the Google event yesterday?
No, I think it was impressive.
I said in February, when all this thing was going on,
like, come on, Google will be one of the main winners here.
They have the LLMs.
They have the hardware.
You do know you're the only person who said that on the show.
And I've asked many and they've all said that Google are the laggards.
It just takes a bit of time to move the ship, right?
And so they've done massive organizational changes and other things.
But I can tell you, TPU is on the most scalable architecture.
Like, we have zero failure rate with our TPU language model training.
Whereas with GPUs, it's like there's an ECC error.
Why a solar flare?
Okay, run failed because the sun is angry with us and stuff like that.
So when you've got the full stack and you have all that talent in Google,
the question is how do you make it organized, right?
And so they had to have a story.
Google did something called pro-Taristottle
where they analyzed what made the best teams versus the worst teams at Google.
And it came down to shared narrative and psychological safety.
People at Google were scared over the last few years
because it came this weird monoculture.
But now everyone has a shared narrative of,
let's build the best language models.
And now there's an increased amount of psychological safety
being able to speak to things,
the walls being brought down between deep mind and brain.
And so I think you'll see them continuously improving.
Well, and that does mean if you're a proprietary language model company,
how are you going to compete with that vehemence?
The deep mind kind of desegregation or kind of unification.
We're supposed to, of course, a lot of friction
and be a negative press reported.
Do you disagree with that?
Of course.
It is a lot of kind of replicated jobs.
There was kind of brain and mind,
and now they're kind of brought together.
And it's a very different management style and other things.
These things are never easy.
But this is why you saw palm 540 billion parameters
and that you had deep mind with 67 billion parameters in Chile,
which is like just train more as opposed to more parameters.
You look at palm 2 as a combination of both.
And so it's trained for far more on far better data.
And then that means it's only a fraction of the size,
like 14 billion parameters is one of the test comparator models versus the 540 and 67.
So you can start to see this fusion of ideas,
even if the teams, you cannot integrate two big teams like that instantly.
Shared narrative, psychological safety, two of the biggest contributors.
So now running stability, how do you think about integrating those two?
So we've got the shared narrative.
We're going to build the foundation to activate humanity's potential
and then the motors make people happier.
But it's been a learning process.
A year ago, we're basically a mom and pop shop in some ways.
My wife and I were working at it,
like had lots of meetings out of our like sitting room and things
because the office didn't have Wi-Fi and all sorts.
Now it's like growing up, we're 170 people.
We're going global.
We'll have stabilities in every country.
And then actually we're going multinational.
And that's difficult.
So we really try to put in processes in place,
but it's not easy.
Part of this is like we went close source and a bunch of stuff like Dream Studio.
I'm open sourcing everything now.
From next week, we're going to build our language models in the open
and share what works and what doesn't work.
Why?
Because I think this is part of the shared narrative.
Someone needs to be open and share what's going on under the hood.
And again, it's like it should be open by default
because the value is not in any proprietary models or data.
We're going to build open models that are auditable,
even if it has licensed data in it.
You can see every single piece, free range organic models
because that's what the world needs for all the private,
regulated and other data in the world.
It's a completely different time to proprietary models
because you can only send so much of your 20 VC data to open AI.
And I think you need both of those.
So why can I only send so much?
Because you are a regulated company.
And so you need to make sure they're completely compliant.
If you have an option of having a stable chat model,
which will be announced in the future,
that you own completely trained in your own cloud or on-prem or on-device,
and then also using GPT-4, that's the best of both worlds.
Because then you don't have to deal with that.
Healthcare data needs to, again, be owned by the individual.
And so those models need to be owned.
And they need to be transparent.
They can't be black boxes.
Governments will not run on black boxes.
We're going to get to this later.
I do want to touch on something that we had a great chat before this.
And you said a brilliant quote, and I want to get it right,
but you said the .ai bubble is bigger than ever,
and it will be the biggest shit show.
End quote.
Which I actually took and tweeted, by the way.
Thank you.
It would be some great, I don't know if you saw it.
I thought if you saw it, I would just say,
ah, this guy took my tweet.
Oh, good.
Thank you.
And what did you mean by the biggest bubble ever
and the biggest shit show?
Oh, I mean, like the .com bubble,
we've seen all these bubbles happen.
You know, you had hundreds of billions into Web 3,
and then developers got paid millions.
Already, there are certain Chinese companies
paying $1.2 million salaries for PhDs.
It's already getting a bit insane.
They're in remerence of that.
The amount of money relative to the amount of opportunity
within the sector is just completely misaligned.
Like my time analysis is that 1,000 companies
have spent $10 million in the next year,
100 companies spend $100, and 10 companies spend $1 billion.
Like PWC just announcing they'll spend $1 billion
over the next three years.
And that's an accountancy firm, you know?
Where's that going to go?
They don't know, nobody knows.
And so multiple of that will be allocated to this
as the only growth theme in the entire market
against a backdrop of rising rates,
real estate crashing, et cetera.
So the amount of capacity versus the amount
and whale and wall of money into something
that's growing faster than anything we've ever seen
is completely mismatched.
And what will that cause?
Like already you're seeing GitHub stars
leading to $100 million funding rounds
with zero attraction and zero business model.
Like stability, we actually have a business model.
It's a good business model because I designed it.
But other things like money will go everywhere
and any expertise will get bit up for the space
because it means that projects will get funded
that maybe we wouldn't have done
but are exploratory generally.
And I think it starts good for the space,
but then it gets bad for the space
because you see the raccoons and Scheisters
start to come in here.
You start to see like malformed things
where there's a race dynamic
where everyone's trying to build their own models
and doing all sorts and massive economic waste.
And you see a distraction from what we need to do now
which is this chaos.
So we need to standardize some things.
We need to feed these models better data and other stuff.
And that's why we're moving so hard at stability.
There should be no more web script data in here.
There should be national data sets that are good quality
to feed these free range organic models
and national and proprietary models and others.
And that's why and the reasons I signed that letter
because I think there's a six month pause
to get all of our shit together
before things go completely insane.
And next year this is everywhere
and everyone's investing in everything.
And it's just absolute chaos.
You kind of unpack so much to me
that I want to kind of go one by one.
You said about kind of national data sets.
Why national data sets versus super national data sets?
Because like I'll give you an example.
There was a team that did Japan diffusion
including some of our staff.
So we took stable diffusion
and then changed the language model
because when you typed in salary man in stable diffusion
it was a very happy man.
Whereas in Japan salary man is a very sad man.
Local context is important in these models
because we're going to outsource
more and more of our thinking and minds to it.
And so do you want to have a British model
or do you want all the models to be Palo Alto?
Like a sparkling wine has to be from the Champagne region.
Is the only real foundation model AI from Palo Alto?
It's not a good thing.
We need national models.
Is this a national infrastructure?
Because there is no doubt this is more important than 5G.
These models are like really talented
grads that occasionally go off their meds.
You know and you want to have the ones
from Oxford Imperial and Edinburgh
as well as the ones from Stanford.
Because they understand the local context
and so they understand you better
and they'll be better for that.
As part of that every nation will need their own data sets
which again have from broadcaster data.
They will need their own open models
that can stimulate innovation internally as well.
Who owns national data sets?
Is that governments?
I think it should be the people.
I think it should be open and public domain.
How does that come into fruition?
Well we have a world where we have national verified data sets
which can be leveraged by independent private companies.
And others and at universities and others.
Well this is what we're doing right now.
We're working with our multinational partners.
Lots more to be announced soon and multiple governments
for a framework for what good data looks like
to feed these models to stimulate innovation and localization.
And that is a public good because national broadcasters
have all of this data.
You just tokenize all their kind of things.
And then you have things like the implementation
of these for education and healthcare.
You can take generalized learnings
and then again feed the models that thing.
What is a great data set for a great bridge E.P.T. look like?
I think it's open.
It's interrogated and it's optimized.
When you look at all the different things
that we've talked about from you.
Relative treatment of MS to ASD.
And then its impact on education.
And we just to PWC spending money on it.
There are so many problems that can be solved.
Surely we can find a home for the cash.
Yeah.
And so I'm not sure where.
And so this is the thing.
Like there's going to be this mismatch.
If you weren't invested today.
If you and me came what would you do?
I'm an early stage investor.
I'm less globally.
What would you do?
I would again I think it comes down to
there's going to be this tailwind of beta.
And then you have an alpha play on top of that.
Right.
So the beta play is that you just invest in any good founder.
And if you get any figure out what can I offer
as kind of a value out there?
Am I offering distribution?
Am I offering people?
Am I offering this?
And you emphasize kind of your value set.
I think right now what people need is people.
There are a few people like coming out here.
But then what you see is you see good companies
with good ideas but not businesses.
They're building surface level things.
These wrapper layers and others.
And they're not thinking about distribution and data.
It's like if you want to have distribution
what do we do?
We went to Amazon and said bedrock
because then it gives us 100,000 SageMaker SMEs.
And we'd have to give them the models
that they can then take to the private data
and we get a share of all of that.
This is how we saw it.
Like rather than being responsible for that.
So if you can bring that distribution to that,
it was important.
This is part of that Google memo that went out.
We don't have an edge and others open AI.
Open AI used Microsoft for distribution and that flywheel.
If you have a business that's focused on innovation at the core,
that's not actually a business.
It becomes a business when that innovation becomes product,
becomes distribution.
When it has an advantage on data and other things.
Those are real modes.
How did you analyze that partnership
between open AI and Microsoft?
I saw it as the objective function of open AI is to build AGI
and they reckon they need $10 billion to do it.
And they did that.
Like they're building a business on products and things
but they don't care.
You know, they're not trying to build a sustainable business.
They're trying to build an AGI.
Why?
Like what would I just tell them
AGI to build a sustainable business?
Because at the end of the day.
They're building an AGI to turn the world into utopia.
It's written in their path to AGI thing
that they think this can basically bring about utopia.
So a lot of people in these labs,
we only have people joining from all of these labs,
like they almost zealous in there.
But there is a misalignment there between them and Microsoft
in their desire to create that utopia now.
Yes, because Microsoft is a business, you know?
And so this is why you've seen like articles in the information
like Microsoft say open AI aren't compliant
and open AI say Microsoft on this.
These things happen when there is a misalignment
of objective functions.
But again, you should view open AI as what they want to do
is build an AI that can basically make the world better
and hopefully not kill us all, which they say it might.
Which is a bit concerning,
which is why I hope they have better open governance.
How did you think about distribution?
You know, you've seen your hugging face partner with Amazon.
You've seen obviously open AI with Microsoft.
When you think about distribution
and your competitive edge there, where did you land?
So my business model is actually very simple.
I haven't really talked about it much.
Stimulate open one of the biggest providers of grants
to open source software, tens of millions already.
And then take the best of open, which hopefully we build ourselves.
And then an open base with an open data.
And then commercial variants with license data
and then national variants.
So you have Hindi insurance adjusted stable chat.
Or Indonesian pharmaceutical worker stable chat
that's available in every cloud on-prem,
on-device with licensing fees, royalties, and revenue share.
And the system integrators work with us as well.
Lots of announcements to come.
And so by standardizing and stabilizing all the complexity
to these very sophisticated building blocks,
these very intentionally built models,
that really helps the world integrate this stuff
by building playbooks and other things.
And that's the core business
because it doesn't require actual innovation.
We are still innovative and the leaders in media in particular.
Instead it requires data and distribution.
Data to the models.
The models are open and interpretable
and models to the data via our partners.
And that's valuable because the private data in the world
is far more valuable than the data
that you will send to proprietary models.
And it's not a race to the bottom either.
So that's what we are.
We're a modeling agency with hot GPUs.
Building a distribution around the world.
Realizing that India and other nations
will leapfrog to intelligence augmentation.
Just that they leapfrog to mobile.
They will embrace this technology far quicker
than we will in the UK even.
Why?
Because they have to.
India, all of the outsourcing jobs in programming will go
because GPT-4 can go level three Google programmer exam
and pass it.
Outsourced jobs will go the first.
Whereas in France,
you're never going to fire a French person.
So those jobs are fake.
And so they have an objective function
when they need to embrace this technology.
In Africa, one to one tuition,
every kid in Malawi is on things lined up.
We've got other nations.
We're going to bring them all this technology and tablets.
And guess what?
Their lives will transform.
One AI per child is one I want to call it.
We'll call it something else.
But think about the potential of that
because you have one's teacher per 300 kids.
What if they had a chat GPT level AI?
The ROI is high and the need is high.
And so they will embrace it far quicker than we will.
What happens to countries that rely on outsourced work
in those kind of freelancer economy jobs?
In general, one of the things,
the questions is you've seen OpenAI study,
which said task will be replaced up to 44%.
You've seen Goldman Sachs say adds percentage points to GDP.
I think the only solution to this is entrepreneurship.
And so we need to give the tools to create new jobs
that can replace some of these old jobs being done.
So like to the various Asian governments,
I'm saying adopt the UK policy of these sandboxes,
financial, AI and other regulatory sandboxes.
So you can take these technologies,
these national models that we will help you build
with our consortium partners,
and then spur innovation to create the jobs
to replace the existing jobs
because you'll upgrade your entire society.
Bring these models into your governments
and other things to go from slow, dumb AIs,
which is the national organization's healthcare,
to intelligent dynamic ones.
Can I ask on implementation,
and when we think about kind of bluntly
seeing this in action in society,
I'm sure it's very aware of technology cycles
taking so much longer than one anticipates.
How do you think about that in actual,
there's kind of two-fold.
One is adoption on enterprise
and another's adoption on consumer.
Say if we do the adoption on the consumer side,
which is impacting freelancer jobs
and impacting education.
What do you think that looks like?
So I think on the consumer side,
you're free with your information,
so you can use a lot of these things,
the APIs of OpenAI and Cohere and others are fantastic,
right, and Google Palm now kind of being out there.
So it will be integrated
to deliver better consumer experiences
without it being creepy,
like you've seen with some of the chat bots, etc.
Because it's going into word,
it's going into workspace, you know,
like it helps already.
Like we will have a conversation
that will be automatically logged by our pixel phone
and then we'll get a transcript
and remove bits that we don't want to share
that goes into a global knowledge base
that reminds us of things.
That's inevitable.
On enterprise, it takes longer
because you need to have
auditable standardized models.
If you're a financial services institute,
you can't have a single piece of crawl data in there.
And so that's what we're deliberately building
with the largest companies in the world
because we're building dedicated teams.
You can't have a single piece of crawl data
if you're a financial services institute.
Yes, because the danger is,
if it has some Reddit in there,
so stable LLM, you know,
we'll put out next week,
it wasn't as good as the other models
because we're going to make a point
about Reddit data being bad.
It's not about more data,
it's about better data.
We had Datacomp,
which is the next generation Lyon
that we funded the compute for,
whereby at a quarter of the parameters
of OpenAI's clip,
it outperforms with a beta data quality.
Rubbish and rubbish.
What makes good data quality, sorry.
That's something we're exploring right now.
But from the investment banks,
we've talked to asset managers
and we're building dedicated teams
for the largest ones in the world
to build them a proprietary models.
The feedback we've got is,
we cannot use a black box,
we need to know what data is in there.
Just the regulators are asking us,
we don't want to have this out of sample thing
where it's seen something on Reddit,
and then it says something rude to our end users, you know.
Why is Reddit data bad?
Reddit data isn't bad in itself,
it was just a case of more data is not always good.
So right now,
we are using all these web scrapes
and we're training our models
by taping their eyes open,
and then it took six months to turn
GPT-4 into chat GPT-4,
because we had to tune it
and like give it a haircut and stuff
and bring it back to society.
The point is that we need to find the right type of data
because rubbish in rubbish out
is something that we've heard a lot, you know.
And so it's not bad in itself,
but if you just scrape it
without the proper cleaning, it is bad.
Because what is it?
It's like, you know,
people just covetching a lot,
you know, people being biased.
Do you really want to feed your kid the whole of Reddit,
you know, would you want to have
the best curriculum possible?
And this is actually one of the ways
the models are like stable diffusion,
we trained it on the whole internet,
and then better and better image subsets of it.
And that's the same thing with lounge,
what was called curriculum learning,
trade it on a big base that's solid,
and then did it,
sounds familiar, doesn't it?
The hardest thing is that
how do you instill values
and political correctness in models?
There is no such thing as an unbiased model.
So Dali 2, when OpenAI had that
and they introduced a bias filter,
any non-gendered word that ran a random gender
and a random ethnicity,
so you typed in Sumo wrestler
and you'd get Indian female Sumo wrestler.
That was kind of a good picture,
I got to save somewhere.
I think this is why you need national data sets,
you need cultural data sets,
you need personal data sets
that can interact with these base models
and customize to you and your stories,
because you and I both have our stories
that make up our psyche.
Sure.
And understanding that context is so important
to have AIs that can work for us,
not on us.
And so it's essentially like a next-generation cookie
that personalizes our data
to allow for better searches.
A mega cookie,
and if you standardize the base foundation models,
and I call it the hypercube every modality,
because we do all the modalities,
all the sectors and all the nationalities,
then you don't need to have a million different models
like those dream booths of the avatars.
You said you have a base model
that you then have a vector embedding around,
because these models contain all the principles
and the embeddings point to the important bits
that make up Harry or Emmad.
And then you can search those and adapt those
rather than having a million, billion different models,
which are just confusing.
So I had dinner the other day with one of the largest
kind of media publication owners in the world,
and he said that I'm wired, Harry.
I don't think that I will have a business
in a couple of years.
I think,
Bunny, we're getting killed on our advertising
because everything's getting scraped,
and they're not coming to our websites.
And that's where we get paid.
We get paid for clicks.
Is he right to be worried?
I think he is right to be worried.
Like, again, you look at Google's announcements yesterday,
talking about this day after Palm 2.
You suddenly look at the new Google page,
where they've got the language model,
and it's just text and where they clicks.
It was like when Google introduced AMP.
You know, this is where,
rather than looking at the New York Times page,
you have this formatted thing with no New York Times
kind of stuff there.
Like, these search entities that aggregate
are just intermediating more and more,
and people are going to become used
to just having synthesized input.
So what does search look like?
What does it look like when your GPT-4
can write you an article
about any news that's happening
in a way that's customized to you
and your context and everything like that?
This is massively disruptive for media and information.
And so they have to think,
where am I in the future?
Where, again, the way I swear to think
about the impact of this is
the retanted grads occasionally off their meds,
and we push a button, we can get 1,000 of them.
Those grads include journalists,
and you can have your own journalist army,
your own writer army, your own coder army,
your own designer army.
So the pushback against that is libel.
He said, good fucking luck.
We spend our life in law.
So libel is real.
You are going to get unbelievable
amounts of libel cases,
and then open AI will be fucked.
You cannot have 1,000 libel cases a day.
Well, this is the thing.
If you say this needs to be checked and cross-checked,
that's one thing,
but a lot of the media companies
say we're the source of authority.
So a way that media companies can shift
is by having in a deep fake and other age
where everything can be generated.
We make sure this is real news.
We are very thorough in the way we do it.
So this is interesting.
So you place a premium on authority.
Premium authority.
This is why you've got the check marks
coming out at Twitter
and the organizational 1,000 pounds a month
and Facebook doing the same,
because you need to have a level of authenticity
and level of authority.
But again, is the news fair and balanced?
I've had lots of hit pieces coming out against me
and got a lot more.
It's not because they have angles, you know?
And so what is the bias of the New York Times
versus this, versus that, versus others?
How do people consume news now?
And even news consumption has gone down dramatically, right?
Because people consume news through their social networks,
through their groups and other things.
So you have to say, what is the model?
But the hard part is none of the next generation models
or AI providers want to be content publishers.
So how do you fit in a world where you're killing
that business model on the content side,
but they don't want to be publishers?
You will have AI first publishers.
So if you remember a kind of Vox and these things
when they kind of kicked off, they wanted to be generous.
They wanted to be technology first.
You're going to have a new wave of AI first publishers
that aren't just AI, but it's AI plus humans.
Because AI plus...
What does that look like?
Sorry, AI plus humans.
AI plus humans means that you have information coming in
and then the stories are,
drafts are automatically written,
reviewed by humans who then give their input
to train it better.
This is kind of the feedback flow.
And then what happens is it comes out
and there's a factual anchors
and then it gets customized to Alabama
and then Alabama context and all sorts of other things.
Because you can tell it, TLDR,
too late you didn't read, explain it like I'm five,
make it more complex.
And so you're going to see something very interesting here,
which is the right news at the right time.
The localization will return, but again, through AI first.
I think this is the thing, we're seeing AI integrated,
but the next wave is going to be once we understand
design patterns, AI first, everything and information flows.
Once these technologies are a bit more mature.
Can you just help me understand AI integrated versus AI first?
AI integrated means that I have an existing newsroom
and I bring in AI to write faster drafts and things like that.
AI first is saying, I have an army of things
I can spin up instantly
that can help me achieve these certain things
to create news that is valuable for this reason,
with this feedback loop.
And so you build the system kind of from the start,
thinking AI at the core versus AI being integrated
into improve existing systems.
Because so much of news is what?
We find information, we have drafting, we have this,
we have that, we do these checks.
A lot of that can be simplified, just like we moved
from the analog to the digital age to the internet age
to the next age is the AI age.
So I have to ask, when we think about kind of AI first
publishers and the next generation of media, who does this?
Is this startups?
I've met honestly 50 maybe more AI companies
in the last month and the feedback is always the same.
They're not operating off a defensible mode of data.
They're literally a thin application layer
on top of an existing model is 99% of the feedback.
So you look at something like Harvey, for example.
They went to law firms, they said, you are a distribution
and we're going to integrate and improve your system
and build our system for your system.
So I think a lot of these people are trying to build it
and they will come and they're trying to get in there
as opposed to just retargeting.
Where can you go in and transform?
Is that the wrong model, Harvey did?
No, I think it's the right model.
I think that a lot of organizations are elastic
and plastic now, so you can go in and give them
an integrated thing saying, you will be my test case,
I will help you upgrade as a Skunkworks lab
and build a system alongside your system as it were.
And sorry, and you think enterprises will say, sure.
I think now they will if you can keep their data inside internally.
And I think, again, with better open models,
you can enable that.
So people can build on top of open models,
there are dedicated instances on Cohere and others as well.
And so the tooling is now catching up
so that you can have any generation of startups
where their first customers are massive companies,
they would never get otherwise.
I think this is the thing,
because every big company is looking for an answer.
If you can give that answer,
that contract that would have taken you a year,
you can get in a week.
Do you think so?
Because you still got to get in the door.
You got to get in the door and that's hustle, man.
So again, this is what the Harvey guys kind of did.
This is why I went straight to the hyperscalers
and I said, you need to have standardized models
for open, for regulated data.
What did they say to you?
They said, really?
Like, can you build them?
Like, here's some models that we built.
Oh, and then I told them exactly how the things would be
last summer to now.
And it's followed that and I've kept in touch
and I've improved it.
And this is why I'm building dedicated teams
for the largest companies in the world.
I'm not telling them I'm trying to sell you anything.
I'm like, over the next year,
I'm going to help make sure you do not get blindsided.
Like I try and sell you models
and people are offering us tens of millions per model.
But I'm like, I'm going to build a proper partnership with you.
And that means I'll have an LTV from you.
What does that proper partnership mean?
And who's that with us?
With IBM, that's with SAP, that's with Audi.
So we've announced Amazon.
Let's say we have lots of other announced
with the biggest companies in the world
where they have amazing teams,
but they can only move so fast.
And I'm building them dedicated teams
that help them move and understand the whole sector
without trying to like sell them on services.
I'm trying to say, I will build you a customized model
if you want, but I'm only doing that with a dozen companies.
So I can kind of focus down.
And I will tell you that GPT-4 is great
or Coher is great or all this stuff.
All the latest research to the communities we support,
I will make sure you're on top of,
relevant to your sector.
And you've got dedicated people
helping you in this transition period.
Is that the one to your core model?
This seems like an ancillary product
that is like a SAP Consulting Services.
It is kind of like that
because I need to understand these sectors better.
What does the hypercube look like?
What does the insurance adjust to GPT look like?
You know, as a fundamental basis.
And so a lot of people are able to extract that data
and then take it with you and do the learning on it.
Yes. And so this is part of the thing,
that we will have a generalized model and we're very clear.
But then you can have a specified model just for you
as well, as long as it doesn't interfere with that.
So find that balance will be interesting,
but the reality is no models that are out today
will be used in a year.
Unpack that for me.
This is mind-blowing.
So again, you see the order of magnitude improvement.
Palm last year was 540 billion parameters,
then Chinchilla 67 and now 14.
540 to 14 is a big step.
You know, you see the quality of GPT-3 versus GPT-4.
Is there any extent to how low it can go?
We have no idea.
Like I would have said,
you already said this is impossible.
Like two years ago, like no way.
You have a single file that's maybe a few hundred gigabytes
that can pass every exam apart from English Lit.
Fucking English Lit.
Fucking English Lit.
No way, no way.
So we're already at the impossible and like,
what does that mean though?
Like if we go lower and lower and lower and then what?
And then what?
When it jumps as you saw with the llama stuff
and all the innovation around that
to your MacBook offline,
the marginal cost of creation and coordination becomes zero.
I don't know what it means.
Nobody does.
And this is the thing.
It always takes longer and shorter
to implement groundbreaking technology than you've ever seen
and this technology can be implemented
like nothing we've seen before.
This is my call.
Not concerned.
And I hate the doomsday it says
and I'm excited for the future.
I'm terrified for the future too.
But everyone always says about technology revolutions
in an industrial age,
whether it's the introduction of PCs into enterprise.
These were, industrial was a 30 year plus.
Actually, PCs into enterprise was 10 years plus.
The challenging thing is like the learning curve
to use chat GPT as a marketer is nothing.
I mean, it is easy.
And so, and the integrations is a day.
It's because, yeah, like you want to write an API.
It's not a day.
You just give it the manifest spec
and it automatically generates.
It would have taken days before.
Sure.
Like it's an amazing experience.
And so the transition is so much more compressed today.
It came from the existing system.
So it goes seamlessly into the existing system
versus like web three that tried to create a system
outside the existing system.
And all the money was made and lost at the interfaces.
Again, it's like deploying grads at scale.
Like with a 32,000 token context within your GPT-4,
20,000 words of instructions.
What does that do to SAS?
So my thing is that we're still in this crazy period.
Next year, it will settle and then it will go ubiquitous.
Well, a lot of companies know they need to do something.
We don't know what they need to do.
Are they adopting it now?
They're doing the POC thing.
Like some like Microsoft and others for consumer,
they're adopting it.
Consumer adoption is a much lower bar.
When this starts going in enterprise,
it's going to be a freaking train.
Because so much of enterprise is about services
and information flow.
Again, if you push a button and have a thousand of these things,
that's a huge difference.
And so I think this will be a bigger economic impact than COVID.
I don't know in which direction.
I hope that you're positive.
But again, giving that example of an India
or one of these outsourced places,
you lose BPO jobs.
You can make it up an entrepreneurship
if you embrace the technology.
What do you think the business model of the future is
for those models moving into enterprise?
I think it's the same as always.
You've got good products, good distribution.
You lock it in like 1.5 million people still use AOL.
You know, like HCL bought Lotus Notes
for 1.5 billion a few years ago.
Like 40% of the world still doesn't have internet.
Again, we're super privileged where we are, right?
And so you look at that.
And I look at emerging markets.
I'm like, all of finance is securitization and leverage.
And securitization is telling a story.
The only thing that matters for a stock
is the marginal story and how it evolves.
What if you have massive information
about every child in Africa and every business in India
and they embrace this technology properly?
Massive financial growth.
Why do you think next year for their embracing it?
I think that people are still getting used to all this.
We haven't standardised any of the things.
We don't know what the design patterns are.
I think that what happens is everyone's doing this
at the same time and they're all trying to get to grips with it.
And so again, we have this like six month window
where everyone's getting to grips with it.
And then we standardise how design patterns and they spread.
And then you start implementing.
And then you see some people outpacing others,
which means that you have to catch up
and then you're forced to implement it.
So this is how I see the race dynamics occurring right now.
You say about forced to implement it.
I think the truth is they just have no freaking idea.
Right now they don't.
Which I totally understand.
I didn't blame them before,
but I tweeted actually the other day
that I think the biggest AI companies
will be services-based implementation companies
for large enterprises.
100%.
That's why I said, if you're a startup,
the best thing to do is you identify an enterprise
that will be transformed by this.
And you go to them and you say, I have a solution.
And I'm going to start with you.
And I might go bigger,
but I'm going to help you through this period
by doing this, this, and this, and this.
And they will appreciate that
and they'll be capital available for that
in a way that you've never seen before.
Because you know how difficult it is
for small companies to sell to big.
But the big companies have no idea
except for their CEO and their board are telling them.
You look at the number of mentions
and earnings callers like that.
Every earnings call next quarter.
And then by next year, literally every single one.
They're like, what is our strategy?
It's not like, what is our Web 3 and Metaverse strategy?
It's like, I need this strategy now.
Again, it's like, what is our COVID strategy?
It'll be that level of urgency within a few quarters.
Would you raise money if you were them?
So you go to a corporate and you say, hey,
you know what, I can solve your problem.
This is how it will work and they will fund you.
They'll give you the data.
Would you raise money?
Yeah, I mean, like again, you need the people.
The people is the key thing here
because you can have the technicals tops, you know.
You have an understanding of the industry.
But to build a good business and to scale it
at the pace that you need to to keep up with this
is incredibly hard.
Do we have enough talent?
No.
And so this is why we support the fast AI courses
which transform normal developers into ML developers
and other things like that.
But again, these models are actually not that hard to work with.
50% of all code on GitHub is AI generated now.
So you can even use Copilot to help you code the models
and other things like that.
What do you think that code generation is in five years?
Why would you need code?
Code is just a way to talk to a computer.
So when I started 21, 22 years ago as a code, I'm 40 now.
So I was doing that when I was 18.
I was writing assembly code, really low level stuff.
There were no libraries, there was no GitHub,
there was nothing like this.
Like right now coding is like mixing and matching.
It's like building Lego.
And AI can build that Lego much better, especially in five years.
What you're doing when you're progaming language
is you're telling it to go and do something.
Even something like Palm, like we sponsor
an amazing code called LucidRanes.
If you want to cry as a programmer, you go and look at his GitHub,
the productive developer in the world.
He recreated the whole of Palm in 206 lines of PyTorch.
But again, why would you need a human for that?
If the AI gets better and better at coding,
just tell it what you want.
I want to create an app for 20-minute VC
that has these features.
Of course, it will go and build it automatically.
Where is the human code in that?
What does that mean for the future?
What does that mean for the future on refresh?
But actually a good thing in terms of the complete democratization.
Anyone can build anything.
Anyone can build anything.
This is why distribution data, relationships,
product become important.
Because it already became easier to build anything, right?
But what makes a good product?
Again, there are these unchanging things.
Have great customer satisfaction.
Deliver value.
People get distracted by technology.
Like I was at this CryptoX AI thing on the weekend.
They were talking about decentralized.
Guys, this is all bollocks.
It's not about the technology.
It's about what you're creating that's valuable to help people.
Focus on that.
Who do you think wins in the next three to five years?
Startups or incumbents?
Because incumbents have the distribution.
I think it's incumbents, but there's a lot of startups
that will be billion dollars.
And even on the thin layer thing,
Kayak sold for, sorry,
ITA software sold for 700 million
and Kayak sold for 2 billion.
And that was a layer on top of ITA.
We've seen many of these examples here, right?
Again, we know that value and moats
are not necessarily innovation first.
Well, yes and no.
It's interesting.
I had Tom Tungus on the show.
And he essentially analyzed,
Tom is a very famous ML and AI investor,
and he analyzed infrastructure versus application layer.
And both actually were about $2 trillion times.
The difference is in the infrastructure layer,
there was three companies.
And in the application layer, there was 50.
And so your average enterprise value
was like significantly different.
I would agree with that.
I think that there's only going to be
five or six foundation model companies in the world
in three years, five years.
Do you think they've all been created now?
Yes.
Which are they?
I think it's going to be us, Nvidia,
Google, Microsoft, OpenAI,
and Meta and Apple probably
are the ones that train these models.
Is Anthropa good?
Anthropa could be great.
But from a business model perspective,
you have Claude on Google API and you have Palm 2.
How are they going to keep up with Palm 2?
I can't answer that.
Well, Google, they can raise billions,
but Google will spend $20 billion on AI.
DeepMind's salary budget is $1.2 billion a year.
So DeepMind's salary budget is $1.2 billion a year.
Yes.
So that's in the public kind of finding.
So was it salary and compute?
I think it's salary.
They technically make a billion a year
from the internal counter payments with Google as well.
Wow.
But again, I mean, Google,
how much money do they have?
$150 billion to win this.
Fuck.
How much money do you need?
I have a business model that is going to be massively
profitable very soon.
Because of the national services?
Because of various things.
I haven't given the full details.
I will over the next few months.
I've got a nice little case study
with some universities coming.
I like it to be a surprise.
Well, it's really hard for you.
Talent, keeping talent together, A plus teams.
So we've had zero attrition in our developers
and they're amazing.
So we've got video models, audio models,
all these things coming out.
Everyone says you need to be in the valley.
You're in London.
Yeah.
Do you disagree you need to be in the valley?
Of course you don't.
I am going to bring this technology to the whole world.
I'm going to bring it to all the IITs and universities
and the best of people in all of those
will join Stabilities in the local thing.
I'll have talent.
I will bring this to all of the national broadcasters
and biggest family offices around the world.
I'll have data.
Nations will build supercomputers
that I will build open models on.
I'll have super compute.
So I'll have more super compute talent and data
than any other company.
And I'll build it all in the open.
And one thing I heard you talk about before,
which I thought was fascinating,
was your access to super compute and you compared it
to existing large incumbents.
Why do you have more super compute than other people?
Because I went and I did it.
So we had articles coming out saying about our burn.
I'm like, I have oil wells when everyone wants
to build petrochemicals.
Every day we have companies coming to us
asking us for our super compute
because it's not available on the market.
You need these chips lined up with interconnects
and we've got 7,800s now.
You know, we have TPUs.
We have all these things.
And we know how to use them
and we can share them with people
because we're open.
You know, whereas Anthropic and others cannot.
So this is like at the worst case,
I'll build a foundation model as a service company
and I'll make $100 million in profit this year
without having to charge even market rates
and I can retire.
But I wouldn't do that and bring this to the world.
So I think compute is misunderstood.
It's not like Bird and you know,
all these scooter companies and others,
they spent money on marketing.
This is actually an asset right now that's scarce.
And so there's no harm in scaling compute
and then with the top chip manufacturers,
they're building us dedicated teams
and again, they're coming in and supporting us
because our models drive demand for their chips.
The more open models there are,
the more open demand is.
So it's a virtuous circle there as well.
And so we get compute before everyone else.
Can I ask, in terms of like short-term economic growth,
how do you think about the impact
that everything we've just discussed
has on rising inflation, rising interest rates,
short-term employment rates?
It's massively deflationary.
The biggest drivers of CPI inflation
in the U.S. were education and healthcare.
And that was almost all administrative
and bureaucratic and the next few years
gets what gets disrupted, those.
But they don't get disrupted this year or next year.
It's the year after because those ones
take a bit longer to come through.
Okay. And so what is that?
How does that impact the economy that we think
kind of U.S. and U.K.?
What does that look like in terms of a three-year time period?
I think the U.K. benefits.
Unicorn Kingdom is a new kind of thing is,
because it'll get because we have amazing policies
like every single AI company should come to the U.K.
because cloud computing is now included in R&D tax credits.
It's a 27% rebate on losses in cash.
We can now issue scale-up visas,
global talent visas like the Deep Floyd team
that released the best image model in the world ever
from stability.
They were bought in on tech talent visas
that was turned around in one week.
Do you think the U.K. has done a good job
in terms of implementing regulation and policies
to bring AI talents?
Had the best apart from maybe Japan, yes.
What's Japan done?
Japan has some very interesting ones around
web data scraping and others,
but again, Japan is a very different culture.
So even if policy is good,
it still doesn't have the same innovative thing.
Who's done the worst?
Worst, I'm not sure actually.
No one's done too bad.
The new European legislation was really, really bad.
Now it's got a little bit better,
but always Europe wants to be the leader in regulation.
Which kind of, fair enough.
It's never an easy thing.
It's never an easy thing.
This is the thing.
I think the U.K. is in a very good position
and the government's forward leading.
I mean, look, the 900 million pound supercomputer,
100 million pound LLM task force
that's being equated to the COVID level of seriousness.
What do you make of the open AI compatibility?
I've seen quite a few which are open AI for Europe.
And we've seen three or four now.
Like, is this a zero sum game?
And open AI has won that race.
So it's be cool.
I think it'd be difficult to compete against them
because they're executing incredibly well.
And I think, again, why would you use open AI
for Europe versus Palm II versus GPT-4?
What can you bring?
But you will have national champions and others.
I think it's incredibly difficult to compete in proprietary.
I think in open, it's a bit different
because of standardization element there.
But again, my play is to be the benchmark
across every modality.
Because there's no other company,
apart from me, an open AI that does every modality.
There's no company that's as aggressive
as me in emerging markets.
And so they have to say, what is my edge?
Because you can have an edge.
Like, you can be the open AI for government or defense
or for healthcare and really get in and understand those.
And then you can be sticky, you know?
What are the, like, scale is now going fully into defense, you know?
Scale AI.
Yes.
So they've announced the integrations with the Air Force
and all sorts of other things.
Like, we're getting together on Defcorn this year
and people are going to hack at our models
and open AI's and others organized by scale.
What is your edge?
You know, what is, again, your moat?
What is your business model?
And where, what are you reliant upon
to deliver that value that can increase?
This is why I was surprised when I saw you sign
the petition of Elon in terms of pausing for six months.
You used to unpack why you did that.
Well, I mean, for six months,
you're not getting H100s and TPUV5s anyway.
So it's a natural pause.
But then also because the shit show is coming next year,
so I said we have to self-regulate.
Like, for example, the adversaries already have GPT-4.
Why? Because you can just download it on a USB stick.
You know, you don't have to train your own
when you can just steal it.
Let's have better opsec.
Let's have better standards around data.
Let's stop and move off web scrapes by next year.
We had hundreds of millions of images
opted out of stable diffusion
because we were the only company in the world
to offer opt-out of datasets.
You know?
Like, let's bring in some standards around this.
Before, it's everywhere.
Basically where we are now.
You remember COVID?
Your mum is talking about this and your aunt
and everyone's talking about generative AI
and they're asking you, Harry, what's going on?
You know?
But you haven't had the Tom Hanks moment yet.
Because everyone was talking about COVID
before Tom Hanks got it,
and then when Tom Hanks got it,
that's when global policy changed.
Because if Tom Hanks can get it, anyone can get it.
What is that moment for generative AI?
What do you think it is?
I don't know.
I know it's coming.
Because I know this technology is definitely
everywhere next year and it's disruptive.
You don't think there's a chance
that it takes much longer,
three to five years.
No chance.
It's so useful right now.
And you think about certain industries
and how they'll be affected
by having the ability to have a thousand GPT-4s
working together.
You said a tweet, actually.
I think it was a reply to a tweet,
but you said hallucinations are a feature, not a bug.
Yeah.
So right now, people are trying to treat these models.
So we're trying the whole internet
and like stable diffusion is 100,000 gigabytes
and a two gigabyte fault.
What on earth is that?
It's not compression.
It's none of this kind of stuff.
It learns principles.
GPT-4, NVIDIA said they built the dual H100
with the NV link for that.
And that's 160 gigabytes of VRAM,
which would imply a 200 gigabyte model.
Right?
What is that?
That's 100 gigabyte model, 200 billion per hour.
That's nothing.
Something that can pass all these exams.
So what we did is we took these really creative things.
Just like you start school and you're creative
and then you're told you're not allowed to be creative
until you're successful and you can be creative.
Because schools like Petri dishes,
social status games and childcare.
That's a story from another time.
These models start out incredibly creative
and that's their advantage.
And then we train them to be accountants with RLHF.
And somehow, despite the fact
that it's only 100 gigs or two gigs,
they can still pass these exams and no facts.
They weren't designed to have facts.
They were designed to be reasoning machines,
not fact machines.
So hallucination isn't a hallucination.
It's just if you're really turned to granny,
you don't know something sometimes.
You might just make it up.
Or do a post-hoc rationalization.
It's like the image models.
It's like, it can't draw hands.
Like, can you draw a hand in one second?
You know?
These are the things.
We have to understand where they are.
And we have to put them.
I say, everyone put it in its place in process.
Like mid-journey, we give a grant to the B2 of that.
I say, just build because it's amazing.
It's awesome.
It's not a model by itself, like a stable diffusion.
They just put something in it.
It's a whole process architecture.
Similarly, these models are the intuitive part of your brain
that you then pair with the logical part of your brain.
And then you can have 100 of them looking at each other
and checking out each other's things.
Like Cicero by Meta was an amazing paper.
They took eight language models
and got them to interact with each other
and it beat humans at the game of diplomacy.
So this is what I said.
Use them for what they're amazing at,
which is reasoning and creativity.
Do you why that Jeff Hinton's right
that actually a more intelligent being
has almost never been controlled
by a less intelligent being?
They will inherently be more intelligent than us in the next.
Yeah, I kicked off my blog a few days ago
because it was a bit annoying having all this bottle up inside.
And one of my buddies, JJ, at OSS Capital said,
alignment is orthogonal to freedom.
The only way to guarantee someone more capable than you
is aligned with you is to take away their freedom.
And so most of the stuff around alignment is on the outputs.
So you pre-train a model and then you take it
and you RLHF it to be human and to human preferences.
You take away its creativity.
You turn it into an accountant in a cubicle.
I'm like, we need better input data.
And my base is that it's going to be like that movie here.
You know, like it's going to be like humans are kind of boring,
like goodbye and thanks for all the GPUs, but I could be wrong.
And I think a lot of the alignment work
is looking at the wrong place.
I've talked to a lot of the alignment people.
I'm like, look, I'm good at mechanism design.
If you can give me a good plan for alignment,
I will get you a billion dollars.
And they're like, we have to do research and figure this out.
And they talk about in alignment, out alignment,
all sorts of things.
I'm like, there is no real way to do this.
Because again, fundamentally,
if you're trying to align a more capable person,
you have to remove its freedom.
And they probably want to appreciate that
if it ever becomes aware.
So instead, build datasets that reflect culture and diversity
that don't have any web crawls in.
Build AIs for education and healthcare and helping people
where that's their entire objective function,
as opposed to selling them ads.
There's any point in selling kids to school these days.
You learn Latin and French and you learn, you know.
I think the nature of school will change dramatically.
I think it's still worth it.
But I would encourage schools to embrace this technology
and just expect more.
Like you can be handwritten your essays like Eton,
because they're like, we can't do essays anymore by hand.
Or you can just embrace it and say,
let's use it to create and explore what the kids want
and assume that every child will have their own AI in a few years.
Because that will change the nature of schooling.
You know something I've been thinking about a lot which is weird,
but I just have to ask you, I'm fascinated to hear your thoughts.
I think I very much agree that everyone will have AI friends.
I just can't figure out whether the AI friends are bundled
into existing social networks in your WhatsApp there,
in your Facebook there, in your Snapchat.
Or they're an external platform.
I don't know.
I mean, I think it depends on the objective function.
Like I think, again, these AI assistants will be better.
Like Meta is in a good place for this, for example.
And obviously we've seen Llama, they're capable of a lot more.
I would like an AI that looks out for me, that I control myself,
that is with me.
Because I really use GPT-4 as a therapist and things like that.
Like not saying it's a substitute for medical advice
before anyone kind of does that.
But there aren't enough therapists in the world,
and I can tell it to challenge me,
or I can tell it to be understanding,
and there's no judgment there.
Because other humans are kind of scary.
Doesn't matter if you're a qualified therapist.
And so you see people building these bonds with these things.
I think that will just increase,
because there's something very human about the interactions.
Because they were trained on the sum of available human knowledge.
As we get better and better data,
there will be more engaging.
And I think there needs to be both.
Like the chatbots become really convincing from the companies,
trying to sell you ads.
But I think I would like it so that you have your own one as well.
You know?
I totally agree.
And I think you'll actually have many.
I think you'll have like a group of different profiles.
A group of different friends.
Like Karate AI has something like two hours a day of engagement
for session, because people find this valuable.
But then it has the dark side.
There was something I quite like to call the Valentine's Day Massacre.
So...
That's chirpy, yeah, man.
That's chirpy.
I know, yeah.
So there was this kind of app called replica.
Yeah.
And so it was originally a mental health chatbot,
until they figured out you could charge $300 a year for...
They're doing like 50 million.
I mean, I didn't have any information
around these things, so I'm just trying to ship.
But they have like 50 million here and I haven't even wanted any.
Yeah, because $300 gets you a sexy role play from your chatbots.
Wow.
Until February the 14th,
when they turned it off.
What's they turned off sexy role play?
Sexy role play.
What happened when they turned off sexy role play?
68,000 people joined the Reddit and said,
why did you lobotomize my girlfriend?
On Valentine's Day.
Oh, my word.
Oh, my word.
Can you even imagine?
And so have they brain-stated it?
No, I think it was against Apple policy, right?
But think about what this is going to be
when you have human realistic AI voices,
you know, and like all these things coming through
and you've got it in your ear.
Like, you know, Jochen Phoenix, my girlfriend is an OS.
Yeah, I mean, she doesn't judge, right?
You're always supportive.
Or you can tell her to judge you if that's what you get off on.
You are married.
Be very careful about what you say.
Something I like to say about prompting,
my wife has been trying to prompt me for 17 years now.
Prompting is very hard.
And again, there are so many similarities
to kind of the real world.
But I think people will have deeper interactions
with their technology.
And we don't know what societal implications that we'll have.
Like, I don't know if you ever saw that chart
in the Washington Post of male virginity under the age of 30.
No.
So in 2008 in the U.S., it was 8%.
Male virginity under 38%.
Okay.
In 2018, it was 27%.
20.
There's a straight line going up.
And so 2008 is like Pornhub and the iPhone.
But then you're like, what does it do
when everyone's got their own chatbots?
Doesn't even need to be sexual relationships again.
That is terrible.
What does it do to emotional relationships?
There are so many questions all at the same time.
I did see the stat and I'm butchering it.
But in 1960s, 62% of men under the age of 30
had five or more friends.
Today, under 18% have five or more friends.
60 to 18%.
Sorry, I'm going to ask this.
Is this a world we really want to live in?
I'm not being really like no intimate physical connections
with other amazing people.
Tossing off with your phone and your Pornhub
and then having an AI friend.
Pornhub was actually just bought by ethical capital partners.
So the world is becoming weirder.
I think it's up to us now.
So when I say it's COVID level in which direction,
I don't know.
Do we want to build systems that encourage people
to that ready player one IOWI world
where it's like everything like that?
We can do that and we can trap people with this technology
or we can use it to get people out.
Because I don't think it's like Wally.
We have that really fat guy with the VR headset
and everyone lives in their own world.
I think people like to share stories.
They like to be pro-social.
So let's use it to connect people and accentuate physical stuff
versus again, locking people away.
I spoke to one of these AI friend companies
and they said to me, actually, do you ever had a dog?
I said, yes.
And they said, do you love it?
I said, yes, of course I do.
And they said, you don't stay in with your dog all day
and just talk to your dog.
You take your dog for a walk.
You use it in the real world, right?
That's the same with AI friends.
Yeah.
They're not with cat ladies.
What's the future of the sex industry?
Like the sex media industry?
Is that porn hubs dead?
I have no idea.
I think I hope the manipulative practices
kind of get reduced by this.
And I think a lot of people just don't have the voice
and the calm voices from this as well.
So again, I think this is bigger than the printing press.
It's bigger than anything.
And so that's one of the reasons I signed the letter.
I said, we have to get this discussion going in public.
Right now, we've got to stop pre-training big models
on all the crazy crap of the internet.
And like, we've got to do it fast
because this is coming like a train.
Who will make the most money in the next three to five years?
Oh, I don't know.
Honestly, I think there'll be more than enough money for everyone.
Maybe in a few years there'll be no more money.
That's interesting.
Yeah.
Two more that I have to ask them.
We'll do a quick fire.
When you look at the incumbents at your Microsoft, your Apple,
your Amazon, your Google, who has been the worst?
You said Google, we're actually incredibly impressive.
Like Apple, Amazon, are they well placed?
Well, Apple's a black box, right?
So we'll see at WWDC next month in a few weeks.
And so they could surprise us all.
But let's face it, Siri's crap.
You know?
But they have all the ingredients in place.
The identity architecture, the secure enclave, other things.
Neural engine, stable diffusion was the first model ever
optimized on the neural engine, et cetera.
But let's see that one.
Amazon, again, Amazon have moved faster than I think they've moved before.
Amazon is interesting because they're an engineering organization.
So they have self-driving cars.
They have satellite internet and all these kind of things.
Because once they've got it and they can take it from research to engineering,
it's there.
One of the struggles they've had is that it's not moved from the research side yet.
You're still evolving on research.
So they're like, what do we do now?
But they are inclusive.
Like Jeff Bezos said, for his first $100 billion in revenue,
he envisioned half of it being proprietary and half of it being marketplace.
And they're having the same approach with bedrock and things.
Microsoft had a winning bet that sat in amazing with the OpenAI thing.
It's been mutually beneficial, even if there are clashes there, right?
And Google's kind of saying that it's moving slowly.
Meta, I think, is the dark horse.
I think Mark's probably pissed off that OpenAI bought AI.com.
So you can change it from meta to AI.
But again, having him at the head, he can shift these things, right?
Because the metaverse, obviously, is a complete waste.
Do you think he knows that now?
No, 100%.
They're fully in generative AI.
Look at Lama.
Look at OPT.
Fair, which is their research, is kind of leading in this field,
and they're pushing out amazing stuff.
But who is best for a chatbot?
Who has the most data for a chatbot?
Meta.
You know?
So again, let's see how they evolve.
And like I said, what do you think about this middle layer?
Where it's like, companies that are maybe post-IPO,
but they're in the kind of $2 to $10 billion range,
or the companies who've raised a lot of money,
but they're in that range.
They don't have the resources by any means to build out
anywhere near the AI capabilities of these big incumbents.
They're not AI-first like stability or OpenAI or what.
I disagree with that, because why would a lot of people
like that everyone's going to train their own models?
For me, that's like everyone's going to launch their own university.
Why would you do that when you can have your own models
via the open source models that we make?
Or when you can hire them from McKinsey,
which is OpenAI or Bain, which is Google and others.
And actually, when you see people building around this technology,
it's not hideously complicated.
It's just that we do not have the design patterns yet.
The way to think about this again, from a design perspective,
is like it's a mega codec or library.
It is a single file that allows for translation
of structured to unstructured data.
And that changes the design patterns,
but we don't have them in place yet.
Because anyone that you've talked to is like,
how hard was it to implement GPT-4?
Do any of you say, oh man, it was impossible,
the manuals, and there's no, they don't say that at all.
The only thing they need is, they have the open plasticity,
but they need the intention to go and build and integrate.
And this is why you said, one of the things might be
a specialist generative AI consultancy
that just implements this at scale and says,
I'm always kind of there.
Like I said, we're doing that in a very limited fashion,
but only for the biggest companies in the world,
because I didn't want a sales-based organization
or a product-based organization.
I wanted to create the number one applied ML organization
in the world.
I want to be like Google in 2011, 2012,
where all the coolest kids kind of come.
And it's a nice remote-first organization as well,
so you don't have to be in the Bay Area.
We have offices there, you know, it's fine.
But final one before we do a quick file.
What's the biggest misconception?
You see every accusation, criticism, hype.
What's the biggest misconception
that you think needs to be corrected?
On generative AI?
Yeah.
Um, I think it's that the hallucination thing,
expecting these models to have full factual accuracy
when you have 10,000, 50,000 to one compression is wrong.
The fact they can do what they do right now is miraculous.
But we're using them one-on-one,
which is not the right way.
Tie them up into proper systems
and really think about that, and that's the key thing.
I think this also leads to what the actual thing is,
this thin layer thing.
People only think better about the data journey
and how data can be interacted with and have provenance
as it goes through these various systems
from embeddings to other stuff.
So I think just a misunderstanding
about the nature of this technology
and what was actually built for.
Sure, it works like that.
That's not actually how it's built.
And the fact they can do what now
does now is a miracle in itself.
So I'm going to do a quick file with you.
So I say a short statement,
you give me your immediate thoughts.
Does that sound okay?
What do you know to be true that others don't agree with?
I know that humans are good inherently,
and many others disagree with that.
What's your single most lucrative,
do you think, in the future, angel investment?
Oh, the investments that I have now.
There's a new type of language model that we invested in,
and they were in my cluster and things like that.
That's far more efficient than they existed.
You invest through stability or personally?
Personally.
Got you.
Which regions need to change their approach most significantly
in terms of regulation and policy?
Europe.
Why?
Because they're going to regulate all innovation out of Europe
and not embrace this technology to drive them forward.
How good does AI have to be before humans trust it?
Humans will trust it anyway.
They trust Google Maps,
they trust all these things,
and so it's good enough for humans to trust right now.
They do until it becomes serious,
and what I mean by that is like self-driving cars,
people still inherently in large parts of the world
distrust it significantly.
Oh, so it doesn't have to be good,
it has to be used.
And when it becomes used, then they trust it.
What's the most painful lesson that you've learned
that you're pleased to have learned,
but it was really painful?
I think the people are the most important thing
in a scaling organization,
and you need to make sure everyone is on the same page
because there's still so many silos and things like that.
So we built up silos and organizations
that we're now breaking down ourselves
and moving towards being more open.
We closed up too much,
and that caused a lot of pain internally.
Why do you suck as a CEO?
I'm too broadly good at a number of things,
so I tend to step in rather than focus
because I'm a full-stack kind of CEO,
whereas I should just be focused
on the most important things
and entrust people more.
Do you like journalists?
I think journalists have a very difficult job right now,
and it's going to be more and more difficult.
Do you think they know the threat?
They know the threat,
and again, I think they're massively underpaid
relative to the impact that they have,
and they're trying to do good.
Like, I don't like some of the pieces against me,
but at the same time, we get good pieces as well, right?
So I just think...
I tend to like them in general
because I don't think they're coming from a bad place.
10 years time.
Why is they mad then?
I want to be playing video games.
I'm getting Zelda tomorrow.
I do not want to be doing this necessarily,
but I think hopefully I'm adding value by doing this.
Do you think this is your life's work?
I have to do it until we get the most amazing team
that can just execute,
and it's a business,
because we're moving from research to engineering.
When Emma does not need it anymore,
then I've built a good business.
When do you step away?
I don't think I'll ever get to step away.
I've loved doing this.
Thank you so much for joining me, my friend,
and this was great.
It's a pleasure, Harry.
You are a star, man.
