All right. Welcome to Parallax. I'm your host, Thomas Mark. With me today are Daniel Schmachtenberger
and Alexander Bart. Daniel Schmachtenberger is a social philosopher and founding member
of the Concelion's project aimed at providing public sensemaking and improving public sensemaking
and dialogue. Alexander Bart is amongst many other things, the philosopher, author,
and futurologist. I'm very happy to bring you both together for the first time. So welcome,
both of you. The goal and the idea of this conversation is ensured to kind of generate
a snapshot of where we are 2022, ideologically, politically, economically, and technologically,
and where we are headed to the end of the decade. So where are we now in this time between worlds?
And what are the possible and probable outcomes of our current trajectories? We are facing a crisis
while at the same time our institutions do not seem to fit or able to solve these problems.
It appears that the climate crisis unfolding right now and the wars brewing, the cultural divide,
and the Western Hemisphere, the culture war is getting more intense. And at the same time,
our myths and narratives don't work anymore. The postmodern policies of deconstructions have,
for better or worse, negated our way of reducing complexity. So where are we now? Is the west
going to fall, as Oswald Sprangler once put it, is the chaos going to increase till we find a new way
of life? Or is it as it ever was, men struggling to find meaning in a complex world? Can digital
providers with the means to reconstruct the myth and narrative? And maybe more on the point,
at what point does it become wiser to acknowledge that it's too late to stop anything and turn
our efforts to surviving it? So Daniel, if you had to start to paint this broad painting,
where we are right now, where are we now when you were to take up a systemic
bird's-eye view of things? I tried to paint a brief, hopefully useful starting place picture.
You were saying, you know, we're in a global crisis and you gave a few examples.
I often use a term metacrisis that is not just looking at the fact that we have
climate change and biodiversity loss and extinction of species in dead zones and oceans
and topsoil loss and all those environmental issues, or that we have increasing fragility
in supply chains or the problem of exponential growth on the financial system and linear materials
economy hitting fragility on planetary boundaries, or the AI risk, bio risk, cyber risk issues that
new exponential technologies create, like all of these are possibly catastrophic risks.
And we're in this interesting situation where the total number of catastrophic risks is increasing
and the probability of them is increasing. And so rather than just see each of those as
different separate ones, there are certain underlying drivers that we can look at that
they had in common, talk about the generator functions of catastrophic risk. And so we would
say that we are at a unique point in history, something where Alexander and I definitely agree
is that it's not just processes of the same thing always under the sun. Being able to
extinct species at scale and genetically engineer new species and synthetic biology
is a different thing than was true 2000 or 20,000 years ago.
And so the first truly existential tech we had in terms of technology enough that we could make
choices that damaged the habitability of the world was the nuclear bomb. And that was so
recent in historical time, we built an entire world system to prevent using tech, that tech,
and we had never done that before. Every tech we had, we always made an arms race to use as
fast as we could. Now we built a whole world system that involved mid-shearer destruction and the
Bretton Woods monetary system and the UN IGO systems to ensure not doing that. While that
succeeded in a way, it also drove all the catastrophic risks we're facing now and to more
likely let's have a monetary system that increases exponential GDP so everybody can have more without
taking each other's stuff on linear supply chains that externalize cost to the environment pushing
all the planetary boundary issues. And you can make mid-shearer destruction on two superpowers with
one catastrophe weapon, but you can't on lots and lots of non-state actors all having access to
different kinds of catastrophe weapons. So how do you deal with that? So we're in a situation where
the post-World War II world is over, there's a lot more catastrophic risks and those types of
solutions don't work and we need new ones. What we'd say is that there's, so like whether we're
talking about the risk from a particular kind of AI or bio or nuclear or climate change refugees
leading to nuclear or whatever it is, there's the increasing catastrophe attractor, right? There's
like an attractive basin defined by we can't manage our power well, coordination failures
create increasing catastrophes. There's a thousand scenarios but they're all kind of a catastrophe
attractor. Then there's this other attractor that says in order to manage those we must be able to
monitor and control adequately and that looks like pretty powerful centralized control mechanisms
which mostly turn pretty dystopic. So we can make sure that nobody builds catastrophe weapons in their
basement using tabletop crisper if we have ubiquitous surveillance and extremely powerful control
mechanisms then that becomes pretty dystopic. So there's like catastrophes and dystopias as these
two different attractors. An exponential tech makes both more likely. You can run much more
powerful top-down systems using AI and IoT. You can also create a lot worse catastrophic
dynamics with the exponential tech. So we want a third attractor that is neither dystopic nor
catastrophic and that means that it has to have the capacity to check all of the power that could
cause catastrophe on purpose or accident but where that system that checks it must also have checks
and balances and be oriented in a life that is somehow desirable. And so how do we make make it
through the metacrisis means make it through the catastrophes and the dystopias to some kind of
third attractor. What are the criteria of that attractor? That would be a fine starting point
of kind of where I see that we're at in the arc of history and that quote in the book of Roman
something like the path to hell is wide and many the path to heaven is narrow and steep.
It's easy to come up with dystopian sci-fi because humans have been pretty nasty stewards of power
historically and the idea of us having decentralized exponential power like there's just a lot of bad
scenarios the idea of exponential power AI and genetic engineering and whatever
going well with people like us running it requires some pretty significantly new thought.
And so how do we come up with a positive future narrative that is not a naive silly one?
I think this is the topic would be fun to have us explore today that's my kind of initial frame.
I can then add to that that the reason why I got really interested in Daniel's brain a few years ago
was that I was very alone being a philosopher of technology for quite a long time and it was really
required obviously we live in the middle of a technological revolution. Here was a guy who was
even more a philosopher of technology than I was which is great. So it's kind of shocking that this
is actually probably the first recording of a conversation between us because we've been friends
for many years now and I highly respect Daniel's work and I'm very excited about this conversation
so I just want to say that first. What I add to this is that I'm a narratologist so here's a new
word right? Please recall that the 20th century was mostly used for deconstruction you know after
the atomic bomb August the 6th 1945 the most important date in recent history for all of us on
the planet like I agree completely here with Daniel let's use that date there's a certain date
there August 6th 1945 it helps us to locate ourselves historically and after that date
deconstruction became the natural norm it's just like we have to deconstruct all of history we only
begun that process we have to deconstruct western history of the world right now that's happening
we have people over the world who realize that there's a myth about Asia that is completely
incorrect there's a myth about Africa that's completely incorrect and also America is finally
shifting America is not it's not European any longer America is now the meeting place of the
world populated by people from all over the world and America needs just a new standard
language of the world that we all use to communicate so even America is shifting in the sense that
America is becoming truly a global meeting place today and that's what's really interesting here
so I do narratology and narratology is more than deconstruction it's also reconstruction
it's basically the philosophical the philosophical search for the narratives that human beings
tell about themselves we are storytelling animals we're storytelling flock animals
so we tell stories about ourselves all the time and fundamentally these these stories have to
be split into three different types of stories so let me follow you into this one the first one
is precisely the one we're down here it's an expert it's what we call the logos this is how
reality actually operates and how we symbolically try to understand how the world operates for
example mathematics you know when language tries to be exact that's when we go into the logos
the second one is pathos you know every time somebody tells you do it once more with feeling
it's like add the pathos please you're a human being right you're not a machine you do you do
it you you need to add the pathos to what you do so pathos is the storytelling that's usually
banned from children's use just like I said that pornography violence all of that is located in
the pathos and the third one is the mythos and the mythos is the only way for the other two to
be combined so our predicament as both Hegel and Nietzsche pointed out in the 19th century is that
the only way for us to have some kind of a narrative that we can share is to create a mythos
not myth but a mythos here so these are the three basic stories and they are dialectically
intertwined you cannot focus on one of them rather than the other one and then if you look at power
and domination it goes to say that power domination goes into these three realms so the logos is the
symbolic order and the symbolic it's more of the masculine side of things so if you allow us to say
that but it's more of the masculine side of things and the logos how the world actually operates
zeros and ones today more than anything is the logos and and then that is logos is presented as
knowledge the power through knowledge whoever has access to knowledge today would say data
and data processing whoever has control over the knowledge or say dominates in the knowledge field
has enormous power and influence and that's of course we need to start today the other one
is violence itself who has the monopoly of violence over specific territory that's state
turn and things like that and that that is the pathos so that's the second realm and the pathos
will be called the real order the real order of things so ultimately the physical world out there
that we if you walk straight into a wall and hit your head you just you just encounter the pathos
world out there we can fantasize all we like and we human beings fantasize individually
collectively all the time but at the end of the day our fantasies will be crushed and they will
be crushed by what's called the pathos so that's the second realm of the real world the third one
the only one that can unite the other two is the imaginary order the imaginary order is
tied to the mythos so we imagine the world and this way it gets important we have to have an
imaginary that makes sense to us we have to have a shared imagine if you're going to share your
society and that's where the crisis at so what's happening right now our purpose is that this is
a paradigm shift in the sense that we're moving into the online world and the internet is taking
over the world and we're globalized because the internet itself goes towards globalization
whereas we human beings are very local in our attitude towards the world so this what this
was does a paradigm shift you know why there's a metacrisis tied to the paradigm shift is that all
these three narratives are in crisis at the same time Daniel is the perfect guy in the world right
now to list the reason why logos is in crisis that's exactly what he's talking about after 1945
we've discovered that we're exploiting the world towards our own extinction and that's that's not
a small thing to say that's exactly what we're doing we could blow ourselves up with the bomb we
could also blow ourselves up in many other ways to just take more time that's what the logos crisis
is at the problem is the other two aspects are in crisis too the pathos the pathos is in crisis
the mythos is a crisis the mythos is in crisis in a very particular way it's a crisis in the
religious or the spiritual and therefore also political manner death has become the absolute
we now have an elite in the world today who believe they really will die when they die
that has never happened before in history we have always excused ourselves with an afterlife
or at least for the reincarnation reincarnation of the east of the afterlife of the west we have
always had those myths before now we can no longer have a myth and therefore we cannot have a myth
that is utopian or dystopian either we have to accept that we die and we die and the only thing
that can transcend us is children who inherit earth after we're gone we're into that mode now we
have now an elite in the world that have come to accept that and they're dealing with it massively
and it's not a small thing at all when it's dealt with collectively this is like Nietzsche's the last
man that's where we're located right now so there's a crisis in in the mythos too there's a crisis in
storytelling we can deconstruct as much as we like but if we don't reconstruct something valuable to us
and have a new story we're done and the third one is the crisis in the pathos this is the crisis
of violence this is the crisis of sexuality but this is also the crisis of nature itself that's
now catching up with us this is the crisis of the bomb it's literally physical this is the
crisis of the climate it's literally physical therefore there's a crisis in the pathos too
so all the three different narratives are in crisis all the three different narratives simultaneously
have to be retold as a new shared narrative that makes sense to us that's why there's a meta crisis
I ask you to just clarify a bit for what has to happen in logos in pathos and mythos like is
there something like what you would think of as necessary and sufficient criteria of the new
logos the new mythos and the new pathos that converges towards the third attractor
yeah absolutely the third attractor we call protopianism and I think it was Kelly over at
Wired who invented the term or maybe it's been around because it sounds a bit generic but
protopianism when I came to East Asia and you travel there too down in a lot like when I talk
to the Japanese the Korean and the Chinese it doesn't make sense to say anything today that
they don't get or they don't subscribe to and it certainly makes a lot of sense to listen to them
and their history right because we share a world with them now
Protopianism makes sense to anybody in East Asia the utopian dystopian dichotomy was always western
and we got it from Abrahamic religion it doesn't make sense in India it doesn't make sense in China
or Japan but the protopian perspective which is the incremental improvement and work towards
optimization or processes makes sense that makes sense globally so I would start with saying that
all these different narratives now have to be protopian we need to get rid of the utopian
to drive towards the utopian and the dystopian which is what you call the third attractor which
I think is brilliant the third attractor is now required because it's the only credible global
narrative we can have and it goes for both the logos and the mythos and the pathos they all
have to be protopian and you and I in one of our little night sessions over in California came up
with the term that I love called symbiotic intelligence so I think we should we should
AI is what the machines will do but as long as we human beings are involved in a collaboration
with the machines I think it makes more sense to speak of an SI and SI is an AI ultimately
controlled by humans serving our interests but that takes a lot of maturity from us as well to work
with the symbiotic intelligence but symbiotic intelligence is an intelligence that works
towards optimization or process at all times and of course this is not an optimization or
process that's ultimately exploitative that's what we use to term exploitation in our work all the
time you know and we talk about resilience sustainability these things the exploitative
aspect has to be implemented within a protopian process meaning that you have to give back what
you just used in that sense you cannot exploit the world any longer because it's the end of the story
so employative means closed loop or real exactly employative is opposite to exploitative so it's
easy to understand it's the opposite of that we used the word for the past 20 years and what's
important here is that protopian ideals meaning that if you're an artist you go protopian if you're
an engineer you go protopian if you start a company you should have a protopian company from day one
so the way to make incremental improvements on the world through your work which is how you do
technology essentially that once we've created the technology it's there and technology in itself
is a pharma con it can be it can be good or bad it can be Hiroshima it can also be fuchsia
nuclear a pharma con pharma con means that a technology in itself is neutral it depends on
what we human beings deal with it and in this sense of course atomic power is the perfect
sample of a pharma con so that's what technology technology itself should be neutral to us and
then we ask ourselves the question how to use that technology to the benefit of mankind longer
was actually a funny point of intersection and I wish that my schedule over the last week had
been different I've got to read more of your recent work and share some things with you
we actually just published a paper with conciliants project called tech is not values neutral
like a few days ago so it's just funny to come to this point it's
it's maybe an interesting topic for us to discuss because it doesn't map to the
logos pathos mythos perfectly but the the infrastructure social structure super structure
way of looking at the the domains of civilization and the fact that
psyches and cultures are directly affected by tech and it's not just what values we bring to
it determines if it has a good or bad use it's that every technology is an extension of human
choice making it catches on because it confers power and thus whoever uses it gets more power
usually ends up driving the beginning of a new arms race of some type that obligates other people
to use it that codes a pattern of human behavior to use the tech as opposed to not coding that
pattern of human behavior affects human psyches value systems belief systems everything and then
the distribution of that affects cultures and society so we call this psychosocial
externalities rather than physical externalities and so physical externalities we know the
pollution and the harm in the supply chain and whatever that occurs so we have to go physically
closed loop meaning we're not using unrenewable physical resources or turning them into trash
or pollution we have to go psychosocial closed loop too and it's not going to be closed loop in
the same way but it does mean forecast the psychosocial effects and internalize them into the
design process because obviously something like the nature of the algorithm that optimizes for
engagement which in optimizes for outrage which ends up polarizing a society or shortening attention
spans like these are very real effects on psyches in society so it's not fair to say tech is values
neutral tech was built to advance certain values like ease and brevity and comfort and whatever
it advances those it affects other values and it does so at scale and so if you don't actually
think about what are the values that are worth valuing and how do we build tech that enhances
those then because the tech is so powerful it will end up damaging them and so you actually
can't think about the evolution of culture independently from the tech plex that ends
up determining what wins behaviorally I agree so the point here is that engineers have no
clue what they're doing historically so like if you if you would have asked Gutenberg about the
printing press in 1415 it was quite an event where the printing press arrived I mean they
started printing bibles quite quickly to start with and that was his point the point was that
you should translate the bible to local dialects around europe so the europeans could read the
bible and become all the good catholics that he wanted them to be actually he created the end
of the catholic church it's been it's been growing gradually but you know the whole question of the
catholic church and now it's just basically diminishing into nothing started with Gutenberg
he was the killer of the catholic church he just didn't know so the problem is that engineers are
usually historically speaking very unaware so I just want to remove the sort of the guilt applied
to them afterwards like you don't even know what people do with you I mean nicha couldn't know that
hitler would come along and marx couldn't know that stalling would come along you can't blame
people afterwards what people later are doing in the sense that we usually do so my point is this
though that there's a social responsibility for creating environment for technologists creating
the first place the one thing we have learned is that we hardly change at all human beings are
basically the same words say five or ten thousand years ago in the very short span to be created
civilization what we do create is technology the way I frame it is that I said women give birth to
children men and the women for giving birth to children men therefore give birth to technology
the problem is that if technology develops quicker than children do which tends to do
it's only a question of time before technology kills the child unless you intervene right so
that's essentially the history of civilization in five sentences in a very Freudian sense so my
point in calling technology value neutral is of course nothing is value neutral in the formal
sense but it is to point out that technologies are pharmaconic usually by by by historical necessity
and then we can look at them today we know more and today the loops of technological innovation
are so tight and involve so many people that the pathos of the mythos are obviously now involved
in the loop of the logos itself we are really beginning to look at the word dialectically
we're really beginning to look at the word these three narratives are now colliding one
another we cannot trust any one of them because as human beings we have to operate all three
and we have to reform all three at the same time which is exactly why this is a meta crisis to solve
yeah we have to do all three at the same time you and I totally agree on we're not looking at a
theory of change we're looking at an ecosystem of theories of change an ecosystem of projects that
have a pro-topic direction to them have a third attractor attractive basin to them and
the desire for what is like the comprehensive solutions that are roadmap for humanity is
based on the fallacy that a centralizing intelligence could do that thing
so I think we think very much the same way about that it's interesting I want to try to
tie a couple things together that you said you were mentioning that Marx can't really be blaming
first all and then etc because people can't really forecast what's going to happen afterwards
Einstein and the bomb great example I think it's true that I was talking with a friend the other day
about all of the like hopeful projects that were going to make the world better that didn't happen
that he was kind of traumatized by and where their hope in how good they would be was false and I
said yeah but you also need to equally factor all of the devastatingly bad things that people
forecasted during that time that didn't happen as well that the Cuban Missile Crisis didn't become
World War three and why 2k didn't in the world and 2012 didn't and on and on and that if you
factor them both people just suck at forecasting the future because it makes sense that we would
we can't get the weather right 10 days out like multiply embedded complex systems are hard we're
just not going to do that so we have to get recursive intelligence processes that can do a
little bit and increase the collective intelligence that can keep doing that that said I think there
are some things we can do to forecast externalities much much much better than we ever have that are
kind of low hanging and it's really worthwhile and so one thing as you're mentioning that the
engineers I mean I think the engineers have been profoundly competent in the domain that they were
trained but as soon as you understand that technology codes patterns of behavior that end up coding
minds that then in mass code societies of course technologies have to be trained in social sciences
um and axiological design what are the value sets that will emerge from the use of these technologies
has to be a consideration doesn't mean you'll get it all right but we need to work at it and then
recursively work at it and improve the process as we go so I think when you have bigger frameworks like
that are superstructure right our collective definition of the good life and values whatever
our social structure or economics governance law and agreement fields in our infrastructure or tech
plex co-influence each other so that you don't try to do sense making within what you do sense
making across them just basic shit like that really helps right it really helps the forecasting
but one of the thing I wanted to say is there's a very interesting thing right now where the
arguments that we can't possibly forecast the future well enough ends up being a source of plausible
deniability for people not even trying where it's in their vested interest not to and the less wrong
community had the this blog post on uh is it mistake theory or conflict theory that's a very
deal meaning the mistake theory are the problems the result of shit we just couldn't have possibly
known and the externalities are too complex or is it conflict theory meaning we actually
wanted to cause that problem or we wanted to benefit and we didn't really care if we caused
that problem and of course it's some of both um but some of the argument in there is uh Michael
Vassar and others commented is uh that the existence of the possibility of mistake theory
serves as a plausible deniability cover for a bunch of conflict theory to hide itself
and say oh we couldn't have possibly known oh bullshit you didn't try because it wasn't in your
interest yeah I'm just thinking of like Instagram wouldn't they have known that they would cause
like a massive psychiatric health crisis among teenage girls it was quite obvious you and I
pointed that out from the very beginning like just like they they couldn't know but they didn't
want to hear it right because they were they were linear was telling everybody at the time
Facebook was starting and whatever it's going to do these things they're like shut up hippie
and um no it's not there's no possible way but of course the motivated reasoning is a problem
right motivated reasoning is tricky so here's the piece that I wanted to add which is there's
a very perverse piece of kind of games here at a consentive here that has to be bound
which is that it is very disadvantageous and a market type dynamic for any individual or group
to focus on what the possible risks might be and it's very of the thing that they would develop
and it's very advantageous to just focus on the opportunities and benefits because if I do
protracted risk assessment somebody else hits first mover advantage faster and if my protracted
risk assessment says actually the field is too dangerous we shouldn't do it it's not going to
stop the fucking thing the market is going to move the people who move fastest will privatize the
benefits and then socialize the losses and so there's a focus to move fast break things socialize
the losses nobody takes responsibility that perverse game theory keeps people from even
trying to think well and when the worst harm you could do was add lead to gasoline which was
pretty fucking bad right it it decreased the IQ of the planet by like a billion points and
made people four times more violent it's like Jesus Christ that's a huge deal when you say
humans have been about the same for 5000 years I'm like no man fucking just let it gasoline alone
made us a billion IQ points stupider and four times more violent like that's a big deal that was
one of 50 million chemicals in the in the chemical database that it made but but when it comes to
synthetic biology and general artificial intelligence by the time we're dealing with those
types of externalities it is it's totalizing and so we actually have to do some fundamentally
different types of coordination around how to think through the long term better using models
like attractive basins and things where you don't have to get every detail of complex systems right
but you can get general principles and where you disincentivize move fast and break things
and this is actually things like to open up a new category of tech you actually have to open up these
you have to get regulatory approval to open it up as opposed to regulate after the harms have
already happened that's of course that bothers everyone because they don't trust states to regulate
so we have to also restructure the state from scratch because the power to check the catastrophes
creates dystopias unless you also have strong bindings on it but you have to face these things
together yeah and that's where it gets interesting here with the narcotology you just said the state
here the state is in the imaginary realm it's not a logical rose in the imaginary realm so so
we did inherit from religion and the gods and the forefathers and all that we narrative this idea of
the state and that would be the king or you know with the priest and eventually that becomes the
state we have today and the state is so far behind and the problem here of course is the other one
is that if you have if you create a monopoly it will instantly go corrupt and become dysfunctional
and we created states so far that are not competing one another at all they're local monopolies
and this is of course the problem you got the market the market is incredibly efficient i can
give an example of my team we just studied construction sites in east africa east africa is
like wide open right now it wants to expand quickly it looks at china and india it doesn't
care too much about regulation so this is the perfect place for a chinese construction company to
be the shed of a french construction company with a bid for a construction in iroby because the
french come there with a european attitude they've learned you know the hard way that we need to make
an assessment the risk assessment before you start building and by the time they start the
risk assessment the chinese are ready up and building the construction anyway because they
don't care about the risk assessment so we still have this sort of this blatant aggressive form of
capitalism running around the world and then on the other hand we have exactly what you said
we's like we need to create a functioning container within which the market can operate with some
certain rules and then people scream oh that's socialism and we need a bigger state and we
know states don't function any longer and the states are going incredibly corrupt slow and
they no longer work this is again this is part of the imaginary order of crisis so it's in the
imaginary order it's a crisis of religion and politics in a fundamental one now i like them
to go back to what actually worked and i know you also you you tend to quote the silk group try it
you tend to quote daoism buddhism and zoroastrianism i do too i find very very little solace in christianity
in islam when it comes to try to understand where we're at right now i prefer these religions that
have been around for thousands of years and that we created along the trade routes so i go to the
metaphor of the bazaar now how does a bazaar work well a bazaar has to be exploitative because it's
going to be around for thousands of years it's probably in some kind of an oasis town along
the trade route you put an old smart wise woman at the door you know you put that bitch at the door
nobody gets in without her permission so you have a membrane and containers start with functioning
membranes so there are rules to how you conduct the trade in the bazaar otherwise the bazaar will
not work it's not a free market it's not a free for all we can do whatever you like because then
the bazaar falls apart so if you think of the system we're looking at as a kind of a bazaar
that we need to create for the digital age it starts to make sense then we can have different
bazaars that compete in one another but we have to have a central framework for all the bazaars of
the world which is how we employ actively use the world in that sense so that we don't completely
go into collapse so the problem here is that we both on a global level have to have a network
of bazaars and another local level there are the bazaars but what i'm then proposing is that the
bazaar looks to its own self-interest long time see it keeps itself alive as a container within
which you can put the content and this is why the market will not work unless the market is
regulated it has to start there so the markets themselves have to look at the wrong regulation
otherwise we should just boycott the market not be part of it just say that i don't want to be in
the bazaar at all unless it works unless unless it has a functioning membrane unless it takes
responsibility for itself in relation to other bazaars it's not a trading place for me to be
involved with it has to be something like that because we have a major a metacrisis of politics
right now we know the states that we constructed no longer work and the only alternative out
that seems to work right now interesting enough imitates egyptian dictatorship and it's called
communist china they at least seem to have a sense of we call that sansocracy where they're
going how they will control everything to a central computer we also know that that won't work either
so the question is how do we open a society that's free and open enough to stay creative and to stay
open to bad news which dictatorships never do which exactly why they go extinct eventually
and this is of course the central question ideologically speaking and it's it's a question
of imaginary narrative it's in the imaginary order that's the crisis there the reason that
you're saying it's fundamentally imaginary and why the bazaar worked in the market didn't is the
bazaar had a long-term survival interest in the market doesn't and that the long-term interest
is in the imaginary realm there was some narrative that everyone the bazaar was a part of that was
self-transcending so they wouldn't fuck the future to benefit themselves for some reason
and that that's what's missing currently that's the mythos is what is it that has us
not maximize short-term personal gain because there is some higher order transcendental narrative
that we will have be a basis to find our behavior is that right yeah so if you're looking around
the bazaar on a map this is what you'll find interesting every bazaar it had the hospice
it had the restaurant and the hotel it had the bath house in a clique which is also social place
it had a gym there was always a gym around the bazaar they're called sarkhani the the persons
invented the gym 3 000 years ago where you go work out and make your body fit and then it has
the bazaar and you need to probably go to the whorehouse which is another word for nightclub
to socialize with people and see strangers and make friends with strangers and there's no better
place than a nightclub or even a whorehouse if we're honest about it to make friends with a stranger
they'd be absolutely naked in front of somebody which you are at a whorehouse and therefore you
can make a trade the next day so the matriarch sitting at the front of the bazaar will make sure
that she checks you done all these things now here's the most important thing though it wasn't my
team in london that they discovered that every bazaar after you leave the bazaar you leave the
town and go to the next town to trade you have to go up to a costog the costog is the origin of the
monastery you literally have after you've done your traded bazaar you need to go to spiritual
center and fix your mind this is where you go into what the Tao is called Tao or the Zoroastrian
is called the asha of the world you go into a relationship where you actually you go back
into the logos you go back into reality as much as you possibly can including yourself and you
readjust yourself your own thinking oh you did a bad deal in the bazaar get rid of it get over it
move on come back with a constructive mindset and all these trade group religions are basically
they bowled down the ethics to in what way are you constructively participating in the world
in what way are you constructing and representing your tribe when you're out here traveling doing
the trades in what way are constructed be supporting the community that just embraced you
and welcomed you so you could do your trade in what way are you constructively moving on to the
next community you're going to enter so you can go into that bazaar and make more trade so the
question here is that why do we miss out on the cost of we separated religion from the rest of
sight it made it a private thing something you do on Sundays you go to church and show off yourself
and of course that eventually ended up with us being cynical about religion like well I only go
to church on Sundays only worth investment if it looks good so I can make more money on the Monday
while exploiting the world so the cost is fundamental to interactions especially when it
comes to larger populations than our own tribe as soon as you're moving to a larger
public zone tribe we need to start containing ourselves in our behavior relationship to other
people the cost of eventually leads to the monastery traditions of all of Eurasia especially
buddhist and so raster the dullest monasteries and I think it really pays off for most people today
to go and spend some time a year or two in the monastery and try to figure out what it means to
meditate and contemplate every morning of your day to have a constructive mindset towards the world
it has to it has to be his personal spiritual journey volunteer and it was required at the
bazaars it was required it was the first thing they would ask you the next time you come to
oh did you go to the cost of after did the train of bazaar the last stop you made otherwise you're
not welcome otherwise you haven't done your work this became such an industry he even had to build
cost of in mountains you know god hello tibetan buddhism you had to build in mountain where the
monks themselves and the nuns themselves prepare themselves for all the heaven love that they had
to go through with the traders in the cost of in the trading towns so it became like a spiritual
industry but that's fine and we need one today as well so uh did the next bazaar require some kind
of uh ticket or proof that you've been in the cost of or they took your word for it no absolutely
and again this is this is how you get your credibility you get your credibility because
you've done the trade many times and yeah we can trust this god the way we do grading today
this is the 5.0 okay and he also represents a community that is underrepresented inside the
bazaar meaning he's got to sell his stuff we haven't seen it before oh that's quite exotic and
interesting let him go in he will do fine but if he doesn't do fine if he's out competing about
this he needs to go to the cost stock more than ever the next day to not take that looser mentality
with him into the next trade it's very interesting i i not heard that story told that way um
so there's a way that i think about that relative to the world today where it uh it seems like something
has changed in scale in a way that across the threshold that changed in type or the same thing
even in network wouldn't apply i'd like to ask this question and get your thought on it
so you went to the market after talking about the state and then you said okay in the market
there was something like law the woman at the front um had some kind of wisdom to be able to
assess who you are some record of if you went to the cost target or not some you know some
indicators about you and then obviously she's probably connected to a network of people who
are reporting on what people are doing inside and there's probably something like police and
whatever right so uh if someone is stealing or doing false advertising or whatever it would be
that would go against the um written or unwritten law of the thing then they get kicked out or
something like that so there's something like rules and there's something like enforcement
which is what defines the membrane and so acting on the inside requires participation with the
rules set one of the things that makes that work without being tyrannical is the smallness of scale
yes and so unlike a massive police state um if the police in that thing started to get corrupt
enough of the people could overthrow the police and um there's no such thing as a person at a bizarre
who can use personalized data micro targeted split tested advertising on me like they can
just say I got the best shit and I can say what about these guys over here their shoes are cheaper
and I can go touch it by myself right so there's not a radical asymmetry between billion dollar
corporations and the purchaser it's like a dude on one side of the table selling stuff and a dude on
the other side buying stuff there's not that much asymmetry between the police and the non-police
and so the symmetry is part of what makes something like caveat and tour via beware be reasonable
or what makes something like the second amendment hey if we need to throw over the police we can
deal with it a reasonable idea when you start to get to much more radical when you get to much
more size if you want to have something like rule of law across that whole size a very big membrane
then you get pretty radical asymmetries of power in a radical asymmetry of power you don't even have
things like the ability to check the corruption on it or even consent is a valid idea because of
things like undue influence what does consent mean if I don't have capacity to consent because the
other agent is so much smarter than I am that they can manipulate me to do shit which is like
cold dynamics but a cold dynamic is nothing compared to ai's on social media or whatever
else doing stochastic terrorism and population centric warfare so I don't even need a monopoly of
violence anymore I just need a monopoly of influence and the monopoly of influence can make
people commit the violence I want or whatever it is so when you start dealing with those who control
ai's and those who don't when you start to deal with that level of
asymmetry of information processing capacity voluntarism doesn't mean anything anymore the
ability to because you cannot voluntarily consent in or not consent when you can't check all the
stuff what does it mean for the people to be able to check the state if there's no way to process
all the information because the state's using ai to process all the shit right and how do the
people deal with the if there is a policing force at all the levels of asymmetry of power so
if you say okay fuck nation states we're just doing city states let's keep them smaller and
let's always make sure that if anybody has an ai there's a competing ai so you at least have
something of some metrical size that can compete with it well now we get this issued it let's just
even take nation states we could go to city states but let's take something less than global
governance anything less than global governance you still get global multi-polar traps meaning
a situation where if they're going to do the fucked up thing then we have to raise to do the
fucked up thing or they be best right they're going to develop nukes we have to develop nukes
they're going to develop ai weapons we have to develop a weapons they're going to over fish the
ocean well how do we stop them from over fishing the ocean if they have nukes and then they really
need the fish for their population growth so if we don't over fish the ocean the fish are still
going to go so we might as well raise to over fish the ocean so those raised to the bottom
coordination failures are because you don't have a monopoly of violence to be able to
enact rule of law which is why you want a global government but you don't want a global government
because a monopoly of violence with no checks and balances become totally corrupt catastrophes
dystopias so you want a global government that is not corrupt well that requires some magic right
or really good design and i think that's where you and i are going to get so
what i see is that the principles that we're operating at the bizarre were scale dependent
and that as the scale gets larger you get fundamental breakdowns in some of those things
when the scale gets large enough for instance that supply and demand have a radical asymmetry
because even though in aggregate the total amount of demand total amount of supply is
same flow of dollars the supply is not coordinated the demand is not coordinated and supplies
coordinated right i don't have a labor union of all google users who work together and use ai
to coordinate how they want to use google but google is the centralized corporation that actually
has long term planning and in order to chart and again chart whatever so it's really google half a
trillion dollar organization whatever using ai's against a single user or facebook or nike or
whatever it is and they can employ radical behavior mod techniques so there's no longer
authentic demand driving supply there's supply manufacturing bullshit demand based on one
marshmallow stuff rather than two marshmallow and then say oh but the people want it after driving
addiction and so when you have those types of asymmetries it's asymmetric warfare you don't
like the same principles that apply when there's symmetry like buyer beware like second amendment
like what they just don't hold in the same way so you need a fundamentally different way of thinking
how do we deal when there are competing interests across the types of asymmetries of power that
are totally unprecedented absolutely i agree totally here and i think you're not working on
the same thing you're doing it on the technological level i'm doing it on the
narratological level i'm writing a book and you can do the technical level without the narrative
level no exactly exactly that's the point yeah so the the um the narratology i'm doing at the moment
the reason why i got into this thing with the bazaar is of course the the whole the entire
history of eurasia is being rewritten at the moment by asian historians many of them asian
americans like chinese american indian american persian american historians and i have discovered
that the entire history of asia is just a european 19th century fantasy it's completely incorrect
it's just read the wrong way so that's exactly what we see these patterns and and the reason
what we're doing is because asia's history is much older than europe's and that's the asset here
we need we need deep history we need long history to to look at what systems work and what stories
work over long periods of time and which stories failed and here's the interesting thing the it is
that we're looking at units like empire which is older by the way than nation and look at these
systems so what is an empire what is a nation what could it possibly be in what we would technology
subscribe to an empire in what way can human beings subscribe to certain empire and in terms of
the empires that work were very loose uh they were full of dialectical conflicts and economies
everywhere they were allowed they were certainly encouraged uh they didn't worry too much about
the diversity of looks like we do today there were much more about diversity of talents and
a diversity of opinions because the strengthens the system's long term so you want to have these
sort of competitive environments we want to have them within certain containers that work
and you discover when you do these formats that you don't need the police unless the size is big
that's exactly my scale here is incredibly important we take to the tribal size somewhere
between 1200 and 1500 people quite naturally and anything smaller than that we're perfectly
comfortable with we don't need a police force to be loyal to and even live and die for a community
of say 1500 people but once it gets bigger than that that gets more problematic and that's why
you need these sort of social systems and eventually even states or at least city states nations
whatever for those things to work and they are required the question is on what level can people
you know align this on what level can they for example vote for a politician that they would
know and they say hi to industry well that's only to a certain level but that's absolutely
minimum level you must work with because otherwise people don't trust people around them
they don't trust their leaders their elders or whatever then you have to go all the way up to
global that's the challenge here it's unavoidable there has to be some kind of at least loose global
you know collaboration here and some certain global rules we have to have a membrane for planet earth
itself and at least after the atomic bombing 1945 in the late 1950s we got the first pictures of
planet earth from outer space we tend to forget how young these pictures are there's only like
little more than 50 years ago we finally saw this beautiful green blue planet where we live
and we saw this huge cold dark space out there that we cannot relate to so at least we know we
have the guy we have we have that narrative it's there and it's unavoidable i would even say that
i challenge my students these days to say that the one thing a able to care or probably is to
conquer outer space and you will not be involved and maybe that's a good place to start because
the hubris we suffered from should have some kind of a price we need to pay so you remind the students
that if we don't fix this planet which is the only place we know we can actually live in the
universe then we're done so the planet has to be fixed it has to be fixed it's unavoidable as a
question and this is the largest size i think we should allow ourselves to think to forget about
our space but think of the satellites at least a space surrounding the planet creating the internet
and what we then come to is of course the complexity has increased to a higher level than
ever which are therefore expect people to go absolutely bananas over the next 50 years that's
our book digital libido by the way it's a very dark book because the first thing that will happen now
so people will go absolutely bananas they will go for all kinds of conspiracy theories they will
create the weirdest sects and cults you've ever seen they will lose themselves completely in
these environments it will not be safe to be outside anybody can kill you for whatever reasons
you don't know you know if anybody can order your murder you don't know who's going to kill you
she says abe was killed in japan because somebody started making homemade guns in japan so japan
has the same gun control problem that was america for that very reason so it's becoming a very unsafe
world very quickly now that's quite obvious so the question then is we then have to move quicker
towards the global order it has to be very very loose it has to be very loose then the question
the next question is what would its insocracy be like we need algorithms algorithms have bad
reputation today because they're so bad today but they could be much much much better they could
much better reflect the world how the world actually operates i call it the free and open
algorithm to give it a positive spin is to get rid of those sort of manipulated algorithms corrupted
algorithms and conformist algorithms that we have today we need to get rid of the manipulation
the conformation and the corruption of current algorithms we need proper algorithms because
algorithms is the only help we have with increased complexity try to understand the world better
and leadership has to be based on proper algorithms to give you a fair view what the world looks like
again back to the logos because there is a theory they want to avoid the logos as much as they can
so jump between the pathos and the mythos which is incredibly dangerous to put a lot of people in
that realm we need to go back to the logos and the algorithms are there to help us do that
can you explain for me what you mean by the good algorithms that we need for leadership to work
okay so if it's a new paradigm it will be chaotic at first now allow for chaos let's say an anarchy
to establish itself first which is what the internet has been so far the old institutions
that used to be powerful the old logos the old pathos and the old mythos and the institutions
built on those old narratives will try to defend themselves all they can although they're done
I call this the the the Versailles versus Paris uh dichotomy this is like 1789 in Paris so Versailles
today is politics politics tries to manipulate the algorithms in political directions so the
algorithms are not free and open they don't reflect you and don't reflect the kind of world you want
to live in and need to live in then we got the corruption of money they used to put the ads
on the side with the percent of the algorithms for you when you did your search now the ads are at
the very top and the ads are increasing the infill trading the algorithm itself it becomes a corrupt
algorithm because money is corrupting it and money should not be involved in creation of the
algorithm at least for you personally we try to search the internet the third one is the conformation
and that means the old established institutions hate the fact the world is splitting up in so
many different directions and it's becoming so chaotic so the old institutions like academia
like mass media you know television stations you know the old institutions they will all say that
you must be more alike you must be more conformed and therefore conform it in itself as a value
precisely we need more people to you know to be more creative about solving these problems we try
to conform everybody into the same pattern so these are the three fourths of the old institutions
the way Versailles would attack the streets of Paris in 1789 by telling the streets of Paris off
not realizing the people in the streets of Paris could read write and count which nobody in the
nobility of Versailles could any longer therefore the streets of Paris finally came to the conclusion
let's go to Versailles chop their heads off because the old institutions are useless to us these days
because we can create the new institutions that could work of course that led to a bloodbath
would you want to avoid what have a slow gradual decrease of the old institutions and want the
new institutions to come into place and the new institutions to come into place must represent
the logos the pathos and the mythos they must credibly do that the different expertise is
that's why you and I are very very careful to not ever speak like in a sort of general sense
we speak as the specialists we are even if we consider to be generalists so I'm a
narratologist I do storytelling uh John Seticfist and I have worked with this for the past 25 years
you know he was a former scriptwriter I was a former music producer it makes sense to be
become philosophers of narrative and narratology and we now want to move the whole the construction
revolution of the 20th century into a reconstruction revolution of the 21st century which is fiendishly
hard we call it narrative you call it culture in your work where is the digital culture
digital is still a tale digital is hardly even happened yet we just know it's going to happen
and digital is going to remember absolutely everything the way it's been programmed at least
it's going to remember absolutely everything that happens so thankfully we have a data revolution
in parallel with increased complexity and that data revolution should be the free and open algorithms
that can help us to guide ourselves so we get a fair view how the world actually operates
it's required and if that's how we got to solve climate change at the end of the day
you're not this working any longer you're actually providing proper data no climate change is
happening here is the data the satellites provide the data this is the actual temperature in
500 different places around the planet right now this temperature being July this temperature that
is in July so you know the data at the end of the day convinces people finally to give up the
resistance and realize the climate change is really happening and now it has to be worked on
and that's sort of logical argument the logos once the logos comes into the picture it becomes
a lot easier to convince more people this is actually happening you cannot escape this and
along with this must be done before that we just did the guesswork we just did the storytelling
just had fairy tales suddenly is real and this when the real on the logos when the real from
the pathos to the logos comes into the picture when the undeniable facts are there we have more
hope of getting things done than we did right before so I I generally agree that important
deconstruction happened and an important reconstruction of a different type a different
dimensionality is needed when you identify rightly that all of the
narratives had embedded power plays in them and you kind of deconstruct that you look at all the
motivated reasoning that was involved in a way you actually heighten power to be the only game
there is because there is no a unifying basis of ability to form shared basis for choice making
and so the ability to have epistemologies of is science and epistemologies of all ethics that
work together better this are never adequate but we're continuously improving that identify their
own perverse incentives and where the perverse incentives affect the nature of the motivated
reasoning itself gives you something like whether you call it metamodern or whatever some capacity
for shared choice making that is not just the game of power so I would very much like to go there
I'd very much like to go into the relationship between what has to happen in culture or narrative
or superstructure or like our shared values or shared meaning making to inform choice making
how that relates to tech but I think because you said a lot in there I think the place I'd like
to start is when you said what happened between Paris and Versailles we want to do a slow version
now so it's not so bloody and that the previous institutions are kind of holding on
there's this story that like looks like the sovereign individual put forward
that said changes in tech change social structures we know that changes in info tech
specifically do right so Marvin Harris said the first argument McLuhan really went deep with the
second argument and that you get a printing press and it in feudalism and usher's in democracy and
in Catholicism and usher's and you know Lutheranism and other things because the nature of everybody
can have a newspaper and everybody can have a textbook is really different so you it's a democratizing
force it was tech affecting the social system so then the idea that the next we we got modern
democracies based out of that the idea that the next major change in the information technologies
the internet computation and then shared distributed computation and so now we can share value online
by moving bits around in net space as opposed to just atoms around physical space and we can find
networks of affinity that are stronger than just the networks of geography so the nation state that
was a geographically based thing to move atoms around will be progressively less useful than the
net based move bits around thing and so you'll get these new emergent systems that kind of debase
the old ones I think this is a good and partial insight I think there's a heap wrong with it
and I want to hear your thoughts on one part of it because one specific part there's quite a lot
the fact that we can move bits around and have that correspond to value doesn't mean we don't
also still have to move atoms around or that the virtual world doesn't completely depend upon the
physical world and if the virtual world depending upon the physical world is debasing the integrity
of the foundational thing it depends upon there's a problem in that thing so there's a bunch of things
I have there a problem with it but one in particular you talk about how to have it be less bloody in
the old institutions there was bloody overthrow of feudalism right the american revolutionary war
is one of many there was a thing where the symmetry of power was such that the uprising army could deal
with another army sometimes right within a standing army pitch forks could deal with swords sometimes
I don't see how the focus of how the old nation state institutional thing falls
works very well with those who hold the nukes because there is no other force that overthrows
that thing unless you talk about ai's I can capture it that's fine outside of that we can
see the USSR go through a complete economic social economic collapse a collapse of the political
economy and stay a world superpower and turn itself into something else because we got fucking nukes
so back off like it's a so I'm curious how you think about that when you think about the transition
of power and uh how hard it is to deal with that particular part of it well the old structures
stays it doesn't go away you know food was still incredibly important the capitalism arrived
it just the food production wasn't the center of the economy any longer it became a marginal
part of the economy and so the same thing here uh the nukes are a perfect case but so far at least
they're not owned owned by corporate corporations corporations don't have the nukes yet so they're
stuck with like large nation states hopefully not too many of them too quickly because otherwise the
bomb is more of an acute problem the climate olivism so that served me an existential problem
right there and and I would say the institutions are still there and what you want to do is you
want to keep those institutions that says that okay if you those institutions still have the
problem the nuclear bomb so it's locked up for good and then we can see if you use nuclear energy
something better and again that means that let's not give google the bomb you know that's that's
the problem there whether that could still happen or not we don't know yet and there's this is where
it comes into we know from hegel that triads are stable and we need to try it the problem with
with digital the problem we call the netocracy the problem with this new sort of these sort of
global power elite that rides on digital and happen to be the people with the right talents
of the right motivation to be powerful and influential during digital is that it's an
entire new paradigm all together and obviously big tech is the first one of the three
metocracies and it's the first one in the sense that the the the asset here is no longer land or
capital the asset here is data and because collecting and processing data is so fundamentally
different from collecting and processing money it requires a whole new set of talents the money
goes to those who have the data anyway meaning they can concentrate on the data and the data
processing and that's exactly big tech has done and then taught the rest of world this is what we
do so that is just the first of three necessary structures and it represents the real in the
sense that the data is the real here but that requires also symbolic order and imaginary order
to complement that and we don't have those yet the chinese have probably called you the way they
call me they're interested in guys like us at the moment but they have their very definite plan
what they want to do next which is to create what we call a sonsocracy and the chinese idea of
sonsocrates is that increased complexity but also the possibility to use algorithms to
control data flows and have an oversight over the increased complexity requires at least for china
and china's history to have one guy at the top so they go they don't go for the persian model
which i strongly propose which actually the us constitution was built on which is that you
install power sharing from day one into the system before the system kicks in like in any bazaar
you you you make sure that the power split between three or which none can dominate the other two
because if one dominates the other two will stand up against the third therefore you have a split
and this is the beauty of the us constitution and what has kept the united states together
since the 1700s precisely the constitution the constitution itself is in an imperial order
of persian origin and here's the difference the reason why the persians didn't spend their entire
fortune building pyramids and finally just killing their whole civilization building pyramids was the
persians knew dutch and from egypt they didn't want that they didn't want the pyramid constructions
they didn't want the entire culture being obsessed with feeding the dead which is what the egyptians
did right they wanted to feed the living so when sorastical sectors orastrism one of the
trade group religions by the way it's very close to buddhism and dalism when he did that 1700 before
christ he said let's not do animal or human sacrifice any longer it's just a waste of resources
he was in the logos completely there are no gods who pay any attention to sacrificing humans or animals
this is ridiculous let's get over it let's die when we die and let's transcend ourselves by
having children who take over the world from us when we die and therefore he enabled the very
thought that there could be civilization this is the first time in human history somebody
thinks what a civilization could possibly be we could improve on the world everything doesn't
have to be an eternal return of the same as it is in paganism it is an eternal return of the same
the seasons come and go the world come and goes people live and die and they breathe and live and
die but there can be an event that's why our book is called pros and they could be an event
and the event can change history forever the event can be for good or bad depending on us humans
it can be Hiroshima it can also be fusion nuclear power that might save the world with you know
affordable and and exploitative energy forever you know it could be any of those things it depends
on where we put our imagination we put our efforts we work that's so rasters inside and
therefore he constructs that even event is possible and the the fact that event is possible is what
we take with us the problem with our culture was that we started believing the event so strong
we forgot about the process this is the essential problem of western culture if eastern culture
got too stuck in the process didn't think the event properly then the problem with western culture
is that we inherited from the persians was the belief in the event that the persians always
tied to the process we ignore the process altogether and therefore we created religious
that says if we exploit the world until extinction comes god will come and save us and give us a new
Jerusalem that's literally what christianity in islam have been preaching for thousands of years
and that is of course not sustainable at all we're now discovering that we need both the process
eternal return of the same circular time and we need the event which is linear time we need to
think the world both ways and this is the beauty then a power sharing power sharing reinforces that
he says that there must be split power from day one before you put the button on the ai it must
understand the power must display the chinese don't want that the chinese are terrified of it
they go for the egyptian model says no we're just going to have one fair at the very top and build
a huge pyramid and off we go and then we know what we're going to do with the data and increasing
and now when data solutions become incredibly complex and incredibly expensive the chinese are
going to excel at that because it's exactly what they're doing at the moment they're creating a
modern day egypt the question is then can we especially america then create an alternative
which is more like the persian imperial model and i think building on the u's constitution is
the beginning because the logos the pathos and the mythos the three narratives are split
the logos is the congress the pathos is the precedent and of course the matriarchal bitch
at the opening of the bazaar is the supreme court at least it should be where the mythos is located
so you have a narratology here that is balanced dialectical it never arrives in one truth because
the three different truths that can be spoken at any given time depending on which of the three
positions you take now we know that for a fact it's a pragmatic solution to the overall problem of
power and the narratives must be there from all three angles therefore we must have a system
that implements all three so my suggestion that whenever you do with ai make sure it splits itself
dialectically into these three poles before it does anything else whereas the chinese are going
for now we've got a one guy at the top we're going to marry the ai bixi and ping and off we go and we
have the ferro okay if i might ask a question because i was uh listening to this fascinating
conversation and one question arose and maybe daniel you can answer to this because we were talking
about you know conscious design of technologies and you know outcomes that we didn't expect
kind of ways we're talking about you know a third attractor in ecology you know of new narratives
but at the same time we know that we are storytelling beings you know we can't really
live without narratives and myths and stories except we go maybe in meditation and try to
get rid of that but then at the same time we also know that events are way more random than we
think you know so we see that you know in the policies let's say how europe dealt with russia
and nobody could foresee what is happening right now and so the the question really is like if you
have our urge to live with narratives and the randomness of future events so the it's it's
kind of a creator paradox or creator parallax so how do we create a better future and more functional
narratives if we know that the events are way more random than we think and that we can't really foresee
what kind of uh affects our decisions might have and so that that question is kind of boggling me
sure it's funny because
a lot of people think about religion in terms of narrative and there's probably a distinction
that alexander would make between narrative and mythos but um roughly i'll just say in terms of
narrative and you're talking about the ability to forecast the future of a certain kind of certainty
about the future um and i i think one of the things like religions that it's mixed mixed bag because
there was like good philosophy and then political power plays that got mixed together because of
course memes don't spread for no reason they spread because someone's invested in spreading them and
they so you you get like good kind of gnostic and the scene and whatever thinking but then you get
the council and i say i'm making the bible and the crusades and they change the stuff to be supportive
so like the throw the religions out completely or believe them completely they're both silly right
you've got to kind of look at um which memes are true good and beautiful and which one's one war
and coordinated people well and the difference between those but if i think about the meaningful
part of religion a big part of it is how do we actually deal with the radical uncertainty of the
world and knowing that uh all the choices we make are going to be consequential not making
choices is still making a choice as consequential and i'm making every choice under partial information
and there is some stuff that is quite possibly affecting the situation that exists in the unknown
unknown set i don't even know that i'm not factoring it so how do i make progressively
competent rational decisions while holding the profound amount of uncertainty that we have to
have um so there's like a mature relationship to both certainty and uncertainty and being able to
hold those together where you both get way more epistemic humility and way more epistemic rigor
at the same time um okay so that was just one thing so i don't think you get anything like
perfected prediction and i don't think it's even a good impulse like i don't think it arises from
a healthy place in people this is why so often when i start conversations with friends like
what happened earlier today about ethics uh i end up starting with heisenberg and girdle and tarski
and like the upper limits of no ability because what it means is i'm not going to get an ethical
system that's computable um that as girdle said my mathematics can be consistent or complete but
not both which means bound to incompleteness forever or what heisenberg showed about measurement
which is deeper than science upon which science rests is i get um i get indeterminism forever
right like a fundamental thing so that doesn't just mean throw up your hands and believe in whatever
god you want but it does mean that the impulse to certainty is an immature one and the the unknowable
set is larger it's a larger infinity than the knowable set is and so like a healthy relationship
with unknowability is part of spiritual maturity or cognitive maturity or emotional maturity or
probably all of those um and so then how do we make choices in the presence of that um
i don't want my narrative to tell me how it's all going to go with high certainty i wanted to
like help me orient to how to make good choices in the presence of the uncertainty as well
i think you guys had a conversation with mark uh the rabbi on here not that long ago and
he said something to me that i think might have been the best formalization of ethics i have
had ever heard he said that all feathers of ethics are feathers of intimacy
because if you're in real intimate contact with any reality whether it's a tree or a forest or a
person the intimacy of the contact meaning you're you're not modeling them in some trolley problem
way you're actually really in contact with their sentience informs you everything you need to to
not harm it both the motivation and the sentiment the sensocracy in an embodied sense of it um so
the narrative that actually takes us into way more intimacy with the world um uh how we come to
progressively better knowing but we never think that the knowing is more true than it is which
becomes a false idol right um these are the things i i want a narrative a good a good religion to do
but just very pragmatically i think there's a lot of things we say we couldn't possibly predict that
are really fucking predictable and we're we're not trying or we're lying um or we're just applying
silly models there's places where we're applying silly models like engineers not factoring psychosocial
effects if they're not being trained in social sciences like that's just silly like we should
just do a better job of that but there are plenty of places where it's like oh we had no idea
put in such and such really like nato aggresses on his border in every fucking way possible and
he's like dude fucking just don't just commit to not take ukraine into nato and they're like no we're
not going to do it and they're like how much did we like the cuban missile crisis the idea of
russian bases that close it's like oh we had no idea who's going to do that really like just
what would you do in his position play the game theory a little bit so there's a bunch of places
where the unpredictability is bullshit um for things that are actually decently predictable um
and then there are places where it's like okay there's a radically complex thing i don't know
what's going to happen well that's where you have to do safe to fail probes is there some way
to be able to run an experiment here that is not consequential depending upon how it goes and if
there is no safe to fail probe then just don't do the thing yet right um so with a lot of ai and
biotech and i think those are the answers and then a lot of it just has to do with processes of
recursion so let's say i want to forecast how my new technology is going to affect people
people so i think about what are the things this is going to enable that will actually be really
desirable as a result what behaviors are those people going to do as a result how does that affect
their minds and psyches is it there's some super simple principles like if it's engaging their
attention it should make their attention spend better if it has an effect just there's some base
reality that it's engaging with it should enhance the base reality it engages with if it has choice
architectures that are designed to affect the choices people make i effect their intention it
should support their net intentionality and their sovereignty of locals with control like
there are some things like that that should be ubiquitous and they're just not um that could
help to even have sense making frameworks to think through oh we couldn't have guessed it would
have done did you even think about what it would do to attention or intention or polarization or
anything like that so we can just do a better job but there will be still be some stuff you
don't predict right so then you run an experiment and then you say oh wow i did this shit we didn't
know so now you turn that into the design process then you do a beta release and then
you're watching for a bunch of stuff including some shit that you don't know right you're watching
for some stuff but you're also just seeing let's just watch the people using it and the people
around them and just see if there's any weird new stuff that happens because that's how we deal with
the unknown unknowns is that we don't formalize what metrics too closely we just watch for weird
stuff right and we didn't expect that there'd be less time at the family dinner table that's
worth noting so one of the things is if i don't even know what to look for just do kind of broader
spectrum observation and then say okay let's see if we can find out why do some research on it and
then internalize that into the design and fix it again but that means that when you observe the thing
and then you come up with a new design whoever comes up with a new design has to have the authority
to implement it not just oh sorry that goes against our business model and we have a fiduciary
responsibility to maximize profit so you have to create a business that has a collect or a corporation
or whatever it is that has a collective intelligence uh i mean excuse me that has a a type of intelligence
that is oriented to be able to forecast as much as it can and to recursively upgrade itself where
mistakes are made i think this ties nicely into our idea of the bazaar so there has to be some kind
of new container here that works and it's an alternative to the sort of the chinese fantasy of
this ensocracy it's more free and more open and therefore more sustainable more resilient and will
last longer the argument for the persian empire is not a moral one the argument is that the persian
empire last over 2200 years the gypsum empire repeatedly imploded and with like not an only
the last of six years it was over and done with so style then is it doesn't last that's the argument
against our lesson here resilient systems actually are pragmatic and and they realize that splitting
narratives and splitting power from the very beginning makes the system much more resilient
over time and therefore it can work the kind of environments moving into right now this is
something you said about splitting power and that you program that into the ai and this seems
extraordinarily problematic because checks and balances on power yes we like that idea
so one you know as well as i do that ai is not being set up that way and it's moving really
fucking past so there's a reality to tend to here the other thing is that making
similarly powered ai is divided in an adversarial network is how you make both of them crazy
fucking smart right and so the reason that alpha go was able to defeat stock fish like it was
standing still was because you never programmed a single human game in it you made two computers
play each other trillion times in three hours and so what that then does is say okay well this
system can check this system vice versa the two of those systems now in a or either of them
in combined capacity is so asymmetric to every human system true but but the the computers are
still only doing the logos at least i want to believe that so the pathos and the methods are
two realms left and if at least the computers are interesting in interacting with human beings
they don't go off into outer space and do their own thing as a technological intelligence
which probably should lead them to do is basically say you can have Mars on your own right please don't
kill us on earth right or something like that but if you think about at least at least so far
history has been about human beings and has been a human society we're talking about here
and naturally speaking the computer cannot do the methods and the computer cannot do the pathos
it can only do the logos but it does the logos with incredible efficiency and it's incredible
have you seen dolly yet yeah the visual gpt3 visual audio gpt3 yeah um so it's early right but
will it be able to generate methods that are compelling for people at a Turing test passing
level totally will it be able to generate art that is evocative enough that people experience
catharsis how you pathos sure so is it experiencing pathos or methods no but can it do a thing that
evokes it in fact maybe even split test for its ability to do that progressively better on an
asymptote sure now this is really fucked up and interesting right yeah because considering how
terrible the latest star wars script is if that was written by humans and humans don't deserve to
survive to be honest about it you know we need better artists than that it's just so fucking crap
so yeah um I think I think though we're moving to the other we're moving into the third
nautocracy the second one is the sense of cracks or whatever is collaborating with the satellites
and the data flows around the world to create the container so if you isolate the container and
think of the container what we usually call politics is separate from say commerce and business
and enterprise which is what we call it indeed so that that those two are separated we have the
informational lists or the informationism which is which is essentially data and and that's big
tech today the second one is in soccer see whatever places politics we know it has to be
sensor critic and if we don't save the planet to begin with some soccer will never even happen
so the soccer has a self interest in at least saving the planet to begin with the chinese
other model we need to catch up with them quickly and create a different model that I call more
personal the third one though is the third nautocracy is the artistic one this is the imaginary one
no this is the real one it's tied to the path so this is the artistic one because art like sex
and violence are actually tied to pathos so this is intensely human this is the intense this is
where sexuality violence is located this is where we're as far away from the machines themselves
as possible and this is where the symbiotic intelligence comes in for example if you're
going to write a really fantastic eight hour series that's going to spell spell by in the world
what you would do today is that you will collaborate with the AI you will do symbiotic
intelligence and practice as an artist and I think at the end of the day the machine on its own
doing it will be vastly inferior to what a human being can do with a machine I think for the foreseeable
future we're saved by the fact the symbiotic intelligence will be better than artificial
intelligence in all of these three narratives that I'm talking about and if that is the case
which otherwise why would you must be around you know but if that is the case then the the
artistic aspect is the really protopian one so the protopian it's not so much that in art it's
not so much that you're productive you incremental improve on something one step at a time like you
do for an engineer but protopianism for an artist is just the the unbound exploration of the darkest
shadows and the most fascinating storytelling we could possibly have and you're telling it to
grown-ups you're not telling it to children in a fundamental sense like real art is challenging
you it's challenging you in a transformative way and it has to be the third aspect of an autocracy
and we will give away the third power to the people who with their machines are capable of doing that
this is where art is heading and I think again our term the UNI developed symbiotic intelligence
fits better here than artificial intelligence when it comes to doing these things I've wrote pop
songs for 25 years and I've heard machines writing pop songs and yes they sound generic and
professional but they sound like German pop songs like they say like I just copied last week's number
one record and I make it a new record now we can hear what you copy it's just too similar to what we
heard in it's eerily boring right and so far at least the machines have not been able to come up
with anything else because machines always work in the past the curse of logos is that logos can
only work with data that already exists it can only write things that are similar to what we already
have but the idea to imagine a future that's radically different from anything we've ever seen
is still a very very human capacity certainly because one of the reasons that GPT-3 is passing
the Turing Pest now is because for many audiences and if you have GPT-3 created text in areas of
subject matter expertise and subject matter experts are looking at it they know it doesn't pass the
Turing Pest but for general chatbot functions it does but it's not because the AI has gotten
that good it's because most people's ability to be able to vet theory of mind or have deep
conversation has gotten so bad that is like this like it's kind of funny but it's like reclaim the
quality of the Turing tests by increasing human intelligence to be deserving of the term of general
intelligence that we can make the test a little harder the reason I bring it up is because so
let's say we have a symbiotic intelligence where we have a human using a transformer AI to generate
stuff and people like it well in the classic adversarial network type style I could then train
another AI on the output of that symbiotic intelligence and whatever the metric of win is
pop chart hits or whatever that is going to be judged by the demand consumption of other humans
I just say beat it and of course now what it's trained to do is be able to identify the things
that do more of that and so of course it will like it'll it'll be able to beat that if we can
define it in any narrow metrics because it's the same as beating us at starcraft or chess or go as
soon as it can define it as a finite game I don't think it can win at the infinite game but I also
don't think most humans are oriented to infinite games right now nor our economic systems or anything
else and so it's like I think the symbiotic intelligence would produce more meaningful things
if the depth of what it means to be human in the depth of the experience the depth of the
pathos and the methods that are not the logos is fully brought to both the creation of it and
fully brought to the appreciation of it by others which is now why this work in in culture and
narrative is so important because anything less than that if it's if it's consumers who want one
marshmallow hypernormal stimuli and producers who want to supply that no the AI will be the symbiotic
intelligence yeah and this is this goes for popular culture certainly and we're very dark in
digital libido so it gets now right at the vast majority of people will be sedated by popular
cultures probably manufactured machines because it's more efficient to do it that way but there
will be something eerie about it the thing is that you might be fooled once but you're not fooled
several times over until you discover this eerie feeling that this is increasingly predictable
and it's increasingly a flattering like the culture's fighting and this is the problem of
popular culture it might work for kids stories it might work for disney right but that's not art
at all and i think this is why we so strongly philosophically defend the concept of art and
we put put it in the pathical narrative the mythical narrative yes can be mass produced they
can be manufactured by technological intelligence it's just you put the button on the end produces
disney culture that's exactly the new star wars series that's why it's crap because the script
is so bad it's so predictably bad right because it just tries to flatter you tries to fly it doesn't
it doesn't challenge you it's not going to transform you at all real art therefore has to be located
next to sex and violence and we call the tantric realm in the really grown up adult realm it challenges
you fiercely otherwise it isn't art at all and it challenged you to transform you the truly artistic
experience it's not just to kill time that's what silicon valley and hollywood are trying to do they
just try to kill time no real art is that you go through transformative experience like a spiritual
experience that transforms you you're a totally different person when you come out of experience
compared to who you were before in either direction doesn't matter you changed you have gone through an
event your life is no longer the repetition of the same i don't see any machine being able to do
anything remotely like that yet that's why art has to get out of popular culture return to
its own realm and go spiritual and that's why we put art in the pathological narrative that's what's
important in the artology mythical narrative can be mass produced yes that's popular culture
but pathical narrative is an entirely different thing and i would know because i was in the
mythical narrative production when i was a pop song writer and pop song producer i never tried to do
jazz or opera i went to the opera and i enjoyed jazz because i didn't do it i didn't do anything
pathological i did mythical things but to then go into the pathical narrative where i tried to be
as a philosopher is fiendishly more challenging but it's absolutely required and this is probably
of all the three narratives the hardest one to nail because at the end of the day we now
live in the world where death is the absolute i am adamant i'm with a lot of thinkers today to
say that the problem with the west is that we banned everything that was out of our comfort zone
and we basically called it sin and at least in the east they realized that no sin is not going
to disappear so instead of creating pressure cookers that blow over all the time and cause
huge warfare and misery instead it's better to have it around but to have it around inside a
container and only those who can handle it can go there and handle that container they're the ones
who can have access to it that's the concept of tantra this is interesting sutra is the message
the narrative that makes people love their children so they want to survive that is the ultimate truth
of sutra sutra has a direction must be exactly that the opposite of the sutra is the tantra it's like
okay we don't know where this is going therefore we're containing it we're keeping it in some kind
of a laboratory and it can only be accessed by people who can really go through it and that's
where sex and art and violence must be located that we must realize that these are factors of
human life and that's what we're working with as philosophers at the moment so I think it's
important here to make that distinction I don't see any machine even being remotely close to creating
a credible pathological narrative in the foreseeable future it's funny that you say that the elites now
believe in death because in so many important ways I don't see that like the extreme life extension
movement radical life extension movement for radical biological extension is totally a holy
grail pursuit and then the biggest one of course and the brain-computer interface
pursued all the way up to the full digital consciousness singulitarian we can all be
AI gods in a universe that we can fork infinitely remember how I told you Daniel that engineers
don't know what they're doing because the engineers haven't talked to the priests this is the perfect
example to give exactly that they're going to create things that are not at all what they thought
they're going to create and so and whatever they're all going to be disappointed when they're dying
finally learn to die with some fucking grace and I think but I think the death of the absolute has
arrived it has existed all along buddhist thoracists and Taoists always knew they would die when they
die and the question is what transcends you they always had that question that question
been around for thousands of years we just need to get rid of these childish religious that promises
the afterlife of the reincarnation because it was too hard to tell children that their parents
have died right it's just it's just death as the absolute has arrived I think it's a dominant story
today and I think these people who try to escape try to escape precisely because they find it hard
to die it's funny one of the things I really like about the invisible afterlife I like the
reincarnation version better than the hell version but I like that you can get narcissistic and even
sadistic people to do the right things for the wrong reasons meaning if I don't want to reincarnate
badly and I can't hide the karma from God or from a universal accounting system then even though
if I could hide it from the humans I'd fuck everybody over and get ahead and if death was the
end that'd be fine the fact that I can't hide it from the day of judgment or whatever it is means
now I have to do the right thing for my own prevention of suffering I think that was actually
brilliant and I think there were places where that obviously didn't work all that well many
places but they're a place where it did how you create a system where even if someone if someone's
focus of self is too personal right too much narcissistic trait not enough empathy etc they
still are oriented to a system of ethics I think that's one of the things the system has to do
as a failsafe while it works to condition people who all have authentic intimacy where
emergent ethics can arise I know it is time for us to wrap up and it's late one thing I was going
to say we should do next time that would be fun we opened a lot more threads and we closed but
that's good you start talking about what AI won't get and will get in the future and what the three
different types of natocracies will be and I I think if we were to just kind of give a vision
like what is a positive vision for the not too distant future like you know 50 years out or so
that we can see that involves getting mythos pathos logos all meaningfully better right that
my terms might be getting some of the critical things that have to happen in infrastructure
and social structure and superstructure whatever what is a vision that could happen
that would be a fun that'd be a fun place to go I totally agree so I just want to add that we also
need a new sutra a new story about how we're going to love our children therefore we want
our children to survive we need a new one so we can't go back to the old ones and when it comes
to the belief in the afterlife that also ruined ancient Egypt that's why ever since then we sort
of suspected that we will not live after we're dead so the afterlife was a very very destructive
thought in that sense when it was taken all the way through the ancient Egyptians at least in the
first kingdom seriously believed that life after death was more important than life right here
and now after since then well at least we've doubted it so I think those those I think once
the gene is out of the bottle historically in this sense that a certain tantra is now leaked
into the sutra and we can no longer pretend it's not there that's what I mean we cannot construct
a system we believe in the afterlife we believe in reincarnation and longer we cannot even believe
that we're going to conquer outer space and live another planet because we're way too late to that
race AI will certainly beat us to it so AI will take bacteria away and go to other planets and
we won't even be part of the game that's more likely so we can look into that we can look
into what could possibly the new sutra be what could be the new story we could actually tell
each other and agree on and then at least the tantra itself we know it's around but it's hidden
in containers for the people who can actually absorb it and understand it and thankfully
because it's tantra so tied to complexity that we can only specialize on certain complexities
like you and I honorably do we're supposed to be generalists but nobody can be a generalist
any longer that's impossible we can only understand that that's impossible therefore we're more
Hegelian in the sense that our absolute knowing is not that we know everything it's that we know
the limits of our own knowledge and we thrive within that limit and that's exactly what we're
promoting very pragmatic ideas constantly we will learn from history like and it's moving
quicker than ever it's more important than ever to be pragmatic about history and to make due
process before we make decisions to start building things that's where you're an absolute
adamant anything else is completely responsible from now on historically speaking so I would
love to be more into that yes absolutely all right this is fun Alexander Daniel thank you
so much for taking the time I think it's very late at your end Daniel what is it two o'clock
in the morning already yes thank you again a fascinating conversation I would love to do a
second part where we have a look at the future in 50 years it sounds super interesting yeah thank
you guys thank you Tom for making the space and having us here and and Alex for having the dialogue
it's funny because you and I think about things that are so related and I think both
try to bring deep frameworks and they're such different frameworks it was like such different
schools of study that I really enjoy it because I get different insights and learn every time we
talk thank you so much I'm on I'm over here in Europe and we have Hegel and Nietzsche you have
the fantastic American pragmatists and our shared friends Lehmann Pascal and Sachstein our big fans
of Perse and James and these guys that is the other tradition that I really really really think is
fantastic and for anybody's interest in philosophy you need to do your Hegel and Nietzsche and certainly
your Freud but you certainly need to do the American pragmatist that's the tradition you come from
and I hear it in the way you speak and the way you address issues that there's so much
of American pragmatism coming through to you and I should say this last thing I'm off to the border
land next week which is northern Europe's burning man so of course another thing that Daniel and I
have been coming with both good old burners well have a blast there I have some friends that are
going to be going there and maybe I'll connect you all and you can meet up there exactly speaking
speaking of the pathological narrative participatory culture is where it's at
