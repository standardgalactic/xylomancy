This is a presentation that comes from my essay on the Unidolamma, we will be covering
some very basic category theory with minimal formulae involved.
Everything in this presentation is very much simplified as it is just an introduction.
So with that out of the way, let's begin.
Here is a formal definition of a category, don't worry about reading it, we'll be going
through it soon, bit by bit.
But many structures and mathematics come alongside some notion of maps, which are used to relate
different objects with those structures.
For instance, groups come alongside groups of morphosomes, vector spaces of linear transformations,
probability spaces of measurable function, and topological spaces with continuous maps
to name a few.
A category is a collection of objects with arrows or maps between those objects called
morphosomes, and that's it.
All of the previous examples are thus specific types of categories, and many common constructions
in all of these fields do not actually align the specifics of that field, and can be carried
out and unified together when at a level of a category.
The most common of these constructions are products and co-products, direct sums, kernels,
that kind of thing.
We unfortunately don't have the time to cover these things in particular detail, but it's
a good motivation as to why category theory is studied, and it's also important to type
theory in partial programming.
We begin with objects.
A logic can be really anything we want, but we often work with mathematical objects,
such as numbers, or sets of numbers, often with additional structure on top, like groups
or fields.
The collection of objects in the category C forms a class called the object class of
C, and notes like I said class that are not set.
This is because these collections of objects don't usually count as sets on the ZFC.
For instance, the set of all sets would be disallowed on the ZFC, but such a collection
of objects is useful to use in category theory anyway, so we use classes instead.
Next, we have morphosomes.
For any two objects, A and B, we can have a morphosome between them.
It can be helpful to view a morphosome as a type of directional relation.
There is a morphosome F from A to B if A is related to B, but B does not have to be related
to A, and we write this to note this relation.
We can also have multiple morphosomes from A to B if A and B are related in multiple
ways.
We could also be the case that A and B are not related at all.
For any two objects, A and B, the collection of all these morphosomes forms the humset
of A and B.
In the case where A is not related to B, this humset is empty.
And because morphosomes are directional, note that the humset of A and B is not the same
thing as the humset of B and A.
And again, despite the name, humsets do not necessarily count as sets.
We'll largely be ignoring the distinction in this introduction, as the castries we
construct will be locally small.
This means that the class of morphosome between any two pairs of objects does happen to be
a set.
If the object class is also small, then the category itself is called small.
The collection of all the humset in the category C is also written like this.
Of course, now that we have things that point from one object to another, we're going to
be able to combine them.
Also, if F is a morphosome from A to B, and G is a morphosome from B to C, then it will
require for there to exist a composition morphosome from A to C.
Compositions have to obey two axioms, the first one being the identity axiom.
For any object A, the category requires an identity morphosome from the object to itself
that follows a few constraints with respect to the composition.
Identities must compose with any other compatible morphosome and leave them unchanged.
They're the neutral elements of composition, just like zero for addition or one for multiplication.
The second axiom is associativity.
It just states that the composition is associative, nothing special there.
So these are the things that our category can post off.
Let's go through a few simple examples.
Let the object class of C contain A, so the category only contains a single object.
Categories require identities, so we have that in as well.
But the identity morphosome by itself trivially satisfies the identity and associativity axioms,
so this category is called the trivial category.
And apart from the trivial category, we usually omit the identity morphosome from these diagrams.
Let the object class of C contain A and B, the homset of A and B contain F, and the homset
of B and A be empty.
This is the arrow category, consisting of a pair of objects and a single morphosome between
them, pointing in one direction only.
So let's move on to some more interesting examples.
Let G dot to be a group, and let the object class of C contain a unique object X.
We set the homset of X to X equal to G, and define the composition of F and G to be G
dot F, so morphosomes have group structure and the composition.
Because groups require associativity and identity, the morphosome axioms are satisfied, and we
see that a group is really a miniature one-object category.
In fact, there's nothing really specific about groups here, we could have started with a
monoid or any other algebraic structure that has identities and associativity.
So these last few categories are pretty simple, but they give us an idea of how basic categories
can be.
We visit a few more important categories now.
We have set, the category of sets and set functions.
Objects are unsurprisingly sets, and morphosomes are functions between those sets.
Identities are just the identity function on each set, and the identity and composition
axioms follow from the basic properties of functions.
We also have group, the category of groups, and group homomorphosomes.
Homomorphosomes are just functions that happen to respect group structure, so identities
and associativity are inherited from set.
We have top, the category of topological spaces and continuous maps.
We have vector sub k, the category of vector spaces over a field k, and linear transformations.
These last few examples might give the false impression that objects are always sets, perhaps
with extra structure, and morphosomes are functions that preserve that structure.
This doesn't have to be the case, we build another simple example of this now.
The objects in our cascades will be the real numbers, and we define the morphosome from
x to y if x is less than or equal to y.
The problem here is that we can't really say what a morphosome is.
It's not a function that acts on anything like a function in set, and in fact it doesn't
seem to do anything at all other than existing whenever x is less than or equal to y.
The morphosomes f and g imply that x is less than or equal to y, and y is less than or
equal to z, so we have x is less than or equal to z by transitivity, so they resist morphosome
to assign the composition of f and g.
We also have x is less than or equal to x for all real numbers x, so identities also
resist.
Associativity and identity axioms are also easy to verify.
So the set of real numbers equipped for the non-strict ordering is a category.
And again, there's nothing specific to the real numbers here, so any set equipped for
the non-strict order is in fact a small category.
So given some existing cascades, there are two ways to construct new cascades that are
of interest to us.
There are more, but these are the two that I want to talk about.
So if you have cascades c and d, we construct the product's cascary by taking the Cartesian
product of their object classes, and by matching up compatible pairs of morphosomes from the
original cascary.
This looks a little complicated, but basically, if you have morphosome f from a to a prime
in c, and the morphosome g from b to b prime in d, then in the product's cascary, c cross
d, we have the morphosome fg from a v to a prime b prime.
We just take pairs of objects and compatible morphosomes between them in the original
categories.
Next, given the cascary c, we construct the opposite dual-category c op by reversing the
direction of all the arrows in the category.
We note that this operation is an involution, so the dual of the dual of the category is
just the original category, because just reversing the arrows twice just gives you the arrows
back.
This leads to an interesting theorem.
The principle of duality states that every categorical definition and theorem has a dual
definition and theorem obtained by reversing the direction of all morphosomes in the category
involved.
We often prefix a dual notion with co, such as products and co-products, or domains and
co-domains.
The proof is pretty simple.
If a statement holds in the category c, then the dual statement holds in the dual category
c op, for every category is the dual of its dual, so the dual statement also holds in
all categories, as required.
We've already been using arrows to show morphosomes between objects, but we can do a lot more
with these diagrams.
If we take a selection of objects in a cascary and draw morphosomes between them, then we
can compose morphosomes by following a path through the diagram.
Because of associativity, each path corresponds to exactly one composition morphosome.
This is useful enough by itself, but certain diagrams have an additional helpful property.
A diagram is commutative, if for every pair of objects in the diagram, all roots between
them are equivalent.
For example, this diagram here is commutative if and only if h is equal to the composition
of f and g.
Now suppose we have objects a and b in the category, and morphosomes f and g is such
as this diagram commutes.
That is, f composed of g is the identity on a, and g composed of f is the identity on
b.
Then, f and g are called isomorphosomes, morphosomes with inverses, and we alternatively label
g as f inverse.
If a life morphosome between a and b exists, then we write this symbol to denote this relation.
An isomorphosome is the mathematical way of saying that we only care about some specific
property of an object.
You've probably heard that a topologist cannot tell a difference between the coffee mug
and the donut.
This is because in top, these two objects have the same number of holes, a topological
variant that does matter in top, and they can be bi-continuously and bijectively deformed
into each other.
So the right and wrong thing.
One central theme of category theory is the idea of mapping between objects.
Whenever we encounter a new type of mathematical object, we should always ask if there is
a sensible notion of a map between them.
But of course, categories are also mathematical objects we can ask this question on.
Let's see in the eb categories.
A functor, f, consists of two parts.
I'm mapping on objects, and I'm mapping on morphosomes.
The object mapping just maps objects x in c to an object fx in d, nothing unusual here.
But the morphosome mapping maps morphosomes in c to corresponding morphosomes in d, as
in the morphosome has the corresponding objects not at the end, as defined by the object mapping.
But this mapping is subject to constraints.
Basically, functors don't have to send identities to identities, and they have to
preserve compositions.
As a consequence of this, functors preserve the connectivity of diagrams.
We're not going to cover the proof here, because it is just a bit of algebra, and it's chasing
symbols around, but it follows quickly from the second constraint.
In particular, functors preserve isomorphism diagrams, so if f is an isomorphism in c,
then f of f is an isomorphism in d.
This definition is rather long, so more concisely, we can say that each pair of objects a and
b induces a mapping that respects the structure of the categories.
So, functors act as morphosomes between categories.
They compose by composing these in d's functions, and identities are just the identity functors
from a category to itself.
This suggests the construction of a category where objects are categories, and morphosomes
are functors, and indeed we have cat, the category of categories.
We also have little cat, the category of small categories.
This is a sub-category of capital cats, but we're not going to go into that at the moment,
because there's way too much to cover.
Now, for a small bit of terminology, the functors we've been considering so
far are sometimes called covariant functors.
A covariant functor from c to d is just as shown here.
This is in contrast to a contravariant functor.
A contravariant functor from c to d is just a functor from c op to d.
So we would say that the upper functor is a covariant functor from c to d, while the
lower functor is a contravariant functor from c to d.
This is mostly just a terminology slash notation thing.
Like if we're working with a named category like set, it might make more sense to say
that a functor is covariant than to start writing set op everywhere.
We'll give a few specific examples of functors now.
Forgetful functor does nothing to the objects and morphisms in the category, apart from
forgetting some additional structure that mattered in the original category.
For instance, we have the forgetful functor from group to set.
Every object between group is a group, that is, a set to g with some extra structure in
the form of a binary operation and a set of axioms.
The forgetful functor u forgets this extra structure on objects, mapping groups to their
underlying sets, sets which are just objects of the category set.
Similarly, morphisms in groups are group from morphisms, which are just set functions that
happen to respect this extra structure.
Forgetting that extra structure still leaves a normal set function or a morphism in set.
Forgetful functors don't have to get all the structure on their object either.
Consider a ring r.
Ring r to the underlying set s yields the forgetful functor from ring to set.
If we keep addition and the additive identity, we get a functor from ring to the category
of abelian groups.
If we forget commutativity on top, we get a functor from ring to group.
Let g dot to be a group, and it approaches the category c with the unique object x.
We will construct a covariant in the functor f from c to set.
We only have one object in c, so we choose a set s to map x to.
The ring morphism g must be mapped to a function f or g from s to s in set.
However, we still need the functor axioms to be satisfied.
There are two natural ways to do this.
We can either define the function f or g by left multiplying by g, or right multiplying
by g.
It should be clear that the two functor axioms are satisfied by either definition, so this
choice is rather arbitrary, but we'll pick the upper option here since it more closely
matches the existing notation.
We can really interpret this mapping to be a two-argument function, taking a morphism
from g and an element little s from s and returning their product.
So f is determined by the choice of a target set, s, and a function from g cross s to s.
We can then see that a covariant functor from a group to set is really just the left action
of a group on some set s, or a left g set for short.
For a contravariant functor, we just pick the other mapping, so a contravariant functor
is a right g set.
So as we said earlier, whenever we encounter a new type of mathematical object, we should
always ask if there is a sensible notion of mapping between them.
Well, functors are mathematical objects, and can we map between functors?
Yes, of course we can.
These are actually called natural transformations.
f and g each map objects and morphisms in c to objects and morphisms in d.
To define a mapping from f to g, we want to associate objects and morphisms in d mapped
by f to objects and morphisms in d mapped by g.
So first, consider the effects of f and g on a single object, x in c.
x has mapped to two objects, fx and gx in d.
Since we're trying to define a map from f to g, it would seem sensible for us to associate
these two objects together.
But since fx and gx are just objects in the category, such a relation is just a morphism
in d, so eta maps each object x to a morphism from fx to gx, called the component of eta
at x.
However, we should recall that there are possibly many morphisms in the homestead of
fx and gx, so which one should we pick?
To help us decide, consider a morphism f from a to b in c, in a left there.
The top and bottom are just the same diagrams before, they've just been skewed slightly,
so we can draw other morphisms in.
But under f and g, we have two additional morphisms, f of f and g of f.
I'm probably sure they'll fix different letters here, but we'll work with it.
So we want to relate these two morphisms under our natural transformation, since looking
for a map from f to g.
We also have two morphisms we want to assign to the components, eta a and eta b.
These morphisms we can control, these are the ones we're trying to pick.
But on the square on the right, there are two paths from f a to gb, we can either take
the upper route or the lower route.
If the components are assigned arbitrarily, these paths are not necessarily equal, and
there could be many such possible paths.
But we can use this to relate f of f and g of f by requiring that this quite commutes.
This is called the naturality requirement.
So overall, a natural transformation is just a collection of morphisms in the target category,
in next-over objects in the source category, such as this diagram commutes.
Now that we have a notion of mapping between functors, we want to compose them, so how
do they compose?
Consider the following setup.
Here, c and d are categories, f, g and h are functors, and alpha and beta are natural
transformations.
From the diagram, it would seem sensible to define the composition of alpha and beta
to be a map from f to h.
Such a composition of natural transformations is called a vertical composition.
There's also a notion of horizontal composition, but it's not super relevant to the construction
we're leading up to, so we'll leave it out.
Consider an object x in c.
Two components of alpha and beta are alpha x, from f of x to g of x, and beta x, from
g of x to h of x.
Because these are just ordinary morphisms in d, they can be composed according to regular
morphism composition rules, so we define the component of the composition of alpha and
beta at x to be this composition.
We still need to show the naturality of this new composition transformation, but that's
simple enough.
We just glue two naturality diagrams together.
Because alpha and beta are natural transformations, they individually satisfy the naturality requirement,
so each square commutes individually, and hence the diagram as a whole also commutes,
so this composition is natural as required.
Putting the components together, we get this definition of the vertical composition.
With this, it's clear that identity natural transformations leave other natural transformations
unchanged on the vertical composition, as one of the components will just be their
identity.
For any two categories, we can now define functors between them, and natural transformations
between those functors that obey the morphism axioms.
This suggests the construction of a new category.
For two fixed categories, c and d, we construct the functor category by taking objects to
be functors from c to d, morphisms to be natural transformations, composition of morphisms
to be vertical compositions of natural transformations, and identity morphisms to be identity natural
transformations.
Recall the isomorphism diagram.
Here, a and b are objects, while f is a morphism.
If we take the case of a functor category, we have this instead.
Now objects are functors, and morphisms are natural transformations.
In this case, we say that f and g are naturally isomorphic.
Because this is just an isomorphism, and in particular type of category, we reuse a notation
and we write to this.
We also say that f is isomorphic to g, naturally, and x, whenever we need to bind a variable.
Note that this is very different than these objects being isomorphic for all x.
The upper statement is a statement about the functors f and g, while the lower is a statement
about the objects in the target category.
f of x and g of x being isomorphic naturally and x is a far stronger condition than f of
x and g of x being isomorphic for all x.
It could be the case that these objects are indeed isomorphic, but there doesn't exist
a natural transformation from f to g at all.
But natural isomorphism doesn't imply that every pair of corresponding morphisms are
isomorphic as well, so this is an actual implication.
And in fact, if we're given a natural transformation from f to g, then this implication is biconditional.
Suppose we wish to study the properties of an object a in a locally small category c.
One way to do this is to look at a from all of the possible objects and examine it that way.
By looking at how a is seen from other objects, we can obtain a lot of information about a.
But thinking about the totality of maps from every other object to a is rather hard, so
let's just pick one object x and look at a from there to start with.
The relationships an object x had with a are exactly the hom set a in x and the hom set
of x and a.
Let's just consider the format for now.
As we move between the objects, we see a from different viewpoints.
If the category is locally small, then what we're really doing is assigning a set to
each object.
Sets are objects in the category of set, so we've really just defined the function from
the objects of c to the objects of set for a fixed a.
As it turns out, every morphism x to y induces the functions from the hom set of a in x to
the hom set of a in y.
So, this is just the morphism between two sets in set, and the whole thing describes
a function from the original category to set.
Let c be a locally small category and fix an object a in c.
We define the covariance hom functor from c to set, also denoted h sub a as follows.
For each object x in c, define the hom functor to map x to the set of maps from a to x.
We can interpret this as the hom functor mapping objects to how they are seen by a.
To reach morphism f from x to y in c, define the hom functor to map f to a function hom
of a in f, defined by post composition by f.
That is, we map each morphism g from x to y to the composition of g with f.
Or in the diagram, we comb the morphisms on the left through to y through f.
We can interpret this as the hom functor mapping morphisms f from x to y to how a sees the
objects y through f.
Use whichever visual you prefer, diagrammatic or symbolic.
I initially found the diagram more enlightening, but it's become less and less useful the
more I actually work with categories algebraically.
The contravariant hom functor is defined duly, mapping objects and morphisms to how they
see b rather than how they are seen by me.
We can actually prove that either one is a functor, but it is again just a bit of algebra,
and you only have to prove it one because the principal duality proves it for the other.
For each object a, we've now assigned the functor h sub a from c to set, encapsulating
how the category is seen from a.
But since it's the same category being seen from all objects, it wouldn't be unusual
for us to expect that this assignment has some internal consistency.
As it turns out, each morphism f from a to b induces a natural transformation h sub
f from h sub b to h sub a.
Note the change in direction here.
A collection of covariant functors come together to define a contravariant natural transformation.
And if we started with a contravariant hom functor, they would all come together to
define a covariant natural transformation.
We'll show how this works now.
Consider the components of this natural transformation at an object x.
Recall that this map just sends morphisms from b to x to form morphism a to x.
We can alternatively interpret these hom sets as contravariant hom functors with a fixed
x.
But we've already seen this before, or at least the dual of it.
This is given exactly by pre-composition by f.
And in fact, there's no reason why we should have to fix upon arguments at the time.
An notation here suggests that we may take both inputs of the hom functor to be variable.
Let f from x to y and h from b to a be morphisms and consider this diagram.
Consider a morphism g from a to x on the top left here.
We'll follow how it's mapped under the square along the two different paths in a technique
called diagram chasing.
Along the upper path, we pre-compose with h before post-composing the result with f.
Along the lower path, we post-compose with f before pre-composing the result with h.
But by associativity of morphism in composition, we see that these paths are equal and the
diagram can meet for any point of regime.
This suggests that the double-argument hom functor is a bi-functor from c cross c to
set, covariant in the first argument and contravariant in the second.
A functor, f from c to set, is representable if it is naturally isomorphic to the hom functor
for at least one choice of a in c.
The object a, along with the natural transformation, are then a representation of f.
It turns out that a is determined uniquely up to isomorphism in c.
The name is also rather suggestive of the fact that a in some way determines f, which
is a corollary of a lemma we'll prove later.
We give a few examples of representable functors.
The identity functor from set to set is represented by the singleton set 1.
Any function from the singleton set to a set x just amounts to picking elements from the
set x, so there are exactly as many functions 1 to x as there are elements of x, which is
exactly the statement of the isomorphism.
Naturality follows directly from the associativity of function composition.
The forgetful functor from group to set is also representable.
Actually, forgetful functors in general are representable, but we'll just look at the
forgetful functor for groups for now.
We're looking for a group that satisfies this condition.
Take a moment to see if you can spot it.
Org.
The additive group of integers is what we're looking for.
Let g be a group, and let phi be the group homomorphism from z to g.
Because group homomorphisms send identities to identities, 0 is always sent to the identity
in g.
This is also why we can't pick the singleton set to represent this functor.
This requirement stops us from mapping the whole element to the singleton set of the
whole group.
However, we're free to pick the image of 1 in z, which also determines the rest of
the map due to the cyclic nature of z.
This suggests that we send each homomorphism to a determining value at 1, and this mapping
defines the components of the natural transformation in alpha.
This app is also invited by sending each element g to a map that sends integers to that power
of g.
Naturality is shown by chasing f around this diagram.
I'm not going to talk through this one, it's just evaluating and simplifying the functions
at each step.
Pause if you want to read it through and make sure you've understood what each function
is.
We can also represent the functor that sends a ring to a set of units.
We can't pick the integers here, because ring homomorphisms require us to send both
identities to their corresponding identities, so 0 sends the additive identity and 1 sends
the multiplicative identity, so we don't have any variables free.
This just gives us a point.
If we try a polynomial ring, then z is fixed by the homomorphism requirements, and the
free variable is free to pick out points in r, so we just get all of r back.
To ensure we only pick elements which have inverses, we use the ring of Lorentz polynomials,
which you might recognize from Lorentz series in complex analysis.
We give an example of a non-representable functor next.
Consider the functor from set to set, to find an object from having each set x to the co-product
of x with itself.
You might also call the co-product of this joint union in set theory.
If you're unfamiliar with it, it's just the union operation, but we keep track of
which set every element came from.
Now, suppose there exists a set y, such that the homset of y and x is isomorphic to the
co-product of x with itself.
If we take the case where x is the singleton set, then the homset of y and x is just the
singleton set.
But the co-product of the singleton set with itself is the set with two elements, so these
sets are not isomorphic, and hence know why it exists.
One almost universal problem in mathematics is to figure out how to describe and classify
objects.
While a mathematical axiomatic definition of an object certainly distinguishes that
object away from many others, this doesn't tell us much about the collection of all these
objects as a whole.
For example, while we can define the group in four short axioms, classifying all groups
is a much harder problem.
In fact, we've only done it for finite groups, and even then, it took thousands of phages,
tens of thousands even.
For a simpler example, imagine we're tasked with classifying the real numbers.
The real number line is a classification of all real numbers by embedding them in some
space that has more properties than the real numbers had alone.
For instance, the number line is a smooth manifold, a metric space, a topological space, etc.
While we can define real numbers with dedicated cuts or with completeness axioms, this kind
of embedding gives a lot of additional and useful information that isn't visible from
the axioms alone.
Importantly, there's a bijection between points in the number line and the real numbers,
but we also have the new information in that the real numbers near each other on the number
line are similar in magnitude.
We can try to extend this idea of a classifying space through other kinds of objects, where
nearby objects have more similar properties than distant objects.
Unfortunately, this classifying space for any kind of useful object is often completely
unrecognizable and has very few properties we can let for its short advantage.
However, we can attempt to examine these spaces by looking at the maps from other spaces to
them.
Let 1 be the set with one element.
Any map from 1 to r effectively amounts to picking an element from r, so there is a bijection
between the functors 1 to r and the points in r, and the fact that there's nothing specific
about r here.
But generally, the maps from the 1 point space 1 to any space x amounts to picking points
from x.
If x is a metric or topological space, then this is a set equipped with an extra structure
in the form of a metric of topology.
By examining the maps from 1 to x, we can recover half of that information.
Just by looking at x from the simplest possible non-trivial space, we recover all of the points
of that space.
Now, what if we look at maps from a more complicated space?
A map from the interval 0, 1 to x is just a parameterization of a curve in x, so the
maps 0, 1 to x recovers the path in x, while a map from the circle s1 to x is just a topological
loop, so the maps s1 to x recover all the loops on x.
The point is, we get more and more information about any space x by examining how it appears
from other probing spaces, but exactly how much information can we recover?
Is it always possible to obtain as much data from looking at maps as we would from just
analyzing the space itself?
After all, we have no reason to expect that the entire structure of the space is always
captured by these maps, except, it always is, and that is the unidol emma, or at least
part of it.
The remarkable thing about the unidol emma is that it's a proof at a level of categories,
so it holds for any category of spaces, topological, metric, smooth manifolds, sheaves, algebraic
varieties, anything.
We begin the lemma by asking what information representables recover.
Let c be a locally small cascary and fix A and C, inducing the covariant functor h sub
a.
For each covariant functor f, from c to set, what are the natural transformations h sub
a to f, in the functor cascary, c set?
We should unwrap what this is saying in exact terms.
Firstly, there is an isomorphism of sets, so there is a bijective function between the
hom set for the hom functor at a and f, and f of a.
There are exactly as many natural transformations from h sub a to f as there are elements of
f of a.
Secondly, the isomorphism is said to be natural in a and f, suggesting that both sides are
functorial in both a and f.
Precisely, we can regard the left and right sides of this expression as bifunctors, from
the product of the functor category of c and set, crossed with c to set, and the yo-in
in the lemma states that these functors are naturally isomorphic.
In particular, the functor on the right is also known as the evaluation functor, since
it takes the functor and an object's input, and evaluates the functor at that object.
I'm not going to cover the proof of naturality here, since there's a lot of algebra, but
we'll just show the isomorphism for now.
Let a to be a natural transformation from h sub a to f, and consider its naturality
diagram.
We'll trace the identity on a around the diagram.
Along the upper path, we apply the components of a to the identity, then apply f of f to
the whole thing.
Along the lower path, we apply h sub a of f to the identity, which is, if you recall,
post-composition by f.
So we can pose the identity on a with f, which just gives f.
Then we map it to the component of a to add b.
But since a to be a natural transformation, these paths should be equal since the diagram
meets.
If we look at the function on the left, the input is always a to add a applied to the
identity on a.
This implies that any natural transformation from h sub a to f is completely determined
by its value at the identity at a.
This naturally induces a function mapping a to the object that determines its value,
and moreover, this function is a bijection, as every such value in f of a conversely extends
to a unique natural transformation.
And this establishes the required isomorphism sense.
Naturality is left as an exercise.
At the beginning of this session, we asked how much information we get when we examine
how an object looks more at the possible viewpoints.
This corollary states that we recover the object up to isomorphism.
That means that the maps into, or the maps out of an object, contain exactly as much
information as the objects itself, with regard to the category.
And I think that is a good place to stop.
