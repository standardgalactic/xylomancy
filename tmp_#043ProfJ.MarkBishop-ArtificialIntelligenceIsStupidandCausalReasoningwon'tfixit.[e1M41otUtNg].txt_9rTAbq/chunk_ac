case when the levers there were in A, or maybe it's at B, and the rest thing follows through,
but we always need that mapping. We've always got to do these mappings between the physics of
what's going on and the computational state that we're instantiating. So now we've got this machine
without the brake, it just goes to A, B, C, A, B, C, A, B, C, A, B, C. And that's
interesting enough. If you're interested in inputless finite state automaton, they're not
very exciting machines, all they can do is go through a cyclic series of states forever and
unbranching series of state transitions. What is interesting is that the appendix to Hilary
Putnam's representation of reality is a little known proof. This shows how we can, effectively,
how we can map the operation of any inputless finite state automaton onto a large digital counter.
Putnam goes further and shows how we can map it onto any open physical system. An open physical
system being a physical system that's open to gravitational waves and all the rest of it,
electromagnetic spectrum impinging onto it. But for simplicity, let's just consider the,
without lots of generality, let's just imagine we can map the operation of any inputless FSA onto a
bloody large digital counter. How does Putnam do that? Well, let's take Turing's machine.
It just says, if the computation is in state A, I'm going to map that to the digital counter state
zero, zero, zero. If it's in state B, I'll map that to counter state one. If it's in state,
computational state C, I'll map that to counter state two. And then the A again will go to three,
the B again will go to four, and the C again will go to five. And then we get over any finite time
period, we can replicate the state transitions of our digital discrete state machine by the numbers
we're psyching through on our digital counter. And again, you might answer, so what? That doesn't
seem particularly threatening result for computationalism at first sight, because real
computations, much more complex devices than inputless finite state automata.
Well, in a paper called, Does a Rock Interment Every Inputless Finite State Automata, David
Chalmers responds to this argument in an interesting way. And he says that, yeah, I'll
concede, if you like, that we can implement really trivial machines like inputless finite
state automata using Putnam's mapping. But when we want to look at machines with input,
this breaks down because we get a combinatorial explosion of states that we need. And
Chalmers introduces a very neat construction called the combinatorial state automata,
which we can implement using Putnam's mapping, but an exponential increase the number of states
that we need. And the combinatorial state automata is sensitive to initial conditions.
And so could be genuinely said, if we could implement it, we have an infinite state to
implement it, could generally be said to be implementing a computation with input. But at
the cost of every time step of the computational, you need an exponent, your number of states
grows exponentially. And Chalmers makes the point that after a very short number of states,
we'll run out of the number of states needed is bigger than the number of atoms in the known
universe. And hence Putnam's mapping must fail. And that's kind of why I entered the debate,
because I made an incredibly trivial, all the hard work had been done long before I came
to play with this game, so to speak. But my only trivial modification to Putnam's argument that
to me makes it robust, the charm, as it says, is to say this, well, if we look at any real machine
of which it's claimed has genuine mental states, conscious states, as it interacts with the world.
And this, this intuition was brought real for me. Because again, some people dispute the fact
that there are people who believe that there are serious scientists who believe in the machine
consciousness program. There definitely are. And I used to, my head of department is at
Reading Cybernetics with one of those people, a guy called Kevin Warwick. And we at Reading
and built these little simple robots that moved around a corral controlled by a neural network.
And Kevin said, well, these got roughly the same number of neurons as a slug. And it's pure
human bias, if you say a slug has conscious experience, and these robots didn't. And I
thought that was a ludicrous claim. And that inspired me to move and develop this dancing
with Pixie's Reductio. So to come back to the case, I said, right, then, Kevin, if you say
your robot as it moves around the corral over a finite time window, T1 to TK, experience is
something that it is like to be a robot bundling around a corral, not bumping into things. I don't
know what that is, but that's just imagine it has some conscious experience. What I, what I can do
is log all the inputs to that machine. And then I'll play them back to them. So I now lifted
the robot out the corral, I've disconnected all its sensors, if you like, and actuators,
and I'm just injecting into the robot the states, it would have got where it was in
around the corral on itself. Test again, does the machine still have conscious state? Well,
yeah, of course it has. It's reading the numbers from a latch. The data was originally taken from
an ATD converter for argument sake. We're now plonking that data in there from a data rejection
system. But the computer still has the phenomenal states. So Kevin Warwick asserted. And that,
unfortunately, then did the problem that he was going to encounter, because if that was the case,
all that were really interesting, we can take, we can collapse the exponentially growing number
of states that Chalmers showed we would have. If you actually want to implement fully all aspects
of a computation using Puttner's mapping, if we just try to look at the particular computational
trace, we just need the inputs to that machine that pertain to any over time as the machine,
it is a little thing. And then we can remove all the counterfactual states. And once we've
done that, we've got a linear series of state transitions that we can reliably map
using Puttner's mapping. And hence, if it's the case that Kevin Warwick's little robot was conscious,
then so must our account to be conscious. And then after Puttner, any open physical system.
So that in a nutshell is the DWP reductio. It's interesting that in all these seminal debates
to me about AI, about penrose, about cell and about my own small contribution,
there's a lot of confusion, people can very easily misinterpret what's being said. A lot of people
got hung up about does a rock genuinely implement a computation? And I think to me, Chalmers
completely proved that it does not. No problem with that. Can we make a rock with a suitable
mapping implement an arbitrary series of state transitions? Yes, I think we can. And I think
we can make any count to do that. And because we always use a mapping, whatever system we use,
I don't think I'm doing anything. There's no sleight of hand involved here. But all computational
systems involve an observer relative mapping somewhere along the line to get them to work,
whether it's only assigning a logical two to five volts and a logical false to not volts.
So I don't think the use of a mapping is something that, you know, and there's no sleight of hand
involved in that. Given that I confused an arbitrary complex series of state transitions.
So then the question is, if you're a physicalist and I approach this problem originally as someone
who, you know, I like to think of myself as if I'm not a mysterious, I don't want to appeal to
some supernatural forces to bring forth my consciousness. And at one point in time, it was
the case that well, if you don't believe in functionalism or computationalism, then you've
got to believe in supernatural effects. Well, that is no longer the case. Cognitive science has
moved on a lot since the 1960s. There's an awful lot of new tools in town. And these are really
exciting tools in my view. And you highlighted a few in the introduction, Tim, but things like
the embodied, inactive, embedded and ecological approaches can go a long way to answering or
giving his insights into these questions without having to bring forth particularly
supernatural notions. So I'm going to put that to one side. We don't no longer face the choice of
either accept computationalism or accept mysterious. Putnam's rock. I mean, there's a lot of interesting
responses to it. But I want to point out a couple of things or maybe just ask you about a couple
of things. So one thing is that first, I think what your goal is and correct me if I'm wrong
with the pixie dancing with pixies argument is to say simply that if we accept, say,
Turing complete computation, or even in this case, finite state machines, but I think we can probably
go one step further, if we accept that effectively computable systems can implement consciousness,
then we also have to accept panpsychism, correct? That's that's what I tried to show,
because once you have a system that you that you play, like my boss Kevin said, that machine is
conscious. I can look at what happens as that machine interacts with the world. I log all the
inputs to it, I can trace the flow of the execution flow of that of the machine code that
control the robot. And then I can implement an arbitrary series of state transitions that would
do exactly that with an appropriate mapping with a digital mere digital counter. So if that machine
is conscious, then my digital counter would push this mapping must be conscious. Right. So that's
the position I arrived at. Now, when chatting to David Chalmers about this, he said, Oh, no, no, no,
you've gone off the road, because we need the full potential of the computation to be there
for functionalism to hold. Now, this is quite a mysterious view. In fact, it was so mysterious
that when he first said it, he had to repeat it about three times, because I'm not the quickest
to uptake. And I found it so bloody bizarre what he was saying. But when I did unpick what he was
saying, for Chalmers, you actually need, once you effectively slice off the potential counterfactual
actions by saying, Well, I know the input at this point in time, I know the input at that,
I'm going to replace the counterfactuals in my program by direct go to statements, if you like,
or just just omit snip them from the from the program. To me, that couldn't possibly affect
the phenomenal state of the system, because really, what he's saying that non entered branches of a
computer program, right, have a causal effect on the phenomenal state of your machine. But the bizarre
thing is, that's what David's saying. That's it. You've got to have the potential for counterfactuals
there. Otherwise, we don't have the machine genuinely instantiating phenomenal states.
So if we just if we just assume in argument, though, that people don't or that we don't accept
panpsychism, okay, and that these arguments prove that if we accept computationalism, it implies,
you know, panpsychism, okay, we also have mathematical results that say,
let's say, Turing computation or effective computation encompasses all computation,
like there is no, you know, there is no other kind of computation, unless there's hyper computation,
right. And so I think what we're saying, I believe and correct me if I'm wrong, but
I believe what we're saying is that there exists hyper computation, and that human minds are
performing hyper computation. So just just take this back to the rock for a second. One issue
with that mapping, right, is that rocks actually have physical states that may be real numbers,
you know, they may have values that in and of themselves are not computable. You know, they
can have positions and states and quantum states that they have values that are essentially defined
by an infinite precision real number and therefore are not even accessible to computability to start
with, like even describably, right. So are we saying because I'm always looking for where
consciousness is hiding, if you will, like, are we saying that it's hiding in sort of real valued
states, you know, maybe quantum states like Penrose would say, perhaps a microtubules or
something like that, you know, is that is that a form of hyper computation? And is that where
our consciousness derives from? Where do we draw the dividing line? Because that's something that's
like I've read quite a few of your papers in preparation as you do when you're going to speak
with someone. And this dividing line where we go from, you know, computational and essentially
impossibly into like impossible to achieve intelligence or understanding or any measure
thereof, to the point where we have an intelligent system that can understand its world and sort of
redefine itself and redefine its world. That distinction is not terribly clear. And as we
dive into this question, I want to drive towards where this distinction lies, if this distinction
exists. Well, to pick up on Keith's point, first, I think I'm neutral. I mean, Penrose has given
the positive thesis as well as a negative one. So famously in the emperor's new mind, he gives
he gives his first version of a goodly the in argument that reports to show that mathematical
insights non computable. And then says, Well, this suggests to me that non computability lies at the
heart of what it is to be human. And then with Stuart Hamroff, they outline a positive thesis
which which reports to show that non computability can arise in the brain through the orchestrated
collapse quantum collapse in the microtubule skeleton of a brain neurons. I'm perhaps neutral
on this. I know that when Penrose held the psych symposium on his work in 1995, and it attracted
a lot of responses well over 20. And I don't think any of his logical work was seriously
brought into question. So the that is is interpreted, even though that was actually
a naive interpretation of girdle compared to the work that he put out in shadows of the
man is a much more nuanced approach to the argument in my opinion. But nonetheless,
it wasn't seriously criticised nearly everybody criticised his positive thesis.
So I get Penrose is a clever guy. It seems interesting. I'm not going to hang Michael
is onto that flag particular if it works great. I've been more drawn to modern approaches to
cognitive science, which look at the end. And there isn't unfortunately a very quick
six page paper that can can lead people gently into this. But there are four schools that all
this work really started out with the work of a roboticist from MIT called Ronnie Brooks,
who wrote a classical paper, which you guess you guys are familiar with called intelligence
without representation, which basically looked at you instead of trying to when I did robotics,
old fashioned old school representational robotics as a young past grad. A lot of our work was
trying to build take data from sensors and build rich internal models of an out there world.
And I remember we spent all our budget on buying the biggest fattest computers we could possibly
afford at the time and strapping them onto these poor little autonomous vehicles, and they were
laden down with computer power, and they moved absolutely tragically slowly. We're going back
in the early 90s now, but they were they were pathetically slow things, you know, really
embarrassingly bad. Because a lot of their work was trying to build up these models,
looking at what's on a bill models of them. Now, I know that these days we can do that kind of
thing bloody quickly, but back in the day, you couldn't and Brooks thought, well, do we need
to do it? And in that paper, he argued that we didn't why build the representation, we can use
the world as its own representation. And in the sense that sort of paved the way for thinkers like
Francisco Varela, then in a book called The Unbodied Mind, with Evan Thompson and Eleanor
Roche, to start thinking about different ways of doing cognitive science. And The Unbodied Mind
is a mind blowing book. It's quite a, it throws your whole view in the same, you know,
in an analogous way to go to Leche-Bart can be quite mind blowing as a young kid. This is mind
blowing as well. But in a kind of a weird way, because it actually questions the existence of
a fixed pre given out there world. And that was quite a shock to me when I first came across
these ideas, not being a trained continental philosopher. My first mode of engagement was
with Varela, who incidentally started out as a theoretical biologist, and then
someone very active in the a life community. So I think his initial work has also been from
a science perspective, but he engaged quite deeply with with the European philosophy, which
at that point in my life, I was sort of ignorant of. And so this led to a development of alternative
schools of what cognition is all about. And the inactive school is one that I'm interested in.
And it says that, you know, effectively, we can look at one sort of
in itself is these days split into numerous sub approaches. One of these from developed by a
guy called Kevin O'Regan and Alvin Airee argue that visual consciousness is something that we
do. So they're moving away from the idea that vision is like interpreting like your eye getting a
scene from the world on your brain having some little like cinema, which you're then interpreting
what all these little bits do, they make the case that vision is more akin to an activity is what
we do. It's it's guided sensory motion exploration of the world. Varela itself was particularly
interested in a broad being in ideas of autonomy, how can how can how can things become meaningful?
There's all these very complicated debates that I think to try and come back to your question,
Keith, and your question, Alex, you need to touch on, but it's really challenging to
touch on them in an intelligible way in a relatively short period of time.
You would at least agree, though, that, you know, your contribution, penrose, etc. points very
strongly that there's something embodied, there's something physical that we haven't quite figured
out yet. Maybe it's microtubules, maybe it's something else, you're agnostic to that. But
there's something physical that allows my intuition is to do with autonomy. And this is why we bring
that idea of ultra poesis in that Tim mentioned at the beginning, ultra poesis is again, in the 70s,
Umberto Acherana, the Chilean side musicians Umberto Acherana and Francisco Varela came up with
a theoretical device for delineating life from non life. Because astonishingly, this has been a
