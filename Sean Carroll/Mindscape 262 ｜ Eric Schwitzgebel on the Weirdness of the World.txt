Hello everyone and welcome to the Mindscape Podcast.
I'm your host, Sean Carroll.
If any of you out there own a copy
of my book, Something Deeply Hidden,
you can go to the copyright page,
the page right after the title page
where there's the copyright information, et cetera,
printed in the United States of America or whatever.
There is a little notation on that page
that gives the version number.
And the version number is not your copy of the book,
personally, all of you and your friends and I
and everyone else that we know has the same version number.
And the version number is 756 trillion, 132 billion,
390 million, 815,553.
If you know the story about what that version number is,
when I wrote the book, I generated a quantum random number
between one and a quadrillion, an integer.
And that's what this version number is.
If you believe or if you for the moment imagine
that the world is described by the many worlds
interpretation of quantum mechanics,
which I explain and defend in the book,
then there are different branches of the wave function
with almost exactly the same book written in them,
but different version numbers.
Every different integer of that size
is represented somewhere on the branches
of the wave function of the universe,
somewhere it's all zeros or all threes or whatever.
And there's gotta be some comment in that version
of the book.
Well, wow, I guess we got really unlucky about that.
But this idea, this little joke that we sneaked
into the book was supposed to be a way
of really making you face up to the claims involved
in the many worlds formulation of quantum mechanics.
And those claims I am very quick to admit are weird.
They are bizarre.
The implications of the many worlds interpretation
of quantum mechanics are very, very far away
from our intuitive everyday experience of the world.
And some people will say, you know what?
They're too far away.
I'm just not gonna go there.
I do not believe there are a quadrillion
different versions of something deeply hidden out there
in some quantum multiverse
with different version numbers in them.
So what are we to do about that objection?
That this idea that many worlds interpretation
of quantum mechanics is just too weird
because quantum mechanics is not the only place
where this issue arises.
There are other attempts to make sense of the world.
To in other words, understand it even better than we do
that like it or not lead us to some place
that seems bizarre and weird to us.
That is the theme of Eric Schwitzgabel's new book.
Eric is a philosopher at University of California Riverside
and he has a new book that is going to come out tomorrow
by the day that this podcast gets released.
And it is literally called The Weirdness of the World.
And in this book, he basically faces up to the fact
that some of our best attempts to make sense of the world
end up looking pretty weird.
In fact, he argues that in some cases
they're going to have to look pretty weird.
There is no version of the correct theory
that doesn't look weird to us.
Now, weird is an interesting thing.
Weird in his definition of it
is a little bit different from bizarre.
He defines bizarre to mean contrary to our common sense
and weird is a little bit stronger than that.
It's contrary to our common sense
in kind of an irrevocable way.
It's not gonna go away just because we understand it better.
We're gonna have to buy into it.
So he talks about not only quantum mechanics
but consciousness is a big theme.
All the different versions of consciousness theory,
just like all the different versions
of the foundations of quantum mechanics,
Eric will argue, involve a certain degree of weirdness.
And there's other weird things that may just be false
like maybe we live in a simulation
or maybe we're brain in a vat or whatever.
Maybe those you can dismiss
but what about when you can't dismiss it?
What do you do when you need to balance different levels
of weirdness of different kinds of theories?
Should we just ignore the weird possibilities?
Should we give substantial credence to them?
Should we be more cautious
when all the options on the table are pretty weird?
So I like it as a work of philosophy
that faces up to the real challenges
that come along with taking seriously
our best ways of understanding the world.
So over the course of all our different podcasts here,
we've gone to some pretty weird places.
We might as well celebrate it.
Let's go.
["The World's Best"]
["The World's Best"]
Eric Schwoodscape, welcome to the Mindscape podcast.
Thanks for having me.
So you've written a book about the weirdness of the world
which is just a great provocative title
that I'm sure will give us a lot to talk about.
But before we do that,
I have to bring up a couple things
that you've also been involved with
that are really interesting, but not on that topic.
But I have to get them out of the way a little bit.
One is virtual Dan Dennett.
You know, we had Dan Dennett as a previous Mindscape guest.
I think that's his claim to fame these days.
But those are before the days
when we had large language models
and could just program up a Dan Dennett to interview.
So you did that and did a little experiment.
So tell us about that.
Yeah, we sure did.
We did this, I should say,
this is collaborative with Anna Strosser
and my son, David Schwoodscape.
And Matthew Crosby was a collaborator earlier on,
but he had to leave to work for DeepMind.
That happens, yeah.
So he couldn't publish something
using open AI technology.
I'm sure he's handsomely compensated for his problems.
He was involved early on
and actually did some of the fine-tuning.
So people know chat GPT,
probably most of your listeners know,
or if it's a large language model,
it can produce texts.
It's very human-like.
A precursor to that,
that came out, I think, in 2020 was GPT-3.
And one of the things that you could do with GPT-3
was you could fine-tune it on a corpus of text.
So it's basically,
it consumes a large portions of the internet.
And from this, it can predict the next word
when you input likely text.
So when you fine-tune it,
what you do is you add some more corpus
and then it readjusts its weights
so that its outputs look like a compromise
between what it is in its original state
and the corpus that you've input, you fine-tuned it on.
So what we did was we took GPT-3
and we fine-tuned it on the corpus of Dan Dennett,
about two million words.
Most of his, I don't know how many books he has,
in the teens, in articles,
we just pumped them into GPT.
And then what we did was we asked
the actual Dan Dennett 10 philosophical questions
and we asked our fine-tuned model, we called DigiDan,
the same 10 questions.
We did it four times.
We got four answers from each of the DigiDans.
We didn't do any cherry picking of those answers
for quality.
We did make sure that they were sufficient length.
So we excluded short answers.
We wanted length similar to Dennett's own answers.
And then what we did was we took experts in Dennett's work
and we said, hey, could you guess
which is Dennett's real answer
and which has come from the model?
So chance would have been 20%.
The experts got it about 50%, right?
So they did better than chance,
but still half the time,
they chose the model's answer over Dennett's answers.
And on two of the questions,
the plurality of experts actually chose
one of the model's answers over Dennett's answer.
And in one of the questions, Dennett said,
you know what, I kind of see why the experts
chose that answer over my own answer.
If I'd thought about it more,
I should have said something different.
So arguably on one question,
the model actually I performed Dan himself.
So anyway, that was our experiment.
We wrote it up, we published it, and it was a lot of fun.
And when you did it, it was only a short while ago,
but probably it was much more surprising at the time.
It wasn't quite as public,
the whole excitement these days about large language models.
That's right, we did it.
We actually ran the experiment before chat GPT was released.
And so people were getting the wind
about the power of GPT-3,
but it wasn't quite the phenomenon
that it has since become.
And when you just, as a technical matter,
when you download this corpus,
does that mean you had to have electronic copies
of all of Dan's writings?
Did he help you with that?
Or did you just pirate a book or get a Kindle edition?
He helped us with this,
and he collaborated with us on the project throughout.
And Anna Strosser did a huge amount of work
converting these old PDFs and junky files
into clean text that could be uploaded into the model.
But you've written things.
You have a blog.
Have you been tempted to do this for yourself too?
That save you time?
Yes, actually the first thing we did
was we uploaded my blog into this.
So this didn't become a publication,
but we uploaded my blog into GPT-3,
kind of lower power version of it,
actually not the Da Vinci model,
but the Curia model,
which is a slightly lower powered version.
And then we had it produce blog posts in the style.
And so readers can go if they want,
look on my blog, The Splintered Mind,
and they can see the GPT-generated blog posts,
which were actually pretty interesting.
I mean, I don't, I think I write blog posts better,
but it was kind of cool.
And at the time that we did this,
it was not generally well known
that GPT could create well-structured answers
over long strings of text.
I mean, if you're thinking it essentially
does next word prediction.
So you would kind of think it would lose the thread
of ideas over time and wouldn't be able
to create a well-structured argument
that runs for paragraphs.
Anyway, that's kind of what we thought,
but it was surprising.
One of the blog posts was, I think,
not a convincing argument,
but at least it had a kind of philosophical
argumentative structure over the course
of several paragraphs,
which we found really interesting
and surprising given the basic structure of these models.
Clearly, GPT does have some memory
of what it's recently said, right?
It's not literally going from one word to another.
Right, it's got a window of, I forget how,
something like a thousand tokens,
and a token's like three quarters of a word,
something in that ballpark.
So yes.
So did you give it topics for those blog posts,
or did you just say, write another blog post
that would fit in here?
We gave it titles.
Okay.
And then it wrote the post given the title, yeah.
This is very scary.
Do you think that the world's gonna change dramatically
because of this technology?
Yes.
Yeah, okay.
It's hard to know exactly how it's gonna change.
Hard to know how, right, yeah, okay.
But for sure, it's gonna change.
So that was one thing I wanted to get out of the way.
The other one, which I only found
when I saw your Wikipedia page,
is that you were one of the people involved
in asking the questions.
Are ethicists, especially ethical,
or does studying moral philosophy
make you a more moral person?
Is that right?
Yeah, arguably I'm the world's foremost expert
on the moral behavior of ethics professors.
And what are your conclusions about this?
Well, I've done a fair number of empirical studies on this,
and what I've found over and over again,
almost without exception,
is that they behave about the same
as comparison groups of other professors.
Though sometimes we do,
the comparison group would be other philosophers
who don't specialize in ethics.
Sometimes the comparison group is other professors
at the same university in different departments.
And there've been a couple studies
where we found a little bit worse
or a little bit better behavior in some respects
for ethicists, but generally speaking,
it's a big null result.
Well, okay.
You just find they behave the same as other people,
which I think is kind of interesting
because you might have thought
that ethicists would reflect on ethics
and then behave differently as a result of their reflections.
And mostly that seems not to be the case.
One particularly interesting example of this
is with respect to vegetarianism
because ethicists on some issues
will embrace more demanding moral standards.
So for example, ethicists are much more likely
than professors in departments other than philosophy,
or they were in 2009 when we collected these data
to say that it's bad to eat meat,
bad to eat the meat of mammals in particular
is what we asked about.
And yet in our research,
we found them just as likely to report
having eaten meat at their previous evening meal.
Now, is that correlated?
I mean, are the people who say it is bad to eat meat
also eating the meat?
Right, it had the correlation that you would think.
So the people who, we gave them a nine point scale
from very morally bad to very morally good.
And the people who ticked one or two very morally bad
or one tick toward good from that,
few of them reported having eaten meat
at their previous evening meal.
But the ones who ticked three or four on our nine point scale,
which was a lot of ethicists,
seemed basically just as likely
to have reported eating meat.
So there was a kind of correlation
between the strength of the opinion
and the self-reported eating,
but there wasn't the group difference that we expected.
So ethicists as a group said the majority,
60% said it was morally bad,
but I don't know, 30 some percent of them reported
having done it at their previous evening meal,
nonetheless compared to, I think it was 38% of ethicists
and 37% of ethicists and 38% of respondents overall.
So if this is a surprising result,
which I'll entertain the possibility that it is,
what's your theoretical understanding of what's going on?
Is it just that ethicists are better at arguing about ethics,
but not actually better at being ethical?
Is there a different kind of study
that would make you better at ethics?
Is it like coaching versus playing a sport?
Yeah, I think coaching versus playing
is an interesting comparison.
We don't hire ethicists to be saints,
just like we don't hire coaches to be football stars.
And yet you would expect if you took a coach
and a random member of the population
of the same age and gender
and put them on a football field together,
you would expect the coach would still outperform,
even if the coach is not a superstar, right?
So I think that's an interesting comparison
that reveals partly why you might think
it's still a little surprising,
even if we don't hold ethicists to saint-like standards.
I mean, in the vegetarianism results, again,
I think that strikes people as somewhat surprising.
So one of the things that I draw from this
is it fits with a view I have about moral psychology.
I suspect that real answer is complex and multi-causal.
But one of the things I think it fits pretty well with
is the idea that people in general
aim to be morally mediocre.
Okay.
So my inclination is to think,
and this is grounded both in personal experience
and in reading social and moral psychology,
that people don't generally aim to be good or bad
by absolute standards.
Instead, they aim to be about as morally good
as their peers.
They don't wanna make the sacrifices
that would be involved in being very morally better.
But they also don't wanna be the worst in the bunch.
Interesting.
So people aim for peer-relative moral standards.
So if you think about that from the point of view
of thinking philosophically about ethics,
maybe what you do when you think about ethics
is you discover moral truths,
like maybe you discover it's bad to eat the meat of mammals.
But if you're aiming just for peer-relative goodness,
your peers are still eating meat.
So what happens is your opinion
about your peer's moral behavior
and your own moral behavior goes down,
but your behavior doesn't change.
That's actually very nicely consonant with other podcasts
I've done recently about other aspects of things
like psychology or even epistemology,
having much more of a social slant than we would expect.
Ryan Lowry explained to us how our sense of selves
serves mostly as social function.
Hugo Mercier explained how our use of reasons
serves largely as social function.
And you're saying that there's a very big social function
that is served by our ethical practice at any rate.
Yeah, right, absolutely.
Social animals, there we are.
But I guess this does segue even more smoothly
than I thought it would into the weirdness of the world
because when you say the world is weird
and now we're gonna get into the topic of your book,
immediately part of me wants to say, come on,
the world can't be weird, it's the world.
What we're seeing is a mismatch
between our expectations and the world
and maybe those can be colored somehow.
So what does the title of your book mean?
Right, so yeah, you're right,
it's not that the world is intrinsically weird,
I'm not sure what that would mean.
The idea of weirdness or bizarreness,
which is a closely related idea in my book,
involves violating our expectations or our standards
or our sense of what's normal or violating a common sense.
So when I say that the world is weird,
I mean something like our common sense
understandings of how the world is
are gonna be sharply violated by how the world actually is.
That's the bizarreness element.
And then there's also an element which I call dubiety,
which is that, and all of our answers to this are dubious.
It's not like, oh, well, it violates common sense,
but we perfectly well understand it.
It's also, and dimension of weirdness
is that it kind of exceeds our ability to fully comprehend.
Right, so I think the example you gave in the book
is special relativity, which tells us various things
that happen at the speed of light
might seem bizarre to us, it's anti-common sensical,
but it's not weird in the same sense,
we can fully understand it once we learn what's going on.
Correct, so special relativity is a nice example
of something that's highly bizarre,
it violates common sense, but it's not dubious.
So the full weirdness thesis also involves
this dubiety claim, yeah.
Yeah, you use the word dubiety in your book
much more often than I've ever seen it used before.
So just to let people know, it's the existence of,
or I guess the claim that you should be dubious
about something.
Right, that doubt is justified.
Doubt is justified, good.
The name, the URL of my personal website
is proposterousuniverse.com for exactly the same reason.
It came out of thinking about naturalness and cosmology
and the cosmological constant
and the fact that the universe is surprising to us.
And it's funny because I get critics,
the usual crackpot on the street
with opinions about cosmology saying,
oh, Sean Carroll thinks universe is preposterous,
he doesn't realize that it's just our ideas that are wrong.
But I'm trying to say like, no, that's the point.
I don't think the universe is making a mistake.
It's definitely we are making a mistake,
that's the whole message that is trying to get across.
Exactly, and I like the word preposterous too.
I was flirting with just borrowing that word from you,
but I decided I liked weirdness a little bit better.
Weirdness works, especially weirdness of the world,
the alliteration, et cetera.
Okay, so let's take the universe's point of view here.
Why is it our fault that the universe looks weird to us?
Is there something about us that is,
despite the fact that we're part of the world
that kind of doesn't quite match on
to what we see out there in principle?
Right, well, I'm inclined to think
that our theories and our common sense
well, especially our common sense, let's start with that.
Our common sense is trained upon,
built upon a very limited range of experiences.
Yeah.
Right, so with respect to big picture cosmology,
it's relatively low energy, middle-sized,
slow moving stuff on Earth.
And that's what we're good at.
That's what we evolved to be good at.
That's what the social pressures
learning environment makes us good at.
You take something at a very different scale,
much larger, much smaller, much more energetic.
And those aren't the kinds of things
that there's any particularly good evolutionary
or developmental or social reason to think
we would have well-tuned common sense judgments about.
So in other words, the way that I've said similar things
in some cases, we only experience a tiny fraction
of what the world is.
And but we make efforts to experience more and more of it.
And guess what?
It looks different and surprising to us.
Yes, I completely agree with that.
And I think the same is true for our understanding
of consciousness, although less obviously so, right?
So the thesis of the weirdness of the world
is partly about large big picture cosmological issues,
but it's also equally or even more about consciousness.
So again, with respect to issues of consciousness,
we're familiar with the human case
and with certain familiar vertebrates we like.
And that's about what we know about consciousness.
And we have not had experience, for example,
with sophisticated AI systems.
Yeah.
So we shouldn't expect particularly
to have well-tuned common sensical intuitions
about such things.
Good.
And so in some sense, I don't wanna put words in your mouth,
but it seems to me that the motto of your book should be
that you're asking us to be courageous to say,
we should expect that as we learn more and more
about the world, we'll find that what we're learning
seems weird to us and we need to develop tools
and techniques to deal with that and handle it.
Yeah, absolutely.
And yeah, I guess that's in a sense courageous,
although I'm not sure that's the word I would use.
I like the word wonderful instead.
Okay.
Because it's got this, it's got two,
the idea of wonderful, it's got two dimensions to it, right?
So it's got the root sense of wonder, right?
That we live in a world that promotes wonder in us
and wonderful, of course, is also something like
a synonym for good, right?
So I think that's a good thing about the world
that it's gonna defies our understanding.
So you have lessons and nostrums that we should get
from contemplating the weirdness of the world,
but I thought that maybe we could just go through
some examples, really think about them in depth
and that will help us extract what these lessons are.
And as you said, consciousness is a big one,
but I first wanted to just talk about the existence
of the external world, you know,
these radically skeptical scenarios.
Like you talk a lot about, are we sure that we're awake?
For example, so give us the general lay of the land here.
Like how do you think about these skeptical possibilities
and what are your favorite ones?
Right, so you have a few different chapters
where I tangle with these skeptical possibilities
in different ways.
The dream argument, of course, is a famous one.
That's the one that you started with,
but I'm also interested in the simulation hypothesis,
the idea that we might be living in a simulation,
the Boltzmann brain idea, which you, of course,
talked about in your work very wonderfully,
and just the idea that even the idea
that the universe might consist wholly
of my own mind and nothing else.
All right, so I talk about all of those possibilities
in the book, but we could start with the dream one,
which is maybe the most familiar one.
Sure.
So this goes back in philosophy all the way,
at least to the ancient Chinese philosopher Zhuangze,
although, of course, Descartes makes a famous use of it.
The idea is, how do you know, if you do know,
that you're not currently dreaming right now?
And normally we think we feel pretty confident
that we're awake, at least if you ask a waking person,
if they're confident they're awake,
they'll tend to say yes.
Yeah.
But what justifies that?
And I think there are a few ways it could be justified.
I think there are some empirical features of dreams
that make them different from waking life.
So for example, I think of waking sensory experience
as pretty richly detailed and pretty stable,
whereas the experiences we have in dreams, arguably,
are less detailed, kind of sketchier,
more image-like, less stable.
Do you know this claim that in dream,
there's a claim that I think actually has some backing,
but I'm not sure how right it is,
that you can't read text in dreams.
The text does not look like text.
It looks like that sort of bad AI text,
that sort of like letter-like
without actually having any meaning.
Yes, that is sometimes called a dream sign, right?
These are hypothesized tests
for whether you're dreaming or not.
So look at text and see if it's stable and if you can read it.
And some people think of that as for themselves
a good dream sign.
But of course, there are also dream reports
in which people report reading stable text.
So it's not universally accepted.
All right, good.
So, right, so I think that if we,
if we accept this fact about the stability of text
as maybe at least in the majority of dreams,
you can't have a stable text,
that creates some evidence that I'm not dreaming right now.
But a lot of dream researchers,
including for example, Jennifer Vint,
who I think is really amazingly knowledgeable
about this kind of stuff,
think that we do often in dreams
have stable experiences that are a lot like waking life,
maybe even experientially indistinguishable
from waking life,
even boring mundane experiences
like that of listening to a podcast.
That's a very exciting experience, Eric.
And so if we think that there are some dreams like this
or if we invest some credence in a theory of dreaming
according to which there are either often
or at least sometimes experiences like I'm having right now
or like your listeners or you are having right now in dreams,
then it becomes kind of less experientially obvious.
Okay, I can't now be sure that I'm not dreaming
based on what seems to be this stable experience
that I'm having right now of seeming to be awake.
And of course, lots of people, including me
and probably most of your listeners
have had false awakening experiences
where you kind of seem to wake up and think,
oh, I just had a dream, now I'm awake, right?
And then you wake up again, right?
So there are reasons, I think,
not to be perfectly certain
that you are not dreaming right now.
Is it also worth contemplating a kind of inception scenario
where we're all dreaming,
there's a more awake version of us
that dreams like our existence,
you know, pretty detailed, we can read text, et cetera,
and then we dream that we're dreaming
in this fuzzier way, right?
I think that's possible,
but I wanna draw distinction between
what I think of as grounded and ungrounded skepticism.
So ungrounded skepticism says,
well, I could be a brain in a vat
and then I wouldn't be able to tell the difference,
so can I really rule that out, right?
An ungrounded dream skepticism could be like,
oh, well, maybe we're in an inception scenario, right?
Grounded skepticism starts
with our ordinary background assumptions
and says, looking at these assumptions,
there's some positive reason
to give some credence to skeptical doubt, right?
So there's no real positive reason to think
that you're a brain in a vat
to assign that any more
than the most trivial likelihood, right?
There's no positive reason to think
we're in an inception scenario,
but there is positive reason to think
that this experience might be a dream experience
once we start thinking about the nature of dream experiences
and weather experiences like this,
at least maybe sometimes occur in dreams,
at least according to some theories
that might be true, right?
So I prefer to focus on these grounded kind
of sources of skepticism.
So I think it's not just, I mean, one of the critics,
one of the critiques that philosophers sometimes give
with skepticism is you could cook up anything.
There's no reason for us to take it seriously.
Whereas I think with dream skepticism,
given the fact that we dream every night,
given that theories of dreams,
at least some mainstream theories of dreams postulate
that we have experiences like this in our sleep,
that creates grounds for doubt.
It's not completely just cooked up out of nothing.
Maybe you can add to that the idea
that at least most of the time
while we're dreaming, we don't think of ourselves as dreaming.
Right, most of the time.
Of course, there are some so-called lucid dreams
and it is the case that if you can
get yourself in the habit of thinking, am I awake?
Yeah.
So much that that thought starts to come to you
while you're actually dreaming,
then that's one way to discover that you're dreaming
and how it starts to have lucid dreams.
I'm very bad at remembering.
But even in the dream, sometimes people will say,
am I dreaming?
And then decide, no, I'm not dreaming,
even though they really are.
That's just what I was gonna ask,
because I was just gonna say,
I don't remember my own dreams very well at all,
but I don't have any memory of ever being in a dream
saying, I wonder if I'm in a dream and then going,
nope, I don't think I am.
But you're saying other people have reported that experience.
Yes, that's definitely not an uncommon experience.
All right, all right.
Now you say you're increasing my dreams.
It could be the case that the majority of times
when people are dreaming and think to themselves explicitly,
am I dreaming?
They come to realize they are.
But it's not clear that that's the majority.
And even if it is, it's not an overwhelming majority.
Yeah, okay, okay, good.
Then let's just go through some of the other famous ones,
because you draw on a very interesting distinction
between grounded and ungrounded skeptical scenarios.
What are some of the other skeptical scenarios
you would classify as grounded,
in other words, worthy of our attention?
So I find the simulation hypothesis pretty interesting.
So this is the idea that we might be artificial intelligences
living inside a simulated reality,
kind of like the matrix.
Except in the matrix, they're really biological bodies,
but you might, you could have a matrix type scenario
where the confused entities are AI systems, right?
Or you could imagine the video game The Sims
with these artificial simulated people
going around these environments,
except the Sims are really conscious.
All right, those are a couple of ways of thinking
about the simulation hypothesis, right?
So Nick Bostrom has a famous argument
that gives us some grounds for thinking
it's at least possible that we are Sims, right?
So the idea here would be that it's not ridiculous to think
that consciousness could arise
in artificially intelligent computational systems, right?
Philosophers have disputed that.
John Searle, who was actually one of my dissertation advisors
is one of the most famous skeptics about that,
but there's, it's certainly no consensus that it's impossible.
So if we accept, give at least some credence
to the possibility that artificially intelligent beings
could arise on computers,
then it seems possible that such beings could exist
in simulated artificial environments
that they take to be their own,
the base level of reality, as Bostrom puts it.
Some of them might even think they're living in Earth
on the 21st century.
And then the question arises, okay,
how many such beings are there?
One possibility would be, look,
they're not ever gonna be beings like this out there, right?
The civilization will not get that far enough.
Maybe it's really expensive to make such things
and no one would bother.
Or maybe there'd be some ethical regulations,
like you don't wanna create real,
create really conscious entities inside your computer
who think they're living in reality, right?
But on the other hand, it also seems like it's possible
that there would be many such beings, right?
Just like we run computer games like the Sims right now
and we run scientific simulations,
it could be the case that there are lots of games
or scientific projects that involve
real conscious beings inside them
who think they're living in the base level of reality.
If the universe contains many such beings,
then it seems not totally implausible
to think we might be among them.
So there are various reasons to think
we're probably not them, right?
Every step of this argument admits of doubt.
Yeah.
But, and you can stack those doubts on top of each other
and it seems like, okay, probably not, right?
But again, it's like with the dream case,
it doesn't seem like we should be absolutely certain
that we're not Sims.
Right.
So yeah, I guess it could be.
So I find that possibility interesting.
And then I guess to turn this into a skeptical scenario,
so one of the things that David Chalmers
has particularly emphasized in talking about this is,
he says, well, look, if you're living in a simulation,
but it's large and stable,
then that's not really a skeptical scenario at all.
He says, because you have a long past,
you're gonna have a long future,
all the people you know, really exist.
And, you know, there might be say a coffee mug
and it might be fundamentally made out of computational bits,
but, you know, that's enough.
It's still gonna be there.
It's gonna react the way that you want.
So it really is kind of a coffee mug.
So basically, most of your ordinary beliefs
would end up being true.
So to turn this into a skeptical simulation scenario,
what we have to do is think about,
what's the possibility that if we're living in a Sim,
it's a small or unstable one?
And there, I guess I'm inclined to disagree with Chalmers.
And I'm inclined to think that if we are in a Sim,
there's a decent chance that it's a small or unstable one.
So if we think about the simulations we run,
they tend to be small and unstable.
If we think about the question of resources, right?
And it probably would take a lot of resources
to run a whole galaxy from the Big Bang
through now and on into the future.
So what scientist is really gonna wanna do that?
Maybe all they're interested in is human cognition, right?
So just run a short, you know,
a few people having a discussion on a podcast, right?
Or something like that.
So I think conditional upon thinking we're living in a Sim,
we should assign a substantial portion of that credence.
Maybe 50%, maybe 90%, maybe 10% to,
it's being a smaller unstable simulation, right?
And in that case, then that in my mind counts
as a radically skeptical scenario
because you might be radically wrong.
But maybe this whole simulation
was created only 10 minutes ago.
Or maybe, you know, there's no one outside of your room.
It's just you listening to a podcast
or just the two of us having a conversation.
And beyond the walls of our rooms, nothing exists.
Those would be various ways of it's being smaller and stable.
So as a professional philosopher, of course,
you know that the idea of these skeptical scenarios
goes back to antiquity, not just Zhuangzi,
but the ancient Greeks thought about this.
So we've been worried for millennia now
that reality is not anything like what we think it is.
Absolutely.
I love the ancient skeptics.
So what are some of your favorite ones?
Well, Zhuangzi is probably my favorite philosopher.
But sexist empiric is also really wonderful.
And they did not know about the simulation argument.
Right, they didn't know about the simulation argument.
So that opens up the possibility
that there are some grounds for doubt
that future philosophers and physicists will think of
that didn't even occur to us.
And maybe we should have some degree of skepticism
reserved for that.
Right, I call this wildcard skepticism.
The idea that I should have a certain amount of doubt
about my ordinary assumptions about the world
just on the basis of the fact
that there's some skeptical possibility
that I'm not even capable of considering.
Right, okay, good.
So there are other skeptical scenarios,
but we have the general feeling
between living in a simulation, we're just dreaming.
What do we do about it?
Do we just ignore those possibilities
because they're too weird?
Do we reserve a little bit of our credences to say,
who knows, maybe tomorrow I'll change my mind
and think this is right.
Yeah, I think we reserve a little bit of our credence.
So the way that I think about it
in terms of numerical credence is that
I think it's rational to assign about a 0.1 to 1% credence
to some radically skeptical scenario
or other being correct.
You know, that's rough and fuzzy, right?
It's somewhere between just being completely confident
they're false and being kind of radically uncertain.
So 99.9% world's basically just how we think it is, right?
Setting aside the kind of cosmological,
the big picture cosmological stuff, right?
But kind of the ordinary Earth world of middle-sized,
dry goods at slow speeds is more or less how we think.
99.9% of our credence maybe should go to that,
but save a little bit of your credence space,
so to speak, for these radically skeptical possibilities.
And then I think that having that little bit of space
there can have some influence on your choices
and your behavior.
Actually, I do wanna get to exactly that issue,
but I realize there's a hanging thread
that we should deal with which is
there's another kind of way
in which the world could be very different
than what we think it is,
which is just there is a lower microscopic level
beneath our manifest image kind of world, right?
So you're not counting,
we are not talking about something like,
oh, there's a whole new theory
where everything is little strings
or wave functions or whatever like,
that doesn't count because in those scenarios,
the macroscopic world is still the macroscopic world
and obeys the rules, right?
Exactly, right.
So I don't count that as a radically skeptical scenario
of the relevant,
because there still would be our everyday beliefs
would still mostly be true, right?
It would be true that earth has existed
for billions of years and it would be true
that there's a coffee mug here and that sort of stuff
and the sun will rise tomorrow, so to speak.
Good, okay, good.
So then we can go back to that 1% skepticism
that you're advocating.
I mean, one question is just,
where did that number come from?
You're saying we should attach a 10 to the minus two,
10 to the minus three credence
to just being completely wrong.
I absolutely agree that we should attach some credence
to any crazy idea you have.
I'm a disbeliever that you should attach zero credence
to almost anything, but why not tend to the minus 10?
Why something as big as 10 to the minus two or three?
I don't have a rigorous argument for that,
but let me just do it for say the dream scenario, right?
So let's say we invest a 20% credence in the theory,
which some major dream researchers accept
that we commonly have experiences
like we're currently having in our dreams.
Let's say we get 20% credence to that
and 80% credence to now dreams
are basically just always sketchy.
Then conditional on that, we say,
okay, how often do I have experiences
relevantly like this in dreams?
Well, maybe this is not the kind of thing
that I would tend to dream about very much, right?
But again, if we ordinarily have kind of sensory,
ordinary kind of sensory experiences of mundane things,
it seems like this is the kind of thing that we should have.
So maybe I should assign a 2%,
maybe 2% of the time I'm having experiences like this
is actually in sleep,
or I should invest 2% of my credence to the idea
that I have experiences like this in my sleep.
Now, once I've attached a 2% credence to the idea
that I have experiences like this commonly in my sleep,
it's hard for me to see on the basis of that
how you would then go, okay,
so I now only have a one in 10 billion credence
that this is a dream, right?
It seems like you can't knock too many orders
of magnitude down off that 2% with kind of,
I'm not sure what the epistemic,
what the grounds would be for that kind of decrement.
I think it's a big philosophical problem
that I don't know whether you know,
if anyone sort of specializes in this particular question,
but what do we do with issues or questions or scenarios
where the credence that it'll happen is incredibly tiny,
but the consequences of it happening are incredibly large.
And it seems, maybe AI destroying the world
is an example of that, or even better
because people think that AI destroying the world
might be 10%, but the large Hadron Collider
turning on in a black hole eating up the world.
And someone says, well,
it's less than a one in 10 billion chance.
And someone else says, but it destroys the world,
that should still count.
How do we reason about those cases?
One in 10 billion times 10 billion people, so.
That's why I chose the number, right.
One expected murder as soon as you turn it on.
But even the number one in the 10 billion,
I mean, if someone said,
oh no, it's really only one in 10 million
or it's one in 10 trillion,
probably I couldn't give a principled argument
in any direction.
So I don't know how to deal with that.
You talk about those kinds of magnitudes,
sometimes it's hard to get.
You lose your sense of magnitude once you get over,
I don't know, a trillion or something like that.
So do philosophers have a toolkit
for dealing with these weird numbers?
No.
That's my impression.
It's becoming, it's an interesting issue
that's been starting to get attention
in the philosophical literature.
You know, there's this idea
that's sometimes called Nicolossian discounting,
which is the thought that once something
has a low enough chance
or you give a low enough credence to it,
you just ignore it completely.
Yeah, yeah.
So that is one approach.
What was that called?
And I, Nicolossian discounting
after someone named Nicholas,
but I've forgotten which Nicholas it is.
So, right, so for example,
in the weirdness of the world,
I suggest that once you give something 10
to the negative 30 credence,
you kind of just forget about it.
And this helps solve certain kinds of puzzles
and paradoxes in decision theory.
But there are also arguments against this.
So there's been back and forth about this.
This also comes up in the debate
about the ethics of longtermism.
Right, exactly.
Right, so longtermism is this idea
in the effective altruism movement
that there's a small chance
that things we do today
could have a huge impact
on a huge number of lives in the future.
Right, so for example,
if humanity goes extinct now,
then maybe there are no other entities
in our galaxy who will ever have the kinds of lives
with the kind of value that our lives have.
Right, and if we manage not to go extinct now,
then maybe we will have 10 to the 40 happy descendants
before the heat death of the universe.
Right, so even if there is a one in a quadrillion chance
that something you did now
could prevent humanity from going extinct,
given the stakes,
maybe you should invest a huge amount
in that tiny little chance.
So that's, yeah, so that's this interesting issue
that's been coming up recently with longtermism
that where this issue about how do you,
what do you do when you're trying to balance tiny credences
and giant values against each other?
Do you have a take on what we should do
or is it just an open kind of question?
So I have two takes.
One is, I'm still gonna stand by a Nicolassian discounting.
Okay.
And the other take is radical ignorance
about what actions that are currently available to us
would have good versus bad effects.
So the longtermists will typically say or assume
that human extinction is likely to have a bad effect
instead of a good effect on future history.
I don't think that that's necessarily true.
So for example, maybe humanity,
because we are so technological and prone to violence
is a kind of unstable species
that is more or less certain to doom itself
sometime in the next 10 to 100,000 years
we're gonna blow ourselves up.
But, and if we do it in a explosive way
then we ruin the earth for other future inhabitants.
But if we were to say bow out peacefully now
by deciding never to reproduce again
as anti-natalists suggest
then maybe we leave the earth in a good position
for other species, like say dolphins,
which might, who might have descendants
that are capable of lives as rich as ours
but who aren't technological, aren't gonna blow themselves up
and could endure potentially four billions of years
on the planet or maybe not billions, but maybe a billion.
If that's the case then,
and you put the numbers into the equation in a certain way
then maybe it turns out that'd be better
from a kind of long-term perspective for human beings
to peacefully extinguish ourselves now.
So I'm not saying that's true.
What I'm saying is it's very hard to know
what really, when you take a billion year time perspective
what really is kind of objectively good versus bad
among options that we have available to us now.
I think that's fair.
So radical ignorance about the very distant future.
And relatedly then, what is the actionable fact
about 1% skepticism?
Like how does it affect our daily lives
to think that maybe there's a 1% chance
or a 10th of a percent chance that I'm dreaming
or that I'm living the simulation?
Right.
Well, for example, just a fun example to start with.
I had been reading a lot about dream skepticism
and it was particularly vivid for me
this one particular winter break
when I was walking across campus
and no one else was around.
And I was thinking, I wonder if I'm dreaming.
Maybe I should try to fly
because I'm probably not dreaming.
But look, if I'm dreaming it would be so awesome to fly.
No one's around, no one's looking.
There's no cost.
It was kind of walking across campus
to the science library to get a book, right?
So why not just like try to fly to the library?
So I did try to fly to the library and I failed.
But I think that was a rational decision
because I could have been dreaming
and then it would have been awesome.
It was not so rational that you would have done it
had people been watching.
Right, so low cost things, right?
Don't try to fly when you're standing on the edge of the cliff.
Yeah, all right.
Plug that into your utility calculus
and you will not get a positive result, right?
But if they're no, if they're very small or no costs
to trying to fly, then why not
if you think this might be a dream and could fly?
Well, the other thing, of course,
as soon as you try to fly and fail
and that should reduce your credence
either that this is a dream
or that if this is a dream, you could fly.
So it might not be repeatable.
You might not just be spending all of your time trying to fly.
In my dreams, I can fly at least a little bit.
I can float.
Right.
It's just a matter of willpower.
Anyway, this is all fun, but it is 1% stuff
and a lot of the book,
I don't want to give people the wrong impression.
A lot of your book, you're talking about consciousness
which has the feature that we're all familiar with it.
I don't even want to say the feature that it exists
because people argue about that,
but at least we're all familiar with the idea.
So what is it about our attempts
to understand consciousness
that drives us into the weird zone?
Right.
So philosophers have tried over and over again
for centuries to make sense
of how consciousness fits into the world.
And one of the striking empirical facts
about the history of philosophy
is that every single attempt to make sense of this
is jaw-droppingly bizarre.
So there are, I divide attempts to deal
with the question of how consciousness fits
into the broader world into four broad categories.
One is substance dualism.
You've got an immaterial soul.
Another one is materialism.
There are no immaterial souls.
You're just a biological entity.
Another one is idealism.
This is the idea that there is no material world at all.
All that exists are minds or souls.
And then there's what I call compromise slash rejection views,
this kind of grab bag of other alternatives.
And the striking thing to me about this
is all of these alternatives end up committing
to bizarre and dubious theses of one form or another.
There's not really a live option here that is non-bizarre.
It's not always obvious.
I mean, idealism is bizarre on its face, I think.
It's contrary to common sense to think
there's no material world and it's only just minds.
Dualism and materialism are not maybe bizarre in their face,
but once you try to get into the metaphysical details
and think about how it really works,
end up pretty swiftly faced with theoretical choices
where there are gonna be bizarre consequences
for any of the choices that you make.
I think that's the important point
because people are gonna hear you say that
and there'll be both materialists and dualists
in the audience who go,
I have no trouble thinking that consciousness works that way,
but your point is that if you really take
the consequences of that view seriously,
you're led to something that we should recognize as bizarre.
Correct.
Right.
So why don't you tell us for either pick one, yeah.
So for example with dualism, right?
The dualist faces two questions
where all of the answers seem to be bizarre.
One concerns what kinds of entities have souls
and the other concerns the causal relationship
between material world and souls.
The causal question is a little more complicated.
So let me just talk about the question
of what entities have souls, right?
Basically you have four choices.
You could say only humans have souls
or you could say everything in the world has a soul.
Both of those are pretty bizarre, right?
Because if you think souls are the locus of consciousness,
then if you accept the first, like Descartes,
then you think dogs and cats aren't conscious, right?
So there's this story of Descartes taking a cat
and throwing it out of a second story window saying,
see cats, they're just machines.
I never heard that story.
He probably didn't actually do this.
Man.
But that story kind of reveals the bizarreness
of those of you that only humans have souls, right?
And of course the panpsychist view
that everything has a soul, even say a proton,
that's also pretty bizarre, right?
So then there are two other options, right?
One is that there's a sharp line somewhere, right?
So okay, dogs have souls, cats have souls, but not frogs.
Where do you draw that line, right?
Across the continuum of animals,
it seems like there's a continuum
of psychological capacities, a continuum of physiology.
It'd be weird if you said, okay,
toads of this genus have souls,
toads of this other genus do not, right?
So a sharp line is pretty implausible, at least bizarre, right?
And then that gives you maybe the fourth option,
which is having a soul is not an on or off thing.
You could have a kind of soul or a half soul, right?
So maybe like frogs have an eighth of a soul.
I mean, what would that even mean?
We normally think of souls as things
that you either have or don't have.
It seems like a discrete category
rather than a graded category, right?
So, but you gotta take one of those horns,
but they're all bizarre, right?
So that illustrates why I think, you know,
on the face of it, it seems like,
oh, having a soul is not a bizarre view, right?
But as soon as you face that choice of saying, okay,
what animals have souls,
you're forced into committing
to some drunkenly bizarre position.
And as a matter of fact,
this was a hot topic in ancient philosophy,
which animals have souls, right?
Exactly, right.
And in ancient, well, I mean,
and the modern conception of the soul
as a locus of consciousness is a little different
from an ancient philosophy.
There was the vegetative soul as well.
So there's a sense in which even plants had souls,
but they didn't think of souls
maybe as a locus of consciousness.
So actually the concept of a soul
that we find in our current philosophical
and religious tradition has a certain history.
It is not a straightforward translation
from say, ancient Greek.
So it's complicated,
but it's been an issue throughout philosophical history.
But here at the Mindscape Podcasts,
we are hardcore materialists about consciousness.
So tell us why that leads us to weirdness.
Well, one of the issues here to think about
is again, what kind of entities have experiences?
I guess there are a few different ways to angle in on this,
but one of them, and this is the theme of chapter three,
is to point out that according to a broad class
of materialist theories, it's very plausible
that the United States has a stream of conscious experience.
The United States conceived of as a concrete entity
with people as its parts,
kind of like you are a concrete entity
with cells as your parts.
So think about that concrete thing
with hundreds of billions of people.
Hundreds of millions.
Sorry, hundreds of millions.
Sorry, I misspoke there.
Don't want you misquoted, yeah.
So that entity processes a lot of information.
That entity represents itself.
That entity responds to its environment,
kind of intelligently or semi-intelligently, right?
You scan space for asteroids that might threaten Earth
and we're prepared to try to deal with them if that happens.
The United States monitors its borders.
It engages in import and export.
It sends its army out to do certain things.
It scolds people in UN Security Council meetings.
It digests bananas, mounts the bananas, right?
It exudes smoggy exhalations.
So if you take kind of standard materialist theories
of consciousness kind of out of the box
and you don't kind of fool around with them post-hoc
to try to exclude the case,
then I think it turns out that probably the United States
is gonna count as consciousness.
So there are a couple of ways to react to this.
You could say, okay, well, so much the worst for materialism.
Or you could say, okay, well, look,
we need to mess around with these theories
to exclude this bizarre possibility.
And I think that is maybe a reasonable response.
One question here is how we know
that the United States is not conscious
whether you should take that as a fixed point
in our theorizing about consciousness or not.
You know, and the third possibility is to say,
okay, well, maybe there is group consciousness.
I mean, we don't have a consciousnessometer
that we could put up against the head of the United States.
Doesn't even really have a head, right?
To determine whether it's conscious.
So that would be one area where I think
if you accept the United States is conscious,
then you end up, I take that as a pretty bizarre kind of view.
If you don't, then you adopt other theoretical commitments
and then we could get into the details of those.
But I think those other theoretical commitments
often then involve kind of further choices
among various bizarre possibilities, right?
Kind of like with the immaterial soul case, right?
As soon as you start making those commitments,
once you develop them, you see, oh boy,
this is gonna have this consequence.
This is pretty unintuitive.
Well, how certain should we be in that conclusion?
Is there a theorem that says that any version
of materialist theories of consciousness
are gonna have this property?
Or is it just, well, as far as we know,
according to our best current art,
that seems to be the case.
In other words, could the appearance of bizarreness
go away with better understanding?
Yes, it could.
And there are two separate reasons, right?
One is, kind of as you suggested, right?
Unlike what I call the dualist quadrilemma,
I don't think we have a kind of rigorous argument
that all of the choices have to be bizarre.
It's that the choices that I've seen articulated
all have bizarre consequences.
But there might be some unarticulated choice
that I haven't run across yet
that turns out to be commonsensical, right?
So I think that's possible, but empirically unlikely,
given the current state of things
and the history of philosophical discussion on this.
So it's an empirical conjecture.
The other way in which bizarreness could end up banishing
is our intuitions and our sense of commonsense could change,
right?
So the idea that the earth moved around the sun
was bizarre when Copernicus suggested it,
but we no longer seem to find that
a sharp violation of commonsense.
Commonsense has changed over time, right?
So it could be that someday we'll find it very commonsensical,
for example, that the United States is conscious.
You say, oh, yeah, of course.
Or maybe panpsychism, oh, the whole universe
is conscious, right?
The ordinary person in the street,
of course they think that, right?
Commonsense can change.
It's not a fixed point.
And we should, so it's a little bit different
than the previous examples of the skeptical scenarios,
right here, unless I'm misinterpreting,
you're not arguing that we should hold out 1% credence
for some bizarre possibilities.
You're just saying, look, all the possibilities
seem to be bizarre.
We should, I guess, learn to accept that
or fold that in, not use it as a knockout argument
against something.
We can't say, well, I can't accept that it's bizarre
because all the other options are too.
Exactly.
So this is why people like panpsychists and idealists
like my stuff on this, right?
Because part of the reason, the main reason
I think people reject panpsychism, for example,
the idea that everything in the universe
or maybe the universe as a whole is conscious,
is that it just seems so contrary to common sense.
But if I'm right, well, something contrary
to common sense is probably true, so maybe that's it.
Right, so, right.
I mean, I do think we have to rely on common sense
to some extent.
I don't think we can just toss it out the window
when we talk about issues like this.
We don't have, in my view, really any great tools
for answering these questions.
And so we have to rely on highly imperfect ones
like common sense.
But the fact that something violates common sense
is not automatically defeated.
It does seem very similar to things
that even I have said about quantum mechanics.
I presume that we're gonna put the many worlds
interpretation of quantum mechanics
into the bucket of things that you would say
are pretty bizarre.
Yes.
I remember a quote from, I think it was David Merman
who is a very famous, very great physicist
who is a epistemic person when it comes to quantum mechanics.
So he thinks the wave function is just a tool
for understanding our knowledge and prediction,
not reflecting anything real.
And he does little surveys of the field, et cetera,
and at some point comes to many worlds,
and he says, yes, you can follow the Schrodinger equation
and its consequences, and you end up with a theory,
and the price you pay is seriousness.
So basically he's just saying like,
surely you can't take that seriously, right?
And that's it, that's the entire argument.
And that feels like not a good enough argument to me
because like you said, in the context of consciousness,
for me, every version of quantum mechanics
is gonna lead us somewhere strange.
Right.
In fact, I think I like the interpretations
of quantum mechanics as an illustration
of what I call the universe of dubiety
and the universal bizarreness claim,
because I think maybe especially your listeners
will find that plausible, right?
Every viable interpretation of quantum mechanics is bizarre.
There's no like common sense way
of thinking about quantum mechanics, right?
And with apologies to the many worlds advocates, right?
They're all dubious, right?
There's at least grounds for doubting all of them.
I don't mean, when I say dubious,
I don't mean that we have to assign
a very low credence to them,
but it's reasonable to be doubtful among them,
to not feel like, ah, we're epistemically compelled
to accept many worlds over all the other interpretations.
So it's a good, interpretations of quantum mechanics
is a good example of a domain
in which I think the universal dubiety
and universal bizarreness claim is true.
And then I wanna say the same thing
about say the theories of consciousness
and theories of the fundamental structure of the cosmos.
And both of those I think are,
I mean, the interpretation of quantum mechanics
and the nature of consciousness
are both part of the fundamental structure of the cosmos.
So you kind of almost get that for free
once you get those two.
You know, I generally when pressed
put my credence in many worlds
at between 90% and 95%, you know,
depending on the time of day,
I'll give one of those two numbers.
And I did that in conversation with Philip Goff,
famous panpsychist and previous Minescape cast.
And he was just flabbergasted.
He's like, you give a 95% credence
to the many worlds interpretation of quantum mechanics.
And I'm like, dude, you're a panpsychist.
You think electrons have feelings.
Don't give me a hard time for giving large credence
to following the Schrodinger equation.
I'm sorry.
Right, totally fair.
Totally fair.
I mean, I wouldn't give many worlds
quite that high an interpretation.
I think we should be more epistemically cautious
about our favorite interpretation of quantum mechanics.
But yeah, there's room for reasonable disagreement.
I mean, I think if you're in the ballpark of 90 to 95%,
you're getting on the cusp of denying universal dubiety.
But how, what exactly counts as being dubious
is kind of a fuzzy.
You do suggest in the book that when you're in this position
where every option is bizarre,
we should give fairly large credences
to the competing possibilities
because we kind of don't have a right to be too confident.
When about preferring one bizarre alternative,
two other bizarre alternatives,
we shouldn't be too definitive.
Yes, I think that's generally true
about the kinds of questions that we're asking.
Because I think we have basically three broad types
of epistemic grounds for choosing among these theories.
One is common sense, which is that we've already talked about
is gonna be imperfect and things are gonna violate it.
These theories are gonna violate it
in one respect or another.
Another is scientific evidence.
Which is kind of just direct scientific evidence,
like measure it, right?
And on something like whether electrons have souls
or what interpretation of quantum mechanics is correct,
we can't now at least run an experiment that says,
oh yeah, this experiment proves, obviously on the face of it,
that many worlds interpretation, right?
And then the third tool we have
is something like theoretical elegance.
And again, that's kind of gonna be indecisive
because there's something elegant about panpsychism
and there's something elegant about materialism
and there's something elegant about many worlds
and there's something elegant about other approaches too.
So these are not gonna be,
they're gonna be trade-offs among these very imperfect ways
of trying to settle these questions
rather than bronze solid grounds.
Well, I wanted to ask you this specifically
in the context of quantum mechanics
because I've put it the following way sometimes.
I wanted to see how it fits in with your views.
If you take something like hidden variables,
versions of quantum mechanics,
so those listeners who don't know what I'm talking about,
we did an episode with Tim Maudlin recently
where he will explain.
And in those theories, you have particles
and they have locations
and that's what you observe when you do a measurement
and you also have a wave function.
It's the phenomenology is much closer to the world
than it is in something like many worlds
where you have this abstract wave function
and there's many copies of reality, et cetera.
I think that there's much less elegance, simplicity,
austerity to the hidden variables version as a theory.
I think this is indisputable.
I think that whether you agree
that it's the best theory or not,
you should also agree it's a clunkier theory
than many worlds.
Many worlds is very simple and austere
but I should also accept that many worlds
is much further away from our everyday life
and our experience than the hidden variables theory is.
So the question is, how do we weigh
these different considerations?
Like how it's good to have a simple theory.
It's also good to have one that tells you pretty directly
and immediately what it predicts and how to understand it.
I mean, how do we be good philosophers and scientists
when we're faced with that kind of choice?
Right, exactly.
And I'd say just leave that hanging as a question.
So I am inclined to agree.
One of the things,
I mean, you're much more expert on this than I am
but one of the things that I like about many worlds
is it is have a certain kind of simplicity to it
and these other theories all seem to involve
a certain amount of fussing around.
But right, how do you weigh that
against other aspects that reasonably draw people
to resist many worlds and prefer these other approaches?
And I don't think that there is a really good
general answer to that kind of question.
And that's one of the reasons to have kind of
non-extreme credences in these various theoretical possibilities.
Good, yeah.
And if you do have non-extreme credences,
then you can hope for progress.
You can hope to get better.
I guess maybe to wind up the conversation,
I like giving actionable advice to the people out there.
We've talked a little about how to deal
with these crazy things.
Maybe to go back to that idea that I'd never heard of
before, Nicolosi and discounting.
Maybe that's the same idea as when your credences
get small enough, I'm allowed to stop thinking about it.
Is that right?
That is basically the idea, yeah.
That's basically the idea.
I think that idea is important,
but maybe part of your message in the book
is don't be quite so quick to dismiss
the tinier, more bizarre possibilities.
I don't know, is that right?
Yes, that is one of the messages, absolutely.
I think that people will tend to have a gut reaction
against views that strike them as bizarre,
whether it's many worlds or panpsychism
or the idea that only humans have souls or whatever it is.
And I think there's reason to take
that kind of reaction seriously,
but there's also reason to not just rely on that
and to allow that some of these theories
that you might think are so bizarre as to be absurd,
maybe they're only bizarre and not actually absurd.
Well, I guess I'm caught maybe in a little bit
of hypocrisy here because that's exactly what I wanna say
to David Merman and his friends.
He will just dismiss many worlds,
even though he's a brilliant physicist,
he'll just say that that's too bizarre.
I'm just not going to accept that.
And I wanna say, no, you have to take it seriously.
But then there are other people, panpsychists,
maybe you're an example, who I will say,
no, that's too bizarre, I don't need it.
And I'm not quite sure what the principle stance is here.
Right, yeah.
Maybe you should give a little bit of your credence
based to panpsychism.
But there is, I guess, just a little,
but maybe here is the issue.
There's sort of, in principle, credence space,
and then there's what I will spend my time worrying
about credence space, right?
Like when the credence has become so small,
I'm not gonna lose sleep over it,
even if maybe someday evidence will come in
that will change my mind.
Right, yeah, that's fair.
That's fair, yeah.
Especially as an academic choice, right?
So there's also this question of,
what do you spend your academic time thinking about?
What do you invest your energy in?
And even if you were to, say, give a non-trivial,
say, 5% credence to panpsychism, that's not tiny,
but that might not be worth enough of your academic time
to build theories on.
I have spent more time than my credence would warrant
thinking about panpsychism,
so I actually take this advice very well, so.
You've given it more than it's 5% due, I think so,
I think so.
Eric Schwitz-Gable, this was, if it was all a dream,
it was a very fun dream to have,
so I appreciate, thanks very much
for being on the Mindscape podcast.
Yeah, thanks for having me, it's been fun.
Thanks, Eric.
