So, to get us started and to make sure that everyone is reasonably on the same page, what
is the process for that?
So here are some definitions that come from an article that I did with Clive Smallman,
Harry Tsukas, and Yvonne Devane in 2013.
And so, process thinking implies considering phenomena as in motion, as unfolding over
time as becoming, and process researchers seek to understand and explain the world in
terms of activity, temporality, and flow.
So basically, we're looking at things moving.
And I have two images that would reflect what I've just said here.
They have slightly different foci in terms of what we mean by process, and I'm just going
to show the two images.
And what I'm going to talk about today really kind of applies, I think, to both of them.
So the first image is this idea of process as evolving over time.
So you have a phenomenon in one state, and you're interested in looking at how that phenomenon
evolves through events, activities, and choices.
And if you are adopting a process perspective, you're going to be focusing on those events,
activities, and choices as your data, and the elements of your theory.
So not talking about dependent variables and independent variables, we're talking about
things that happen, which are quite different.
So that's the first image.
The second image, which is now on the screen, this idea of process as activity and flow,
in other words, is process as all there is.
Everything is made up of processes.
So this is a second image of process, and some people call this a strong process approach.
And I really like this quote from Russia, 1996, which kind of reflects this.
So the river is not an object, but an ever-changing flow.
Things are made up of processes.
The sun is not a thing, but a flaming fire.
Everything in nature is a matter of process.
So this second image really looks at phenomena as processes,
rather than looking at phenomena as changing over time.
So these are two different ways of looking at process.
That's just the backdrop.
I'm now going to look at the implications of this for methodology.
So if you are taking a process perspective, you want to capture that activity and flow.
And so you're going to collect data, and what are your data going to look like?
Well, typically, process data involves at least three different kinds of things.
So the first kind of thing that you might collect is observations in vivo.
So you are looking at things in real time.
You might be going to meetings, capturing conversations, capturing events,
shadowing people in the things that they do.
And so part of your data is likely to be observations.
A second way of collecting process data is to build on people's memories and interpretations.
And you do this through interviews, diaries, focus groups,
questionnaires, all kinds of ways of getting at how people understand what is happening,
what has happened, and how that evolves over time.
And the third way is to look for artifacts.
So artifacts that were created at moments in time that we can actually timestamp
so that we know when they happened.
So things like minutes of meetings.
Recently, we've been using emails, reports.
So all of these sources of data, and this presentation is not about data.
So we're not going to spend a lot of time on this.
But all of these sources of data are complementary.
They provide different strengths and weaknesses.
An interview has problems because of memories.
People don't necessarily remember.
But if you see something, you observe it, then that can compensate for that and so on.
So these three, I call them the big three, sources of data for qualitative research more
generally and for process research more particularly.
We're going to be using them if we want to develop process understandings.
And if you think about it, if you've got all of these three sources of data,
got interviews from all sorts of people, you've got observations from all sorts of events,
you've got documents and emails.
What is the result of that?
It's a S total mess.
So and it's shapeless.
You've got all these separate bits and pieces.
So the question then is, what are we going to do with that?
And so this is what this webinar is really all about, is what we do then.
And what we would like to do is move from that mess, the cloud of miscellaneous stuff
that we had collected, to something which is understandable, abstract, generalizable, a theory.
Some kind of theorizing is what we seek to do.
So the question is, how do we move from that mess to something which is much more defined,
posimonious, clear, and so on.
So here's a picture of what we're trying to do.
This is our challenge.
We have to move from something on the left that is concrete, very specific.
It's rich and it's messy, to something on the right, which is abstract and novel.
And the process for doing that, for connecting the concrete rich and messy
and the abstract and novel, has to be credible, right?
We have to couple the two so that a reader of our work, our thesis or our article,
can actually see how we've done this.
That we have started from a mess, we have ended up with a theory,
and that the coupling, the way we have joined the two is credible, but creative slightly.
Because if we're not producing anything new, then why would we be doing this?
So that's the challenge.
And starting from that point, there are several things that can go wrong.
So I'm just going to give you a little portrait of some of the things that can go wrong with that
and that we're going to try and avoid.
So the first thing that can go wrong is that we have wonderful, concrete, rich, messy data.
And beautiful abstract novel theory, but we haven't properly connected the two.
And so that is a very easy mistake to make.
We can look at our data and be inspired vaguely about some kind of theory,
but we haven't shown tight connections between the two.
So that's loose coupling.
That's blind LA-1.
I need to be careful with that.
So blind LA-2 is that we code the data to death and end up with something
which actually doesn't reach beyond the data.
It is just descriptive and dull.
And that's very easy, too.
If you, in a certain sense, if you stay too close to your data, this is what happens to you.
You don't reach beyond it.
So you just have codes, lots of codes and descriptions.
And you've got tight coupling.
Nobody is going to question whether you have accurately reflected your data,
but your data is not saying anything at this point.
It is just not descriptive.
So it doesn't work either.
And then the third one, which is a little bit more difficult to understand,
my diagram isn't great.
It's when you impose theory on your data.
So you see some theory that you think might be relevant to your case.
You draw a wonderful conceptual framework beforehand,
which is showing all the relationships that you think are going to be there before you do your study.
And then, lo and behold, when you do your study, you take the concepts that are in your conceptual framework,
impose them on your data, and you say, oh, look, I thought I would get this.
Look, I got exactly what I thought.
And what you've done there is you've squeezed the richness out of the data.
You've squeezed out everything that could give you new.
So I call this circular coupling.
And it's actually quite a common problem.
And I've seen it myself, and I got trapped in it myself.
And the reason one gets trapped in it is because thesis advisors naturally want students
to look as if they know what they're doing before they do their study.
So in their proposal, there will be this complex theoretical framework.
And that becomes the thing that drives the research.
And if it drives the research too much, you already end up with what you started with.
And that will not make a strong contribution.
So those are the different problems that might arise.
And we're now going to talk about some of the ways that we might try and do something
that would lead us to the first diagram, which is concrete, rich, messy data, abstract,
and novel theory, and credible, but creative coupling, which is kind of what we're trying to achieve.
So in order to talk about this, I'm going to rely a lot on a paper, which some of you
may have read, which is my 1999 piece, which is published in the Academy of Management Review,
which was titled, Strategies for Theorizing from Process Data.
It's now about, what, 24 years later?
Some things have changed, but I still think that those ideas have value.
And so I'm going to start from those ideas and give you some thoughts about my more recent ideas
around that and experience around trying to use those ideas.
And these are a set of ideas.
And so I'm going to put them forward.
I'm going to point you towards sources that might help you with some of these ideas about how to do this.
I'm not going to give you a complete recipe.
I'm going to give you these ideas.
And these are things you can mix and match and work with.
And we'll look on do this now.
And I'm going to let's see.
OK, so this is a list of the items that I included in the 1999 paper, which I called Strategies for Theorizing from Process Data.
And there were seven of them.
And so you can look at them and you can sort of group them into three areas.
And so the first two that you see there, I call them grounding strategies.
And they were actually about coding.
So the first one, grounded theory, is this idea that you're going to start with the data and you're going to build your theory bottom up from the data.
The second one is kind of a different way of looking at it.
Instead of building up your theory bottom up, you're going to take a priori known theoretical lenses and fit them to the data top down.
And if you do it with more than one, that enables you to see which one fits best.
So I see these two as kind of opposites of one another, theorizing from the bottom up, theorizing from the top down.
And we're going to talk about those first.
The second two I see as ways of displaying data.
So you can display data either as a story, as a narrative, you can construct a narrative from your data, or you can try to draw them.
Using visual mapping.
So I see those two as kind of opposites of one another as well.
And then the last three are all about comparing data.
And for me, comparing is really the essence of, it's the thing that drives, for me at least drives theorizing.
When you're comparing two things, you immediately ask yourself, why are they different?
Why are they similar?
What is it that explains that?
So as soon as you start to compare, it really is a great stimulus for theorizing.
And I introduce here three different ways to compare.
So comparing cases, comparing this notion of temporal decomposition or temporal bracketing, which is comparing phases.
And the last one, modifying.
And so that's the kind of portrait of these seven approaches that you can use to data.
And, of course, they are not, you don't pick one and then use it.
All right, you do all of these things when you are trying to theorize from process data.
And it's a very iterative process and you move between them.
So I have this in my next slide, I have this diagram, which expresses that.
So on the left, you have what I call the grounding strategies.
In the middle, you have the organizing strategies, which are useful for displaying.
And on the right, you have the comparing strategies.
And you can do them in any order.
I put the diagram from left to right because I think there's a sort of a progression from coding to displaying to comparing,
which I'm going to put coding, displaying, and comparing.
I think there's a progression, but that doesn't mean you might start at a different place.
OK, so let's start with coding.
And so I'm going to talk a little bit about coding process data and then we'll stop and take some questions and have some conversations.
And then I'll talk about the other two after that.
So let's start with coding.
So there are these two strategies that I mentioned, grounded theory and alternate templates.
The grounded theory idea is from the bottom up.
And alternate templates is taking the top down where theory is at top and data at the bottom.
OK, so let's look at grounded theory first.
So grounded theory means building from the bottom up, so you have no a priori framework.
And there is some classic authors that have talked about that, so Corbin and Strauss, Charmas.
And more recently, Denny Joyer and colleagues and Mae Hamilton and Kevin Corley have this organizational research methods piece,
which explains how to do grounded theory and it's become really dominant in the field of quality to research.
And I'm an editor at the Academy of Management Journal and I see that, you know, one, I am editor for all the qualitative papers.
And I would say that one paper out of two has one of Denny Joyer's diagrams.
And I just want to say before I start talking about that, that that is not absolutely required to publish a paper.
But it is a very common approach and it has all kinds of benefits.
And grounded theory, the tools like Atlas, TI and Pivo, Max QDA, etc.
are great for managing your coding.
They don't do it for you, but they manage it.
I haven't yet got into chat GPT.
And maybe there are some opportunities there to see what chat GPT can do for you in terms of coding.
That's the kind of life on the front there.
And I think there are people who have already started looking at that.
I'm not looking at that here.
So that might be an issue that we might want to get to.
So I'm going to talk a little bit about the Joyer method.
For those of you who haven't seen it before so that we can see what this method is about.
So a really great example of the Joyer method is the 2004 paper by Corleone Joyer on identity ambiguity in administrative science quarterly.
And I use this as an exemplar of the type of bottom-up coding that dominates a lot of process research as well as any other qualitative research.
And so this method involves three types of artifacts.
And the most famous one is this one, right?
And this is a coding approach, which is so elegant.
What you can see here on the left, the first order concepts, is how a researcher takes their original data and looks at the data in vivo and codes it into the first category.
So there may be lots and lots of first order codes.
You're going to have hundreds of them.
You start doing that.
You start coding bottom-up in vivo.
You end up with far too many codes, but that's okay because then you group them.
And so you come to the second order things.
And so they look at the similarities and differences.
You put them together, you group them, and then you do that a third time and you can do it a fourth time.
You can do this any number of times you like.
And what you have on the right then is some key concepts that are going to become the essence of your theory.
And so the brilliance of this is it shows you exactly how you move, in theory, from your original messy concrete data to some abstract concepts.
And it shows the pathway.
So that's the first artifact.
And unfortunately, a lot of researchers kind of stop there.
They show you the data structure and that's it.
A second artifact is actually showing the link between the two.
So here this is in the paper, just an example.
They've got their concepts and here you've got quotes that reflect those concepts.
So that's the second artifact.
And the third artifact is taking the second order and themes and the third order, the overarching dimensions and creating a process model with them.
So they didn't see the flow between all of the concepts in the paper.
And there you can see how Corley and Joya have brilliantly started with a database, just a mess.
They had observations, they had documents, they had interviews, and they generated these concepts.
And here is the theoretical model at the end.
So this looks wonderful, right?
What you don't see in the paper, of course, is all of the back and forth that they must have had to do to get to the data structure in the first place.
This does not suddenly appear, right?
You need to know what you're doing.
So this is much more complicated than it looks.
So looking at this approach, it's really a brilliant approach to show in an Anna paper the rigor of your coupling between the data and the theory.
One of the things that have been said about it, and I share this concern, is sometimes if you've got these concepts, you're glossing over, for example, the conversations, the interactions, the interactional details.
You have labeled everything in terms of concepts, and you may be missing the temporality and the dynamics through this process.
So that can be a concern.
And you could code differently, though.
You could code recently in a study, instead of coding things that people said, we coded the interaction.
And so there would be different types of interactions.
So then you've got some of the dynamics included in the story.
And the other thing is, if this is entirely uninformed by any other approach, my concern is that if you're just doing bottom-up coding, just doing bottom-up coding, starting from your data, and you think that the theory is going to kind of result from that, you're going to run into blind alley, too.
And Cooley and Joya do not do that, because they are theoretically informed, that they're not starting their study from total scratch, even though the idea that grounded theory is from entirely bottom-up is not quite true.
There are always efforts to connect to existing theory, and we should never forget that.
So just doing coding is not going to get you to an interesting, or bottom-up coding, is not necessarily going to get you to an interesting process theory on its own.
And it's very iterative, and you have to keep going back and forth, and so on.
So that's the final comment there.
So here we've just so far talked about the bottom-up side.
Let's now talk about the top-down approach, which is a little bit different in terms of coding.
So we're going to look at alternate templates, which is my strategy, too.
So the idea here, when I wrote the paper in 1999, was this idea that you could fit one iA priori theory to your data.
But what's probably more interesting is trying to apply more than one, because if you do that, you will get to see your data in different ways.
You might even be able to verify which theoretical framework is more appropriate, fits better.
And doing this, coding based on any priori frame, can be very useful for doing that.
And the classic inspiration for this is a book which I recommend everybody read, which is by Graham Ellison, and it's the Essence of Decision.
And he's a political scientist, and he studied the Cuban Missile Crisis, which is an event which I'm old enough to have lived through, although I was a child in the 1960s.
When nuclear missiles were placed in Cuba and the United States had to decide what to do about it.
And what Ellison did is he got access to a huge amount of documentary data on this and analyzed it according to three different theoretical frames.
And the first theoretical frame was the rational actor model.
So according to the rational actor model, countries are rational actors.
So countries consider the alternatives they have available and pick the best one.
So the whole assumption is that the country is one actor.
The second theory they applied to that was to say, no, no, no, countries are not actors.
Countries have bureaucratic organizations that are part of them.
So, for example, the US has the Pentagon, the military that are doing one thing.
They have the Congress that is doing something else.
They have the president who is doing something else.
All of these individuals have their own routines.
All of these groups have their own routines that they know how to do.
So the military knows how to do an invasion.
They know how to do a blockade.
And if they're given the right stimulus, they will execute the bureaucratic processes that they know how to do.
And so the second explanation was really a March and Simon based bureaucratic model.
And then the third one was political.
So they were looking at individuals, what their individual interests were and how those interacted.
And they applied these three models to the same data and ended up with three different stories,
which they kind of argued in the first version of their paper, we should keep separate
because they enable us to see different things.
These things are not wrong.
They're just lenses for looking at things.
And having different lenses to look at things is insightful.
So this is this is a completely different approach because you are starting from the theory and not from the data.
This is an approach that probably, in my opinion, we don't use enough, at least.
And it's one of the reasons is it's very hard to introduce three different
theory of theoretical frames into a 40 page article.
It's not possible.
But you can do it in a thesis much more easily.
And that can be the basis for three different articles.
So that so this can be used more.
I have an example here of a single paper where they looked at three different frameworks.
And this was in organization science.
It was by two colleagues of mine in Montreal, Susanne Huvard, who's at HSC, and the point who is at McGill.
And they studied the implementation of computer systems in hospitals.
And they considered three different theoretical models for understanding that.
And the first one was that this was a problem of people.
And so that model was about how individuals cognitively related to an information system.
So if you wanted to understand if it was implemented or not, you had to see how people found it useful or not, essentially.
And it was basically a question of whether different individuals could cognitively absorb the implications of the information system.
And so in order to code for that model, they coded by individuals, right?
They had the list of individuals.
They considered the elements that are in the model.
So there were four elements in the model.
They coded them systematically and looked to see how that worked.
The second one is a political model.
And the theory behind that is that people will resist information systems that take power away from them.
And so they looked at different groups.
So they looked at doctors.
They looked at administrators and how they were reacting to the information systems over time
and considered whether this model might explain things.
And the third model is an organizational design model developed by Henry Menzberg.
And here they were trying to consider whether the organizational form was having a difference to the implementation process.
So they basically tested, and in this case, it was a test.
It was not really different lenses to enrich, to accumulate, to have three different explanations.
But they tested the value of each of these three models on the same data and came to the conclusion that in the early phase of implementation,
it was one model that dominated and another phase was the second model that dominated in the third phase.
It was a third one.
So that in the end, this enabled them to generate a really interesting theoretical framework,
which showed how the importance of different processes evolved over time.
So that's an example of how you can do that.
And before I move on from this, I wanted also to draw attention to Andy van der Ven's work.
Unfortunately, we lost Andy van der Ven last year, but he has made a fantastic contribution to process research.
And one of his papers, which I really find at the same time extremely stimulating,
but at the same time I've always questioned it a little bit, is a piece of work with Marshall Scott Poole,
where he proposed four different theoretical, possible theoretical models of process.
And in terms of thinking about alternate templates, these are really, really useful.
These are classic process theories.
And I'm just going to give you an illustration.
And I actually used this recently in a study with a colleague from University of Gothenburg.
And we were looking at migrant workplace integration in Sweden, in organizations.
They've had many, many refugees come to Sweden, and organizations and governments are struggling with how to ensure workplace integration.
It's clearly an important factor that can explain whether refugees can adapt to a society.
So van der Ven and Poole identified these four classic process models.
They called a lifecycle process, a learning process, an ecological or evolutionary process and a dialectic process.
And I have little diagrams which illustrate each so that we can just sort of see what the kinds of frameworks might be.
And these are really useful kind of heuristic ideas about how you might consider your process data.
So the first one is, it's a process that evolves over time in a predictable way.
So, you know, you're a refugee into a country, you try and get a job, you go through certain processes of development.
And at some point, you reach a level of maturity as integrating into your workplace.
So this is a very linear process model, and it assumes that there are kind of deterministic phases through which you pass.
So that's one way of looking at process.
It's probably the simplest way, and many process models, the first iteration, that's what they look like.
It's maybe not the most inspiring in terms of understanding the complexities.
So that's one type of model.
A second type of model is this idea of learning.
Van de Ven and Poole call it a teleological model.
I like to think of it as a learning model, because I think it's easier to understand, which is that you have an objective, and it's all about agency.
You have an objective, you form a plan, you try to execute it.
If you are able to execute it, so much the better you continue.
And if not, you change your plan.
So it's a circular model, really.
I think that those of Edward Deming, it's a little bit like that.
It's learning.
You plan, you do, you check, and you act, and then you plan, and you do, and you check and act.
And so, yeah, migrants who arrive in a new country are doing learning as well.
And companies who are trying to develop processes to support workplace integration are also doing learning.
And so you could apply it to different levels.
And so this is another process model that you can consider.
The ecological process model that they propose is this idea of survival of the fittest, Darwinian processes.
And so you start with variation.
So let's take innovation.
You start with many, many, many different ideas for innovation, but some of them fit better with the environment than others.
And so the ones that do get selected and the ones that don't get thrown out.
OK, here's the third one.
Unfortunately, the Darwinian selection applies equally to migrants' integration processes.
So there are selection mechanisms, which mean that not all people manage to become integrated.
And so the integration is a very selective process, in fact, when you look at it carefully.
But that is another model that can help explain what is going on.
And then finally, the dialectic process.
So the whole notion of the dialectics is two systems or two sets of objectives that are in conflict that collide.
And so the driving force of a dialectic process model is contradiction.
And contradiction generates something else.
What it will generate, you don't quite know.
And so this is the model that actually my colleague at Gothenburg, Bedran Omanovich, and I found most useful.
And so our model is more of a dialectic model.
And the idea here, we look at the sociopolitical context.
We look at tensions between management interests and migrant interests,
which generate different factors and patterns of integration.
They generate tensions.
These tensions give rise to either transformation or perhaps reproduction, depending on the power dynamics.
So a dialectic process model is very much oriented around process dynamics.
So what you see here is four kinds of a priori ways that you might think about process.
And I think that these are generative.
And the only thing I would say is I think there are not just four.
So you could apply.
There are many a priori process models out there.
Van de Ven and Poole would argue that all of these are combinations of these four.
But sometimes it's interesting to consider them on their own merits.
So I've always found actor network theory to be an interesting theory.
It's a process theory that might apply here as well.
So the basic idea is taking theories and trying them out is very generative
in terms of process theorizing is the point I make here.
The only problem, and this is if you try to impose one theory onto your data and match it,
what you're doing is you're just labeling things.
And so that's why more than one or doing top down, but also doing bottom up as well,
is much more likely to give you something that corresponds to our ideal portrait.
The danger of imposing one model is that you end up with the richness squeezed out.
Looking at several, you can tell, I mean, if you could look at my diagram,
you could see that you would get several different circles on there.
And that might on the left, on the bubble on the left.
And that might do a better job of understanding your whole process.
So, again, this is not a mechanical linear exercise,
and there's a lot of value of iterating with the ground at the bottom up coding as well.
And then that sort of raises the question, how do you do this?
Right? Because you're doing bottom up, you might be doing some top down coding as well.
And I have another example here, which kind of is really interesting.
It's a paper by Kaplan and Olikowski, where I think the reviewers of the paper
must have asked them to explain that coding process.
And so they've introduced this diagram in an appendix, which explains that coding process.
And their final model is the little diagram in the bottom right of that picture.
And what you see, all of the circles, you know, what these circles going around,
is showing how they iterated between bottom up coding of their data,
going to the literature, finding a theory that might help,
and then doing coding based on the theory that they had found,
and doing this iteratively multiple times.
And they are trying to describe here the exact process
that they went through to arrive at the particular theory they ended up with.
So this is a really nice illustration of what it really looks like,
something of what it really looks like to engage in coding of process data.
And increasingly, actually, seeing diagrams like this appear in articles,
because people are being asked to explain, well, how did you do this, actually?
How did you take theory that is out there,
combine it with the data that you have to produce something new?
And so this is the combination, I think, that is important.
So I'm going to stop here for a moment and stop here,
and see if we have some questions, so I can see at all.
Yes, thank you so much, Anne, for the presentation and for all the information.
It's been super helpful.
I have two questions.
One is a clarifying question, and then the other one is also for recommendation.
So maybe I start with the clarification question.
So you spoke about alternate templates, and it's something that I've actually
thought about quite a bit.
I'm not doing a process study or I'm not doing a study with process data,
but I do find all the strategies you've mentioned very useful.
I thought that alternate, or at least from my perception,
I feel like almost every qualitative study would, at some point in time,
come across alternate templates, because you do try a lot of different things
to see what fits your data.
So from the back of my mind, I felt like it's kind of intuitive,
but you mentioned that it's not used often.
So that made me feel like, OK, maybe I didn't understand
what you meant by alternate templates well enough.
So is it really just trying different theoretical lenses
to see which one fits your data in the analysis process,
or what you displayed where the authors, eventually, in their final output,
also explain each of these theoretical lenses and then argue for each one,
which one qualifies as alternate templates?
Yeah, so a study that would really,
I would consider to be an alternate template study,
would show the different templates in their study and say,
I looked at my data according to three different theories.
Here's what happens when you take this one.
Here's what happens when you take that one.
Here's what happens when you take the third one,
or there could be four, or there could be two.
So it provides different accounts.
So if you were going to use that in a study, it would provide different accounts.
But that doesn't mean, and I was perhaps confusing about that,
that doesn't mean that a researcher might not be doing this in the background anyway.
But when it comes to actually write the paper,
it's kind of as if all of that variety might disappear
because you have picked the one that's going to work,
you don't have room to describe all the other alternatives you look at,
so you go for one.
Yeah, so and the one is usually a combination
of both the top-down and bottom-up in practice,
because you take your model, you apply it,
and it doesn't quite work and enables you to introduce new things,
or if you're going bottom-up, you do something and you think,
oh, yes, I found this, and then you have to look in the literature.
And you see, well, the literature also found that, so is that new?
I mean, what is it I'm adding?
So it's this back and forth that's important in the doing,
but in the presenting, alternate templates is very rare.
Okay, thank you so much for clarifying.
The second question is that, like I mentioned,
I don't specifically use process data,
but I do find all your strategies quite helpful.
But I realized that in the qualitative community as well,
it's very important who you cite on what studies.
And I can imagine that citing process methods papers
in a study with variance data could be problematic,
but I still haven't quite found,
or maybe I haven't recognized other resources
which talk about similar strategies for variance data,
maybe except ground of theory and yeah, except ground of theory.
So I was wondering if you have any recommendations on,
first of all, would it be right,
or if it would be right, how to couch it in a paper
if you are borrowing from a different area of qualitative methods
for your approach?
So if I would want to say that I used alternate templates
as recommended by Anne Langley, and then I cite your paper,
but then it's not a process study that could be problematic.
So how could I couch it so that it doesn't come across as problematic?
Or if I can't do that,
then do you have any recommendations on other resources to consult?
I would not worry if you cited me for alternate templates for any study.
And in fact, when I teach qualitative methods, I use this paper.
And many of the strategies make sense for other kinds of qualitative data,
even if you're doing a variance study.
Some of them don't, quite so much.
So things like temporal bracketing, it's all about time.
So it doesn't necessarily make so much sense.
And so it depends.
When I first wrote this paper,
I was struggling with what to do with process data specifically.
And so I was looking for solutions to that.
But in terms of resources,
I mean, I could recommend a few things.
So there is a very recent issue,
special issue of organizational research methods.
I think the title is Beyond Templates.
So, but
the issue is extremely helpful in offering a range of other ways
of analyzing qualitative data.
And so it really tries to get beyond the idea that
here's a recipe that you just apply and tries to look for more complex ways.
One of the papers that I really find resonates with me.
It talks about Bricolage, which is putting things together that seem to be helpful.
And really, strategies for theorizing from process data
is actually recommending some kind of Bricolage as well.
But the Bricolage paper is particularly helpful,
I think, in terms of suggesting different ways.
And they give examples from their own research.
But every individual is putting different things together.
So it's not a recipe.
It's not a recipe, but it's a very useful citation
and helpful in justifying your approach, I think, whatever you're doing.
Thank you so much, Anne.
Ravi.
Yes, thank you.
Excellent presentation.
Very, very, very impressive.
My question is, can you elaborate a little bit on process variants?
I ask this because I think there is a missing bridge or link between
all the material that you suggested you cited to the whole body of knowledge
that's happening in operations management, where we look at process variants.
We also teach in the operations management courses,
tools and techniques, like the fishbone diagram, Ishikawa diagram and so forth,
to really understand how we can manage those processes
so that we can reduce variability to make the processes better,
more flexible, cheaper and faster.
I think that practical call for why we try to manage processes
is conspicuously missing in what you suggested.
And this is not a criticism.
I'm just trying to connect two bodies of knowledge here, what you cited
and what goes on a lot in operations management.
Thank you.
Yeah, so what I'm talking about is a researcher who is interested
in understanding process theoretically.
I'm not talking about how to analyze a specific process to improve it,
but obviously that is a complementary kind of an approach.
And some of the techniques that we might use to theorize
might also be particularly useful for improvement as well.
So things like, and I'm going to be talking about this later,
process diagrams, for example, that look at how things are working over time
and which activities are taking place.
And process diagrams can be useful to describe what is going on
and to theorize from it, but they can also be useful to pinpoint, okay,
this process is kind of not efficient.
There are ways of cutting steps that might be useless.
And there are ways also of improving steps so that there's greater consistency,
which is what you're talking about, eliminating variance.
Right? So, but I'm using the terms process and variance in a little bit of a different way
and more in terms of processes of theorizing.
But I do understand that there is also a practical application as well of these things.
Emma?
Yes, hello, Professor Langley.
My name is Anna Koudija.
First of all, thank you for the presentation.
I've been doing ethnography research projects since three years
and it's still ongoing until next year.
So it's about four years data of ethnographic observation and interview session.
There's quite a lot and messy, as you explained.
I tried already the first round data analysis using Joya method,
but I realized, as you mentioned, I'm missing the temporality
because I've been studying about project management stages and how culture
affect the project and performance on.
And so what I could get from Joya is just a kind of constructionist.
So it's like almost static in the way that it's just forming a certain theory,
but it doesn't show how dynamics in the project team evolve along the stages.
So now I've been following the one from Professor Niederman,
the socio-evolution theory, so like more like a process theory.
It looks like really like a process theory, but I believe I cannot share my screen.
But the way I did it like this, I don't know if it's correct.
So first I used the theoretical lens from the literature.
So I created a code book with my research team.
I get the codes around 50 codes or something and I did the deductive approach, top down.
And then I did another round with my team also inductive coding
so that to get some new ideas or maybe we are not in the right domain and so on.
And then at the end we kind of map the episodes like what happened in conflict,
what happened in creativity, and then we started from the project,
started the project N and we create like a couple of episodes mapping
and then we kind of show it to the front.
And I don't know if we are doing the right thing,
but at the moment this is so far the best approach that we could think of
to generate such a huge amount of data.
Otherwise, I'll be also overwhelmed with analyzing this.
If I would like to get your insight, if I'm in the right track or should I try another approach?
This sounds really good to me.
If you'd like to send me something, I'd be glad to sort of comment on it.
But it sounds like we're doing both bottom up and top down coding.
And I think that just focusing on one can be problematic.
If you just do the top down, then you don't produce anything new.
If you do the bottom up, you just kind of end up being descriptive.
So it's the combination of both which can give you that richness, I think.
So yeah, I'd be glad to look at what you're doing.
I'm happy to get your feedback on that.
Thank you so much, Professor Langley.
Okay, Yuxi.
Hi, I have a question about your strategy to alternative templates
of fit a different theoretical framework to the data.
And sometimes people from different disciplines study the same phenomenon.
So the alternative templates may come from another discipline.
For example, in addition to management, there may be economics,
there may be sociology, there may be economic geography.
I really like your picture in the beginning.
The river is not the object, but ever-changing flow, just analogy.
Like the person driving the boat is like an entrepreneur driving a business.
And the river is kind of like community institutions.
It's like economic geography, that kind of thing.
For example, the river is changing flow.
Like there are a lot of economic geographers study the community institutions,
but they are not considered a management.
So when I use alternative templates, when I incorporate those,
to let different disciplines have a conversation is answer your call of the river is not object,
but they are ever-changing flow.
That's very juicy part because my background was from economic geography.
But a lot of times people say, this is not an internship paper.
You should submit it somewhere else.
But I am targeting at management, mainstream conversation.
I want to join that debate.
I think some people say that because the entrepreneurship is changing.
Like a very long time ago, it's like Steve Jobs, a kind of entrepreneur,
but later on come to the community's level, for example,
and then come to the social level.
So what is expanding attached to the boundaries of different disciplines,
for example, economic geography.
But right now, I want to speak to the mainstream entrepreneurship literature,
or join that debate.
And I want to use the alternative template by citing the framework from different disciplines
and let that to have a conversation so that I can answer your call that the river
is not just object, but the ever-changing flow.
That's bring the community lens into the conversation.
But speak to the mainstream entrepreneur.
Can you give me some suggestions so that people will say?
I think that that sounds great.
I mean, I think that multidisciplinary research is difficult.
But if you are not just, if you are bringing in alternative templates
that are not based in management and comparing them with those that are,
I think that's extremely generative and it's likely to be well received.
In the entrepreneurship field, I know of one paper that really does a good job
of looking at alternative templates.
And that's a paper by Greg Fisher.
I think it's entrepreneurship theory and practice is the journal and it's 2012.
And it's a kind of a classic application of alternative templates approach.
So that might be something that you would want to look at.
So can you type the literature in the chat box or I follow up, give you a email?
Yeah, maybe what I will do is send a bibliography to Ibrat at the end,
if that's possible, because there are ways to distribute that too.
I think I can do that.
Yeah, okay, I will create a bibliography and send it.
Wonderful, thank you.
If anyone could type that paper in the chat box, I really very appreciate it.
Thank you.
So we have Ibrat and Melissa.
Yes.
My question is about, you talked about kind of doing bottom up and top down approach to
working with the data.
Where do you see the role of the fake description in this?
And would you say a fake description?
What is the sit in between those two polarities, so to speak?
Well, I think description for me is more of a bottom up approach.
And I'm going to be talking about narrative after, you know, next.
So I think that we can get into that.
And, you know, it's narrative is doing a fake description is something that you might do
first or something that you might do last when you have done coding.
Both is possible.
So anyway, we'll talk about that in a few minutes if that's okay.
So let's have probably best to have one last question from Melissa.
Thanks, Anne.
I'm struggling a bit because I'm looking at transformation and comparing it with
typical organizational change in that it's constant.
And so looking at a strong process theory, but at the same time, looking for those
constants that are in the river and how to sort of frame it.
So I've been trying to use different lenses like performativity and the transformation is a journey.
But I'm getting a bit stuck between, well, the right, really the right lens to sort of capture the
and make the theoretical contribution to show that this is something different if we're talking,
for example, in this case about digital transformation versus sort of status quo
organizational change.
So I'm not quite sure I have to respond to that, but I do think I've always thought of,
you know, transformational change as being okay, fine, you get you shock a system with some kind of
what, you know, one time supposedly one time initiative, but then it kind of gets itself
into woven with what is already going on in the company or the organization.
And so it becomes continuous.
And so change changes.
This is the way I think about it so that so that you have this one time transformation,
but it gets transformed, it gets changed by the continuity of ongoing change.
And so I like to have that, I like to have that kind of image where, yeah, the you do a merger,
and then you don't do a merger and then everything is, you know, then you have a result,
you do a merger and then all of the things that were going on anyway in the enterprise
kind of change what that means.
So I think that that can be done and I think that you can trace, you can trace, you know,
the moment of change and then trace through the ripples that it creates so that it may
create big ripples and small ripples.
And I don't know, I would tend to look at some kind of temporal bracketing where I would see
waves occurring.
We're trying to understand capacity for the transformation.
And the issue is that capacity seems to be a boundary.
It is or it isn't.
And yet are there certain constituent components that enable this transformation to be possible?
And is it the right theoretical lens to use performativity if we're trying to
to sort of talk about, and maybe boundary condition is not even the right term to use
anymore, but you know, the approach was to use necessary condition analysis and the data to
try to find, you know, that doesn't even make sense.
I'm not sure.
I mean, why don't you send me an email?
I have a little problem with the notion of capacity because it's kind of static, right?
It's a thing.
It conveys the idea of something that's fixed, a capacity or a capability,
because this is something which changes over time.
The capacity, you know, you learn, so you have great capacity.
And so everything is evolving.
And so the notions like capacity feel a bit uncomfortable with.
You could when you could talk about capacity work, which is working on the capacity.
And so then you get to doing again, but that's super helpful.
Thank you so much.
All right.
Okay, so I think we'll we'll move on a little bit because we don't have that much time.
So I'm going to try and perhaps accelerate a little bit here.
And I have to share my screen again, right?
Okay.
Okay, so we're now moving on to the middle column here, which is displaying process data.
And so I'm going to talk about two strategies that I mentioned in my paper,
which are narrative and visual mapping.
And so there's two different ways of displaying.
The first one is displaying your data in terms of words.
And the second one is in terms of drawing, in terms of pictures.
So if we look at narrative, this is so easy.
Just tell the story, just write it up.
You know, all you have to do is to write the story.
And there are classics here, Alfred Chandler, for example, historian tells a narrative,
his theorizing is very much narrative based.
And as Brad mentioned, thick description from anthropology is a term that Geertz uses to
to talk about his approach as thick description.
And if you do these things well.
So basically what you're doing is you're taking the mess of data that you have,
bringing them together to create a narrative.
And a narrative that will hopefully tell you something about the world that reaches beyond
the particular case.
And so narrative can be very powerful.
And if it works, you get a sense of data.
I've seen this before.
So a really good narrative study.
It'll be like a really good novel because you will see, okay, this makes sense.
This is this is how the world is.
And so it can be really appealing to have a strong narrative.
And then I really like this quote from John Van Lennon,
who argues in favor of narrative because precisely because narrative allows for complexity
and ambiguity.
And if your case that you have is fuzzy and messy and ambiguous,
then if you want to render it and keep that side of it, then, you know,
he says, to be determinate, we must be indeterminate because things are confusing,
because things are messy and so on and so forth.
So a narrative approach tends to try and keep as much of the richness as possible,
but at the same time give you that sense of deja vu.
So that's the positive side.
This is the negative side.
And so this is Laurel Richardson in the Handbook of Qualitative Research.
And she says, I have a confession to make for 30 years.
I have worked my way through numerous supposedly exemplary qualitative studies.
And it's boring.
Basically, it can be so boring.
And the reason is that it's just descriptive sometimes.
And so it's blind alley two again, where you have so closely captured your empirical data
that we can't see the deja vu.
We can't see the plot within it.
And so this is the problem of narrative.
But at the same time, there's almost no qualitative study where you don't at some point
draw on narrative.
So what are some of the other ways to draw on narrative?
So one way is to use it as the first step.
So you have all this mess.
Why not just try and write it up as completely as possible.
And this Kathleen Eisenhardt is this is the step that she always recommends.
And she talks about multiple case studies.
And she talks about how for each of her cases, she writes something like a 70 page,
single spaced story.
And that story becomes like a secondary database for the rest.
It's a way just to get started.
And it becomes as we're writing this narrative, it becomes the stimulus for your coding
that you're going to be developing.
So that can be one way to use it.
The other way to use it is to consider it as your loss.
You write the narrative to integrate your coding and your data and your theory,
to bring the data and theory together so that you're telling a story which has concepts in it.
And is kind of bringing codes and specifics and generality together.
So a really strong narrative as a last step is going to be able to
take specifics and show how they reflect a more theoretical concept.
And you might consider multiple narratives, which is getting back to the alternate templates approach.
Or you could look at multiple narratives based on the visions of different people in your case.
That's another multiple narrative.
So these are richer ways and more useful ways, I think, of thinking of narrative.
And there's this paradox about narrative, which is
you can't write a really good narrative until you know what the plot is.
But you can't discover the plot until you've done the narrative.
So it's this hermeneutic thing.
It's this iteration once again.
You start writing, you don't have the plot at first.
When you discover the plot, you have to rewrite it completely.
And so it's a little bit of a paradox.
And now so that we've talked about narrative, I'm not going to talk about another way,
which I really like of displaying qualitative and process data.
And this is visual mapping.
And so draw it.
Draw your data or draw something, draw your theory.
And so we're talking about graphs, tables, drawings, diagrams.
On visual mapping, the gurus here are Miles and Huberman and Sal Daniel,
the most recent version of their book has a third author.
So Miles and Huberman, you should read this.
It's a really useful book, which offers a variety of ways of drawing data.
And I like it a little.
So here's an example.
OK, so what is visual mapping?
So visual mapping, you can use any kinds of forms and drawing that you'd want.
But there are a certain number of conventions, which you might want to keep to.
So boxes and arrows are obviously important aspects of drawing data.
But you can use boxes and arrows for different kinds of things.
So boxes can be things, they can be objects, they can be concepts,
they can be actors, they can be events.
Depending on the shape of the box, you can code whether your event is, for example,
a decision or if it's an event that just happened externally.
So you can use the forms of boxes to indicate different things.
Arrows can indicate different things.
So particularly for process research, we're going to be using arrows
not so much for causality, probably, but more for temporal relations,
like precedence.
What comes before what in time is something that we're going to be using with arrows.
We're showing with arrows.
We can use icons, emoticons, etc.
And there are a certain number of conventions.
So at least in the West, time goes from left to right.
It does not necessarily go from left to right in other parts of the world,
and that can be confusing.
So if your writing starts from right to left,
you may think of time as going from right to left, and that can be confusing.
Most of the American journals will expect time to go from left to right.
Hierarchy top to bottom.
You can do things with overlapping boxes.
You can do things with boxes that interact, lines that interact, and so on.
So there are all kinds of ways of doing that.
Here is some of the thoughts of how you can use visualizations.
So here's my diagram with data and theory and coupling.
You can use diagramming visualizing all along this chain.
So when you look at a published paper, what you usually see is a diagram, a process theory.
So that is not what the author necessarily started with.
That's the distillation of their theoretical ideas.
So they're using it for conceptualizing or communicating their theory.
But you can also use visualization for actually mapping your data,
not just simply presenting the findings or presenting the theory,
but also for mapping the data and for analyzing the data themselves.
So it becomes a coding tool, essentially.
And this is an example that I put in a paper, very old paper,
that I wrote with a student.
It's a flow chart.
And this, we were actually mapping the data.
It was a technology adoption process.
We classified events according to different domains of the company.
So the top to bottom, the different domains of the company.
We identified different codes for events outside the company.
Those are the ovals for activities, which were, I believe, square boxes,
and decisions, which were the round cornered ones.
And we showed precedence.
We showed interruptions.
We showed events that impacted other events.
And depending on to what degree they impacted them,
we placed different symbols on there.
So this is an example of how you can take some data,
and instead of just coding it according to Joyer method,
you can display it along a timeline with events.
And so this is quite a different way of coding.
And it's still coding because we have coded the different kinds of events.
And this is a tool for describing your data.
But then if you wanted to compare different timelines,
and this is what we did, we had five processes that we mapped this way,
we could compare them so we could see what comes before what,
what tends to come before what.
But can we see some patterns in the types of interactions
between different kinds of phenomena over time?
So this is a really interesting tool for process research.
And most cases you never see, you don't see the mapping itself
in a published paper, but you see the final diagram.
So that's just looking at the time.
I'm going to skip a few things here.
Because I want to talk a little bit about comparing as well.
So we've talked about the two methods for displaying.
Comparing for me is a really powerful tool for theorizing
because it makes you, it makes you theorize.
If you, if you have an example I always give is if you have children
and you have a little boy and a little girl,
you immediately stop theorizing about the differences that come from time.
You're, you're, it's, we are programmed to theorize from empirical differences
and similarities that we see.
And so it is really powerful to do that.
And you can compare in all kinds of ways.
And so I talk about comparing time periods.
And this is particularly useful for process data.
But you can also compare cases.
You can compare incidents and drawing tables that show these comparisons
is a great way to kind of focus, get yourself to focus on that.
So I'm just going to give, I'm going to skip this
and just give an example of some temporal bracketing,
which is decomposing by time period.
So this is a paper that I wrote with with Jean-Louis Denis
and some other co-authors.
And it's about a merger of three hospitals.
And they were in a double mind.
They had a real tension because on the one hand,
they had been told that they would get a lot of money if they agreed to merge.
And on the other hand, they hated each other.
So they couldn't agree about anything.
They had to stay together.
They were stuck.
So they had this initial condition of constraint.
They had to be together, but they couldn't agree.
And so how were they going to work out how they were going to do this merger?
And we showed that they kept making decisions that embedded ambiguity
so that they would need to make the decision all over again.
And the processes were that, okay, they would put forward a proposal
where they would try and integrate everybody into the decision.
And in order to do that, they would have to make it ambiguous,
which meant that they could not implement the decision because it was ambiguous.
So they would have to decide all over again.
And so this is the overall model, but we followed it through empirically
with three different stages.
So here are the three different stages.
So this is temporal bracketing.
What we showed was they went through the process.
It produced ambiguity.
Therefore, we had to start all over again.
So this is a kind of a temporal bracketing of a process over time.
And this was very helpful in helping us to understand this process.
And the title of the paper is escalating indecision.
This is what happens when you need to work together, but you hate each other.
But you find yourself in this escalating indecision cycle.
The good news is that about five or so years after we finished our study,
they did actually do something.
So it didn't.
But this was the process that we observed.
And then you can also compare cases.
So you can do it compare outcomes.
If you're doing that, you probably are more into explaining variants
than looking at process.
So that's one thing.
But you can also use a comparison between cases to show similarity
rather than difference across different settings.
And if you do that, then you're demonstrating that the process that you're looking at
is not just in one case, but several.
And so that can be helpful as well.
You can use comparing cases to show variety.
You can illustrate richness around a similar structure.
And you can combine process and variants also.
So there are authors who use multiple cases to show different processes.
But then they compare the processes and show that some tend to lead to positive outcomes
and others tend to lead to negative ones.
So they're combining process with variants.
So I'm looking at the time here and I'm going to just skip things and move on to my last point,
which I think is important because I have all these strategies.
But at some point, that's not enough.
And I think it's a really important point that theoretical insight does not just emerge.
So when you read a qualitative paper that at some point somebody always says
the theory emerged or the concepts emerged from the data, well, yes, no.
I mean, you did this work.
And then there's this step which you cannot know exactly what happened, but you saw something.
And it's that step that's missing from any of the strategies that I've mentioned so far.
I called this the conceptual leap.
And I wrote a paper on this with Malvina Clag.
And this is an image in the paper where we point out that making the conceptual leap
is, yes, about analyzing your data carefully, about using all of these
a priori theories to look at your data, about talking to your friends.
It's all about doing systematic, disciplined things.
But it's also about doing unsystematic, undisciplined things, like going for a walk in the park,
going for a run, sleeping.
Sleeping is excellent when you wake up or you're turning over in the middle of the night.
That's when you get good ideas.
So it's a combination.
The discipline is really important.
And what we've spoken about most today is the discipline.
But there's also this kind of creative side.
And if you don't have that, you won't get what we're trying to achieve.
So I'm going to stop there.
See, we still have 200 people.
So I think we might be able to have a couple of questions at this point.
Yes, Arvore.
Thank you so much, Anne.
This has been very, very informative.
I'm really grateful.
And I guess we're all really grateful as well.
Just one question on the very last point you mentioned, which is the
creative leap.
So I remember writing in one paper about having a creative leap as well.
But I don't know if it's the way I framed it, but then I got back from the reviewer that
even though it's a creative leap, I should be able to explain how I got there.
And that was a bit counterintuitive because that's the point.
I can't necessarily explain exactly how I got there,
which is why it's a creative leap.
So do you have any pointers on how to really couch it so that it doesn't sound like it came
out of nowhere?
But then at the same time, you don't also try to force fit anything.
But then you can show that, yes, it came from knowing my data and all of that.
But the direct link that you want to see, I can't necessarily show you.
No, I think what is important to show in a paper is the coupling.
So the way you found that coupling that you can't explain,
but you can show the coupling.
And that is, you must show that the data, if you look at them carefully,
you can see the link with the theory.
So if you can show that link, that's the important thing.
You don't have to tell them how you actually got there.
But if, or you can mention that you had a creative leap,
but at the same time in the same paper, you have to be able to show that coupling happening
so that it's tied up with a bone so that the reader can see that the data, yes,
is a good explanation, or the theory is, yes, a good explanation for the data.
And the data do justify the theory that you're proposing.
So it's the coupling that's important.
Okay. Okay. Thank you so much.
Yeah. So you get your creative leap and then you go back.
And you mustn't stop with your creative leap.
You have to go back and check it out.
Otherwise, you can go wrong as well.
Are you ready?
Yeah.
Are you ready?
No, thank you very much, Prof.
Really, really interesting and useful presentations.
And I find them really very, very relevant to my work,
because I've been doing quantitative work until the PhD had to do process research.
One of the things that I'm really keen to do is to really make the best decision on how to,
which particular vehicle I use to write, because I'm using data from several sources over time.
On how a form of behavior continued to take different shapes in an industry that is trying
to be formalized, but then a lot of the informal activity kept on happening over time.
So the dialectic one seemed quite interesting.
But my question is, is there like, would you recommend picking a model and then
trying to write after that model?
The question I think you're asking is, where do I start?
What does I do first?
I think that I would, I tend to start with temporal bracketing.
Because I sort of like to see in the data, what is it, are there turning points?
And then once I've seen that, if there are no turning points, well then that doesn't really work.
Maybe there's this kind of a smooth continuity, but if there are any turning points or whether
something happened, like some new people came in or a new company appeared in your industry,
or something that changed significantly, more significantly than other events,
had a potential for change, then those turning points are kind of like a starting point for
looking at the data. Then you might move towards more detailed coding of what was going on in each
period. And so you would collect together bits of data, which are relevant to each period,
and start working on what's going on, what different actors were doing during those periods.
So I mean, that's, I think what I would do, but yeah, it depends. I think you have to find
something where you kind of have something to grab onto. Another approach is to find another
basis for comparison in your data. So do you want to compare certain types of firms with
certain other types of firms? You know, if so, can you subdivide your data according to different
types of firms? Or can you subdivide it in some other way? I think it's very useful to find something
to grab onto, which you can compare with another thing. I tend to go for temporal brackets, because
I'm a lot closer. Daniel.
Hi, Anne. Thanks for a great session. This is a question that came from one of our participants,
Eva Maria Spreitzer. And her question is, what would you say, or what kinds of theories
are great to inform the coding of the data, such as different levels, depths, etc. And the thinking is
because it is easy to go from low or tight with concepts or too high or too broad with
theoretical frameworks or meta theories. Yeah, well, I mean, it depends on the nature of your data.
But, you know, as I mentioned, you can you can code your data with no a priori theory,
you can just read it and see what you see. That's the theory behind grounded coding.
But if you want to develop more oriented coding, I mean, think about what it is,
what are some of the concepts that you're interested in. So if you want to
really focus on processes, maybe your coding should be about activities, right? So what
activities are people thinking about? So that would be one angle to look at. So process
process theory is about activities. So can we code activities? But you might be interested in
something else, you might be interested in emotions, for example. So then you might code
emotions, and then you might ask yourself, well, what emotions are associated with which
activities and which events? So that then you would code those. So I mean, this is a decision,
depending on the research questions you're interested in. But if you're interested in
process, I think, I think activities, I think events would be things to focus on. I don't know
if that's helpful. For me, it is. I hope Eva Maria likes the answer also. Thank you.
Hi, thank you very much. So my question is about this combining a grounded theory approach with
the a priori approach. And I was reflecting on on this from a more
based homological point of view. So as far as understood, one would be more interpreted and
the other would be kind of more positivist. And I, and I, I still struggle to see how can we do that
and how we can combine both. And I don't know, maybe I didn't get it right. Or maybe you have
some insight for me. Thank you. Yeah, but I mean, some, some theories are interpretive. So I don't
think it necessarily, you know, means that one is, one is more interpretive and the other is
more positivist. But you know, there is this idea of induction and deduction. But I think that
what you need to understand is that even if you are doing an interpretive bottom up constructivist
approach, you need to connect it to in order to make a contribution, you need to connect it to some
a priori theorizing. So if you read carefully, even Denny Joyer's papers, they are not a
theoretical from the start, he reviews, he reviews the literature, he comes up with a research question,
and his work, his work done with other colleagues is cumulative, actually. He's interested in
identity or has been interested very much in identity. And if you look at each of his papers,
they kind of build on each other in many, very, very, very many ways. And so they're, they're not,
they're not a theoretical. And so I think you always need to refer back to other literature.
Yeah. But you need to find your sources that fit with what, what you're doing.
I think a really interesting body of work, which really shows this, this kind of bottom up top
down idea is the body of work on organizational routines, the, the, the theory of routine dynamics.
And so this is always, the studies are almost always qualitative. The notion of routine dynamics
was developed by Feldman and Pentland. They wrote a very famous 2003 article in administrative
science quarterly. Other people interested in routine since that time have built on that paper
and their theory, but each one is making a very distinctive contribution.
And, and it's qualitative and it's processual. But the, the research questions are different,
except there are, there are some concepts, foundational concepts that everybody is using
that, that, that just simply get more richer and further elaborated each time. So that might be
a good body of work to sort of situate this, this kind of top down bottom up idea against.
Thank you very much. If could I add a second question?
Yes, okay.
It's actually more on the practice on the, on the coding and analysis side. So as a PhD student,
I also find sometimes a bit overwhelming to look at different cases at the same time. And so
I was trying to playing around with different approaches. And I was wondering if you have
any suggestion to maybe start from one case or actually know it's much better to look directly
through all of them. And what's your opinion on that? Thank you.
Yeah, I don't know. I think it depends a little bit on whether you want to explain each case
individually and, and maybe think of them as separate contributions or whether the comparison
is really critically important to you. And then you want to keep it, keep it going.
But I mean, another, I think Daniel asked this question, you know, no, it was someone else who
asked the question, where do you start? And I said temple bracketing and another, another way to start
is just to write these narratives for each of your cases. That's, that's, that's so helpful.
If you have different cases, write the narrative, put quotes everywhere in, in the narrative, you
know, let, let, let, let's just tell the story. And, you know, all the quotes that you think are
so great that you absolutely need to use them, you put them in the narrative. And then you've
got this kind of secondary database where you can compare the narratives. And so that becomes,
then you can write new tables that compare the narratives. So you, so you can look case one,
case two, the first phase, the second phase, and then, then it becomes organized. But narrative
can be a great way to get started as well. Loreto. Hi, thanks, Anne. This is a really
brilliant presentation. I'm really going to help with my, my projects that I'm doing at the moment.
So thank you. And I'm, my question is more about the end point and about where, where
to get published and where you think are kind of the journals that are more aligned to process
research. Thank you. Well, it depends what your field is. I'm in the field of management. So
the, the North American management journals, like Academy of Management Journal and Admirative
Science Quarterly and Organization Science have, they publish all kinds of research,
they publish quantitative and qualitative research. And they have editors who are dedicated
to qualitative research. So I am an editor at Academy of Management Journal, and I am dedicated
to qualitative research. And we have five, we're a team of five editors that consider qualitative
research. And it wouldn't be the same in the other journals I mentioned. And so although
they publish a lot of quantitative research, they also publish much a great deal of qualitative
research. So that, that's a good place to go. Many of the European type journals are more
qualitative oriented than the North American ones. So organization studies is a great journal,
journal management studies are great journals for this work. I'm not sure that I think what,
in order to decide which kind of journal you want to publish in, it's a good idea just to read
you know, those journals and see where you see things that, that correspond to your interests.
And that you, you think that you can relate to. So some journals have more of a sociological
flavor and they may relate more to sociological literature, some are more managerially oriented.
And there, there are delicate differences that you need to kind of get familiar with. And it's,
it's very difficult to, to pick one, but all the journals I mentioned, and others as well,
are very open to process research. Yeah, you might, if I mentioned some that probably less so,
I mean journal applied psychology might not be so open to it. I don't know.
Some, I interrupted somebody. Patrick. Yeah, thank you very much for your very, very brilliant
presentation. I have a pretty busy question that has been very, very confusing for me,
which is, how do you do process to arrive in from a one-off interview where you are,
you are, where the respondents is talking about how they make decisions within the organization.
Clearly, this person is talking about a process, right, and how they finally arrive at a conclusive
decision. But this is the one-off kind of interview. So how do you, do you process to arrive in from
such a data? Well, I don't think you can. I mean, because you only have one person,
but you can, you can represent that person's theory of decision making. So, so you could,
and if you have several different people, you can look at their theories of decision making.
So that, that they are, they are suggesting the stages that you go through and things like that.
What I think, you know, when you're looking at an interview, is that there are two ways to
develop theory from an interview friend, from the data. One is to
take the generalizations that the person is telling you. So, let's say the person says, oh,
we always make decisions in, we have a committee and we make the decisions in the committee.
Okay. So you could read that and think, okay, they make decisions in the committee. So I'm
generalizing from the generalization of the respondent. Or instead of doing that, and I think
that this is much better, is that you have the accounts of that individual of several specific
decisions. So this happened, this happened, this happened, this happened, this happened, this happened.
The second decision, this happened, this happened, this happened, this happened, this
third decision, this, get them to talk about lots of different decisions. Then real months,
concrete months, then you generalize from their stories, not from their generalization.
See what I mean? It makes a huge difference. So if you, if you're talking, if you're using an
interview, get the stories. And sometimes you do generalize from other people's generalizations,
but it's much better to get the, get as close as you possibly can to the actual events and the
accounts of the actual events. And you're getting deeper when you're doing that. I don't know if
that's, that's helpful. Yeah, thank you very much. That was very, very helpful.
So how are we doing? Anyone?
I'm just looking, is there something in the chat which I should respond to?
I'm not sure we'll have time for that. Yeah, Izidora.
Hi, thank you for a great presentation today. I believe this is a very broad question, but
if you can just give us sort of just your general opinion, I'm really interested about
quantification of qualitative data. I have thought about it in one of my previous research,
but I opted against it because of all the division of whether this is a right research
strategy. So I just wanted to hear your opinion on it. And maybe if you can suggest
some kind of resource that would be valuable in sort of providing a starting point for that.
Yes, so thank you for the question. Because one of my strategies was quantification. I didn't
talk about it. And I didn't talk about it because I'm not particularly fond of it.
But I do think quantification can be useful. And when is it useful? It is useful. It's not
a useful description. It doesn't make any, you don't need to count anything if you just want
to describe phenomena or advanced types of events that happen. You don't need it.
Where you do need it is where you want to say, case A is more of a success than case B,
or some kind of way of judging differences that is along a scale. Then you have to find ways to do it.
And so, for example, I recently did a study with a colleague, which was about, it was an
18-year history. So it's kind of a process study of how managers cited their founders
in their discourse, in their communications. And we wanted to show that the way they cited them
changed over time. And in order to do that, we had to count them. We had to code them into
categories and count them to be able to demonstrate to the reader that it's exactly true that we
were saying they were more like this than they used to be. And so, counting gets important
then. And when you're counting, you know, inter-rater reliability starts to get important.
Because the precision is important. So then you need to go to resources that can talk to you about,
you know, very content analysis type coding. Where you have categories, and you need to
be able to show that these categories are reliable, valid, and so on.
So I would look, you know, on the, on Google, I would Google content analysis, probably Kruppendorf
would be a good author for that. Talking about how you would take qualitative data and then
use it to quantify certain concepts. But I wouldn't do it unless you really need that comparison.
A is bigger than B. Otherwise, one of the reasons I don't like it is you take out all the ambiguity.
If you put things into categories and count them, all of the richness of your data kind of
disappears. It just has to go. Because the obligation to be able to find exactly the same
number as your colleague means that you have to make things so clear that there is no possible
doubt that you have categorized correctly. Which means that all of the ambiguity and fluffiness
and richness goes. And that's not good. Qualitative data is qualitative. It's not quantitative.
So it's a good thing if you need to do that comparison. But if you don't, don't do it,
just, just to do it. It's not worth. Okay. Yeah. Thank you so much. Yeah. I think I
eventually decided against it simply because, yeah, the essence and the nuance within each of the,
you know, qualitative aspect sort of gets lost. But I still think that it might have been an
interesting strategy to show intensity of a certain outcome. Exactly. Exactly. Exactly. That's
what I think. One person who does it very well and still keeps the richness is Stephen Barley.
So if you look at many of Stephen Barley's papers, he's real. He's a fantastic qualitative
researcher, but he also counts things. And as a great paper recently in Academy of Management
discoveries about buying cars. But he does a lot of qualitative analysis, but also does counts.
So that might be a good example. Okay. Thank you so much. Burak.
Thank you very much. I have a very brief question. It's about the lens. You mentioned
about the theoretical lens. How about the paradigm as the lens? And combined
with the theoretical lens, would you please elaborate differences and similarities? How do
we use them? Thank you. So you're referring to whether you're having a critical paradigm or
you're adopting a interpretive paradigm or a positivist paradigm. Yeah. So I'm agnostic as
to which one you might want to adopt. And it's also possible to play with them. So you can pretend,
you know, you can say, okay, today I'm a positivist. If I were a positivist, how would I consider these
data? Now I'm a critical theorist. How would I consider those data? So you can do that.
And it certainly would help you see, it would get you to ask different questions
about the data. So if you're a positivist, you're going to be asking, what is the truth? Right.
And if you're an interpretive, it's how are people seeing things. And if you're a critical
theorist, you would ask yourself, well, who is winning and who is losing in this?
And so you ask yourself different questions. And I think that's hard to do within a single
paper, but it could be something that you could try and, you know, sort of play around
with those approaches. I mean, you can do the same thing with an interview. Take an interview.
Look at the interview. What if this was true? The person is telling me. And how can I know
that it's true? And if you're looking at an interview positivistically, you will say, well,
only the things that are about verifiable facts, I know are to be true. And in order to find out
whether it's true, I will need to find someone else's view or I will need to get other data.
If you look at an interview interpretively, you would think, well, no, I don't really need
anybody else's opinion, because I'm only interested in their interpretation, and I'm not trying to
do anything wrong. And if you were to look at it critically, yeah, if you were looking at it
critically, you would be very skeptical of what that person is telling you. And you would be
asked now, why are they telling me this? What is it they're trying to convince me of?
That you would look at it in a much more skeptical manner. So just thinking about those things,
even on one interview, it can get you to see things different.
See, exactly the example that you gave about the hospitals merging, like for example,
in this case, we can try to understand the phenomena of decision making from, you know,
generative constructionist perspective. But also we can look at it from a conflict paradigm,
meaning that decisions are going to create conflicts. So in this case, our theoretical lens
would be different, depending on the paradigm. Yeah, indeed. Yes. I agree.
Thank you. Thank you. Thank you.
