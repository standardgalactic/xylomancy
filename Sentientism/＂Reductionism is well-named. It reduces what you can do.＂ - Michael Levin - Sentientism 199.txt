the best thing I hope my lab does on their best days,
taking these ideas from deep philosophy
that people have argued about for thousands of years
and bringing them to the bedside, to the clinic.
What you look like and where you come from
simply cannot be the foundation
for how we're going to relate to each other.
But I don't feel in any way diminished by the idea
that there are an infinitude of other minds,
highly diverse minds, endless sentient forms
that are also having experiences that strive
and suffer to various degrees.
I think what we have is essential.
I would like humanity to scale its cognitive capacity
more specifically, not just the intelligence,
but the radius of concern of care and of compassion.
I think we need to scale that up.
The amount of emails that I get every day
from people with the most unbelievable examples
of biomedical suffering is just incredible.
So I think it is utter moral cowardice
to focus on what we shouldn't do,
as opposed to our duty now that we have,
for the first time, we have the ability
to actually rationally approach these matters,
to try to guarantee a better embodiment
for sentient beings on Earth.
["Good Morning, Mike, How Are You?" playing in the background.]
Cool. Well, good morning, Mike. How are you?
Good morning. Excellent. Thanks for having me.
Yeah, it's wonderful to get the chance to talk to you.
I'm very much an amateur in this field,
but I've admired your work for a long while.
And I can't offer you the size of audiences
you're used to with your TED Talk
and with some of the other interviews you've given.
But I can trade that for quality,
because my audience might be small,
but they're lovely and deeply thoughtful.
So I'm sure they'll appreciate your work and your thinking.
So it's great to have you here.
And I think you're probably, in nearly 200 episodes,
my first full-on biologist,
which is a gap I should have filled long ago,
because there's this sense that maybe the mathematicians
should look down on the messiness of science
and maybe even the physicists look down on the mess of chemistry and biology.
But I think the hierarchy goes the other way.
I think biology is the harder, more challenging space,
whereas the mathematicians and the physicists
with their spherical cows can abstract
some of the interesting stuff away.
You upped your elbows in it quite often.
So it's great to get the chance to have a biology-focused conversation.
Well, thank you. Yeah, I mean, we biologists have plenty of spherical cows.
A lot of people talk about some of our constructs as real pathways
and things like this, but of course, these are all imaginary kinds of constructs
that we do our best with.
Yeah, cool.
So this is a series of conversations
about what I think of as the deepest philosophical questions
and also the most important.
And they're questions of what's real, really more epistemology than ontology.
How should we go about best understanding this crazy world we all share?
But just as importantly, the questions of ethics.
And within that complex field, the simple question of who gets to count,
who should we count as another as we're thinking about how to lead a good life.
And I have an obvious bias because this sentientism worldview
I'm trying to popularize and develop is very pluralistic and very broad,
but in a sentence is evidence, reason, and compassion for sentient beings.
So when we're answering the what's real and how to understand the universe question,
it suggests a really broad, humble, naturalistic approach
that uses evidence and reasoning.
And when it comes to the ethical scope question,
the clue is in the name, it says that all sentient being,
any being that has the capacity to experience things, to flourish, to suffer,
should count at least some minimal regard and moral consideration.
I'm talking to people in this series of conversations,
some of whom agree and some of whom don't.
So it'll be interesting to see how you have gone through your own philosophical journey
in answering those questions, where you are now
and how that runs through the work you do today.
But before we get on to those big questions,
how would you best introduce yourself for those people in my audience
who haven't come across your work so far?
Well, let's see. So my name is Mike Levin.
I'm a professor at Tufts University.
I run the Allen Discovery Center here at Tufts.
I'm also an affiliate faculty member at the Bees Institute at Harvard.
I do a number of other things.
I co-direct the ICDO, the Institute for Computer Design Organisms with Josh Bongard.
And yeah, that's me.
I study a range of things.
I mean, we'll get into all the details.
But in my group here, we do a combination of biology or biophysics,
mostly computer science and cognitive science to understand embodied minds.
That's really what we do.
Yeah, that's great. Thank you. Yeah, we'll dig in.
We'll dig in.
So let's start with the first of these big philosophical questions,
the question of what's real and epistemology.
Quite often an interesting way into that space,
because it's so broad.
It covers anything we might choose to believe or have credences in.
But an interesting way, and many of my guests, is to talk about their journey
with respect to religion and spirituality and whether they grew up in a religious,
spiritual sort of context and household,
whether they held onto those types of beliefs or not,
and how that side of their thinking about some of the sort of ultimate questions
of the nature of reality might have shifted since.
But so I don't know if you want to wind the clock back
and sort of tell us your story in that space.
And then we could get into, I guess, more of the field of science.
So yeah, yeah, my background, I think you could say is not religious,
but highly spiritual.
So, you know, I went for a few years.
I went to a Hebrew day school.
And, you know, my background from that perspective is Jewish.
And then we studied some thoughts around that whole thing.
You know, and I harassed everybody with questions about what happens in conjoint
twinning and how, you know, how souls are supposed to work
and how they solve the problems of, you know, the hard problem of consciousness
and all that kind of a thing.
And, you know, the answers weren't terribly forthcoming from that direction.
But in my home, I think it was always very clear from the time I was very young
that we had an emphasis on inquiry, on asking big questions,
on making sure that whatever we spend energy on is towards things that matter
in an ethical way.
You know, I was always encouraged to find things that I'm passionate about
and to use intellect and every other tool at my disposal
to sort of get to the bottom of things.
So we had lots of deep conversations about kind of the big questions
and how they might be addressed.
You know, the question, how do you know what figured prominently in my childhood?
So we always encouraged to think about those kinds of things.
So that, in the way I'm describing that naturalistic epistemology,
using evidence and reason and sort of thinking things through in that inquiry
was there from quite an early age, even within a family that sat within a broader
sort of religiously defined community and culture, I guess, yeah.
Yeah, yeah, but also to be clear that, you know, there are many ways of enhancing
wisdom, or at least attempting to.
And so rationality is an amazing tool, but one can also ask questions
about its limitations and what other alternatives might be on offer
and, you know, making sure that we understand.
But what are the things that we're not seeing, you know, and it's sort of,
there's an old saying that says, show me the net with which you're fishing
and I'll tell you what you're not going to catch.
I forget who said it, but that's, you know, that being, having that level of skepticism
about the approaches you bring to a problem, whether that be different kinds of logic
or whatever else, you know, that was always emphasized as well.
Yeah, and that if your choice of evidence or your choice of methods are tuned now,
that can become its own dogma, as you say, you've got to be able to question those,
you know, those choices too.
And part of the way I try and counter that is to talk about evidence and reason
in a very broad sense.
So some people will think of that as being a narrowly rational or empiric or even
a scientific process that, you know, it doesn't count as evidence until you've
done a randomized control trial.
And I don't think that in those terms at all, I think of evidence and reason in a
very broad open sense that can include the experience from our senses,
our subjective experience, you know, how aware those might be.
I think those are all types of evidence too.
We can be skeptical of them.
But I think that broad conception of naturalism is something I'm much more
comfortable with than something that's really narrowly scientific, if you like,
which can, I think, narrow down too, too early.
And how did that sense of inquiry, but a broad sense of inquiry,
shift your actual beliefs over time?
Even when you're asking the awkward questions, did you still hold on to some
of the supernatural beliefs anyway?
Have those shifted over time?
So I guess there's probably two linked questions there.
How do you think about the possibility of some of those supernatural constructs now,
gods and souls and spirits?
And is your sense of those still linked to this
inquiry and a naturalistic approach?
Or do you sort of reserve certain areas of knowledge for different epistemologies
that might be more faith-based or revelatory?
Yeah, I think I pretty much only have one supernatural belief, which is that
the universe is understandable in some fashion, whatever that may mean, to be understood.
And that we are, at least to some extent, capable of resonating with a fundamental
principles that guide its development and therefore knowledge seeking and things like
this are not hopeless.
That I fully admit is a supernatural belief because that's the kind of thing you can't really
get behind.
But once you've taken that on, then everything else becomes possible.
So I can't think of anything that would be truly supernatural in the sense that
it might be completely outside of current abilities to understand, maybe beyond
current scientific formalisms, but also perhaps beyond our cognitive capacities.
So all of us are finite beings, guaranteed there are going to be things that we are
simply not capable of comprehending as well as we can comprehend other things.
And so beyond that, I don't think anything is really supernatural.
I think all of us are doing our best in cobbling together some kind of
coherent understanding of the world and our place in it.
And then the interesting empirical part is then you get to find out how well it's working for you.
So not just in the narrow scientific sense of specific paradigms that help you do
experiments and make predictions and things like that, but the same idea applied to one's life.
And so you have various outlooks that you might take on various frameworks,
and then you have to ask yourself, so how is this working out?
Is this helping me have a more meaningful life?
Is it helping me be a more ethical person to have better relationships with others?
Those are the kinds of things that are not specifically scientific outcomes,
but the process is exactly the same.
You examine your framing and you ask yourself, are there ways to tune that framing to do better,
to have a better experience with others?
Yeah, thank you.
And I quite like describing this naturalistic approach as being just an attempt to honestly
engage with reality and an attempt to understand it.
And now understanding will always be partial and probabilistic and provisional and uncertain
and open to revision.
But I guess that's an interesting way of putting it.
It's not just about, does the evidence start with my hypothesis?
It's also, how does the application of this knowledge or these beliefs
actually work for me in practical terms, whether they're my life or engineering context?
So yeah, thank you.
Yeah, it became pretty clear early on that how one looks at data or at life or at anything else
is a very strong determinant of how one is going to interpret everything that happens.
And these kind of frames are, they drive what happens next.
And they drive the kinds of things that become possible for you or impossible.
You know, they determine which things are facilitated and which things are constrained.
And so that aspect of it being really in control of how you interpret things, I think,
is really important.
Yeah, thank you.
And if we narrow down now, I think of, I guess, the scientific pursuit as being a subset of
naturalism, it's the sort of a formalized way of doing that.
And your focus is in the field of biology.
And it's been, it's fascinating, because I think for most people, with their memory of the sort
of high school sense of what biology is involved in, you've been taking the field in very different
ways, although some of the different ways have quite old roots too.
How have you come to understand biology as a field writ large and what are the sort of
distinctive angles that you've been trying to develop, particularly as you think about
one of the introductory comments on your lab's website talks about this fascination with
the fact that all of us have gone from matter to mind in some sense.
Yeah, I don't really think of myself as a biologist.
I mean, we certainly do biology in my lab, among other things.
But my fundamental commitment in my career and my life, basically, has been to understand
embodied mind.
So I've got this mind map that I print out every once in a while and hangs in the lab.
And it's about nine feet wide, this big kind of poster thing.
And in the middle of it, the root node of this mind map is embodied mind.
That's really what I'm interested in.
I'm interested in cognition, intelligence, and inner perspective in a wide range of diverse
systems, some of which we would call alive nowadays.
I actually spend very little time figuring out a definition of life, although if you want,
we can talk about it.
But I don't worry about it too much at all.
I'm interested in the things that all cognitive agents have in common.
I'm interested in the scaling of mind from its most sort of primitive and humble examples
in the world, which I don't think anybody would call alive necessarily.
But I think cognition is broader than life, broader category than life.
And yeah, and that's what we're interested in now.
Now, it just so happens that life is our best example so far of how that gets scaled.
So we do a lot of work in our lab using the phenomenon of molecular networks, scaling
into cells, scaling into tissues, scaling into organisms, and beyond.
As an example of how to understand collective intelligence, how to communicate and ethically
relate to those collective intelligences, where do the goals of those collective intelligences
come from, and so on.
So biology is an excellent playground for these kinds of things.
But I actually think the question is bigger than that.
Yeah, thank you.
And again, the sort of high school, and when I talk about it in the third person,
it's really my high school sense of these things,
it does reflect this sense that there are different scales of reality.
And you're interestingly trying to span them and work across them and look at some phenomenon
that may be scale free in some sense.
But I guess you can start, you can think about the fundamentals of physics,
whether those are fields or fluctuations in them represented as particles,
and you can come up through the different layers.
For our purposes, I guess where it starts to get useful,
most people would think of life as being the point where we're getting into the realms of
considering the possibility of mind, at least there are entities that are separated from their
environment that have some sort of evolutionary history that have some form of drive to live.
But you've hinted there already, you don't necessarily find the concept of life that
interesting. But then you can move through, you know, simple types of life in the earlier
evolutionary stages, but also in the degree of complexity as well.
So in our current panoply of living beings, you know, very simple single celled organisms,
plants and fungi, and then it feels intuitively like we take another step on the cognition
path when we're starting to think about animals as well.
So as we're sort of working across that boundary from non-life to very simple life
through to plants, fungi, and the simplest animals, where do you see this idea of cognition
emerging? Where did it come from? And I guess, what is it? But one of the things I find interesting
in at least your public writing is that sometimes it does feel like there's a little bit of slippage
in the term, because sometimes it cognition feels like something that's more narrowly computation
you know, it's something that maybe my spreadsheet on a laptop could be doing.
But sometimes there is an implication of mind and a subjective perspective
in the way you talk about cognition as well. So I should ask a better question than that.
But in that sort of space of simpler living organisms, how does cognition emerge and what
do you think of it is in its simplest terms? Yeah. So, so here's, here's how I think about
these things. All of these cognitive claims, in other words, where you think something is on
the spectrum of cognition, you know, how much mind and all of that, I don't think these are
terms describing particular systems. I think these are terms describing our intended relationship
to them. So I don't think any of this is about the system itself. It's when you make a cognitive
claim about something, you say it's this system is at the level of whatever, which you're really
telling me is an engineering interaction protocol, you're telling me what your viewpoint on that system
is and that viewpoint is going to determine how you interact with it. So I'll give you a simple
example. People argue all the time about whether whether humans are machines, you know, and now
now this is a long conversation because you have to define machine, you have to define human and
all that. But, you know, if if if you have an orthopedic surgeon who does not believe you are
a machine, you're in trouble, you need to you need to find a different orthopedic surgeon.
If you have a spouse or a psychotherapist who thinks you're a simple machine,
you're also in trouble, not not not a great not a great fit there. So there are plenty of
supposed doctors out there, you think you're a fluctuation in the cosmic quantum wave vibrations.
So yeah, yeah, yeah, I mean, so so so my framework, so I'm working on this framework
called TAME, T-A-M-E technological approach to mind everywhere. And and one of the main
claims of this framework is that none of these things can be determined from a philosophical
armchair. You can't just decide what things are you have to do experiments. So if you think,
you know, you're a quantum fluctuation, whatever, whatever, that's that's great. It's all open.
It's a it's a fine hypothesis. What has it done for you? Right? Like what what are the benefits?
And so and so I think this is this is the difference between, you know, this kind of
pluralistic view that I have where multiple observers can differ as to their assessment
of any given system. That's that's that's what I believe, but it doesn't mean that anything goes
because those observers can then compare. Well, how well did that worldview work out for you?
What has that enabled you to do? What has that enabled you to discover? How rich are your
relationships with with the various systems given the view that you have? So so what you want to
do is you want to get it right or at least optimize it. You don't want to have false negatives where
you attribute cognitive qualities to systems that where they don't give you any any new purchase.
So so for example, you know, kind of old school animus ideas where there's a spirit in every rock,
that's a fine hypothesis. What is what? How does that work out? You know, what does that do for
you? You know, you need to do experiments, you need to show that, hey, by saying that this thing
has goals, it has learning capacity, it has whatever, this is now what I'm able to do. I'm able to
either either make better prediction and control, or we're having a more richer experience,
you know, interpersonal experience or something. So all of these things need to be empirically
testable. So in this framework, your spreadsheet may or may not be doing some of the things that
are tractable using the tools of cognitive science, for a spreadsheet probably not,
but but you'd be surprised. The thing about the thing about treating these things as
empirical questions, not philosophy, is that you are often surprised, which is what is good
about science, is that when you when you when you are surprised, that that's an opportunity to learn.
And so what I think all of these cognitive claims really are, are these hypotheses about which set
of tools am I going to apply? So am I going to apply the tools of physics and simple engineering?
Am I going to apply the tool of cybernetics and control theory, the tools of behaviorism and,
you know, learning and training and things like that, or the tools of communication and,
you know, psychoanalysis and love and all these other things. So so so the thing is that when you
when you treat that as a as an empirical question, you get to do experiments and you get to be
surprised. So for example, we have found that very simple systems that represent gene regulatory
networks. So just small numbers of chemicals that turn each other on and off. That's it, no cell,
no, you know, no, no, no, no indeterminism, no magic, just just differential equations of
describing how genes turn each other on and off. That system, which most people would assume is,
has zero cognition, they would say, well, that's a very mechanical, you know, it's just as people
say, it's just obeying the laws of physics and chemistry. That that turns out in that just.
Yeah, yeah, right, right. I mean, I really hate that framing. But that's what that's what people
often say. That system by itself is capable of six different kinds of learning, including
Pavlovian conditioning just there. So with nothing else, we've also done, we've also done work on
sorting algorithms. So these are extremely simple, deterministic, fully transparent algorithms of
people in computer science have been studying for, I don't know, 60 years or longer, things like bubble
sort and so on. Even those things, when you when you probe them the right way, show novel problem
solving capacities and behaviors that are not in the algorithm themselves. So what I am taking
from all of this is that we really need a sense of humility about what things can do and what
kinds of tools are best appropriate for them. You don't know, we are not good at guessing.
We think we are and people assume this all the time, but we're not good at guessing. And so we need
a mature science. So this is, you know, if I had to pick one field that I think I work in, it's
diverse intelligence research. That's what I think we do. We are trying to develop principal
frameworks for really knowing which kinds of cognitive tools, which scale of cognitive tools
are appropriate for various systems. And we're just not very good at guessing from the beginning.
Yeah, thank you. And intelligence, I think, again, you can spend three hours talking about
definitions of it, but I think many people would talk about it in simple terms as being
the faster to solve problems, which is something that could be done without mind and without
subjectivity and without feeling. Whereas cognition, or maybe again, you're going to
tell me that these distinctions are maybe not even well posed.
Yeah, so let's break it down a little bit. So intelligence, I agree with you that a good
definition of intelligence has to do with problem solving. Now, I'm not claiming that
problem solving encompasses everything that's interesting about cognition. There are
other things that are not about problem solving, but problem solving is good because it's
publicly observable. It's a good scientific thing to study. And it's about competency and
navigating some problem space. And there are many, many tools and tricks that a system can use to
navigate that problem space. Now, the thing about inner perspective is this, which is,
and at this point, I'm not talking about the hard problem of consciousness. We can sort of talk
about that separately. But here's the thing about inner perspective. It's not a binary. I don't
think any of these categories are usefully binary. What I think is important about inner
perspective is this. For any kind of system, you want to be able to answer the question,
how important is the system's perspective onto the world for me to understand what's happening?
So let's have a simple example. I suppose you have a bowling ball on a hilly landscape. So
you've got this energy landscape, you've got bumps and valleys, and you've got a bowling ball.
If you want to know what that bowling ball is going to do, your view as a third party
observer to this as an external observer, your view of the landscape tells the whole story.
Okay, there's nothing more. You don't need anything else. You will have everything you
need to know to predict what's going to happen from your external view of the landscape.
By the way, imagine what it's like to be the ball. Well, that's the next step. That's the
next step, which is that if you want to now know what a mouse is going to do on that landscape,
your view of that landscape isn't really very interesting at all. It's not predictive of
much. The important thing is the mouse's view of that landscape. Because if it has
an internal representation of the valence of different portions of that landscape,
so rewards and punishments and which things are important to it and what attention it's
paying and all that, the inner landscape of the mouse is the actual landscape that's going
to determine what happens next, not your view of the landscape. Different kinds of
systems have different degrees of representation of their outside world. It's not just
brainy smart animals that do this. All systems represent the world to some extent. The question
is how much? The question is how much do I need to worry about? One way to quantify this
is in terms of the size of their cognitive light cone. You can ask for any given system.
If you were to draw a space-time, a butchering of Minkowski's space-time cone diagrams,
you can draw a little diagram that says, what are the events both back in time and forward?
Because some systems anticipate. Both back in time and forward in time and spatially,
what are the things you need to know to have a really rich relationship with the system?
Meaning prediction, control, something that benefits you in some cases, something that's
ethical and all that. What do you need to know? For a bowling ball, the cognitive light cone is
tiny because everything you need to know is right there. You add up all the pushes and
pulls on it, you're more or less done. Once you start entering the systems that are even as simple
as a collection of genes regulating each other, that's no longer satisfactory because they learn
from experience and things that have happened before are going to make huge differences to what
happens next. You cannot gain a full understanding of what's happening or to gain good control
without understanding their inner perspective. I think inner perspective is something that to
some degree is wider than biology. I think what biology is really good at is scaling up these
cognitive light cones. In a rock, the cognitive light cone of the pieces, which by the way is not
zero, it's very small, but I don't think it's zero, is not really summed up. The rock has exactly
the same level of cognitive light cone as its pieces, but biology is super good. To say it
another way, I think we call living things any system that's good at scaling up the cognitive
light cone of its parts. It's going to look alive to us. Just the final thing, which we'll
probably get to again later, in terms of what kind of world we want to live in, I think that
evolution has no monopoly on producing cognition. In other words, up until now, yes, that's
probably, at least on Earth, that's probably mostly where cognition came from, is from the
fumblings of mutation of selection and of some other things. I don't think intrinsically that's
where cognition has to come from. I don't see any reason whatsoever why the rational efforts of other
cognitive agents, such as ourselves, couldn't make new minds going forward.
Yeah, thank you. We're good to dig into that. The point you mentioned about the
approach to genetics is one of the things that you've helped to radicalize this view,
this simplistic view that DNA is some form of blueprint where you programmatically and linearly
follow it. That's one of the things, as I understand, your work has radically opened up. It's nowhere
near that simple. It's much more about systems interacting and memory can be held in different
forms and so on. It's broadened out that view. As we're moving further up the scale, if there is
such a scale, one of the things I've heard you resist before, as you are here in a way,
is this idea of really clear binary concepts, concepts like sentience and consciousness that
try to take ideas like cognition and map them onto this intuitive sense that we have,
that we are ineffable, distinct, somehow unique entities that feel like we're separate. We're
not just physics. I empathize with that resistance because I think there's a danger in
that intuition that we reify these ideas because they're obviously important to us.
Intuitively, I can understand why anyone's consciousness will be important to them. Ultimately,
it's all they experience. Everything we experience comes through the consciousness,
but there's a danger in reifying that and taking it away from just being physics because ultimately,
I think I share your view that just physics, we are all just part of the natural world all the way
down. That doesn't mean these aren't interesting concepts, but they're not distinct from
physical reality. But at the same time, I prefer not to put them completely to one side. I think
in the way you're describing needing some sort of research concept or some
concept of relationality can still provide at least a couple of reasons why it's important to
still focus on ideas like sentience and consciousness. I guess one, it came partly
through my conversation with Mark Solms, who I know you spent a lot of quality time with. I've
loved some of your discussions because part of the way he tells the story about evolution is that
sentience, the capacity to actually experience a valence is one of the things that's probably
driven the process of broader cognition and evolution in the first place. He puts that
concept or the ability to feel things, feel good, feel good, bad, how am I doing now in this environment
as quite central. I guess that's the way I think of sentience as being just that capacity to have
an experience and to value it from yourself, whatever yourself is. But I guess another reason,
another potential research project links to our next question, which is that these things also
seem to have some quite deep moral or ethical significance too, and we'll come back to that.
But I guess those are two of the reasons why those sometimes problematic concepts, and I certainly
don't think they're binary in any sense, they're still a drive for us to understand and dig in.
So what do you think about those sorts of challenges about? Because you could go to a point
of view where you never talk about sentience and consciousness or subjective experience in
those senses at all, and you stick purely with a more neutral description of cognition and
agent spaces and Markov blankets. Do you feel that there is some meaningful pull to delve into
and better understand those ideas of sentience and consciousness in their own right? Or how do
you think of this? Yeah, well, I think those are essential. My resistance to binary categories is
not to kind of reduce these aspects that you're talking about at all. On the contrary, it's to
have a better understanding of them and their potential. I get a lot of pushback from both
directions. So I get mechanistic, supposedly reductionist scientists who say, well, this is
crazy, your painting feelings onto cells and chemistry is the best kind of explanation. That's
not really reductionist, because then if you say, well, you mean quantum foam, you want to talk about
quantum foam, they say, nah, that's not it, it's chemistry, it's got to be chemistry. So they've
picked the level, okay. But I also get a lot of flak from the organists, which, and I consider
myself in the organist tradition, but who say, look, by putting non-living things such as
physical objects and computers and whatnot on that somewhere on that spectrum, you're
undermining this battle that we've had for hundreds of years to preserve the magic and the
importance of life and of inner perspective and so on. I don't think understanding these things
better and understanding how they scale up reduces the importance or the majesty of the obvious
sentience of living beings. I think much like with any kind of science, it helps us to understand
what we are and what our potential is and what we need to do. I think that this weird obsession
with chemistry and with physics, too, is what undermines the efforts to really understand this.
I'll give you a simple example. Well, two examples. One is, I often hear people say this,
that's not real goals, real preferences, real valence, real anything. That's just,
it's just following the laws of physics and chemistry. Well, guess what? If you were to
zoom in to your brain or the rest of your body, guess what you would find? You wouldn't find fairies,
you would find physics and chemistry. If you found fairies, they'd be following the laws of
physics, too. They would have to be following something. I'm not against that. If you have a
model of people sometimes email me, what about the soul? I say, bring it on. If you've got a model
of the soul, explain how that works and how that solves these problems and we're good to go. The
problem is, I've never seen such a model, but the question, I always bring it back to the
paramecium or a single cell. Do you or do you not believe that that thing has, to some small
extent, a preference about what happens? If you do, then we simply point out that, well, look,
it's very clearly made of a set of interacting chemicals. At some point, we'll be able to
reconstitute one. So what's the issue? If you don't, then you have to explain to me what happens in
embryonic development, where you actually go very slowly and gradually from a single cell
into whatever it is that we are. And again, there is no magic lightning flash that converts
the chemistry of the oocyte into the mind of the adult human. So this continuity, you can't escape
it. What we owe is not a story about magic bright lines. We owe a story about scaling.
And the other thing that I think is really curious, and it's kind of, I don't know if
it's my upbringing with too much science fiction or what, but I find it really amazing. There was
a great scene in a movie called X Machina. And there's a great scene in that movie where
the protagonist is now so confused by this AI that he's been dealing with that,
he's standing there in front of a mirror and he starts cutting his arm because he wants to see
if he is a robot too. And it's very important to him. This is critical to him. He's very
stressful. And I get emails all the time also from people who say, I've read your paper. I
understand now that I'm a walking bag of cells. Now I'm depressed. I don't know what to do with
myself. This is terrible. And then let's just unpack this cutting your arm thing. So what that
means is if you were to find, so you cut open your arm and you find a bunch of cogs and gears,
you've had, you know, I don't know, 40, 50, however many years of experience in your own skin,
being an agent, exerting effort towards various outcomes and having moral quandaries and having,
you know, Qualey and all these things. And when you see those cogs and gears, what you're going
to decide is none of that was real because I am committed to the idea that cogs and gears can't
support it. This is so bizarre to me. And it's bizarre because we don't know what cogs and
gears can and can't support. You know, why are you so attached to protoplasm and proteins and
whatever else is inside you over something else that you might find? What do you think you know
about those things that overrides your primary experience as a human? It's just, it's amazing
to me that what people naturally tend to say is, okay, well, then I guess I'm not real. I'm not
important. I can't do all of the amazing things I was going to do versus, wow, I guess I just
learned something great about cogs and gears. Look at that. You know, I guess cogs and gears
can do it. They're not too much more shocking than finding out that proteins and carbohydrates
and whatever else is in our bodies can do it. Yeah, and neurons firing. Yeah, but people are
so committed to simple, well, to two things. First of all, to the idea that if your parts obey the
laws of physics, then you are somehow reduced, which I think this allegiance to a low level of
description, I think it's completely arbitrary. Dennis Noble does a really nice job in his work
on against privileged levels of causation and things like that. And then the idea that we know
what various kinds of materials and architectures can do. We have absolutely no idea. This actual
field is that despite the rest of science is at a very young stage. We do not know. There are
not just emergent complexity. So everybody studies emergent complexity. That's been around
for a long time. It's not emergent complexity here. It's emergent goal-directedness and
emergent cognition. And that happens. And even in very simple systems, it surprises us constantly.
We are not good at predicting it. We are not good at creating it yet. Well, I should say we may
create it unwittingly all the time. And so people who say, you know, I know what this is because I
made it, I think that's a really dangerous idea because you don't know what something is just
because you made it or because people say this a bunch of language models or whatever. Just because
you know the parts that went into it, we do not yet know what it is, what it can do and how important
is the inner perspective and what kind of inner perspective it has. So yeah, I think a lot of
humility here is needed and a letting go of this idea that the right level of description is chemistry.
And you know, I think it's fine that that's there. It does not tell the whole story in any practical
way. Yeah, thank you. You need to understand that these things run and operate at different levels
and interlocking levels here. Well, very specifically, the business of physics and
determinism, right? One of the key issues here is that determinism is well and good if what you're
interested in doing is looking backwards. So something has happened, and you're going to tell
a mechanistic story of why it happened. And then you can always do that. That's always on the table.
So you zoom down and you say, look, this person did that because these neurotransmitters Zygden's
agged and they did that because of the electron forces and all of this stuff, right? You can always
tell a story going backwards. But that isn't what we're interested in both as humans and scientists.
We're interested in going forwards as in, what can and should I do next? And what can I invent
or how can I increase my understanding next? And that is a completely different kind of task.
So here's one of my favorite examples. The game of life, cellular automatons, right? So you've
got three simple rules that dictate how the state of each cell is going to be on or off
based on what its neighbors do. Okay, so just a simple two-dimensional grid, isn't it? Completely
simple. Yeah, super simple, two-dimensional grid that the cells are on or off and it's
fully deterministic. Okay, there's not even an Easter Caster City here. So every cell in every
tick of the clock, each cell becomes on or off based on how many neighbors it has. That's it.
Now we know and if anybody in the audience hasn't seen it, look it up and you can see these amazing
things that happen, right? So emerging complexity is very strong here. And if anyone hasn't played
with it, I'd recommend go and find some of the online tools because you can play with this stuff
yourself. Yeah, it's mind-blowing, yeah. Absolutely, absolutely amazing. And so now look,
you can imagine being a reductionist determinist about this world and say, so for example, one
of the things that happens in this world is there are things called gliders. So gliders are patterns
that are a particular shape and the shape moves across. Now to be clear, nothing actually moves
across, the cells are just turning on and off, but the pattern itself, it's like a wave in the,
you know, the pattern itself moves and those are called gliders. So now you could be a reductionist
about this and you can say, look, there are no gliders. All there is are the individual cells,
and I can tell you precisely which cells are going to come on and off. And the fact that you
think you see gliders is an epiphenomenon. It does nothing in the system. There are no gliders.
All it is is the rules. And that isn't exactly wrong because the physics of the world are quite
clear, but it's absolutely limiting in the following way. If you don't believe in gliders,
you can predict the next state of whatever state I set up in the game. You can tell me exactly
what's going to happen next. There's no escape from that level of determinism. But here's what
you won't ever do. You won't ever build a Turing machine made out of gliders, as somebody did.
Somebody designed a pattern that does computations by sending gliders back and forth.
If you don't believe in gliders, you're not going to do that. It poses off that level of
inventiveness. So looking, so a key thing about these higher levels is that they enable you to
have a richer relationship with the system going forward, not just explain what happens backwards
after somebody's done the interesting work of preparing a system for you.
Yeah, it's fascinating. And the idea of a universal Turing machine is essentially a computer that can
carry out any computation given enough time and enough resources. And this is from individual
cells linking on and off based on a super simple rule set, clicking forward all the time.
And I don't know if this is right, but I like the difference between this idea of determinism
looking backwards and looking forwards, because in a sense, it's the same deterministic mechanism
going forwards. But for it to be useful, we need to actually shortcut whatever that deterministic
computation is going to be for us to be able to predict. And to do that, we need to understand
patterns at different levels. And sometimes we can't do it. Sometimes the thing is
computationally irreducible, such that the only way of finding out what's going to happen is to
let the process run or to create a simulation that's so perfect, you basically just duplicate
the reality. So even if it's conceptually deterministic in the future, that doesn't
necessarily help you anticipate. And the idea of these high level concepts, as you said,
give you useful tools in your relation to these phenomena to anticipate maybe the future and
understand the past. Yeah, and control what happens next. So as a simple and some of these
systems, the cool thing about living and other kinds of systems of this type is that they offer
this kind of shortcut. So here's a simple example. Imagine that you had a rat and you wanted him to
do a simple circus trick. I don't know, sit on a little bicycle or something. One thing that you
might do from the level of chemistry and physics is you might say, okay, so I want the muscles to
move in this particular way. I need to calculate which neuronal impulses are going to move exactly
these muscles to do it. I need to trace it back into the brain, figure out all the circuits,
how everything is going to propagate through the brain and figure out which pixels on the retina
I need to stimulate with various images shown to the rat to get him to get on the little bicycle.
If you try to actually, so that's completely computationally intractable. If you try to do
that, the sun will burn out long before you actually get it done. But there's an amazing
thing here, which is that you can just train the rat. And that's because the rat has a particular
cognitive causal architecture that hides all that stuff. And it takes on all the complexity
of figuring out how should my internal parts be arranged in order for meaning, meaning all the
different neurotransmitters and everything else, how should that all be arranged in order to achieve
a particular goal. So the way you do this is you get the buy-in of the rat, you make your goal,
the rat's goal, and then the rat does all the hard work for you. You don't have to calculate
all this stuff forward. So one of the things that understanding the large-scale capabilities of your
system is critical in having a productive interaction, a predictive, powerful productive
interaction going forward. And this is something that I think is the rate limiting step right now
for regenerative medicine. Because in biology and biomedicine, the standard operating assumption
is that cells are mechanical agents. All the excitement is about the hardware. So CRISPR,
genomic editing, pathway rewiring, everything is down at the level of hardware. And that closes
off a huge number of potentially really powerful interventions, which things we're doing in our
lab like cellular training, exploiting cellular problem solving. Because if you insist on
viewing systems from that low-level perspective, not that it's wrong. I mean, that perspective is
there. It's there for you to take. But it limits you. Reductionism is well-named. It reduces what
you can do. It reduces your ability to really exploit what's powerful about these systems.
And we are leaving so much on the table by refusing to test out the tools, the interaction tools that
we have and that have been used for... This is why humans train to dogs and horses for thousands
of years knowing zero neuroscience. It's because these systems make it accessible, make that whole
process, the goal rewriting process so accessible. They offer that beautiful interface, that learning
interface. So cells and tissues do this too. And if you refuse to test those hypotheses,
you leave a lot on the table. Yeah, thank you. So these ideas of sentience and consciousness
are very important to you still and not things you discard. But you refuse to say they're binary,
they're on or off switches. If there are boundaries, they're fuzzy. And in your sense,
there may not even be a boundary at all. Ultimately, it may just be a question of
degree across every possible system. But that doesn't destroy their meaningfulness. Because
there's a sense, I think, with some people who have a very expansive
view of consciousness, that they either reify it in some sense. Again, they pull it away from
the physical and that can lead people into, again, back into some sort of mystical or soul-based
ways of thinking about it. Or they declare it universal, as some might say, you would,
because you're saying, well, it's a spectrum and there's no real end to the spectrum. So in a sense,
maybe everything shares in these characteristics to some degree. But by declaring it universal,
they almost destroy what's meaningful about the concept. And it sort of flattens out. And I don't
think you're doing either because you're recognizing that while you don't want it to make it binary,
there's still something distinctive that you can describe in terms of how we relate to these entities
and what these concepts can help us understand about these entities. So it retains their meaning.
Yeah, it's not just for explaining. It is essential and useful. My claim is that
ideas about cognitive capacities and unfamiliar contexts and unfamiliar embodiments
are essential. They're practical and they're essential. This is not philosophy. It's not
some kind of feel-good mysticism. My claim is, and it's a testable claim that we've been testing
for now for 20 years successfully, is that it helps you do better in the empirical world.
I mean, the best thing I hope my lab does is on their best day, what I think we're doing is taking
these ideas from deep philosophy that people have argued about for thousands of years
and bringing them to the bedside, to the clinic. And these ideas are empirically essential to get
the kind of outcomes that you want. So I don't know what more we can say about why these ideas
are real. Because by taking that inner perspective, by asking what do cells remember? What do they
care about? What is the size of their goals? What are their goals? These are questions that
lead directly to therapeutics. They lead to work in regenerative medicine and cancer.
I don't know what more evidence we could have that these things are critical. And
the other issue is that this idea that if we start to apply the tools that we use with
cognitive systems, we try to apply them elsewhere, that that kind of leads to some sort of sliding
creep that devalues our own cognition and our own majesty, that's a weird zero-sum game that I don't
buy into. I am in no way diminished by, I don't feel in any way diminished by the idea that there
are basically an infinitude of other minds, highly diverse minds, endless sentient forms throughout
the universe. And I think I'm certainly here on earth that are also having experiences that
strive and suffer to various degrees. I don't think that diminishes us at all. It seems childish
to somehow pin the quality of what we have on the fact that no one else has it. That just seems,
I don't know why we need to make that move. I think what we have is essential. I think
understanding it is essential so that we can scale it up. I would like to scale my cognitive
capacity. I would like humanity to scale its cognitive capacity more specifically,
not just the intelligence, but the radius of concern, of care, and of compassion. I think
we need to scale that up and you only do that if you understand what it is that you're scaling.
You've done the perfect segue into our second question about the ethics. And what I might do
is collapse these questions of what matters and who matters just into one. Because in the big
questions of ethics, in a sense, there are a bunch of different choices. You can take a nihilist
route where you sort of give up on the idea. You can take a relativist approach where you
think about ethics as just sets of rules that groups have negotiated in a more transactional
relational sense, but there's no real truth of the matter about whether those rules do
good or bad. You could follow a divine command theory going back to our early conversation
where you could turn to the Bible or the Quran or some other source of supernatural authority and go
basically following those rules or being obedient to that deity is the ultimate arbiter of what's
good or bad. But if we put those aside, and personally, I think we should, whatever sort of
moral philosophy we have, whether it's about rights and day ontology, or whether it's about
consequences and utilitarianism, whether it's about feminist care ethic, where we have relations of
care, whether it's about virtues, whatever the system is, they do all seem to share
a sort of common sense ethical core, which is that somehow morality is about
whether and how we care about others. And the obvious question then is, okay, well who gets
to count as another? That's really our who matters question. And again, I and this podcast have a
bias because we tend to focus on this idea of sentience as being the qualifier in that
for an entity to count as another, they need to have their own perspective within which
they value their own experiences, states, interests, and lives, I guess. And because they
value those things themselves, that's the rationale for us also caring about them. Because in a way,
if morality is about caring about others, let's care about all of the others that have their
own perspective and so qualify as others. So it's almost a little bit secular. But anyway,
that's, that's I guess the starting point from a centio centric ethic is to care about all of
those others. But I'd be really interested in your own thinking about either the sort of foundations
of ethics, right, wrong, and good and bad. But also given what we've talked about so far,
how you think about moral scope and who gets to count and what are the implications of that?
And what what journey have you gone on through your life so far and thinking about those big
questions? Yeah, well, you know, it's it's somewhat beyond my pay grade to try to lay out a global
theory of ethics for everybody else and so on. That's, I won't try to do that. But but I will,
I will give you some thoughts and how I think about these things. A couple things. First,
I think it's, it's important to not pretend that once we understand how sentient something is,
we are automatically good at treating it ethically. Okay, so we know that's not the case. We factory
farming, you know, we all know, we all know pigs are our biggest value of their own, their experience
that they feel pain, all that. And yet here we are. So so so I think what we know and and how we
treat them are not unfortunately the same thing. But but but certainly, we should we should have
a principled way of apportioning our relationships with with other with other beings of all different
kinds. I think that moving forward in assuming assuming we all, you know, survive the next
few decades, I think moving forward for the flourishing of humanity of ecosystems of other
beings on earth really requires the deep lessons of diverse intelligence. I think we need to understand
that there is no such thing as a magical standard human that is the the the subject of all these,
you know, philosophical arguments. For first of all, because, because evolutionarily, we have a
lineage going back to single cells. So anything that you think about human responsibilities,
whatever, well, how about a human of 200,000 years ago, about 500,000 years ago, you know,
where where was it, right, where how did it get here, and so on. So all of those things are
continuous. The same thing is true of embryonic development, you can ask how these things showed
up over in your journey from from an OSI to a to a being. And all of the the current discussions of
neuro atypical humans and, you know, the bodily modifications that some people do,
these things are going to be laughable to the to the humans of the next couple generations in
their in their minor sort of degree of this their timid degree. I mean, you're going to have humans
that are so modified in body and mind, you know, cyborgs, hybrids with various biological and
technological changes, that it's going to be completely obvious. You know, right now, we're
kind of lulled into a fault. Well, we have been for for centuries, lulled into a false sense of
security in the sense that it was easy. You know, before you could say, does it speak? If it speaks,
then it's it's like us, and even even that humanity fails, you know, we've, we were really
terrible to each other for much more, much smaller differences. But but but you could, you know,
you could say, where did you come from? Meaning, were you evolved? Or did you come from a factory?
And you could sort of knock on something. And if you hear a metallic clanging sound, you say,
okay, we know, we know how we're going to deal with this. And if you're hardly, you know, some
kind of soft and kind of a thud, then that's something else. Those categories were never
any good, but they served us kind of okay for a long time. Those are gone. Those are those are
gone. Now they're going to be left in the dust by the next couple of a couple of decades. It's
going to be essential that we learn to have an ethical, I call it synthbiosis, with other beings
that are nowhere with us on the tree of life, they are modified in body and mind. And what you
look like and where you come from simply cannot be the foundation for how we're going to relate to
each other. And again, science fiction dealt with this a long time ago. But but somehow,
people today have lost sight of some of those things. You know, again, the current debates over
AI, it's very easy to say that language models aren't this and aren't that. And I'm not a defender
of any particular view of sentience and language models. Although more generally, I don't believe
we really know what we have once we've made it. But but but the thing is, those kind of language
models, they're so different from us, that it's very easy for people to say, Oh, that's not that's
that's not the things we want to care about. What are you going to do when you're confronted with
humans that have, you know, 51% of their brain replaced by by various silicon appliances. And
and you know, they're linked together with other people and also a few, a few AIs and
some things like that. So all of this is coming. It is, we are going to have to develop a more
better better more principled ethical frameworks for for dealing with it with with beings that are
just very alien, you know, in their construction. And so that means that you need frameworks to
understand what's in what what do all these beings have in common. And this is something that a few
years ago, I developed this notion of a cognitive light cone to try to get away from the idea of
what kind of material embodiment you're in and instead focus on what are the things you care
about what's the what what is the size of the biggest goals you can you can you can pursue.
And regardless of your of your embodiment or implementation or origin story, and that kind
of a thing at least begins to give us a way to to a portion our degree of moral concern
to beings that are capable of pursuing goals and and and having, you know, various kinds of
competencies of navigating problem spaces and and and suffering when those goals are not
are not made are not are not reached. So that that for that reason, I think, you know, I think I
think the the diversity of what we who and what we think counts is going to be enormous. And
this business of language models and and so on, it's just it's a distraction from a much
much deeper puzzle. Yeah, thank you. And one of my previous guests, Josh Gellis has done quite a
lot of work in that space about thinking about potential artificial intelligences and sentience
and so on. And actually, he's quite challenging about the idea of sentience, because he's worried
it's seen too much as a sort of easily isolatable property that we will then deny to, for example,
artificial intelligence and robots and so on. And he prefers a much more relational approach,
which we can go back and forth about the risks and the challenges of that. But one thing I do
agree with him. And I think you is that we're going to be forced into working this stuff out,
whether we like it or not. And I think it will open up and radicalize the way we think about what
it is to be another and and that need to appreciate radically different perspectives from different
beings. But but I was really glad you mentioned animal agriculture, because one of the frustrations
with many people who are involved in sentientism or the worldview is that there's a frustration
in the current zeitgeist that people seem really excited about talking about artificial
intelligences and artificial sentience and whether robots could ever feel something and
become moral patients. But people seem to conveniently skip over the hundreds of billions,
if not trillions, if we include aquatic, non human sentient beings that we brutally exploit today.
And it's and it's a really interesting case study, because
I think when you take a naturalistic epistemology, and you understand the facts of what farming
and fishing are like, not just factory farming, but all of it. And you take the ethical perspective
of the beings that are going through those processes, it quite easily leads you to a point of
quite extreme ethical condemnation of what's going on in those situations. But our society
is trained us to think this so normal that there's a brutal clash between, you know,
if you like the epistemology and the centiocentric ethic and today's social norms. I was thank you
for mentioning that. I mean, so a couple of a couple of things there. What one is that,
yeah, I mean, you're absolutely right, of course, in in in talking about these AIs,
and instead of other problems with the with the existing life forms is a huge issue.
It also comes up when people say, Oh, wow, we're, you know, we're going to make these high level
intelligences. And who knows how they'll be raised and what they're going to do in the future.
I mean, you've heard of having kids, right? Like, like, I'm just, you know, we do this all the time,
we have an enormous amount of guaranteed high level intelligences that created all the time
and a huge diversity of good and bad environments that they're raised in. We have a very limited
ability to make sure that they are they have a good embodied experience and are aligned with
our values. And some of them go on to do wonderful things. And some of them go on to, you know,
to do horrible things. That's already an issue. We already have that the thing with so these
in many in many ways, these problems are not new problems brought on by AI, their perennial
existential problems that humanity has felt it has faced forever, you know, in terms of being
supplanted by the next generation that finds your values, you know, irrelevant, and how much control
do you want over how your neighbor is raising their kids and all these kinds of things. This is,
this is, this has been with us with us for the longest time. The one, the one unique thing about,
about AI intelligences, though, is that they can be copied in a much easier fashion, they can be
reproduced and copied in a much easier fashion than real animals. And I think that now, now while
there are some good debates about whether something that actually can be copied even counts in this
case. So, you know, there's a few arguments that that's not an issue. But, but, but I'm not sure
yet. And I think that for that, for that reason, because there's just going to be such an uncountable
number of intelligences of the software variety, whether embodied or not, it's something that we
need to, we need to consider, you know, and I'm hopeful that with the advent of different, different
ways to grow food proteins and so on, we're going to eventually completely just, you know, do away
with, with animal farming and so on. But the creation of novel synthetic organisms is only
going to increase. And I mean, you know, digital or embodied or not. So, so that's, you know,
I think we need to, we need to focus on both sides of both sides of that equation.
Yeah, I agree, agree. And I don't know if you've, you're thinking on that has led you down the path
of boycotting animal agriculture and its products so far, or whether I can help you offline on that
path. But yeah, why don't we, why don't we, why don't we talk offline? That's good, sounds good.
So the other ethical question I wanted to touch on with you is how that bears on your own work in
the lab, because you do work with a variety of different entities, animal and non. How does that
play in because you're into your choices, because you're working with some very simple organisms,
and you're working with more complex organisms as well that would have richer experiences. How do
you think about that? Again, I won't take you through it in depth, but I'm interested in
sort of simple perspective you take on animals and research.
Yeah, yeah. Well, first, just to say that animal use and research is incredibly stringently
regulated. So in order to do the things that somebody would do when they go fishing for an
afternoon, we have three months of paperwork and oversight by veterinarians and ethicists and all
that. So there is a huge amount of oversight as there should be, I'm not in full favor of that.
But this is something I think that's really important and it gets to this issue of what
matters. A lot of folks see scientific ethics in the following way. Everything's great,
and you scientists better not screw it up, right? So here's a long list of things we don't want you
to do. We don't want this, we don't want that, don't make things worse. Now that could, I suppose,
could have been a viable worldview when people believe that our current world is in some way
set up in the right way for us. In other words, it is the best possible world, everything is great,
now don't screw it up. What we now know is that that's not the world we live in. We are the process
of meandering evolutionary path. Evolution, as far as I can tell, does not optimize for any of our
values. It doesn't optimize for happiness, for intelligence, for any of that stuff.
We are where evolution dumped us with all of our ridiculous susceptibilities to
bacteria, viruses, lower back pain, stray cosmic rays that might have hit a DNA molecule
during development and now your potential is radically limited.
When you broaden that scope out to all of the potentially sentient beings, that
just becomes even stark, right? If there is some tealoss to this
universe, it's a pretty brutal one.
Yeah, it is. There's no doubt. I'm not even a clinician, but the amount of emails that I get
every day from people with the most unbelievable examples of biomedical suffering is just incredible.
So I think it is utter moral cowardice to focus on what we shouldn't do and as opposed to our duty
now that we have, for the first time, I guess, on Earth, we have the ability to actually rationally
approach these matters to try to guarantee a better embodiment for sentient beings on Earth.
The number of people that are suffering because of our ignorance, because we don't
know what to do, and also because of our timidity and our unwillingness to take responsibility
we are the ones that are now, it is on us now to improve this for people.
And not just people, for ecosystems, for other beings, for just the amount of ignorance and
inaction that is letting a sentient being suffer worldwide is incredible. And so I take animal
use ethics extremely seriously, but I think to the extent that it is our responsibility to relieve
the suffering worldwide, science has to go on, and we have to do experiments that are going to
enable us to improve embodied experience for all. The Buddhists have this concept of an inauspicious
birth, and it's this idea that in one of your many lifetimes you're born in a body during which you
just can't make progress towards enlightenment. I think at this point, I know this is a controversial
view, but I think basically right now every birth is an inauspicious birth. All of us are limited by
the vagaries of random mutation and selection and all these dumb things, all these dumb things that
have no one's best interest. And I think in the future, sometimes I imagine this dialogue that
children in the future are going to have with their teachers, the kind of thing where you
tell the kids, yeah, we wrote on chalkboards, and we didn't have cell phones, and they're like, what?
And so they're going to say, you're telling me you would just have to stay in whatever body you
randomly got. And if you had some sort of defect, you just have to live that way. And if the IQ
and the lifespan that you were born with wasn't enough to fulfill your goals, that's it. You just
had to, that was your bad luck. That will be unthinkable to a modern humans going forward.
And in a way, that's a beautiful link into the final question, which is how do we make a better
future? Which is what, you know, what are the promises of these types of research and thinking?
Yeah, I mean, I think, ultimately, from the kind of the bigger picture, for me, is freedom of
embodiment. I think that every sentient being should have the, and we need to, we should offer
assistance in the same way that we offer assistance to beings via education, via, you know, support
of every kind. We should be in a position to offer the ability for sentient beings to have
better embodiments to fulfill their potential, their goals, and so on. Practically speaking,
what that requires is complete control over growth and form. It means that we need to really be able
to direct what it is that cells build. Now, right now, that just looks like regenerative medicine
in the sense that if we knew how to get cells to build specifics as anatomical structures,
then birth defects, traumatic injuries, cancer, aging, degenerative disease, all these things
would go away if we could communicate our goals to groups of cells. And this is something that
we and some other labs are working on now is this kind of, you know, this idea of an anatomical
compiler where you can just specify the shape of the structure that you want, and it gives stimuli
to cells to make them grow exactly that. And again, linking to what you said before, this is
different from the classical ideas of genetic engineering or, you know, what you do with
CRISPR and so on. This is a different mode of engagement with a system. Yeah, the goal is
similar because certainly people, you know, at the time that genetics was getting off the ground,
this is a vision that people had then too, that if we understood the genetics, we could control
the shape. I think we have a much more practical path to it because I think the genetics specifies
the hardware that every cell gets to have, so the proteins. But as we know from the advances of
computer science and information technology programming at the level of hardware, while
possible, it's really hard. And if you have good hardware that's actually reprogrammable and offers
high level interfaces, you know, you might say APIs, which I think is exactly what it offers,
then you can do this in a much better way, specifically by honoring the agency of the cells
and tissues and being a collaborator with them. We don't micromanage our cells and tissues here.
I mean, in my group, we basically collaborate with them and modulate their goals and take
advantage of their competencies, their problem-solving capacities, their memories and so on.
So I think that is a way to move the field forward much faster. I think that CRISPR and
those kinds of things are going to flatten out soon because after you've picked the low-hanging
fruit of single gene diseases, the next question is going to be, well, what genes do you add
to make the changes, the anatomical changes you want, and development's not reversible in that
way. You can't just figure out what, in any easy way, what to edit. So I think taking advantage
of the interfaces that cells use to hack each other is critical. But initially, that just looks
like reprogramming tumors and regrowing limbs and growing new organs and so on, all of which,
by the way, we've done here in various model systems. But ultimately, it leads to freedom of
embodiment. It means that if you want to have a different embodiment, you can. And if you decide
you want to change it, you should be able to do that too. There is no reason any of us should be
stuck in the embodiment that we got, including IQ and lifespan and all those things, because
those things were not chosen with your welfare in mind. They were a long process that would
shape by forces that don't honor any of our values. Yeah, thank you. It's quite a vision.
And it will lead to some of the things I've touched on with some of the people who are interested in
the transhumanist space like David Pierce and so on as well. And again, it's that freedom of
embodiment for human and non-human sentient beings that is, to put it a different way,
shaped by their own values and aspirations and experiences rather than constrained by
inherited biology and freeing from some of those constraints. But some of my audience
will love that sort of vision and see the potential. Others will be nervous about
classic problem of human hubris and intervening where we're not really ready to intervene.
What do you think of the risk profile and the approach you're taking? Are there risks we need
to watch out for that we need to build in? For sure, there are going to be risks, but I'm pushing
in the very opposite direction of the hubris. My argument isn't that everything is great and then
in an effort to make it even better, we're going to screw things up. And we may screw
some things up. It's pretty inevitable. My argument is that things are so bad right now for so many
that it is a moral imperative. We do not have the luxury of saying, don't do this.
Denaction is a choice too.
Exactly right. The opportunity cost of doing nothing is massive. It's absolutely massive. And
this idea that we don't have to do anything because we can let things go how they are now,
that's simply not acceptable. That opportunity cost is too huge. So yes, we're going to make
mistakes, but anybody who we know from our personal lives, if the thing that you are most
optimizing is to never make a mistake, what's going to be the value of your life and all the
huffing and puffing that we do during our brief time here? What's the goal? Obviously,
you want to minimize making mistakes, but I believe there should be a constructive element
to this where you have a purpose to elevate and help others. And that is not going to happen by
focusing on the things we shouldn't do. And just more broadly, I ask people who focus on this negative
kind of risk-based perspective, what does humanity look like 100 years from now? Are we still getting
lower back pain and bad knees and dying into our 80s once we've gotten a little bit of wisdom
under our belts? That's it. And if you happen to some cosmic ray or something hits one of your
chromosomes, then are we still living like that? I can't imagine. That would seem like such a waste
of this incredible gift of intelligence and compassion that we have that it seems ludicrous
to me. But anybody, I think people should spend time painting the future that they do want.
Everybody's already written down all the things they don't want. That's fine. Now,
paint me a picture of what do you want? Where should we be 100 years from now?
Yeah, thank you. I'm a sucker for a bit of utopian thinking. I know you're a fellow sci-fi fan as
well. And some people will use that as a way of discarding some of the ideas you're working on
and saying it's just sci-fi. But I think sci-fi has got a lot to teach us. I often find better
philosophy in sci-fi than I do in actual philosophy. And one of the things about sci-fi is it's very
good at sort of intuitive sentientist starts because it's so common and just natural and even
unthinkable in most science fiction stories to recognize the salience of sentient beings that
are radically different from ourselves. And I think there's a lesson there we can take too.
For sure. And sci-fi, to me, if somebody says, this is just sci-fi, my question is very simple.
Are you saying it's impossible or are you just saying it's going to take a while?
For certain things that maybe, I don't know what those would be, but there are certain things that
may be physically impossible. Fine. Everything else is just a time to then we're just quibbling
over a timetable. Everything that's possible is going to be done. And there's dystopian sci-fi,
but there's also utopian sci-fi. So yeah, like I say, paint those pictures. Well,
it's been an inspirational conversation. Thank you so much for talking to me today, Mike.
What's the best way of people following you, finding out more about your work? I'll include
links in the show notes, of course. But where's the main place you point people? Yeah, the official
lab website that has all of the kind of peer-reviewed hard stuff is drmike11.org.
One word, drmike11.org. The more speculative, you know, the photography, the pros and all
that stuff. And so just some thoughts that I wouldn't, you know, I wouldn't put in a scientific
paper is at thoughtforms.life. It's a blog called thoughtforms.life. And I'm on Twitter at at
drmike11. Yeah, that's awesome. Thank you. And I'll follow up with some vegan tips offline.
Cool. That would be great. I appreciate it. All right. Well, thank you so much for being a guest
on Sentientism. It's been a pleasure, Mike. Take care. Enjoy the rest of your day.
Thank you, you too. Please stay in touch.
