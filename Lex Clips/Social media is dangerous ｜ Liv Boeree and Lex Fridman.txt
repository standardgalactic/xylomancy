You did a great video on Moloch on one aspect of it, the application of it to one aspect.
Instagram beauty filters.
Through.
Very niche.
I wanted to start off small.
So Moloch was originally coined as well, so it's apparently back in the like Canaanite
times.
There was an ancient Carthaginian, I can never say Carthaginian.
Somewhere around 300 BC or 280, I don't know.
There was supposedly this death cult who would sacrifice their children to this awful demon
god thing they called Moloch in order to get power to win wars.
So really dark, horrible things, and it was literally like about child sacrifice, whether
they actually existed or not, we don't know, but in mythology they did, and this god that
they worshiped was this thing called Moloch.
I don't know, it seemed like it was kind of quiet throughout history in terms of mythology
beyond that, until this movie Metropolis in 1927 talked about, you see that there was
this incredible futuristic city that everyone was living great in, but then the protagonist
goes underground into the sewers and sees that the city is run by this machine, and
this machine basically would just kill the workers all the time because it was just so
hard to keep it running, they were always dying, so there was all this suffering that
was required in order to keep the city going, and then the protagonist has this vision that
this machine is actually this demon Moloch.
So again, it's like this sort of mechanistic consumption of humans in order to get more
power.
And then Alan Ginsberg wrote a poem in the 60s, which incredible poem called Howl about
this thing Moloch, and a lot of people sort of quite understandably take the interpretation
of that, he's talking about capitalism, but then the sort of piece to resistance that's
moved Moloch into this idea of game theory was Scott Alexander of Slate Style Codex,
wrote this incredible, one literally, I think it might be my favorite piece of writing of
all time, it's called Meditations on Moloch, everyone must go read it, and...
Slate Codex is a blog.
It's a blog, yes, we can link to it in the show notes or something, right?
No, don't.
Yes, yes, but I like how you assume I have a professional operation going on here.
I shall try to remember to...
What are you, what are you, what are you, what are you, what, you're giving the impression
of it?
Yeah, yeah, I'll like, please, if I don't, please somebody in the comments remind me.
Oh, I'll help you.
If you don't know this blog, it's one of the best blogs ever, probably.
You should probably be following it.
Yes.
Are blogs still a thing?
I think they are still a thing.
Yeah, he's migrated on to Substack, but yeah, it's still a blog.
Substack, better not fuck things up.
I hope not.
Yeah, I hope they don't, I hope they don't turn Molochie, which will mean something to
people when we continue.
When they stop interrupting for once, that's good.
So anyway, so he writes this piece, Meditations on Moloch, and basically he analyzes the
poem and he's like, okay, so it seems to be something relating to where competition
goes wrong.
And you know, Moloch was historically this thing of like where people would sacrifice
a thing that they care about, in this case, children, their own children, in order to
gain power, a competitive advantage.
And if you look at almost everything that sort of goes wrong in our society, it's that
same process.
So with the Instagram beauty filters thing, you know, if you're trying to become a famous
Instagram model, you are incentivized to post the hottest pictures of yourself that
you can.
You know, you're trying to play that game.
There's a lot of hot women on Instagram.
How do you compete against them?
You post really hot pictures and that's how you get more likes.
As technology gets better, you know, more makeup techniques come along.
And then more recently, these beauty filters, where like at the touch of a button, it makes
your face look absolutely incredible compared to your natural face.
These technologies come along, it's everyone is incentivized to that short-term strategy.
But over on net, it's bad for everyone because now everyone is kind of like feeling like
they have to use these things.
And these things like they make you like the reason why I talked about them in this video
is because I noticed it myself, you know, like I was trying to grow my Instagram for
a while.
I've given up on it now.
But yeah.
And I noticed these filters, how good they made me look.
And I'm like, well, I know that everyone else is kind of doing it.
Go subscribe to Liv's Instagram.
Please.
So I don't have to use the filters.
Post a bunch of, yeah, make it blow up.
So yeah.
You felt the pressure actually.
Exactly.
These short-term incentives to do this like this thing that like either sacrifices your
integrity or something else in order to like stay competitive, which on aggregate turns
like creates this like sort of race to the bottom spiral where everyone else ends up
in a situation which is worse off than if they hadn't start, you know, than it were before.
Kind of like if, like at a football stadium, like the system is so badly designed, a competitive
system of like everyone sitting and having a view that if someone at the very front stands
up to get an even better view, it forces everyone else behind to like adopt that same strategy
just to get to where they were before.
But now everyone's stuck standing up like, so you need this like top down God's eye coordination
to make it go back to the better state.
But from within the system, you can't actually do that.
So that's kind of what this MOLIC thing is.
It's this thing that makes people sacrifice values in order to optimize for the winning
the game in question, the short-term game.
But this MOLIC, can you attribute it to anyone centralized source or is it an emergent phenomena
from a large collection of people?
Exactly that.
It's an emergent phenomena.
It's a force of game theory.
It's a force of bad incentives on a multi-agent system where you've got more, you know, prisoners
dilemma is technically a kind of MOLIC system as well, but it's just a two-player thing.
But another word for MOLIC is it multipolar trap where basically you just got a lot of
different people all competing for some kind of prize.
And it would be better if everyone didn't do this one shitty strategy.
But because that strategy gives you a short-term advantage, everyone's incentivized to do it
and so everyone ends up doing it.
So the responsibility for, I mean, social media is a really nice place for a large number
of people to play game theory.
And so they also have the ability to then design the rules of the game.
And is it on them to try to anticipate what kind of, like to do the thing that poker players
are doing, to run simulation?
Ideally, that would have been great if, you know, Mark Zuckerberg and Jack and all the
Twitter founders and everyone, if they had at least just run a few simulations of how
their algorithms would, you know, different types of algorithms would turn out for society,
that would have been great.
That's really difficult to do that kind of deep philosophical thinking about, thinking
about humanity actually.
So not, not kind of this level of how do we optimize engagement or what brings people
to join the short-term, but how is this thing going to change the way people see the world?
How is it going to get morphed in iterative games played into something that will change
society forever?
That requires some deep thinking.
I hope there's meetings like that inside companies, but I haven't seen them.
There aren't.
That's the problem.
And it's difficult because, like, when you're starting up a social media company, you know,
you're aware that you've got investors to please, there's bills to pay, you know, there's
only so much R&D you can afford to do.
You've got all these, like, incredible pressures, you know, bad incentives to get on and just
build your thing as quickly as possible and start making money.
And, you know, I don't think anyone intended when they built these social media platforms
and just to, like, preface it.
So the reason why, you know, social media is relevant because it's a very good example
of, like, everyone these days is optimizing for, you know, clicks, whether it's the social
media platforms themselves, because, you know, every click gets more, you know, impressions
and impressions pay for, you know, they get advertising dollars or whether it's individual
influencers or, you know, whether it's the New York Times or whoever, they're trying
to get their story to go viral.
So everyone's got this bad incentive of using, you know, as you called it, the clickbait
industrial complex.
That's a very mollkey system because everyone is now using worse and worse tactics in order
to, like, try and win this attention game.
And yeah, so ideally, these companies would have had enough slack in the beginning in
order to run these experiments to see, OK, what are the ways this could possibly go wrong
for people? What are the ways that Molek, they should be aware of this concept of Molek
and realize that it's, whenever you have a highly competitive multi-agent system, which
social media is a classic example of millions of agents all trying to compete for likes and
so on. And you try and bring all this complexity down into, like, very small metrics, such
as number of likes, number of retweets, whatever the algorithm optimizes for.
That is a, like, guaranteed recipe for this stuff to go wrong and become a race to the
bottom.
I think there should be an honesty when founders, I think there's a hunger for that kind of
transparency of, like, we don't know what the fuck we're doing.
This is a fascinating experiment.
We're all running as a human, as a human civilization.
Let's try this out.
And, like, actually, just be honest about this, that we're all, like, these weird rats and
a maze, none of us are controlling it.
There's this kind of sense, like, the founders, the CEO of Instagram or whatever,
Mark Zuckerberg has a control, and he's, like, with strings playing people.
No, they're-
He's at the mercy of this, like everyone else.
He's just, like, trying to do his best.
And, like, I think putting on a smile and doing overpolished videos about
how Instagram and Facebook are good for you, I think is not the right way to actually
ask some of the deepest questions we get to ask as a society.
How do we design the game such that we build a better world?
I think a big part of this, as well, is people, there's this philosophy,
particularly in Silicon Valley, of, well, techno-optimism.
Technology will solve a lot of issues.
And there's a steelman argument to that, where, yes, technology has solved a lot of
problems and can potentially solve a lot of future ones, but it can also-
It's always a double-edged sword, and, particularly as, you know, technology
gets more and more powerful, and we've now got, like, big data, and we're able to do
all kinds of, like, psychological manipulation with it and so on.
It's- Technology is not about values, neutral thing.
People think- I used to always think this myself.
It's like this naive view that, oh, technology is completely neutral.
It's just- It's the humans that either make it good or bad.
No. To the point we're at now, the technology that we are creating,
they are social technologies.
They literally dictate how humans now form social groups and so on.
Beyond that, and beyond that, it also then- That gives rise to, like, the memes
that we then, like, coalesce around.
And that, you know, if you have the stack that way, where it's technology
driving social interaction, which then drives, like, memetic culture,
and, like, which ideas become popular, that's Moloch.
And we need the other way around.
We need it so we need to figure out what are the good memes?
What are the good values that we think we need to optimise for that, like,
makes people happy and healthy and, like, keeps society as robust and safe as possible,
then figure out what the social structure around those should be,
and only then do we figure out technology.
But we're doing the other way around.
And, you know, like, as much as I love, in many ways, the culture of Silicon Valley,
and, like, you know, I do think that technology has, you know, I don't want to knock it.
It's done so many wonderful things for us, same as capitalism.
There are- We have to, like, be honest with ourselves.
We're getting to a point where we are losing control of this very powerful machine
that we have created.
Can you redesign the machine within the game?
Can you just have- Can you understand the game enough?
Okay, this is the game.
And this is how we start to re-emphasise the memes that matter,
the memes that bring out the best in us.
You know, like, the way I try to be in real life and the way I try to be online
is to be about kindness and love.
And I feel like I sometimes get, like, criticized for being naive and all those kinds of things.
But I feel like I'm just trying to live within this game.
I'm trying to- Trying to be authentic.
Yeah, but also, like, hey, it's kind of fun to do this.
Like, you guys should try this too, you know, that-
And that's, like, trying to redesign some aspects of the game within the game.
Is that possible?
I don't know.
But I think we should try.
I don't think we have an option but to try.
Well, the other option is to create new companies or to pressure companies
that- or anyone who has control of the rules of the game.
I think we need to be doing all of the above.
I think we need to be thinking hard about what are the kind of positive, healthy memes.
You know, as Elon said, he who controls the memes controls the universe.
He said that.
I think he did, yeah.
But there's truth to that.
It's very- There is wisdom in that because memes have driven history.
You know, we are a cultural species.
That's what sets us apart from chimpanzees and everything else.
We have the ability to learn and evolve through culture as opposed to biology
or, like, you know, classic physical constraints.
And that means culture is incredibly powerful.
And we can create and become victim to very bad memes or very good ones.
But we do have some agency over which memes, you know, we sub-
but not only put out there, but we also, like, subscribe to.
So I think we need to take that approach.
We also need to, you know, because I don't want-
I'm making this video right now called The Attention Wars,
which is about, like, how Moloch- the media machine is this Moloch machine.
Well, is this kind of, like, blind, dumb thing
that where everyone is optimizing for engagement in order to win their share
of the attention pie.
And then if you zoom out, it's really, like, Moloch that's pulling the strings
because the only thing that benefits from this in the end.
You know, like, oh, our information ecosystem is breaking down.
Like, we are- you look at the state of the U.S.
It's in- we're in a civil war.
It's just not a physical war.
It's a- it's a- it's an information war.
And people- people are becoming more fractured
in terms of what their actual shared reality is.
Like, truly, like, an extreme left person, an extreme right person.
Like, they- they- they literally live in different worlds in their- in their-
in their minds at this point.
And it's getting more and more amplified.
And this- this force is, like, a- like, razor blade pushing through everything.
It doesn't matter how innocuous the topic is,
it will find a way to split into this, you know, bifurcated culture war.
And it's fucking terrifying.
Because that maximizes the tension.
And that's, like, an emergent Moloch-type force.
Right.
That takes any- anything, any topic, and cuts through it
so that it can split nicely into two groups.
One that's-
Well, it's- it's whatever- yeah.
All everyone is trying to do within the system
is just maximize whatever gets them the most attention
because they're just trying to make money
so they can keep their thing going, right?
Yeah.
And the way- the- the- the best emotion for getting attention in-
well, because it's not just about attention on the internet,
it's engagement.
That's the key thing, right?
In order for something to go viral,
you need people to actually engage with it.
They need to, like, comment or retweet or whatever.
And of all the emotions, the- you know,
there's, like, seven classic shared emotions
that studies have found that all humans,
even from, like, unc- previously uncontacted tribes, have.
Some of those are negative, you know, like sadness,
disgust, anger, et cetera.
Some are positive happiness, excitement, and so on.
The one that happens to be the most useful for the internet
is anger, because anger is- it's such an active emotion.
If you want people to engage, if someone's scared-
and I'm not just, like, talking out my ass here,
there are studies here that have looked into this-
whereas, like, if someone's, like, disgusted or fearful,
they actually tend to then be like,
uh, I don't want to deal with this.
So they're- they're less likely to actually engage
and share it and so on.
They're just going to be like,
whereas if they're enraged by a thing,
well, now they're- like, that triggers all the, like,
the- the- the old tribalism emotions.
And so that's how then things get sort of spread,
you know, much more easily.
They- they out-compete all the other memes in the ecosystem.
And so this, like, the- the attention economy,
the- the wheels that make it go around are- is rage.
I did a, you know, a tweet.
The- the- the- the problem with raging against the machine
is that the machine has learned to feed off rage,
because it is feeding off our rage.
That's the thing that's now keeping it going.
So the more we get angry, the worse it gets.
So the mollic in this attention- in- in the war of attention
is constantly maximizing rage.
What it is optimizing for is engagement,
and it happens to be.
The engagement, um, is- is more propaganda.
You know, it's not- I mean, it just sounds like every-
everything is- is putting- is- is- more and more things
are being put through this, like,
propagandist lens of winning whatever the war is in question,
whether it's the culture war or the Ukraine war.
Yeah.
Well, I think the silver lining of this,
do you think it's possible that in the long arc of this process,
you actually do arrive at greater wisdom and more progress?
It just- in the moment, it feels like people are-
tearing each other to shreds over ideas.
But if you think about it, one of the magic things about
democracy and so on, is you have the blue versus red,
constantly fighting.
It's almost like they're in discourse creating devil's advocate,
making devils out of each other.
And through that process, discussing ideas,
like almost really embodying different ideas,
just to yell at each other.
And through the yelling over the period of decades,
maybe centuries,
figuring out a better system.
Like, in the moment, it feels fucked up.
Right.
But in the long arc, it actually is pre- productive.
I hope so.
Um, that said, we are now in the era of-
just as we have weapons of mass destruction with nuclear weapons,
you know, that can break the whole playing field,
we now are developing weapons of informational mass destruction,
information weapons, you know,
WMDs that basically can be used for propaganda,
or just manipulating people.
However, they, you know, is needed,
whether that's through dumb TikTok videos,
or, you know, there are significant resources being put in.
I don't mean to sound like, you know, to doom and gloom,
but there are bad actors out there.
That's the thing.
There are plenty of good actors within the system
who are just trying to stay afloat in the game.
So we're effectively doing monarchy things.
But then on top of that, we have actual bad actors
who are intentionally trying to, like,
manipulate the other side into doing things.
And using, so because it's a digital space,
they're able to use artificial actors, meaning bots.
Exactly.
Botnets, you know, and this is a whole new situation
that we've never had before.
Yeah.
It's exciting.
You know what I want to do?
It is.
You know what I want to do?
Because there is, you know, people are talking about bots manipulating
and have, like, malicious bots that are basically spreading propaganda.
I want to create, like, a bot army that fights that.
Yeah, exactly, for love.
That fights that.
I mean.
You know, there's the, I mean, there's truth to fight fire with fire.
It's like, but how you always have to be careful
whenever you create, again, like, Molek is very tricky.
Yeah.
Hitler was trying to spread the love, too.
Yes, so we thought.
But, you know, I agree with you that, like,
that is a thing that should be considered.
But there is, again, everyone, the road to hell is paved in good intentions.
And this is, there's always unforeseen circumstances.
You know, outcomes, externalities, if you're trying to adopt a thing,
even if you do it in the very best of faith.
But you can learn lessons of history.
If you can run some sims on it first, absolutely.
But also, there's certain aspects of a system,
as we've learned through history, that do better than others.
Like, for example, don't have a dictator.
So, like, if I were to create this bot army,
it's not good for me to have full control over it.
Because in the beginning, I might have a good understanding
of what's good and not.
But over time, that starts to get deviated,
because I'll get annoyed at some assholes, and I'll think,
okay, wouldn't it be nice to get rid of those assholes,
but then that power starts getting to your head,
you become corrupted.
That's basic human nature.
So, distribute the power.
We need a love botnet on a dow.
A dow love botnet.
Yeah, but, and without a leader.
Like, without.
Exactly, distributed, right.
Yeah, without any kind of centralized.
Yeah, without even, you know, basically, the more control,
the more you can decentralize the control of a thing to people.
You know, but the balance.
But then you still need the ability to coordinate,
because that's the issue when you think,
something is too, you know, that's really, to me,
like the culture wars, the bigger war we're dealing with
is actually between the, like the sort of the,
I don't know what even the term is for it,
but like centralization versus decentralization.
That's the tension we're seeing.
Power in control by a few versus completely distributed.
And the trouble is, if you have a fully centralized thing,
then you're at risk of tyranny, you know,
Stalin type things can happen, or completely distributed.
Now you're at risk of complete anarchy and chaos,
where you can't even coordinate to like on,
you know, when there's like a pandemic or anything like that.
So it's like, what is the right balance to strike
between these two structures?
Can't Malik really take hold in a fully decentralized system?
That's one of the dangers too.
Yes.
Very vulnerable to Malik.
So a dictator can commit huge atrocities,
but they can also make sure the infrastructure works and...
They have that God's eye view at least.
They have the ability to create like laws and rules
that like force coordination, which stops Malik.
But then you're vulnerable to that dictator
getting infected with like this,
with some kind of psychopathy type thing.
What's reverse Malik?
So great question.
So that's where...
I've been working on this series.
It's been driving me insane for the last year and a half.
I did the first one a year ago.
I can't believe it's nearly been a year.
The second one, hopefully we're coming out in like a month.
And my goal at the end of the series is to like present...
Because basically I'm painting the picture of like what Malik is
and how it's affecting almost all these issues in our society
and how it's, you know, driving.
It's like kind of the generator function,
as people describe it, of existential risk.
And then at the end of that...
Wait, wait.
The generator function of existential risk.
So you're saying Malik is sort of the engine
that creates a bunch of ex-risks?
Yes, not all of them.
It's a cool phrase.
Generator function...
It's not my phrase.
It's Daniel Schmacktenberger.
Oh, Schmacktenberger.
I got that from him.
Of course.
All things...
It's like all roads lead back to Daniel Schmacktenberger, I think.
The dude is brilliant.
He's really brilliant.
After that, it's Mark Twain.
But anyway, sorry.
Totally rude to interrupt this from me.
No, it's fine.
So not all ex-risks.
So like an asteroid technically isn't because it's,
you know, it's just like this one big external thing.
It's not like a competition thing going on.
But, you know, synthetic bioweapons, that's one
because everyone's incentivised to build, even for defence,
you know, bad viruses, you know, just threaten someone else,
etc.
Or AI, technically.
The race to AGI is kind of potentially a monarchy situation.
But, yeah.
So if MOLIC is this, like, generator function that's driving
all of these issues over the coming century that might wipe us out,
what's the inverse?
And so far, what I've gotten to is this character
that I want to put out there called Win-Win.
Because MOLIC is the God of Lose-Lose, ultimately.
It masquerades as the God of Win-Lose,
but in reality, it's Lose-Lose.
Everyone ends up worse off.
So I was like, well, what's the opposite of that?
It's Win-Win.
And I was thinking for ages, like, what's a good name
for this character?
And then tomorrow, I was like, okay, well,
don't try and, you know, think through it logically.
What's the vibe of Win-Win?
And to me, like, in my mind, MOLIC is like,
and I dress as it in the video, like, it's red and black.
It's kind of like very, you know,
hyper-focused on its one goal you must win.
So Win-Win is kind of actually like these colours.
It's like purple, turquoise.
It loves games too.
It loves a little bit of healthy competition,
but constrained, like, kind of like before,
like, knows how to ring-fence zero-sum competition
into, like, just the right amount,
whereby its externalities can be controlled
and kept positive.
And then beyond that, it also loves cooperation,
coordination, love, all these other things.
But it's also kind of like mischievous.
Like, you know, it will have a good time.
It's not like kind of like boring, you know, like,
oh, God, it's, it's, you know, it's not to have fun.
It can get, like, it can get down.
But ultimately, it's, like, unbelievably wise,
and it just wants the game to keep going.
And I call it Win-Win.
That's a good, like, pet name.
Yes. Win-Win.
The, I think the...
Win-Win.
Win-Win, right?
And I think its formal name,
when it has to do, like, official functions,
is Omnia.
Omnia.
Yeah.
From, like, omniscience,
kind of words of why Omnia.
She's like, Omnia.
She's like, Omnia.
Omnia-Win.
But I'm open to suggestions.
I would like, you know, and this is...
I like Omnia, yeah.
Yeah, like, that's...
But there's an angelic kind of sense to Omnia, though.
So Win-Win is more fun.
Exactly.
So it's more like, it embraces the fun aspect.
I mean, there is something about sort of,
there's some aspect to win-win interactions
that requires embracing the...
The chaos of the game and enjoying the game itself.
I don't know.
I don't know what that is.
That's almost like a zen-like appreciation of the game itself,
not optimizing for the consequences of the game.
Right.
Well, it's recognizing the value of competition in of itself.
It's not, like, about winning.
It's about you enjoying the process of having a competition
and not knowing whether you're going to win or lose this little thing.
But then also being aware that, you know,
what's the boundary?
How big do I want competition to be?
Because one of the reasons why Molek is doing so well now
in our civilization is because we haven't been able to ring fence competition.
You know, and so it's just having all these negative externalities
and we've completely lost control of it.
You know, it's...
I think my guess is, and now we're getting really, like,
you know, metaphysical, technically.
But I think we'll be in a more interesting universe
if we have one that has both pure cooperation,
you know, lots of cooperation and some pockets of competition,
then one that's purely cooperation entirely.
Like, it's good to have some little zero-sum-ness bits.
But I don't know that fully and I'm not qualified as a philosopher to know that.
And that's what reverse Molek, so this kind of win-win creature
is in a system as an antidote to the Molek system.
Yes.
And I don't know how it's going to do that.
But it's good to kind of try to start to formulate different ideas,
different frameworks of how we think about that at the small scale
of a collection of individuals and a large scale of a society.
Exactly. It's a meme.
I think it's an example of a good meme.
And I'd love to hear feedback from people
if they think they have a better idea or it's not.
But it's the direction of memes that we need to spread,
this idea of, like, look for the win-wins in life.
