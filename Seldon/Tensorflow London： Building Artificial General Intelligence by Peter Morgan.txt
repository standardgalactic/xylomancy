Now, so I'm going to talk about EGI.
I've got long, I've got lots of slides, so I'll move very quickly.
Here's a report I wrote for Riley.
There's a company I started as an AI consulting company.
And so what are we going to talk about?
So the first question we have to ask, and I apologize if you've seen this talk before,
I have given it a few times, hopefully there's none in the room who has.
What is intelligence and then what physical systems are available for us to get inspiration from
and how far have we come in building the hardware.
And then I'm going to look at very briefly deep learning as, you know,
just ask very quickly the question, are we on the right track?
And then with deep learning, is that going to get us all the way to EGI?
The answer is no, spoiler.
And so what do we need, what's missing?
I'll do a very quick overview at the end.
And we'll look at one particular, one theory in particular called active inference.
And amongst a whole, you know, zoo of theories, really, EGI theories.
We'll pick that one out, I'll explain why.
And then I'll wrap it up with conclusions.
So, you know, why do we want to build it?
Well, it's kind of obvious, right?
We want to build it to solve the problem of the century, probably,
of the human race, maybe, arguably, so I might argue.
And then, you know, to make lots of money doing it, but really it's just to solve it.
And see, and then once we solve it, as DeepMind said, we can use it to solve everything else.
That includes all science or medicine, how to live longer, how to be alive,
new materials, you name it, you know, spacecraft, explore the galaxies, use your imagination.
So, that really is the aim, right, to build general level intelligence
and quite quickly, you know, move beyond that to superintelligence.
So, you know, a quick question I always ask the audience.
Are any of the general intelligence, so we've got Watson there, super impressive,
you know, we've got the chess playing Deep Blue, IBM, Alpha Star, just very recently,
you know, DeepMind built that system that could beat some of the best players at Starcraft,
and online games, and AlphaGo.
So, no, no matter how impressive all of these are, and they certainly were, you know,
years in the making, 10, 20, 30 years since the birth of AI maybe, they're not,
they're nothing to do with AI.
So, and here's why, because intelligence is much broader than that.
Remember we asked the question, what is intelligence?
Well, a guy called Howard Gardner at Harvard, I think in the 90s,
wrote down quite a nice way of categorizing it.
So, you put it into nine categories.
So, we've got naturalist understanding nature, the external world, can go do that, no.
You know, and I want to keep going, can go do that, can go do that.
The answer is no, no, no.
The spatial visualization.
So, we have AI, you know, that can do maybe one of these really well,
but never more than two, right?
So, we're nowhere near AI.
Interpersonal, you know, introspection, you know, there's a TPU sitting in a Google Data Center.
No matter what algorithm you run on it, it doesn't go, why am I here, right?
Why am I a TPU who made me?
Right, no.
This is all part of intelligence.
Introspection, even though I make light of it, is, you know, a very important aspect of intelligence.
Language, linguistics, we have NLP.
We can have things that read and classify.
Sentences, and, you know, are they created?
It's mostly based on statistical analysis of words and images and pixels and whatnot.
It's not quite how the brain does it, or the biological brain.
We have movement, you know, the best assets in the world get paid.
You know, all players getting transferred for 100, 200 million pounds, right?
I mean, there's some of the highest-paid people in the world, because they use their body so well.
A basketball player is in America, a football player is in Europe.
So, that's a part of intelligence.
And, you know, we have robotics, right?
So, there's nowhere, we haven't got any robots that can play football like Nestle or, you know, the Beth, Michael Jordan, and Russell Gould.
They're very close, although, you know, impressive progress has been made with that.
Let's just see if they can backflips and whatnot.
Super impressive, right?
Not quite general, even that one small, limited sense.
Interpersonal, how we communicate with each other in the world, animals, ourselves.
Interpersonal, communications, modeling what the other person is thinking, right?
And then predicting what their next move will be, knowing they're that.
It's essential, that's the way we hear it, and the logical mathematical path that we've kind of got.
I would argue, you know, fight with it, chess, and go, and numerical stuff,
and then calculate it, and up and forth, out-calculate.
Almost every human being, it's a very simple calculator.
So, we probably were okay in that part.
And then musical and other creative art, music, writing poems, just, you know, but mostly musical.
You know, writing would be linguistic.
So, art, the creative, the creative fine arts.
Yeah, you know, AI narrow, AI has written some songs, but, you know, you sort of have written very loosely.
You know, one could argue, again, it's statistical, not creative.
So, what are we missing?
So, you know, how far have we come?
The highest is probably logical mathematical at 50%.
So, calculation is great, but not creativity.
You know, they can't really invent new games of go, or new types of math yet, okay?
You know, there's mathematicians in the world, the guys who gets the field middle,
they can't, you know, do math at the level of a field middleist or a Nobel Prize winner.
And then linguistic is good as they are.
It's in creating stuff and complete sentence completion and, you know, sentiment analysis.
It's a statistical analysis.
It's not what we're doing.
It's not a creative thing.
And then, I don't know, let's read the list, right?
Spatial, we've got the plan and body, you've got atlas, you know,
in understanding the environment, I thought 10%.
That's a generous 10% music, you know, Google, Gentile, 50%.
These are all pretty generous numbers, I would say.
So, basically, you know, we know we need a general intelligence.
We're not at 100%, but we can do all of these really well.
You know, we specialize in what we pick, what we put out and specialize.
But we can do them all.
So, it takes a village to, you know, raise a child, and it's going to take a village to create AGI.
So, we're going to need computer science.
That's the one that everybody's got right now, but we're also going to need physics.
We're going to need neuroscience, and we're going to need psychology.
We're going to need people from all walks of life, because that word general means general, right?
It's everything.
And so, let's move on now to the hardware.
You know, how far we've got with the hardware, then we'll look at the algorithms and put it all together at the end.
So, we basically look at, you know, we haven't existed proof.
That's us.
You know, that's a three pound of wet flesh in ourselves.
That's what's creating this general intelligence, unless you believe it's something else.
But, you know, neuroscience, physics tells us that it's all we have.
So, we need to get, we are getting inspiration.
Maybe not enough, actually, but this is where it's the first place, you know, I would probably start looking at how nature builds intelligence,
or how nature heads up intelligence.
Even though it's had a little bit of a head start on us, like four billion years.
You could argue the Big Bang 13 billion years.
We've only been doing it for about 50.
But it's come up with this thing up here in our skulls that can come up with a general theory of relativity,
play chess, play games, drive a car, go shopping, raise children, create mathematics, do this,
pay, you know, everything that civilization has done.
You know, there's a little three pound thing up here.
Given there's a lot of us, and, you know, we think that on our own, we don't collectively.
We know we're near there, are we?
We're honest with ourselves.
So, how does nature do it?
Well, you know, you start off with a single cell organism.
This is where the definition of intelligence gets a little bit tricky.
It's like, is that thing intelligent?
It's alive, it's living, it responds to its environment.
I would argue, yes, it stays alive, manages to stay alive over billions of years even.
Maybe it's more intelligent than us, in that respect, the way you see.
And it reproduces.
It doesn't come out, it can't come up with a general theory of relativity.
So, in some sense, it has limited intelligence, but it's still intelligent.
So, you know, what's that doing?
Can we reproduce that?
Let's start there.
That's the C. elegans worm.
It has 100, 302 neurons.
It has a central nervous system.
It's an organism with the simplest nervous system, CNS, central nervous system, 302 neurons.
We can build that today.
We've got models of that.
So, that's sort of where we are.
You know, we have 80 billion, 100 billion neurons.
We're at 300.
So, we've got a little road to travel, but if we can kind of understand how that thing works,
you know, maybe we can extrapolate and scale a little bit.
We can't give ourselves too hard of time.
In the last 10 years, we can model a C. elegans worm.
We have the bumblebee.
That's about a million neurons.
And they can navigate and do little dances and tell the rest of the bee colony where the hunt,
where the polliners and come back and mate and stay alive.
They're super intelligent.
I would argue they're super intelligent, right?
They cannot come up with the general theory of relativity, but they're still super smart.
We haven't got that far.
And then there's these things, the wick mushy bit in our head, three pounds in our skull.
And we're nowhere near that, even though, you know, it's small, right?
And we're trying to understand the universe, the cosmos, the galaxy.
We're kind of, you know, doing a better job.
We can't even understand the tiny little thing.
I mean, just, it's not just.
It's very, very clever.
It's had billions of years to evolve.
So, you know, what are we missing?
What's the math?
What's the mathematical model to build something that can model or come up with math and model
its environment into personal introspection?
How does that happen, right?
That's what we've got to figure out.
It's not it.
It's no small problem.
So, the first thing we notice from biology is it's hierarchical.
It starts off with molecules and neurons cells and then networks of cells and then sort of
subceptions of the brain or integrated connected together wonderfully to create a whole brain.
That's a connectome.
And, you know, there's a part doing math.
There's a part doing language.
There's a part doing emotion.
There's a part.
Is there a part that creates music?
Is there another part that drives a car?
Is there another part that, you know, or is it all sort of integrated?
You know, so that's the kind of inspiration we need to take from biology to kind of use
that to build mathematical models and then actually build it in physical hardware.
Because Simon said, we don't understand anything in this.
We can build it.
And I quite agree.
Right.
We can write down any mathematical stuff you like.
There's lots of models, the public kits, all sorts of different models.
But until we build it, we don't really understand.
We don't know if it tries.
It's just a few.
Okay.
And then, yeah, we have, certainly we have societies which are kind of hierarchical.
We organize ourselves hierarchical cities and countries and nations, et cetera.
Right.
Okay.
So this is biology.
Super complicated, super complex, right?
You know, do we have to go down to that level of complexity?
Well, that's a good question.
We just start at the cell in Europe.
That's a bit of an open question right now.
It's good to have open questions because it keeps, you know, that science, that's what
science is about.
Okay.
But then it sort of organized itself into about two million of these cortical columns.
So the brain has some sort of sort of substructure there.
And it's quite common over the whole brain and the neocortex.
Yeah.
The math part, the seeing, the hearing.
So one part of our brain, if we go blind or whatever, it's a accident.
Those cortical columns are used to analyze the sound.
So there's some, something very fundamental going on there.
These are all clues from biology.
There's a connectome and there's a central nervous system helps all connect together.
Maybe we don't need to build bodies.
You know, if you want robots, we do, but if we just want something to get things really
well, create series like Stephen Hawking, I mean, parallel to get around it now, but
I'm just saying that we only need the rest of that if we want to build a robot.
Okay.
We're really focused on the neocortex a bit.
Okay.
And then the society.
So what have we done?
What have we built with hardware?
Okay.
Well, we've come a long way.
We're up to about 10 billion transistors.
And there's different types, CPU, GPU, the graph core, IQ, and different types of,
due to different data sets, basically.
So if you want to understand environmental data.
That's where we probably need something beyond the GPU.
The GPU is really good at matrix multiplication.
And the brain doesn't do matrix multiplication to understand and create, right?
But deep learning does.
So we do need GPUs to that and CPUs.
But if we really need to go beyond in a different sort of hardware architecture, if we do want
to have general intelligence.
Okay.
So there's a little nostalgia here.
That's a cray 1976 40 over 40 years ago, 160 megaflops.
How quaint, you know, we have teraflops in our pocket now.
So this is where we are today.
We have, you know, with Moore's law, we've had a factor of a million or so since then.
So we've got the I nine Intel CPU.
We've got the invider video V 100 Volta GPU.
We've got the Google TPU version three, which are absolutely pedaflops.
But just beyond the TPU coming online is the graph or IQ.
But really, these are all matrix multipliers.
So super impressive.
You know, we've got 100 pedaflops in a thing that, you know, we put on the stage, which
is somewhat what the brain does.
I think the brain does about a pedaflop or so.
So it's not about raw computation.
Right.
If it was, we would be there.
We would this thing would be coming up with theories of relativity and all sorts of stuff.
We would be trying to do creating symphonies, but it can't.
It's done as a brick.
Right.
Right.
And so that's that's exoflops, right?
That's a thousand times a pedaflop.
So we're going to need something more.
What are we missing in the hardware?
Right.
So it's not just about hardware.
It's actually about the hardware, which is pretty obvious when you think about it.
What's up here is different than the hardware we've just seen.
What about new amorphous computing?
So this is where things get interesting because now we we're using analog circuits, which
is what the brain is.
The brain is spiking neural networks, which is almost a combination of analog and digital.
So there's a guy called Steve Berber, one of the co-founders of ARM.
He after 20 years, he left ARM and University of Manchester 20 years ago.
He set up a project called Spinnacle, which is now being folded into the human brain project.
There's IBM True North.
There's brain scales at the human brain.
But there's various projects throughout the world building these analog, this analog hardware.
Right.
So to me, I think this is this is a big, big part of it.
Okay, algorithm is certainly important.
But I think the hardware is important as well.
So Spinnacle, we've got a hundred, I've got a billion neurons.
So a thousand, a hundred times that we've got the human brain.
So we've built the mouse brain already, and it can do stuff like navigate through mazes
and play Sudoku and do crossword puzzles.
It does intelligent stuff.
You know, and then there's some people who have heard about it, but it does not get depressed,
does it?
And DeepMind does.
And AlphaGo and everything else.
I can argue that this is part of my thesis that this is what will take us to general intelligence.
And there it is.
Five racks are up to 10 now.
There it is sitting in a data center in Manchester.
It's part of the human brain project.
And that is neuromorphic computing.
There's a billion neurons here.
There's a mouse brain right there.
It's a little bigger than a mouse brain, but we've seen with Morse law, we're quite good at scaling, right?
So the point is we built some stuff here, which might be useful for us.
And that's how you scale up.
You put a thousand neurons on a core.
You put 18 cores on a chip.
You send it away.
You get it built.
It comes back.
You put them together.
You put the chips on the board.
Put boards in a rack.
And then you get 10 cabinets and put five racks in each cabinet.
You've got 50 servers, neuromorphic servers, and you have a mouse brain.
That's how you do it.
And it's been done.
That is the brain scale approach that I mentioned at the human brain project.
That's about the same size as the spinnaker and the same power that a mouse brain uses a slightly different architecture.
I won't go into the details.
True North IBM uses a slightly different architecture.
But the point is, when you're neuromorphic, and you're analog based on spiking your networks.
And that's sort of general intelligent mouse level compared to the Google TPUs,
which are super impressive at different types of things.
But I'd argue they won't get us a general intelligence with the thing on the left.
What about quantum?
I don't think the brain is quantum.
It's too warm and wet.
Quantum needs super cold temperatures.
It's decoherence very quickly.
I don't think it's qubits in the brain.
But they look nice.
I put a picture of one on there.
That's what a quantum circuit looks like.
So suddenly, we're not just start the CPUs anymore.
We've got these four different types of architectures.
And one's biological, one's quantum, or three are not biological.
We've got quantum.
We've got neuromorphic.
And we've got digital.
And I'm arguing the thing on the top right will be needed.
The general intelligence is what they look like.
We've built them all.
The quantum that's a seven bit IBM qubits, a seven qubit IBM processor,
a quantum processor.
There's a neuromorphic.
That's what they look like microscopically.
There's a digital.
I mentioned 10 billion on a chip, on a processor with a CPU-PPU.
And that's how biology looks like.
So, you know, I think the neuromorphic in biology,
the neuromorphic will map onto the biological,
the best out of all of those options there.
Not to say the other's unclear.
So the data centers of the future, they'll look like this.
We might just have them fill up with CPU GPUs.
We'll have neuromorphics.
We'll have quantum.
And we'll have a little bit of classical as well.
Interesting time to head.
Deep learning.
Just going to have a couple of slides here.
There's this plethora of neural networks.
It won't get us there.
They've got very good classification and regression,
and pattern matching.
They're very good at, you need,
this is all statistical analysis.
Very clever.
But nothing to do with what the brain's doing it on.
And so this is a TensorFlow meetup.
So I had to mention TensorFlow.
Here's how popular TensorFlow is.
So if you're going to start on the deep learning,
you need a quick pie talk to TensorFlow.
So there we go.
So what do we need?
How do we build AGI?
So, well, I would start as a physicist.
I would start with the laws of physics.
And we've come up with physics as an old subject, about 400 years old.
Computer science is quite new, about 70 years old.
So I would just go back and start with the laws of physics.
What are the laws of physics?
Because the brain, I would argue, is a physical system.
So probably that's the best place to start.
Don't just start writing a JavaScript.
Don't start, you know, go back to basics.
This is what physics is.
And basically all the physics,
and maybe not too many people in the room know this,
can be written as a principle of least action.
S is the action, L is the function, blah, blah, blah.
You know, it's a credit level physics.
So I know this stuff really well.
Build them to me, hundreds of exams, assignments, blah, blah, blah.
And there's been a book just recently called
Principles of Leaf Action, which surprised me.
So it sort of has checked us on each section of physics
and how you can derive it from delta s equals zero.
So I would start there if I was going to build an intelligent system.
So that's physics.
What else do we need?
So intelligence isn't just about pattern action.
So, you know, I've conveyed that already.
Nine different types.
And one or two types is about pattern action, really.
It's about modeling the world, really.
That's what intelligence is.
It's how well we can model the world,
and then make predictions and predict the next step.
That's how we make money.
That's how we stay alive.
You know, that's how we do everything.
That's what intelligence is.
We can play chess and do all sorts of things.
But really chess is about understanding our environment,
modeling our environment,
the ability to model our environment,
make predictions and then to take action on those predictions.
We need to understand, explain and understand what we see.
This is what we need to build.
We need to imagine things and we need to problem-solve
and plan actions.
We need to build new models as we learn about the world.
Nothing to do with AlphaGo.
Nothing to do with Deep Blue.
Nothing to do with AlphaStuff at all.
Okay.
I would argue they're super clever,
but they're statistical.
They're not really intelligent.
Okay.
So what is intelligence?
Well, there's loads of theories.
I'm going to pick out active inference,
but there's a ton of work,
and all of these people have been doing this work for 30 years now.
There's Schmidt-Rieber, Ruta,
Violetta, Princeton, Tishvie,
and Friston at UCL here.
Yeah, this is their life's work.
You know, they're mad scientists twining away,
but sort of it's starting to happen for them.
So they'll probably get to see a little bit of, you know,
the fruits of their labor.
Okay.
So what is active inference when I pick up?
So more than welcome to go home and Google all of these.
They're all got papers on archives.
They've all got wonderful websites.
There's loads and loads of beautiful,
really reading and interested in intelligence, essentially,
and how we might get there.
And they all have useful input,
and we don't quite know which one is right,
maybe the combination of the few.
But this is what Friston's saying.
It's called active inference.
It's based on physics and information theory,
so it's a very fundamental theory.
It uses something called the freedom principle,
and it doesn't encompass all space and all time scales.
So, yeah, it works from the very small to the very large,
and it works from nanoseconds to the age of the universe.
It's completely general.
Yeah.
Now, I don't expect you, there is there.
I don't expect you, you know, to go, ah, I get it now,
because this is hard stuff, and it takes a lot of reading.
It certainly took me an awful lot of time, actually,
to read through all of these different theories,
and just start at the basics of computer science.
Remember when I said it took the village,
neuroscience, physics, psychology.
You know, I just learned a lot about a lot of things, right?
And we do.
This is why it's a hard problem, isn't it?
So this is how he sort of puts it down, models it, I guess,
so the freedom principle.
You just divide the world into internal states,
which is our brain, and outside the environment,
and agent environment.
Anybody's ever done reinforcement learning.
It's a similar sort of thing, right?
You have the agent and the environment,
but this kind of explains how the agent works itself.
What's going on inside the brain?
What's going on outside the brain?
It's separated by something called a Markov banquet,
which is kind of a cool-standing name.
The guy called Julia Pulitzer,
at the University of Southern California,
came up with that in the 80s.
So, you know, there's this contribution from everywhere
into this theory.
And so it works from, like I say,
small to large at which we sell some brains,
external states, internal states,
because that's a cell.
Microscopic, when we saw the cell,
I think that was intelligent to a brain.
The difference is the brain is much more complicated
internally than the cell.
It's got 10-bit immune cells, it's got none.
But that's a similar setup,
and so you can kind of, you know,
it all different scales.
Nice people, bacteria.
Okay, there's the math.
The math gets ugly.
That's what it looks like,
but if you've ever read a reinforcement learning paper,
that's what that looks like as well.
So, you know, if you're a deep learning researcher,
the only difference is these are physical quantities
like entropy and things like that.
And the reinforcement learning
needs to be much more statistical,
but it's kind of similar looking.
Probability distributions,
but this one's based on
information theory.
Okay.
Don't expect you to take any of that,
and I just wanted to show off the math.
So, how terrible am I?
Look at that math, but I didn't do it.
It's not mine.
Okay, so, can we build it?
Well, yes, we can.
We have the theories.
Theories, theory, theories.
We have a few candidates.
We have the algorithm.
We even have software.
The Professor Pritzen has a big software base
that has been developed over the years.
We have the hardware.
I'm going to argue that the Neomorphic hardware is there,
so if we run this on Spinnaker,
we should be good.
And we have data sets.
It's a thing called the Internet.
We have all the data we need.
And so, I would say,
to some extent, we're kind of there.
We have the mouse sprain,
and we have, you know, the active inference running on it.
And I'll tell you what kind of there.
We're kind of in the very early stages.
We're not millions of miles away,
20 years away down the road.
We're sort of there on the road,
the initial road for the beginning.
I don't think there's anything missing.
There's no theory missing.
There's no hardware missing.
There's no data missing.
And there's no, you know, we have a theory.
That's a big statement, right?
So, I think we're there.
Okay, so what do we need?
We need hardware.
We have data hardware.
We need a taste of code for general intelligence.
So any software engineers here in the room
want to get started about building.
You'll be completely missed.
And, um, yeah, it's a pilot project about time.
I mean, you know, it's the one, right?
We've got to solve intelligence and music,
solve everything else.
There's many, there's a huge,
there's a deep, deep line of brain,
the human brain project.
China's just invested $10 million
in setting up a city, the whole city,
to develop EGI.
And should we build it?
I mean, it's ethics and safety,
but I'll leave that to another discussion.
Finishing off.
Here's some EGI projects that are real.
They exist.
They have venture funding.
They have people.
They're working on it 24-7 every day.
That's their life.
That's what they do.
You know, I didn't put the deep mind up there.
Some of them are well-known, some not so well-known.
Some are smaller, some are bigger.
And so, in conclusion, it's obvious to most
that deep learning is lacking the foundation
to see if the general theory of intelligence
is based on statistics, not physics.
Some groups are starting to look at
viable models.
And it frustrates me that they weren't starting
looking at them all along somewhere,
but a lot of this deep learning stuff is just,
you know, it was never going to get us there.
And people, you know, hopefully realize that now,
but I'm not that optimistic.
But I'm saying right now,
it's not going to get us there at all.
Is it? Yeah.
I've already said we've sort of,
we've already got it.
Not human level, but mouse level.
And normal, if it might be a platform to get us there,
and I'll leave you with this parting words
from Geoff Hinton a bit.
Okay, so what he was saying there is basically
what I think the Godfather of AI
of deep learning from the 80s and his whole life,
he used to work with Friston at UCL, by the way,
went to Toronto in the end.
What he is saying is that deep learning won't get us there.
It was never meant to.
I didn't make a mistake.
It's just I was working on something else.
What we do need, what will get us there,
is understanding the brain.
And this is in 2016, he's saying,
I think that we are very close to that moment.
And I've put up a few theories there,
which maybe he wasn't even aware of.
Maybe he was, he's a smart guy,
but I believe we do understand the brain.
I believe we're there. Thanks.
Great stuff, Rana and Klaus.
Okay, good stuff.
So we're a little bit tight for time, but I'm curious.
So you've done, you've been a research fellow.
You've obviously been running deep learning partnerships
for quite a while now.
What is your interest?
How come so much focus or interest in this?
And where do we find you online?
And what's your next project?
Yeah, so I have started a company called TuringAI.co.
Which was up there, right?
Yeah, yeah.
It was one of the boxes up there.
Yeah, it was actually one of the boxes.
Tell us about that.
Yeah, Turing, Nike is now in TuringAI.co.
Now, I've actually started that company with Professor Friston
and a couple of very clever post-docs.
So we're working on this.
Schmidt Hooper's working on it.
Viallek at Princeton's working on it.
DeepMind are working on it.
I'm not saying that we're going to crack it first,
but yeah, we're very involved in solving the problem.
Big respect.
Well, with you all the way,
we'll have you back on TensorFlow
once you solve that problem.
Yeah.
Okay, cool.
Let's, we've got time for two quick questions.
Anyone in the crowd?
Okay, Jens, for that.
Introduce yourself.
Hi, my name is Atul.
I help you with some regard.
It's been added.
The one you mentioned was less publicity.
That 3.0 could be deep blue within nine hours of learning.
Why isn't there something similar being done, promoted?
Yeah.
So, I mean, I don't know, really.
They're using reinforcement learning
and Markov Monte Carlo's tree certifications.
So I'm not going to take anything away from you.
That works.
It's brilliant, right?
It's like a calculator can out-taculate us
at multiplying two large numbers together.
They can, they can, you know,
there's no way we're going to be going to the chairs
or going over again.
It's super clear as well.
But remember my nine types of intelligence,
they can't do anything.
No.
They might, I mean, I'll go,
can't write a symphony.
We need a different algorithm for that.
So, you know, how do we integrate them all together?
I mean, that's a pretty big problem.
Yeah.
Any other questions?
If you have a question.
Hi.
My name is Nikia.
I'm just wondering,
what's the algorithm that's going to do
to compare to the numbers?
I mean, yeah, the number of neurons is the same.
Is it going to be the same?
Yeah, nothing like it.
So that's a great point.
So there's two metrics, isn't it?
It's a number of neurons,
but there's also the connectivity between the neurons.
So the biology seems to like to connect
about a thousand to 10,000 synapses
per neuron.
So spinnaker is nowhere near that.
It might have a few dozen.
So that's a very important method.
Connectivity is the super important thing.
Can I start talking a little more?
There's one over here.
Mark, Mark.
Hi.
My name is Mark.
I watch the VR stuff called Input.
My question is,
you focus a lot on the CPU architecture,
but obviously the charge-tooling pieces,
say that any function that is computable
can be executed by any machine,
whether they are the CPU, whether the GPU.
Is it just the execution speed that you care about,
or do you see anything wrong with the charge-tooling pieces?
No, I do believe that's a great question.
And there's been a lot of debate,
even for last philosophical debate,
about whether the brain is Turing-complete.
I think it is, and most people do as well.
So it's a very fringe people who say,
there's something else in the brain that's not Turing-complete.
So I don't believe there's any bottleneck there at all.
I just think it's a different type of computational system.
We're going to follow you.
Don't anything happen to any type of CPU?
Yeah, I still think we need the synaptic connections,
like a thousand to 10,000.
It really is a deeply embedded hardware problem.
But that hardware is Turing-complete.
So the general theory of computation applies,
but it's just a different hardware.
That's a good question.
Okay, thank you.
