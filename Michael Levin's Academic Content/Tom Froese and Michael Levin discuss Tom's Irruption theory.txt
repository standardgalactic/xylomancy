through it. And I'd love to talk about eruption theory and the thing you were saying the other day
about, you know, the information that's not lost and all that stuff. Right, right. Yeah. And we
can also, if we have time, we can also talk about this issue of how far down it goes and all that.
Yeah, ideally, we want to have a measure, right, like a operationalized criterion for that. So
that's, this is exactly what this is about. Let me just see what's the best way of sharing this.
So I think, is it okay if I put out my second screen? I will be a little absent looking to the
side. Maybe if I record it better, like if I have it in the background. Well, it's mostly going to
be the, I mean, just to share this, I don't even know that we're going to see you. We're just going
to see the slide. So it's fine to share that. Okay. All right. Yeah. I can see you basically,
it's easier that way. That's fine. Okay. All right. Safari. How's that looking? Perfect. Yeah,
I can see it. Great. Okay. Let's put this over here. Yeah, great. Okay. So this is the new paper
that just recently came out. And it's a more mature version of eruption theory that now both
consider is not just the mental causation or like the agency part, but also the other direction.
Like how does something non mental become part of the mental part of subjective experience
to part of mental content. And so now it has these both classic problems, which, you know,
how many varieties. But I think now in this paper, for the first time, I see a way in which we can
do science with that, which is getting me very excited. So I'm going to take us through like the
main figures because they kind of encapsulate the different stages of the argument. So
we start here. Okay. So the human version of the mind body problem. So, you know, we're asking
here the big questions, how is the mind related to matter and vice versa. And, you know, analytic
philosophers have been banging their head against this problem for a long time. And if you read Kim's
kind of like final book account of this, I quite enjoyed it for its clarity of showing that even
if we solve the problem of mental causation by going kind of a reductionist roots, and just
basically saying that, you know, the mental is the physical and therefore the physical can cause
the physical, you know, you lose a lot of what is nice about thinking about the mind in terms of
its qualities and teleology and, you know, your intentions and free will, everything goes out the
window. But you might save causality, right? So you still might get mental causation saved that way.
But the problem is that if some of our things that we do depend on conscious experience,
then the problem is not fully solved. Because that would mean that you also have to have an
account to solve the hard problem of consciousness to have a full account of mental causation.
And so right from the start, I want to say I want to be realist about this in the sense that, you
know, I do think that our experiences make a difference for how we behave. Right. And if someone
wants to say that our experience don't make a difference to how we behave, we've kind of like
have two different premises, like the conversation where it kind of stops there. But to my mind,
you know, it's a very hard sell to try to argue that our experiences don't make a difference.
You basically lose most of the population of this planet basically just, you know,
exits the conversation. Right. So we should do our best not to go down that route. But what that
means is that we also have to solve the problem of consciousness. So these are interlocked. Right.
And this is a big problem. And it gets worse. Because you might think, well, that's just for
people, you know, because that's the problem of consciousness, you know, but if you talk about
rats or, you know, even more basal cognition, then this might not be an issue. But what it
proposes that actually there's a more general mind body problem working in the background.
So on the left hand side, I call this the heart problem of efficacy, which is that for any mental
property, let's say a representation, a goal state or whatever you have, there's a problem
explaining how that state as such as being a mental state makes a difference to the physical
state. So it's a generalization of the problem of mental causation. So it's not good enough to
say there's a supervenience relationship or something like that, but the causality at the
bottom level maintains, you know, what I want to say is how do we say that the goal as being a goal,
as being an intention, as having normativity conditions, as being able to succeed or to fail
or to be better or worse and things like that, the whole normativity of it,
that also somehow needs to be able to account it for in this kind of account, right? And that's
the heart problem of efficacy. And then we have the heart problem of content, which is how does
anything even become part of the mind in the first place. And so representationism, for example,
just kind of brushes this away a little bit. But let's say even if we gave representation as
half of this and said, okay, let's don't worry about how to naturalize content in terms of
its origins, let's say some future point, we have a story of how you go from something purely physical
to something that has semantic content and has mental content that has about these conditions
or normativity, let's assume that problem is solved, then we still have the problem of how
does that even make a difference to something physical, you know, take a thing like, I don't
know, like a neuron in the brain that's supposed to represent, I don't know, your place in a maze
or something like that, your classic, you know, place cell stuff. Well, the fact that it's
representational, that it has representational content, which is kind of like Nobel Prize winning
material, right? So this is, you know, exciting stuff. We find the correlation, but then where
in our analysis of the neural activity itself, does the content enter the picture? All right,
so when we look into the brain and say, here's this neuron, and we know it's correlated with this,
you know, content outside of the rat, like being in its position in the maze, but hey, you know,
like, the rest of what we're seeing here is just physics, it's just biochemistry, it's electrical
potentials, right? It's like, you know, membranes opening and closing and molecules floating around,
there's no content there, there's no normativity, it's just physics, right? So there's a kind of
sense of disconnect here, where, how do we even work across this gap? And my feeling is that this
is not, we can't just, you know, talk it away. My feeling is that we should face it head on and say,
yes, there is a big gap here, right? On the one hand, we can talk about content and consciousness
and the mental and intentions and norms, health, you know, being, you know, worse or better and so
on, terms that have no frame of reference in the purely physical sciences, but they do
have an existence and we know they make a difference, so we're realists about it. So why don't they show
up when we do our best science, you know? And one of the things that, you know, already should come
out of this is that just because they don't show up as such doesn't mean that they don't make any
difference, okay? So that there are two different things here. One would be a demand for observability
and even maybe intelligibility. So I observe something and it makes sense as content. And the
other one is to say, well, maybe that's not what I can do here, but I notice that something else
is happening that wouldn't happen otherwise, you know, if the system wouldn't be in such a state
and so on. So, you know, so far, most people have demanded that the mechanism should be observable
and intelligible, but why should we assume that, right? There's a big gap here. And we know already
from other fields, quantum physics, a prime example, that demanding intelligibility and
observability can be a big stumbling block, right? Sometimes you just have to get in and say, yeah,
you know, we don't understand why it's happening, but something's happening and we can measure that
and we can work with that, you know? But so far, quantum science hasn't done this, you know,
allowed itself to conceive this possibility. So let's go down. So what I want to propose is that
we do need to make this room for this conception. That's why I call it a black box framework.
Let's just for a moment accept that we don't understand this relationship.
So we have two versions of it. Let's stick with the human one for a moment because it's easier
for us to relate to. So we have mental causation. The scenario is, you know, putting our neuroscience
hats on or whatever, you know, looking inside an organism, okay? If something mental makes a
difference to its material basis of this behavior, you've got an unobservable mental cause, right?
Like I said, just said, we just have physical stuff happening. We don't see the mind of such
when we go inside the organism, causing an unintelligible material event. And it's unintelligible
because we cannot directly observe what caused it, what made the difference. That's outside of
the scope of observation when we make quantitative assessments. And the other way around is the same.
So, you know, we know that some things happening in the brain make a difference to mental content
or make a difference to subjective experience, but we can't measure subjective experience directly
inside the brain. It's not there. It's not something that we can actually quantify directly.
So that would mean that to the extent that something is making a difference to experience,
you've got our cause without an observable effect. Okay, so you've got an unintelligible material
effect event here that something is happening, some changes happening, but we don't understand
why it's happening. Okay, so we've got these two categories. And what's interesting is that they
point in different ways. So that already suggests that, you know, the signatures for these kinds
of relationships will be different ones. And so this is then where I introduce my proposal for how
to work with this kind of situation. And this is the eruption theory, where if we have the mind
and the matter relating to each other, and we don't know how, okay, this is the hard problem of
efficacy or mental causation or the heart from our consciousness, we know that they're related
somehow. But when we trace one domain to the other, it escapes us. Okay, so let's just go through
this one more time, right? I have an intention of saying words of moving my hand to make a point.
And I can notice that my intention is making a difference to my body, right? If not, it would
be crazy, right? So, you know, I have the experience that there's a coherence between what I want to
do and what my body does, except that I don't know how my body does it. If something gets lost along
the way, I can see the effect of my intention, but I don't have access to how it has that effect.
So that's one aspect of the black box, right? And it's also true of the other side. So now imagine
I'm a neuroscientist and I look at what's happening in the pathway from my brain to my arm to make my
arm move. If it's really the intention as such that's making my arm move, well, the nearsight
doesn't have access to that. He can't measure intentions using his, you know, I don't know,
EEG apparatus or whatever he's might be using. So again, something gets lost. I can go work
backwards from the behavior to all the activity in my body, but at the end, something gets lost.
I cannot actually make the jump to the other side. So that's what I mean with the black box.
We know these things are related, but by some reason, maybe by necessity, we can trace properly,
translates like transparently across. And so that's why I propose the way to think about
this is in terms of absorption and eruption. Absorption means that on the side of the mental,
when I inject my intention to do something, it basically there's a compression effect.
You know, Dreyfus talked about this in terms of absorbed coping, right? So when I'm really
engrossed in my activity, actually, there's a narrowing of my vision. The world disappears
a little bit into the background. I lose myself and so on. There's a kind of like compression
of the variability of my experience as it's invested into the activity of my behavior.
But what happens on the other side? Okay, now you're totally involved in generating your behavior,
but that involvement is subjective involvement. It can't be quantified. It can't be translated
into something happening purely in quantitative terms. So then that means that there's a hidden
variable. Okay, now there are factors making a difference to how your behavior is generated
that cannot be traced to causes at that level of description. That's what I call eruption.
There's a kind of diversification, an increase in variability that in principle would remain
unexplained at that level of description. And we can trace it back to the higher level.
And that was the original proposal of eruption theory in the first paper. And I
like elaborated on that part a lot. And there's many examples that we can talk about of,
you know, how this fits with some of the empirical data. And when we talk about neural
entropy and complexity and all this kind of things, you know, and why organisms are such
noisy systems in the first place, you know, like a lot of this starts to make sense from this point
of view. But then let's talk about the other side first for a moment. That's the absorption. That's
a new part of this paper, which is to say that if there's a cause that has an effect which can't
be observed, it's a little bit like a reduction in variability. The difference that would have been
made is now not being made because that difference is appearing in a domain that I cannot directly
measure in the one that I'm currently observing. So there's a reduction in variability. So two
things kind of collapsing or canceling each other out. There's information loss of a different
kind as things are getting kind of translated into the to do the other domain. And so right now
what I'm working on is more on the right hand side trying to flesh out that part. And, you know,
it's coming together quite nicely with the things we've been talking about, like both time
motifs and things like that, which are very nice ways of canceling out things. I think that's
pretty much it. So just let me just end on one final note, which is that in my mind, this is just
a first step of something much more general. And so what it looks like to me now is that
this is just one special case of an interaction that crosses two ontological domains,
or regional domains, regional domains of being, or if you want, it could also be considered as
crossing different scales of agency, right, going from the scale of agency of inside your body and
all the agents that are working there to your agency as a person. But basically, as long as we
have a transition between ontologies of some kind, then this kind of framework probably will apply to.
And that could even be true for cellular biology, for example. So when I was reading your work on
how is it that the higher levels, you know, transform the lower levels, and how do they
get incorporated into the higher levels again, you have very similar notions actually as eruption
and absorption already. So with eruption, the way you phrase it is that there's a deformation
of the energy landscape of the lower level, right? So suddenly, you know, these guys are
happily doing whatever they're doing, but now there's an unexpected change in the kind of in
the game that they're playing, and they would have to study adjust. And from their point of view,
well, they will never be able to figure out why that happened, you know, what just happened.
That's all the outside of their scope, right? So it's a little bit like an eruption in that sense.
There's an increase in a change, unexpected, and it can't be explained at that level of description.
Okay, it just goes beyond it. And at the same time, when you talk about how the components get
integrated into the larger whole, you talk about something like a loss of identity or something
like that, right? So for example, the molecules produced by one cell, well, you know, they're not
tagged with the name, right? So if another cell produces it, you know, they can't distinguish
where it's coming from. So they kind of like, you know, the identity starts to merge between
the different little components. So that's, that's very close to what I'm talking here in terms of
absorption. And so one thing that would be very nice to contemplate is whether this kind of framework
gets a quantitative grip on some of the things that are happening at those scales. So not just
talking about the mind body problem, or mental causation, but just talking about multi scalar
integration to some extent. So principles that would apply to the left-hand side, the rupture side
would be, you know, increases in noise, increases in hidden variables, dimensionality, you know,
entropy, these kinds of things. So there's an expansion of variability and that expansion
is unexpected and to some extent irreducible to the things that are happening normally in that
domain. And on the right-hand side, you have things like compression, maybe synchrony, symmetries,
order parameters, this kind of thing where there's a kind of informational loss as
multi components that could be behaving differently normally, don't behave differently.
And that's maybe the both time motive and things like that fit into that category.
So anyway, that's kind of the mini overview of what the paper proposes.
Yeah, very, very interesting. What's your thought on, is there, do you think there is a similar
problem in the case of, so let's say we have some sort of classic computational device,
it's running some sort of algorithm, you know, and then there's the physics perspective where you
can see the electrons shuffling around, you don't actually see the algorithm, whatever it's doing.
Do you think there's a similar dynamic going on there, or is there something unique to the
biological case that isn't captured in the software hardware dichotomy, if there is?
I think it's a really good question. It's one that I started exploring now with some colleagues at
O'Nam. And I think I'm changing my mind about it. So I used to be very resistant to that idea.
I'm slowly coming around to it, especially on the side of absorption. It's almost like
computers are the perfect absorption devices. All that variability that you have at the level
of electrons and so on, computers are designed such that variability does not matter for the kind
of algorithms that are being implemented. So if anything, that is the most excellent example
of the right hand side. But here's the problem. It's like one-sided. I don't want to put it this
way, but it's like we create devices that are super rich in experience, possibly. So they've
got lots of variability that they're absorbing and possibly creating experiences for them,
but they can't do anything about it. It's the eruption site that's blocked. Because if you do
have things that are acting on those things, well, that's like the old school Windows blue
screen of death kind of stuff. Like suddenly you've got an unexplained change that can't be
reduced to the rules at that level. Well, you've got error correction. So either it gets thrown out,
or if it can't be thrown out, well, then you just got a system failure. So it seems to me that the
issues on that side is like, if you wanted to make computers that could fit into this framework,
the question would be, how do we loosen them such that the higher levels can make a difference to
the lower levels in their own terms? Yeah. Yeah. So we have a weird example that might be
relevant to this, and that's maybe this. So I'm very interested in higher order behavior that
seems to be, in some important sense, decoupled from them, either the algorithm or the mechanisms
underneath in that it is not just emergent complexity, because emergent complexity is easy.
You get that with cellular automata, whatever. That's easy. I'm talking about more interesting
emergent goal directed behaviors. And you've seen this preprint of ours on the sorting algorithms.
I purposely wanted to start with the dumbest, simplest system that is transparent, deterministic.
Six lines of code. Everybody thinks they know what these things do.
And these sorting algorithms, and it turns out that they have some really interesting
behaviors, including this clustering thing, which is, by itself, nowhere in the algorithm.
And so I wonder, now, clearly super primitive, but that was kind of the point. We wanted a
very basal example of this. But I wonder if it's related to what you just said, where
they, on the one hand, yes, in our current architectures, they can't do anything with it.
On the other hand, there seems to me, and I think this is all over the place in biology, too,
there seems to me that even though constrained by deterministic algorithm, that there's no
magic, it doesn't screw up, it follows the algorithm, there's no error in that sense.
But it also manages to do some things that are not, so to speak, in the algorithm.
And I wonder if, and I think biological things are super good at it. In fact, I think that's
probably what we call biology or systems that are really good at this. But fundamentally,
I feel like it starts very, very early. I don't think you need much to start seeing these things
appear. And where do they come from as a whole other thing? We face that question with our various
synthetic Xenobots and Anthropots and things where they've never existed before. There's no
evolutionary long history of selection that would explain why they have certain properties.
So where it comes from, and I mean, I'm pretty sympathetic to this kind of black box approach
because I think looking for mechanism and looking for explicit representations in terms of how it
works and where things come from, I think may not always be tractable. But yeah, I think already
we have some of these issues in a very minimal way with even just very simple stupid computer
architectures. And then there's the whole polycomputing thing, right? So this is what
Josh Bongard and I have been working on, on this notion that when you have a physical process,
what it is that it's computing is in the eye of an observer. And multiple observers, in fact,
Josh has some amazing, his student Atusa has some amazing actual data on this showing that
the same physical processes can look like very different computations depending on how you look
at them. And what is it that it's really computing is up to an observer's interpretation,
which I think in biology, that's what's going on is that every subsystem is interpreting
every other subsystem however it can. And then that also gets to this issue of mental content
and the subjectivity of it, which is, what is it really? What are these mental causes and so on?
What is their actual content? And is there a privileged one answer to say, okay,
that's the content of that, you know, that mental state? Or could we could we do this
kind of polycomputing thing and say, well, there are modules inside and based on what you were
telling me before, there may be even physically external other beings that that you may be coupled
with in some way that will also have an interpretation of what the what any given mental
state is. So, you know, yeah, I think this is this is partially why, you know, we were talking
about like how far down it goes. I think these issues are very deep and they crop up very early.
I don't think they, I don't think we have to wait till we get brains before these deep
questions come up, you know, of interpretation. And I've heard you talk before about this,
you know, polyfunctionism or what you call it. But isn't it the case that
was it put number someone who used the argument that you can read any kind of function into
physical process as I deduct you out of service for computationalism, the sense that if you want
to be realist about the implementation of the algorithm, then then you know, it shouldn't just
be the observer who, you know, determines what kind of algorithm is being run. Because I don't
know what this argument was, but it was basically like, you know, if you take any bunch of molecules
and you just sub select, you know, the right kind of properties, they'll be running windows or
something like that, you know, because there's such a mind blowing degree of freedom that,
you know, there's enough there that, you know, you just have to be selective and then, you know,
you get whatever you want. But, you know, but the question is, like, does that have downstream
consequences for the process, right? And so there you don't want necessarily the observer to be the
one who determines what it is that was there, right? You know, I so I don't know what the
reductio there is, maybe I need to look it up. But but it seems so far, I it seems fine, everything
you just said seems completely fine to me, because what I think happens in biology is so so in
computers, we're used to the fact that there's somebody who wrote the algorithm, and we sort of
we tend to take that interpretation as the privilege. Like I know what this is, I wrote it,
that's what I'm telling you, it's a bubble sort, whatever it is. But but in biology, you don't
get that. And so every every subsystem with cells, subcellular components, tissues are looking at all
the stuff going on around it. And they don't, you know, they don't get a manual to say, well,
what the hell does this mean? There's signals coming, what computation is this? And I think
what they have to do for adaptive advantages, interpret it however they can. So they form
their own internal model of what the computation is, and say, Oh, I see what this is, this is,
this is telling me, you know, that the metabolism is going to shoot up a five minutes from now.
And somebody else in this some other module is looking at that. No, no, no, what I see here is
that this set of genes is going to be expressed. And therefore, I'm going to do this and that.
And right. And in that case, and, and, and, and, and, and Josh is in Josh's work, you can see this
like, it's this particulate material. And depending on how you look at it, you see an AND gate or an
OR gate. And there is no privileged answer to well, which one is it really? I mean, there is no
really. And I think biology has that takes that to, to, to, to an extreme.
But many, many, many, many, many, many, maybe I should read this, but, you know, if I had a
computer built, and like, you know, there was an ambiguity whether an AND gate was an AND gate
or an OR gate, would the computer work? No, right? I mean, like, you have to depend on that it does
a particular translation of its inputs to its outputs. And if it doesn't, then, then, you know,
well, then you have a kind of proper realistic machine or something like that. But you know,
it would be some kind of other kind of system. Well, so, so, so let me, let me push back on that.
I think that that's true if you stick to one observer and an idea and the idea that I, there is
a definitive one thing that I that that observer wants it to do. And, and then yes, if the observer
can't, if one observer can't tell what it's doing, that's a real problem. But I don't think it's a
problem if you have a physical device, and there are multiple observers, and one observer says,
oh, this is this is this is great, this thing's generating prime numbers. And somebody else looks
at it and says, oh, whatever, I what what I see is that it's, I don't know, it's doing it's doing
some other function. Now, you know, for us, I mean, it's it's statistically very unlikely that you
can say, oh, look, it's running Windows and somebody else says, oh, no, it's completely different,
because it's it's hard to have a process that matches both those descriptions at the same time.
But, but, but I think what happens in biology, because there's there's noise, there's there's
a high tolerance for fuzziness and all that, there are lots of systems that that are looking at the
same set of events, and interpreting building internal models of those events as completely
different, different things. And it's like, you know, I agree with that. But that's from the point
of view of, you know, looking at it, right? So if the point of view is that there are multiple
interpretations possible, and that diversity of points of view is helpful in some way for the
systems around it, I can I can I can totally agree with that. And I think that's interesting to explore.
But that's very different than saying that those multiple possible perspectives make a difference
to the process itself, which is lending itself to be interpreted in these multiple ways.
Well, what I think what I think then happens is so the so the second the other side of the
I think you're absolutely right in how you divide this right into the two the two sides.
So the other side is tenon bombs. Have you seen this, his paper, The Child as a Hacker?
Child as a Hacker. It's really good. And it's this notion overall, I mean, so like I
sort of expand that beyond me, he's studying, you know, brains and human development and so on.
This the notion of hacking is from where what's fundamental there is that
you don't know or care what the correct way to to interact with a system is,
you are going to exploit it however you can, right? That's that's kind of this notion of it.
And so so I think what happens in the in the biology is that part of interpreting these
things however you want is that you are also going to use that to control them however you can.
So you try to find ways, right? So so I think that's basically what's happening in in in biological
material is that every both within levels and across levels, you have systems that are constantly
hacking each other and track not completely agree. So here we're on the same page. Actually,
it's like, you know, this is something that also follows from the frame where it was proposing,
because if you if there's a black box, basically components at different levels have to have a
high level of tolerance of uncertainty. And they have trust they have to have trust to some extent.
Sometimes from their point of view, it doesn't make sense what's going on around them.
But that doesn't mean that they should disengage or kind of like, you know,
fight it or try to resist it or counteract it. Because what it could mean is that actually
it's a different level of agency, a high level of agency, rearranging things, aligning things.
And, you know, you need to just roll with it, even if you don't have everything that, you know,
is required in order to understand where that's coming from. And but if because of that,
there is a gap for, you know, free riders or pathogens or something like that,
to take advantage of exactly the same trust, trusting nature that, you know, okay, today
I'm producing this other molecule, I don't know why I'm producing it. Yeah, it turns out you're a
hijacked by a virus, and it's not, you know, the higher levels that are kind of like, you know,
messing with you. So, but yeah, that's kind of built into this system. So so you can't avoid it,
you know, that's because it's such an indirect architecture, that which allows the multi scalar
integration is also that which allows like, you know, bad things happening to some extent.
Well, absolutely. And my guess is, and we're now starting to explore this experimentally,
is that systems have probably way by biological systems probably have ways to try to determine
whether something that's happening was caused by me versus.
Nice. I want to do the same for the brain. Yeah, there should be probably some frame of reference
in the background that tells you how much unexpectedness should you be expecting at each
moment, rate of unexpected events, for example. And if it exceeds your expected rate of unexpected
events, something else is messing with you. Yeah, that's, that's, that's right. Right. So,
so it's the question of, there's a couple of ways to pose it, like, am I learning or am I being
trained? That that's that's interesting distinction, right, because how much agency is there in my
environment? Is there another agenda that's responsible for my learning process? And if you're
a cell, like, so the way we're going to do it is basically to look at a readout is going to be
stress response and some other things. But you know, you can imagine a cell or a group of cells,
and you can imagine messing with it in progressively different degrees of internal
targeting. So, so here's a signal that comes from the outside of the cell. Fine. Here's a signal that
we generated, you know, in the second messenger pathway right under the membrane, here's something
that we did in the nucleus itself. Like, right, at what point, at what point does the cell say,
yeah, that's cool. That's what I'm doing versus, you know, oh, no, this is clearly coming from,
from outside. And I think so this has quite the response like a brain stimulation. So I want to
get into that for lab. And one of the reason is that if eruption theory is on the right track,
you know, doing TMS to the brain or whatever stimulation is basically eruption simulation,
right? So suddenly you have an uncost fluctuation in activity. But from the point of view of the
local components in the brain, they're used to that. That's the always that that's already how
they always get impacted by higher levels of organization. So then it's kind of like, we're
speaking the language of the higher levels of organization by injecting this, you know, you
know, external variability. And that's that's nice, because then we can actually play with this,
like, you know, we can say, what's the rate, you know, of agency that the system is currently
expecting. And there's all kinds of interesting things like, you know, why, why is deep brain
stimulation helpful for overcoming, I don't know, obsessive compulsive disorder, or maybe like helpful
in depression and so on. So certain conditions where our agency becomes constricted, somehow
compressed or limited, are helped by what otherwise looked like kind of crude interventions. Like,
you know, why should just putting this kind of like, you know, random stimulation somewhere in
your brain, you know, have the same effect as you opening up your space of agency possibilities.
That's very strange. But if the way in which agency of a personal level connects with the
subperson level is only indirectly through this deformation of the state space in unexpected
ways, basically, well, then all you have to do is deform it in unexpected ways to mimic,
to some extent, the signals that they're expecting from the higher levels.
That's a that's a really, that's a really interesting point. I wonder if I want to end
that this is like totally beyond my expertise. But but I wonder if some aspects of plastogens
and psychedelics and things like this can be understood by what what you're really doing is
lowering the vigilance of the system to to hack from the higher levels, right, so that so that
you're more willing to sort of not resist. I mean, this issue of resistance, right, knowing that
you're being hacked, whether, right, whether laterally, whether by a parasite, whether by a
mis like a malfunctioning component, or from above by some, you know, some higher level of
organization, that resistance, like biomedically, this is huge, because one reason I think why
why we have to trouble designing new drugs that actually fix anything. And we have almost other
than antibiotics and surgery, we have basically nothing that fixes anything, right, these drugs
hold down sometimes best case scenario, but they don't really fix anything. And I think I think
part of it is that we are operating in a way that's very easy for the cells to tell and try to
fight back. I like it. Yes, I think that's the limit. I know that someone else is messing with me,
that's not coming from the higher level of organization. Because because it's such micromanagement
and the cell that was this, there's this, you know, receptor that's being targeted by some
frequency. That's why, you know, you see, you see all these drugs, and then there's like a list of
potential side effects that are a mile long, that you know, your head will fall off and you'll
go blind. Yeah, no, you're actually on the right track here. So I'm thinking that there could be
a spectrum of possibilities. Because we're now we're separating mine and matter a little bit,
just a tiny gap between them. It opens up two possibilities. Imagine we have a reduction in
agency, like dementia, okay, so people stop being able to express themselves, language goes away,
they stop being able to, you know, take care of themselves and so on. But in that case, it could
be that the brain itself is no longer, you know, flexible enough to be able to receive these kinds
of perturbations and let them percolate through the system and scale them up in the right kinds of
ways. Could be that agency is almost intact to some extent, like the mind is still there, but it
just cannot find the channel to express itself. On the other hand, maybe in some other cases,
like I say depression, it could be that, you know, the brain is fine, you know, it's actually ready
to receive whatever you're going to send it. But there's something happening at the level of
motivations and will and like experience, which the person is overwhelmed or for whatever reason,
it's not sending the kind of, you know, impactful interventions that would normally make the body
move in the right kind of ways. So both might from the outside look similar in the sense that
there's a reduction of engagement with the world, but the physiology of it could be very different.
So, you know, so I like that because it feels more natural to have these two
possibility access, you know, it's not always everything in the same place. And what you're
saying about the fact that we need to be a little bit more clever about how we interact with that,
I really like that. So that makes a lot of sense. So and what you're saying about, you know,
the intervening in the different levels, we're starting to think about that too, in terms of
humans, right? So we can trigger muscles directly, you know, by applying, you know,
contraction to your nerve fibers here, that's, you can grasp like that. And that also can feel
like you're actually doing it if it's doing in a good way. But what if we do it like, you know,
from here, or what if we do it by doing something here? At which point, you know, is there a sense
for, Hey, this is not me doing it anymore, or something like that. Yeah, yeah, that's, that's
very interesting. I was, I was actually trying to look up some papers on this related to confabulation.
And, you know, people, people with like, like I've seen, you know, examples where somebody has an
electrode in their, in their brain and, and it triggers laughing. And so push the button and
your mouth starts laughing. The patient doesn't report. That's weird. I was, I was having a serious
thought and then my mouth starts laughing. That's what they say. Oh, I had a funny, you know, I
thought of a funny joke. That's what they say. So, so, so this issue of confabulation and to what
extent does the system, as you said, does the system take this on as, okay, I'm going to tell a coherent
story of why it was me versus I'm going to accept that. And actually, the dementia in another, I
just wanted to say another quick thing about dementia and those things. I have a, a collaborator
who is a hospice nurse. And she cares for, she's not a, you know, not a scientist, but she's a,
she's a long term hospice nurse with a lot of experience. And we're actually writing a paper
on case studies, where what seems to, there's this phenomenon called terminal lucidity, which is
really interesting, where basically you have somebody that has been in a very debilitated
state for a really long time. And, and it's just, you know, progressively been going down, they don't
speak, like, you know, all that stuff. And you think, okay, you know, that, that's it. Like, it's
all gone. And then I think I forget the exact amount of time, but I think it's like a couple days
before they actually die. It all comes back and they have a lucid conversation with people and they,
you know, they remember things and they give some, you know, some, some instructions and whatever.
And like, there's this like sudden, sudden burst, like, and, you know, and it's, and it's, I don't
think there's a good clinical understanding of it, because if it's just the fact of the,
of the hardware degrading, then, you know, that, that's nice. Yeah. So having a slight
gap in our account would allow for that, you know, make sense of that possibly. Yeah. Exactly. Yeah.
Yeah, I like it. Yeah. So I think, you know, I think there's that clinical component, I think it
would be cool to study some of that stuff from, from the perspective of the, of the model that
you're, you're putting forward, I think that could help. Here's another interesting example,
clinical example, which is if we think about the absorption side, what would be the maximum
version of it? It would be if almost the whole brain is, you know, in synchrony. Okay. So that's
like, you know, all the local variability, every, you know, each neuron has tens of thousands or
connections coming in, all the variability, suddenly they're all like firing in unison,
right? So it's a huge reduction of complexity, lots of information loss. When you do that,
agency goes out the window, okay, you collapse. Okay. And that also makes sense because now you
can't have any more eruption, right? Everything is ordered, everything is regimented. It's no
possibility for, you know, injecting superior variability anymore, just gets, you know, there's
no room for it. Okay. So no more agency, but the model would predict that experience might still
happen. In fact, it might even be more happening than in a normal state. And so I started, you know,
just a little bit investigated, but for some people, indeed, having an elliptic fit can come with
all kinds of experiences, you know, even like divine intervention kind of experiences, right? So,
you know, like, you know, having a, you know, something that changes your life kind of experience
can happen under those states. So that's, that's interesting in the sense that it fits again with
this model that, you know, on the one hand, although it knocks our agency, now your, your
experience channels have been opening up, you know, on the other hand. And so it's, and sometimes,
you know, like, there's something there that, you know, there's lots of this kind of thing that,
you know, it mentions psychedelics, we didn't talk about this, but, you know, it's like the other way,
maybe it's actually loosening things up. So it becomes easier to integrate with your brain.
And that fits very nicely also with other work that shows that if you're under anesthesia,
you know, if you measure neural entropy, complexity, diversity of signals,
it turns out that if you're doing a cognitive task, while you're slowly falling unconscious,
if you're doing the task well, your neural entropy is higher than baseline.
Okay, so even though you're falling unconscious, your neural entropy goes up more than expected.
But if you're actually falling unconscious and you're stopped being able to do the task,
then it goes down. So assuming that both groups of people actually are losing consciousness,
then this kind of entropy is not tracking the state of awareness. It's tracking your cognitive
effort. How involved are you mentally in what's happening? And that's going back to dementia.
Like one of the best things you can do for preventing onset of dementia is learning extra
languages, you know, like, you know, engaging in extra normative frameworks, you know,
becoming able to respond in a much more multifaceted way to your environment.
And if you think about the way in which we lived before, you know, modernization to some extent,
we were embedded in a symbolic world, you know, everything had meaning, you know, nothing happened
just by chance, you know, like the fact that this cat crossed the road might mean that my mother
will die or I don't know something, you know, so, so everything had super significance. And
this kind of symbolic framework was overlaying on all of our perception. And if involvement,
mental involvement in our behavior is actually causing eruptions, well, then that has very
loosening effects on everything. So it makes sense to me that the best way of preventing your,
you know, like things freezing up, so to speak, is to actually become more involved normatively.
And it's not just about, you know, autopilot stuff, this is important, right? So it's not,
if you're just an autopilot, you know, your body can take over. And maybe that's also a little bit
about what you were saying in terms of stimulation. And then, you know, this kind of confabulation
happening, right? It's kind of like the habit. The habit takes over. It's not like you're really
freely willing the words coming forward. It's just that your body has already made response
to the situation that's kind of like, you know, unfolding in that moment. And I think a lot of
our behaviors like that. And what I've been speculating a little bit that the success of
large language models, to some extent, hints that, you know, even when we talk like this
conversation right now, a lot of it is actually habits and our body's predispositions just
unfolding themselves with the affordances and the environment. And that's why they can be modeled,
you know, by just looking at, you know, linguistic patterns and so on. And so this is another
consequence of the eruption ideas. And if you have this little gap, it also means that we're no
longer directly in control of our behavior, right? We can set the intentions, we can open the space
of possibilities, we can make things more flexible, for example. But then you have to be in the right
context. You have to have the right affordances. You have to have the right history of interactions.
You have to have the right body for that behavior, then to also express itself in the right way.
And if some of these things start crumbling or deteriorating or something like that,
then maybe intentions don't connect that well anymore with your behavior or with your regulation.
But when things work well, it looks like we're in control, because, you know, the body just makes
it happen, like magic almost. But, you know, all we can do really is to go open spaces of
possibilities. But to turn those into actualities is coming out of our embodied history of interaction
with the environment. So it's a different take on free will, it's interesting, because yeah,
you're free in the sense that you still have the choice of opening possibility spaces, but you don't
have the choice of how to close them. The only way to do that is to cultivate the right kind of
environment and the right kind of skills such that you're always poised to respond in a way
that you want to be responding. Yeah, yeah, yeah, I completely agree with that. I like a notion of
free will that basically extends it to a longer time scale to the idea that what's free is
modification of self and environment to enable you to do it in different ways in the future.
That's where you get to really exert it, right? Yeah, yeah. And it's a bit strange to think about
that in the first place. I mean, just thinking about like, you know, hey, I can't directly control
the next word that's coming out of my mouth. I just have to trust my body that it will choose
the right word. Otherwise, I get a Freudian slip or something like that, you know? Yeah, but, you
know, once you're okay with that, then, you know, your focus shifts and says, well, what can I do
today such that tomorrow it will be better? You know, this kind of thing. Yeah, yeah, I think
that's a much more useful view of it. Yeah, and I think it's true of all of biology. It's close
the same way. So, you know, there's a slight indirection, which is basically the higher level
of organization can't directly control what the lower level is going to do, right? You can set
the conditions for it. You know, I guess it gives you more possibilities to do things or I give you
less. But, you know, within that space, you know, I just have to trust that the tendencies are the
right ones. Yeah. Excellent. Yeah. Thanks so much. This has been very helpful. Yeah, I think it's a
really interesting framework. So, yeah, play lots and lots of talk about. Great. Yes, thank you.
And look forward to seeing how you work with this experimentally when you start intervening at these
different stages. I think that's going to be very insightful. Yeah, yeah, well, we'll talk more
because I want to get your thoughts on some of the you basically using some of the, you know, brain
clinical data to inform how we do some of the things themselves. So, yeah, I think that, you
know, there's a new horizon opening up with this way of thinking, you know, suddenly we can quantify
these things and then everything changes. Yeah. Yeah.
