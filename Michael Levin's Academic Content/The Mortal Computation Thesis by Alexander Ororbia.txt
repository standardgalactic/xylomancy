Yeah. Thank you for having me, Michael. And thank you, everyone, for coming to the talk.
So I'm going to talk to you today about some work that my friend Carl and I have done.
We call it the Mortal Computation Thesis. And I think it complements some of the things
that I know Michael's group does. Actually, in fact, we cite particular mortal computers
that I will get into a little bit later. And we can talk about that perhaps. So just
very briefly, who am I? So I'm Alex Rubia, and I'm the director of the Neural Adaptive
Computing Laboratory at Rochester Institute of Technology. These are my students, as you
can see. And we work on quite a few things, but our primary focus is building biomimetic
systems and the learning algorithms and computational architectures that would facilitate their
learning and inference with the goal of obviously building things in hardware substrate.
So again, neuromorphic computing might be familiar to some of you. We also work on a
lot of things based on the free energy principle. Some of you might have heard of predictive
coding or active inference, and my group contributes to that. And we have a lot of collaborators,
but this is just our brief little intro. So you might be asking, what exactly is mortal
computation? And if you're familiar with it, you might be, you might be aware that Jeff
Hinton last year came up with a phrase called Mortal Computation. And one of his works,
the Ford Ford algorithm paper, and the idea effectively is that software cannot be divorced
from the physical substrate or hardware in which it is instantiated. And the idea is
that the calculations and processing are embodied. And in fact, inseparable from the medium,
when the medium breaks down and stops functioning, the software ceases to exist and cannot be
carried out on another medium. This sort of effectively says that the software should die
as long along with its quirks and its properties, if the hardware or substrate that executes it
ceases to function. And of course, this is going to have implications for edge devices,
energy efficient systems and robotics, and so on and so forth. However, this challenges the
notion of immortal computation in computer science, sort of a foundational idea that we can
essentially write our program independently of the medium that we're going to execute it,
and that this program or software can be copied or executed on another GPU or TPU server, for
example, if you're doing machine learning, and it's going to pretty much run the same.
It's not going to have any particularities that are tied to its actual medium. And so effectively,
the knowledge and characteristics that your program acquires is done irrespective of the medium
in which you're executing it. So this is the work that maybe I believe you were linked to.
It's a little bit long, so I don't blame you if maybe perhaps you didn't read it all. But this
is work that we sort of did like a review and then sort of a perspective on what mortal computation
really should be as Jeff sort of just introduced it in about a couple of sentences. So Carl and I
wrote 40 pages roughly about it. So why exactly mortal computation? Well, part of it is a thermodynamic
consideration. And this is basically getting at the relationship between information processing
and thermodynamic efficiency. The idea effectively is that we want to adhere to Landau's principle.
And these are just some principles I'm going to briefly introduce. Those of you who might have
deep physics background might even understand them even better than myself. But the idea is that
there is a minimum amount of energy required for any irreversible operation. Think of like
erasing a bit on your computer. And it is proportional to the operational temperature
of the computing system. And I just give you the relationship here. Pabea's Boltzmann's constant.
And the idea is that an irreversible change in a computer's stored information requires
dissipation of a minimum level of heat to the environment. This is paired with the Jarzynski
inequality. And I have a floating bullet point there, but that's because I wanted to remove
some unnecessary detail. But the idea is that we're talking about the difference of the free
energies, the physics free energies between two states, x and y. And we are saying that
the difference between them can be constrained to be equal to the average of the work, the physics
work done from all paths taken from perhaps an equilibrium state x to a typical non-equilibrium
state y. What does this really mean in plain English? Well, roughly we can know something
about a system's equilibrium by observing the system when it is not at equilibrium.
And so the main takeaway when you pair these ideas together, as Carl and I argue, is that
there's a lower amount, lower bound on the amount of thermodynamic work that you need to do to change
information content in an information system. And so this of course has wonderful implications
if we can get our intelligence systems that we try to strive to date in artificial intelligence
to emulate to build something that adheres to in-memory processing. And effectively this just
means that we are changing the computer's information content and we are saying that it's
equal to the inference belief updating in response to external perturbations. So as the
computing system is dealing with an environment, we essentially want to be working at as close as
possible to the substrate. These calculations should not be divorced. And then of course we can tie
this as I'll show you a little bit later to the variational free energy formulation. And effectively
that when a computing system or an intelligence system is minimizing its variational free energy,
it's the same minima as the thermodynamic free energy. And there is equivalence in work that
we point you to. And so of course the idea is that we need to essentially try to circumvent what's
called the von Neumann bottleneck or the memory wall. And that's the idea that when we are doing
things you might be aware of deep learning and what is rocking the world of artificial intelligence
to the state. We're effectively executing our programs on software that is in random access
memory. And as you can see in the bottom left diagram, there's a lot of expended energy to
start moving information from long term memory, depending on your computing structure to random
access memory. And so we essentially would like to overcome that. And that's sort of what
just one common example that we see today in memory computing is neuromorphic computing,
where we're effectively designing our biological models, our neuronal models, actually as close
to the hardware as possible, and using things like BEMRisters to adhere to synaptic connections,
and so on and so forth. But ultimately the idea is that realizing thermodynamic efficiency
of Bayesian computations, which is effectively what biological systems we are doing,
requires belief updating in memory. To be Bayes optimal is to be thermodynamically efficient
and vice versa. This also has some wonderful implications for green AI, which is this argument
that we need to essentially figure out how to do the intelligent operations we do today,
without expending the quantities of energy, chat GBT and transformers themselves are pretty
expensive. So then there's also cognitive philosophical motivations. I won't dwell too
long here as well, but the idea is that there is in cognitive science, the embodiment thesis,
or the embodiment hypothesis and inactivism, which is just effectively saying at a high level
that the mind, your mind or any mind is grounded in its sensory motor accompanying. So the idea is
that we are shaped by the actions that we take, the nature of mental activity, depends on your
body. Effectively, you need to be in some type of actual physical instantiation. You cannot have
what is known in classical cognitive scientists known as brain and event. So the idea is that we
don't have something called isolated cognition. We are actually primarily driven by our body,
and inactivism takes us an extra step further. And the idea is that we are dependent on our
environment. Our cognition is we are coupled to an environment we act and effectively that affects us
as well as affects our environment. So a mortal computer in effect is an active participant
in the generation of the information that it processes, thus shaped by the consequences of
how it acts and has acted on its niche. Effectively, this is called niche construction.
And then we also talk a little bit about some other nice connections in naturalist philosophy
and existentialism. That actually refers to a little bit the initial quote that you might have
seen in the paper by Soren Teichegard. But the idea is that there is a finite two to life.
It endows us with purpose entails reproduction and motivates us to pass on knowledge to future
generations. Ultimately, death is a horizon that shapes our behavior and consciousness.
Now, of course, while mortal computation doesn't go as broad and as far reaching as existentialism
and other aspects of natural philosophy does, it does actually we do pull or extract a small part
of it, talk about that even animals in any organism is implicitly constrained and conscious or maybe
not conscious of the fact that they have a finite horizon and they act accordingly.
And of course, there's some other parts that we touch on in our framework about
operational closure, which is just the idea that the system must auto undergo auto poetic,
met self assembly and self maintenance to keep separate its internal states from its external
states is going to motivate the Markov blanket construction of the mortal computer. I'll talk
to you about later. And then of course, the idea of sense making, which is that there's a mutual
dependence between external processes and an entity, whether it's a biological organism or
rather any mortal computer as we generalize, because a mortal computer does not need to be
artificial. We are all effectively mortal computers. A biological system must distinguish
itself from its niche, yet be coupled to it in order to persist in that niche. And this will
motivate the idea that we don't want to dissolve in our heat bath. We don't want to cease to exist.
So effectively, a part of the work that again, you might have read is it's a review. This idea
is interestingly enough echoed for many, many decades across both kinds of thinkers and engineers
and wonderful ideas have cropped up throughout time. So we sort of unified them and scoped them
out. Obviously this talk, given time constraints is not going to possibly go into all the details,
but I will give you a swath. So sort of you can think of the paper or the concept in terms of
three particular slices. That's why it's called the three slices of mortal computation. We have a
biophysics physiological naturalist philosophies interpretation in the top left towards the top
bottom left, we have a cybernetics interpretation, and then a cognitive science interpretation.
And I'm going to give you some of the highlights. So we're going to start with the biophysics
aspect of our framework. And I'll just leave this diagram to sit here as I explain just a few of the
key concepts to sort of parse it. So the idea is that a mortal computer self organization
constitutes its thermodynamic and metabolic efficiency. And we talk about metabolism and
autocatalytic closure as some motivating concepts. But effectively, these ground it's the mortal
computer's agency or its ability to adapt. Ultimately, we need to understand that a mortal
computer is not a thermodynamic equilibrium. And it operates as a dissipative system,
given that energy and matter would be lost by essentially in the ideas that we are adhering
to the first order first, the law of biological thermodynamics, which allows us to reconcile
and ensure that we are still adhering to the classical second law thermodynamics, entropy
has to increase the environment. But in biological open systems, we don't see that we see entropy
decreasing. So the idea is you have to kind of view it all as one big closed system, you need the
environment and the entity itself. But ultimately, a mortal computer or any entity that could be
considered one, its metabolic organization stands far from thermodynamic equilibrium.
And so ultimately, it needs to forage like any living system or any system to continue to acquire
new resources. This sort of motivates like that bottom level, the diagram, the metabolic processes
are essential primitives. This is something that Carl and I chose his language to pull a little
bit from cybernetics, and bring it back into the biophysics interpretation. But ultimately,
these are the foundational components of a computer or a mortal computer or any system
arranged within a morphology, of course. And then of course, we need homeostatic or
homeohedic processes that live on top of it. This is our active regulation of those essential
primitives. And the ideas that we have metabolic processes is we discuss reactions that use energy
to trans materials into structures that then harness further energy to transform transport
material, eliminate toxins or surplus material. And of course, this is sort of our way of keeping
track of set points if we want to stay within a certain range or near a particular value.
And so we need to be designing out homeostatic processes, which ultimately, by the way,
you'll notice that there's these arrows for influence in the diagram. So all of these processes,
in effect, should have some type of influence on their sensory motor action. This is motivated
actually a little bit by work by Egbert and others on chemotaxis and talking about metabolic
dependencies and the idea that action is shaped driven by your metabolic functions. Sometimes
it can be entirely dependent on only dependent on that. But we sort of generalize it a little bit
to allow some design flexibility. On top of this, any of you are most likely aware of what allostasis
but we also need allostatic processes because this is instead of having error reaction or
reactive processes, we have error correction processes as well. So this is what serves homeostasis
or homeohesis, precludes future deviations to the essential variables. And then of course,
at the very, very top is our auto-paedic autonomy level. And this is where we need to
account for the fact that a mortal computer, if to be unification of artificial as well as
biological systems, needs to have the ability to make itself from within. It must continuously
reproduce, organize, maintain the relationships between its parts, and as well as do this without
external intervention. It must come from within. And of course, then we have the notions of morphogenesis
because the idea is that the mortal computer needs to persist longer than its actual physical
instantiation of its components. So it means its actual organization or relations live longer and
that's its identity throughout time. This will also motivate the self-evidencing aspect of mortal
computation and it's continuously reproducing itself. And then as I mentioned, there are motor,
sensory motor dependencies that a couple this to its niche. So ultimately, what does this really
tell you at the highest level? Well, that we need to essentially design our mortal computer system
with the niche in mind. The niche cannot be this decoupled or disentangled. We need to understand
the properties of the niche as well. Again, some might be wondering from computer computational
backgrounds, won't this make the system rather brittle because it's rather dependent on the body
in the niche that you are designing? But that's sort of the point. The idea is that your behavior
and your cognitive functionality is directly dependent on your physical instantiation and
the environment or niche in which you live. So again, the organizational closure of the mortal
computer, it means that the mortal computer operates on the basis of self-reproduced structures.
And as I've said already, the mortal computer is auto-poetic. And so this is where we have
sensing, actuation, and we need to be modeling or essentially accounting for energy exchange
and matter transformation. And so again, at the bottom right is our reinterpretation of the
homeostatic dependencies of some good work over the years. Well, we just have that as a little
more, and it was called, well, we generalize and call it homeostasis dependent, but it was originally
called metabolistic or metabolism dependencies. So now we can move on to what we call the
cybernetics backend. And again, this could take a while, but I'm not going to dwell too long on it.
Effectively, what I want to say to you is there's a couple of concepts that we can bring from
classical cybernetics. It's sort of like the forerunner to aspects of computer science and
certainly to artificial intelligence. But ultimately, cybernetics deals with this concept
known as retraction. A system must incorporate ends or goals into its means or mechanisms in
order to ensure goal attainment is absolutely inevitable or almost inevitable. And so the
system essentially the question that characterizes cybernetics is how can a system learn what it needs
to know in order to act effectively? This gets into those notions of self organizing systems,
elementary parts and local interactions with upward and downward causation. And we detail
these a bit more in the paper and point you to plenty of references for all those details.
But the idea is that the system is dealing with variety. And this is the central concept behind
cybernetics. And you can see as you see on the slide, it's the number of distinguishable states
in a system state space. Another way you can interpret it is the degrees of freedom that a
system has in choosing what state it will be in. This can be reduced via selection. And this leads
us to sort of organizing and another aspect of cybernetics is there's a lot of principles and
laws. And so we try to organize a couple of them into three central pillars that we felt were
useful and complementary to the notion of mortal computation. So we organize them into,
as you can see in the bottom, stability, regulation and growth. And so effectively stability is going
to relate really nicely to homeostasis and homeohesis as we discussed in the biophysics
part of the talk. And the idea is that the system ultimately its goals to reach a state of stability
or ultra stability. And all this means is that it performs selections to cross state space to try
to reach new states until it converges to a place where essentially it doesn't need to alter its
part to part relationships. It sort of stabilizes and ultra stability means it's found an attractor
it really likes. So this is a good place for the system. It's very hard also for it to leave
that particular state. So ultra stability is effectively it's able to maintain its homeostasis.
It keeps those variables near its set point. It has all that it needs to sort of stay
in a good configuration. And then of course, there's other principles like the principle of
asymmetric transitions. And these are things that are characterized deeply in cybernetics.
System in unstable configurations usually moves to stable ones, but not the opposite.
And again, a system as it rejects fewer states as it reaches more stable ones,
the variety decreases as the system becomes more organized. Again, it's sort of converged to a good
state. You can equate variety with thermodynamic free energy. But the idea is that then the system
does work or it exerts its variation to reach those stable states. If it is stable, it's not
going to undergo variation. And it's less likely to expend the energy to leave its current stable
state. So then the other aspect or the other pillars you can see on the right slice of the diagram
is growth. And again, we're not going to talk about all little sub principles. Again, I recommend
reading work to see how they all kind of fit together. But the idea is that our mortal computer
must be morphogenic. It maintains its continuity and integrity by altering aspects of its
organization structure over time. Morphogenic processes may also be triggered by environmental
conditions. And then of course, we have this principle in cybernetics of self replication.
This is kind of really important, something we don't really have in artificial intelligence
systems today. System behavior is important that it results in copying or generating copies of
itself. We do have some classical work like the von Neumann universal constructor, you might have
heard of Conrad's game of life or Conway's game of life. Sorry. Any ideas that these are models of
rules or rule based systems that can show you how you have death and life in the computational
systems? And then another important notion is that reproduction on a mortal computer would not
just be replication, but you would add mutation. So if we have perturbations to a replicated copy,
now we have an offspring. And now that is subject to the same pressures that the original source
computer is subjected to, and it will undergo selection and try to find its own stable states.
Ultimately, then you can think of reproduction as another means to propagate one's identity
through time. And then the last principle or the last pillar that we organize is cybernetical
regulation. I do mention sometimes cybernetical homeostasis is kind of like implied throughout
various principles, but we have the law of requisite variety. Just very briefly, what these
three principles ultimately try to tell you is that you need to have enough internal variety
in order to at least in enough equal amount of internal variety compared to your environment's
variety in order to successfully maintain, for example, homeostasis or block particular variables
and stay in a stable state. Or more, you could have more variety, that's fine. So it is an inequality.
But the idea is that this is important for a system essentially to try to maximize its internal
variety in order to be optimally prepared for all possible perturbations or things that the
environment could throw at you. The good regulator theorem complements this a bit. And it's just
basically saying that every self-regulating controller of an environment must itself contain
a model of that environment. And this motivates the notion of a generative model that effectively
one way you could think of it is that the mortal computer or entity is a generative model of its
own environment. So the mortal computer ultimately seeks to become a model of the niche that it
wishes to control. And then this motivates aspects of survival. And the principle model,
internal model control, I'm not going to go into it for sake of time,
complements the good regulator theorem. It just basically talks about
things that are how you deem if the system is structurally stable. And I'm going to move on
because I want to make sure that I get through to the actual definition. So then the last slice
that we review are, and we had a preview of this earlier, is aspects of cognitive science.
So effectively, Carl and I sort of generated something that we called a 5e cognitive theory.
You might have heard of 4e cognitive theory, so we slightly extended it. Very briefly, if you
look at the center component, the extended, embedded, inactive, embodied, and elementary,
you'll notice elementary is the new aspect of the new extension to cognitive theory.
Elementary cognition, and I know many of in Mike's group is very familiar with basal cognition.
And this is that cognition stands on fundamental functions and structures
that enable acting and tracking aspects of an entity's niche to ensure it's survived,
find food, avoiding danger, trying to reproduce. So these are, again, known as basal cognition,
and it's a manifestation manifested through a system's autopoiesis. So this is sort of the base
level that you must have as the starting point, essentially, to build a reasonable or effective
mortal computer. And then, of course, on top of that lives the embodied cognition aspect. And this,
again, they all depend on each other. So if you have one, you're going to start getting the others.
If you add these levels of complexity, so it's kind of organized as the higher up in this chain
you go, the more complex your mortal computer is. The body cognition, as we talked about earlier,
is that you can't describe your cognition or mental processing without a body. The idea is that you
must involve the body or morphology of the living system. And yes, this is a little bit more of the
extreme version of the embodiment thesis. There are a spectrum of different types, but we sort of
leaned in more on the idea that we even offload cognition to aspects of our body. And this is
motivated by like morphological robotics, where, again, we know that if we can offload the physics
onto particular limbs and things of that form, you can reduce the processing of the computational
brain that you build into the computer. We know that inactive cognition lives on top of this is
the idea that you depend on your environment, and you have a meaningful relation to a relationship
with it. Again, not only for extracting resources and transmitting waste, but you are essentially
inhabiting and actively shaping your niche, niche construction, as I mentioned earlier.
Then on top of these, we didn't really go into detail. I'm just going to mention that you can get
further and further and more complexity introduced. You have embedded cognition because the idea is
that you live in a system of other mortal computers. So that's kind of what we have there.
On the left, we show some neuro robots as just an example. And the idea is that you are determined,
your cognition is affected by cultural norms and other social interactions and the behavior of
other entities that are also in this environment undergoing the same forces that you are. And so,
again, the mind extends now beyond boundaries of the individual. And then, of course,
extended cognition is the final one where you offload cognition or the theory of extended mind
into non biological or non mortal objects. So if we generalize things to mortal computation,
these are not mortal computers like your pencil or your phone. So essentially, we are using objects
as an extension of our cognitive functionality. And of course, that kind of like pie sliced
circle is just sort of grouping them in another way. So we have basal cognition as like the biggest
slices more the foundational component, morphological cognition deals with anything that would be
bodily kind of cognition or processing inactive, of course, you need to account for the environment
and externalized sort of absorbs extended embedded. So that was another way that we organized it.
So maybe you might have heard of Kirchhoff's life mind continuity thesis is another way of saying
like it's an artificial manifestation of it. So what now with equipped with all this review
of wonderful work of far smarter people than myself, we get to the mortal computation thesis.
So there are a couple of parts that I'll just introduce briefly. And I have reduced and cut
away some of the mathematics. We can talk more about that if we want later. The Markov blanket
is really the central underpinning of a mortal computer. And effectively, what this does is
this is our interface between what's inside you or the entity, or the mortal computer and what
exists outside of it. It is that particular interface and things are exchanged through that
interface will be couple. We can break it down a little bit further. You could think of by the way
Markov blanket like a cell surface, which separates intracellular from extracellular elements. And
then of course, we talk about sets. And again, these can be viewed as discrete states, but
everything's really continuous. And it makes things more complicated. But as you can see in
the diagram to the right, we can decompose the Markov blanket into sensory states and active
states. And these are the ways in which the agent actually gets information from the environment
and transmits information to it can do things to it. Always the external states of the environment
and Z is the internal states of the system itself. So these again, are not observable by
the environment. And the observable states are not observed by the agent and must interact through
this Markov blanket formalism or this construct. And again, this motivates again, how you now need
to design the body need to account for the morphology of the agent. And so here we have a
little bit of an expansion, where again, I told you what all the different ones are, we have
iterators, and we talk about them as actual sets of states, and they evolve with time as well.
So again, ultimately, what we want to take away from this is that there is a weak coupling
and local interactions. And this will motivate the free energy application of the free energy
principle shortly. And the Markov blanket provides that necessary partitioning. Non-living systems,
by the way, that exhibit persistent local dynamics, do not maintain a boundary. So you could argue,
well, well, this is your framework and the concept of the free energy principle Markov blanket
supplied to a campfire. And the answer is no, because the campfire dissipates rapidly in the
flux of the universe, it is extinguished by the downpour of rain. So this is not going to have
persistent dynamics, it just has local dynamics, or you can think of a candle flame as well as
an example of a system that would not be a computer. So now we get to the idea that mortal
computation or the mortal computation thesis is really just another corollary of the free energy
principle. And just to briefly review what the free energy principle at one perspective is,
is all centers around what I was already hinting at before, which is the non-equilibrium steady
state solution, or the NESS. This is what agents or any mortal computer really wants to strive to
reach. And so the idea is that, according to the free energy principle, or the FEP, entities
maintain their structural and functional integrity by changing their relationship with their eco-Niche
through action. So action is really important because this is our way of which the system can
actually forage for materials. So the free energy principle is about random dynamical systems that
actively resist the natural tendency to disorder. Going to equilibrium and non-equilibrium is bad,
that means you have died. And so the whole idea of mortality is we act so that we do not talk,
that we do continue to persist. And then the free energy principle can then be broken down into
two key parts, as you can see with numbers one and two. Mortal computers' internal density dynamics
are conditionally independent of its environment. What does that mean? The environment and the
mortal computer are weakly coupled, and the mortal computer has states that are distinct
from its external or environmental states. That was, again, what was ZT versus OFT.
And then the second key point, or the key aspect of the FEP, is that the mortal computer will
continually self-evidence by returning to or trying to be as close as possible to its NESS,
its NEST state. So the mortal computer behaves to preserve its functional integrity,
and its dynamics do not diverge when a perturbation is applied. So it's trying to gather those
resources to continue to survive. It's striving to reach ultra-stability, which connects back to
the cybernetics back in. And then we talk a little bit about the formulation of the
variational free energy. I removed all the terms for you for simplicity here, again,
for the sake of time. But really, under the hood of the free, the F, curly F, is that an entity
has a morphology queue. This is referring to its actual structural organization. It has a set of
internal states, and it has parameters move. And so, again, ultimately, the free energy principle
is following the gradients or the differentials across each of those aspects. And we talk a
bit more detail. But I'm going to shift you to the final piece of the puzzle, which is just,
and we've seen this again, like throughout, morphic versus amorphic is an important distinction.
We've talked about biological entities having a 3D physical structure, and von Neumann computers,
do also have that physical structure. They're designed to maximize heat dissipation and things
of that form. But our programs and our software do not adhere to that structure. They are not
entangled with it. They are not taking advantage of that. And so we have, again, in a morphic system,
we have a thermodynamic cost, and we have information coupling. These are very important
constraints that characterize entities in this category. And so the morphology itself is a
computational resource in living entities. We also go in the paper in the free energy principle
about how you'd need to do structural optimization, which connects back to morphogenesis. But our
computers are amorphic, or sorry, our programs, our intelligence systems today, our software is
independent of that substrate. Think of when you, if any of you have experienced writing
mathematical model for a deep neural network, you can write those equations independently
of any realization of a 3D environment. The execution of that program is possible because of
that computer's architecture, but you are not accounting for its morphology. It is amorphic,
even though we present it pedagogically as dots and arrows and try to connect them back to
synaptic structure. So ultimately, mortal computers follow self-evidencing, the same self-edit
evidencing principles as enduring entities, they are inherently morphic, thus we can apply or ground
them in the free energy principle. As I mentioned briefly earlier, you can see to the far right,
those are the gradient flows that you follow. And of course, we formulated them as differential
equations or differentials that you could essentially traverse as the free energy sort
of gets you back towards or trying to minimize your variational free energy to get back to that
ness. But this is the essentially, we talk about the relationship between inference,
learning and structure and how there is a circular causality between them. And we go at
quite length and I'm not going to go into this talk because that's going to take a while. We also
talk about mean field approximations and simplifications that give rise to known structures and neural
structures in the brain. But the idea is that a mortal computer is a dynamics on structure
with dynamics was ultimately one conclusion that we lead. And we call this backbone,
mortal inference and learning or mills for short. And this is a key part of the final definition
I'm about to show you. And remember that learn inference, changing or altering your internal
states or variables internally depends on learning. And of course, learning depends on those
internal states. And then there is another interesting relationship we point out that the
morphology or the structure depends on the learning or the synaptic parameters if we're
thinking about neuron networks and vice versa. So there are these causal relationships or these
circular dependencies that are necessary and actually important to embrace that a lot of
modern day machine learning or artificial intelligence does not embrace. And we should
be looking to biology and neurobiology for those sources of inspiration for design.
And I also mentioned that mortal computers are an instantiation of physically realized
Bayesian evidence. Not only are they going to read to you this entire definition, but this is
effectively one starting point, an informal definition of mortal computer or mortal computation
and what it would mean for designing this going forward for artificial general intelligence.
Very briefly, the core agent goal is to remain in non-equilibrium steady state of stability
in the face of a changing environment. Very briefly from the high level view of this definition,
you will notice that it emphasizes strongly you need to have a morphology. Although we give you
sort of a backdoor for those that do computational modeling, perhaps a virtual morphology would be
acceptable for now. And then we obviously need to have accounts for homeostatic,
homeohedic processes. So a generalized homeohesis or homeostasis. We also need to ensure
that we have implementation of various aspects of mills as I just briefly discussed earlier.
And then we end by talking about categories of different types of mortal computers. And
we came up with some very broad and these are subject to change because this is sort of pointing
in a completely new direction for artificial general intelligence research to go into
or biomimetic intelligence. So we have homeostatic mortal computers and they satisfy essentially
the core principles of the definition, but in a very basic sense. So it has homeostatic
regulation over those essential variables or primitives I mentioned very early on. You also
then have a higher level regulatory processes, so allostatic mortal computers. These mighty
VINS homeohesis in contextualized by allostatic regulatory processes. Obviously the ultimate
goal is to have a fully auto poetic mortal computer. And we actually already have some
of these interesting enough. I'm going to wrap up with those examples, some of which
Mike's group definitely knows for sure. And of course we need to events homeostasis allostasis
and engage in self repair and self replication. So what you might ask, do any mortal computers
currently exist? We already have some of them, not necessarily that the problem is solved,
but rather we have some wonderful examples that we could bring back to the science as the artificial.
One of the earliest ones is Ashby. Ross Ashby is a very important founding figure of cybernetics,
which was one of the slices that I read, Carl and I reviewed earlier. And Ashby's homeostat,
which is what's shown in the picture here, is one of the earliest examples of what we would
consider a homeostatic mortal computer. It's very, very simple, but it is able to stay autonomously
in its own stable state. So it's able to maintain a form of homeostasis without any external
intervention. And usefully enough, if you read into the literature without any knowledge on the
designer's part of really how this even works, which is kind of interesting. So the primary aim
is it keeps its control variables within certain ranges. And we'll do this with random exploration.
There are modifications that were done over the decades to add learning components to it.
And then you can kind of make it look like what Carl tells me is an allostat.
If you add some form of memory or learning, you sort of get a little bit more of an allostatic
interpretation. The funny thing was the homeostat can survive as one comment from an early cyber
nutrition says something that any normal computer cannot or digital computer, a wire cut, a wire
cutter, you can turn off your normal computer and break it down. But a homeostat would learn
to replace one of its sub modules if you cut one of its wires, which is really interesting.
Then we also have things by Bap, Pask and Beer and many of those that contribute to what was known
as Maverick machines. These are actually variants of autopoietic mortal computers in some sense.
The electrochemical air was essentially a system made of several platinum nodes inserted in a dish,
given an electrical stimulation, and they would grow and self organize. You can also give them
positive reinforcement. And that's why it was called the electrochemical ear. It would actually
grow sensory organs in some sense that it could actually pick up sound waves. And it could build
filters conducive to its survival. We also have fungal and mold based computing. Some of them are
designed based on or using actually integrating the pink oyster mushroom, which is known for its
internal geometrical calculations that can be reprogrammed. And then it can leverage the
result in electrical activity from the pink oyster mushroom to drive the actual circuits of the
system. So you sort of get a chimeric hybrid type of system. And they have many useful properties
that have aspects of autopoietic mortal computing, but not all of them. And it's not quite clear
the current direction that fungal or mold based computing go, but it is a promising example of
aspects of mortal computation. I don't need to spend your time on this one. I know you guys
know Xenobots quite well, but they are certainly an example of an autopoietic mortal computer.
And you know, it's a swarm of bio bio bots or biological robotic agents. Essentially,
really, I'll just digest to the point of that they essentially exhibit a form of morphogenesis
and basal cognition idealized in a multicellular form of a biological mortal computer. These could
serve as a source of inspiration for in silico mortal computer designs as well, especially for
example, a neuromorphic computing, maybe we could borrow a couple of the principles that we get.
The nice thing about Xenobots is they heal, which I think is the most important part.
Yeah. And then there's some nice aspects about the hardware. And we talk about this in the paper
and the very the extra appendix that the hardware includes the genome, whereas the software is
the cellular communication, sorry, the emergence cellular structures and the software is the
cellular communication that underwrites the creation of higher level structures. And then,
of course, what was let me see if I have it here. Why is it not showing up? Oh, for some reason,
my oh, there it is. We also had very new recently actually, we'd already finished drafts and
robots, which are wonderful as well. We also have the organoid there to the bottom right or
known as intelligence at a dish. I also know you guys are quite aware of that. So I don't
necessarily need to talk about sentient organoids. But these are examples of autopoietic mcs or
mortal computers. And the idea is that they have aspects that strongly embody those central five
tenants of mortal computation that we discussed earlier. And since I don't want to take up any
more of your time, there's a lot of implications for artificial general intelligence. The mortal
computation thesis could be one possible catalyst for what we think is the next stage of artificial
intelligence research, where we need to go. A lot of today's work, again, from the artificial
transformers you might have heard of, is that we have sort of centered around tool oriented view
or perspective of artificial intelligence, while it's valuable and stands to make a lot of nice
benefits for humanity. The idea is that this is very different than how animals and humans,
for example, conduct processing and how we are naturally intelligent. So we should be pursuing
survival and its relationship to mind and how what that can teach us about embodiment and
inactive intelligence. This could be the place that we need to go for biomedics. By the way,
Bionics is just the engineering application of biomedic intelligent concepts. And then we have
some things, these are actually the appendix, but I just wanted to briefly mention we're essentially
working towards a form of artificial sentience rather than using the word intelligence. We are
also not dealing with the questions of consciousness. We try to not really deal with that because that
can get quite messy philosophically. That's not important for what mortal computation says we
need to go, but there are some implications if we actually built the exact idealized mortal computer.
Well, now we have the fact that they can feel, they can think that do we have to consider giving
them rights? And I think that's a wonderful and important ethical discussion that would
need to happen assuming that this research program gets built on. And then we have this
problem called the body niche problem, very briefly just means that let's say research groups like
myself, we don't have Xenobots, we don't have access to organoids. So it'd be very hard for us to
actually use those resources unlike those in biological domains. But perhaps we could build
virtual morphologies. And we talk a little bit about how that's done in robotics, and that could
serve as an example to democratize aspects of biological mortal computers. And so I just,
I'll leave here, I'm not going to blab about this slide, but I'll leave it hanging here. These are
some questions that even I had as I was reading or rereading some of Michael's group's wonderful
work about Anthrobots and Xenobots, and some potential interesting collaborative or at least
directions that could be explored. And I am shamelessly plugging my lab software
for modeling neuronal dynamics in biological credit assignment and so forth. So with that,
thank you very much. And if there's any questions, I think we have like at least 10 minutes or so.
Cool. Thank you so much. Anybody else have questions?
I've got a question. So, yeah, thanks. This was really interesting. So back when you were talking
about these three pillars of the cybernetics as they apply to this, I was interested in the
growth pillar. Could you just expand a bit upon what that is telling us basically?
Yeah. So, and I don't know if I have it here. Actually, it's good to look at the,
actually, I'll do it this way. I don't have too, yeah, the growth. So there was a,
there's a couple of more principles and things that I sort of hid here. Can you kind of see the
slide? At least the picture? Yeah. So the nice thing about growth from cybernetics is the idea
that, and I mentioned that, you know, one of the starting points is self-replication, the idea
that you should be able to produce copies of subsystems or produce essentially duplicates or
be able to produce extra parts and change and repair with time. But autocatalytic growth was
something I didn't really mention. And this is the idea that you sort of get a feedback process. So
you can see from some of the arrows that this is leading to self-assembly. And so what it really
was saying that we need a morphogenetic process. And as we gather resources, then what ends up
having is you see like an increase out of a catalyst, right? The idea is that growth will
start to grow up to a certain point until, of course, you have no more resources. This is what
we talk about the niche, providing that substrate, that material and energy exchange is really important
in a course. Doesn't allow you to just keep growing infinitely. Ultimately, what this leads
in cybernetics view is this another principle called the principle of recursive growth,
which ultimately leads to the emergence of heterarchical, not hierarchical heterarchical
systems that are saying things grow really, really, really big. And of course, they start
creating things that are stable in the sense of building blocks. So there's a point where
a system that's reached like an ultra stable state or has reached a certain point of organization
becomes a building block to a much bigger, higher level system. And so that's kind of where the
idea that like Herbert Simon and other classical thinkers talked about the emergence of heterarchical
systems. So effectively, it's trying to say that you need to essentially build in these morphogenetic
changes. You need to have this process that promotes growth and self repair, because this
is what's ultimately going to allow that system to continually persist over time. And again,
it sort of affects the ideas that you get more and more complex systems. I didn't mention it
later in the talk, but you can have nested Markov blankets, you can have Markov blankets
of Markov blankets of Markov blankets. And now you get the
of top down and bottom up causal modulation. But ultimately, growth is just trying to say that
we need these resources, and we need to be able to replicate either your entire entity,
and then add mutation, which creates the offspring, as I mentioned earlier,
or you need to be able to reproduce and grow and replace subsystems. And that's the part where
the building block concept comes in. There's also one final comment that I least I recall,
which is that as these things become stable, systems that are built of lower subsystems
make it easier for those building blocks to join in. Because again, now we have this
organizational principle from a high level relationships between parts. I don't know
if that was helpful. Yeah, it was. Okay, thanks. Yeah, thank you. It's a good question.
Any videos? Oh, yeah, I also had a question. So one of the hallmarks of classical one diamond
computers is programmability, right? What type of computer? I just didn't hear you.
One diamond computers, the conventional computers, it's programmability. So we can almost
anyone can write a program almost using natural language. What about programmability of models
computers? Do you think that we might need some sort of model programming language framework,
which is fundamentally different from a traditional programming language framework?
That is a really good question. And yeah, that is something that in my view, you would lose
from classical computer, because the idea is that, as I just said, and everything is sort of
dependent on the morphology and the niche in which that morphology is to exist in that agent,
or that mortal computer is to interact with. So I would say that it gets difficult because you
need to now account for the properties of the morphology and sprinkle throughout the paper.
We talk about that the homeostatic variables or the sorry, the metabolic primitives will largely
depend on the actual substrate in which you are building. And it could be in silica, it could be
biological. I think that there is potentially, and it's not clear to me how, so I'm just
speculating to design general specifications, not so much that it would be like you can program
in a mortal computer, just like you would in your standard von Neumann computer and like the
Python programming language. But you could take advantage that the systems organizationally closed
and that they have essentially relations between the parts. So there are some sort of design
principles that they adhere to. And I think you could design some level of general programmability
for certain classes of mortal computers. It wouldn't be like, oh, let's say I have an animal,
let's say a very low level type of mortal computer, something very low level cellular versus a complex
organism. I would say that the programming specifications might be dependent on the class
of mortal computer and the type of entity and even the niche in which it interacts.
But you could essentially program classes or slices of mortal computer. So again, if we're
dealing with like I had in my other diagram, the neuro robot, that was a version of like
the dog robots that come from like Boston Dynamics, you could essentially imagine designing
programming language around those types of quadrupeds. And so I think you would need to
account for like the essential primitives and the environmental variables that are part of
this process. And we need to be able to specify them to some degree if we want the programmability.
I think it gets complicated, though, because I do think while we are sort of arguing for this
entanglement, right, because the software really isn't divorceable from the hardware and real entities.
The place where maybe you get some of that general programmability is in the virtual
morphology. And I think that's our best bet, because ultimately, when you're building these
systems themselves, you sort of need to work with the actual hardware for time. But let's
see robotics. It's a little bit different with biological entities too. Although I know like
the Xenobots that you have way or the Anthrobots even, you have ways of which you can program them.
You know, there was some biochemical processes that were described in some of Mike's work.
I don't know if that helps, though, but I do think you lose some of that programmability.
But what you gain is this massive energy efficiency as you start to approach
those lower bounds, you start to approach the place of thermodynamic efficiency, the best
that you can get with physically realizable Bayesian inference. I do think, though, that
programming part can come in from more virtual morphologies to allow us to deal with the
organizational properties and allow us to experiment and work with different designs.
Does that answer your question too?
