you
you
you
you
you
good afternoon I still have to wait for a sign since we
the livestream determines the program are we ready I guess we are ready good
afternoon dear ladies and gentlemen the president of the Bavarian Academy of
Science I would like to welcome you all to our talk focusing on current
developments of advanced computing technologies we are very proud to host
this event in the Royal residence in the center of Munich which houses the
main office of the Bavarian Academy of Science founded in 1759 the academy
functions today as a community of scholars a non-university research
institution and a communication interface between the Bavarian
scientific community society and policymakers with the scholars the
academy provides a powerful internet disciplinary network of very
established scientists this network of excellence interacts very closely with
all Bavarian research institutions and political decision makers and represents
an important part of the science communication with the public research
activities range from the composer Richard Strauss to the study of climate
change in their alps from baroque ceiling paintings to quantum physics the
longer term basic research spans from natural science to technology to
humanities and social studies the academy research project actively
leveraged the latest digital technologies the Leibniz supercomputer
center also part of our academy serves as an important infrastructural support
for digital activities at Bavarian universities today we will hear an
important contribution to the rapidly growing discussions about artificial
intelligence from Jan Lecun who is according to the Time magazine one of
the hundred worldwide leading AI pioneers is professor of NYU on chief
I scientists at Metta not in California in New York I just learned the title of
his talk from machine learning to autonomous intelligence artificial
intelligence as you all know is the key topic of our time not only in research
and industry but also in the broader society this becomes evident as a large
interest and thank you for all coming to this meeting on sharing this
experience we're very pleased as Bavarian Academy to gather with the AI agency to
be part of biosphere biosphere is the official network of all AI activities
in Bavaria we partner in this important task to advance AI science in Bavaria in
close cooperation with the Center for Advanced Studies at LMU the Bavarian
Research Institute for Digital Transformation the Munich Center for
Machine Learning and the Konrad Susie School of Excellence in Reliable AI the
event today is part of this successful cooperation and we're looking very
broadly forward to learn more about recent progress from advanced computing to
autonomous intelligence I hereby hand over to professor Thomas Seidel member
of the Bavarian AI Council Chair of Database Systems on Data Mining Director
of Munich Center for Machine Learning to all of you I wish you a very insight
for and informative afternoon the Seidel
yeah thank you President Schweiger for this nice introduction and very warm
welcome also from my side to all of you particularly to Jan Leckardt to be here
today I wear two hats today one is I'm a member of the Bavarian AI Council we are
20 members appointed by the Bavarian state government as part of their high
tech agenda from universities research institutions and also companies in the
field to advise the government on AI strategies and actions particularly in
steering the Bavarian AI agency so the representative is also Dr. Klimke which
promotes the Bavarian AI network which we call biosphere so the logo is there
as well so the biosphere comprises a variety of strong AI players in Bavaria
also universities research institutes and from all over Bavaria as well as a
lot of the global companies we have here including Google, Microsoft, IBM but
also the locally sitting global players Siemens, BMWs, Aval insurances, Munich
3 Alliance and so on but also many regional small and medium enterprises
and startups in the field of AI so the second hat I am aware today's I'm one
of the four directors of the Munich Center for Machine Learning one of the
co-directors Daniel Gremmels also here and we this is a consortium of LMU and
TUM funded by the BNBF and the Bavarian high-tech agenda with around 50 PIs in
machine learning in the IE3 junior research groups recently established
around 200 doctoral students and our focus is on foundations of machine
learning where we have several players including Gitta Kottiniok from the
Mathematical Park and Statistics and Computer Sciences there then Perception
we are particularly strong in computer vision here and in Munich and in natural
language processing the two big things where humans and computers interact
and a lot of domain specific things it's not on research but also on transfer
activities fostering the collaboration network together with the biosphere
outreach to the general public things like that if you're interested we also
have openings of course so this is that part so I'm sure we get fully inspired
by your presentation and between your presentation is now the next is Dr. Mayer
from TAS, you're on stage, thank you ladies and gentlemen may I also welcome you
warmly on behalf of the Center for Advanced Studies at LMU and let me
briefly say a few words about this institution and how it comes into play
the Center for Advanced Studies at LMU was founded 15 years ago to provide a
forum for precisely those research questions that cannot be tackled by
only one discipline this was intended to take account of an increasingly
diversifying but also specializing body of research that's becoming more and
more disparate not only in terms of content but also in terms of space in
Munich you can just think of the campus in Ober-Schleishheim, Ober-Guy-Ching,
Norit in the far south so the Center for Advanced Studies offers the place
where these centrifugal forces can be bundled and for what topic does this
task play a more important role than for artificial intelligence which is
spread across most faculties of LMU and other universities it was therefore a
great pleasure for us when Gitta Kutinyork freshly appointed at our
university approached us and asked whether a form it could be found that
would network research on AI at LMU and unable to discuss overarching issues
together it wasn't long before a so-called interdisciplinary CAS
research focused entitled next generation AI was born bringing together
researchers from 14 faculties working on the topic of artificial intelligence
over the course of two years a wide variety of lectures workshops and
conferences was organized and held and we were thrilled by the spirit that
emerged of that group that's why we look forward to Professor LeCun's lecture
today with both a smile and a tear as it marks the formal conclusion of the
research focus we are honored and grateful that Professor LeCun is going
to give the lecture in this framework today yeah also a warm welcome from my
side to everyone here on site and also to everyone who participates via
live stream it is wonderful to have so many people with us here this afternoon
and a great thanks to all of our cooperation partners for actually
making this lecture possible and here I would like to particularly thank Dr
Anette Meyer and the Center for Advanced Studies of the Ludwig Maximilians
University MÃ¼nchen Professor Dr. Markus Schweiger and the Bavarian Academy of
Sciences and Humanities that this event can take place here in the academy in
these really beautiful rooms Professor Dr. Thomas Seidel and Dr. Michael
Klimker from the biosphere the Bavarian Eye Network which made the live stream
for the event possible and also Dr. Christoph Egle from the Bavarian
Research Institute for Digital Transformation and now it's my great
pleasure and honor to welcome Professor Jan LeCun thank you very much for
accepting our invitation and for coming to Munich for this lecture today
Professor LeCun is chief AI scientist at Meta and the silver professor of
computer science at New York University he started his career with a PhD in
computer science at Sorbonne University in Paris and then moved to the US where
he became the head of the image processing research department at the
famous Bell Labs the AT&T Bell Laboratories then after intermediate
stations he joined New York University in 2003 and he also became there the
founding director of the NYU Center for Data Science in 2012. His groundbreaking
work includes among many others the development of convolutional neural
networks which are the state-of-the-art for basically any problem in particular
imaging sciences and computer vision and a particularly particular convolutional
neural network architecture is also named by him the so-called LeNet which
in sense also promoted the impressive development of deep learning and AI as we
experience it today. His contributions are honored by numerous awards many more
than I could name here let me just mention that he's a member of the US
National Academy of Sciences and the National Academy of Engineering he
received various honorary degrees for instance from EPFL received the IEEE
neural network pioneer award and in 2019 the Turing Award which is typically
referred to as the Nobel Prize of Computing and just a few weeks ago we
already heard at the Time Magazine and congratulations to that has selected him
as one of the 100 most influential people in AI worldwide and he also
repeatedly contributes to the public debate about AI was also controversial
proclamations for example on the current craze around large language models. How
could machines to learn as efficiently as humans and animals? How could machines
learn to reason and plan? In his lecture Professor Jan LeKang will now talk about
a possible path towards an autonomous intelligent agents based on a new
modular cognitive architecture. Welcome Jan, the first yours.
Thank you very much for the introduction and thank you very much for
inviting me for coming here so so numerous I have to correct one thing
though I did not call convolutional net solonet this was my lab director at Bell
Labs who gave it that name I would never done this but it's a good name okay it's
a long title and a long subtitle objective driven AI this is what I call
this I used to give this talk with the title autonomous machine intelligence
and and it scares people you know they say do you mean machines that will be
autonomous we're not going to be able to control them so I changed the name to
objective driven AI because that's really more accurate and they're really kind
of systems it's an aspiration it's not something that we've done it's something
that we should do and there are systems that could of course learn remember
reason plan have common sense be steerable controllable safe and have the
same kind of learning abilities and intelligence that we observe in animals
and humans so let me start by a little bit of the state of the art okay because
there's a lot of debates today about about AI and a lot of people are afraid
of AI it's understandable whenever there is technological revolution people are
afraid of the unknown and AI is promising to be a big revolution so people
are afraid so let's first talk about the benefits before we talk about the risks
and the benefits are of AI are numerous already today and there is you know even
more coming in medicine particularly in imaging diagnosis assistant treatment
protocol drug design things like this very promising research transportation
every car sold in the European Union today has to come with what's called a
automatic emergency braking system a system that will automatically stop the
car there is an obstacle in front of it and the driver does not react this
saves lives it reduces frontal collision by 40% so AI saves lives and that uses
convolutional nets by the way and in all the systems that I know in fact Germany
was kind of a and and a barrier in particular was a pioneer in this some
of the early systems of this type was the word developed by them events so
driving assistance autonomous driving energy storage and management things
like that environmental environmental monitoring and protection I'm going to
say a few words about this content information and management this is
probably the biggest use of AI today and of course in industry manufacturing
information systems quality control etc a lot of applications are expected also
in things like education for personalized education connecting people
with each other with translation today presence augmented reality virtual
reality and then enormous applications in science biology and genomics
neuroscience physics particularly physics of disordered systems complex
systems very large-scale simulations chemistry material science very
promising area for AI so this well really and of course you know we've been
talking a lot about creation like creating art AI is essentially enabling a
lot more people to be creative people who don't necessarily have the technique
the underlying technique for producing art so I will affect every aspect of
human activity and let me give you a couple examples so this is a video that
was put together by my colleagues at Meta a couple years ago this is already
sort of aging if you want and we chose the capability of computer vision system
as of about two years ago so we can have systems that detect objects and put
frames around them give them a name they can track human bodies and figure out
in what what pose they are densely actually so that's actually very useful
for all kinds of applications and more interestingly we can have systems that
perform what's called semantic segmentation which means isolating every
object marking them with kind of a mask and then giving them a name for a
category and this works for a very fine-grained category for example the
species of a bird or or plant or something of that type so it's pretty
amazing it's not like computer vision is completely solved in fact if it was
solved we wouldn't have the large conference that takes place in Paris
next week called ICCV so there's still a lot of work to do but but there's been
a huge amount of advances there and a lot of advances in AI but no advances in
my slides for some reason okay my presentation refuses to advance hang on
just one minute one second
okay I mentioned medicine so certainly medical imaging is an area where a lot
of work is going on there's two we need to cite really this is some work by some
of my colleagues at NYU that use 3d image recognition not just 2d in some
cases this is actually 2d but that use various techniques to detect for example
tumors in mammograms or particular things in MRI and other types of images
enormous amount of progress there some product project that took place a few
years ago which was a collaboration between the NYU radiology department and
people at FAIR Metas fundamental research lab which essentially allows to
accelerate the data collection for an MRI by a factor of four without degrading
the image quality so instead of having to lie down in a MRI machine for 40
minutes or something you can reduce it to 10 minutes and have the same quality
of images and that's thanks to deep learning essentially a lot of
applications in science what's interesting today is that the favorite model
that neuroscientists use to explain how the brain works use artificial neural
nets so the best explanation for what we observe using functional MRI data in
the visual cortex of humans and animals are actually models that are
essentially convolutional net models and that's kind of a closing the circle
because the architecture of convolutional net is actually inspired by the
architecture of the visual cortex classic work in neuroscience from the 1960s
the similar work also in language understanding this is a recent paper in
science by some of my colleagues from from from MITA actually and they tried
to figure out if the current large language models that everybody is
playing with explain the what we observe in the brain when people are asked to
kind of remember or understand a story and the answer is sort of but not really
it doesn't work nearly as well as a convolutional net models for vision so
what that means is that we're missing something that those models probably are
not sufficient to explain what the brain does when we understand language I
mentioned some applications in science in particle physics in particular
high-energy physics to kind of make models of particle collisions and things
of that type image processing to discover exoplanets some estimate says
that about 12% of all physics papers today actually mentioned AI as a tool
that he used which is astonishing in just a relatively short time and in the
large-scale simulation sort of universe scale simulation that could sort of
validate or invalidate certain theories about dark matter and things like this
so very fascinating work and applications this is a very interesting
project that was started by some of my colleagues at fair by Larry Zittnick in
particular called the open catalyst project and you can actually participate
if you want the website is open dash catalyst org and and that project the
idea of that project is that we could solve climate change if we had a good
efficient scalable way of storing energy if we had a good way of storing energy
we could cover a small desert with solar panels and produce enough energy to power
Europe or the entire planet the problem is you have to have a way of storing
energy which is why renewables today despite the decisions of the German
government to go all out on it renewables are not drivable you can't
control whenever there is wind or sun and so you need another source of energy
when there is no no sun or or no no wind and and for that you need to be able to
store energy and ship it wherever it's needed the best way to store energy is in
the form of hydrogen or maybe methane and the best way to do this is by
separating hydrogen from oxygen from water right so take some water put two
electrodes and then separate hydrogen from oxygen probably this is that it's
either scalable if you use catalyst to do this like platinum sorry it's either
efficient if you use catalyst like platinum or it's scalable but not
efficient and so the big question is could we design compounds new catalyst
that would facilitate this reaction so that it's efficient but this does not
require exotic materials like like platinum so that is scalable and the
idea there is that you do a lot of chemical simulation that's called DFT
simulation of various of water on two various compounds and then you generate
that data using simulation and also using experiments you put that data you
make it available and then you ask people can you train machine learning system
to figure out what the underlying rule is so that we can use it to design new
materials that might have the same effect but be cheap so fascinating
program it may not work but it's worth a shot okay now what's important to
realize is that the progress we've seen over the last few years in AI and
machine learning are due to a set of techniques that we call self-supervised
running which I'm sure many of you here in the room have heard about and
essentially self-supervised running would be a set of techniques that allows a
system to be trained to represent the data the world without requiring
labeled data okay without requiring sort of manual human intervention to produce
the data so perhaps the best success of this idea which I've been advocating
for a long time is in the context of natural language understanding so the
way all NLP systems are trained today whether there are LLMs of the types
that we play with or others is the following you take a piece of text a
sequence of words and you remove some of the words you you mask you mask them
you blank them out you replace them by a blank marker okay you corrupt
essentially the input and you put it at the input of a large neural net you
trained is very large neural net usually usually a transformer architecture to
predict the words that are missing in the process of doing so the system has to
extract representations of the text that contain the semantics the syntax the
you know grammar everything I sort of lied slightly here these are not words
that are input they are what's called tokens which are essentially subword
units so in most languages words have a prefix and a root and a suffix and you
need to kind of separate those for those systems to work properly otherwise your
dictionary of words would be gigantic and then in German you have to do it
because you can have words that are long like this they are you know by so so
there is no choice you have to break up words into subword units you know in
tokens and so you train that you train the system and and this is the so-called
Bert model if you want or idea and that's being incredibly successful it's
completely self-supervised you don't need any other data than the text and once
you've pre-trained that system you can use the internal representation produced
by the system as input to a subsequent task a downstream task like let's say
translation hate speech detection you know summarization whatever so that's
the general idea of self-supervised running fill in the blanks have a big
piece of data corrupt it in some way and then train some big neural net to fill
in the blanks or or recover the original data a particularly stunning example of
this which I'm not going to go into the technical details of but I will later is
a system they came out of my colleagues that in Paris that fair Paris called
Dino v2 you can think of it as a foundation model for vision so it's a
system that is trained to extract features from images such that those
features can be used for anything you want whether it's classification fine
grain classification depth estimation semantic segmentation instance
retrieval so the same kind of application that I showed in the video but
basically with very little supervision the system is pre-trained and it
basically because it's pre-trained on enormous amounts of data just training a
very shallow head to solve any particular one of those problems actually
beats the state-of-the-art for death estimation or classification or whatever
you can actually play with it interactively that's the URL that you
see here and these are some examples of visualization of what the features that
are extracted are it's kind of a you know colorful representation of the like
different feature vectors are represented by different colors this is
actually kind of each color is like a principal component if you know what
that is so those are you know examples on sort of typical typical images and
people I've been I started to use this for all kinds of stuff for biological
image analysis for astronomy for for environmental protection so that's the
next example I'm going to show you so this is a project by someone on the team
Camille Coupri and a large collection collection of collaborators and what she
did was use those Dino V2 features and trained relatively small system on top
of it to tell what the height of the trees are from a satellite image so we
have lots of satellite images on the entire world at half meter resolution
you can get this from satellite imaging companies and for some areas there is
lidar data which tells you how tall the trees are so you use that to train the
system and then you can apply it to the entire world and what that tells you is
how much how much carbon is captured by the trees if you know roughly what the
height of the tree is you know roughly how much carbon is captured in the tree
that's super important to know like you know should we protect forests of course
we should should we plant more trees where things like that so very interesting
this publications on this where you know everything is detailed and everything
another success of self-supervised running of the type that I showed for
natural language processing where you remove some other words is in in biology
proteomics particularly so you can a protein is a sequence of amino acids and
we know hundreds of millions of them so you take a sequence of amino acids you
remove some of the amino acids and you train some gigantic neural net to predict
the amino acids that are missing the system kind of learns to represent
sequences of amino acids that constitute proteins and then you use that
representation as input to a system that predicts the conformation of that
protein how it folds well they can stick to another protein a particular
location so there's a famous work by our colleagues at DeepMind at FFOLD but
this idea of using pre-trained transformers for protein was actually
first published by my colleagues at FAIR they're actually no longer at FAIR now
they have left FAIR to create a startup around this around this idea but this
incredibly successful thousands of research groups around the world are
using this kind of data this actually a atlas of folded protein contains 600
million proteins or something like that with the structure that is predicted
it's called the ESM metagenomic atlas and ESM atlas.com a very big tool for
biologists that really may change completely the way we do drug design
and understand the mechanisms of life another very impressive project here
that required a lot of effort is a project with no language left behind
again from FAIR a collection of people from the various sites of FAIR and this
is a system that can translate 200 languages from in any direction and when
you look at what those languages are it's a lot of languages most of them we
never heard of in you know square corners of the world but it's important
for people to be able to preserve that culture that you know they can speak
their language and basically be understood using automatic translation so
what's interesting about this is that there are 40,000 directions for
translation but the data only covers 2,400 of those pairs among the 40,000
despite that because we train a giant transformer to represent language
regardless of the language the system takes advantage of the similarities
between between language families to actually kind of extract a multilingual
language independent representation of language which allows the system to do
translation in any direction including four directions has never been trained
on that's pretty amazing pretty small model but today standard only 54 billion
parameters I mean sizable the same team now as another project called seamless
which was was announced a few weeks ago they can do speech to speech speech to
text text to speech and text to text translation as well as speech recognition
speech synthesis etc. Speech to speech is interesting because it can do
translation for languages that are not written directly from speech to speech
that system can handle a thousand languages which is really impressive okay
so applications of deep learning that are less visible perhaps is that deep
learning or AI connects people to knowledge and they connect people to
each other the biggest deployment of machine learning today is probably in
social networks and online services like like search engines and if you take
deep learning out of Google or Meta or Microsoft companies crumble they
literally are built around it so deep learning helps us deal with the
information deluge for doing things like search and retrieval ranking question
answering things like this but and that requires machine to understand content
of course for translation which is very useful for people who are not literate
for example or people are blind or visually impaired so there's three
billion people in the world today who can't use technology because they
basically can't read more or less so here's the biggest use of AI today
filtering out illegal and dangerous content and this is something that's
very hard to do it's impossible to do perfectly but to tell you to give you an
idea of how much progress AI has made those idea of pre-training transformers
and stuff like that the proportion of hate speech that Facebook was able to
take down automatically five years ago was about 20 to 25 percent okay it was
using sort of fairly simple machine learning techniques and LP methods of
the types that were common five years ago and then self-supervised pre-transformers
happened and that number went to 95 percent last year and it's just progress
in AI so a lot of people that we hear talk about AI who generally don't know
much about AI actually tell you about all the dangers of AI that then you know
AI is going to destroy I don't know democracy because of disinformation and
things like that what they don't understand is that AI is actually the
solution to those problems it's not actually the problem it's the solution
to those problems and it's already the case that doing content moderation on
social networks makes massive use of the latest advancements in AI and the
people who try to corrupt that system are not nearly as sophisticated in terms
of their AI so something that needs to be known okay but everybody is excited
about generative AI and autoregressive large language models and things of that
type right so many of you certainly I'm sure have played with those image
generation things where you type a text and outcomes image and this is the state
of the art about a year and a half ago from either a meta and make a scene
system or a PNAI Dalit or Google's image and as of yesterday this is that what
you get out of meta so this is actually from a paper and you can get the paper
from archive it's there but there's a product attached to that paper called
emu it's an acronym but actually don't remember what it means and what the
system can do is in it can generate images from a text prompt and it was
rolled out as a product yesterday as well as the paper right so it's one of
the things where like the science the research the technology and the product
come out to the same day pretty crazy and this is available in physical
messenger if you use Facebook messenger you can you can ask to talk to meta AI
that is the name of the intelligent virtual assistant that meta the generic
ones and then if in a font you type backslash sorry forward slash image in
and type a text then the system will produce an image in five seconds this
used to take minutes the results are pretty amazing the same team is is
working on synthesizing video this is actually some work from about a year ago
they're making progress on sort of practical things of this type okay but
how do those LLMs those large language models you know that you can talk to how
do they work they are autoregressive right so what that means is they are of
the type that I talked about before you take a text and you remove some of the
words and then you turn it train the system to predict the words except it's
a special case where you only train the system to predict the last word okay to
take a long piece of text remove the last word and train this gigantic neural
net to predict that last word and if you train the system this way you can do
what's called autoregressive prediction which means give a text predict the
last word or the next word then inject that into the input and then predict the
next next word and then shift that into an input produce the produce the third
word etc that's autoregressive prediction and it's amazing how it works
there's a whole bunch of those models around actually I typed that list a
few a couple months ago and now there is a whole bunch more but Blunderbot
galactica lama lama to from from meta which is actually open source code
llama that came out in July which is basically llama specialized for
generating code alpaca lambda chinchilla chadgbt the various incognitions of
chadgbt and then there is one that came out just a few days ago called mistral
by a French startup in Paris formed by people who used to be at fair and
defined actually that's interesting so performance is amazing for those systems
right we've all been surprised by it but they do make really really stupid
mistakes they don't really understand the world they they're trained to produce
the most likely sequence of words that follow a particular prompt and then
they're kind of fine-tuned to sort of work well for particular types of
questions but they make factual errors logical errors they are inconsistent
they don't really have reasoning abilities it's very easy to kind of
chorus them into producing toxic content they really do have a limited
knowledge of the underlying reality because they're purely trained from text
they don't have common sense like a cat can have common sense and they can't
plan their answer so you can you can play with llama so basically the chatbot
I just mentioned meta AI is sort of a productized version of llama too if you
want and it has various incognitions actually various personas that you can
call and there's three models the production model is a different one but
it's open source you can download it if you're a big enough GPU you can run it
on your GPU there's a lot of people working towards running those models on
mobile devices and laptops and things like that and they they can generate text
this is a funny one so in the early days of llama my colleagues kind of
interrogated that so they typed into llama did you know that Yanlok kind of
dropped a rap album last year we listened to it and here is what we thought
and this system writes a critique of my alleged rap album so they showed this to
me and they say is it okay if we put this in the paper they say yeah sure no
problem but I said like could you do this with jazz because you know I'm like
a rap is okay but like I prefer jazz really and they told me yeah yeah we
tried and it didn't work because there's not enough training data for jazz so I
cried so as I was saying you can fine-tune the system to sort of play
different roles and what meta announced yesterday is that is 28 different
chatbots that are specialized for different applications so things for
example you can have Snoop Dogg a rapper be a dungeon master if you are into
dungeon and dragon or text adventure games others that are like advisors for
traveling others that are cooks or or sous chefs or whatever so different
but those things really suck I mean they really not that great because they
don't understand the world they just manipulate language because they
manipulate language fluently we're fooled into thinking that they are
intelligent but they're not intelligent in certain ways but they're not
intelligent in sort of what we think as as human intelligence so you will see if
you go to X from a Twitter or any kind of social networks people who make posts
say oh there is a latest LLM from so-and-so company and you type this
and it's mind-blowing you know we are this far away from human level
intelligence what I call a GI I hate the term and you know it's for tomorrow like
you know all the naysayers are wrong blah blah blah it's just happening
tomorrow they are wrong okay this those things do not have anything close to
human intelligence they appear to do to have to have it because they train on
so much data that they've accumulated an enormous amount of background knowledge
approximately that they can regurgitate approximately so whenever they seem
intelligent it's usually because they can do information retrieval in an
approximate way that sort of looks reasonable but they cannot possibly
understand how the world works because their only training data is text and
most of human knowledge this may surprise you but most of human knowledge
has nothing to do with language it has to do with our experience with the
world every day physics another limitation that people have been pointing
out increasingly with various papers is the inability of those LLMs to plan so
an LLM produces those tokens autoregressively as I explained earlier
right they don't plan their answer they just produce one token after the other
and whatever token they produce will determine which token they produce next
because it's autoregressive there is a process by which the system is basically
an exponentially divergent process the system makes one mistake that takes it
out of the kind of correct set of answers it cannot recover and so this
entire architecture of autoregressive prediction in my opinion is is inherently
flawed and my prediction is that within a few years nobody in their right mind
would use autoregressive LLMs okay everybody is working towards something
better because those things are major flaws now what's the issue though is
that there's a lot of people who are scared about future AI systems that may
have the may attain attain human intelligence or or be more intelligent
than humans and if you extrapolate from what LLMs currently do you might think
well it's gonna be very dangerous because those systems cannot really be
controlled they can spew complete nonsense they can be jailbroken blah blah
blah if they are smart they might be dangerous that's a big mistake future
AI systems will not be using this particular blueprint they're not going
to be autoregressive LLMs okay and I'm going to tell you what I think it will
be okay so autoregressive LLMs suck I just said all that no reasoning no
planning essentially right the amount of computation devoted to producing a single
token by an LLM autoregressive LLM is constant there's a constant amount of
computation per token produced so there's no possibility for the system to
for example think about something for a long time before saying something it's
cannot do that by construction so machines do not of this type do not
learn how the world works unlike animal and animals and humans they will not be
able to approach human intelligence okay so whatever I don't know the CEO of some
company that thinks they have the best LLM in the world tells you AGI is just
around the corner don't believe that we're still missing some major advances
but there is absolutely no question that eventually machines will surpass human
intelligence in all domains okay it's basically no doubt about that and it's
going to happen during the lifetime of most people here maybe not me you know I
might take a few decades there's no question it's going to happen so these
are I think the biggest challenges for AI going forward learning representations
and predictive models of the world and I'll tell you why in a minute and that's
what's addressed by self-supervised learning so we have good handle on this
at least for text not so much for video learning to reason so if some of you
know about Daniel Kahneman's theory of system one system two sort of subconscious
things that we do without thinking and then conscious things that we have to
focus our attention on LLMs currently can do system one but not system two we
need to build AI systems that are capable of reasoning of the type that Daniel
Kahneman calls system two he's a Nobel Prize winning well he won the Nobel
Prize in economics but he's a psychologist and one possible path towards
a solution that I've been proposing for about a year now year and a half is what
I call this objective driven AI so this paper I put on open review it's not on
archive it's an open review because on open review you can make comments and
this is a working document more than a kind of finished paper if you want it's
long though you can also listen to technical talks I've given about this
are a little more technical than the current one and it's based on this idea
of a modular cognitive architecture where you would have a system composed of
multiple modules first module would be the perception so it's represented
overlaid over the back of the brain because in the human brain perception is
in the back so perception basically perceives the world and then constructs
an estimate of the state of the world right so it produces an estimate of the
state of the world perhaps it needs to combine this with the contents of a
memory that contains you know other information about the state of the world
that is not currently perceptible then that goes into a world model and the
role of the world model is to imagine the outcome of a sequence of actions
okay so the system can imagine a sequence of actions that's the role of the
actor the yellow module so the actor imagines a sequence of actions feeds that
to the world model the world model knows the current state of the world and what
the world model predicts is the future state of the world that will result from
that sequence of actions now that cannot be a perfectly exact prediction
because the world is not entirely predictable but that's the role of the
world model and then the entire purpose of the system is to figure out a
particular sequence of actions that will predict a state of the world that
satisfies a certain number of constraints that are implemented by the cost module
so the red module that you see this cost module that that's the drive of the
system that's the the current goal of the system if you want and the entire
purpose of the system so imagine this module as getting the predictions from
the world model and then computing a cost for it right so basically it computes
the degree of in comfort of the system discomfort and what the system does is
that it figures out internally a sequence of actions so the actor does that
it figures out a sequence of actions that will minimize his cost according to
the predictions of the world model okay and this is very much system to type it's
very similar to what you know people do classically in optimal control it's
called model predictive control and it's really like this right observe the state
of the world get an initial world state representation combine that with what
you think about the state of the world from your memory feed a sequence of
actions to your world model and ask the world model to predict what the final
state will be then feed that to your objectives the objectives might implement
the goal that the system has set for itself or that you set it for it but
also you can have a number of guardrails so maybe a guardrails if we
have a domestic robot that is cooking has a knife in its hand because it's
cutting onions or whatever you might have a cost that says if you have a knife
in your hand and there are people around you don't move your hand too fast okay
don't flail your arms right that might be dangerous so you can imagine all
kinds of guardrails of this type to basically ensure the safety of the of
the system and the system has no choice but satisfy those because they are
satisfied at inference time they're not it's not like RLHF for LLMs
reinforcement learning through human feedback where it's a it's a training
time fine-tuning to make sure the system produces only safe behavior the system
can always produce unsafe behavior by you know being prompted something that the
the people training it didn't think of didn't think about here that's impossible
the system cannot produce a sequence of actions that will not satisfy the guardrails
according to the world model so those systems would be intrinsically safe
provided two things provided that the guardrail objectives guarantee the safety
and that's complicated also provided that the world model is accurate and that's
also complicated so you can imagine something like this that works over time
so that you know you can have a sequence for example in this case sequence of
two actions you can have and again this is very similar to what control
theories call model predictive control except here we're learning the world
model and possibly learning the cost as well you might want to imagine the
system like this that does hierarchical planning humans animals do
hierarchical planning all the time it's a essential characteristic of what we
can do and we don't know how to do this at the moment we have some ideas working
on it but it really doesn't work like if there is like a really good opportunity
for young scientists or aspiring scientists to really solve a problem
like try to see if you can do something about hierarchical planning because it's
really hard but the payoff if you can do it I think is enormous so a good
example of this is let's say I'm at NYU in my office at NYU and I want to go to
Paris okay so my objective is my is my distance to Paris I want to minimize my
distance to Paris at a high level I can say well first thing I need to do is go
to the airport and then catch a plane and there is a latent variable that may
indicate like which airport I'm choosing depending on traffic or whatever or what
airline flies at what time okay now how do I go to the airport well I have to go
down in the street and catch a taxi you can do this in New York you can just
hail the taxi in the street how do I go down in the street I need to stand up for
my chair open the door go to the stair staircase of the elevator how do I get
out from my chair I need to kind of push with my arms or something or or turn my
chair and then you know you imagine you can imagine decomposing this all the way
down to millisecond by millisecond muscle control I'm not going to plan my
entire trajectory from my NYU office to Paris in terms of millisecond by
millisecond muscle control that would be classical planning it has to be
hierarchical and people can do this today I mean engineers do this in
control but those various levels in a hierarchy are designed by hand the
question is can we train a machine to automatically learn what the proper
hierarchical representation of the action plan is and that's the unsolved
problem yeah you're looking to do a PhD or something or two or three that's a
problem we could use techniques like this for LLM's so LLM's that would be
non-autoregressive instead of producing one token after the other they would
basically infer a sequence of tokens that would satisfy a number of
objectives on a guardrail the objective that measures to what extent you're
answering the question and an objective that measures to what extent the answer
is non-toxic or toxic or whatever right that would make LLM's controllable
nothing like this works today right again if you are looking for a good topic
for a PhD that's a good one ultimately we need machine to learn to understand the
world that's the purpose of that world model the essential central piece of
that architecture I just talked about is this world model given the state of
the world at time t given an action I might take or a sequence of actions what
is going to be the state of the world at time t plus 1 or t plus whatever and
humans and animals are amazingly good at this babies learn how the world works in
the first few months of life at an amazing speed and they learn an incredible
amount of background knowledge about the world first thing you learn is that the
world is three-dimensional then you learn that something like object
permanence the fact that when an object is hidden behind another one it still
exists okay five and babies learn things like basic notions like gravity in the
around the age of nine months takes a long time to learn intuitive physics like
inertia gravity things like that okay but it's mostly just by observation a
little bit by experimentation and we don't know how to reproduce this kind of
learning with machines and that's why although we have fluid systems that can
pass the bar exam or medical exams we don't have robots that can clear up the
dinner table and fill up the dishwasher something that any 10 year old can learn
in one shot in a few minutes we don't even have completely autonomous level
five cell driving cars even though any 17 year old can learn to do this within
20 hours and then drive at 300 kilometers an hour on the autobahn you know
obviously we're missing something really big with machines that humans and
animals can can do in terms of learning that learning efficiency that that we
don't we don't know how to reproduce so we need this ability to learn world
models to get machines to learn world models from video essentially from
natural signals and so this is idea of self-supervised learning but now applied
to video not text and it turns out text is easy text is easy because text is
discrete and finite it's only a finite number of possible tokens in every
language on the order of thirty thousand or something and so it's easy to
predict a distribution a probability distribution over the next token you can
represent it by a long list of numbers between zero and one that's on to one but
if you want to predict video you can't do that because we don't know how to
represent probability distributions over all possible videos at least not in a
good way so if you train a neural net to predict what happens in a very simple
video this is over overhead video from a highway you get this kind of prediction
very very blurry prediction because the system can only predict the average of
all the possible things that can happen and it can't make it make up its mind so
the solution I'm proposing to this is something I call joint embedded joint
embedding architecture okay or joint embedding predictive architecture
JEPA and this is a non-generative architecture so everybody is talking
about generative AI what I'm telling you here is abandoned generative models
okay so not only am I telling you AI is not gonna kill us but LLM suck machine
learning sucks and generative models suck right all the popular things at a
moment okay so a generative model predicts you know if you have an
observation x you're trying to predict y just predict y from x using an
encoder and some predictor right but what the problem with this is that you
have to predict every single details of y and in video they're just too much in
text it's okay it's just like you know what word okay you don't know exactly
what word but it's okay in video it's just not possible so what you should do
instead is what's on the right here the joint embedding architecture where you
run both x and y through encoders the encoders eliminate all the irrelevant
details about the input and the prediction takes place in representation
space okay so joint embedding predictive architecture JEPA there's several
incarnations of this I'm not gonna go through the details because I don't have
time and you can read the details in this long paper I can't read what's on it
but I can imagine and and that's kind of the basic JEPA architecture so let me
skip ahead a little bit there's two there's two ways to train those JEPA's
basically two major techniques to train those JEPA's that cannot be understood
within the context of probabilistic methods but only within the context of
where I called energy based models and I was going to explain what this was but
I skipped that section but you don't need to know about energy based model to
understand what I'm gonna say so there's several methods to train those JEPA's
and this is a particularly interesting one this is a paper that was published
at CVPR just a few months ago it's called image JEPA and it's using this
masking idea so you take an image you mask regions of that image okay and you
feed that partially masked image to an encoder the encoder produces a
representation and with that representation you you try to predict
using another neural net predictor you try to predict the representation for
use from the full image okay and they both they run through essentially
identical encoders so not identical one of them uses something called
exponential moving average weights but but but they're almost identical and
and that works amazingly well so you you train a system this way pre-train it
with images that you corrupt by masking them partially and you get amazing
result on using the features that are produced by that system you get amazing
results for classification for segmentation for all kinds of stuff and
the Dino method I told you about before is very similar to this uses kind of a
slightly different way of encoding the outputs but it's it's in spirit it's
very much the same idea and it gives really good performance on image
recognition on transfer tasks on all kinds of stuff that I don't have time to
tell you about okay but things we're working on today that we need to work
on because we don't know how to do it perfectly is self-supervised running
from video so basically a version of this image JEPA that would work for
video and learn good representations of videos by observing the world basically
the same thing that babies can do right so we have a project along those lines
V JEPA and we have a paper that we're just submitting to a conference that some
of you probably know what it is because the deadline is today actually if you
know what it is you're probably not here you're working on your paper I think
the deadline is passed by two hours so maybe maybe you're here so then you
would be able to use those JEPA as world models right because you know you have
an input and you can feed it maybe a set of actions that an agent might take and
it will predict the representation abstract representation of the state of
the world at the next time step and so this could be used perhaps as a world
model as one of the components of the big architecture I introduced earlier
okay okay I said that already all right so there's very questions that we need
to answer with AI and this is my second life slide how long is it going to be
before we reach human level AI years to decades probably decades it's probably
harder than we think it's certainly much harder than what the most boasting
people believe there's many problems to solve along the way and before we get to
human level AI we're going to get to something like cat level AI okay so
people who are scared that you know one day someone is going to discover the
secret of human level AI is going to turn on this gigantic computer and that
gigantic computer is going to take over the world and kill everyone that's just
ridiculously stupid just cannot possibly happen we're going to start small we're
going to you know start with something that has all the right components but
it's small it's not gonna be very smart it's gonna be like a rat or a cat right
and then we're gonna work our way up and you know change the objectives to make
sure it's safe and test it in all kinds of sandboxes and blah blah blah so this
idea somehow that you know the discovery of a GI is going to be an event and
that machines are going to escape for control that's Hollywood movies it's not
the real world there is no such thing as a GI anyway because intelligence is
really a multi-dimensional thing humans are only good at certain things and
terrible at many things in fact our minds are extremely specialized we don't
realize this but we're incredibly specialized and we know this because
computers are much better than us at many tasks for example chess go poker
pretty much every video game I mean not today but eventually recognizing a
species of a bird by just listening to the song recognizing an individual
whale or marine mammal by the shape of the tail like AI systems can do this a
very small number of humans can do all of this I mean we just we totally suck at
chess as humans machines are much better than we are and so we don't have
general intelligence ourselves so this word a GI makes no sense human level
yes a GI no there's no question as I said before that machines will eventually
surpass human intelligence and so people are scared by this but really this is
a interesting question to ask ourselves imagine a future maybe 20 years from now
or maybe longer where every single one of our interactions with a digital world
is mediated by an AI system okay and it might happen faster actually okay if
some of the startups that are being created today and some of the big
company plans product plans actually fulfilled this may happen fairly
quickly that essentially every time that we want to connect to the digital world
that we be through the intermediary of an AI system then those systems will
become the repository of all human knowledge right and it's very important
for that at least the base for a foundation of this to be open-source
every infrastructure the internet is open source runs on open-source software
and the reason is because it's too important for one company to control it
right so it's the same for AI systems they will have to be open source because
it's too important for any single company or small number of Californian
company to control AI systems if all of our information of all the citizens are
basically filtered through those AI systems the way those systems will be
trained will need to be quite sourced kind of like Wikipedia to collect
culture and information and knowledge from the entire world not just from the
view of the world in parallel to us in place right so that's why I'm a huge
advocate of open-source base models for AI and a number of my colleagues at
at meta and his company policy at meta to open source those base models because
it makes them safer more powerful the progress faster they're more culturally
diverse if more people can train them and it creates an entire ecosystem of
startups and research projects that can build on top of it so it's a very
important political questions at the moment because a lot of companies are
pressuring governments around the world including the German government to
basically keep AI under lock and key to say AI is too dangerous it needs to be
controlled and licensed and and not put into the hands of everyone I think it's
the exact opposite I think it's too dangerous to actually keep in the hands
of just a few a few people okay so I became a little philosophical political
here those people have convinced the UK government the Prime Minister that AI
should be regulated under lock and key apparently the EU Commission also is
convinced this is very bad and I think if we do it right AI will make everybody
smarter it's like we will have those intelligent assistant with us all the
time it's like having a staff of intelligent people working for you okay
every person who is leading anything including me only works with people who
are smarter than them right only hire people who are smarter than me because
that's the way to be successful so that everybody is gonna be like that we'll
have AI assistant that are smarter than us we shouldn't feel threatened by them
because we'll be controlling them they will be designed to be subservient to
us so this may have an effect on society similar to what the printing press had
five hundred years ago not too far from here of basically causing a new
renaissance because intelligence is really the commodity that we lack the
most this will make humanity smarter thank you very much
yeah thank you so very much Jan for an amazing lecture we have about 10 minutes
for questions and I'm sure there are several so
much for the great talk asked Ma from Hemant Munich you alluded to the fact
that we should keep code open which is great however as you know right many of
the recent developments not just rely on the code but also on the hardware so
many of the things are developed at companies because they have access to
large GPU resources now not only Germany I guess we are limited by that so and
what's your take on that also being in an academic and an meta environment right
how do you deal yourself with it do you do some things only at universities and
others only at meta or how I mean how do you see that in the future okay should
have used an automatic speech recognizer because there is an awful echo and it's
very hard to understand it's not your fault but anyway I mean hardware is a
big limitation so currently the only entities they can train large language
models that are good are people who have access to large amounts of computation
either in-house which is the case for Google and meta and Microsoft or through
cloud services which is the case for open AI and and so I pick and others they
have access to Microsoft Azure and you know some of them use AWS some of them
use other other tools so but that costs a huge amount of money so training a sort
of top-of-the-line language model today you know costs tens of millions of
euros right it depends how many tens depends on how you do it possibly more
if you want to buy an infrastructure that is sufficient power today you have to
buy basically stuff from Nvidia and it's going to cost you a number with with
ten digits it's in the billions it's insane so what that tells you is that
it's like it's like an autobahn you don't want ten parallel autobahn going
from one city to another city you just want one and that has to be sort of
accessible to everyone so that's the idea behind open source base model
foundation model they need to be open source because it's a common infrastructure
they can be customized and there's no point having 50 of them because they
cost so much to train that's another argument for open source
hello yes hi thank you for the great lecture there was a slide that had
challenges of AI and machine learning and there were three points in there it
went by really fast and I couldn't catch if ethical fairness responsible AI was a
challenge that you're facing with and if so what are you doing about it okay so I
think that point was wrapped into the the second point but sort of not
mentioned directly it was more can I mention in the other thing so this idea
of objective driven AI the fact that a system can only produce answers that
satisfy a number of objectives including some guardrails the answer to your
question is how do you design those guardrails essentially we don't have an
answer to this and the reason we don't have an answer to this is because we
haven't really began to build systems of this type and so it's as if someone in
1925 asked aviators how are you going to make sure that transatlantic
transatlantic flight at near the speed of sound would be safe nobody could be
possibly answering this nobody across the Atlantic on a plane in 1925 at least
not in there not with that any stuff nobody knew what a turbojet was like
the idea of you know speaking at near the speed of sound was completely
unthinkable so we're a bit in the same situation we don't know how exactly how
to make those things safe because we haven't built them yet but I think it's
an engineering problem like any other problem and there is a there's a fallacy
also which is that to design those objectives a lot of people say oh we've
never done this before so we're not gonna know how to do it but in fact we are
doing this all the time we've been doing it for millenia designing objectives so
that intelligent entities behave properly that's called laws lawmaking is
designing objectives for humans to behave properly and it's even designing
objectives for superhuman entities to behave properly superhuman entities
like corporations for example right corporate law basically is a way to make
sure that whatever a corporation does is aligned more or less with the common
good of society right of course you know they can be corruption and everything
but that's the that's a busy guy yes so we're very familiar with this with this
this concept it's not it's not new
and thank you Jan for the really great talk I want to follow up on the question
we had earlier about GPU resources what I see is that in machine learning and
AI the biggest breakthroughs in the last years were achieved with huge amount of
GPU resources the amount that academic institutions typically do not have do
you see a future for academic research in the field of AI so I'm gonna can make
myself I have two hats okay let me tell you something many of the best ideas come
from academia okay the whole idea of generating images from text and things
like this those actually came out of a German university right and then you
know people picked it up and made products out of it but originally this
was done not too far from here in the university the whole idea of using
attention mechanisms which is the basis of transformers they came out of
university or Montreal so that was an interesting story they this was Dimitri
Bada now Kim Jong-chul who is now a colleague at NYU and Joshua Benjo and
they came up with this idea that when you build a translation system the
system should be able to decide which word to look at to translate you know
English into let's say German in fact German was the main issue because you
know the verb is at the end so it screws up all the translation system so so
that was actually the solution to that problem and and they came up with this
idea of the those kind of learn attention mechanism and then there was a
paper that that by Chris Manning at Stanford that sort of picked up this
architecture and made it work at scale so they won the WNT competition a few
months later and then the entire industry jumped on it right and then you
know as much people at Google said oh you can build an entire neural net based
on just this idea and the title of the paper was attention is all you need and
that was the transformer and you know so the root of some of those good ideas
are very often in academia then the problems that I talked about you know
how you do hierarchical planning how you're done world models from video that
kind of stuff these are things you don't need enormous amounts of computation to
demonstrate a principle you may not be able to you know beat some benchmark
results or whatever but it doesn't matter if you show that a principle can
work and it's convincing enough then there'll be other people who pick it up
and actually build something real out of it it's okay that's the way you have
intellectual impact so if you think about your career and what drove you would
you say that more the dreams you had about what could be possible or you're
so interested in the topic let yeah just all the work you contributed to and how
that maybe change also over time yeah so interesting question I think at the
root of it is really a scientific question what is intelligence how does
the brain work you know it's a very sort of front and center big big scientific
question over time so right there's three big scientific questions is what you
know what's the universe made of what's life all about and how does the brain
work right three questions but then I'm kind of an engineer as well so for a
complex system like the brain the only way to really understand how it works is
that you build one yourself and you verify that like all the hypothesis that
you built into your system actually kind of correspond to what happened and it's
really the inspiration behind convolutional nets and multilayer learning
and the whole idea of neural nets in the first place right getting inspiration
from the brain but not copying it because you copy it blindly you're not
gonna get anywhere you need to understand the underlying principles so
underlying the understanding the underlying principles of intelligence is
really what kind of drives me and then it's great if you have like multiple
applications whether they are useful or entertaining I mostly don't do this
myself but but I'm really happy with people do it
hello LeCun I want to ask you a question what's your opinion on the field of
embodied AI and robot learning I think it's very interesting because it's
deployed artificial intelligence techniques to change the real world yes
I completely agree so in fact in fact that's kind of one of the point that I
perhaps didn't make clear enough that this idea of world model as I said is
easy to do in the context of language which is why we have language models
that are so impressive but it's very hard to do in the context of sort of real
world data video things like that property of sensitive data from a robot
and so the good news about the good thing the good aspect of embodied AI of
like working with with robots whether they are real or simulated is that you
can't cheat you can't take shortcuts like representing everything as a word or
something although some people are trying to do that but so I think
focusing on this kind of type of problem I think makes people honest so I
think the most interesting advances in AI over the last several years are not
in LLMs they are in people who do robotics and try to do control and
sort of make robots basically learn efficiently without having to be trained
by you know for hours in simulation this teams there's a colleague at NYU
Lera Alpinto who's working on this there is I mean I've looked at colleague
Emelon and his colleagues and then probably the biggest group working on
this is at Berkeley Peter Abiel, Segelle Levine and Chelsea Finn who is a former
student of theirs at Stanford those are really kind of interesting approaches
there this whole idea of planning objective-driven kind of planning you
have to do that in the context of robots so in that sense is very interesting
there's a whole division at fair that actually is called embodied AI for that
reason thank you yeah thank you so much Jan I mean this amazing lecture and I
think you're all very grateful that you shared your thoughts and perspectives on
future AI with us and I think we all got a lot of impulses from this today so we
have a small gift for you as well
thank you
yeah so let me also again I mean thank all cooperation partners who contributed
to this event so the Center for Advanced Studies, Biosphere, the Varian Academy of
Sciences, Humanities, Munich Center for Machine Learning, the Varian Research
Institute for Digital Transformation and the Konratsu School of Excellence in
Reliable AI and sorry I would like to have a special thanks to Dr. Ursula
Olinger who is Science Manager at my chair and who headed actually the
organization of the entire event so I think she deserves a small applause
yeah thanks also everyone for coming here and also for those who joined us
via live stream we now have we I would now like to invite you to a little
reception in the Sitzungsal 1 and 2 which is here right around the corner so
thank you so much
you
