Okay, after that we have our discussion session for about half an hour from 4 to 4.30.
So the next talk will be given by my colleague, Major Naik, who will talk about scallops and
other seafood.
Hi everyone, thanks Val.
So I'll be talking about this programming language and compiler that we have been building
over the last three years on this exciting topic called Neurosymbolic Programming.
As a disclaimer, I'm a programming languages researcher mostly consuming all the cool stuff
that folks in databases and AI have been doing so.
So you won't see much in terms of novelty, but you'll see a lot of interesting synergies
and empirical results that come from importing good theory from other theories.
Let me first motivate the need for Neurosymbolic Programming.
So there are these two prevalent paradigms of modern programming as all of you know.
So these are commonly called System 1 and System 2 by noted psychologist Daniel Kahneman
in his book Thinking Fast and Slow.
So if you see System 1 is deep learning where you have a lot of benefits.
For example, you have subsymbolic knowledge, what that means is you have meaning associated
with say a name Tom that likely is a male and so on.
There's open domain knowledge so you don't have to write and code everything explicitly.
They're good at rapid reasoning, handling noise and naturalness and what we nowadays
see with foundation models is in context learning or more accurately prompt engineering.
On the other hand, we have classical algorithms which is System 2 where you can explicitly
encode knowledge and get more data efficient solutions.
You can also do complex reasoning, things like multi-hop reasoning using recursion but
also negation, aggregation and so on, which traditionally deep learning isn't great at.
You have other benefits like interpretability, modular reasoning and better generalizability.
Traditionally these two systems don't talk to each other very well but we do want features
of both for many AI applications and so that has given rise to this field called Neurosymbolic
programming.
Now this term means slightly different things to different people and so I'm going to define
more specifically what it means to us that there is a much richer taxonomy of different
styles of Neurosymbolic programming that we don't necessarily encompass but I will show
you that at least this form that we consider is interesting enough to write a lot of useful
applications.
So what I've shown here is a picture of the three approaches before proceeding to why
it is hard to combine deep learning and classical algorithms in a single system.
So in deep learning much of the success comes from gradient descent algorithms for back
propagating the loss to learn the parameter theta of this neural model.
X and Y are in these double boxes indicating that you have supervision on them.
On the other hand classical algorithms such as this program B can typically work on structured
data which I'm going to indicate with R.
And in Neurosymbolic this is a simple Neurosymbolic program where there's initially a neural
component and theta which takes input X produces an intermediate representation R which is
structured which in turn is fed to a classical algorithm P to produce an output Y.
And we have gradient descent here dR by d theta but we'd also like to somehow back
propagate the loss across this program, this discrete program B.
And even though this looks like a supervised learning setting we have actually used Neurosymbolic
programming in many different settings that I'll show you today including RL and even
unsupervised learning with foundation models.
So what are some of the challenges that we tackled in building Scallop?
So the first question is what is the symbolic representation to use for R?
And the second is what is the reasoning language for programs P?
As you can imagine there's a lot of different choices for these decisions.
First importantly how can we obtain an automatic and efficient differentiable reasoning engine
to learn this dY by dR under what we call algorithmic supervision?
What that means is you're not given supervision on R and that makes this whole problem more
challenging.
You only have supervision end to end on end to end observable input output data X and
Y but not on sort of intermediate data R and this makes sense for a lot of applications
if you think of an healthcare application, you have data about a patient, all of their
lab measurements and so on and you have some outcome Y of say a treatment but even an expert
clinician might not have time to label every intermediate piece of information or might
not even know how to label it even if they could.
So that makes this problem particularly challenging.
We also have two other challenges here we'd like to tailor learning of this computing
dY by dR by different applications characteristics at this point we are looking at approximate
algorithms which go along well with gradient descent which is already approximate.
And lastly we'd like to integrate with all the existing training pipelines.
So more of an empirical challenge here we don't want to reinvent something like PyTorch
and so we'd like to reuse all the existing models and training pipelines.
So here are some of the design decisions that we made much of this borrows from work by
other researchers we were particularly inspired by DeepProblog but would later learn that
there was work by many other researchers as well and our main contribution here was really
using Datalog and putting all of this together in a practical system.
The first design decision here was to use a relational representation for R and I don't
need to tell a database community about how the relational model has withstood the test
of time it can represent very general forms of data in arbitrary graphs and there are
many other nice properties about relations as I will show you when we tag tuples with
probabilities and more general kinds of information how this relational representation is really
helpful.
The second is the choice of the language for P and here we use a Datalog based language
we started out literally with Datalog but it has grown over the years we have support
for algebraic data types, foreign functions and so on actually it is at this point Turing
complete so depending on what subset of a language you use you get different guarantees.
Perhaps the most interesting piece here for this audience is we accidentally discovered
provenance semirings we were playing with different kinds of tags and eventually realized
that they could they were one could generalize them in this very elegant work which was mentioned
at the beginning of this workshop on provenance semirings I will show you the different semirings
that we have in my talk and lastly we have you know integration with both PyTorch and
Jax so PyTorch for getting models that might be pre-trained and so on that we might want
to fine tune but also for computing the loss here using something like Jax.
So it is a pretty usable framework and to end with lots of moving pieces let me give
a simple motivating example of the kinds of things we can do with Scala.
This is a simple strategy game called Pac-Man it is actually a simplified version which
is called static Pac-Man as in the ghosts are not moving the setup is as follows there
is this grid of 5 by 5 cells right each time in each instance of this game we randomly
assign these ghosts the Pac-Man agent and the goal in different cells right and as I
said the ghosts don't move and so the goal is to learn to for this agent this this Pac-Man
to learn to reach the goal without hitting any of the ghosts right.
We set this up as a as a simple RL reinforcement learning problem and we use a simple model
here which is DQN DQ networks to train this agent right so the baseline here is an end
to end neural model a convolutional neural network which is not given supervision on
which cells contain ghosts or the or the goal post or the the Pac-Man itself right all of
this is the intermediate representation to be learned the only supervision one gets is
after an entire game episode where either the Pac-Man reached the goal so you get a reward
of one or it didn't and in which case it gets a reward of zero right and we formulate this
problem in scallop by decomposing it into a neural model right which is doing sort of this
low level perception so the goal of the neural model is to simply learn what each cell might
contain right and there are four choices can either be empty or it can contain a ghost
or it can contain the the Pac-Man itself or it can contain the goal okay so these are the four
choices now this neural model outputs these choices to a logic program in scallop whose goal is to
do the path planning okay so in summary instead of having a monolithic neural network which is
trying to learn end to end how to do both entity extraction and path planning we decompose this
task into entity extraction which is sort of low level perception that is best done by a neural
module and a logic program a classical algorithm which does the path planning right and at each
step the goal is to decide whether the Pac-Man should move up down right or left right but you'll
get the reward only after an entire episode of around 20 steps okay so here is our empirical result
in in just 50 such episodes with this scallop program that I showed you we can get an accuracy
of 99.4 percent whereas if you do this with a baseline of end to end neural you get a much
lower accuracy and it requires over 50,000 episodes right there's some hand waving here this is not
entirely a fair comparison right because we have written a domain knowledge using logic rules
I probably skipped over the the program itself so here goes so this is our our syntax for our
data log based language but in this case for path planning so the goal here is to compute
the next action right one of these four choices and that in turn depends on whether there's a path
from an adjoining position where the Pac-Man currently is to the goal right and the definition
of a path is itself a recursive predicate it's a path that does not collide with any any of the
ghosts right and that is encoded using what we call safe cells okay any questions so far
okay so so the programmer writes this discrete program without any probabilities and so on
but what we will see happening under the hood when when when both at training and inference time
is a neural model will compute these predicates such as actor goal and enemy
only with different degrees of certainty right so in some sense we have all of these possible
words being tracked simultaneously by the the scallop engine okay and all of that computation
will be done through tags which you don't see here at the level of the values that are being
propagated can I ask you a quick question on this is there a notion of a shortest path or it's any
path or how good question so it is so here we say any path but if I understand this correctly
the tags will penalize paths that are longer okay get cycles in the path you will
like I think so okay so let me get into the semi-rings okay so the short answer is the tags
will track you know will be tracking a finite amount of information so they won't
necessarily compute all you know paths with cycles and so on yes in this example
they are now very responsible for extracting the state of the program and then you have a
actual program to kind of like perform the logic I guess the neural network extracts like
action information or something else like this so the neural network only extracts okay so the
question was whether the neural network extracts these predicates these actions right if it did
so that is the baseline that I was showing you that you don't have a logic program so the neural
network is taking in this this grid of pixels 200 by 200 pixels and producing one of these four
outputs or rather distribution over these four outputs so that is the baseline I mean if you
were using that then you wouldn't need scallop right here we are trying to show you that you can
actually give more data efficient and robust and so on okay by the way this program which is
learned it generalizes very nicely to much larger grids even 25 by 25 so you see whereas a network
which was trained end to end would probably not generalize well to other grids grid sizes okay
so let me briefly talk about what is going on in the scallop compiler so we have this
differentiable reasoning framework first a preview of our entire compiler so the surface
syntax looks like this in this case you know it even has limited forms of quantifiers we have a
front end which produces these abstract syntax trees and there are several passes here for
type inference and so on then we have a back end where which is based on extended data log
where we do a lot of optimizations including query planning and magic set transformations
and so on and finally we have this relational algebra machine or RAM which is what is actually
executed at training and inference time right and this is what the equivalent scallop RAM program
looks like for that high level constraint okay so where does prominence come in so the semantics of
scl RAM which is essentially just extended relational algebra which is well the semantics of
data log we have implemented a very general framework for tracking provenance right and this
is inspired by the work on provenance semirings that was mentioned at the beginning of this workshop
and we even have this very clean interface to define new provenance structures right and so
again covered in the original tutorial but briefly there's this tag space that you have to
define yourself and then various operations for disjunction conjunction negation and saturation
right I've shown one instance of this abstract structure here which we call max min probabilities
here the set of tags is real numbers between zero and one and and disjunction is max
conjunction is min and so on and so forth okay if you apply this max min probe to a particular rule
during the execution of the program I showed you let's say the rule which computes whether a cell
x comma y is safe okay so it is safe it's if it is indeed a grid cell okay a cell in the grid
in the five by five grid and we do not believe that there's an enemy in the cell right so this is
the standard semantics of data log of discrete data log okay untagged semantics so let us say
that in one comma two and two comma three are two different grid cells and let us say the enemy is
in the cell two comma three then we know how to compute this difference so that's just the
two per one comma two right but in the tagged semantics something much richer is happening
which is that we have these tags t1 t2 and t3 now and they are they are they are propagated here
along with the output values of each rule and once you use a particular
provenance semiring in this case the max min probe we can for example say that in this case
we believe the enemy is in cell two comma three with the probability of 0.2 coming from the
convolutional neural network right and so now you can imagine every cell has some probability
of an enemy being there um and accordingly you can now get estimates of um which cells are safe okay
yes go ahead
so the difference with from what is with more companies that use this fuzzy logic
we are propagating the probability difference to prob log so the problem has been weighted model
accounting semantics right so you use the fuzzy semantics to propagate the
so so we so i wouldn't know the answer to that we can probably take that offline but we do have
so this was as i said inspired by deep problem we do have weighted model counting what i just
showed you so max i see so you mean fuzzy as in this max min okay okay so i just showed you
simple semiring in practice we don't use any of those we just use them early on while we are
developing applications but very quickly turns out these fuzzier semirings don't really help
learn the model okay so the one that we really use so as i said there's the discrete uh execute
execution um there's the probabilistic one uh and and then finally there's the differentiable
one which is what we use for for learning right and the one that you are probably talking about is
what we call top k proofs so along with each uh tuple we we track um you know the what we call
you know up to the top k proofs which i think eric in the first talk referred to as i believe
w of x okay so we don't count how many times a tuple is is was used or anything yes
with respect to the negation and saturation operations right uh can you expand a little bit
on what your requirements for them are um for this to work yeah this is sort of too low level
for me to explain so i wouldn't know i'll be happy to get you in touch with uh the student
you know first of all it will be stratified negation but i think you are asking me a deeper
question than that structure what the test to what the negation has to prove that
if it comes to me i'll let you know i i do know exactly what you're asking and i'll i'll try to
see if i can remember okay um there are certain restrictions on on on all of these on on negation
and saturation okay um but you prove them once and for all when you're defining the semi-ring
okay um and so you can then use it um okay so i'm not going to go too much into further into
semi-rings other than to just say that uh the nice thing here at least to me is that the programmer
writes as if they are programming against a deterministic neural model that is producing
these outputs right but under the hood you have all of these probabilistic and differentiable
uh uh reasoning happening through these tags okay um we have applied this to a wide range of
benchmarks and are now moving to even more sophisticated ones uh in robotics and healthcare
for explainable healthcare and so on but i'll just show you some core uh uh you know some
challenges in in the field of ai that we started out with um and these include um you know benchmarks
in computer vision which have images and video for example here this is uh this mugen benchmark
where the goal is given a short video and a piece of text to give a score between zero and one uh
that tells how likely is this text uh uh talking about the frames in this video right so this as
you can imagine has applications in in in video captioning video search video recommendation
and so on right um there is we have benchmarks in nlp as well um again fairly standard ones um
and um and then we also have multimodal benchmarks and and much of this these benefits of relational
the relational model uh are useful here for example we extract scene graphs from images
which can be represented as relations we extract abstract syntax trees from uh in semantic parsing
which are again represented as relations right um this is where the rubble meets the road all of
this theory is elegant but if it doesn't work in practice then it's not uh then it doesn't help us
right um when we started this project many of these baselines uh both neural and neurosymbolic
were far behind us right but by the time we got all of this published some of them had even crept
back up ahead of us right so this is sort of the challenge we face against the end to end
deep learning paradigm right which is it will you know um you know as newer neural architectures
and so on are designed they might even outperform say the neurosymbolic approaches okay so um any
questions before i proceed yes maybe also right so accuracy is one thing right but i could also
see that since you're encoding some domain knowledge into your program right i could see that for
example you might need like less data to learn the model and things like that and maybe it's more
performant yes so so great question and and and we have all of these results in our pldi paper pldi
2023 uh where we talk about better interpretability so if you remember the intermediate representation
are on which no supervision was given we can actually look back what did it actually learn the
right representation right uh and and the answer is yes so it is so it is more interpretable it is
more robust and better generalizable and so these better neural networks are they kind of trying
to do what you do with your structured constraints are they trying to do that through network structure
are they trying to simulate physically what you can do no more elegant yes um so first of all these
are end to end deep neural models right like transformers and so on we wouldn't necessarily
know what they are trying to do but but they are solving uh this problem let me show you one right
so this path finder it was a benchmark by i think google research a few years ago called path x
you see there are two tiny dots and and you have to tell whether there's a dotted path from one to
the other okay and even for a human uh it can take up to two minutes to tell for some of these
difficult images whether there's actually a dotted path or not it's a binary classification
problem right so uh you know so the state of the art now here is actually a transformer which uh
i'm sorry which uh which beats what we have so you see for path x there's this transformer model
which is doing even better than ours in our case we simply love you know we have the rule for
computing transitive closure so once you know which where are the two dots and where are the edges
you can use trans you know simple these two rules to tell whether they are reachable but you don't
know if their model is trying to do something like that in the deep learning model directly right
so we haven't actually seen you know like for explanations within them so so it would be nice
to see that there are also some neuro symbolic uh baselines here i mean work that ghee and others
have done by the way a lot of his work has gone into this with sentential decision diagrams and so
on in our weighted model counting that i'm you know just ignore you know not mentioning here
but but there are the neuro symbolic works as well uh uh based on you know abductive reasoning
and so on that we were able to outperform yeah so i have a question about the gradient
semi-ring which was mentioned several times today so i don't understand how it's useful in
in the context here because gradient semi-ring really computes the forward derivatives which
means that if you have a neural network for object detection with a million parameters you have to
push forward a million dimensional vector through your whole computation path and what you really
need for machinery is the backward derivatives which are you know linear time and so even though
mathematically the gradient semi-ring is a beautiful thing it's actually the wrong tool for machine
learning you want the backward derivative not to forward
yeah so so i think yeah i think we'll have to talk about this more offline sorry about that i
i yeah i i i wasn't paying too close attention to the gradient semi-ring let's talk more
yeah could you go back once yeah so uh so for the first two examples of you have to
m this this is like after you recognize so another approach is that you recognize this
and then you just write Python to some something together right so why is this any better
why are you doing anything your supervision is not given on the individual MNIST digits okay it's
only given on the final result yeah so but this example is it feels a little bit confined right
so i could have done this by doing the two basic approach yeah yeah for example here we are this
kind of more streamlined approach has uh declared anything of course so so if you had supervision
on the intermediate results you wouldn't need scallop at all okay right right in in none of these
benchmarks do we have intermediate supervision even though many of them are synthetic and you
actually know the intermediate labels so that is how we actually you know measure whether you know
the degree of interpretability how much has it actually recovered the information so i'm not
showing you you know we have heat maps for all of this to show you actually what intermediate
representation was learned and it is it matches the synthetic data's labels
okay so you know that is you know i'm just going to show you some fun things here there's not much
more i can say here with you know so now what happened was in these two years that we did this
work LLMs and more generally foundation models came on the scene and we wondered you know can we
catch up right can we somehow integrate this into scallop and the answer surprisingly is yes
okay and this is still open i think joe also brought this up you know if i understood correctly what
you're saying you know so what is the the programming you know abstraction for say you know these
generative models and surprisingly the relational model still works if you think of any foundation
model right it is a binary relation which takes a prompt and and gives a response right and these
are data types where the strings or tensors and so on are all supported in scallop okay and it's
actually a relation not a function because based on the temperature and so on that you use the same
prompt could have different responses right so it fit right you know very well into scallop
and we built this library of plugins we now have 12 foundation models integrated into scallop and you
can add new ones very easily using our foreign function and predicate interface i'm not going
to go too much into these but i can you can sort of see how we are we have these decorators for
relations and you can use a few short examples or you can use chain of thought you can use auto gpt
you can even fine tune you know layers of these models in scallop using again just end to end
supervision in this case you know we break down this task into sort of this in-context learning
which extracts tuples you know which are the basic relationships between pairs of people mentioned
in this passage and then we write a few rules in this case just three which can compute the answer
to a question which is how is a particular pair of people in this passage related right so this is
sort of showing you multi hop reasoning by the way we even have rule learning here so the parameters
don't just have to be in the neural model but for example this relation composition is itself noisy
and you could learn the weights of individual tuples of this relation right we can extend it to
vision models as well so here's a simple one which is actually a multi model model clip from open AI
which also provides probabilities so in this case the the the input is an image so it's a bound
argument and the output is the label so in this case if you give a set of labels such as cat and
dog it will tell you the probability of this image being a cat or a dog right we have also
integrated meta segment anything model so this in this case you are given an image as an input
and it produces a set of tuples with an ID of each segment and and the tensor representation of the
segment right you can put these all together and build very interesting multi model applications
in scallops so in this case here what you see is three different models put together to solve
the problem from this clever benchmark which asks in this case some some question that involves
elementary reasoning about a scene right in this case how many green objects are there in the image
I'm not showing you all of the rules that we wrote in scallop there are about 100 rules that we wrote
for this particular task but we use these three different models to extract basic information
in this case doing the semantic parsing of this question extracting segments from this image
and finally labeling each segment with a piece of text and finally we can get the answer that there
are three green objects in this image okay so I'm not going to show you the imperial results
this work is still under review we have applied it to a wide range of benchmarks including those
involving vector databases also you know you're having retrieval and generation but also image
generation and so on right and you can actually run many of these applications at this URL and
there's a lot more resources at this particular URL okay so thank you very much for your attention
I'll be happy to take any questions
