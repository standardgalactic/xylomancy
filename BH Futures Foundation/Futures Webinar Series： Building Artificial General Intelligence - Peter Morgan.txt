Okay, good evening, everyone, and welcome to Future's webinar series by BH Future's Foundation.
I am Ivana Yevtovich, webinar coordinator.
Tonight, we will hear about artificial intelligence.
The development of artificial general intelligence is going to require algorithms that can do
things like inductive reasoning, planning, and optimal learning from limited amounts of data.
Several efforts are underway to develop these technologies for deployment in future systems.
We are currently witnessing these new approaches being given more and more attention
as we enter the new and perhaps golden age of artificial general intelligence.
In this talk, we will present some of the newer, more general approaches
to solving intelligence that are really currently under development
with the view to deployment in the intelligence system of the future.
Tonight's speaker is our guest, Peter Morgan.
Peter is author of the popular report, Machine Learning is Changing the Rules,
Ways Businesses Can Utilize Artificial Intelligence to Innovate, published by O'Reilly.
He's passionate about artificial intelligence and the positive changes in this technology can and is bringing to society.
Peter founded the artificial intelligence consult company, Deep Learning Partnership,
to carry out his mission of helping to bring artificial intelligence to the world.
He advises and mentors technology startups and is a speaker at artificial intelligence conferences and meetups.
Peter founded the popular London Deep Learning Lab Meetup.
Links for the mentioned companies are listed down below so you can check it out.
Peter, it's an honor to have you here tonight and thank you so much for being with us.
Thanks, Havana.
Okay, so this gets started.
So Havana has just introduced me and there is a data science conference
on the 2nd of July at Croatia that I'll just put a little shout out now for.
So if you want to look out for that, tune in for that as well.
Okay, so there's a little book I wrote that Havana mentioned on a practical book on implementing machine learning in real plants for companies.
That's what I do for a living.
I'm a consultant, machine learning consultant.
Today's talks are going to be a little more futuristic in that there are no actual deployments yet.
But it's a look towards the future where we are now, where we want to get to and how we will get there.
So here's an outline of my talk, what is intelligence, that start off with the basic question we're trying to solve.
And then look at how the world produces intelligent systems, either biological or non biological.
We're trying to non biological route here.
We are the biological humans are, you know, the most intelligent thing that we know of in the universe so far,
or though at times it doesn't seem like it right.
And I'll do a very quick recap of deep learning and just to see, you know,
if that's part of the journey or not, if it's a dead end or if that's, you know, a step along the way to artificial general intelligence.
And hopefully everybody's, you know, at that kind of level, you've heard of deep learning, machine learning.
That will probably help understand the talk.
But even if you don't, it doesn't really matter.
This is a fairly general talk high level.
And then we'll look at AGI or artificial general intelligence.
And we'll see, you know, maybe how we might build such a system or if it's possible.
And then if it is how we might build it, then we'll wrap up.
So my talk will be about 40 minutes long.
And so let's get into it.
So, I mean, why do we even want to build general intelligence?
Well, the idea is, and you may have heard deep minds say that it's a company based here in London under the Google umbrella these days.
Because then we'll build intelligence and use it to solve everything else, right?
That's the big goal. That's the vision.
So at the moment, like I say, we're the most intelligent things around.
So we're solving, you know, all scientific problems, medicine, you know, climate change.
Just every problem right now, humans are tackling it as we have been doing, you know, from the beginning of time.
So, you know, it's a big vision, right, is to build systems that can basically supersede us and accelerate science.
Isn't that an amazing goal, right?
Isn't that an amazing achievement if we could do that?
Clearly, you know, it's worth a lot of money.
So everyone's working on it, Microsoft, Google, a lot of bunch of startups.
So let's see where we are on that journey.
OK, now, first thing I'll mention is that people do get a little bit worried.
Oh, my God, what happens when, you know, we're no longer the most intelligent things.
That's a rather philosophical question, and there's a lot of debate and books being written about that.
It's a very hot topic at the moment.
It comes under the umbrella of AI safety.
And so if you want to look into that, you know, I encourage you to do that.
But we'll focus on the engineering in this talk and the science.
OK, we'll leave the philosophical problems to the philosophers, I'm afraid.
Or that that's a topic for another talk, which I could give to, but I won't on this one.
So again, you know, what is intelligence?
Is it, you know, beating go?
Is it, you know, winning at StarCraft, you know, beating the best go play
at the best players in all of these games, basically, go StarCraft, chess, jeopardy?
Well, as amazing achievements as all of those were, like breathtaking, you know,
when it happened at the moment, I remember, you know, watching all of them actually
and just, you know, put my breath away.
But no, it's not actually general intelligence.
Those are examples of very narrow intelligence, impressive as they may be.
Because the system, the clever system that beat Gary Gatt, Casper Robert,
chess, it can't, you know, beat Lisa Doll that go, it's essentially done
outside of its very narrow domain in which it's superhuman intelligence.
OK, so they're not generally intelligent systems.
OK, so they're all examples of narrow AI.
So what is intelligence?
Well, Howard Gardner at Harvard a couple of decades ago, you know, it seems
so obvious now, but at the time, you know, no one had kind of thought
about this or written it down, which I, you know, it's one of those things.
But he did and I like it because it sort of says there's about nine
different components to intelligence, right?
So, you know, the go, the chess, that's the logical mathematical component.
That's superhuman at the moment.
I mean, a calculator that we can buy for five bucks or whatever, you know,
can do long multiplication, you know, far faster than we can.
OK, so there's clearly superhuman in that domain.
But what about the others, musical, nature, spatial, you know,
robots maneuvering, navigating through space, time, self-driving cars,
that kind of thing, intrapersonal.
Now, these are the harder ones, aren't they, the personal intelligence,
social intelligence, and intro knowing ourselves and then enter
knowing about others.
OK, so that those are probably, you know, the most challenging thing.
And the was that, you know, people say, you know, there are a lot of skeptics
and they will never have, you know, be able to build systems like that.
Well, I'm going to argue there's nothing in physics,
the laws of physics that says we can't and clearly biology has done it.
Right. And so that's, we're a physical system.
There are people and, you know, it's fine.
80 percent of the world believes in some religion.
That's fine, too.
I would argue that, you know, once you get the right physical systems,
that, you know, they will be capable, have the capacity of,
you know, believing in higher powers and stuff like that, too.
So, you know, there's all these philosophical questions come up as well,
but they can be, you know, I will try to reason to scientific questions,
engineering questions.
There's linguistic language,
natural language processing, translation, you know, Siri,
Google translate, you know, these are amazing systems,
but they're not quite there yet, are they?
They're not quite superhuman.
Go is, you know, calculators are.
But, you know, all of these are the types of intelligence we are working on.
OK, we're not there yet.
We're not human level intelligence, but we certainly work on them.
You know, the bodily kinesthetic, you know, you watch,
is it Atlas, the Boston Robotics, Boston Dynamics,
whatever they're called, company, you know, doing flips now, you know,
like a gymnast.
So we're making a lot of progress on many of the, on most, on all of them, actually.
And it's essentially why are we here?
You can imagine a robot sitting there going, hmm, why am I here?
You know, that that's how we'll know we've got your own intelligence.
And there's a nice beautiful picture of one right there.
And so how far have we come?
Well, I've covered all these, you know, we've got the calculation,
but they're not creative.
We have to tell them what to do.
These systems, they're not self aware.
They don't have subjective experience.
So the existential down the bottom is zero.
They don't ponder, you know, as far as I know,
my laptop's not wondering, you know, why it's here.
Maybe maybe it is.
And just not telling me, but I don't think so.
OK, so, um, so how will we get to AGI then?
Well, it will take a village to create, you know, it takes a village to create a child.
The well known saying in psychology, well, the same thing,
it's going to take a village to create artificial general intelligence.
And in that village will basically comprise of computer scientists,
physicists, neuroscientists, of course, because we are the example and colleges,
sociologists, so general intelligence is general, right?
We're trying to, you know, basically build human level intelligence and then suppress it.
So it's going to take not just computer scientists set in sight of Google anymore,
it's going to take physicists and neuroscientists and psychologists.
No doubt, you know, Microsoft, Google, they have teams like this in place.
OK, so it's a little early.
They don't talk about it.
But yeah, people are working on this stuff right now.
So we'll have a look at some of the efforts and some of the history and some of the future of that,
which is what this talks about.
OK, so physical systems, what have we got?
So we've got biological, you know, I can argue that plants, bacteria, insects, mammals, us,
we're all natures full of, you know, intelligent systems.
How many species are there?
You know, absolutely millions.
And, you know, locus is intelligent.
It's adapted to its environment.
You know, it can overcome and reproduce.
It doesn't really make goals and accomplish them, though.
It doesn't consciously do that with, you know, mammals are the only things that do that.
And so there are various levels of intelligence, too.
So we're trying to build the human level intelligence, the mammalian intelligence.
And, you know, perhaps we'll start off with an ape intelligence and then, you know,
progress to human level and then superhuman.
So that's where we are.
And so what are we physically what we have?
We have CPUs, processors.
We have GPUs, FPGA, ASICs.
And we also those are all digital examples of digital processing systems.
Okay. And those of you who have done a computer science degree or a
electrical engineering degree, you'll be familiar with all of those.
And then we have something called neuromorphic, which is which process is based on biology.
Okay. And those are very interesting.
Those exist today.
And they're quite large as well.
We're up to about a billion neurons, okay, artificial neurons.
And that's like a mouse.
So we could argue we have mouse level intelligence today.
And we'll see a little bit of that later on.
And so that's exciting.
Digital is always going to be an emulation.
Neuromorphic, it's going to be more of a direct simulation.
Okay. So there's the difference between an emulation, which is something that you run on
a digital processor and an emulation, which is an actual physical or simulation,
rather, which is an actual simulation of the actual physical system.
Which is the brain.
So neuromorphic, we can do simulations.
We can run it on real time, just like the brain or artificial neurons,
all the rest are emulations on digital processors,
which actually takes a lot more energy and time.
It's, it's not, you know, we can get there, but it's, it's just,
it's not a direct way of getting there, whereas neuromorphic is.
And then we have quantum.
Is there any quantum processors you've all, we've all heard of quantum computing nowadays
as catching the news.
Is that a part of the journey or not?
We don't know.
Maybe the brain uses quantum physics at the level of microtubules.
Roger Penrose would argue it does.
Who's to argue with him.
He's very clever.
Physicists up there in Oxford.
But, you know, the fact, the fact is, you know, we don't know.
Okay. So we'll look at, we'll look a little bit deeper into all of those.
And then we'll wrap up at the end and I'll tell you where we are today.
So biology is what I mentioned from the lowest little, you know, single celled amoeba to the,
you know, C. elegans, that little worm there with 137 neurons.
We can count them.
We built that system actually.
So we can actually, we built that little guy there.
B, we haven't built.
That's got about a million neurons in that tiny little brain there.
He's got a little nervous system, central nervous system.
And then the human brain.
That's a hundred billion neurons set.
You know, that's clearly a tough one to crack.
That's what we're trying to go.
So a little bit of the big picture, you know, he's a, the brain is a system at what level
do we attack this on?
Do we attack it at the level of atoms or molecules?
Like, you know, Roger Penrose is doing.
That's where the quantum physics is after all.
Or do we start at synapses?
Or do we start, you know, at a collection of neurons and synapses, like a connectome?
Is that a better level to start?
Or do we have to start right down at the molecular level?
So these are very fundamental questions that need to be sort of asked and
experimented with and broke.
This is a science.
So, you know, there's theory, but there's also experiment and test ideas out.
But if we did start at the neuron, this is what we'd have to build.
Now, that's a very complex system, right?
But this is quite wonderful because this is how nature does intelligence.
So who were the guests, right?
We needed such a complex thing to come up with conscious creatures, you know, like ourselves.
I mean, this is very fundamental.
You know, it's a neuron of intelligence, one could argue.
Now, do we have to actually recreate that?
Or can we do it some other way?
Okay, that's, that's a very good question.
Clearly, if we could just reproduce, we would just be recreating nature, right?
So a lot of this is these artificial neurons are not this complex.
The simplified versions.
Can they, you know, can that give rise to consciousness?
Yeah, we don't know yet.
Okay, so clearly it's a tough problem.
So it'd be a tough engineering problem to build something like that.
Okay, so the next level up really is, you know, we have about
two million cortical columns made up of these neurons in the brain.
There's a hundred billion neurons.
So you do the math and you see, you know, there's 10,000
neurons per a cortical column or something like that, maybe 50,000.
So, but there's basically two million.
Maybe these are the fundamental units.
Maybe this is, if we build two million of these,
this is all we'd need to do to build consciousness and human level intelligence.
So, I mean, neuroscience as a science has been around 150 years.
I mean, a lot of progress has been made in understanding the brain, right?
With the hippocampus, all those different parts.
And so, you know, we know a heck of a lot actually about intelligence, biological intelligence.
So, you know, the question we've got to ask ourselves is, you know,
what level do we start at?
What level is needed?
And then how do we build it?
A lot of this comes down to an engineering problem.
So there's a connect time.
There's the next level up.
So we started with neuron.
Next level up, these cortical columns in the slightly high level we mentioned earlier,
the connect time.
And so that's, you know, from one side of the brain to the other, you know, our emotions,
you know, creativity, poetry, painting, you know, sculpture, engineering structures.
You know, is this, you know, is this the level it's kind of happening at, you know,
or does it happen at cortical column or the neuron, you know?
Or can we just start here?
The kind of bigger conceptual.
So these are good questions.
These are all good engineering questions.
And then of course, you know, if we want to embody this stuff,
not just have it running in our laptop or data, we need to, you know,
we'll need a central nervous system basically.
So if we're going to build robots like Atlas, you know, if we're going to have to connect,
you know, CPU, but it also reaches out in a very complex central nervous system as well.
The beautiful thing, nature, you know, we've been, Earth's been here 4.5 billion years,
first life was about a billion years ago, that single cell protozoa, you know,
so we've had about a billion years to develop this, you know, evolution, dead ends, branching,
99% of species are extinct, you know, evolution just tries everything, okay?
The laws of physical try everything.
Intelligent, you know, survivor, the fittest, the things that are well adapted to the environment,
they get to survive.
And, you know, over time, you know, what was it, a million years ago, they're in the endothel,
and then they developed a bigger neocortex, which enabled them to think a bit better than
the next type of ape, and all the rest kind of basically went extinct, right?
So, so we want homo sapiens, and we don't, you know, trying to build ourselves, okay,
replicate nature.
So, and then the last level up is social systems.
So, you know, if you build a, you know, few robots, they got to get on,
you know, we have our social systems, you know, we're a lot more peaceful, maybe than we used to be.
We still have the capacity to go to war, but maybe there's less war.
So, you know, we want to build these higher level structure, hierarchy,
societal structures, okay?
And there's two sides, people say utopia, dystopia, what's it going to be?
Are we going to all get along these super intelligent machines?
Are they going to show us how to live in harmony, and, you know, solve science and cancer and
everything?
Or are they going to be like the Terminator and come and just get right this out?
Because they see us as kind of destructive and kind of stupid in a way, okay?
Good philosophical questions, right?
So, we're not there yet.
So, but one day we will be, and people give kind of serious attention.
So, biological hardware, okay, so there's the CPUs, GPUs, and something called the IP
intelligent processing, you know?
There's a company called Graphcore, based in the UK, it's just got $200 million
or $500 million of funding every day, it seems to go up.
To build this new type of processor, basically it's not really intelligent,
it just does matrix multiplication much farther than the GPU.
So, it's kind of, I probably shouldn't know, it's specialized to do deep learning.
It's very good at artificial, you know, deep learning calculation.
I'm going to argue deep learning won't get us a general intelligent, but they're very
good at classifying and, you know, drawing graphs, that kind of stuff.
They're not intelligent though, they'll never become conscious, but this is just basically
showing you the CPU, GPU, IP, digital processors, and there they are, that's what they look like.
They build them, they ship them, they get paid money for them.
So, maybe some of you didn't know that, you know, where we are with the A6.
It's kind of a very, they're calling it like the Cambrian Explosion in processors.
There's a hundred different companies building these A6 processors, but they're all designed to
optimize the deep learning calculations, okay?
So, we had the CPU there, the Intel, we had the Nvidia GPU, AMD make them too,
but now there's the Google make the GPU, Graphcore make the bottom two A6.
They're really good at deep learning, but they're not going to get us to general intelligence.
Again, they're narrow, what I would call narrow AI, okay?
And, but yeah, there's a lot of money going into building these things right now.
A lot of these startups are raising a lot of money to build these for the deep learning.
So, basically we're solving deep learning, okay, which is not general intelligence,
but we're well on the way to optimizing the hell out of that.
Okay, but it will not get us to general intelligence.
So, that's what a cloud TPU looks like.
So, today we can log into these things.
They're a little bit more expensive than the GPUs, which we can also log into.
So, say I want to do a deep learning calculation.
I go to Google Cloud, you know, I just say, you know, you go to Amazon, Google, Microsoft,
Azure, the three main cloud providers.
Only Google have the TPU.
That's what they look like.
That's a hundred petaflops, okay?
So, that's incredible.
I mean, the biggest supercomputer in the world is about a hundred, is a thousand petaflops.
And they take out more than 10 times as big.
These are very powerful things, but they're very domain specific.
They narrow AI, but they're hugely powerful thing and super impressive.
And if you're, if you're into hardware, these things, you know,
Google hired 10 years ago some guys to the best in the world to build these things for them.
And they kept them secret for a while.
That's how DeepMind won AlphaGo, by the way, they use these.
Okay, so those are TPUs.
Again, this is a larger supercomputer, but it's as dumb as a brick, okay?
It can multiply to very large numbers or factor something very quickly in the, you know,
flash of an eye, but they don't, they have no consciousness,
there's no creativity, there's nothing, okay?
So these things, they, they're good at number crunching, but that's about it.
But they're hugely impressive and they cost a lot of money.
They also use a lot of power.
This thing, the summit supercomputer by IBM.
So it's not just a matter of raw compute, right?
This thing uses 13 million watts of power.
The brain uses 30 watts.
So there's always a factor of a million more efficient, okay?
The brain, and then we do a heck of a lot more biology is very clever, isn't it?
So, you know, what these, that just gives me more and more respect for biology
when I see things like this.
So yeah, there it is.
There is the creation.
1.1 million, or you could say 4.5 billion years of evolution
is optimized to this, to us here today.
You know, Einstein, Picasso, Van Gogh, you know, Leonardo da Vinci,
who's the smartest guy on the planet today?
Maybe Ed Whitton at Princeton, he's a physicist.
We can do a lot, which computers cannot.
So how the heck do we do it, right?
It's 30 watts.
It's, it's just, you know, fits in the skull.
It's, it's 1.5 kilo.
So what's going on?
What are we missing?
Okay, this is where neuromorphic computing comes in.
And there's a project called Spinnaker.
So this guy called Steve Furber up in Manchester,
he helped build the ARM processor, which is a CPU.
And recently sold to SoftBank, I think, for 20 billion.
Now he, after that, 20 years ago, he started to build neuromorphic computing.
And so Spinnaker is his effort.
It's now part of the human brain project.
So these things are, my point is that, you know, these things are real.
You may not have heard of them, but, you know, they've been going 20 years now.
IBM have an effort called True North.
So these things are based on, these processes are based on how the brain works.
Okay.
They're not like the summit, they're not, not a emulation.
They're actually a direct simulation of how the brain, so they're basically building
artificial neurons and silicon.
Okay.
Artificial neurons and silicon.
And we're up to about a billion, which is about a mouse.
Okay.
Today, 20 years ago, we had one right now.
Everything's on a mouse law.
So yeah, we're up to about a billion.
Maybe we need just to scale it another 100 times and have a human brain.
That's quite possible, actually.
It's in the human brain project.
It has a billion euro funding.
So that's, that's, that's moving as fast as it can move.
Okay.
It's a big European project now.
So yeah, and it's available today in the cloud.
IBM have theirs.
Intel also have something called the Ohi, Loohi.
It's a Hawaiian word.
There are many startups as well.
So again, there are, you know, maybe 50 startups, Neuromorphic,
just Google it, Neuromorphic computing.
There are bigger efforts.
Brain Scales is another human brain project.
One study started in Germany.
It's been a Chrissy.
UK one, true North is IBM and Intel have one.
And then there's all the startups as well.
Exciting times.
We live in exciting times.
So, so basically, you know, we have the digital processing,
which I showed you, including the ASICs, TPUs, the Graphcore.
We have Neuromorphic, which is biologically inspired computing.
And we have quantum computing.
Okay.
So, you know, 20 years ago, we just really had the digital today.
We have three different types of computing.
And so things are going to get interesting.
We live in interesting times.
The next 20 years are going to be very interesting
in terms of computation.
Because we now have this Neuromorphic, which is like biology,
and we also have quantum computing.
So things are going to get very, very interesting.
So that's what it looks like.
There's five cabinets.
We're up to 10 now.
And this is how it scales.
You start off with 1000 neurons in the core.
You put 18 cores on a chip.
Then you put 48.
This is all engineering at this point.
It goes to a fab and it gets built.
You have 48 chips on the board, 24 boards in a rack.
And then you put five racks per cabinet and 10 cabinets.
That's the intelligence of a mouse right there.
So that's a billion artificial neurons,
much bigger than a biological neuron.
But again, all of this is on Moore's law.
When they first, we had 1000, remember in 1970, I think,
we had 1024, the first processor that ever built.
And it was the size of a one inch by one inch thousand neurons.
Now we can fit 10 billion neurons on a one inch by one inch.
Okay, it's Moore's law.
So these things are shrinking.
So it's on a trajectory.
So that will scale down nicely in 10, 20 years.
That will be the size of the mouse brain.
Okay, so that's what they look like.
That's on brain scales on the left.
That's a human brain project from Germany.
And then there's Google GTPs on the right.
So analog versus digital.
I'm arguing that we need the newer,
we need the neuromorphic on the left
to get us to general intelligence.
There's the one on the right, we can simulate it,
but it's like a thousand times less efficient.
As impressive as an engineering fee is that it's,
but it's very good at deep learning.
Okay, what about quantum?
Maybe we're making progress there.
We're up to about a hundred qubits, quantum bits.
That's on its own Moore's law.
So within 10 years we're on a thousand,
then we'll start doing interesting calculations
and does the brain use quantum.
Roger Penrose would argue yes.
We don't know if we have to go to that level.
Roger Penrose actually argues that consciousness comes.
It's the only way to get a conscious thing,
is the system is to go down to the quantum level.
Interesting, huh?
Okay, so there we have it.
Those are the four types of compute.
We have digital, we have neuromorphic,
we have quantum and we have biology.
Okay, and that's what they look like at the microscopic level.
So in some sense, their computation,
the physics of computation is called information processing.
Okay, and in some sense, when you get down to it,
the equations are the same for the three classical systems.
For the quantum computing, they're different.
They obey the laws of quantum mechanics.
But theoretically, if you're interested,
you could just Google information processing
and eventually you'd wind up here.
But the trick is to build them, right?
Okay, so that's what the data center of the future
is going to look like.
Right now, that's just almost 99% classical digital computing.
There's a few spinnaker machines.
You can buy that spinnaker processor.
You can actually buy them.
But not many data centers have them.
But the point is you can buy them.
Quantum computing, you can also buy that.
You can log into the cloud today and log into an IBM machine.
They have 20 quantum computers on the cloud, as of today.
And also log into a Regatti machine.
Amazon and Azure, Microsoft and their cloud
are also going to offer quantum computing as a service soon.
You can log into a spinnaker, a human brain project,
but I think you have to be an academic to do that.
It won't be long before they commercialize that, too.
But you can see the road ahead.
I'm arguing that probably neuromorphic is the way
to get us a different intelligence.
Quantum is going to be very useful for
simulating molecules, molecular dynamics, drug discovery.
In classical, it will be good for the internet, our iPhones, etc.
So each type of computing has its own specific use.
I'm going to argue neuromorphic is probably the one for AGI.
Okay, so deep learning.
What about deep learning?
I had the time here.
30 minutes.
Okay, probably be another 15 minutes.
Okay, probably two-thirds through the talk.
So we keep on this call.
Everyone's heard of deep learning.
You know, I make a living out of it.
I've been doing it for six years, seven years now.
That's, you know, it's not going to get us a general intelligence.
So I basically put that in here to point that out.
It's good at classifying images.
It does some sort of language translation and text to speech, etc.
There's neural network, deep learning optimized chip in all phones now,
or you see all laptops.
Okay. Yeah, it's called system on a chip.
You have your CPU, you have your GPU,
but you also have a neural networking deep learning
processor as well these days.
Okay. So the use of some things,
mostly, you know, to do with image recognition,
classification and language.
Okay. So it just swaps over to whatever processor is best for the time.
So if you have an application on your phone that requires deep learning,
it will swap over to the deep learning processor.
And these are known as co-processors.
So the CPU is always the main core processor.
But if it has something that needs to offload
on the GPU or the neural deep learning processor,
it will do it in the back and forth between CPU, GPU.
They call it co-processors.
So, you know, these neural network
pressure on all devices these days.
Okay. Probably in the last five years,
they've started putting them on all devices
because deep learning is a thing now.
There's no neuromorphic processors yet.
Maybe that's to come.
Okay. They're too big, right?
They won't fit in the phone yet.
You have to use them on the cloud.
And so, you know, we've all heard of the different framework,
TensorFlow is the most popular.
PyTorch has become quite popular as well.
The two main deep learning frameworks,
the TensorFlow and PyTorch, which are interesting.
And that's it.
This isn't a talk about deep learning or TensorFlow or PyTorch,
but I just put it in there to see whether, you know,
deep learning is getting all the press.
You know, is it part of the journey? No.
Doesn't give you what a neuron does.
No. It can do, like I say, image classification language,
but it will not do the other types of intelligence.
Remember the creativity, the moving around,
navigation through space, intrapersonal, intrapersonal,
won't give you that at all.
Zilch zero.
Okay. So we're going to need something else.
I've mentioned neuromorphic, but what about the theory?
Okay. So let's have a quick look at that now.
Okay. So general reason of intelligence.
So, you know, what do we need?
What are the different approaches?
I'll cover them.
Okay. There's tangled active inference,
which I'm going to really focus on.
And then what do we need to build an AGI processor?
Okay. So what do we need?
So what we do is we turn to physics, right?
We're a physical system, a human brain, a brain of a fly,
a snake, a monkey, you know, these are all physical systems.
And so what do we need to understand in physics?
There's no easy way out.
There's no magic. We've got to go down.
We've got to do the math, right?
So, you know, are we missing anything in physics?
Well, there's everything we know about the universe right there.
And all of that can be described as a,
there's a very fundamental principle called the principle of least action.
Now, about two or three years ago, there's a book published two years ago.
In fact, they came at university press called the principle of least action.
All the physics can be actually reframed as, you know, this principle,
which basically says now it gets mathematical for the next couple of slides.
Switch off if you want to.
But conceptually, what we do is we write down something called the action,
which we denote as s.
And we write down that equation.
It basically goes back to Hamilton Lagrange about 150 years ago.
And, you know, it's quite common if you're a physicist to formulate
things in terms of Lagrangeans, Hamiltonians.
The action is a function of these Lagrangeans.
And, you know, you do some scary math.
And basically, I can formulate any system in the world,
whether it's a brain or a car going down the road,
a couple of billiard balls on a billiard table,
anything like atomic quantum physics, classical physics,
the universe cosmology.
Turns out there's this very unifying principle called the principle of least action.
Okay. So maybe we could start there.
Okay. So what we have to do, what's different about the brain compared to,
say, you know, a black hole or, you know, a system of galaxies or,
you know, a chemical interaction?
Okay. What's different here?
So we got to understand the system we're trying to model, right?
So we need to, we need to build a system that can model the world.
Hmm. Okay. Just like a mouse makes a little model of the maze,
or we make a model of how we're going to make money or get up and go to work or,
you know, get in the car and go on a holiday.
You know, we're always modeling the world,
crossing the road without getting one over, et cetera, et cetera.
You know, finding a mate, getting married, having kids.
You know, we're modeling all the time.
You know, solving, you know, problem in chemistry.
We're modeling, modeling, modeling.
We're always trying to model the world.
So we need to build a system that can do that using the principle of least action.
That to me is general.
That would be a generally intelligent system.
Okay. So how do we go about doing that?
Just so happens that a lot of very smart people in the world have been
working on this for the last 30 years or so and doing the math.
Okay. They've been writing papers, publishing them,
writing the equations down, building prototype systems.
Okay. But it's got to, these systems have to be able to explain and understand
what they see, play all these board games, go chess, Sudoku,
but also, you know, cross the street without getting run over.
They have to be able to model their world.
Okay. If you build a robot,
no use having it just walk in front of a car, right?
It has to be modeling its environment.
I mean, that Atlas robot doing flips.
I mean, that's mind boggling.
So that's a robot modeling its world that it can do that.
But also has, that's physical and it also has to be smart, right?
That Atlas is dumb as a brick, you can't play chess.
We have to have the whole thing.
Like we have, you know, 1.5 kilos, 30 watts.
We have to make the whole thing,
which is where the neuromorphic process would come in.
So it can plan, problem solve, build new models as they learn more about the world,
update their prior knowledge, you know, just like we do.
Imagining things, having imagination, interpersonal skills.
Okay. So here's some approaches.
I mentioned some very clever people who work on this.
There's a guy called Carl Friston here at the UCL in London.
There's a guy, Tishby in Israel.
Bialek at Princeton Hooter is in Australia at the moment.
He started in Germany, I think.
Schmidt-Huber is in India, in Switzerland.
He's set up a company called Golden Machine with lots of patents.
He's a very smart guy.
So, and there's many more.
So these are very clever people being, you know,
trying to solve intelligence for their life.
I mean, you know, as children, they were going, you know,
how do I solve intelligence?
You know, some of us say, well, you know,
how do I get up at nine and come home at five?
I mean, these guys, you know,
just like Einstein, natural born with this thing, right?
I want to solve intelligence.
So these are the guys.
Okay. So let's focus in on Carl Friston.
So basically he's using the principle of lease action.
It's, I should call it the free energy principle,
but it's the same thing basically.
He uses physics.
Okay. So basically his stance is that systems, you know,
operate in a world to minimize your free energy,
something called the free energy.
And, you know, that will cause them to explore.
You know, you get the explore, exploit, trade off.
They will explore their environment.
How else do we learn?
Remember his little kids, baby, watch the baby.
They just roam around, crawl around exploring your environment,
putting things in their mouth.
Yeah. This is how we learn.
Okay. So the principle of free energy allow, you know,
this is what basically our brains are doing.
They're just minimizing the free energy the whole time.
If there's uncertainty, we want to minimize it, right?
Maybe that's what the best definition of intelligence is.
Minimizing uncertainty as quickly as possible
and effectively as possible.
Okay. How do we, you know, solve chemistry or physics
or figure out the universe?
Well, these are uncertainties.
We're just trying to minimize them as quickly as possible.
And it turns out the brain,
we're not separate from the universe.
Okay. We're a physical system within the universe,
which, you know, our environment.
So, you know, they're interacting the whole time.
So it's just physics.
Okay. Basically, I say just in quotation mark.
So you can write down equations for these interactions
and how our system might minimize this free energy in the areas.
That's Carl Friston.
That's awesome.
I mean,
we could listen to him for two seconds.
Okay.
So I guess technical quite quickly,
a lot to do with probability, Bayesian influence.
He mentioned the word influence.
Yeah. So the brain, it's always, there's always sensory input,
right?
Even when we're sleeping, you know, we have dreams,
there's subconscious, there's conscious.
I mean, you know, there's internal sensory perception.
It is perception from our environment.
You know, there's mental illness, schizophrenia,
where the information processing goes awry.
You know, it's a complex system.
There's 100 billion neurons, all different parts,
layers upon layers, it's true evolution.
The neocortex is what enables us to come up with things
like a theory of relativity and build cars and, you know,
solve physics and chemistry problems and mathematics.
So yeah, it's a complex system,
but it's basically a system that's based on the free energy
principle, which you heard Professor Friston explaining a
little bit there.
That's what it looks like in a diagram.
These other guys like Schmidt-Huber,
they have their own systems,
but I think they will all basically boil down to,
you know, the free energy principle, the equations,
you know, they look kind of similar.
They may use different terminology vocabulary,
but physics is physics, right?
Okay. So they're all trying to model a physical system
called the brain.
Right. So we have external states, internal states,
and there's only a few more slides now.
And something called Markov Blanket,
which kind of delineates the two,
the internal from the external environment,
but there's no real, you know, there's no fixed thing, right?
I mean, things enter and we take action,
enter our brain and we take action, right?
All the time.
We're always interacting with our environment
throughout the pores and our skin.
There is no fixed line,
but it's a theoretical construct to help us do the maths.
Okay. And it's completely general.
It works for cells.
Cells are intelligent.
They reproduce, you know, they survive in their environment,
right up to brains.
Okay. And this is the math, pretty ugly.
Okay. So last few slides.
Can we build general intelligence?
Okay. Very clever math.
These guys might end up getting Nobel prizes and whatnot,
because, you know, one could argue it is maybe the defining
problem about our time, right?
Build intelligence, you know, solve climate change,
solve cancer, build intelligence.
You know, these are the big problems.
If someone solves it and builds the system,
you know, they're going to get a lot of money and a lot of prizes.
So, I mean, a lot of these guys have a super lot of recognition
already if you're in the field.
So, and, you know, it's a combination of,
like I showed before, computer science.
So a lot of them are computer science, physics, and neuroscience.
So a lot of them are neuroscientists,
some are more computer science, but with a little neuroscience.
Some are neuroscientists with a little computer science,
you know, a little physics.
But yeah, the one thing is they're all really, really good at math.
Okay. So can we build?
The answer is yes.
We have candidate theories.
We have some algorithm software, some math.
We have the hardware now, and we have masses of data sets.
So when, right, basically the question is, how about if it's when?
It's going to be like a TensorFlow for general intelligence,
just to kind of touch base with something we're familiar with.
And we're going to need a lot of software engineers
to actually build these systems and hardware engineers, too,
build a new model of processors.
It's a big project.
I mean, the human brain project, you know,
is an Apollo project of our time.
You know, it's going to require funding.
There's a lot of funding going into this stuff at the moment.
And you've got the human brain project, DeepMind.
You've got the US brain project.
China's working on this.
Everyone's working on it.
Should we build AGI?
Again, that comes back to the philosophy, philosophical question.
You know, safety, ethics, singularity.
But that's for another time.
Okay. So here are some AGI projects I mentioned,
from countries all over the world, all very, very viable projects,
in my opinion, all of them.
No clear winner.
No.
All good stuff.
Okay. So in conclusion, it's obvious that
deep learning is lacking the foundations
to build general intelligence.
It's based on statistics, not physics.
It's a statistical hack.
It's very clever.
But it takes a million times as much energy as the brain
to do, you know, about 1% of what the brain does.
So clearly, that's a no.
Research groups are looking into bioplausible models.
That's the way to get there.
That's, you know, in terms of theory and hardware.
So the real question is when, right?
So we've got prototypes now.
Schmidt-Huber, you know, he's building stuff, commercializing it.
Oh, Friston, you know, has a huge code base, you know, hundreds of papers.
So we were on our way.
We're at the beginning of an exponential curve, I'd say, right?
And so, yeah, it's not a win.
It's not a defining moment.
It's a continuum.
We're at the beginning.
We've got a billion neurons, artificial neurons
in a human brain project.
We've got the brain of a mouse.
It can do Sudoku puzzles.
It can solve stuff that humans can solve,
that deep learning would never be able to solve
at 1,000 times less energy.
So we've got the hardware.
That's on its own Moore's Law.
And what else?
So finally, even Jeff Hinton,
he's a godfather of deep learning, right?
Won the Turing Award with Jan Lacoon
and Yoshua Benjo last year for deep learning.
He's saying, assuming, you know,
he knows as much about anybody about deep learning.
He's one of the founders.
Assuming that the computer industry
can keep producing better hardware,
I think business issues are going to take us a long way.
He's talking about the TPUs, the Graph Call, all of that.
Obviously, if we get the big conceptual breakthroughs,
probably from neuroscience, it'll take us further.
I think one of the big breakthroughs that's going to come
is we're going to understand the brain.
I hope, yeah, it's all about understanding
how nature has done it.
And nature is used to laws of physics.
And Culverston's act of inference
formulates that beautifully in some beautiful mathematics.
Okay, so was this your final word?
Can we move on to questions?
Yeah, so any questions?
Yeah, thank you.
Okay, we have a few questions.
It was a really enthusiastic speech of yours.
And so these are the questions.
If we managed to create artificial general intelligence,
what would be the odds of the AGI being sentient?
Yeah, so that will fall out naturally.
So sentience is part of intelligence.
Remember the types of intelligence?
So that's the existential part.
That's what that meant.
So yeah, they have to be sentient.
First of all, we'll build ape-like intelligence.
Apes are sentient, right?
They know what's going on in that level.
Okay, so they will be sentient.
And as we get more and more intelligent,
they'll become more and more sentient.
Yeah, we haven't seen that movie here.
That's a beautiful movie with Joachim Phoenix.
Have you seen it?
The thing on the iPhone gets smarter and smarter,
more and more sentient,
until it goes off into its hyper universe somewhere.
I mean, that's the kind of thing.
It will start kind of like human level,
ape level, then get the human level,
but then go into, you know,
they'll be more sentient than us.
Okay, and together with this question,
if it grasps the concept of the humor,
it controls us by giving us false predictions.
Can you trust it and secure it?
Is that slavery?
Yeah, so that's a good question too.
No, they'll have rights like us, right?
Just like, you know, there's animal rights.
Animal cruelty is a no-no, right?
You go to prison if you harm an animal, right?
It's not right.
So yeah, that comes down to ethics and law.
Yeah, they'll have their own rights.
They will have rights.
You still here?
Okay, and okay, what do you think about artificial intelligence in drug design?
Yeah, so it's going to help a lot.
So right now we took a question,
because we're using deep learning
to help us discover drugs,
to explore the chemically molecular dynamic space
much quicker than we can if, you know, we do it ourselves.
Okay, so deep learning is actually accelerating drug discovery right now.
Okay, the idea is to accelerate it even further
by using an artificially journal intelligence system.
So yes, right now deep learning is absolutely accelerating drug discovery
and has witnessed in the deep mind winning the particular thing competition recently,
which is, you know, molecular dynamics,
which is similar to drug discovery.
Okay, so there's just one comment.
A lot of science fiction's work have gave rise
and inspiration to many great technologies and research.
So they want to know which science fiction
or any other general books have gave you inspiration
and helped you shape yourself towards the professional that you are today.
Yeah, so science fiction is, you know,
when I was younger, I used to always read science fiction and watch Star Trek,
you know, huge science fiction fan, really.
So yeah, I mean, Azimov's Foundation series, Robert Heinlein,
Isaac Azimov, Arthur C. Clarke, those are kind of the...
But yeah, there's new guys around right now
with, you know, different science fiction series.
Always good for the imagination to read science fiction.
Arthur C. Clarke's fact, there's nothing wrong
or a fact that's encouraged, right, to...
Imagination is a great thing.
That's, you know, it's the start of all sciences of imagination.
So yeah, you can encourage it.
Okay, and if we ever reach artificial general intelligence,
do you think laws would be implemented on time
or we would firstly see abuse of artificial general intelligence in daily life?
You partially gave the answer on this.
Yeah, so, you know, there's always going to be good actors and bad actors, right?
So yeah, we're going to have to come up with laws
and try to find ways of enforcing it.
There's going to be some silly things happen, of course,
you know, the site with nuclear energy, right?
Very, all very powerful technologies can get misused by bad actors.
And so yeah, we're going to have to keep an eye out for that.
We have to enforce it, we have to have police at that point, right?
Yeah, of course.
And the last final question as far as I can see,
how, oh, okay, one more.
Okay, how artificial general intelligence could affect religions?
What's that?
Okay, how the artificial general intelligence could affect religions?
Oh yeah, so I did mention that I think
a sentient being will have the capacity for religion
and religious in spirituality and all that good stuff.
You know, so yeah, it just comes along with a legend.
It's a type of intelligence.
Spiritual intelligence is a type of intelligence.
Yeah, of course.
Okay, as far as I can see, that those are all questions,
but we'll wait a few minutes more.
Thank you so much for your answers and for this presentation
and being with us tonight.
It was really enthusiastic and inspiring to watch this
and to understand it a bit more.
So we really thank you.
Thank you so much, me and all the people from Foundation.
And I look forward to watching it.
Yeah, and we hope to collaborate again with you, of course.
So thank you so much.
There are no more questions, so I would call it.
And okay, thank you everyone for watching.
See you on the next webinar.
