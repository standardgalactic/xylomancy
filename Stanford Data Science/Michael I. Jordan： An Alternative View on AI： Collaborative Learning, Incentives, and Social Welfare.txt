So, our closing event is a special lecture given by Mike Jordan, who almost, I think,
does not need an introduction, but I'll still give one.
So, he's a Pei Hong Chen Distinguished Professor at UC Berkeley, and Mike has been a leader
in the computational and mathematical study of learning for a long time, and he's achieved
such prominence that I think in 2016, he's been named one of the most influential computer
scientists on Earth, and so I'm just looking at his computer right now, or the most influential
computer scientist.
He's been recognized for his work by many contributions, many awards as a member of
the National Academy of Science, of the National Academy of Engineering, of the Royal Society.
He was the inaugural winner of the World Laureates Award last year in 2022, and he receives
a John von Neumann Medal from IEEE in 2020.
If I were to list all these awards, I think we would be here for a long, long time.
But I would say that personally, there are three things that amaze me about Mike Jordan.
The first is his range of interest.
They span an enormous array of fields that goes all the way from computer scientists
to statistics, to control theory, signal processing, mathematics, information theory,
cognitive science, and now economics, and maybe we'll hear a bit about this today.
And I think the range and the breadth of his interest is just very unique.
There's another thing that is unique about Mike.
He's his track record of training the next generation of students.
I think he has a very impressive CV, but I think if you look at the CV, the thing that
impresses me the most is the name of his grad students, because your students, and we have
one right behind you, Lee-Wa, we have another one right there, so we have already a lot
of various, they are actually, they make up the who's who in machine learning today.
I mean, so if you open who's who in machine learning and ask the question, is this one
of Mike's students, the likelihood of a yes is very high.
And so, and I think he's done this by fostering an environment of inclusivity and curiosity
that has really moved the entire field.
And so I think the whole field is grateful for this.
The third observation is more personal.
I think Mike's age is public information, at least if Wikipedia is correct, so you've
been at the top of your game for a long, long time, and this is really unique.
And the way I think about Mike in the evening is I think it's a kind of the Roger Federer
of science, someone who has been dominating the circuit for a very, very long time with
no signs of slowing down.
Mike, welcome to Stanford.
All right, thank you, that was perhaps the most fun introduction I've had ever.
When I next time introduce Emmanuel, which will happen, I'm sure I'm gonna have to think
about the right metaphor.
Maybe someone has an idea, help me out there.
I gotta get my mind off that, because it's a fun thing to think about.
So I'm a pleasure to be here.
I am a data scientist, and in fact, this kind of quote that I was like an influential computer
scientist is kind of funny to me, because I'm trained as a control theory statistician
and I was never a computer scientist.
I embrace it because of the entrepreneurial spirit in computer science, and just let's
try everything.
I love that.
And I found less of that in control theory and statistics, so that's great.
But intellectually, I'm a data scientist.
I really want to think about how data and inference can inform real world decision making, and
I think that's where it's at.
I think that it's in the first time in my career that sort of all of campus agrees.
It's sort of a, it's just not the truth, you know, a technologist inside of a computer
scientist or statistician wasn't enough.
This is much more fun.
And indeed, it's economics, which is the most thrilling to me right now, the connections
to economics.
So that's really what I want to mostly convey tonight, is why I think that's thrilling
and important and so on.
All right, the elephant in the room is this thing called AI, and I've never thought of
myself as an AI researcher.
I never aspired to the Frankenstein-like thing of create some, you know, thing, and I kind
of want to say why.
Not only didn't aspire to it, I don't think it's right, but it is what everyone's talking
about.
So I want to say a few things about it.
So first of all, the thing that triggered all of this was back propagation, gradient
descent and layered neural networks.
There's all these other ideas along the way, you know, unsupervised this and that, which
didn't really quite pan out, but back propagation had this huge impact.
Dave Rummelhardt was my advisor at UCSD, and he developed that.
You know, it's just great in a sense, so you can't say he invented it, but he invented
the idea of doing it layered neural networks and applying it to all kinds of problems.
And he took about a year to do that.
It was not trivial for him.
And he was not trying to be an AI person, he was just trying to understand learning.
I think he'd be somewhat shocked that, you know, suddenly that becomes AI to this era.
All right, so what I think is happening really is not that we have a new technology.
We don't have this new brilliant idea of AI, and then we start applying it everywhere.
I don't think that's the right way to think about it.
And so I think you need to go back in history a little bit and think about engineering fields
that have emerged.
So like in the 40s and 50s, the chemical engineering became a thing.
The name was actually used, I kind of looked into it a little bit more, like already by
1890, I think there was a department of chemical engineering at MIT.
But chemical engineering really wasn't, you know, it was very simple chemistry, kind of
done its bigger scale than before.
But you know, polymers and all the kind of things that have triggered the revolution
that we're all living in, that happened in the 40s and 50s.
Before that, there was quantum chemistry, and there was fluid dynamics, and there was
no thermodynamics at all.
So there was a lot of, well, deep understanding of the phenomenon.
And people then were able to start to envisage, what if I take the laboratory test tube experiment
of how you put molecules together, which I do understand because of the quantum chemistry,
and I do that at a huge scale in a field somewhere, will that work?
And of course, it didn't really work.
Often those things would explode, often they just wouldn't deliver a product and so on
so forth.
But over a 20-year period in the 40s and 50s, it kind of started to get worked out.
And an engineering field emerged that had huge impact on all of our lives.
Electrical engineering, I know less about the history, but obviously there was Maxwell's
equations before there was electrical engineering, so it was a full understanding of the phenomenon
at some level.
But it wasn't clear how to bring electricity into homes, how to make it safe, how to do
communication on top of the waves, and so on and so forth.
So a whole field emerged, which we now call electrical engineering, that did all that
in the early part of the past century.
It took a couple of decades again.
So I think that's what's happening right now.
We have a new engineering field emerging, I wouldn't call it AI, but it's a field that's
based on flows of data, networks, flows, inferential ideas, large scale decision making, cooperative
endeavor, building transportation systems, commerce systems, healthcare systems, it's
all part of this engineering field.
That's really what's happening.
And so it's the first engineering field that has got, as its objects of study, not just
bits and information and atoms and laws of physics, it has humans involved, critically.
So utilities and aspirations and so on.
And so economics has minimally got to be involved, but the rest of the social sciences
is as well.
And the implications are vast.
So actually that's the phenomenon, and it's going to take 20 or so years.
The difference though with these others is that there was a deep understanding of some
underlying phenomenon there.
We don't have that now.
We do not understand intelligence, I can assure you.
So we're calling it AI as if we got this understanding and then it leads to technology, and I think
that's kind of backwards.
So let's just say, why did this happen?
Well, first of all, there was McCarthy and so on in the 50s who invented this terminology,
and for good reason.
There was a philosophical aspiration almost.
There had been discussions of mind and body, and now we have a computer that has software
and hardware.
It looks like mind and body, and it looks like we can now make headway on that.
And let's talk about putting thought in a computer.
That's a really interesting thing to talk about.
And of course, people got excited about that notion and worked on it.
We don't have thought in a computer to this day, and it's not clear why we really care
in some sense.
It'll somehow emerge and we'll call it thought, but it's not clear what that means.
And in the meantime, that's not what happened.
What computers started to do was aid humans.
They became complementary.
Search engines and translation systems and all that aided our own intelligence and expanded
it and networks expanded a planetary scale.
So let's not call it McCarthy's version of intelligence for sure, but that aspiration
still exists.
And people who study psychology and neuroscience and core AI, whatever that is, they are working
on that.
It doesn't matter in my view, but it's a worthy thing.
But we should be waiting for that, because in the meantime, all these systems are being
built in the real world that are having this huge impact.
We should understand the phenomenon.
All right, now the other part that happened wasn't really so much McCarthy, but others.
It had to be autonomous.
Why did the AI have to be autonomous?
Well, if it's not autonomous, if it's tethered to me, it doesn't seem so intelligent.
It's tethered to me.
And if it's developed by vast numbers of humans as engineers who built something, it doesn't
seem so intelligent.
So it had to be built by small numbers of people and it had to be all on its own.
Now that's a science fiction-y aspiration, but it's a bad idea for technology.
You don't develop technology that way.
You don't want self-driving cars to be autonomous.
They should be highly networked, so you think about the overall traffic system, so you don't
ever have an accident.
All right, just like air traffic control, you don't want autonomous airplanes.
So there'll be a lot of cartoons in this talk.
I don't mean it's never a good idea.
So burning building, I want an autonomous robot.
Up on Mars, I want some double autonomy.
But for most applications, I don't want the intelligence to be autonomous.
I want it to be federated, linked in, transparent, cooperative, all those things.
So I think this was a big mistake to add that to the list.
I think it became kind of about bragging rights.
Look at my autonomous AI, how great it is, and it's better than your autonomous AI.
And again, this is all kind of fun and games for like 40 years, but it's no longer fun
and games.
It's actually going to hurt the planet.
All right, so here's a counterpoint, which is that, first of all, this is kind of maybe
an obvious statement, but if we want to talk about intelligence, there's not one kind of
intelligence.
It's not just human intelligence.
It's much about the collective as it is about the individual.
And an economist thinks this way all the time.
They recognize that a market is composed of many small decisions by entities that don't
have to be the intelligent themselves.
They just have to kind of know a demand curve and follow some of their nose.
And you're not using huge intelligence within it, but the overall market becomes really
intelligent.
It can do things like bring food into cities, running a shine at any scale for hundreds
of years, and it can create all kinds of opportunities.
And then there's like ant swarms that we talk a lot about.
Not an individual ant might not be so smart, but the swarm could do amazing things.
So we're all aware of that, but too dimly.
I don't think we understand that we could be creating new kinds of collectives that are
really exciting, that do new things as human beings.
That's what's opening up to me in the era.
Not the super intelligence replacing a human, look at how great that is.
So in particular, if you're going to be a little less exuberant, but you're going to
say what are the goals for this emerging engineering field?
It's not make a super intelligence at a computer and you're done.
It's rather what is the overall object like the factory in the field?
Is it a transportation system?
Is it a logistics chain?
Is it a healthcare system?
Is it a communication system designed for that level?
And then think about what the components need to be and what data is needed and all that.
It sounds more boring than a typical AI person's talk, which is we'll solve intelligence and
then the intelligence will solve climate change.
That's a typical Silicon Valley thing to say.
It sounds great and you get rid of it in the New York Times, but really to me, logistics
chains and supply chains are much more exciting and interesting and important for human life
and healthcare.
And it's not that the AI is going to solve healthcare, it's us designing really good
systems with good data science principles and economic principles.
So I think I've said all this, mimicry is just not a good way to think about the implications
of collectives.
Autonomy is also maybe a losery and so there might be new forms of collectives.
So if you want to read a little bit more about this kind of philosophical ruminations, I
wrote an article, our official that the Revlon hasn't happened yet, three years ago and
I still very much stand behind everything in there.
Even though we've had this kind of upswing and surprising chat GBT abilities, this was
like about where's the data come from, what's the provenance, what is the bigger scope and
all that.
And so if you want to read about that, and then there was a bunch of commentary by including
Emmanuel Candace by some luminaries and it was quite a lot of fun and there was my response
to those luminaries.
And then with some colleagues, mostly social scientists all down here, we wrote a paper
about two years ago called How AI Fails Is and it's less about the kind of economics
perspective that I was pushing up above and more about what are the implications for technology
if you've got autonomous systems being designed by small numbers of people.
That kind of incentivizes entities like OpenAI that they get fast amounts of money for a
small number of people, they build this thing and it's not for everybody, it's they control
it.
And it was supposed to be open, it's no longer open.
And so this idea that AI is the future, it just has a natural tendency towards making
it be in the hands of small numbers of people.
And again, I think this article kind of gets into some of the social science reasons why
that's just really a bad idea.
And people pretend that it's not happening, it's all open and all that, but that's a
pretense, it's just not true.
If we stop thinking about AI this way, I think it'll actually liberate us from that.
So again, I've already sort of said this, but just to lean in a little bit more, McCarthy
had this imitative perspective, it was a great aspiration, still remains one, it's just not
what's happened.
What really happened was more like IA, that's Doug Engelbart there who kind of talked about
technology to augment our intelligence and for certain it has.
The search engine has augmented my intelligence more than just about any other piece of technology
that I can think of, in addition to everybody's intelligence, and then this third bullet is
kind of what I think is a better description of what's really emerging.
It looks kind of like Internet of Things, they've got all these little devices around,
they all send data around and decisions are being made, it's all delocalized and everything.
But Internet of Things was a little too computer sciencey, it wasn't thinking about the data
and the inferences and the predictions and the people, it was just about putting things
on the Internet.
But anyway, that is still the right spirit and I think this is really what's happened.
Even like the pandemic response of the planet, that was a engineering system that sort of
didn't worry, it worked okay, but we could do better.
Now, if you go to an ML person or an AI person and say, okay, aren't you guys thinking about
this, is it all this classical AI stuff and they say, no, no, no, we work on all this.
Here's for example, federated learning, it's decentralized learning.
You have a server up there and they're collecting data from a bunch of edge devices and then
they're analyzing the data centrally and we're worried about privacy and all that.
So we got the social stuff, this is our, we handled all the social stuff.
All right, now I'm being a little bit again cartoonish here, but at terminology of federated
learning, a number of groups were working on it, but it's a Google patented, not patented,
but it's a Google terminology because Google wanted to collect a lot of data for their
speech engines, all right?
And so everybody has cell phones and is talking on their phones, let's just collect a lot
of data from that.
Let's worry about the compression, let's get the gradients back cheaply, let's also do
some differential privacy and that's the technical problem if we solve that, wow.
All right, so, but what's missing in this picture, all right?
Well, I'm going to give some examples of what's missing to make it more clear, but what's
missing is that these are actual humans here and they have their own values and goals and
aspirations and they want to join this collective for some reason.
They don't want to just be assumed that they are in the collective because they want Google
to build a bitter speech model.
Okay, so the nodes are often people and they value their data and by data I don't just
mean like where I went today and what was around me and all that, I mean things I created,
works of art, things I wrote, songs I wrote, et cetera, et cetera, that's my data, that's
stuff that's on the internet now that's being exploited by other companies and I've lost
all value, that's wrong.
All right, so we need to talk about cost and benefits of these centralized paradigms where
learning is involved.
So we need learning to wear mechanisms and mechanisms to learn.
Mechanism is a economics terminology and I want to get into that.
So just, I'm going to give some more kind of industrially, real-world examples, but as
an academic, I needed to kind of think a little bit about what is happening academically,
are we kind of a reset up for this emerging discipline, whatever you want to call it.
And I'm not sort of sure we are.
So the three disciplines, and it's not really the disciplines, it's the styles of thinking
that I think are most important here and I don't want to exclude anybody, but computer
science certainly, the algorithms, the networks and so on, statistics and economics.
And just to say there are pair-wise interactions among these fields for quite some time, computer
science meets statistics, that is machine learning.
In fact, I would argue machine learning is just statistics with kind of a computer science
way of thinking.
Every time I see a new idea in machine learning, I know that it already exists in statistics
and I tell people that, they get mad at me, but eventually it kind of, and there's lots
of ideas and statistics they don't yet know about, too.
I could give lots of examples, but I won't.
Statistics meets economics, that's econometrics, and I've got Hito and others in the audience
who are masters of that.
Well it's great, but it's kind of about measuring the economy.
That's what the main goal has been, doing the causal inference to measure the economy.
And it's less about algorithms and mechanisms and engineering kind of thing, artifacts.
So it's had its important role, but it's missing that third leg.
In economics meets computer science, that's called algorithmic game theory.
That emerged 15, 20 years ago.
It's very important to feel.
It's a study of auctions and combinatorial auctions and how they behave and incentives
and all that.
What's missing there is they have no statistics.
They don't worry about gathering data and changing the preferences and learning them
from as part of the auction and all that.
So all three of these pairwise things exist, but they are critically missing the third
leg.
Now the interesting thing is if you go into an industry, and I spend the day a week at
Amazon, and you look at any real world problem they are studying, like how do we provision,
how do we interface with third party sellers, blah blah blah, there's always all three disciplines
around the table.
And just to add, there are always operations research people who already have kind of ingested
all three disciplines, just to say, and control theorists and mathematicians and so on.
So I don't mean to exclude anybody, but it's never one of those perspectives alone.
That kills you if you just have one of those perspectives.
You need all three.
All right, here's a real world example that I've been involved in.
So I'm a musician, I dissed into being an academic, and I met up, I have a friend, Steve
Stout, someone introduced me at some point.
Steve is a legendary producer, entrepreneur, well known in the hip hop and the Latin world
and so on.
And he and I kind of came together on this idea of modern data, modern systems, platforms,
should not just be about taking streaming bits.
Music shouldn't just be about streaming.
It should be about creating two and three way markets.
And so the idea that we originally sat down and talked about, and Steve is the CEO of
now a company that has taken this and made it real, it's called UnitedMasters.com, or
United Masters is the company.
Company provides a three way market.
So if you make music and now you can sign up with UnitedMasters, they give you a record
company in your pocket, you're able to kind of produce songs on your cell phone and upload
them to UnitedMasters and then they connect that to a market on the other side.
So in particular, Steve has gone to the NBA.
The NBA used to be streaming music from the record companies and they would pay the record
companies a royalty and they might give some money back to Beyonce or whatever, but most
musicians are not the big famous ones.
In fact, if you look at the data, if you do some actual data science, today 95% of the
songs being listened to in the United States played by people you've never heard of and
they're probably between 16 and 20 years old and the song was probably recorded in the
last six months.
So everybody thinks we're all listening to the Beatles and Madonna or whatever, it's
just not true.
So you think, wow, there's this wonderful market that's been created because of the ability
to stream music and you'd be wrong because it's not a market.
No one's making money.
All the 16 to 20 year olds are not making any money off of this.
They do it for a few years and then they disappear.
So well, what Steve has done is by creating UnitedMasters is that a musician signs up and
now there's 3 million young musicians signed up on the platform.
And if you now go to the NBA website and you watch a video, there'll be some music
behind it, that music is streamed from UnitedMasters.
And when every time it's streamed, the musician gets paid.
It's an actual two-way market.
And it's in fact a three-way market because it's got the NBA, it's got the listener,
which is you and me, and it's got the person who made the music.
And now all kinds, I could give a longer talk about that, but all kinds of other market
sort of forces are trying to come to play.
People are reaching out to musicians and partnering with them.
Shows are being made.
People are playing at weddings.
There's 3 million people who now have access to a steady income stream.
So this is a sense in which AI can create jobs.
Three million people have access now to a possible job.
And these are 16 to 20 year olds in the inner city, just to say, this is quite important.
And that's just in the US.
This can be done in every country around the world.
And entrepreneurs thinking about a new company, instead of thinking about how do I steal some
bits from somebody and then sell them, should think about how do I create a two-way market.
And I just help the market get going.
You could do this for art.
You could do this for works of, you know, scholarly works.
You could do this for travel information, all kinds of things.
You can start to think more about markets.
Okay, so that was the first half of my talk.
That was kind of why do I work on what I'm working on?
Okay, and so hopefully you get a little bit more of the picture.
It really is, in some sense, economics and mechanisms and networks and all that.
But with all due respect, those fields didn't have enough of a statistics and learning perspective.
They assumed a lot of things were already known and you get certain curves that cross.
But they didn't kind of just adapt the market as you went and use large data sets to inform
it and have recommender systems.
You don't see economics talking about recommender systems.
recommender systems are the way that social knowledge gets used and exploited among groups
of people.
So anyway, when you start thinking about what are the new problems that are going to emerge
if you put these three axes together, it's really quite exciting.
So in machine learning and statistics, we're really good about talking about optima.
We can find optima in hundreds of thousands of dimensions, even if they're saddle points,
and we can guarantee a rate and prove theorems about it.
And we're really good at that.
But in economics, you don't often find optima.
You find equilibria.
And moreover, the equilibria are rarely just stationary.
They're moving around and you need to follow them.
And so you need to talk about the dynamics.
And so now there's topological issues and dynamical systems issues and stochastic process issues
all merged together.
And so there are algorithms.
Gradient descent does not work for finding equilibria, but extra gradient does work and
so on.
There's a whole emerging.
It's fixed point theory.
Most of these ideas go back to the 30s and 40s, but they have been forgotten.
But fixed point theory in hundreds of thousands of dimensions with stochastics, that's something
we can start talking about and do and prove rates and get really new algorithms.
And there are people doing that now.
Exploration, exploitation, incentives in multi-way markets.
Those are words that usually don't come into the market perspective.
How do I exploit?
How do I explore?
And how do I put that together with incentives?
I'm going to talk about some of the rest of these, but let me just sort of highlight.
These are mostly words you will not see on a machine learning person's talk or AI person's
talk.
They will talk about trust maybe or fairness or privacy.
That's all good.
Those are social concepts.
But they don't embed it in a fuller, what are the underlying foundational principles
that make it fair or make it private or make it valuable to people.
They just want to kind of stamp privacy or fairness on it and that's enough.
So let's try to think about what are these underlying concepts.
And let me just say that I've loved learning all this economics.
I had learned a lot of statistics and I've eventually learned some computer science.
And that was fun, but learning economics has been particularly fun.
And it's maybe because I already knew the math and I could just kind of go through the
books really fast.
But this notion of incentives and really thinking about asymmetries and decentralized, I really
get that out of economics in ways I never got from any other field.
So I'm having a lot of fun here and I'm realizing that if I'd gone back to the 1950s and I'd
hung out with David Blackwell and Von Neumann and others that they were doing all this.
This was kind of the spirit of the era.
And operations research emerged in that era, kind of bringing it all together.
And then somehow that all got kind of forgotten.
We got all buried into building certain kind of systems or doing certain kind of data analysis
or measuring certain kind of linear models and we forgot about the overall picture.
So these blue ones are the ones I'm going to kind of use now as vignettes and the rest
of my talk.
And so given this is an evening talk, I don't want to make this a highly technical academic
talk.
There are archive papers on all this with theorems and so on and so forth.
But I do want to give a sense of what's the problem and what is the theorem, and what is
the consequence of that.
So I'm going to give enough of that to highlight some of these issues.
So I picked these three to talk about in some order.
I forget which order.
So here's perhaps my favorite one.
I get to recognize two Stanford people.
Stephen was a student with Emanuel and joined my group two years ago, three maybe, fabulous
intellect.
Michael, I actually don't, we've only, because of the pandemic, met online, but he is a Stanford
person.
And then Jake was a student with me.
He's now a postdoc with one of Emanuel's ex-students, Serena Fogelbarber.
So a lot of nice connectivity there.
Okay.
With all due apology to the economists in the room, I'm going to say a little bit about
incentives.
You know, there's a kind of general theory of incentives.
There's books on it.
And roughly speaking, there's kind of three branches to it.
There's auction theory that you all know about.
There's matching markets, and there's contract theory.
So contract theory is maybe the less well-known outside of economics, but you all know about
it because you experience it daily.
It's where agents provide, possess private information, and there's a principal who wants
to incentivize to do something with that private information.
So why does this happen?
Well, you know, the boss wants to get the employees to do something.
And it's not just because the boss would do it themselves, but you know, they have to
get the employees to do it.
The boss would know how to do it.
The employees have local information.
They're smarter.
They may, if they're incentivized, they'll do even better work and so on.
And now the boss has got to kind of offer them, you know, incentives so that they'll actually
do the labor.
So this came up in economics, sort of after General Equilibrium Theory, which is very
symmetric, you know, Nash Equilibria and everything is very symmetric.
This recognized that real life is full of asymmetries.
There's someone trying to get someone else to do something, and that person has power
because they know something that's not known upstairs.
All right, so you know about it because you've all, like, for example, you travel.
And you probably have wondered, you know, why aren't there, why is there, this is so complicated.
Why is there not one fare for every seat on the airplane?
Right, there is for, like, a movie theater.
All right, and you all know the answer, kind of, right, because there's different willingness
to pay in the population.
So a business class traveler, or a business traveler, not a business, a business traveler,
maybe the company's paying so they could care less what the fare is.
Or maybe they're really urgently needing to get from one place to another.
They have high willingness to pay.
And there's a lot of other people who don't have high willingness to pay.
They could wait until tomorrow, you know, and so on.
So the airlines, really in the 80s, realized that they could start to price discriminate.
They could try to figure out who had higher wills to pay and charge them higher, and who
had lower wills to pay and charge them less, and fill the airplane, and get a blend of
both kinds.
And it's, you've got to be clever to do this, right?
And so what you do, if you set a single price, that's not going to work.
And if you try to screen for people, like, you know, look at somebody wearing a suit
and tie, you say, I'm going to charge you more.
And well, that person's going to the next time show up in jeans, all right?
So people are doing this all the time.
They're aware.
They're gaming the system.
And you've got to think this through, all right?
So you know the answer.
What you do is you provide a menu of options.
You provide a service, and you provide a price, and a service and a price.
And everybody gets the same menu, all right?
Now what is this menu for the airline?
Well, there's this class called business class, and the students don't know about this yet,
but eventually they'll learn about it, where you get a little glass of red wine, and you
get to be first in line and be all proud of yourself, and you get a little bit bigger
chair.
And people will pay $1,000 more for that.
It's amazing, all right?
Now, only class that actually makes money, right?
But the marginal cost of putting people on airplanes is sort of zero, all right?
So you want to fill the rest of the airplane, all right?
So amazingly, there are people in the back who don't want to spend $1,000 for a little
glass of red wine, and they feel very good about themselves, because they didn't spend
all their money, and they're still on the airplane.
So everybody's happy.
That's what's called social welfare.
And the plane is full.
That's what's called revenue, okay?
So you can make mathematics out of all that.
So you get the usual crossing curves and all that.
They're just not the same crossing curves as in general equilibrium theory.
They're a different set of things.
And every one of those texts says we have missing information.
We're going to assume there's some probability distribution, and we're going to call the
whole thing Bayesian.
Now, as a statistician, I look at it and say, wow, Bayesian.
It's not Bayesian.
There's just a distribution on unknown quantities.
That's all.
There's no updating.
There's no learning.
There's none of the above.
Okay?
All right.
So, wow, wonderful opportunity.
We should work on this.
And we have.
Okay.
And so you all know about clinical trials.
Costs tens of millions of dollars a year to run clinical trials in any particular therapeutic
area.
You all know about it for vaccines.
It's amazingly expensive, and it's amazingly important.
And if you don't do it at the right scale, you'll make big mistakes.
You all know this.
All right.
So you would imagine that the FDA does a great job of this, and in some level they do.
They're very good statisticians.
But they're not good at being the economics.
All right.
So this really should be thought as a contract theory problem.
The FDA is a principle, and they're trying to decide what drugs go to market.
But they only have partial knowledge about the drug candidates.
Okay?
Where do the drug candidates come from?
They come from the pharmaceutical companies.
Pharmaceutical companies know something internally about some candidate they're about ready to
send up to the FDA.
Maybe they know they put their best engineers on it.
Maybe they've had experience with it.
Maybe they did a little internal testing, so on and so forth.
All right?
The FDA is now getting all these candidates, and they would like to say, pharmaceutical
company, that candidate you just sent me, how good is that candidate?
Well, the pharmaceutical company does not want to reveal.
Because the FDA, if they're told it's not a good candidate, they'll put yet more, they'll
ensure there's no false positive.
They'll put yet more clinical trial money into it.
Where if they think it's a really good candidate, they won't.
And also the license they will get will be titrated to risk.
All right?
So the companies are incentivized to not say.
All right?
But that's a problem.
All right?
So now let's think about the actual paradigm.
What is the FDA doing?
Well, they're being, you know, statisticians, frequentist statisticians.
So let's, here's a little Naaman Pearson kind of setup.
A bad drug, theta equals zero, doesn't mean that it hurts people, because they definitely
screen for that.
It just means it has no effect.
All right?
So there are tons of drugs on the market that have no effect, for better or for worse.
And they have a type one error of, say, .05.
It's actually more like .01, but they set up a classifier that achieves that.
And then for the good drugs that are actually having an effect, they want a high power.
So you know, .8 is kind of a standard number for that.
Is that a good protocol?
Well it's optimal.
It's the Naaman Pearson test.
So yeah, of course, it's great.
But is it a good protocol?
And the answer is no.
So let's do a little thought experiment here.
In situations where there's a small profit to be made, it costs 20 million dollars to
run the trial.
But if you're approved, let's suppose you would make 200 million.
So this would be for a niche drug of some kind.
And so the CEO can do a little calculation, as can the FDA, conditioning on theta equals
zero.
Now no one knows if theta is zero or not, so this is counterfactual.
But thinking conceptually, theta equals zero, what's my expected profit?
Well, you can put all those numbers together and you get minus 10 million.
So the CEO looks at that number and they say, only send candidates up to the FDA if you're
really pretty sure it's a good drug, that it's going to get passed because it's a good
drug.
Don't hope for a false positive.
We'll go to business.
That's great.
Now the FDA is mostly getting good drugs and they have a good screening procedure, so everything
that's getting through is looking good.
If that were real life, that'd be great, but here's more like real life.
So you have $20 million to run the trial and if you're approved, you could make 2 billion.
So this would be like ibuprofen or something.
So this is more common.
And now the CEO could do the same exact calculation.
If it was the case that theta is equal to zero, my expected profit would be 80 million.
So now the CEO is very incentivized to send as many candidates as they can to the FDA.
And the FDA would get flooded and they do get flooded and they will do these tests and
there will be some false positives and these things will go to market.
They don't hurt anybody, but they just don't have any effect and people will make money
and then eventually that changes.
So this is broken.
And it's just broken because it's not being thought of as a contract theory problem.
All right.
All right.
So we have now lured on this.
We have a paper and we have an idea we call statistical contract theory.
And so here is the protocol.
There are four steps to it.
It's only step three, which is new.
The other three are standard contract theory.
So an agent comes to this contract and they opt in or they just decide to walk away.
So the drug company comes and they just looked at it and say, no, I'm not interested.
Or if they opt in, they have to pay a reservation price R, say 20 million.
And then they get to select a payout function from a menu.
And I'm going to say more about what that means here in a moment.
But it's going to be a function from observe the clinical trial to the amount you get to
licensed for.
And we're going to design the menu.
That's going to be our goal as economical statisticians.
Then we do a statistical trial, which yields a random variable, z, coming from P of theta.
Theta is the true theta in nature, because we're getting data from the real world.
No one knows theta, but we get data from P of theta.
And then there's the payoff.
So agent gets payoff f of z.
They were the ones who selected the payout function.
So they get paid that amount they selected.
And the principal receives a utility, which is a function of f of z, because they have
to pay that, and theta.
Because the FDA, if they make lots of approvals of not so good drugs, they'll eventually look
bad.
And so their utility should reflect that.
Agents in this setting need to maximize their payoff.
Their best response is simply to take the arg max of the expectation under this data
of the payoff.
That's what they want to maximize.
So that's pretty clear what an agent should be doing in this paradigm.
All right.
Now, if you're going to do economics together with statistics, the key thing you have to
think about is incentive alignment.
Am I doing a situation where the incentives or what I want to achieve is aligned with people's
interest?
All right.
So here's a way to set that up.
For the null agents, those who have the null candidates, it should be the case that the
utility of the principal is decreasing in f of z, whereas for the non-null agents for
a good drug, the utility should be increasing in f of z.
So it's kind of obvious.
So in English, the principal wants to attract as transact as much as possible with the good
agents, the ones that have a good drug.
All right.
So now the definition is that a menu of these options is incentive aligned.
If it is the case for all of the null drugs, the expectation under the null of the difference
of the payout and the reservation price is less than or equal to zero.
If that weren't true, then these companies would just make money for free.
So you need to have that be the case, so the principal would be happy with this.
The p less than or equal to .05 protocol that we're used to from statistics is not incentive
aligned.
That's simple to see.
Okay.
All right.
So now we have a theorem, which is right down at the bottom there, which is that it turns
out that a contract is incentive aligned if and only if, this is a characterization,
all of the payoff functions are E values.
What's an E value?
Well, it's like a P value kind of.
It's a statistical measure of evidence.
But whereas a P value is a tail probability under the null, the probability of under the
null hypothesis being more extreme than the observed data, that's a P value.
An E value is under the null hypothesis, the expectation of this E value is less than
or equal to one.
It looks a little bit like a super martingale, and in fact, the more general story is these
are non-negative super martingales.
Because they're martingales, they kind of compose nicely.
You can stop them because of stopping theorems.
They just are a nicer measure of statistical evidence.
Whereas P values don't compose.
You can't stop them.
They just have all these troubles.
So this is a neat result, which is that this concept from theory of contracts is exactly
the same concept as E values in statistics.
And moreover, we have a result, which I don't think I have a slide on it, nope.
That if we now want to do, how do you actually design a menu and get, say, a Maximin menu,
the maximal overall theta of the minimum risk, it turns out to be characterized by taking
all possible E values.
That's your menu.
So for computational reason, you might want to do that, or for interpretability reasons,
but that's another if and only of theorem.
Okay, so I'm going to move on.
We're now rolling this out in various domains of actually designing menus and contracts,
but we have this guide.
We now know how to design the optimal contract.
We know what, we use E values, and we know lots of E values.
There's a lot of literature on non-negative super martingales that are E values and so
on.
So we'll be doing that.
And I'll just say we've done this in particular in the federated learning domain.
This is now just, again, the picture of federated learning, but now with an incentive structure.
So we're able to design an incentive-compatible mechanism that incentivizes agents at the
edge to contribute data.
And in particular, this handles a problem that has been recognized in literature, which
is a free writing problem.
If I have some data to send up, but sitting next to me there is a manual, and he has data
to send, and I know that his data is pretty much the same as mine, I'm going to watch
him send the data, and I know I don't have to, pre-writing.
This paradigm incentivizes against free-writing.
It's a good question.
I was hoping that it was going to come up later, it's all this rational economic stuff.
No, and sort of the behavioral economics here is kind of coming in the fact that we're
gathering data.
All these distributions are informed by data, and if we just write down the utility, that's
only the assumption we have to make, because we agree that you want to maximize that.
And that's usually not so strange.
And then the data informs it, we don't make a distributional assumption about the data.
So I can get into that a little bit longer, but behavioral economics is very much part
of this agenda, but it's not just that it's broken and we think about the psychology of
it.
So we collect data, and data is coming from real people.
So we already have a little bit of a help there.
So hopefully that partially answers your question.
Anyway, if you're interested in this application, we have a paper on that, and we're continuing
on with that.
I got two more vignettes, I think, and I'm just going to go a little more quickly on
these.
I just want to give you a flavor of these.
Classification is the big killer app in machine learning.
Classify, yes or no, good or bad, blah, blah, blah.
But if you do this in domains where there are strategic agents, you get something called
strategic classification.
So this is a work with Tiana Zernich, who's still a student with me and will be joining
Emmanuel's group as a postdoc.
He and I shuttle these superstar people back and forth, and then Eric is now a professor
at Caltech.
All right, so here's a little picture to suggest this, you know, health insurance.
The health insurance company has got to do a classification problem.
I fill out a form, they have to decide whether to give me insurance or not, all right?
They're going to ask me, how much do you exercise?
I'm going to say a lot.
How much do you drink of wine?
Very little, so on and so forth.
Now, if it's implausible, they'll kind of see that, but you make it plausible.
They know that, however, so they're not going to make it so easy for you.
So they're going to ask questions like, would you be willing to have us look at your cell
phone accelerometer for one day?
Just opt in, you know, you don't have to, but are you willing to do that?
You say, sure.
And now if my cell phone moves around a lot during that, it shows I'm very active.
If it sits in one place all day, I'm not so active.
They would use that as data.
So someone went out to build a device, then you put your cell phone on the device and
it moves around all day.
So this is the kind of problem that arises, and economists are very much aware of this.
They call this Good Heart's Law, you know.
If you set up a poverty index score at some year, this was in Columbia in 1994.
It looks very good, very Gaussian and all that.
By 2003, people have discovered that if they move just a little bit left of there, they
get more better housing.
So everyone cheated a little bit so they could move over, and so the poverty index score
has now been ruined.
But this is real life.
This is what people really will do, and they should.
Why not?
It's not an ethical issue.
See, that's the, you know, ethics is sometimes used a little bit too easily here.
So the real problem is that when you do learning, you rarely have just collected data set and
analyze it.
In the real world, you have to say, where's the data come from?
The people supply, if it's people supplying the data, are they aware of what the outcome
is?
Do they have some vets that's interested in it?
Probably they do, because if not, why would they really be engaged in this whole exercise?
All right, so now we have a Stackelberg game.
It's a game theory setting which is sequential.
I send some data up, and the essential decision makers say the bank is trying to decide about
loans, collects a lot of data, they build a model that predicts whether I should get
a loan or not.
And then that starts to make some decisions.
People start to realize what's happening.
Maybe the bank has got to reveal by regulatory reasons I'm using logistic regression or something.
People realize that, and they say, okay, the next time they send the data, they're going
to alter their data.
And that goes back and forth, and you want to ask what equilibria rise here?
We're not trying to optimize any likelihood, it's an equilibrium problem.
Okay, so we have studied this as a Stackelberg game, which is the appropriate concept in
game theory.
Classically, in a Stackelberg game, you have a leader, and you have a follower.
Maybe the decision maker would be thought of as the leader here.
They run the whole show, and agents are the follower.
You can show in that situation in this setup that the leader gets high utility, and the
followers get low utility, just to say.
So it seems reasonable.
But if that's an analysis you could do in a synchronous situation, where there's a model-built
data gathered, model-built data gathered, all synchronized, the real world is no synchronization.
Why should people wait until, you know, there's no synchronization between the central model
and me sending up data?
Okay, so you could start to think about analyzing different scenarios where there's different
kinds of time scales.
So here's one where the modeler goes slowly, only updating every once in a while, and the
street is getting to send data much more rapidly.
So does this arise in real life?
Sure, this is, for example, like college admissions.
The college is gathering all these applicants, and they have all this data, they're not going
to adjust their policy after every applicant.
They'll do it every couple of years or so, and they'll publish it and all, for obvious
social reasons.
So that's a real scenario.
What about the other way around?
Where the central agent updates very, very rapidly, and agents are much more slow?
Well, that happens all the time too.
That's like YouTube.
Every time someone clicks, they update a model in principle.
So these are different scenarios, and so what happens here?
So you can analyze this as now you do the game theory.
So we were able to prove a theorem that shows, first of all, that in either order of play,
you get an equilibrium.
It's not so hard to see that and analyze that.
Much more surprisingly is that in these statistical settings, where it's a data analysis problem,
not just an arbitrary Stackelberg game, it turns out that when the decision-maker is
a follower and the strategic agents are the leader, the flipped-around version, the strategic
agents have higher utility than before.
That makes some sense, but also the decision-maker has higher utility.
It's a rare example in game theory of a win-win.
Going in the order where the strategic agent is a one's going fast, that leads to higher
utility for both parties.
So that's not a true fact about game theory in general, but it's a true fact about statistical
game theory.
These statistical modeling exercises for generalized linear models, just to say.
I'm going to skip this little part here.
I like to show pictures of my students, so there's Lydia and Haria.
And just to say this, I'm going to show you really quick the slides, but it's a cute little
paper where you bring together bandits from machine learning and matching markets from
economics.
And let me just show you a picture.
Here's a learner in a bandit problem.
They're trying to find which of the set of options is the best, gives the highest reward,
and they're algorithms like upper confidence bound that help you guide you towards diminishing
your uncertainty and also picking the optimal arm.
So we asked the question about, what if you put this in a market setting?
So I don't just have one decision-maker, I've got a two-sided market.
And so in particular, I might have two decision-makers who are selecting actions from the other side
of the market.
And there's preferences on both sides.
And so you ask questions like, what if both of the agents select the same action?
And so we model this as congestion, that one of them gets the reward, the other gets no
reward at all.
And who gets the reward?
Well, that depends on the preferences on the right side of the market.
So both sides are learning about each other.
And so again, you can do the mathematics here, and it turns out to be pretty interesting.
What you're really asking is, if there's competition in a bandit situation, does that make the
regret higher or better?
What does competition do for the learning process of a person trying to learn the best
action?
OK.
And long story short, here's a theory.
Here's a regret bound, and so this is more for the experts.
But the regret is, as a function of time, which is n, logarithmic in n.
So that's an optimal result from a classical bandit theory.
So that is still true.
Competition does not hurt your rate of learning.
There is a denominator term, though, which is a constant, which is a gap between the
preferences of nearby agents.
So if there's competition, and you have a small gap between me and somebody else, we
start to compete more, and that gives us a higher regret, but it's only a constant.
So I put that up there just to show you that it's really fun things to do with simple learning
algorithms, explore exploit type, and simple matching market kind of ideas.
And this was motivated by this kind of restaurant setting where 100,000 of us are out looking
for a restaurant in Shanghai, there's 100,000 restaurants, and we're all kind of trying
things out as we go, and getting rewards or not, and on both sides of the market have
some preferences.
And how does that market clear?
That was our question.
All right.
So last two weeks ago, I talked about this in this very room, so I'm going to kind of
go quickly, but this is a very exciting project here that I want to spend five minutes on.
More collection of students, but also, again, Stephen, who's a post-doc, Anastasia, Stephen,
Clara, and Tiana.
So this is really more about the statistics, there's little economics here, but less.
This is more about how do we do things like use neural nets to do science, just roughly
speaking.
So you all know about things like alpha fold, they will make huge numbers of predictions
of, say, these tertiary structure proteins, hundreds of millions of structures, whereas
the hand-labeled ones, there's only hundreds of thousands of such sequences.
So that was a problem that's now being revolutionized in biology.
So here's an example of someone in 2004 wrote a very important paper in Nature studying the
relationship between intrinsic disorder of proteins, where things don't fold, they kind
of are more strand-like, and that turns out to be very important for grid-like things,
and phosphorylation, which is an important part of it, and many pathways.
So they wanted to ask, is there an association between those two notions, what the parts
of the protein are disorder, they tend to be more phosphorylated or not, but they really
couldn't test it, and now you go forward to 2022, instead of this small amount of data
we had back in 2004, now you have vast amounts of alpha fold-labeled data.
It's not really data, it's predictions, but they're good predictions.
So why not throw them in as if they were data?
So someone wrote a paper in 2022 doing that, and so they wanted to quantify this odds ratio,
probability of intrinsically disordered given phosphorylation, and kind of amazingly didn't
even use any of the hand-labeled, the gold standard data, because they had so much of
this other stuff, they just threw it all in, because it's such a good predictor, why not?
But as a statistician, you know better, even if it's very, very accurate at making predictions,
that doesn't mean the inferences you make are any good.
So I think this one picture I'm about to show, so there's the mayor.
This picture is probably the end of my talk, really, and I'll just kind of scroll through
a couple more.
So let me take a moment on this one.
Our statistic here is this odds ratio.
We'd like to know if there's an association or not.
We've all taken elementary statistics.
We have to find whether it's significantly different from one.
One would be no association, bigger is an association.
We did a Monte Carlo version of this where we, in the set of labeled data, we actually
got the true odds ratio, that's the dotted line there, and then we redid the entire experiment
with AlphaFold output using the predictions.
So what are we doing here?
That gold region right there is a confidence interval, and it's based on taking all of
the AlphaFold predictions and treating them as real.
And from those, you form a confidence interval on this odds ratio, and that's an elementary
statistics exercise to do that.
That confidence interval is tiny.
That looks really good, because you have all this data, it's not real data, but it looks
really good.
You're very, very confident.
You're just dead wrong.
All right?
The statisticians in the room will say, why'd you do that?
We know how to do confidence intervals.
Just use the gold standard data.
Don't trust these wild machine learning predictions, and I would do that too.
That's what my first thought would be.
That gives you the gray region, so it covers the truth, as it was asserted to be.
But it also covers one, so it doesn't allow you to include, there's an actual association.
So the new method gets the best of both worlds, this prediction-powered inference.
It forms a confidence interval, which is guaranteed to cover the truth, with 95% probability.
But it's also much smaller than the, it uses the predictions, but it corrects them.
All right?
And I think the most fun thing to show you, I'm going to skip that slide, is just the
examples that we've been applying this to, and we have a paper that does these.
Here's voting.
Here's a ballot, here's a messed up ballot.
So this was a San Francisco election.
People use computer vision to look at all the ballots, and make a prediction, whether
it was yes or no.
All right?
And now you can feed that in, and do a data analysis on that.
And you can see the little gold region there, it's a little small confidence interval, it's
just missing the truth.
And again, I don't know why some things are not coming out here.
Our new interval is the green one, and then there's a missing, a classical one there that's
much lighter, larger, but again, covers the truth.
This is counting spiral galaxies.
You know, there's some hand label, here's the spiral galaxy, here's not.
And again, you can see the small confidence interval if you use the computer vision algorithm,
but it's not covering the truth, and again, we cover the truth.
And I think this was the last one I wanted to show.
Yeah, here's the California census.
The estimate is a logistic regression coefficient of income when predicting whether a person
has private health insurance, and there was a machine learning algorithm run on that,
you can see the tiny little confidence interval.
It's very, very sure, and dead wrong.
I hope this conveys, you all kind of knew this, that very accurate machine learning models
can still lead to completely wrong inferences.
I just don't think my machine learning colleges get that, but it definitely can.
But you can get the best of both worlds, and I think I'm going to skip all the way to this
last slide here and just show you roughly how this happens.
It's kind of like a bias correction procedure, but it's not quite that.
So there is a bias between the predicted parameter using all the predictive data and
the true parameter, theta star.
That bias is a population level quantity.
If you had the whole population, you could just write it down as a number.
There are ways to estimate bias, like the bootstrap, and you could take that estimate
and correct your estimate.
That's done a lot.
We have a different idea, which is that we take that quantity, that bias, or we call
it in general a rectifier, and we don't just estimate it, we'd put a confidence interval
on it.
We get all the possible values of that correction.
Now we take the original predictive quantity, which is wrong, and we correct it with all
the possible corrections.
That leads to that green region there, which is a confidence interval on the corrected
predictions.
And then our theorem at the very bottom of the page shows that we're good statisticians.
The probability that this new confidence interval covers the truth is bigger than or equal to
1 minus alpha, and it's much, much smaller than if you have forgotten all the predictions
altogether.
Okay.
So I put that up there just at the end of an economics talk.
It's more statistics, but I just think many people in the room are already thinking about
this and working on it.
It is one of the critical issues.
If you're going to do science with machine learning, you've got to face this.
You've got to be a good statistician while exploiting the advantage of the machine learning
paradigm.
And I think this is a step towards doing that.
All right.
So that's my last slide.
That's the slide I had up earlier.
I just wanted to kind of remind you of the big picture, the more provocative issues.
This to me has kind of been a no-brainer.
I just, what's happening this era?
Well, it's just statistics and computer science and econ and all, and we're being good engineers.
We're trying to deliver artifacts that will help humans and how to do that well, like
previous generations of engineers.
And this kind of Silicon Valley hype thing of, you know, we've discovered this great
thing called AI, and it suddenly, we've got to worry about all the things that's going
to happen because of that.
It just, to me, wrong.
Thank you.
I hope, I knew.
I shouldn't have picked on you, Art.
You have a better idea?
Well, I have a paper where there's an island of really high-quality gold standard data
and an ocean of data where you're not quite sure of the quality, and then we sort of do
a shrinkage of one onto the other, but we just got point estimates so we didn't get
a confidence interval.
Yeah.
I mean, so this is a little bit like the semi-supervised paradigm.
So we have an ocean of labeled data, sorry, an ocean.
We have a small pool of labeled data and an ocean of unlabeled data.
The machine learning person says, oh, yeah, that's similar to supervised.
No.
We're using the unlabeled data to find a confidence interval to correct the, sorry, we're using
the, got it wrong.
We're using the unlabeled data to find a confidence interval to correct the unlabeled
data and get a confidence interval out of the whole thing.
But yes, I think I was aware of that work of yours, and let me just say this is not,
none of this is ever new.
Statisticians in kind of small data census work did things like this, and semi-parametric
statisticians did some too.
So this is, again, there's always somebody who did it probably in the 1950s in statistics
or art, or Brad Efron or what, it's always, any other, yes, there's two over here.
As you pointed out, there's been a lot of attention around uncertainty quantification
and similar, you know, similar moves in that direction lately in the machine learning space,
which is great.
What does that mean for the future of applied Bayesian statistics and, you know, MCMC, that
sort of thing, given that it's computationally less tractable than a lot of modern machine
learning training techniques?
Is there still a place for it?
Where is that going?
Thanks.
Good.
Thank you for asking.
I tend to be a Bayesian, as with most statisticians, sometimes I'm a Bayesian, sometimes I'm not.
And I'm a Bayesian when I'm working with a scientist over two or three years, because
I'm trying to kind of get out the knowledge that they have and use it, all right?
And that's a prior.
And so why would I not do that if I'm going to work with them a long time?
I'm a frequentist when I'm trying to produce a piece of software that people all over the
world will use, because I'm not going to work with them and get the prior.
I'm just going to put it out there and I want to put a stamp certificate that 99% of the
time they're going to work for whoever uses it.
That's the two perspectives I have.
Now, a little more nuance to that.
Bayesian way to structure models is very nice.
You get hierarchies, you get sharing of shrinkage, social network kind of things, or naturally
Bayesian.
I think that Brad Efron, who has been the luminary in statistics here at Stanford but
worldwide, had it right, which is that you often will go into a problem, you think Bayesian,
you start to structure the model, think about what I could know, what would be together
with what, and then you become frequentist.
You say, I'm going to do empirical Bayes.
I'm not going to just run the Bayesian MCMC paradigm.
I'm going to at some point just say, okay, there's some things I can estimate, I can
plug them in at the Bayesian procedure and I'll get the benefit of both worlds.
Now, that's, I totally agree.
So a lot of the things you saw here have a kind of an empirical Bayes interpretation
and a lot of the, but it's true, the conformal things and the uncertainty of what you're
talking about don't necessarily, maybe Emmanuel could correct me there, but those are kind
of pure hardcore frequentist at some level.
But I tend to, when I would use those in practice, I would probably have not just one conformal
predictor over here, I'd have another one over here and another one over here, I would
want to shrink them towards each other, I'd want to have them related, because in real
domains, if you really start to scale, the Bayesian way of thinking helps you immensely.
So that's funny, you know, Bayesian frequentists do conflict, but it's like wave particle
duality, it's kind of my metaphor, right?
Waves and particles are both correct, and they conflict a little bit, but if you throw
out one and just use the other one, you're going to do bad physics, and same thing with
statistics.
Yeah.
Professor, you were emphasizing the importance of forming collectives in solving the problems.
And I'm very curious to know how you think about how those collectives can actually be
formed to pursue a goal, especially because, I mean, I don't know if a principle or a platform
is required to kind of create the market where agents can actually trust that and cooperate,
or do you actually feel like a decentralized kind of a network is possible?
That's a fantastic question, I'm delighted to have it.
And just for the young people in the room, I hope you see the questions like that are
kind of the thing of the era, and they're hard.
I don't have an answer to your question, it's going to be the short answer.
The colleagues I had on that paper, the social science colleagues, they talk a lot about new
models for democracy, and they emphasize that democracies tend to arise when you have multiple
layers of like, bring 200 people together, get some consensus, take 200 people here,
get some consensus, put the consensus together, and form cities and countries and all that.
That's what humans have done throughout history.
We've had this experiment now that we have this thing called Twitter, and we're assuming
that it's all good that all of us talk all the time, or that we all listen to one person,
and those are terrible ways to do democracy.
So there are experiments that have been underway for quite some time for people like that,
like those famous examples in Taiwan where they have a legislator, which is using lots
of data analysis together with kind of structured assemblies of ways to kind of come to coherent
decisions and to get consensus.
And Ireland has used this, and their latest this, they kind of legalized abortion at some
point, that's very hard to do in Ireland.
They did it partly because of these new assemblies, new structures.
So I love this, you know, people thinking about out of the box of new mechanisms that
bring together visibility of, you know, but it's still among relatively small numbers
of people.
That's really critical, and I think that the technologists who just built the YouTubes
and the, you know, the Facebooks and all that, were trying to do this experiment on human
beings that was just destined to fail.
You know, the big broadcast channels were terrible.
We want communities, and we've got to think about how to structure those.
So I don't know much more to say about that, other than, you know, how do you form collectives
and support them and make them healthy and all that is hugely interesting and important.
And there are social scientists who spend their life doing this.
This is definitely not just a technology issue.
We need to both cooperate and listen and have a dialogue with those kinds of social scientists.
There's many others we should cooperate with, but I think that's a particularly pregnant
one.
Economics certainly talks about collaborative things.
There's cooperative game theory and how do coalitions form.
But it's a little bit dry, and maybe Hido can help me a little bit with, kind of, maybe
there's more to it.
But it's, you know, a little bit about how do I do negotiation and get the most money
out of the deal I can and so on.
Yeah, or align with incentives and so on.
But that just means that we just haven't thought about it enough.
And for the young people in the room, wow, that's a great topic to think about.
How do I start to structure collaborative efforts in data-oriented ways?
Because I think economists didn't have enough kind of, they talk about communication and
signaling.
They didn't really have enough data to kind of really signal interesting things and do
it in adaptive, interesting ways.
So let me just lean in again to this, you know, there's a lot of young people in the
room.
This is the most exciting era to be in.
The previous eras kind of gave us greatie descent and gave us networks and all that
and all these tools.
And now they threw them out there in the world and they kind of work and they kind of don't.
We got better commerce.
We got better transportation.
And we can sort of fix all those.
We can also think a lot more about, wow, new things, good things could happen if we start
to think in the right way.
And what problems are needed to do that?
You can just work on self-driving cars and whatever or make Facebook advertisements better.
Work on problems that you believe in and there are plenty of them, but bring these two fields
together though.
Don't just think of yourself as a system builder.
