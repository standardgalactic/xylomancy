Do you remember the taste of the last orange you ate?
Do you remember the warmth of that welcoming cup of tea that you had when you came in from
the cold November rain?
Do you remember the smell of the hair of the first love that you kissed?
I'd like you to try and hold on to these sensations because I'm going to come back to them.
Welcome back to the Machine Learning Street Talk YouTube channel and podcast with me,
your host Dr Tim Skaaf. If you want to be exposed to completely new ideas and challenged intellectually
then this episode is probably the episode for you. Last time we had a philosopher on the show
we had absolutely atrocious viewing numbers but I'm a big believer that we need to be
challenging our preconceptions on absolutely everything. Pedro Domingo said that there were
only five tribes in artificial intelligence and he didn't even consider the other tribe
which not many people talk about, cybernetics. Cybernetics is the science of communications
and automatic control systems in both machines and living things. We're going to discuss AI
across three key dimensions today. Computability, understanding and the phenomenological experience
or consciousness. When we talk about artificial intelligence what we basically mean is the science
and engineering. We're trying to engineer machines to do things that we might say is clever.
Professor Mark Bishop does not think that computers can be conscious or have phenomenological
states of consciousness unless we're willing to accept panpsychism which is the idea that
mentality is fundamental and ubiquitous in the natural world or put simply that you're
goldfish and everything else for that matter has a mind. Panpsychism postulates that distinctions
between intelligences are largely arbitrary. Mark's argument is distinct from Searle's argument
that computers cannot understand and also from Roger Penrose's view that some tasks which humans
perform are simply non-computable. He thinks that there is no objective fact of the matter
about which computations a physical system is computing. This is because of the observer
relative problem which Mark will outline in great detail in today's episode. Many of the
ideas we're going to discuss today are anathema to the current modus operandi in artificial
intelligence research. Just the reading list we got from Mark today will keep us busy for the next
year. Mark's work in the philosophy of AI led to an influential critique of computational approaches
to artificial intelligence through a thorough examination of John Searle's the Chinese remarkument
and we'll be discussing that in great detail later. Mark is also the scientific advisor to
Fact 360, a startup deploying artificial intelligence using natural language processing
for e-discovery or detecting malicious insiders by subtle changes in language in human communication
networks. Insiders who might pose a threat to your organization and they use sophisticated
graph analysis to do that. Mark just published a paper called artificial intelligence is stupid
and causal reasoning won't fix it. He makes it clear in this paper that in his opinion computers
will never be able to compute everything, understand anything or feel anything. For much of the 20th
century the dominant cognitive paradigm identified the mind with the brain. You, your joys and
your sorrows, your memories and your ambitions, your sense of personal identity and free will are
in fact no more than the behavior of a vast assembly of nerve cells and their associated
molecules. You're nothing but a pack of neurons and that was according to Crick in 1994. The church
Turing hypothesis stated that every function which would naturally be regarded as computable
could be computed by the universal Turing machine. If only computers could adequately
model the brain then the theory goes it ought to be possible to program them to act like minds
with its myriad of features running the gamut from causal learning, reasoning and understanding.
Even Bengio observed in 2019 that we know from prior experience which features are the salient
features and that comes from a deep understanding of the structure of our world. The church Turing
hypothesis has triggered an explosion of interest in biologically plausible neural networks. We had
Dr. Simon Stringer on the show last week talking about the spiking dynamics, the temporal binding
circuits which emerge when you create some of these biologically inspired neural networks but
I'm not just talking about the biologically inspired versions, even the relatively pedestrian
vanilla neural networks that we all know and love on this channel. This has all been a huge
focus point for the last 50 years or so. AI eschatologists like Ray Kurzweil and Nick Bostrom
believe that there might be an intelligence explosion where all of humankind will inevitably
be crushed like ants, although viewers of this channel will well know Francois Chollet's response
to this view. Alan Turing deployed an effective method to play chess in 1948, many decades ago,
but since then we've seen little progress in getting machines to actually genuinely understand,
to seamlessly apply knowledge from one domain into another. Judea Pearl believes that we won't
succeed in realizing strong AI until we can equip systems with a mastery of causation.
He thinks we need to move away from simplistic probabilistic associations to machines which
can reason causally. He even proposed a so-called ladder of causation which is seeing, doing and
imagining, which I feel is almost self-explanatory actually. Unfortunately for Pearl, DeepMind have
already demonstrated several times a reinforcement learning system which can perform causal reasoning
and counterfactual analysis. It seems obvious to me because if you're interacting with a system,
then of course you can learn the causal factors. I'd completely take Pearl's point that with
traditional machine learning where you're not interacting with a system, you can't learn any
causal factors. That seems quite intuitive. Anyway, all of this is small fry compared to the
point which Professor Bishop wants to make. The idea that these silicon ensconced algorithms can
become thinking machines becomes a little bit bizarre once you realize that a machine has no
choice in what it does. Computation is not an objective fact of the world, it's observer relative.
Even Wittgenstein said that the meaning of a computation is in its use. He thought that
understanding could not be a process and therefore it cannot be a process of symbol manipulation.
Whether a given individual understands is often external to that individual. Mark's intuition
is that evolution, autonomy and environmental interactions give rise to phenomenological
consciousness. He thinks that we cannot live inside a computer simulation because he can
feel the sensation of cool air on his face. So Mark thinks that the meaning of computation
becomes relative and lies in its use by humans. Mark gives several examples in the show this
evening demonstrating precisely why he thinks this. So I think Mark's main contribution is this
dancing with Pixie's reductio ad absurdum. He quotes Hillary Putnam. In 1988 the influential
American philosopher Hillary Putnam published a paper in which she showed that under the influence
of gravitational waves and cosmic rays and the subatomic particles that make up all the objects
of our world, your seat, the seat you're sitting on, the very clothes you're wearing, the room that
we're in, they're all containing a rich dance of subatomic particles, a dance that never repeats
itself. And Putnam realized that this is analogous to a state machine going through an infinite series
of non-repeating states. So it then seems to me that if a computer, a terminator perhaps, is conscious
purely as a result of moving through a series of computational state transitions, then if I
know the input to that machine with input fixed, I can generate exactly the same series of state
transitions with any large counter like a car's marlometer or following Hillary Putnam's move
with any open physical system. So if a machine is conscious merely as a result of following some
computation, then consciousness is everywhere in the bricks of this building, the clothes that
you're wearing, the very seat you're sitting on, they are all experiencing the zing of that orange,
the warmth of that cup of tea, and the memory of your first love's kiss. If machine consciousness
is possible, everything, even the smallest grain of sand, is filled with an infinitude of conscious
experiences. Bishop interprets Putnam's result to mean that computationalism demands that every
physical system is host to a multitude of conscious minds, which he refers to as little pixies.
Since a computationalist believes that to be a conscious mind is just to implement the right
kind of computation, not only would we be surrounded by pixies, but the vast majority of
conscious experience would be realized in these pixies. Since any physical system is
implementing any and all computations simultaneously, then all possible conscious minds must be
instantiated simultaneously in every physical object. For Bishop, this is the most patently absurd
manifestation of panpsychism, and thus demonstrates that computationalism must be false.
So it seems like a contrarian position that Bishop is saying that computation is very much in the
eye of the beholder, whereas most of us think that computation goes on inside our brains.
Anyway, the key takeaway from the Dancing with Pixies reductio ad absurdum is that computation
doesn't have those phenomenological conscious states. A finite state automata cannot give rise
to conscious experience, unless conscious experience is in everything. Bishop says that he's an embodied
entity, which is to say he's not just thinking in his brain, he thinks with his body and his body
in the world. In today's episode, we also talk about some of the greats of computability,
mathematics, and logic, starting with Alan Turing on computability. He described a machine
called a discrete state machine. I now call it Turing's discrete state machine because that was
the first time I read about it in his work. So over any short time period, we can replicate the
behavior of the different state transitions of Turing's discrete state machine with any other
one such as a digital automata. But because when we added input, the number of possible state
sequences grew exponentially, we can't easily do the same thing when you have a machine with input.
But then I realized, if I know the input to one of these machines,
that combinatorial state structure collapses again just to a simple list of state transitions.
He invented this interesting thought experiment called the discrete state machine,
and he had this physicalist desire to explain all of humanity via a computer program.
And interesting, what he learned later on in his career about the non-computability of numbers
led to a significant amount of tension for him later on in life and his children.
The American philosopher, John Searle, was so exasperated that anyone might seriously entertain
the idea that computational systems, purely based on the execution of appropriate software,
no matter how complex, might actually understand... it was ridiculous. He formulated the now
infamous Chinese room experiment, and we'll go into this in some detail in the show,
but essentially he said that syntax is not sufficient for semantics, and that programs
are not formal, and minds have content. Therefore, programs are not minds, and computationalism
must be false. Now, most of the Chinese room argument is the first proposition, which is that
syntax is not sufficient for semantics, and we will come back to that later.
Another interesting character is Godel. Godel's first incompleteness theorem famously stated
that any effectively generated theory capable of expressing elementary arithmetic cannot be
both consistent and complete. In particular, for any consistent, effectively generated,
formal theory, F, that proves certain basic arithmetic truths. There is an arithmetic statement
that is true, but not provable, in the theory. And this can be used almost anywhere, and it's
often referred to as the Godel sentence for a particular theory, and it was used in anger
by Roger Penrose. He made the Godelian argument that mathematical insight cannot be computable.
He said that the mental procedures whereby mathematicians arrive at their judgments of
truth are not simply rooted in the procedures of some specific formal system. And he followed up by
saying, human mathematicians are not using a knowably sound argument to ascertain mathematical
truth. Anyway, I really hope you enjoyed the show today. I'm absolutely honored that Mark came on
to discuss this with us. I'm very interested in the philosophy of AI and the philosophy of mind.
Make sure you read some of the material that Mark has signposted, and I'll link those in the
description. Remember to like, comment, and subscribe, and we'll see you back next week.
Mark is interested in the philosophy of mind and artificial intelligence.
Sorry, that's my Siri. It seems to be very interested in getting involved in this conversation.
Mark is interested. Now it's playing music. Because AI is stupid. That's why AI is really,
really stupid. And actually, that's a great segue for our conversation today, because Mark, our guest
today, also thinks that AI is really, really stupid. But anyway, Mark is interested in the
philosophy of mind and artificial intelligence and rails against what he calls computationalism.
We'll get to that in a sec. Machine consciousness and panpsychism. In 2010, Mark was elected to the
chair of artificial intelligence and simulation of behavior, which is the world's oldest AI society.
He's been invited to advise on policy at the UN, the EC, and also the UK government. He's published
three academic books, 200 articles and won £3 million worth of research funding. He serves as
the associate editor of nine international journals and his research has spanned the practice and
theory of artificial intelligence. He's regularly asked to comment on AGI, particularly in response
to these AI eschatologists. Of course, we were speaking about this a few weeks ago. So folks
like Hawkins and Musk and Kurzweil, who warn of an existential threat of an intelligence explosion.
Now, in one of Mark's recent papers, he concluded that cognitivism, which is the whole idea of
viewing the brain as a computer and its concomitant computational theory of mind, is inappropriate.
And instead, we should emphasize the role of foundational processes such as autonomy, exploration,
autopiosis. And that's a strange word as well, isn't it? So that means a system capable of reproducing
and maintaining itself by creating its own parts and eventually further components and social embeddedness
in giving rise to a genuine understanding of our lived world. So in summary, Mark thinks that
computational theories of mind cannot explain human cognition. He thinks that the claims of its
research is that, you know, genuine conscious mental states can emerge purely in virtue of
carrying out a specific series of computations. He thinks that those claims are egregious.
Now, I discovered Mark about a few months ago because he's published this paper called Artificial
Intelligence is stupid and causal reasoning won't fix it. It's actually a really cool paper because
it's a tour de force of all of the computational and philosophical issues surrounding AI at the
moment. And he kind of kicks off in the paper by saying that AI is a brand tag, it's becoming
ubiquitous. But a corollary of this is that there's widespread commercial deployments where AI gets
things wrong, whether it's autonomous vehicle crashes or chatbots being racist or automated
scoring, you know, processes discriminating on gender. And of course, we have a whole load
of people saying that we can improve it. So Judea Pearl and Gary Marcus, they say that deep
learning is just curve fitting. It's just reasoning by association. And, you know, if only we could
build computer systems that took things a step further and thought about time and space and
causality. But Mark takes the AI skepticism to a whole new level because he thinks that machines
cannot and will never understand anything. Professor Mark Bishop, welcome to the show. In
your paper, you talk about Cric and you talk about church and ensuring giving rise to computational
ism. What did those folks say? Well, in my paper, I start off with the idea that it's become known
as Francis Cric's astonishing hypothesis that you and everything that we are is defined by
the set of particular sets of neural firing patterns at any one instance. And if we run
with that idea to its logical conclusion, it would seem to be that if we have an appropriately
high fidelity simulation of just the brain, we abstract from the brain with all the dirty chemicals,
the neurotransmitters, the serotonins and the like, we abstract from all that and just look at
the neural firings, we've got everything, everything else drops out for free. And a lot of people
surprisingly buy into this, to this idea. And in fact, it's one of the, one of the hypotheses
that pushed the human brain projects and one of the biggest European Union funding grants of all
time a few years ago, it was over a billion, if I remember rightly, by only my cram. And that
courted a lot of controversy with some people saying when the EU was putting a lot of its eggs
in one basket. And a lot of people had doubts as to how much real science that program would
deliver. And I think Ham died a very interesting presentation to the group, the human brain project
group, a number of years ago, because I was arguing, as Tim outlined in the introduction, that
we were not likely to get conscious states. In fact, I think there are good a priori arguments
for believing we won't get conscious states are very computational simulation, no matter what
that simulation is, no matter how fast it is, or no matter what algorithm it is, unless we have
to bite the bullet and we accept a very vicious form of panpsychism, the idea that conscious
phenomenal states are living in everything, the very cup of tea of coffee that I'm drinking at
the moment as its own mental states. And the similar likes to pin my colors to the scientific
mask, I find it somewhat implausible to believe that my coffee is conscious of me drinking it.
And so we're led to reject that horn. And if we reject the horn of panpsychism, then unfortunately,
we're led to, in my opinion, we're led to reject the idea that the mere execution of a computer
