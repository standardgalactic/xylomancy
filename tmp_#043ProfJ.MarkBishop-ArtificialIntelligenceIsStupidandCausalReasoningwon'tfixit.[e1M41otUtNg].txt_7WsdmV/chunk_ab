program can bring forth conscious states. So that's kind of in a nutshell, the executive summary,
if you like, of an argument I described as dancing with pixies.
That purports to show that unless we're willing to accept panpsychism, computers will never have
phenomenal states of consciousness. Now that is a distinct argument from the argument that people
like Sirle makes that says computers can't understand. And it's also distinct from people like
Penrose who say there are certain things that people can do. And Penrose very famously talks about
mathematical insight that are fundamentally non computable. So it's my own minor contribution
to the debate. And that is I don't believe that computers can be conscious and less willing to
accept a very nasty form of panpsychism. So I think some of that impulse, right, to
break things down, you know, and to find the absolute minimum component that can implement
everything in humor. I mean, that's a very Western kind of analytic, you know, scientific approach
to start with. And so if we don't want to throw out analytics as a whole, like in what gap or
let's say, what do we need to add to kind of artificial neurons, if you will, in order to
or even to the computational paradigm itself? So what do we need to add to say the Turing
machine or Lambda calculus, you know, concept in order to be able to create consciousness? What's
missing? It's usually complicated stories, as you can imagine. And I'm hoping that at some point
in time, we'll get to go into engage in a little bit more depth on what the dances with pixies
reducture actually says, because otherwise it just sounds like an airy, hands waving
philosophical statement that I'm making. And it might be quite interesting to go into the nuts
and bolts of why I believe that argument works. But to come back to Keith's point,
by many people, I think, working in the field as a young teenager, back in the 70s,
I taught myself to program and had an unhealthy interest in science fiction. And you put those
two things together, and you're led to the belief that I have very strongly as a teenager that we
would build thinking conscious machines, and that one day they would they would come to tyrannize
mankind and then slavers and go on to be the next stage of evolution, if you like. I'm not alone
in that. I'm sure many people have had similar entertains, similar fantasies. And it wasn't
until I went to university that my choice of degree at university was informed by these
interests of mine, peculiar interests of a teenage male. And I went to read cybernetics at
the University of Reading. It was the only place in the UK where you could read cybernetics at the
time. And that was a great education, not least as some of the people my tutor, for example,
Alex Andrews was one of the was an early first round neural net pioneer from the sort of 40s
and 50s and famously gave a couple of great papers at the mechanization of thought conference of
people like Minsky and Rosenblatt were all out. So I was surrounded by old school academics who
were from that first wave of new people working in neural networks. And that was a really interesting
place to work. One of the guys that taught us a subnet is kind of an engineering and it touches
on all sorts of things, but it works sort in the UK is very much an engineering discipline.
And so one of the things we had to do from year one was build computers, but not perhaps as you
might think of building computer, are you going to get on board and putting a few chips in perhaps
but literally starting out with TTL and building your own half out of building your own address
decoders and building literally computer from individual TTL chips. And once you've done that,
you get a very low level but real engineering perspective of what's going on in a computer.
You don't tend to think anything too fancy. The idea that these things are thinking machines
start to become a bit bizarre. Because you realize the machine has no choice in what it does. If I
imagine like a balance a ruler on a pivot that's balanced and press the ruler down one side,
the other side comes up, it can't do anything but that. And when you see that the operation of
the logic gates in the computer work in exactly the same way, that seems to be a very different
mode of operation to that which we're used to entertaining when we think about human cognition.
That said, all those thoughts were further down the intellectual line for me when I was
engaging as an undergraduate. I'm just interested in building these things. And I guess it wasn't
till my third year, I was doing a joint degree in some editing a few of the science. And then
one of my lecturers seemed to be the science was a guy I went on to be professor of theoretical
computing at Oxford, a girl called Richard Byrd. And he introduced me to the notion of
Turing non-computability. And also introduced me to Gerd Lecher Bach, but that's another
terrible, very interesting book, which I'm sure you're all very familiar with. And that was quite
an intellectual shock because prior to doing that course, I'd had this sort of, I was very
modest in man, and I had this idea that you give me a problem at enough time and I'll boss you
out of the computer program, not solve it. And the idea that there could be problems that were
fundamentally non-computable was a shock. And it took a while for that shock to actually see
pain. I was a bit skeptical, even though I knew what to write to get the reasonable mark in the
exam. I can't say my heart was completely wedded to the notion of non-computability. Not least,
because the proofs of these are kind of weird as well when you get into them. There's lots of
self-reference and things, and they seem a bit sort of bizarre. They did to me as a young undergraduate.
But then Roger Penrose, and I came back to read from a PhD at Reading, I was lucky to meet Roger
Penrose. Just around the time he was publishing The Emperor's New Mind, or just before that time.
And we got chatting, and I realized that my intuitions about the horror that non-computability
might pose were being echoed by someone who was even, at that time, known as being a bit of a
polymath, the guy that taught Stephen Hawkins, amongst other things, and worked with him.
And the fact that this guy was also echoing some serious reservations
that were based on good leaner ideas, and based on showing non-computability,
stuck a chord with me. But the real big intellectual shock to my, again, I started out
in a PhD in neural networks with the intention of building a thinking, living, proving,
conscious machine. And then over that period of doing that PhD, my position changed 180 degrees.
So after meeting Penrose, the next big thing was I went to a conference at Oxford in 19,
or when would it be? It was around the time that parallel distributed processing first came out,
and Ruma Hart McClendon came over for the first time in the UK to describe backprop. So this is
how long ago it is. I'm really quite old-skilled in all these things. So yeah, it was the first
presentation about profit at Oxford. It's a massive conference. There was, you know,
it was a set-out conference for the main room, which probably held about 7,800, was sold out.
And they had two overspilled theaters. We were in the second of these overspilled theaters with
video links to the main stage. And we heard these presentations about profit, which is all very
exciting. But the thing that blew my mind, having been brought up in an engineering discipline,
cybernetics, was listening to two philosophers, because that was quite odd. And there are two
philosophers with dinner and soul. And I've never heard a presentation like it, because unlike the
sort of kind of measured, dry presentations of how to control the server mechanism or
a new algorithm for quicksort or whatever the hell it has to be in our computer science and
engineering presentations, I soon learned that philosophers argue in a much more
fisticuff kind of way. And it was a shock, but also very engaging. And so I came across,
you know, Searle describing his Chinese room argument, which resonated with me at the time,
and hearing Dennis poo poo this at the time in his own unique way. And so around that time,
my thesis, I began to entertain, began to question where I was going, am I, and am I team? And are
people other people in the world who are doing exciting things when you all know, are we going
to build these thinking machines? And actually over that time, and in the few years that followed,
I reversed that opinion. And the core intuition that drove all that I guess really was Searle's
Chinese room argument. No, I think you'll find a lot of sympathy. A lot of people that actually
work, you know, very close to the AI, or, you know, what's referred to as AI, when we're trying to
sell things, you know, we'll raise an eyebrow and skepticism, because, you know, we know GPT is just
a big pile of linear algebra. You know, the, the talk about the transformational effects really
come from the business side. You're among good company here. But to kind of go back, you said
you wanted to touch on this dancing with pixies argument that you raised earlier. And this kind
of links into the notions of panpsychism, and how this relates to, you know, if you, if you want
to take the idea that a computer can be intelligent, that it can think that it can understand things,
then you end up concluding that anything can kind of have this. You run us through that,
like very briefly, people haven't read the paper, pants like his argument, the dancing with pixies
fallacy, and kind of like how this all kind of flows into the conclusion that computers cannot
be intelligent. Yeah, one of the actions in which this argument is built is the idea that
computation is not an objective fact of the world. It's observer relative. So I first of all want
to give you a couple of examples that I think will underscore that axiom one, because a lot of
people reject that's a nonsense computation. What a computer does is a fact of the matter.
So again, I'll go back to my undergraduate days when we had to build
before we use TTL, we literally have to build these logical gates out of transistors.
So it doesn't get much more basic than that. So imagine you built some, a set of transistors to
perform the following electronic logic, you have two inputs to the circuit and one output,
call the inputs A and B and the output A. If both inputs A and B are zero volts, the output is zero
volts. If A is five volts and B is zero, the output is zero. If A is zero volts and B is five,
the output is zero. If A and B are five volts, the output is five volts. What logical function,
guys, is that performing?
And?
You might be right. It's performing and if we assume that no volts is false and five volts is true.
Now, if I tell you that you are actually wrong in your assumption that no volts was true
and five volts with false, what logical function is that performing?
Oh, who remembers their bullion? There we go. Oh, that's right. It's performing. You're not.
So in other words, the computational function, this bit of electronics is doing,
is contingent on the observer relative mapping between the electronics and the world, right?
If I use a zero volts, false, five volts true mapping, it doesn't end. If I use the inverse of
that, it's doing an or. You cannot tell a Martian from Planet Mon couldn't look at that and say,
that's an AND gate. That's an OR gate without knowing that mapping. And that mapping is subjective.
I might have one mapping. Alex might have another. Keith might have another one.
In fact, a great Israeli computer scientist, Oran Shigiri, extends this argument pathologically
and looks at multilevel logics. And the problem gets really weird if you go down that route.
But I'll just stick to the simple case with the AND and the OR function.
So that's one of the reasons why I said fundamentally, I mean, it seems to me just
axiomatic. I just baffled when people tell me this is not the case. But I still occasionally
meet people who dispute this. There's a second follow through argument. And it's built on work
of Winograd and Flores in their book, Understanding Computers in Cognition,
when they start to think about what is a word processor. And I've reframed the argument a
little and I think about what is a chess program. I don't know that any of you guys are old enough
to remember in the 70s, we used to have these little chess, plastic chess computers that
were square. They had little holes on a bit of board and little tiny little plastic chess pieces.
When you made your move, you lifted piece up and plonked it where you wanted to go,
and then the computer would light up the piece you had to move and where that was to go.
Using one of these gadgets, I could quite happily play. I'm not very good chess player,
so I could happily get thrashed by these machines day in, day out and enjoy that thrashing, so to
say, to speak. And I could use that piece of computational equipment to play chess with.
Now, in the UK, there's a famous conceptual artist by the name of Tracy Emin, who does a lot of
work with neons. I don't know whether you guys have come across at work at all. And also in the
60s, there was a big movement in what's called kinetic art, where you're in cybernetic art,
where people interacted with art pieces. So now, what can be noticed to me, Tracy's sabotaged my
chess computer. She's ripped the innards out, and she's now wired all the inputs to pressure
pads in an art exhibition, in an art gallery, and all the outputs to neon strips. So when people
walk over these pressure pads, different neon lights come on and off. Now, there was no sense
that you can possibly, it seems to me that you could possibly say that when I walk around the
art gallery, I'm playing chess, I'm interacting with a bizarre piece of abstract art, certainly
not playing chess. So it doesn't seem to me there's anything intrinsically chess-like in this device.
Yes, it was engineered very carefully, so if I knew what I was doing, I could play chess with it.
I could use it in other ways as well. And the problem gets even worse if you've come across
isomorphic games. That's, in my opinion, probably all you know is Noughts and Crosses. Now, imagine
you've got a Noughts and Crosses game on your iPhone, and you've got it like I have a six-year-old
daughter who's just about got her head around Noughts and Crosses. I can keep her occupied for,
I was going to say half an hour, that'd be a exaggeration for five minutes, say,
giving her this thing, and she'll play Noughts and Crosses happily again, and she says,
oh, daddy, I'm bored. What am I going to do? I say, ah, well, I've got another game I can show you.
But she says, daddy, you've only got one game on a computer, so I'm going to play it against the
computer. Do not worry about that. We've got the Noughts and Crosses. I've got another game. I'm
going to call it Computer Wist. Now, imagine you lay the deck of cards out, ace through to nine,
and we take it in turns to pick cards from this deck. The winner is the first person who can get
15, get cards to seven to 15. It transpires that if you've got a program that can play Noughts and
Crosses with a suitable mapping, you can get it to play a perfect game of Computer Wist. So,
given the grid, just like a magic square, where all the verticals, horizontals, and diagonals add
up to 15, you then plot your computer go, marking a one square, and choose your go,
you can tell you which card to pick next, and you can play a perfect game of Computer Wist.
So I can use that same computer program with my mapping to play a perfect game of Computer Wist.
So you cannot say in advance, without knowing what I'm going to do with that program, whether I'm
going to play tic-tac-tac or Computer Wist. So I think those three arguments together make, to me,
a persuasive case to paraphrase Wittgenstein, that the meaning of a computation is in its use by human
computer users. The phrase that, as you want to, you're all aware from Wittgenstein, I'm paraphrasing
it's one of the investigations where it makes the claim that the meaning of a word is its use in
by human players with human language games. And I think the same applies to computation. The meaning
of a computation lies in its use that we as human users of computers put that too. So that's kind of
setting the stage. So I think there's always going to be this mapping at the physical level,
and then there's always the idea of what we're going to use a computation to do,
and that's a very social human activity. So that's setting the stage where I want to go with it,
answering the pixies. Now, the next move I make, I know you'll have all have read
Competing Machinery and Intelligence, Turing's famous 1950 paper. Everyone's at least looked
through this, and, well, Turing first outlined the Turing test, what became known as the Turing
test. Also in that paper, he outlines the operation of a very simple machine, Turing's discrete state
machine, as it became known, and this is a beautifully simple machine. It's a disk-like device,
and it can go around in 120-degree intervals, and it can stop at the 12 o'clock, the 8 p.m.,
and the 4 p.m. position as it moves around a clock, and it can exist in each one of those
discrete positions. And we can describe the operation of that machine as a finite state
automaton. If the machine is in state A, and the next clock tick is going to go to B, if it's at B,
the next clock tick is going to go to C, and if it's at C, it will go back to A again.
Now, if we want to, we can arrange that when the machine is in computational state A, it will
do something. When it's in computational state B, it will do something. Turing envisages it when
it's in computational state A, and light would come on. You also imagine there being simple input
to the machine, like a big lever brake mechanism that you could have on or off. So if the machine
was in state A and the brake was on, it would remain in state A. If the brake's off, it would
go to state B. One of the first interesting things, again, like computation, when you're
given a Turing discrete state machine, to read off the computational state, A, B, C, we need a
mapping between the physical position of the lever machine and the computational state to
which it refers. So we may define computational state A to be the 12 o'clock position, in which
