.
[♪ Music playing, birds chirping, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling, wind howling,
wind howling, howling, wind howling, wind howling, wind howling howling howling, wind howling, wind howling, wind howling, wind howling howling, wind howling, wind howling howlingl, wind howling howling壞 howl, wind howling howling howling, wind howling howling, wind howling howling howling, howling, wind howling howling, wind howling, wind howling howling, wind howling, wind howling howling, wind howling, wind howling howling, wind howlingoke, wind howling, wind howling wind, wind howling howling, wind howling, wind howling howling, wind howling, wind howling, wind howling howling, wind howling howling, wind howling, wind howling, wind howling, wind howling howling, wind howling, wind howling howling, wind howling howling, wind howling, wind howling, wind howling, wind how
journal in October 1950, which started actually the whole artificial intelligence journey.
So it's a good reason to discuss what is done on 70 years of artificial intelligence.
And today with us a few best in the world experts on artificial intelligence and on
information technologies.
So first of all, you will hear from Gurdjil Pao, corporate vice president of Microsoft
Microsoft Research and our long-time partner with whom we did not only one research project
and we are happy that Gurdjil will join us for artificial intelligence journey.
Everybody of you actually who is a little bit older than 35 are familiar with Gurdjil
because if you know Windows NT and if you know VPN, then you know some of his products
which he developed while he is quite a long-stay at Microsoft, almost 30 years.
So some of you are younger than Gurdjil is working for Microsoft.
So Gurdjil is inventor of Windows NT, at least part of Windows NT, Gurdjil is inventor
of one of the first VPNs and stand in the beginning of the Internet Air, Windows Air
and now artificial intelligence air.
So Gurdjil, please, what is allure of thinking machine, please.
Hello everyone, firstly I'd like to start by thanking Albert for inviting me and giving
me the opportunity to talk to you about one of my favorite topics which is really in the
artificial intelligence space.
I'm joining you here from the Turing room which is in the Microsoft research building,
Microsoft campus in Seattle area.
So the topic of thinking machines has been a fascination for a very long time.
I thought I would start with the intelligence in life itself.
Now you know the earth is about 4.6 billion years old.
About 500 million years ago something very interesting happened, at that time all the
life was living inside the oceans.
The oceans had very low oxygen levels but around 500 million years ago there's something
sometimes referred to as the Cambrian explosion or the Cambrian acceleration happened where
life suddenly got more intelligent and scientists are still arguing about what is why that happened.
But the few things that happened at the time which we know is that number one, the oxygen
level in the oceans went up.
It went from about 2 to 3 percent to about 10 percent.
Another thing which happened, scientists believe that the developmental genes developed
through mutations which allowed the regulation of how creatures were able to control their
basic genetic processes.
But the most interesting explanation to me is that it was about 500 million years ago
that the complex eye structure was developed in creatures and that was a very very interesting
development because once the creatures could see they could find food easily, they could
avoid predators and they could actually go after other creatures and that allowed much
more complex organisms to be built.
I think it's good to remember this as we think about artificial intelligence moving forward.
Now after the 500 million years ago, the first documented idea of artificial intelligence
was provided by none other than Homer himself from around 8th century BC, 8th to 12th century
BC is sort of the time when a lot of his writings are attributed.
When he talked about in the Iliad how the lame god Hephaestus actually was talking about
different kinds of robots around him to help him in his life.
One were these tripods with wheels, then there were these robots to shape like the female
form who were helping him with lots of things that Homer, what Hephaestus was trying to accomplish.
After Homer's writing, the next significant piece of thought in the area of artificial
intelligence is attributed to Ramon Lul who was a philosopher and a thinker Catalan region
of Spain.
Ramon Lul actually came up with the idea, in fact he had invented a kind of a seven
disc rotating system where each seven discs had different kinds of concepts and he basically
said that if you rotate the different combinations of these discs, you can pretty much contain
all the ideas and concepts around that humans exhibit.
And it was a very, very interesting idea that inspired just a lot of thinking actually centuries
later.
You know it was you know William Gottfried Wilhelm Leibniz in the 17th century who then
took that idea to create perhaps even a more developed system in which he created sort
of this alphabet of thought and he wanted to sort of create this computation of ideas
and he sort of furthered that cause.
You know after that of course why we are gathered here today, you know this Alan Turing sort
of seminal paper on can machines think.
You know in that paper Alan Turing did a couple of things.
I think number one really created, really formulated this how to even think about this
idea of artificial intelligence by having this so-called Turing test.
But also you know I thought the work, his taking the different arguments and really
sort of you know playing them out I thought that was incredible work and it was also very
telling towards the end of that paper when he talks about things like telepathy and so
on which sort of you know he kind of created this sort of very open-ended aspect to artificial
intelligence which I think is something that we should all keep in mind as we move forward.
The last 70 years have been quite interesting in the artificial intelligence journey.
You know of course it started off with a lot of the rules-based thinking, a lot of the
symbolic systems that people worked with, expert systems and you know while that gave
some pretty early sort of off the races we found that that sort of thinking you know
ran out of steam and we ended up with this AI winter until some of the data-driven approaches
started to show promise.
But it was only in the last decade that we saw the neural nets make comeback thanks to
you know a lot more computing power and a lot more digitized data being available and
we're starting to see some really really incredible progress in the last 10 years.
Now if you take a step back from this journey in the last 70 years you will find there is
about three different schools of thought which represent these cognitive metaphors.
You know you have the connectionists who are really trying to model you know intelligence
in the sort of this graph form you know with these units which are connected to other units
and it's through this composite analysis you're able to find you're able to sort of emulate
intelligence.
Then you have the symbolists who were I would say have tried to you know sort of latch onto
the idea that humans think in certain concepts and humans think in certain building blocks
of knowledge and the best thing for us to do is to really emulate that inside a computing
system and you can build you know the different layers of intelligence just based on that
particular idea and then there are the probably the lesser known dynamicists you know who
believe that these dynamical systems can be best modeled with things like differential
equations and so on and what we've seen in the last 70 years is you know these different
cognitive metaphors sort of you know taking the lead pushing forward until they hit some
walls and then you know we take we stall for a while and we go pick up the other idea and
we run with it but generally you know you can classify all the work so far in these three
sort of buckets.
Now let's talk about the connectionists who are really having their day in the sun as
it were with the resurgence of neural networks and with deep learning.
Now the core construct there is really the construct of the neuron which as you see you
know there is a biological neuron inside the human brain so it said well you know how about
we create an artificial neuron which actually is very simple when it comes to sort of the
mathematical operation that it does and you know with the activation of that particular
neuron recognizing that it has already been proven that the biological neuron is much
more superior than the artificial neuron that we envision today.
One simple example of that is that a single biological neuron has been shown to exhibit
nonlinear capability for example if you have to take the XOR function and you have to do
it and with artificial neurons you will need at least two layers but it can actually be
done in one biological neuron.
Now taking this basic idea of an artificial neuron of course we create neural networks.
In the same way that our biological networks in the human brain we create artificial neuron
and neural networks and it is again through similar kind of a connectivity of these different
neurons through which in biology is with synapse here it is connections between the
layers of the neurons and you know in the last ten years or so some of this is little
predates that we've seen just tremendous amount of deep learning architectures for specialized
tasks starting to emerge and some of these are actually inspired by biology.
In fact if you look at a lot of the work in computer vision not only it was inspired
by biology it is now explaining human biology when it comes to computer vision and some
of the processes that we see in the visual cortex.
Similarly some of the work with memory based architectures whether it be LSTM etc. are
starting to really you know get very very specialized you know really taking some inspiration
from biology.
Thanks to the progress in deep learning we have seen some amazing breakthroughs in the
last five years.
Now all the breakthroughs that I show to you on the slide here all happened in Microsoft
research everything from the ability to have speech recognition at a level that is better
than humans the ability to detect objects better than humans machine reading and comprehension
where the AI model reads a corpus of text and is able to answer questions based on that
captioning of video things all these have happened just actually in the last four to
five years and these milestones in Microsoft research of course tremendous amount of progress
has been made globally in the industry not just in Microsoft research but there's just
a glimpse to show you how much progress we have made.
Now none of these tests actually would qualify as a Turing test by definition because the
Turing test basically you know said you could ask a question you could ask the entity something
that you know could be outside of the domain that these models are perfected for but regardless
you know they represent significant progress but also the significant limitations of the
progress that has been made.
So before we talk about you know some of the you know the limitations I want to talk about
the GPT-3 model which I'm sure that you have heard about this is the work that has been
done by OpenAI this year you know they announced GPT-3 which can be called the grand master
of language models it is a generative model using some of the transformer architectures
that have been perfected it is incredible the kind of results that we are able to see
with GPT-3 you know you could say their language results but actually many of them are fact
based results as well because this thing was trained on about 5 billion tokens of data
and it has 175 billion parameters which is you know absolutely incredible and you could
say that you know sort of underlines the fact that the deep learning based approaches really
became possible because we had this incredible amount of compute that we could bring to bear
and also incredible amounts of digitized data.
This GPT-3 has in addition to you know of course you know being able to write different
kinds of long form text it is being used for many many many applications largely in the
language domain for example you know there are already applications for writing a python
code there are applications for automatically generating emails there are applications where
you know there are plugins where you can automatically fill out Excel data etc. which
have all been written on top of the GPT-3 model which has been very very very impressive
I think if you have to look at the progress of AI today you have to use this as where
we are 70 years after Alan Turing's paper and said this marks probably the most significant
progress.
You know we are very happy to be working with OpenAI at Microsoft we have a deep strategic
partnership with them and a lot of this work happened on the Azure platform itself.
So okay great progress but but we also have lots of lots of limitations I'll talk about
some of them which have listed here well number one you know the amount of data required to
train these models is just I mean it's just really really too much for us to get this
level of performance and we know that you know humans are able to do very well without
using that much data.
The models themselves are opaque you know all the learning itself itself is sort of encoded
in in these in these multi-dimensional vectors you know which is which no one can make sense
of we have this problem which humans don't have which is that these models are used for
training offline and then you know they're used for inference when they are being used
but there isn't this notion of continuous learning in most cases you know there is no
semantic understanding I'm going to talk about some examples on that the power required to
train these models is is incredible you know estimations on GPT-3 which I have read on
the on the on the web you know take us into megawatts of power for training these these
models while the human brain you know seems to do fine with about 20 watts of power that
it sort of runs in so there are many many different limitations you know all these models
are trained for fairly narrow set of tasks though with GPT-3 we're starting to see that
change you know these are multitask models can be built on top of the single representation
that is learned which is which is quite impressive so you can see you know we've made a lot of
progress in the 70 years but there is so many other hard things that we need to solve for
including causal reasoning. So I thought you know how powerful the GPT-3 model is but it
is also has lots of limitations which kind of highlights the point I was making about the
kind of limitations that exist today even with the best models if you ask GPT-3 which is heavier
a toaster or a pencil it says a pencil is heavier than a toaster and you ask it like when counting
what number comes before 10,000 it says 9,099 comes before 10,000 and he asked like who is a
president of the United States in 1700 it says William Penn was the president of the United
States in 1700 okay let's examine these three questions well the first reason the first answer
that got wrong about pencil being heavier was because in all the five billion tokens of text
that were there nowhere it had actually had a direct reference to the weight of a pencil
and a toaster so it got it wrong when it comes to counting it actually does not have an underlying
idea of mathematics which is a very important point that's the semantic understanding part
it it therefore it basically tries to find a close answer and gives it it turns out to be wrong
in the third case you know this was a bit of a trick question because United States did not
exist in 1700 but it made up an answer because it you know it thought you know I'm going to take
some famous people from the 1700 Peter time in this area and they basically came up with an answer
basically telling you that while we have made a lot of progress on some very fundamental things
that you could probably see if you ask a maybe a nine-year-old kid and ask the answer to these
questions they will probably get these answers right which this amazing model could not get right
now Marvin Minsky who you know can be called one of the elders of artificial intelligence
in 1970 you know said that in three to eight years we will have a machine with the general
intelligence of an average human being you know this was 50 years ago so you know predicting
when we will have the average the intelligence of average human being
is is a very very difficult task if Marvin Minsky got it wrong you know many of us will probably
get it wrong if we try to predict it so it was very interesting for me to read another prediction
by the Turing Award winner this year Jeffrey Hinton who's considered as one of the three
I would say the fathers of of deep learning movement you know who made a statement deep
learning will be able to do everything which made me you know think you know like could this be true
and I came to the conclusion that it is it is he's probably right and for one very very fundamental
reason is that deep learning has given us a an approach which allows us to to do function
approximation better than we have ever been able to do now the place where I feel you know his
statement is is ambiguous and maybe it was intentionally so is that I believe that some
of the the approaches that are going to be needed to get to artificial general intelligence are going
to be a lot more coming from the from the the symbolists and the dynamicists world as well
even though some of their ideas may be solved best with some of the deep learning approaches
that are there so you know that's kind of where I see things going I feel that if you look at
you know where do we need to make tremendous amounts of progress if we are going to you know get to
the sort of the human level of intelligence number one I think model based notions of
space time and physics I mean this can also be called common sense you know a little child
doesn't need to learn that you know if you throw an object they've never seen before up in this
in the you know up in the air what's going to happen to that object and you know they certainly
have notions of time they have notions of space these are fundamental ideas that somehow needs
to be encoded into all the approaches for AI that we have I think knowledge representation
we are starting to make really good progress you know certainly on the language side but I
think this needs to expand into numbers into graphs into you know pretty much how humans
you know have this notion of knowledge that we sort of we acquire and we we organize I think
reinforcement learning I think is a very very important maybe coming more from the dynamicists
sort of side I think it's a very very important discipline largely because if you look at how
how children humans learn a lot of those approaches can be considered as reinforcement
learning though I would say it is also you know online reinforcement learning it's probably
better be to say it I think causal inference work is critical you know today artificial
intelligence work is completely devoid of causal inference at least as we know today
the work that Julia Perlman but Julia Perl has been driving has been you know I think
really amazing it'll be great to see a lot more people focused on that and then lastly I put in
sparse learning because I think that you know this power hungry approach to building these really
really deep and high parameterized models is is not sustainable from an energy perspective
you know so we I think sparse learning is pretty much you know how human
brains also actually operate I think is something that needs a lot more attention we started to see
some some really interesting work here but lastly I would say I think if we are going to make
progress and towards a truly thinking machine it will require the connectionist symbol the
symbolists and the dynamicists to all come together and perhaps using some of the constructs
we've got from deep learning to solve the problems you know for example if you look at
the symbolists you know they they're their entire thinking is based on the idea of
symbols that are really used to construct you know all the different layers above it
but symbols you know don't necessarily have to be symbols that humans also recognize
and I think this is a very important insight in fact you could argue that some of the breakthroughs
in GPT-3 which came through the representation in the latent latent space with with vectors
you could say they are symbols it's just that videos don't recognize them
similarly you know deep reinforcement learning you know neural ODE work this is how you know
we are seeing how deep learning is even helping the classical disciplines like you know how do
you solve differential equations or build models based on differential equations except using the
neural approaches so I think this is where we are I think these three disciplines work together
we will have a truly thinking machine hopefully in our lifetimes thank you very much
so we keep our discussion panel during 70 years of publishing mind article
right now besides Gurdipal who is temporarily out of connection I would like to introduce our
other guests who are joining our panel our first guest is Mr. Dr. Leonid Zhukov who is
the head of artificial intelligence laboratory in Sber and well our closest collaborator on many
fields of artificial intelligence which is running here and you can learn about activities of his
laboratory I think everywhere at this conference Dr. Leonid Zhukov joined Sberbank quite recently
from high school of economics where he was one of the head of faculties for computer science
and artificial intelligence so we are very happy to welcome Leonid in Sber and research
and development block for Sber also today you're already here Michael Woodridge professor from
Oxford University computer science department head of computer science department and Michael is
author of a wonderful book best book of the year by financial times and I'm very proud that I read
it from cover to the end of the book and please buy this book at Amazon or maybe it's Sbershop
because it's really worth reading and it's not a chance that it's a really best book of the year
so but before discussing with Gurdip with Michael with Leonid during 70 can machine sink
I thought that I need to give a context of our discussion because this is really important
probably I forgot to introduce myself for those who are not really familiar with me but
maybe some of you at least my students are might be familiar with you my name is Arbuty
Himov I'm working in Sber more than three years and now I'm heading R&D
block for whole Sber with vice president title I wear many hats in my career and I would say
I'm just amateur scientist and R&D manager here in Sber and trying to be very useful for everybody
so back to our topic computing machinery and intelligence was published first time 70 years
ago it's quite a long time many people might remember epocha where we have no computers at least
my scientific advisor for my phd was born long ago before Turing published his thesis but it's
very important to look at the past because we recall the past it serves the present today it
give us fresh insights on what we sometimes overlooked and cause our attention to ideas
that might be missed in for some reasons it might give us new perspectives and that's why
we are looking for new ideas 70 years past since Turing published this article in October 1950
so it really was discussing but first of all let me remind you who was Alan Turing he was
scientific prodigy some of his friends in childhood called him scientific Shelley at the age of 14
at the age of 14 he ride by 120 kilometers to his new school and next year he actually
published a small article dedicated to Einstein's theory of relativity at the picture here the drawing
here you see you see drawing by Turing's mother Sarah and it's Alan playing game but he actually
gave up game and just looking at how daisies grow and this is all Alan Turing he always did
something contradictory to others later on in his life he was famous for very ugly trousers
it was not the fashion at the time in England it was always trousers should be always very very
well ironed and Alan was always with wrong trousers so everybody actually paying attention
to it but he was still very much scientific prodigy and very early he was elected as a
fellow in King's College Cambridge and published a paper on computable numbers with application to
engineering problem which is problem of computability which got attention of Alan the church and he's
got his phd visit to united states to work for his phd with Alan the church he finished it
he turns back to Cambridge and actually come to Ludwig Wittgenstein to have some discussion
on intelligence and the foundation of mass with him and as soon as world war two broke
he joined government court and the cypher school as one of the leading coders court breakers there
foundation of peace which we are enjoying right now was actually late at the time it was 1940
when he traveled in France during the war to meet this Polish crypto team and then he established
so-called hot a team which helped actually not to win the war but to save enormous amount of
lives for the fight of England and North Atlantic in 1941 he breaks he got transmissions and
Bletchley Park where he Alan was working was reading all the messages asked instantly as
German were typing them in 1942 he created first automated machine to read German messages and
it helped to defeat Germans in North Africa also at the time he visit us again and meet
Claude Shannon in Bell Labs in 1943 he walks on the first in the world speech encryption system in
Bell Labs and then returns to United Kingdom where he builds world's first electronic computer
colossus on the premises of Bletchley Park I advise everybody of you to visit Bletchley Park which is
now in museum it's a very very was was visit 1945 he completes this speech encryption system
but there is no use for it because he celebrates V-day in 1945 with quite work with his friends
that's it and then he immediately travels to Germany to study the cryptology as well as to
deliver a lecture this picture shows you how it looks Bletchley Park at that time it was actually
the head of Alan Turing and after the war it was mentioned that he was one of the founders of
racial club which was founded in 1948 and it was very much multidisciplinary and it was very much
dedicated to new ideas so it says you see that no professors only young people were allowed
and Alan Turing was a kind of celebrity there so a lot of new ideas were proposed during racial
club his days and he actually many many later ideas he developed there
so in 1946 he started develop first electronic calculators in NPL Lab which is in London
and also start running marathon 30 kilometers and 1947 he visit US again meet with
some US scientists including von Neyman and his meeting for this von Neyman was actually
laying foundation for the future study of von Neyman himself and von Neyman architecture
then after his I would say not successful presentation to NPL national physical lab he
decided to move for Cambridge for sabbatical one of his bosses at NPL said on Turing report on
artificial intelligence first during report that it's a school boy said and not suitable for
publication that's where well-known fact in Turing historians and that's actually it should be
very much encouraging for all young scientists please keep working and don't be upset if old
guys like me and somebody else criticizing your ideas which you are presenting to them on internal
workshops so please please be be ready for critics and don't afraid of it and in 1950 he
writes the world first programming manual and then complete publishing computing machinery
and intelligence in mind journal mind journal is philosophical journal and that's why Alan Turing's
become father of rye at that year he also bought a house in Manchester to be happy there
now I come to foundation of life and eternity in 1951-52 he gives a few talks to bbc on artificial
intelligence with some predictions and then he switches to actually biology and I think he also
published the first paper dedicated to bioinformatics so he might be also as well as
father of bioinformatics many many modern historians believe that due to accident not
suicide but accident he died at June 7 1954 just a little bit not leaving to his 42 birthday so
he left no death note and many people believe that it was just tragic tragic
accident so I strongly recommend you to if you are willing to know more about Alan Turing
read this book written to one of my good friends Humashan and Kevin Barwick as well as of course
Mike Woolridge book and some some other books which are available
widely so I have some some further ideas but first let me let me tell you two major
things two major ideas which gave us Alan Turing first is universal Turing machine
and second is Turing test which laid out a foundation for computer functionalism what is
computer functionalism very simple idea Descartes believed that 500 years ago that humans are
machines might be machines animals are machines but Turing and later philosophers who created
computer functionalism believed that humans are machines with software brains are hardware and
software is running on them is what actually makes us humans and he created Turing test
which probably many of you had of but universal Turing machine as well as very important one
his achievement because every every machine sooner later become Turing machine it means we have
emulation of everything possible with that simple Turing machine which is actually going back and
forth on the paper and print erase and print again that's it very simple algorithm very simple
machine but it can emulate everything so what we do what Gurdip is doing what Leonid is doing
right now is just make Turing machines a little bit faster and that's it we are not doing anything
so going going going back to Turing test is enormously popular it's millions of mentions on
Google it's a foundation of imitation game where we can think on can machine think comes from this
but we discussed it might be in more detail and I don't want to spend much time on
some of my slides and I go to I go to questions for our discussion which are
very important and I see that my friend Gary Buratsky also joined us so we welcomed Gary to
our discussion Gary Buratsky is a well I started with from past so he is one of the leading members
of the team which won DARPA Grand Challenge in 2005 and then sold this team to Google he later
sold another startup to Google and Gary we are happy to it and Gary is famous for being founder
of OpenCV and Gary has got enormous amount of fans here in Moscow in Russia and actually every
young man and girl who are working on computer vision start with OpenCV which was developed by
Gary team already many years 20 years ago I think something so and also Gary has got many
interesting ideas on what is what are computers right now what is computer science and what is
artificial intelligence so all together we have four great experts one of the world greatest
experts and you see I'm like I don't understand what happened to me why I'm so lucky and happy
to have you here at my panel and I put in front of you actually six questions you might you might
see right now and three of them but two questions actually most important for me right now
first question is what was wrong for the last 70 years in search of artificial intelligence
and thinking machine would be chewing surprised if you come to date our conference and see what is
going on and what his surprise the most and second important questions what should we do
to make our research our policy right for the next 70 years of research Jürgen Schmeckhooper today
was laying out picture of billions of years well that's impressive but let's not go that far 70 years
is just enough for any predictions what we should do right for next 70 years and what mistakes we
should certainly avoid so I will start with Leonid and I would like Leonid to give you
maybe five minutes to express briefly but very clearly your ideas on those two issues what was
wrong for 70 years and what should we do next 70 years Leonid please thank you very much well I'm
not sure if it was wrong for 70 years right we definitely got a lot of achievements in those 70
years and the breakthrough for example in of course in deep learning and the way we heard today in
all our presentations it's actually proving it but at the same time it could be that we interpreted
you know the paper the ideas in slightly if we interpreted the ideas slightly differently the
story the history could also be different because for me you know I think we should start with this
notion of intelligence right and what is intelligence and I don't want to be like philosophical here I
want to be very very practical right and so intelligence is you know when I think about
intelligence it's really ability to set up and solve problems and achieve certain goals in real
world and that's it right and artificial intelligence it's a computer or program that can do it nowhere
in this definition have I ever said the word human and so you know somehow you know going back to the
Turing test we put machines in this unfavorable positions in order to pass Turing tests they
need to know what humans are right they need to know how to simulate and mimic and behave like
humans at the same time intelligence really doesn't mean to be human intelligence means ability to
solve to set up and solve problems and so I don't think we went in in the wrong direction but part
of the effort could have been avoided in the sense of trying to make machines that exactly mimic
humans now while doing so we of course you know make huge interesting discoveries and learn a lot
about humans and learn a lot about for example human brain structure etc etc but in general setting
up a goal of building a machine that mimics human might not be the right goal and going forward I
think we should focus on things like actually building machines that solve things that can
set up problems and solve them and not necessarily the problems that humans would be able to solve
in fact why do we need machines to solve problems that humans can solve so we need to have machines
that will solve problems that humans cannot solve and we need to go and and look in that direction
more than trying to replicate humans and though you know humans and our brains are probably a huge
inspiration for computer scientists to build machines they're insanely complex and I think
trying to reconstruct them in and to reconstruct for example continuous way the brain operates
in our sort of digital binary zero ones that computers operate this probably is not going to
work anyhow so bottom line I think we need to refocus a bit you know understanding intelligence
as ability again to solve to set up and solve real-world problem and work into solving intelligence
in this sense and not in replicating how human brains work and what us as humans can do thank you
Lenny I have a question can you give us example of that kind of problem that humans cannot really
solve without you know for example you know genomics right now we a lot of things we cannot
solve we cannot for example map precisely genes on the you know gene that's on the phenotype genes
on to precisely diseases right you know there might be a reason for huge enumerate a huge
number of possibilities or maybe we're approaching it in the wrong way and I think the great advantage
that could come from AI is being able to solve the problems in a different way that we're thinking
about them that's one thing another thing is I think and as a professor you perfectly know that
you know solving problems when it is well posed well positioned well specified I mean when you
specify the problem really well it's not that hard to solve it it's actually hard to formulate the
problem precisely that it is solvable right and so if machines learn how to actually formulate
problems before solving them right that would be a huge advantage so and that's what AI cannot do
like AI cannot formulate tasks for AI to work on AI cannot put any actually goals and that's a big
problem for artificial intelligence right now because goal setting aim setting target for moving
forward is the biggest problem for artificial intelligence right now I think I also wrote a
paper on this too okay do you think Leonid that that deep mind alpha something with molecules
might work for application AI in science do you see that example of what you're talking about
well it's actually a very good example you're talking about the recent you know this the folding
example right when I'm folding yes alpha folding this is actually an amazing example and it's also
you know I would say it's on the same level of amusement for me as you know GPT-3 when
you interact with it but the thing is the truth is you know GPT-3 has no clue what it is talking
about right and so it learned the statistics of the sequences right and honestly if alpha go by
learning the certain statistical patterns is you know can you manage to predict the right
protein folding that allow us to build new new new for example new medicines that's fantastic
that's that's that's terrific does it bring us closer to like AI in terms of understanding no
so thank you very much so actually Gary I would like you to join us our discussion
and also to elaborate on those two things what was wrong for the last 70 years in terms of our
quest for artificial intelligence and at least I know two things you saw two startups to google
that's a good one but what was wrong and what should we write to make it better you sell another
one start up to google maybe and something else okay can you hear me yes excellent okay so
what was wrong well you know early on we we didn't actually have a lot of compute for number one
I mean our brain has a fantastic amount of compute in it and we had not we still don't
we're still not at the that level that's like probably available anywhere but
is you know we're we're getting there so that that was one there there was some
understandings of neurology there was also what the idea is of intelligence what it really is
I mean people got enamored with like logical proofs and other things and this isn't really
you know a large part a large part of what our intelligence is is simply survival as
that you know a simian in an environment for for whatever reason so you know there were
the goal that we had set out to do was was largely wrong like logical proofs and and
we didn't have the compute to do it we didn't have a lot of understanding
there weren't kind of sort of interesting machines like robots that were even capable hardware or
the compute so you know what was wrong was like too early and naivete so you know what do we do
well it it's it's beginning to to get a little better and that was like let's say
you know I've been I started my academic career and in neural networks and those of us working
in it like an early friend of mine was yon lakoon I contacted him when I was in graduate school
because I wanted a corner detector he was working on but but you know we were working on neural
networks and we knew that was the kind of structure not this symbolic AI so you know but but what we
have right now is not it's a fantastically useful tool but I call it it it's still
basically a deep associator it's not it's not intelligence itself and intelligence itself is
is a little bit difficult to define but but you know I think there's there's
a right now you have to understand like what the mind is and what a mind can do and and I think
there's you know a lot of misconceptions there's you know it can a mind live forever it's pretty
clearly no not not in any not in principle like it can because a mind is built up off of structures
and those structures suffer a kind of decay of when you it's supposed to represent like
distributions and and and they become you know overloaded but but an example like I'm going to
use another talk is is when you're building a robot you have to build a mind and that mind
explicitly or implicitly represents the the world and the robots and like you're forced to do this
every time you do it every time you want to make something operate in an environment
and then the very primitive ones have a very primitive model but you know some of them that
I've worked on it let's say a Stanley which is a simple example what it did is it it had the
sensing in the it had various modes of sensing lasers gps wheel odometry whatever
in an environment and it and vision and it fused all this information into a world map
and then it it knew the direction of gravity and in that little world map so it had this model of
itself it had the world and the world was very simple it was bad things good things and things
I don't know add a tilt and then it ran that in a physics simulator and like how and and and so
another thing people don't understand is that we aren't our intelligence we're our emotions those
are what drive you not you know your intelligence is a how what is always by your emotion so so if
you love like computers given a certain intellectual level you're going to become very good at
computers if that if that's what you really love and and so Stanley's emotion system was gps
waypoints that's what drove it it wanted to get from one to another safely and and so that was its
entire mind its mind formed the world of bad bad good and I don't know on a you know on a tilt
and it knew where it wanted to go next the next the next and it simulated itself going there and
then it would actually take that step in the real world we're very much like that you see your
simulation when you're asleep which I just was and you know and I like to say when you wake up
your dreams don't stop they they just connect to a data source which is the world but you look
look at Stanley's mind and and and this is all mine so it's a very simple mind but
what can it understand all it understands is kind of like bad good don't know you know
direction of world well if you if you wanted to explain I you know maybe it's Dostoevsky
you know crime and punishment you know what this the person takes a very rash move well a rash
move to Stanley if you wanted to explain this Stanley the robot a rash move would be cutting
across the I don't know land to take a shortcut to the to you know not go the long way around but
jump to a further waypoint well that's a a rash move and so you could explain Dostoevsky you know
crime and punishment to the robot but not really its brain cannot understand this because it's not
rich enough well to a rounding error that's us so we will never understand the world under this
theory but we can create these self-operating agents who have a certain level and can do
certain things in the same way if you have your cat it will never understand you know you play at
Dostoevsky it will never understand it because it doesn't have but if you could talk its language
you could say well it's like a kitten that doesn't listen to its mother and it's going to get in
trouble and then the cat will say I understand you go no you don't we're the same like two
rounding error we're the same we'll never understand the world all we get is a model of the world and
that model is a causal model that likes Stanley that allows us Stanley needed to drive across the
desert we need to operate in a social simulation we will never understand the world and physics
there'll be no final theories because we don't even see the what needs to have a theory of it
we have none of that circuitry and you know so we can create these machines when we we can create
a machine that has this interior model that socially simulates and it will become conscious and aware
and it might be more powerful for us and we could say well what's the real
structure or meaning of the universe and it will say well it's it's like
that's going in danger right we won't be able to understand what it understands after a certain
level I totally agree with the last point we will not be able to understand the machine
conscious machine if you ever be conscious at that point I would like probably to return
one of my flights which I prepared for our talk please bring up this slide which I selected
I don't know if you see it can you the chewing continuum yes chewing continuum so I actually
thought about it for a while and I think that chewing continuum consists of chewing himself
was working on very noble things like solving mathematical tasks
and by the way our our listeners our viewers please get caught and answer my question
going back to chewing chewing continuum is from virtual world to physical world and
from non verbal interaction to verbal interaction and chewing was concentrating on the left upper
corner of this with this noble task of solving mathematical task cryptography talking playing
chess learning languages whatever gentlemen are doing but he gave no attention to the physical
world because he considered too complicated for realizing in robotics and I think that
what what I thought in booty talk before and what I heard right now in gary talk that physical
world and interaction with physical world in a verbal and non-verbal way is might hold the key
to creating thinking machine it's maybe optimal position and of course you can argue with this
but gary I would like a little bit you to elaborate on very briefly but very clearly
please excuse us that late night in the United States what that's early morning what we should
avoid and be very careful in exploration of disabilities which is artificial intelligence
is creating for us what we should be avoiding for next 70 years what is dangerous
in I think what's dangerous is not going fast enough with AI I think human humanities
well if humanity's existence depends on the survival depends on getting these techniques
fast for design and and whatever I'm not one of these that that's worried about that AI is going
to kill us I'm worried on the other side that we're not doing it fast enough also I'm not worried
that if AI that AI will kill us we're a technology the primary thing of our species is we create
technologies if that's not stable and survivable so what then we die that was what nature intended
because that's what we do and yet like we can't we can't shy back from this we have to accelerate it
in my view and I'm not really worried also if AI turns on us and decides to destroy us
well then we succeeded right we created another species that can live without us you know that
will be our greatest day so I'm on the total opposite side of this like we should be applying
much more efforts and funding and acceleration and just go go all out you know we need the robots the
human labor is failing around the world it's not there's not a population problem there's an
underpopulation problem that's rapidly going to hit us I mean it's gonna hit yeah it's gonna
hit us like a freight train and we need we need the labor we need the AI's ability to solve
environmental problems and the global warming problems energy problems like we just cannot go
fast enough thank you very much Gary yep okay I'm going please bring up my slide with chewing
continuum is it possible that for me to bring it up yeah yeah yeah I have it no no Gary it's
all right so thank you very much Gary yep and chewing continuum also allows us to do one thing
it's I sought out all possible chewing tests around this chewing continuum and you can see that
all chewing tests which created for the last 70 years are a group in upper left corner
and almost nothing in physical world and nonverbal interaction which is also very important
because dark matter of culture is what is our I would say nonverbal interaction might be as
important as verbal interaction chatbots and some some other things also please take some time to
to answer my question so and I would like to go to Gurdip Pao Gurdip I listen to your presentation
I ask carefully as I could in terms of I'm also one of organizers of my journey and I know that
Microsoft is betting on GPT-3 it's good to know that but that's we also know for sure and I think
Gary mentioned it a little bit that GPT-3 is at least not energy efficient as well as all other
frameworks in terms of I would say chatbots computer vision so my mind right now is consuming
only 25 watts of energy and I'm extremely I'm not that smart as GPT-3 maybe but I'm extremely
energy efficient so for today I have only one cup of coffee and it's just enough for me to run all
day and robots need a battery replaced maybe eight hours at least in hours Burbank mobile robots
need robot battery replaced quite often so Gurdip do you think that this bottleneck energy bottleneck
is a very serious bottleneck for the next 70 years of development artificial intelligence
those GPT-13 will be ever be energy efficient as human and of course you can also help us
to liberate what was wrong for the last 70 years so Gurdip please great so you know I was thinking
about your question about last 70 years and you know I would say that you know humans are very
resourceful creatures and we approached after you know the Alan Turing famous paper we approached
artificial intelligence in a very resourceful manner as well now you know what I mean by that
is that you know we we basically immediately looked at the problem and said you know we understand
logic we understand rules so we took you know that bit and we ran with it and then we realized well
we can only get this far with artificial intelligence with this sort of rules-based approach
then you know things sort of quietened down and then we realized well we know math pretty well so
let's start using you know some of these math-based techniques you know k-nearest neighbor some of
the clustering approaches and you know sort of this classic data-driven machine learning came about
sorry so I was saying you know so we're pretty resourceful creatures and and now because there
is so much digitized data and there is so much compute of course you know we are leaning heavily
on on on deep learning methods and you know gpp3 I completely agree with you is it reminds me of
this expression more thrust Scotty which is basically you know saying that you know let's throw more
and more at it in terms of compute and data and of course the performance is going to get better
um I you know so so that sort of I think has been sort of the journey of the last 70 years
but obviously this is not a sustainable model as well and I think that if there is one thing
I would look at sort of critically in the last 70 years is that you know we tend to get obsessed
in the community with one method or the other you know and and we go through these different
waves and right now we are on the deep learning wave which you know I'm a huge fan of and you
know I think as Gary said you know it's a deep learning and that these neural network architectures
are great function approximators but uh we have to you know take a step back and say you know what
are the big gaps that exist and are we making sufficient progress in addressing those gaps
versus you know just pushing forward with more more energy and you know more data and I think you
know in my towards my one of my last slides I talked about some of the areas we need to
make progress on you know specifically with the area of power consumption you know I think that
you know since we are inspired by the brain let's look at the human brain and see you know how
it deals with you know so works so efficiently and I think part of it is that it is actually reasoning
with a lot of these sort of what we could call model-based approaches where it doesn't need
a lots of data to understand that if I throw an object up it's going to come down because it has
fundamental notions of physics similarly you know I think you know some of the sparse network
based approaches are something that you know I think are are pretty important that I think we
need to pay attention to you know just because we have power doesn't mean we should you know go waste
it you know the human brain for example does amazing things even on power with things like
heavy and sort of learning and you know when it finds like two adjacent neurons firing it
sort of short circuits them so I think that you know certainly we should be impressed by GPT-3
but I think it is just a very small stop on a very long journey and we need to always keep these
things in perspective that you know what are we really trying to solve for what are we optimizing
for as you know as I said earlier in the talk I think if we define that clearly I think the next
70 years we will make tremendous progress so I have a question for a good debate that might be
go later right now there is a famous saying of Mark Anderson on software in the world so probably
everybody heard of it means every engineering complexity sooner or later defined by software
and actually universal truing machine but for us is actually software is not only one one this
one part of equation because software is robot for breakfast culture for lunch and knowledge for
dinner so software is actually it's everything including culture including knowledge and
and everybody knows that
Kasparov lost to computer in 1997 and it was kind of beginning of victories
for computers and artificial intelligence in board games even they were playing board games
a little bit earlier but in 1997 it was not a computer who was playing against Kasparov it was
chess culture which was accumulated in that IBM computer who was playing again against Kasparov
and in 2018 it was go culture rules of go matches which are alpha go zero playing played against
each other which were was kind of playing against Lysidol so and I believe that we have time when
our artificial intelligence systems can just accumulate our culture make huge huge storage of
everything we say everything we do and then sort it out and then make a response a response
and also our questions based on the whole humanity history so now I'm going to you Michael and
actually I remember something similar in your book which you wrote on limits of artificial
intelligence right now but not going to your book but going to my two original questions I would
like to say what was wrong for the last 70 years by the way what is the distance between Oxford and
Cambridge about 60 miles 60 miles well that's the physical the physical distance the emotional
distance is far far greater than that yeah I understand where well this by the way about
emotional distance I have the same situation in Scotland where I graduated and we said we usually
say that funerals in Glasgow a lot of Mary's and Edinburgh marriage oh yes emotional distance
might be more but I thought that Alan Turing was running distance something like 15 miles
almost every week so it's maybe a quarter or something of distance between Cambridge and
Oxford you are from Oxford and Alan Turing was from Cambridge so this emotional distance between
two schools are actually quite quite important right now but going back to the question what was
wrong for the last 70 years except the fact that Alan Turing from from from Cambridge
so I think there's a there's a couple of things and I think my answer will resonate with what Gary
said and and others today so the first thing is I think there's an obsession in AI historically
with discovering one idea and thinking that one idea that one technique is going to be a magic
ingredient which takes you all the way and so as as as you said Albert as Gary said I mean for a
long time it was the idea that knowledge knowledge representation we just write we need the right
way to find human knowledge and to write that down and if we can just give that to machines
then that will take us all the way so I mean there was a famous experiment the psych experiment
where they tried to code up the entirety of human consensus knowledge and the idea was if you could
give that to a machine then you know AI would would be solved so it's that idea that there's one
kind of one single technique you know we have one advanced wow this is it this is the magic ingredient
and that's going to take us all the way and it doesn't right I mean it just doesn't and I guess
I'm I'm very I'm hugely impressed as I'm as impressed as anybody is by the current advances
in AI the things that are going on in deep learning these are real and they're cause for
excitement I mean I think they are real advances but they are narrow advances and they are ingredients
but they're not the whole ingredient they're not going to take us the entirety of the way to
to artificial intelligence so I think that's the first thing that's the first lesson right
don't imagine that there's one single ingredient which is going to take you all the way
second I think this is quite interesting the examples we've seen in the example on your slide
things like chess and go those why why do AI researchers study problems like chess and go
and proving mathematical theorems they do it because those are the things that they regard
as requiring intelligence as requiring genius right those you know being a good mathematician is
something that you know lots of computer scientists aspire to be so they look at those problems
and they say well if we can solve you know if we can prove mathematical theorems with a computer
then we must have solved the intelligence problem but actually the truth is that's not where a lot
of the hard problems are so to go back to the driverless car problem that Gary was was talking
about earlier and I'd be interested to see whether Gary disagrees with me or not what is the hard
problem in in driverless cars is it knowing whether to speed up or slow down or to turn left
or to turn your indicators on no I don't think so the problems with driverless cars are knowing
where you are and what's around you what's going on in your environment right all of the problems
that my guess anyway is that Gary and his team had to solve back in 2005 were to do with perceiving
your environment if you have all that information then knowing whether to speed up or slow down and
so on is going to be is going to be easy actually that's that part of it I think is a relatively
straightforward and conventional bit of computer code um so perception and actually that's where
neural networks the current wave of AI technology that that's where it's turned out to be very very
good at dealing with problems related to perception understanding problems in computer vision
you know in understanding speech and so on these were fiercely difficult problems and that's where
that technology has proved to be very very successful and the third thing I think that
the third historical mistake is not understanding that where the difficult problems are is the world
right um we have evolved over billions of years to succeed in inhabiting the physical environment
that we inhabit the planet earth and the narrow bit of planet earth that we do actually inhabit
imagining that you know you can you can build a neural network and train it up in the lab
you know over over a couple of days and that that's going to be as good at dealing with the world
as we are I think is just a huge huge huge mistake so the world is really really important
let's go back to GPT-3 so what is GPT-3 GPT-3 is this program developed by open AI I believe and it
was trained by giving this program huge numbers of texts vast amounts of written texts so let's
take an example something that you might want to do something that Gary might want to do when the
for breakfast is make an omelet right um completely routine task for a human being
making an omelet so GPT-3 is read every omelet recipe that's ever been written right it's there's
no recipe for an omelet out there it's written every it's read every essay about omelets it's
probably read books about omelets so in terms of just knowledge it must surely have all the
knowledge about omelets that there exists in the world but could it make an omelet no of course it
couldn't it doesn't know anything about omelets because omelets are things that exist in the real
world for it omelet is just a symbol but it's seen time and time again in these huge numbers of
repositories that have been thrown at it none of that knowledge that is coded into GPT-3 none of that
stuff is actually grounded in any experience of the world that we all have for me the word omelet
represents every experience I've ever had with an omelet every omelet I've ever tried to make
every egg that I've ever tried to break to go into an omelet every successful and bad
omelet it reminds me of an omelet I had in Paris in 1997 and so on right in that sense the concept
of omelets means something to me because it's grounded in my experiences with the world GPT-3
doesn't have any experience of the world to ground itself in so in that respect it's just a disembodied
I mean it's a very to be clear it's an incredibly impressive feat of engineering and people will
do really really cool things with it but it doesn't understand I think just to reiterate a point and
I say it doesn't understand because it can't it doesn't have any experience of the world so those
are the three things I think where you know this obsessing on one idea and imagining that there's
one single single technique which is going to take you just kind of the holy grail of AI
that's a mistake focusing on problems which actually you might find impressive as requiring
intelligence in people but actually is not where the real hard problems are I think that
historically has been a mistake and finally not realizing the importance of dealing with the world
you know experience human experience human knowledge everything about the human condition
is grounded in our experiences in the human world and I think too if we ever succeed in building
machines that are self-aware and conscious and sentient and all of those things machines that
have understanding then that understanding will have to be grounded in the world in the same way
thank you very much Michael so going back to
to some ideas which I said before that you see Alan Turing I don't know if you see this slide
but Alan Turing said that board games talking is very important for artificial intelligence
but he said that there is real human pleasures food sport and sex and those are very important
actually for understanding the world exactly as you Michael said so I think that without
understanding those three we will not have any intelligence at all and at that point I'm going
back to Gurdjie because I was asking question on the role of embodied intelligence and robotics
in for is it important for the future research in artificial intelligence Gurdjie together
Sber and Microsoft Research did wonderful project for info using reinforcement learning in robotics
then I would like to pose this question now openly to anybody who would like to answer this
Leonid Garry Michael but my question is how important embodied intelligence to study
perception cognition machines and how important it for a search of general
intel artificial intelligence and artificial intelligence with specific applications so
can we create artificial intelligence with no embodiment or we really need embodied
machines to advance fully in that direction so who would like to answer this question
Leonid Michael yeah I'll be I'll be I'll be short I actually want to you know support Michael in
this in the sense that in order to build like you know truly artificial intelligence machines
should gain the experience that human has right and what's the best way to gain an experience
than to explore the world and to explore the world and to do it autonomously yes you need to
have those type of systems those embedded systems with intelligence and you know when when you when
you see when you look at the for example at the robot dogs running around right in outside Boston
you realize that we're actually pretty close to the to the phase where the systems will be exploring
world on their own gaining the experience learning what omelet is eventually and hopefully will
will not only read about it but try it thank you we will we will soon surprise have some surprise
with robot dogs around here but we should be patient in this Michael please yeah so I'm going to
bring in a slightly different sort of aspect to this problem so there's a famous there's a famous
six word exchange that was formulated by Steven Pinker the psychologist and linguist and it goes
like this so Bob says I'm leaving you and says who is she um so the six words right and everybody
who hears those six words immediately has a rich mental picture of what's going on as people
we all understand that right maybe somebody listening to this actually just lived it last
night I'm very sorry if that's the case um so what's going on there how do we understand that we
understand that because we've got experience of the human world right we understand about human
relationships human beliefs human desires and so on and nobody trained us in that that's just our
experience as human beings living as social animals that have relationships with people
in the human world now there's a this is a big problem for AI if AI you know suppose you're on
that you're talking on the telephone to to an AI system which decides whether you get a loan or not
and uh and it says no you're not going to have a loan it must surely be if it's going to be any use
it has to be able to understand that this is going to make you upset or angry uh and so on I mean
an AI system that would be that would be a doctor right an AI system that took the place of a human
doctor would have to be able to understand the intricacies of human relationships because being
a doctor is not just knowing about diseases and illnesses it's knowing about people and the lengthy
training process that doctors go through is every bit as much about training them to deal with people
and to understand the people that they're dealing with and what kind of treatment regimes are going
to work for them and so on as as individuals understanding about their personal circumstances
their relationships you know all of that kind of stuff so we all have that because we've been trained
both genetically through billions of years of evolution and since birth right uh where um you
know where our parents teach us right from wrong and so on and teaches about what's acceptable
in relationships and and and so on we all learn about that because we're part of the human world
how are we going to give that stuff to machines it's a big I mean technically it's called theory of
mind right how are we going to give machines a theory of mind so we can they can understand
what that six word dialogue means I'm leaving you who is she sometimes I also don't know who is she
yes you know for I'm unclear whether embodiment again there's many kinds of mind
right and and so um but you know I'm unclear to the extent of you know we we we can be disembodied
but embodied in a virtual world right so you know it can all be happening in a cloud but but I do
think embodiment does give you certain like things which are primary to us like the the fear of death
and the need to survive and that's a lot of what we're we're that's a lot of what we're based on
and it's a we form this causal model that's necessary for our existence and then we press
that causes that causal model for everything else we think we understand and and so if we
want ai's that are intelligences that are going to be useful to us they must share a certain like
embodiments and you know the same kinds of things that we do and it's unclear um you know this how
much a a a giant body of associations it like GDP three it's kind of shocking how far it can
carry you and yet there's like no soul in the in the structure it's just a chain of of associations
right between then and and so you can it has all these brittle points and unexpected failures
that are hard to predict versus you know with us we're we're kind of regularized in our environment
by our physical you know need to understanding of how we would get damaged how we would survive
what's particular with humans is a large part of our mind is devoted to a social world which is
what we created and so we're always modeling our place in the social world and how to interact
and survive with other entities in it and and that's that's a very key thing for us in fact
it is a large amount of our whole brain and understanding and again you see this social
world in your dreams you fully simulate other people and your interaction and your hierarchical
place with them in your dreams and so a large part of our mind is devoted to that and and so to
that extent like I think like if we want roba I mean we want intelligences they have to sort of be
embodied with us and you know if we if we want them for the human factors there are many things
like protein folding and whatever that are a very specialized area and yeah we want we just
want a machine to do that again such a machine really needs to and explicitly or implicitly
embody a kind of internal causal model of folding if we really want it not to just be
associational to sort of mostly like getting a lot of stuff right but not really fundamentally
understanding the 3d chemical world that these things are in it would just be a kind of weird
associational manifold over chemistry without the sort of physics and the causal physics that it
really needs to understand it so so in that sense it should embody a causal model of the world upon
which it it grounds its meaning and and that's what's gdp3 lacks it lacks any of this grounding of
meaning right so any model lacks actually yes but but but you know it's not that the problem
isn't that models lack this is that you you want a model that spans your space because we're always
going to lack like there is no super intelligence that that it can know everything in every aspect
it's always going to be grounded to a causal situation and when you try to go too far out of
that it's just going to break it won't you won't be able to expand this mine indefinitely it will
be based and built upon a causal structure and that will be its limits forever you need a new
mine to to go into some completely new area but um i could write books about this but yes please do
i might okay so you see uh now um i actually before i kind of knew that our discussion will go
this way so uh this slide is summarized three ways to build artificial general intelligence
first one we discussed a lot is representation of a symbolic approach to the description of the world
second is connectionism based on basically neural networks deep learning neural networks and the
third one is embedded intelligence and kind of combination of maybe two with robots so i would
like briefly to any of you ask which which approach you believe the most or might be non and there is
fourth approach or maybe only combination of all three will bring us forward so uh i'll start
with leonid with you and then gary and then michael please what is the most important approach here
to me right now the the most nearest future is is um i believe lies in this newer symbolic
computations right so which is in some sense connecting symbolic representation and connectionism
and to me that's probably where the next advances will happen and that's the sort of i think the most
fruitful direction for the near future going forward yes embodiment definitely will join to
actually gain those experience and uh you know the meaning and understanding of the world around
us physical world yes i think you are in line with our what our tutoring said because he said
robots are very important for future development of thinking machine but they're not ready here
to be built here because there is no spare parts for them and it's not very clear how to
gary please well i you know for agi i first of all i don't believe in agi it's a si a specific
intelligence i don't think we have a general intelligence because we use our internal
structures to extend to like what is a quanta you know what is a particle it goes as a wave
and a particle down at the small scale it does not that's just where our metaphor that we have
for our brain breaks down and and so i i do think you need all of these things i think the
the symbolic representations derive from from this this kind of this necessity to build a world
model for yourself and and it it's those parts that give you the symbols again like this would
extend to people think well math is universal and i go no no math only exists in here it's not a
property of the world it's a human property and it exists in the human mind and it works for our
models but it but it's not some magical thing that existed out in the universe that we tap into
it's a structure that works in our causal models and it breaks down like most of math is unknowable
to us like most thing the the vast majority of the universe is unexpressible by by even
unknowable by our functions and symbols right but causally at our scale at our time we have a very
flexible model that can extend so you know the quick answer is we need all these things and
they'll always be relative to the job we want it to solve so to achieve artificial specific
intelligence you know that can be do very general tasks but there's no such thing as this universal
intelligence it's always in terms of learn grounded models in my opinion thank you very much gary uh
michael please yes i'd like gary i am a skeptic about agi and i don't see anything on the table
at the moment which is which is going to take us to to agi i think all of those things are important
connectionism symbolic representations i mean i think it's pretty widely accepted now that um
symbolic approaches and connectionism i think need to talk to each other um i don't think the
symbolic approaches that were popular 30 years ago are likely to be the way forward so i don't
think that's going to be it but there will be some form of symbolic reasoning that's that's that's
got to go on and i think what i would say is the reason i'm a skeptic about agi is that um again
going back to a point i made earlier you know we are the product of billions of years of reinforcement
learning with thousands of generations of our ancestors uh where mother nature has tuned us
over that immense period of time to be able to be uh generally intelligent in the world that we're
in the current techniques you know the headline techniques like alpha go and the chess playing
programs that are so successful and and so on these are all based on reinforcement learning
where a program just experiments and gets feedback it tries to do something it does badly and in
a computer game for example right a computer game like um space invaders um so you can have a
program which learns to play the game of space invaders but actually it does that by just essentially
starting by moving randomly seeing what works and what doesn't work and when something works when it
gets a good score it does that again that's reinforcement learning it's just just over time
playing and playing and playing good the problem is reinforcement learning doesn't work in the real
world gary couldn't have used reinforcement learning to train his cars in 2005 right because
they would have got through a great many cars these cars wouldn't have gone anywhere reinforcement
learning doesn't work the kind of reinforcement learning which is so successful in games for
example virtual environments is very very successful there but doesn't work in the real world um so i'm
somewhat of a skeptic about agi for that reason i mean we are the product of reinforcement learning
but it's billions of years of evolution which have given us a kind of reinforcement learning
to generate uh human beings that can uh that can successfully occupy uh the human world
in sberbank we recently published a book um probably half of absolute of this book are
presented on this conference and it says in russian um strong artificial intelligence
and actually the book was written on artificial general intelligence agi
well not not not to go deep into the story but uh we here we are actually putting a lot of efforts
in understanding how to advance science further on and i think our discussion um for like like
we just had before uh is very important step on not only advancing artificial intelligence
research in general but also finding bridges between our communities here in russia united states
uh england great britain and i think that it's very important for us to listen to
and especially in the conditions that we cannot travel we cannot go to our countries to visit us
and believe me gary and michael you will not regret if you come to russia and enjoy gary being here
quite a few times with us visit us and we always like to welcome you here but michael when you have
time certainly you should visit us and you will enjoy staying in russia in moscow and visiting
sberbank laboratories which quite a few of them and i'm sure leonid will join this invitation and
extend to all of you i will remember that invitation yes please yes please we we love
guests here um so i hope that uh pandemic and covid will uh finish uh quite soon and we will
have opportunity to travel uh to each other and also to send our researchers to study with each
other because we welcome your researchers here uh to study with us and to do research and i'm sure
that our researchers will be more than happy to visit britain united states uh in robotics
laboratory we have uh five people visiting microsoft research and for almost half a year
studying there artificial intelligence and reinforcement you're learning uh and applications
these two robotics so gudip is not with us so he's he will not tell us about it but i'm sure that
my colleagues from robotics laboratory are explaining in sections for this conference
so i would like to summarize what we said today and the general idea which we just discuss is that
um we need all three approaches for building artificial general intelligence strong artificial
intelligence symbolic approach connectionism approach embodied approach but the phases of
this might be different so it might be all together or it might be first approach where we combine
best parts of symbolic and connectionism together to build a very solid foundation as leonid uh said
before uh so uh the one thing which mike uh also said very important to us is that we should not
focus on only one thing uh many years ago chinese leader mount ze dun said 100 flowers should blossom
so probably for artificial intelligence we need more than one hundred flowers
and we need more than one hundred speakers and we also need to exchange embodied approach
and make conference dread again so thank you very much for spending time with us and i would like to
thank you all our visitors or our listeners viewers which i'm sorry for technical troubles i'm sorry
to all of you you'll be patient our guestware patient and i have wonderful team and i hope that
next year we'll have you and maybe some other excellent speakers for my panel where we discuss
something else i don't know what so thank you very much thank you
