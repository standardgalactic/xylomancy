In many ways, the town of Livermore, California, was the ideal getaway
destination. It was quiet, dry, sunny, and just an hour away from the home drum
of 50 San Francisco. During the war, it was home to a military outpost. The
climate and remote location were perfect for training new pilots. Locals would
often see gliders soaring in a deep blue sky. Most expected the base to close
after the Allied victory, and indeed it was abandoned shortly after. But it soon
became clear that the end of the war would not signal the end of military
development, far from it. A new research lab will set up in this small town, a
branch of the University of California Radiation Lab. Its aim? To create the
most destructive weapons mankind would ever develop. You see, for the United
States government, ensuring the country was the world leader in nuclear
research was paramount. The development of the Manhattan Project at the sister
Los Alamos National Laboratory in New Mexico had ended the war in the
Pacific in an instant. The progress on the next generation of nuclear weapons
has slowed, and researchers felt that a competing lab would help speed up
advancements. Leading the lab was Sidney Fernbark, a master physicist who
had studied under the wing of Robert Oppenheimer. Fernbark would put an
emphasis on using computers to solve the complex equations that underpin
nuclear physics. While they were still in their infancy, there wasn't much
choice. Testing nuclear weapons was hugely destructive, extremely expensive, and
politically dangerous. In less than 10 years, detonating nuclear weapons above
ground would be prohibited. Mechanical computers, using wheels, cults and
relays, had been utilised in the development of the first nuclear
weapons a few years prior. At the time, the technical limitations meant the
equations had to be solved in one dimension. However, the hydrogen bomb was
a far more complex weapon, and one-dimension simply wouldn't be
enough. The addition of the second dimension increased the number of
mathematical operations required exponentially, and as the difficulty of
problems continued to increase, only one thing mattered, speed. The first
electronic computer at the Livermore lab was the Univac One. It took 30 days to
assemble, major components were made out of fishing wire, and it would break down
all the time. But the machine could crunch numbers thousands of times
faster than anything else that existed, and that was all that mattered. As
weapons development continued, faster computers were required at breakneck
pace. The near unlimited budget that the Atomic Energy Commission had given
both the Livermore and Los Alamos labs created the opportunity of a lifetime
for computer manufacturers. The labs needed the fastest machine possible, and
as soon as it arrived, another that was even faster. The question was, who is
going to build them? As the war ended, and the need for large numbers of
military recruits disappeared, many of them had to make a decision about their
future. Most wanted to return to their pre-war life, working on farms or in
factories. For some, however, the last four years had changed their outlook on
life, and wanted something completely different. At Seesaw, the US Navy's
code-breaking division, servicemen faced this very choice. There were some of the
first people in the world to use a mechanical computer. Each day, they would
feed the machine's encrypted radio messages sent to German U-boats to
decipher. When the operation came to a close, some began to wonder about the
potential use cases of computers outside Seesaw. One individual of note was Bill
Norris, a Lieutenant Commander who had joined the division four years prior.
Norris came from a farming background, but was technically minded, and had
worked his way up to an engineering position. His experience with the
code-breaking apparatus led him to think about the wide range of applications
for a computer, and wanted to set up a company to explore this idea further. He
was not alone on this. Commander Howard Engstrom, who before the war had worked
as a professor of mathematics at Yale, was eager to pursue this plan.
Surprisingly, high-ups at the Navy were fully supportive. This was for two
reasons. They knew that most of the engineers would leave the Navy, and it
would be easier to subcontract the work to their companies and start fresh with a
new internal team. Also, due to the war ending, their budget had been cut
significantly, and they were unsure whether they would be able to fund the
development of a new code-breaking machine themselves. Thus, Norris, Engstrom, and a
few other Navy recruits had a plan, to leave the Navy and set up their own
computer company. The first thing they needed was funding. To Norris and Engstrom,
the commercial use cases of the computers were plentiful. American airlines could
automate their flight reservations. Chase could instantly store trades of shares
on the stock market, and General Motors could immediately see the stock levels
of all their dealerships. But all of their previous work on computers was
classified, so they couldn't give any details about how the machines worked or
how reliable they were. As a result, the stuffy, bureaucratic boardrooms of
corporate America didn't share the young engineer's visions. Despite the
Navy's support, it was simply too radical of an idea. There was one contact who
was intrigued by the concept, an investment banker called John Parker. He was the
owner of a large glider factory in St. Paul, Minnesota, which during the war had
made thousands of gliders as part of the war effort. Parker had gained large
wealth in the process, but like many contractors across the United States,
the orders had dried up, and the business was quickly bleeding cash.
As a former Navy officer himself, he was more understanding about the restrictions
Norris and Engstrom faced when discussing their ideas. In having exhausted all other
funding options, the Navy higher-ups repeatedly emphasized just how important it was that this
new company were set up. Parker was skeptical, but he was smart. He wasn't really sure about
the technology, but he knew that this company would have lucrative contracts with the Navy,
and with the glider business on the verge of collapse, he had little choice. So he agreed,
and together with Norris, Engstrom, and a few others, set up a new company, Engineering Research
Associates, to work on this new technology. The contract ERA had with the Navy allowed
engineers total freedom to design and build equipment however they wanted.
While the company would take on a variety of projects, including data recorders and
instrumentation, their main source of funding was from the government, who would pay however
much it cost to develop a computer. This flexibility created a hotbed of innovation,
which manifested with the group's first computer, the Goldberg. Computers of this time used vacuum
tubes for much of their logic and memory, and the Goldberg was no exception. Their use allowed
the computers to process hundreds of thousands of calculations per second, but their reliability
was poor. If one blew while the computer was running, which wasn't uncommon,
then often the machine would have to start from the beginning.
To prevent this, engineers wanted a way to store and retrieve information without using a vacuum tube.
To do so, they've placed a metal drum coated in magnetic tape inside an enclosure,
with magnetic read-write heads sticking out. By rotating the drum, data could be read from
and written to the magnetic tape. In the Goldberg machine, it was incredibly slow,
taking nearly 10 minutes for a full rotation, but it could store more than 40,000 numbers.
The company hit a snag with their next computer, Demon. While the drum memory technology evolved,
the project was rendered useless just before completion due to the Soviets changing their
messaging formats. Due to the high cost of producing purpose built machines, engineers
realized that the only way forward was to build a general-purpose computer with the
program stored on the magnetic drums. This way, if something changed, the machine could be reused,
and the program simply rewritten. So for ERA's next machine, Atlas, they did just that.
The magnetic drums used in these machines were truly revolutionary. So revolutionary, in fact,
the concept would become the basis for the hard disk drive. Their inclusion brought a host
of advantages. For one, the machine could access data very quickly without having to read yards of
tape. The drums were also non-volatile, meaning when the machine was turned off, the data stored on
the drum remained, and it would be there when the machine was next turned on. Most importantly of all,
the user could write any program they wanted to, run it, and make near-endless modifications
almost instantly. ERA knew that the magnetic drum technology would give their machines a huge
advantage over their competition, and set about modifying the Atlas into a commercial machine.
The finished product would prove to be popular, and its design would last well beyond 10 years.
The Navy contracts and the success of the commercial products grew the company rapidly,
from 40 to 400 staff in just five years. However, despite this, the company was in a dire financial
state and was a bleeding capital. It was 1951, and the market for computers simply wasn't well
established. In addition, the company was coming under heavy increasing legal pressure due to the
questionable, almost monopolistic arrangements Norris and Engstrom had negotiated with the Navy.
The company would be acquired by typewriter-manufacturer Remington Rand in 1952, who wanted to increase
their presence in the computer market. Many in ERA were skeptical of the purchase,
but Remington Rand's prior acquisition of Univac, who made the world's first commercial computer,
showed they were serious about the machines. However, the differing approaches of the two teams
almost immediately caused tension. Unlike ERA, who had spent years pitching their machines to
businesses, the Univac machines were built by academics who had little concept of the world
outside the lab. They would hemorrhage cash, often spending more than five times the allocated
budget developing a machine, which would usually suffer from poor reliability.
Their first machine, the Univac One, would only run for 10 minutes before component failure,
in comparison the ERA Atlas could run for 30 hours without issue.
The original plan was for ERA to focus on the Navy machines and Univac to focus on the commercial
side. But when Remington Rand was purchased by Sperry Corporation, another electronics
manufacturer, the two divisions were combined under the new Sperry Rand management.
The new unit would retain the Univac name as it had better brand recognition than ERA,
but with the merger, the funding for projects rapidly dried up, and tensions between the two
teams, who were now forced to work together, was reaching boiling point. No one was more
frustrated than Bill Norris, who had founded ERA 11 years prior. He'd seen his company and the
engineers become a shadow of their former selves, and he'd had enough. Willis Drake,
a senior ERA engineer, shared Norris' frustration. He'd witnessed years of incompetent management
and felt that Remington Rand would never be able to succeed in the increasingly crowded computer
market. They both knew that they would get no support from the Navy, and would have to raise
funds in order to start a new company. To find this, Norris, Drake, and top ERA engineer Frank
Mulaney met up with ex-ERA worker and Harvard Business School graduate Arnold Reiden to discuss
funding options. Reiden suggested a unique approach, simply sell shares in the street,
convincing people to invest based only on a business plan. This seemed risky, but Reiden
explained that a loophole in Minnesota law allowed him to do this while they were still
working at Remington Rand. By doing so, they could stay at their old company for as long as it took
to gain the required funding. Drake liked the plan and left the now monolithic Univac division
to join Reiden in selling stock in the new company. It didn't take long before they had enough.
ERA's aircraft hangar had never been considered a glamorous place to work,
but compared to 501 Park Avenue Minneapolis, the headquarters of the newly formed Control Data
Corporation, it was a palace. Engineers arriving at their new jobs walked into a dark,
noisy, and pollution filled warehouse used by local newspapers to store printing paper.
Most workers would have walked straight out, but the lack of overbearing management
created an atmosphere that was filled with enthusiasm. The Navy was well aware of this,
and to reduce the brain drain at Remington Rand, asked control data not to take employees
who were working on key Navy projects, the most prominent of which was Seymour Cray.
Cray was a University of Minnesota grad who had joined ERA straight out of college.
Despite his youth, he had the confidence and abilities of a veteran engineer.
Within two years at the company, he was already making important decisions about computer components.
Breezing through simpler tasks in his first six months, Cray was assigned to work on the
control system for an upcoming machine, the ERA1103. The function of this component was to
convert the lines of code being fed into the machine into computer instructions.
It required sending signals to various parts of the machine in a specific order,
which would often take weeks to work out. Such a mechanism would seem trivial these days,
but in 1951 there were no manuals and little prior research.
A fresh college grad would have balked at just the thought of designing such a component,
but not Cray. He knew he could do it, and his fellow engineers did too.
By the time control data had been incorporated, Cray was one of Uniback's top engineers.
The Navy had kept in there to finish designing a data processing machine for warships,
but it was only a matter of time before he too walked out the door.
The new company was initially unsure about where their revenue would come from,
spending its first year selling drum memory technology that their engineers pioneered at ERA.
Large computers, which is what the company wanted to develop,
cost millions of dollars. Millions of dollars the control data did not have.
But when Cray joined as head of engineering, he simply told them,
all I know is how to build computers. So I'll do that.
To try and entice investors, Cray set about developing a small prototype computer,
which could be used to demonstrate CDC's technologies.
The machine, the CDC little character, was significant due to its use of transistors
instead of vacuum tubes. They were far smaller, used far less heat, and were more reliable.
When the machine was finished, it was an impressive piece of equipment,
being a useful sales tool and a vital test bed for new technology.
However, control data was bleeding money. It needed to develop a flagship machine that was
a quantum leap above the current fastest and on a shoestring budget.
The design would be based on the Unimac 1103 that many engineers, including Cray,
had worked on at Remington Rand. Many small improvements would be made,
but the biggest difference was that their machine would replace the vacuum tubes
used in the 1103 with transistors. Having used them on the little character,
Cray knew that any state-of-the-art machine would need to use them.
Their advantages were simply too great. The problem was that they were expensive,
costing four dollars each, and the machine would need 25,000 of them.
Faced with no other choice, he trekked over to a local hardware supplier
to purchase the cheapest transistors he could.
Costing just 37 cents each, Cray was so impressed by the price, he bought the entire stock.
Their performance was terrible, with widely inconsistent electrical properties that surprised
even Cray himself, but they worked. To adjust for the lackluster capabilities to the components,
each transistor was paired up with another, which brought the properties of a pair
in line with a good quality part. The components would be mounted onto hundreds of small circuit
cards, five by eight centimeters in dimension, which would plug into a mass of connectors,
allowing the cards to communicate. Development was a slog. It seemed like the machine would
never get completed. The project was consumed by a double whammy of financial and time constraints.
Employees had to take deep pay cuts to ensure the company didn't go bankrupt,
and as fall turned into winter, there was still no working example.
But slowly, the printed circuit cards would fill up the prototype casing,
and by mid-1959, the machine was working.
At a size of 192 kilobytes, its memory systems would struggle to hold even a small JPEG today.
But when the newly christened control data 1604 was tested, it was simply incredibly fast.
Being the first fully transistorized computer, it was easily 10 times faster than any vacuum tube
machine, surprising even the engineers themselves. The capabilities of the machine started to attract
investment, including a $600,000 injection from an insurance company. When the machine launched
in 1960, demand was steady, but in the years following, this would rapidly increase.
Initial customers were branches of the US government, the Navy, various research labs,
but it was industry that really filled up the order books. Universities, defence, aerospace,
oil and gas. For control data, each of these sales meant one thing, cash.
Profit sword, increasing five-fold in just three years. Out of nowhere, a small computer company
operating at the newspaper warehouse had built the fastest computer in the world,
and its designer, Seymour Cray, was regarded by many as a pioneer.
Anticipating the success of the 1604, the company had been working on a cut-down machine,
which would incorporate similar technology, but at a lower cost. The 1604 was a success
for the biggest businesses and research institutes. But for general purpose computing,
it was simply too expensive for most enterprises, and management saw the potential for a cost-reduced
system. The machine, the CDC 924, would use a 24-bit processor compared to the 48-bit of the 1604,
and the memory would be cut from 192 kilobytes all the way down to 24.
However, as a result of these compromises, the machine's 1961 launch price was just $180,000,
about a fifth of the price of the 1604. The product was well engineered,
but the 1604's success failed to trickle down. Primarily, the world of business computers was
dominated by IBM, and CDC's lean architecture made programming business applications unnecessarily
difficult, less than 15 were ever shipped, compared to more than 50 1604s.
As a result, the head of control data, Bill Norris, decided that their computers should be more
business-friendly. New machines would need to include more instructions, and full-back
was compatibility with the 1604. Even in the early 60s, growth was the key to start-ups,
and this direction would allow the company to springboard off the success of their first product.
The idea was to have a lineup of machines, to be dubbed the 3000 series, that could serve as both
commercial and scientific enterprises. The first machine, the 3600, would be a flagship,
a replacement for the 1604. It would be seven times faster and have eight times the memory,
all at the same price. A low-end machine, the 3200, would replace the 924.
It would also be seven times faster and have four times the memory.
Then there would be the 3400, a mid-range machine with the same memory size as the 1604,
and the same clock speed as the 3600, but at half the price.
Cray would lead the initial development of the machines, but grew frustrated at the new
business-focused direction the company was heading in. The ballooning number of instructions and
backwards compatibility were compromised, something Cray saw as poison.
IBM's newest machine, the 7030 Stretch, had been the subject of constant modification for
management and a flopped upon release. It was a textbook example of how corporate bureaucracy
could ruin a project, and Cray worried the same thing could happen at controlled data.
There was no doubt that new machines could be successful, but he had little interest in their
development. He was focused on creating the fastest machines in the world and nothing else.
Cray and the engineer started to design a new system with a performance target of three times
that of IBM's latest. The first stages of development were focused on replacing the
37 cent transistors in the 1604 with new state-of-the-art parts. But when this was done,
the performance was nowhere near as expected. Months of tweaks and modifications went by
without any success, facing hurdle after hurdle. Meanwhile, the business-focused 3600 wasn't.
Tensions rose as management started to question the validity of such a risky
from-the-ground-up project. It was burning through the newly acquired cash with very little to show,
and visits from executives became more and more frequent.
Eventually, Cray had enough. He stormed into Norris' office and gave an ultimatum,
something had to change or he would leave the company.
For Norris, he too was nervous about the new machine. The 6600 project, as it was now known,
was going nowhere. Unlike the rest of the executives, however, he understood Cray's
anti-corporate working style and the effects the interference from above was having.
Besides, Cray was simply too important an engineer. He let the man have what he wanted,
a remote research station away from management. Engineers were allowed to join Cray under their
own free will, and with the prospect of working with complete creative freedom, many did.
Working in a new office built in Cray's hometown of Chippewa Falls,
excitement filled the air, and progress on the new machine started to accelerate.
To address the issues faced in Minneapolis, the engineers began testing a bleeding edge
transistor from Fairchild, made from silicon, rather than germanium.
The proposed clock speed of 10 MHz, 50 times faster than the 1604,
had simply been impossible with the old transistors.
These new parts, however, went in a different league. They offered lightning fast switching,
and using them would mean the 6600's clock speed goal would finally be attainable.
But with such a fast clock, there was now a new bottleneck. The wires.
In this era of computing, CPUs had grown increasingly large in order to handle the
complexity of instructions that were required. The size introduced signalling delays,
the idea that one part of the processor can't progress because it's waiting for a signal
from another part. To get around this, the central processor was simplified to only
perform mathematical calculations, with other functions such as memory, management, and I.O.
being handled by other components distributed throughout the system.
This meant the processor could be small, and that meant that the wiring could be much closer together.
In fact, this is often considered the first implementation of a reduced instruction set
computer, a technology that would become ubiquitous 40 years later.
Using this approach, the logic circuits were made 32 times denser than in the 1604,
so dense that the heat would almost certainly fry the circuit boards.
To address the issue, Cray turned to engineer Dean Rausch, who had been working on the machine's cooling.
Rausch was an expert in refrigerants, working in freezer and air-conditioner design before joining
controlled data. Up until this point, all computers had been air-cooled, but seeing the
eye-watering heat dissipation of the new system, a different solution was needed.
This new approach pumped DuPont free on coolant in between each of the circuit boards,
and then sent the warm liquid to a refrigeration chamber where it would be cooled.
The approach worked, making the machine the world's first liquid-cooled computer.
The final innovation was perhaps the most significant. In prior machines, the main
processor acted as a single unit, executing instructions one after another.
Cray noticed that this approach resulted in many parts of the system left idle.
For example, if the instruction was multiply, then the circuit's handling addition would be unused.
The CY600 would be different. Its central processor would contain 10 functional units,
each handling different instructions. As a result, the machine would be able to multiply,
divide and add floating-point numbers in parallel. Today, this technique is known as superscalar
processing, and has been commonplace in microprocessors since the release of the Intel Pentium in 1993.
But this was 30 years prior, and something no other machine could do.
The result of these innovations was a machine unlike anything that came before.
When initial testing was performed in July 1963,
the in-moon shot targets Cray had set at the start of the development really were met.
It was three times faster than the current fastest IBM 7030,
five times faster than the CDC 3600, and 50 times faster than the 1604.
At the press launch, journalists were astounded that a team of 34 people,
based in a small West Constant town, had created the fastest computer in the world.
As a result of the incredible performance, the next few years would be golden for control data.
It would sell over $1606 at $2 million each, generating half a billion dollars a year in sales
and adjusted for inflation. The company had grown from 11 employees to 9,000 in just eight years,
becoming the third biggest computer manufacturer in the world.
It positioned itself as the most agile computer company out there,
offering a suite of services that no one else could.
A physical machine too costly, you could simply buy time on one that controlled data owned.
Want to write software but don't know where to start?
The company would send over programmers to help you.
New accessories? No problem. They made them all in-house.
This was the result of CEO Bill Norris' desire to stabilise the somewhat volatile financial
status that had plagued the company in its first five years. Sales of services and
components would help balance out any lulls in demand for a specific model or line of computers.
The company would begin a flurry of acquisitions to achieve this.
It completed 8 in 1963, and more than 10 in 1964.
From the outside, control data was a perfect example of the American spirit and innovation
that defined the 1960s. But from the inside, all was not well.
Many of the acquisitions were not profitable, and those that were, still built parts of
vacuum tube machines, desperately needing funding to upgrade their equipment.
The vast cash reserves that had been built up from 1604 and 3000 series sales were rapidly
decreasing. And many in the company began to wonder if this was the right direction.
Kray, however, detached from management as usual, was largely unaware of these struggles.
He was focused on the 6600 successor, the 7600.
The successor and performance of the 6600 prompted many to wonder whether a brand new machine was
necessary. Two years had passed since the product's release, and it was still the fastest computer in
the world. But the industry was cut throat, especially for control data, who despite the
acquisitions were still far smaller than IBM. With this in mind, Kray was ambitious. The 7600
would be 10 times faster than the 6600. To achieve this, a breakthrough design would be required.
One of the essential elements of the 6600 design was its parallel functional units,
allowing the machine to multiply a pair of numbers while adding together another pair.
This gave great performance, but it had its limitations, the most significant of which
was that an instruction had to completely finish before an instruction of the same type could
execute. These scheduler could mitigate this to an extent by interweaving different instructions,
but it only had limited memory. If a program contained a series of additions in a loop,
there would be no parallelism at all. Each instruction would have to wait for the previous
to finish executing. Kray realized that the functional units themselves were almost completely
linear in nature. The instruction would be fetched from memory, decoded, executed,
and then the result would be written back to memory and the registers of the processor.
Each one of these stages was independent, using different circuitry and different parts of the
system. This was something that could be exploited. By processing instructions into
series of steps, instructions could be processed in parallel within a single functional unit.
This technique, known as instruction pipelining, had already been tried on other machines,
including those from IBM. But the combination of pipelining and the 6600 superscaler design
was not only unheard of, it was groundbreaking. In theory, this could boost performance by around
10 times, but limitations in the circuitry meant real-world performance would only be
about 3 times faster. The rest of the performance would be gained by packing the circuit boards
even closer together and cranking at the clock speed. At launch, the 7600 was unquestionably
the fastest computer in the world. While the latest IBM could perform 2 million operations per
second, the 7600 could perform 7. Its architecture was groundbreaking. There was particular praise
given of its innovative C-shaped packaging that allowed for the blistering clock speed.
The machines sold well in the defense sector, where governments could absorb the $5 million
base price. However, sales elsewhere were not as strong as expected. For one, software written
for the 6600 was not compatible with the 7600. The machine was also unreliable, often breaking
down several times a day, and many of the internal components were not easily repairable due to the
tight packaging. For all the 7600's performance, it was the wrong time to launch such a product.
The country's slowing economic growth weakened appetite for flagship machines,
and the lack of cut-down versions limited profitability. Many customers wanted to buy a
cheaper machine and upgrade to a more powerful, compatible system when required.
This was simply not what controlled data offered. For all of IBM's bureaucracy,
their market researchers knew what they were doing. This new low-end market was where the
growth would lie. Customers would purchase a basic machine and upgrade it when the company
had grown large enough. IBM's System 360 family of computers did just this. It was a range of
products from $150,000 to $6,000,000 that could run all the same code. While it was true that
the 7600 sold far more units than the fastest System 360 model, the low-end machine sold in
such high numbers that it didn't matter. IBM had a computer for almost every customer.
Control data had a computer for almost none. The development of the 7600's successor,
the 8600, started shortly after the 7600's launch. Typical for Cray, his ambitions were
mighty. The new machine should be 10 times as fast as its predecessor. Unfortunately,
increasing the clock speed to help achieve this would be much harder than it had been prior.
The development of discrete components had plateaued, and the increase would have to come
from packaging alone. The 8600 design itself was also ambitious, packing four 7600 processor units
within a single system. The processors would all run the same instructions, but would split the
workload between the four of them, reading and writing from a shared memory pool. While it would
require programmers to rework their code, the potential benefits were immense.
When the engineers benchmarked the first prototype, the performance was astounding.
In front of them was a machine that when programmed correctly,
really was 10 times faster than the current fastest computer in the world.
But there was a problem. A problem so big, even Cray didn't know how to solve it.
The 8600's processors were made up of modules, essentially 8 inch by 6 inch circuit boards
stacked on top of one another. To reach the required 125 MHz clock speed, the components
within these circuit boards were packed together so tightly that the heat generated was simply
unmanageable. Each module was only the size of a college textbook, yet used more power than
three refrigerators. The cooling solution, developed by Dean Rausch, mounted large copper
heat sinks between each board, drawing heat away into the coolant. Even with a refrigeration
capacity twice that of the 7600, the machine still ran way too hot. The combination of typical
failing components and the excessive heat resulted in a machine with truly catastrophic
reliability. Cray, of course, was used to set back on his projects. The 6600 had spent years
in limbo, and the 7600 didn't work reliably until at least a dozen had been produced.
Two years went by as the team of engineers attempted to address the issues,
but it was to no avail. The machine simply would not work.
By 1971, controlled data who had been fighting a legal battle with IVM over monopolization
were hemorrhaging cash. It was a battle they would eventually win, but to stay afloat in
the meantime, the company would need to cut spending. Management sent a memo to the Chippewa
Air Force research team requiring them to reduce expenses by 10%. For Cray, this was a slap in
the face. His team had generated over a billion dollars in sales, yet they were pulling funding
for a struggling project. To keep the project going, Cray sacrificed his own salary, dropping his
pay to minimum wage. It dawned on Cray, however, that the 8600 would never reach the market in
the current conditions. Sitting down with company chairman Bill Norris, Cray spelled out the situation.
The 8600 did not and would never work. The team would need to start fresh, and they would need
funding to be increased. After all, this exact situation happened with the 6600 and that machine
generated half a billion dollars in revenue. But to Cray's disappointment, Norris said he couldn't
do it. While Cray was building the 8600, another legendary CDC engineer, Jim Thornton,
was building an equally ambitious machine. The difference was that Thornton's Star 100 was
working. The company was already taking orders. Norris explained that the company could not
afford to finance two flagship supercomputer projects, but if the project was put on hold for
a year, the company may be able to increase funding once development resumed. Cray replied
that he needed time to think it through, but by the time he walked out the room, he had already
made up his mind. Cray met with colleague Lez Davis shortly after. Davis was a brilliant engineer,
one of Cray's closest partners. The two worked well together. He was soft-smoken and likable,
possessing the people's skills that Cray didn't. When engineers had a problem,
they would come to Davis, not Cray. In the meeting, Cray spelled out his plans. He was going to leave
control data to start his own company. He'd spoken to long-term colleagues, including Frank
Mulaney, and had raised $2.5 million of funding. Of course, with a large computer costing $50
million to develop, it wasn't going to go particularly far. The new venture would likely
have to do contract work for much larger computer manufacturers. It was ambiguously Cray research
for this reason. This wasn't ideal. They would prefer to work on their own projects,
but it would be far more enjoyable than what they were currently doing.
Davis agreed. The cutbacks on the 8600 project had seriously lowered morale,
and control data management simply didn't see computers as a growth area,
limiting the leverage that engineers like him could have.
Over the next week, the two began to crystallise details, who they'd bring with them,
where they'd work, what the salaries would be. It was important for Cray not to poach too many
staff for control data. He'd split on good terms with the company. The chairman, Norris,
completely understood Cray's decisions, even choosing to invest $250,000 in the new business.
The team would be small. Cray, Davis, Roush, and a few other engineers,
working in a small facility a few streets away from the control data lab.
By mid-1972, the new venture was fully operational.
Although funding was limited, the ultimate goal for the new company was to build a revolutionary
supercomputer. Previous Cray machines had used discrete components. Physical transistors and
resistors soldered to a printed circuit board. However, during the development of the 8600,
it had been clear that this approach was no longer feasible. The new machine would use
integrated circuits, a component that incorporated transistors and digital logic onto a single silicon
chip. While integrated circuits had been available during the 8600 development,
their performance was not sufficient enough to be used in a supercomputer. However, in the five
years that passed, the quality of the chips had improved dramatically, making them viable for
this new project. Incorporating integrated circuits into the new machine would bring several
advantages. Firstly, it would allow for tighter packaging, improving performance.
Additionally, the cooling could be simplified. The integrated circuits Cray wanted to use for
all the same height, so a single cooling plate would have direct contact with every chip.
To be competitive, the machine would need to employ a technique called vector processing.
In essence, vector processing allows a computer to perform calculations on a group of numbers
in the same time it would take with just one. Consider a program that adds together two numbers
four times. A traditional supercomputer would process one addition after another,
but with vector processing, a machine could calculate all four additions simultaneously.
In addition, fetching the numbers from memory and storing the result of the additions could
be done just once. Traditionally, this would have to be done four times.
In practice, it was never that simple. The Star 100 project to control data faced enormous difficulty
implementing this technique efficiently. Its vector implementation worked by reading and
writing data directly to memory. By doing so, the machine could process vectors at a limited length.
However, since the memory was slow, the processor required a long pipeline
to ensure it didn't bottleneck the system. Unfortunately, this meant switching between
scalar and vector instructions, something done frequently by most scientific programs,
carried a heavy penalty. This, combined with a slow clock speed,
resulted in the machine being no faster than the 7600 in the real world.
Crazny machine would be different. From the beginning, the computer was designed to have
excellent scalar performance. A combination of advanced wiring and packaging techniques
meant the machine could run at a clock speed of 80 MHz, more than three times faster than
the Star 100. However, it was in vector processing that the computer would really shine.
Crazny noticed that in scientific programs, the code would mainly consist of a series of
mathematical operations on the same data. On the Star machine, the result would have to be written
to memory and reread after every operation, killing performance. With a new system,
a different approach would be taken. The processor itself would contain eight vector registers,
each 64 numbers wide. Values would be loaded from memory, calculated on the processor,
and then written back to memory. The advantage was that the values wouldn't have to be written
to memory until all the calculations on the data were finished. The machine would also
feature a vector pipeline, allowing programmers to chain together vector instructions to extract
even more performance. The result was that by 1974, the team felt that they had created something
special. Testing on the newly christened Cra1 showed it could easily compute 80 million
operations per second, making it roughly four times faster than the 7600. However,
like many of Cra's projects, the software stack was unfinished, and hardware unreliability needed
to be addressed. This required funding. The company was spending $42,000 a month,
and by this time was $2 million in debt. But Cra knew a man who could help.
By every definition, John Rollwagen was exceptionally talented.
Graduating from MIT with a degree in electrical engineering, he'd worked as an intern at
control data before completing an MBA at Harvard. The man was bright, easy to like,
and charismatic, the ideal salesman. Returning to the company after graduation,
he had been the driving force behind the sales of the 6600, the most successful machine Cra had
ever worked on. His stint there was short, he only stayed for two years before moving on to work
for other companies. But Cra knew that if anyone could find funding and customers, it would be him.
Rollwagen joined Cra research in early 1975 as vice president of marketing.
At the time, Cra had recently secured a $5 million loan from a bank,
assuring Rollwagen that he had plenty of time to find further funding.
However, in the first board meeting, Cra announced the loan had fallen through.
By August, the company only had enough cash to last 45 days.
Eager to impress, Rollwagen quickly managed to secure a $1 million bank loan,
enough to last an entire year, and generated a further $600,000 by selling bonds.
Cra, however, didn't want to borrow any more money. He wanted to raise funds by taking the
company public. Rollwagen was stunned. At the time, many people saw the supercomputer industry
as one in decline. Flagship machines were too expensive and too risky to produce,
and mass market machines were where the growth was, where computers were becoming smaller and
smaller. But to his surprise, investors were delighted to invest in Cra's new company.
By this point, Cra had built up a reputation of a supercomputer magician,
and with a new machine almost ready, the IPO managed to raise $10 million in a matter of days.
The infusion of funds allowed the company to settle its debts, expand,
and finish the production of the Cra one. Now it was time to sell it.
To drum up enthusiasm, the first computer was leased to Los Alamos National Labs for free for
six months. As the supercomputer community were fairly tight-knit, by doing so, Rollwagen hoped
hype for the product was spread through word of mouth. And spread it did. Calls started coming
in monthly from companies asking when they could get a machine. Production jumped from two to four,
then eight machines a year. By 1979, orders were coming in at a rate of one a month,
astounding compared to Cra's original goal of one every six months.
Rollwagen, who by now was president of the company, heavily promoted Cra's genius
for marketing purposes, a technique that was extremely successful.
The company would go on to sell more than 100 units, generating over a billion dollars in sales.
During the late stages of the Cra one development, Cra began to dream up the next machine in the
company's lineup. The Cra two would feature a four processor design, akin to the CDC 8600,
which was now possible to implement reliably using integrated circuits.
The design featured four vector processors, entirely for data processing, and a foreground
processor designed to feed the vector processors and manage the system.
Development would begin in 1976, but a combination of shifting focus to a new memory-enhanced Cra
one model and personal issues resulted in more than a year passing without any progress.
To catch up on lost time, Cra proposed ditching the four vector processor design
instead suggesting a 64 processor scalar concept. But after a year, this idea was scrapped due to
compiler difficulties, and the design reverted back to the original. Even this proved a challenge.
In the Cra one, heat was removed by placing large cooling plates along its circuit boards,
running the coolant across the integrated circuits before piping it into a chiller
where the heat would be dissipated. The increased density of the new machine meant that this design
had to be modified. The Cra two would feature a significant amount of components and component
wiring, requiring holes to be cut in the cooling plates to allow these wires to pass through.
The issue was that by the time enough holes had been cut, there wasn't much of a cooling plate left.
By now, it was 1981, five years after the development had started, and the machine was going nowhere.
The flurry of administration that Cra faced day to day certainly didn't help.
The company had hundreds of employees on the payroll, and his position of chairman left little
time to work on the engineering. Cra would shortly leave this position, becoming an independent
contractor for the company to focus more on the project. With his time now freed up,
it wasn't long before Cra cracked the cooling problem.
The original idea of building the machine out of large circuit boards would be scrapped.
Instead, eight smaller boards stacked one on top of each other would be used in their place.
Communication would be handled by pins running between each board,
allowing you to stack to perform just as well as the first design.
The boards would be too difficult to cool using air, but Cra had no such plans.
Instead, the electronics would be submersed in a new coolant developed by 3M,
which allowed the components to have no issues running submerged.
Progress was finally starting to accelerate, but the staff, including Cra,
were well aware that the project was in its sixth year of development, and still years away from
release. The machine would also have competition, not from another company, but from within.
You see, Les Davis, close friend of Seymour and the co-founder of Cra Research,
had witnessed the damage the 8600 project had done to control data 15 years prior.
Thus, when the Cra2 project started stalling in 1979,
Davis led a separate effort to develop a replacement to the Cra1.
The computer would be designed using the company's new hot-shot engineer Steve Chen,
a Taiwanese designer who studied parallel computing at the University of Illinois.
Upon hearing about this effort, many of the Cra2 team dismissed the project.
They saw it as corporate, uninspiring, and jokingly referred to the new machine as the Cra1.5.
The machine would be an evolution of the Cra1 design, but with significant upgrades.
For one, the design would use new integrated circuits with improved density.
The number of logic gates per chip increased from 2 to 16.
Inside the casing would lie two central processors,
sharing a 16 megabyte memory pool. Finally, memory bandwidth would significantly improve.
Each processor would have four parallel connections to memory, compared to just one on the Cra1.
Even though Chen's team had started just three years ago, by late 1981 the machine,
dubbed the XMP, was fully operational, and at two and a half times faster than the Cra1,
it gave the Cra2 a real run for its money.
The Cra2 did eventually launch in 1985, but it was barely faster than the
four processor CraXMP that had launched a year prior.
The machine had its niche. The advantage of the Cra2 design was that it could support a huge amount
of memory. At launch, the machine was fitted within an almost 2 gigabytes, 32 times that of the
flagship XMP48. The Cra2 was a supercomputer in the traditional sense, built without compromise
incompatible with the previous generation and designed for a niche audience.
But the truth was, the times were changing. Customers wanted compatibility as well as performance.
Many organizations could now afford the $11 million starting price,
but the cost of rewriting all of their software pushed them to machines such as the XMP,
where few changes to their codes were needed.
The Cra2 would only sell 27 units, less than a quarter of the XMP.
The success of the XMP created a changing power dynamic.
Many in Cra management felt that the machine had saved the company.
The 10-year gap between the Cra1 and Cra2 would have been difficult to survive without it.
Steve Chen was handsomely rewarded, becoming vice president of engineering,
and was selected to design the replacement for the XMP, the YMP.
This machine would be a further evolution of the original Cra1 concept.
It would feature up to eight processes and advance the VLSI integrated circuits,
which improve clock speed and simplify the cooling system.
Like the XMP, it was also compatible with code written for prior machines.
However, Chen wanted more.
He felt that Les Davis, whom Chen reported to, was not giving him enough freedom on the project.
He wanted to push the YMP beyond an evolutionary design,
using a dual-pipeline and complex new circuitry.
But Davis, now a veteran of the industry, had seen ambitious projects
spiral out of control too many times, and the YMP was too crucial a product to experiment on.
Despite this, he couldn't leave Chen empty-handed.
He was a brilliant engineer, well liked some of the team's staff,
and it would be unfair to simply ignore his demands.
The two came to an agreement. Chen would work on a new, far-reaching development,
the CraMP, and Davis would oversee the YMP to completion.
Meanwhile, Cra1d started work on his latest machine, the Cra3.
The architecture would borrow much of its design from the YMP,
but would now feature up to 16 vector processors.
The most significant difference between the Cra3 and any other machine
was the use of gallium arsnine semiconductors.
Compared to traditional silicon, gallium arsnine transistors ran cooler,
and were much, much faster.
The issue was that no one had ever mass-produced any,
requiring the company to develop them all in-house.
By 1987, the company was bleeding cash.
It was funding the Cra3 project, Chen's MP venture,
and the beginnings of a YMP successor called the C90.
The last few years had been incredibly profitable for the company,
but like control data before it, it had simply grown too fast.
The YMP was still a year away from release, and sales of the XMP were slowing.
Cutts had to be made.
The Cra3 project was spanned off into its own company,
Crae Computer Corporation, with Crae himself being an independent contractor.
Chen, hearing that his funding was being cut, was furious,
and also decided to follow his own path.
Along with other engineers, he would soon leave Crae Research to
found supercomputer systems incorporated, or SSI,
to build a machine even more daring than the MP.
Only the C90 would remain in-house.
The reality was that the supercomputer market had not only stopped growing,
it was shrinking.
The fall of the Berlin Wall and the collapse of the Soviet Union
led many governments to re-evaluate their defense spending.
After all, why spend billions of dollars to defend against an enemy who no longer exists?
The end of the Cold War drastically reduced supercomputer sales,
which were already struggling as a result of a recession
that had hit many Western countries.
The Cra3 would never be commercially sold.
Only one unit was ever produced, loaned out for free to a government agency.
The company would go bankrupt shortly after, and Crae's design would never be used.
Chen's new company, SSI, followed a similar fate.
By 1993, his company was also bankrupt.
Only the C90 would see the light of day, selling moderately well.
The 1990s brought in a new era of massively parallel systems,
replacing a small group of custom processors with thousands of desktop-class microprocessors.
For many years, this concept was dismissed by the industry,
as the performance had always lagged behind ground-up designs.
However, the massive cost of engineering custom systems,
combined with significant advancements in Gopala technologies,
made the traditional approach harder and harder to justify.
It was the microprocessor vendors, Intel, AMD, and IBM,
who would reap the benefits of these new approaches.
But the impact of Crae's designs, along with the engineers around him, are still felt today.
Technologies pioneered by Crae, such as pipelining,
superscalar architectures, load store units, and SIMD processing,
form the basis for all modern microprocessor designs.
Some estimate that today's microprocessors would be decades behind if not for Crae's work.
The Crae 3 and its successor, the Crae 4, would never have any success.
But it didn't matter. Crae's legacy would live on, forever.
