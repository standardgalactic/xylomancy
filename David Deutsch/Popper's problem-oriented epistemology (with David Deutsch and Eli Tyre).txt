You're kind of taking on board Popper's idea that, that ideas doesn't matter where they come from.
And what matters is what happens to them. So what happens to them in your picture is that they are subjected to criteria.
Specifically ideas that I would call goals. I think it makes more light. I think there are more time kinds of critique that are available to other sorts of ideas.
Like, for instance.
Yeah, if I'm evaluating a scientific theory, I guess, I guess maybe I would, I could still reformulate that as criteria.
But I'm going to compare it to different kinds of ideas, depending on the sort of idea that I'm thinking about, like, like the sort of idea of like, should I go to the gym today or should I walk to the
grocery store and get a chocolate bar is it has some different considerations as to whether or not I'm going to accept it even tentatively then asking the question.
Like, do I think there's a tree outside or is it raining or what is the fundamental nature of physics.
So all those things you've mentioned.
None of them are our problems that none of them take the form of problems, which according to Papa is where thinking actually begins.
So a problem is a conflict between ideas.
Yeah, that's an aspect of problems that I've mostly stressed.
I'm not sure Papa would put it that way.
I want to say that many problems are the form of conflicts between ideas.
But but many aren't and he would say that even an amoeba has problems, but it doesn't have any ideas.
And still, I think, I think the conflict between ideas idea is still there, even in those cases, even an amoeba.
The problem is the implicit problem of surviving in an environment and the conflicting ideas are basically the existing genome and a mutant.
And until you have an existing genome and a mutant, there's no evolution.
There's, there's, there's no natural selection.
Yep.
Nothing can happen.
And the, the, what's more, well, nothing can happen until the solution has already been guessed.
So, again, it's important in evolutionary biology.
What's in common with the amoeba and the person who's going to go down the road to fetch a hamburger or whatever it was, was the, the, the thing it is that that the
the idea comes first.
It's, it's, it's, it doesn't, it doesn't come from wondering what I should do, unless that's a problem to you, unless the, the, what I should do is a, is a place in your mind where there are conflicting ideas and that
the problem has, has come to the top of your, of your scheduling.
Okay.
Ideas but, but normally when we, when we go to get a hamburger when we, when we put one foot in front of the other, we're not wondering where should I put my foot, where should I put my foot next, we're not doing anything like that.
We just have an existing idea. And since there's no problem, there's no thinking.
My guess, so I'm not sure if this is a tangent my guess is when you are literally walking. There is in fact a bunch of little bits of conflict, where you have sense data, although I think we may need to clarify what sense data
is saying sense data are ideas.
So, although also theory laden.
Okay, so sorry, go on.
Like you put your foot down and you have like a little bit of like sense of being off balance or on balance and there's a bunch of low level processes that manage this such that something goes a little bit wrong and you correct it.
There are things happening in the human body, like, like the immune system. Yeah, which is also reacting to things.
Doing one thing stabilizing itself doing another thing, changing levels of importance and so on. None of that is thinking. None of that is creating knowledge.
There are things that the brain does also that aren't thinking they are they are just automatism.
So, when when I wonder what three times five is what I'm actually doing is just retrieving a memory. And if I accidentally retrieve if there's some corruption and you know this memory was formed by wrote learning
somewhere sometime in my childhood when something was messed up in my brain. And therefore, I, the only thing I can think of when someone says what seven times three.
I think of 21.
But, and if I accidentally think 31, then it might be that an error correction process comes in and but what it's doing.
We can anthropomorphize it by saying, Oh, the 31 sounds a bit wrong, let's go back to try to retrieve our memory and do some error correcting on the memory, and then let's get back to 21.
That's all things that that happen.
They happen in the brain, but they are not creative.
They're then they're not creative thought. And similarly, there's lots of things that an amoeba does most of the things that an amoeba does aren't part of evolution.
I mean, any of them can be part of evolution but but it just mostly what an amoeba does is enact its existing theories, which have within them.
Algorithms.
Okay, so let me let me see if I can summarize that.
So, so in human bodies, and in systems in the world there there are. Yeah, let's start with human bodies in human bodies there are a bunch of systems that I would say are epistemic.
Although maybe that is too strong, like, like the immune system in particular does something that looks like learning, it will encounter some stimulus and it will store.
I guess you wouldn't say it creates knowledge per. I actually I'm not sure if you would say it creates knowledge it sounds like not definitely doesn't.
It's, but it does do something like store memories.
Yes, so does a single bit of computer memory. Yeah, okay, okay, doesn't learn.
Okay, that seems right. All right, so there are there are many processes that store knowledge in various ways or reflect the state. Yeah, so so you can you can write an algorithm that will take in some input and produce some output and some of that
output might be and now store this in memory.
Like, in fact, yes, you know, I have in fact written algorithms that do that.
And you might also think of like a sunflower, which is apparently responding to the world, like it, the face follows the sun. But again, if you look at the details of it there's like some specific.
There's a specific process that the side that's that's in the shade grows a little bit faster and so it tends to lean towards the sun.
And that that that algorithm that the sunflower has. Yeah, that does contain knowledge. But what the sunflower itself is doing is not generating any knowledge that knowledge was generated over a million years.
Yeah, natural select natural selection.
Okay, that knowledge is already there.
And no new knowledge will be created under until there's a problem.
Okay, give me a moment to think about that. No new knowledge will be created until there's a problem.
And then probably not even then but but it's only right.
All right, you know when the combine harvester comes.
It may cause a problem in some sense but but usually it'll just result in death.
But the sunflower's knowledge arose from those few cases where death where some ancestor of the sunflower survived death. Yeah.
Right so so I definitely don't think that the sunflower is accumulating knowledge. I do think that it didn't if there is knowledge embodied in its structure.
Yes.
But humans only acquire knowledge when they encounter a problem.
I'm not what about just playing out logic, like I start with I start with a set of premises and there there is implicit in those premises, a set of conclusions.
I might not start out knowing although maybe you would disagree with that I might start I might not start out knowing the conclusions of some logical premises.
But if I sit down and think and write it out on a piece of paper. I'm like, ah, this, like this mathematical proof is actually kind of surprising to me, but it turns out this is the case.
I knew I had all of the, like all of the pieces all along to derive that, but I actually need to sit down and derive it. And at the end, it seems like I have new knowledge.
It's a good example because I also think that isn't knowledge either but but looks looks much more like, you know, simulacrum of knowledge that than than an amoeba or or a sunflower.
So, what happens much more often in regard to mathematical proofs is that somebody can learn a proof of my heart can verify each step, according to rules of inference.
Yep.
And then doesn't understand it at all.
Yes, I'm also familiar with this phenomenon.
So, all this goes to show I think that proving is not the same as understanding and following an algorithm is not the same as creating knowledge.
Okay, so I agree that proving is not the same as understanding and it seems like the thing that you're saying is in order to have understanding from a proof, there's also resolving problems, which does relate to like that does reflect my experience of doing math.
Yeah, like I will sit down and I sort of have a bunch of intuitions that I'm working through I'm like, it seems like this, but yes. Okay, but what about with this thing and I sort of pushed those two ideas together until I'm like, okay, yeah.
All right, and you're that that's resolving a problem.
Yeah, and knowledge is created there.
Yes, and it involves a lot of conjecture involves a lot of false conjecture.
So, and that is not written in the proof. It's not in the proof.
You're guessing what you're really guessing in the case of learning existing knowledge. You're guessing what was the problem situation in the author's mind.
The problem situation that he tried to write down but but wrote down that you can never write that down fully or even, you know, partly fully, you write down basically a set of clues that that will help the next person maybe to get there faster than you did.
Hopefully, I mean so far it's working civil is like, we don't all have to completely reinvent calculus each time.
We're able to train people in calculus without them needing to do what Newton did. Yeah, well, like with many things in the educational system, learning calculus usually means learning the algorithms.
Yeah, fair enough.
And, and never understanding it and and you know people people get to get to university, and then they see that that the understanding that they had of calculus, which was wrong, and, and the things that they thought were sort of self evident were actually
wrong. And then they learn this kind of better set of things for how to pass university exams, then they become graduate students, and then they're like, Holy shit. That was all false.
And eventually you realize the calculus like all mathematical ideas like all ideas are.
They're not, they're not.
They don't come from anywhere they they are conjectured that they are they are calculus, for example, arises out of problems it arises out of problems like Newton had what on earth does it mean to have a velocity at an instant.
A velocity means rate of change of something rate of change of position.
Rate of change means the difference between one one position and another position.
So it inherently involves two different positions.
So, how can the instantaneous velocity at one position have a meaning.
And he struggled with this idea mean while Leibniz was struggling with the same idea in the cross continent and they weren't trying to find an algorithm that they were guessing.
Yes.
Most of the things they guessed were flat out wrong in the sense that they didn't even solve the problem that these people had. Finally, they found ideas that did solve the problem, but later generations of mathematics and mathematicians were like, Okay, it worked but that doesn't mean it was true.
In the 19th century, people worked hard to try to construct something that was true. In the 19th century, what they thought would clarify everything, you know, and get rid of these possible mistakes.
Yeah, by proving everything. And so they evolved better and better methods of proof until in 1900, the great German mathematician Hilbert David Hilbert.
He put out a challenge for mathematicians to demonstrate a method of proof where if something passed the test of being provable by that proof that it was true. And if it didn't, then it was false.
And girdle proved that that was impossible. Yeah, you can't do that.
So, there we are that they in mathematics you can actually prove that mathematical ideas don't come from anywhere.
I am, I'm not sure that I buy that in full generality.
I can't show that a Turing machine.
Any given Turing machine will halt because you could have an algorithm that asks whether or not it halts and then if it doesn't keeps going and then feed that to itself.
You can't show that it won't halt. Yes, excuse me.
Yes, in general.
So therefore, although there's such a thing as valid programs and invalid programs.
There is no program that can tell the difference.
Okay, which is a kin. Okay.
Because we can.
And that is akin to
there are true ideas and false ideas, but we can't distinguish between them.
There is no, there is no reliable process for distinguishing between them. What we can do is find errors.
Which is sort of like noticing that some particular machine halts.
Yes, on a particular input. Yes. Yes.
Right. Having an explanatory theory that a certain program won't hold. For example, if the program is finding prime numbers.
Yes, you can actually form a theory of prime numbers, which tells you that that program won't hold. But that theory of prime numbers depends on the theory of integers, which girdle proved cannot be proved consistent.
So it's, it's a conjecture.
I think there are simpler cases like you could, you could posit a Turing machine that just, you know, it's only instruction is it takes whatever's in the, in the current register and moves over one, and then takes whatever's in that register and whatever it is it moves over one, and I can look at that I'm
like I'm pretty sure that's not going to halt because of.
Yes, but the, the obvious, the axioms that you use to prove that.
Okay.
So the particular, you know, pretty straightforward application of the axioms, but trying to prove the axioms is impossible.
Yeah, so the axiom is for any integer, there is an integer one larger than it.
And the process that that searches through the integers will not find a last one.
Yes, okay. And those, those are the axioms that set up the arithmetic of the integers. And we think it's true. We're sure it's true. It is true.
What we can't do is derive that it's true from anywhere. Yes. All right, so just summarizing where we're at.
We have some ideas.
Yeah, so first of all,
working out some computations is not the same and does not necessarily lead to getting some new ideas. Yes, at least
for human beings, although I'm just, I mean, I have like some footnote there, like, would other, is it, would it be different for other entities?
Understanding something is not the same as deriving it.
Yes. Also, incidentally, we can't really derive anything from, from like the root, the very bottom, because there's no bottom that we can use.
Yes, somewhat unfortunate, maybe, or at least disappointing, but you know, we humans are figuring out how to deal.
It's the only thing that makes life worthwhile. Yes.
All right, well, it sounds like you don't think it's disappointing.
It's hard for me to visualize the like, I'm not even sure exactly how like the world where there is a bottom might be just very radically different from our world.
Okay, we can't derive it. We can't derive anything from the bottom. I think I do think that that's true for a number of reasons, which are maybe all actually isomorphisms of the same reason.
And so the thing that we're calling knowledge in this context is conjecture, where we're starting from where we make some guests, we,
okay, so actually we make a bunch of guesses, and then we look at the guesses next to each other and we're like, well, this we starting from this one has logical contradiction, maybe not necessarily logical
but we're born with guesses. Like, yes, we don't like, we don't make them all we're born, we have some inborn ideas, and they have inborn they they have conflicts with each other.
Okay, we're born with problems.
Can you give me some example. So I also think that we are born with guesses. But can you give me some examples of the sort of thing that you're thinking about.
Poppers, one of Poppers examples is that a baby is born with the expectation that there will be a breast there and what it will look like.
Yeah, and what it will look like.
I'm not sure if that's encoded actually but
what it will feel like or whatever I mean.
Okay, stimuli make it make it go towards that and do the right thing and some make it go away from it and do the do a different thing. And these this expectation is never perfectly met.
The baby has has also other expectations and other knowledge.
Some of it inexplicit I mean all of it in explicit but some of it, like not directly encoded.
So,
immediately.
I want to ask what you mean by it's not perfectly met.
The expectation is not perfectly match that is that because there's like a very.
We couldn't mathematically crisply describe what the
No, it's like.
So if let's say that I mean we don't know how any of this works so you know how to just make up stuff about how to make a baby, we couldn't make a robot that behaves like a baby.
So, one thing is that some of these expectations are also desires desires for certain sensations.
So, when it's drinking milk.
It.
It is not satisfied with the state of drinking milk.
Because the that that whole process involves being unsatisfied so that you drink more.
And then you come to a place where drinking milk is actually unpleasant.
Because you're so you're, yeah, when you're full but but it's not exactly when you're full because the physiological mechanisms aren't perfect either.
They are just a guess as the evolution made as to as to what would be best for babies and that's not perfect either it's it's a in fact, it's a cobbled together compromise.
Because the sensory apparatus isn't good enough to to detect the exact criterion of when the digestive system is you know the.
So, anyway, at the end you have a conflict as well. So the baby decides whether to how to cope with the problem of the pleasure of getting more milk with the discomfort of being full.
So, at some point, I think sooner rather than later with with with something like a dog, they have similar ideas for newborn behavior, and they have also an inborn criterion for choosing between them.
And if you get, if you get, you know, 100 different puppies, and put them in exactly the same situation, they will start and stop drinking at exactly the same moment.
You know you will be able to see how what the difference was in the environment that triggered the, the one response rather than the other. And that's why there is such a there is such a thing as a book on canine newborn behavior.
Okay, and you're claiming you're claiming this is not the case for human infants for humans, it's already mind guessing it's already not true for babies.
You know I haven't I haven't got strong evidence either way but I would certainly it's possible that there's also an inborn criterion for this specific thing.
And they're balancing the pleasure of eating and the and the discomfort being full. Yes, but the, the, the thing is that that babies.
At some point, very early on, they do things like learn the meanings of words.
And there we know that there can't be an inborn criterion because, at least it's very hard to imagine that there's an inborn criterion, because everybody learns different meanings for all the words and for the grammar.
And so no two people grow up learning the same language. What is the problem that is solved by learning language.
Oh well the baby learns to improve its environment by understanding and speaking.
Before it can understand and speak. It can't say that it has a stomach ache.
It can scream but it would scream in for many other reasons as well and and people have to guess what the reason is once it can speak.
It can form a theory. By the way, note that it doesn't know that it has a stomach ache it guesses that it has one.
It can form a guess and it can correct errors in that guess.
And it doesn't know in the sense that none of us really know anything.
I'm saying that there isn't a deterministic connection between various states of nerves in the digestive system and various states of preference in the brain.
Again, there's only a loose connection, which is initially formed by evolution.
It's very crude. There's things like referred pain. You can have pain, which is actually caused by one part of the body that appears as a pain in the other different part of the body, just because the sensory system is not.
It's just a crude lashed up system.
Alright, I think I think there's maybe two things there I could be maybe hearing you to say at least one of two things.
So I'm surprised to say here you say that it wasn't deterministic. It seems like seems like ultimately, all of this has to be able to be described in terms of the interactions of particle fields, which are deterministic.
Many worlds for granted know that you can have a perfectly true theory of particles.
And it will tell you nothing about the behavior of babies.
It seems like if I have, if I have a detailed enough model of both babies and a theory of particles, I will get something about the behavior of babies.
In order to do that, you would have to have a model of the knowledge creation process in a baby, which would be a baby, it would be a person.
That is sufficient.
So definitely.
It may even be necessary.
Okay, hold on. Let me let me say that because part of the thing that a baby is doing is creating knowledge in order to predict what knowledge it will create it will you need a process that itself creates that knowledge and therefore your your computer simulation for predicting the baby is itself a baby.
Yes, and can't be predicted.
And can't be predicted. Why, why is that it seems like suppose I took all the particles in a baby.
Well, you know, we may have some problems that we take all the particles of a baby, we measure where they are and where they're going.
There's where our problems are.
And then this point you still don't know right, you have to, you still can't predict what the baby will do you have to put it in put all those atoms, the positions and everything into a computer.
Yes, that runs physics forward still don't know until you get to the point that you were wondering about you know why is it doing this and not that.
Um, yep.
So you've got a baby there.
And you can't predict what it will do until it does it.
Um,
in your program.
Uh, oh, okay, I see, I see, but, but I, it's a, I can't predict in my program what it will do before it does it.
But I could run the program, like if I take to literal to the, to the, the particle level clones of two babies, and I run one of them forward in the same conditions, and then see what happens at time step and then I can also predict that at time step and for the other baby.
And then something will happen. Is that right. You've set up a situation where predicting some, some baby is retrojecting another one.
Yes, yes, that's exactly right that is, that is what I'm trying to do.
So you, so basically, you cannot predict the growth of knowledge because, because the only like certain types of knowledge, because the
one that predicted it would be the process that you're trying to predict.
And it's only after so the, the baby, you know, call it Fred Fred is normally instantiated as a bunch of proteins and and carbohydrates and stuff, but you could also instantiate that person in a computer program.
There is also Fred.
There is no way in which that's not Fred that they are both Fred.
Although I might give, I might like say Fred one and Fred to just to like, keep it Fred one and Fred to behave the same which we are assuming, then they are the same person.
I'm on board with they're the same person and you okay and you're like well you can't predict what Fred does like in general you can't predict what Fred does, because in order to do that you need to just watch what Fred does.
Yes.
And then you can retroject it.
Right.
All right.
So there's there's something different about knowledge creation from other physical processes.
Here is where there is a weakness if you want to find a weakness in my whole position about this. Okay, what is that thing that's different was was the thing that makes creative computer programs different from non creative ones.
I don't know.
All right.
That's problems of our age.
Is there a reason so this is also not the, okay.
It's so the reason why it is not the case so I can look at a bit of Python code and be like, and work through the logic and predict what the Python code will output without running the Python code itself.
And this is running it in your brain.
I, yeah,
I'm an explanation of what it's doing.
Then you might be able to predict what it's going to do without running it.
Yeah, so I, there are, I can either sort of work through the code step by step and be like and now it, you know, this variable goes up the for loop and goes down again and I sort of keep keeping count maybe on paper, and that that's just running the algorithm in my head.
Yes.
I could also do something which is more like a mathematical proof and being like, well, if I'm starting with these conditions, I know that the output can't be outside of these bounds.
And that that's a different that is a kind of prediction of an algorithm, which is possible for my Python program, at least in some context, but is not possible for Fred, because
because basically because I there's no way to to prove what Fred is going to do short of simulating actual Fred. Yes, that is my guess.
I mean, I do expect, particularly in the in the long future, when we have, we are much better at just instantiating agis.
When we want to be this thing where I can predict and and I can predict some instantiation of an agent by retro dicting what another instantiation of an agent did is pretty practically relevant.
It means that it is in practice, I can have a deterministic model.
Actually, that's not quite right, given some conditions or some inputs, I can have a deterministic model of how a individual develops through time.
And that may become relevant as this discussion progresses.
But as it stands. Alright, so, so it is both the case that human beings are deterministic, they're defined by the laws of physics, at least as best we can tell, be
not even sure exactly what it would mean if they were not
but also
you can't predict what a human does without
just having the human do the thing. Yes.
At least in full generality, like sometimes I will like, you know,
I, if I, I'm going to like poke a person with a needle, I predict that they're going to make a sound.
It depends. Yeah, but but as I said, many of the things that humans do are not knowledge creation.
So so long as a human is doing something that isn't knowledge creation, they're much more predictable.
Right. Okay, because human humans are are animal mechanisms, and also have some knowledge creation machinery.
So let me think of if there is a counter example of predicting knowledge creation.
So, so I'm so one thing that I might do is I'm like, well, Moore's law has held pretty well.
I'm predicting that we will somehow I'm not sure exactly how of course because if I did then I would make a lot of money probably.
But if it's somehow we will figure out how to get, you know, even fewer transistors on to these chips.
I'm like pretty confident in that prediction. I mean, I have been paying that much attention I hear that Moore's law may be failing lately but
that's a kind of predicting the growth of knowledge.
In vague terms, I'm not saying specifically what knowledge will create I'm saying we're going to create knowledge which allows us to do something in this category.
Yes, so you, you, there are aspects of the situation that that that you can guess will not be affected by the growth of knowledge.
Like for example, you know that the bits will not be stored in in something smaller than atomic nucleus.
So something has to give by the time we get there. Also, you know that the way that progress has been going.
Basically, it has been an implementation of the same idea in higher and higher resolution.
So the idea has been an array of bits of memory that the memory is divided into bits they are addressed in certain ways that there's a microprocessor which has has certain elementary operations, which we know as a matter of logic.
So how what they are and how they would fit together. So the problem of making the same more transistors on the same chip or smaller transistors is, is a problem of just implementing things smaller.
You could guess that originally when they used optical.
What's it called anyway, optical systems to photographically change something which then allowed acids to etch into the silicon or however they did it originally.
And later you could predict that well you could get a higher resolution if you use ultraviolet light, instead of visible light, and that that will, and then you can guess what it would take are there any fundamental reasons for, and so on.
To the extent that it's an purely, well I want to say purely engineering problem but that's that's to denigrate engineers I mean they they have to be creative as well.
They got a lot of problems. Yeah, but they, right, but they, the problems they, they are solving is how to do it.
Yes, than what to do so you can guess that that's not such a big deal.
For instance, inventing the computer in the first place. Yes, you're forecasting the future and you're like, if you don't account for will have artificial computers that's like a big difference.
Even the, even the subscaling down thing didn't go smoothly.
There were various places where there were hold ups there's a hold up right now, I believe that none of the big companies are managing to get the bugs out of whatever the latest thing is cool.
Huh. Okay, you know, Moore's law has sort of got a bit of a glitch if you look at microscopically predicting Moore's law is not a case of predicting growth of knowledge.
At least in the sense that you mean it here. Yes. I mean, like there is, there is an important sense in which we're predicting something that I might call the growth of knowledge, but there, there's also an important distinction.
So, the big picture this is pointing towards. Yeah, is whether we can say what what we can say and what whether we can say certain things about the behaviors of knowledge creating systems, whose design we don't know yet.
Yes, that seems right. I mean, I think we can know some things about them. But yes, that is that is where we're going. At least I hope so.
Okay, so, so babies have some inborn ideas.
And those ideas that have some inborn ideas that are in conflict humans start out with some ideas in conflict.
Well, that may be misleading with the thing. We have some ideas which come into conflict as as they are executed. They come into conflict.
I'm not sure that static ideas can be in conflict. Yeah, okay.
Fair enough.
And also, I'm not sure if this is relevant, but you're claiming that that doesn't happen for other animals.
Yes.
Yes, they do have ideas, but their ideas don't come into conflict in their execution.
There's, there's a, if, if there are two of them in conflict to fixed ideas that are that are, we would say, naively are in conflict and there's, there's also a fixed idea for resolving the dispute so they aren't really in conflict.
I think this is a little bit of a tangent, but I have sometimes seen a dog, which is told to stay, and also it really, really wants to get up, and it's like very obvious from watching the dog that it really, really wants to get up.
Yeah.
And I would definitely suggest that this is there's a conflict happening there.
It's, I'm not sure how I would assess whether or not there's an inborn criterion.
I can't just from that description, though note that when a human is very inclined to disobey a thing that he also has a strong reason for obeying. It often results in him not looking like that at all.
Because he's biding his time waiting for his moment.
Yeah, it does. There's a way that for a human, it can be much more integrated than the dog that really wants to.
Like, the human can can choose to react in any way.
Can can choose to react just like the dog if he wants to, or like a cat. Okay.
Whereas a dog can't choose to react like anything except a dog.
Um,
I think something, I think that is probably true. Although, like, I'm not, I don't, I don't think that dogs pretend to be other animals ever.
Although if they did, that would, that would change your mind here.
So I'm sure there are animals that pretend to be other animals, but genes say so.
Yeah, those animals can't stop pretending to be other animals if the conditions are right.
We can't stop is sort of interesting because it seems like humans also can't stop if the conditions are right because like for any given human behavior, it's like from the laws of physics perspective it is deterministic.
And some inputs that's going to produce some output.
We can't choose not to do what we choose.
Yes.
But we still choose on what we can choose. Yes.
For a moth pretending to be a frog.
The fact that it can't stop doing that is a limitation on what it can do.
A moth pretending to be a frog.
Oh, I see, I see, I see, oh yes, many animals, many animals are mimicking other animals.
Large eyes on their wings. Right, right, okay.
Right, okay, a moth pretending to be a frog cannot stop it. That is just embedded in its structure.
Yeah.
I'm a little bit suspicious of this concept of choice. I sort of expect that choice is a hand wavy term that we use to describe the behavior of systems that are too complicated for us to predict well.
Okay, here's the thing.
The way it's vague is that it involves creativity and we don't understand creativity.
However, that it exists is the conclusion of, I think inescapable arguments like the ones that I've just said about predicting the baby.
You know that that the growth of knowledge for example is unpredictable.
We don't know that about it, even though we don't know anything about how it works.
I mean, sorry, we do know something that's the thing.
In fact, we know quite a lot if you take, if you think that poppers epistemology is in part a theory of creativity.
Then we do know something about it but we don't know enough to program it and that that's that's the, you know, that's the important.
We don't know enough to program it yet. I, it is unclear to me exactly how far away we are from that.
Yeah, to me too. Like, I said in that article, you know, we might be just one idea away. Yeah.
Or we might be 500 years away.
Yes, and yeah, sometimes people are like we have no idea how to build an AGI and I'm like, I think it's so for one thing, it's you, it's no individual human can assert what all the humans know there's might be some human
right now who's putting the finishing touches on it as we speak.
That will happen.
My best guess is it won't be an individual human. It will probably be a large group of humans that have been working really hard with a lot of money, but you know it could be you know a guy in his garage who had some clever idea and then coded it up and then there's
a note that that the question of what is life was the plagued philosophers and scientists for millennia, and then one person or actually two people Darwin and Wallace discovered it.
Meanwhile, there were hundreds or thousands of biologists in the world, going down a completely hopeless path of cataloging insects and putting them into groups and so on and and that didn't lead to the answer and and just Darwin found the answer basically sitting in his
armchair. They, I mean he also went out and looked at it's told us a story about going out on HMS Beagle and and finding birds and and so on, but he found nothing out there that he didn't already know when he was sitting in his armchair.
The key thing that made him different from all the other people that were cataloging birds was this idea that these ideas that were already beginning in his armchair, and which he then when he went out and looked at different kinds of
what was it finches finches. Yeah, he knew what he was looking for.
And, and everyone else who had cataloged thousands of different species of things they were looking for something else and they didn't find it.
Yeah, so I certainly, I certainly think this sort of thing happens, at least sometimes where there are lone people who have very who are doing something different than what the whole field is doing.
Yes, often make progress where the whole field is missing it.
And then there's a question of when what sorts of fields does that happen in.
Although doesn't seem that crucial to me right now, I agree that it is, it is possible that the first agi maybe built by some guy in his garage.
Yes.
Okay, I guess I want to talk about creativity. So creativity is, here's my understanding of where we're where what creativity is right. So you got a bunch of ideas.
And you sort of execute the ideas, and then they conflict with each other. And then when they conflict.
There's a problem. And I guess some part of your mind identifies that there's a problem or I'm not sure exactly how that process works but you identify that that's an essential thing that the mayor fact that they're conflicting if you don't notice it doesn't
cause you to problem in the psychological sense.
Right.
Thinking is always the results of is always the result of a problem. What am I getting from this one, one thing that is new that I sort of need to reformulate around is problems are central.
Let's start from problems. Okay, so, so we have ideas. The ideas have some conflict that produces a problem. Yes, we identify that there's a problem via some mechanism.
Yes.
And we may be mistaken about that too.
Sure. Sometimes you're mistaken that there's a problem.
Well, I might say that if you're mistake, if you mistakenly identify there's a problem, but there is a problem. Yes, yes.
But it's not between the theories you thought it was between. Yeah, right.
That happens, you know, that's not a that's not just a theoretical point that happens. Yeah.
And then.
So then you have a problem, and then
magically creativity generates a conjecture.
And the conjecture is like, maybe it maybe the whole situation works like this, does that resolve this conflict between ideas. Yes.
And you.
And the process of being a human is just doing that over and over and over a million times a day.
And at various scales.
Yes.
And there's a positive here, which is we don't know anything or almost nothing about the process that generates the conjectures.
I think most of what we know is negative. We know how it doesn't work.
But we know certain things about, you know, how it can't possibly work and and and Papa is a sort of apotheosis of of understanding why lots of common sense ideas about how it must work.
Can't be true.
Okay.
So, so that that is, I think this is maybe a tangent to this whole discussion, but that is interesting to me because my current best guess.
Although the way the way we're using words is is maybe a skew somewhat so so it may turn out that when I say this it actually relates to something different in your ontology.
My current best guess is that conjecture conjectures are basically inductive and that you generate conjectures via extrapolating out from what in a long various dimensions from what things you've seen or reasoned about before.
And I think that there's some reason why that can't be the case.
Because extrapolation implies similarity.
And similarity implies a theory of what is what counts as similar and what counts as different.
And therefore the content of the extrapolation is in and that theory can be false and can't be discovered by extrapolation.
Okay, so I was with you until, and that theory can't be discovered by extrapolation.
Yes.
Somebody, you know, some, somebody down the street here might say that that he doesn't like black people because black people commit crimes.
And I could say that that's that's the wrong way of thinking about it. It's actually poor people who commit crimes.
I mean, I don't believe either of those theories but I'm just using as a very simple example.
All right.
Now, he thought he was inducing his theory, because to him he saw black people black person commits crime black person commits another crime, another black person commits a crime and so on.
And to him, you know, he was thinking that that he had induced this theory, whereas a different person sees the same data.
And he sees poor people committing crime poor person committing crime and so on. He thinks he used that.
Both of them have actually just been interpreting the data in the light of their pre existing theory.
Yeah, and have pretended to themselves I mean they don't know that they're doing this but they have reinterpreted the thought process in their own mind as one of extrapolating a theory from the data.
And actually what they have been doing is interpreting the data in the light of a theory.
And the theory came first.
Yeah, actually what they're doing is interpreting the data in light of a theory.
Okay, so, so the conjecture generation process.
Couldn't that be doing. It seems to me that that could be doing something like interpreting data in light of a theory. I'm not saying that it's not theory laden there is there is theory like background knowledge or whatever.
No one does that one isn't creating knowledge.
One, one may subjectively feels though one is, as I said, because one mistakes the, the processes being one of getting the theory from the data.
But what one is actually do what we do all the time we have a few just making a guess though it's just a conjecture you still there's still like many layers of criticism.
I mean, everything is a conjecture but in the case where, for example, the person has only that one theory about this particular issue.
Then, although it's a guess it's not a guess about this thing. It's a guess that he formed before, and it's just applying now, because it's his only guess.
So, this guess arose at some point in his past as a result of solving a problem.
But then if he solved it is satisfaction if it didn't conflict with anything that that he knows of, then it became part of him that wasn't controversial it wasn't the subject of thinking.
And then when it was used that use also isn't thinking.
I do, I do feel like we're drawing some tight lines around thinking here, which I'm not sure if I would on reflection endorse.
I'm using whatever shorthand is.
Okay, useful but but like I said, at some point in my past, I got the value of three times seven.
I printed on my brain. And now whenever I want to know what three times seven is. Yeah, okay but but that's not new thinking you're just that's that's an automatic process that is, yes, of recall.
That always I mean when we have a theory that's uncontroversial.
We can apply it without thinking.
Yes, that's what you've referred a while ago to compiling ideas. When we compiling ideas that that's, that's, that's a very good way of putting it because not only do we make it sort of automatic and therefore its application is not as it used to be part of a creative
process. It's it's just a mechanical process, but we may also throw away some knowledge. We may forget some knowledge we may forget the variable names and the sub routine structure, and only retain the machine code.
What happens when when you learn to drive. Yeah, a beginner is just thinking all the time about when should I change gear and that kind of thing, whereas an experienced driver, not only does the thing, but can't can't explain to you what he's just done.
Yeah.
Okay, I guess I want to summarize here a little bit.
When people talk about extrapolating.
They are making an error, or, or, yeah, they're always making error. I'm not sure that I would need to think further to see if I think that it's always the case but they, but you're claiming at least they're always making error, which is,
they're making some categorization schema, and they're using that categorization schema to interpret some data that they have. It's not in no way pure.
You always start with some categorization schema. And if you're like well conjectures.
You're sort of passing the buck and you're like well where did you get to that categorization schema in the first place that must have evolved from some problem that you solved where this this seemed like a good enough solution to resolve that.
The atheist would give a different answer to the question where he would say, I may not remember exactly but it must have been itself, an induction process.
So, the philosophers who in the 19th century who are thinking about induction, they would say, we have in our minds a principle of induction. Where did it come from, we induced it.
We, I definitely don't think that I think that's stupid.
It's an infinite regress and it isn't true.
Yeah, exactly.
People were quite smart.
Yeah, okay, when I say that that's stupid, I am, you know, it's like when I was reading Aristotle in high school and you could tell, you know, the parts where I disagree that would just like the margins would be filled up with many essays about how Aristotle did not understand
economics, but that's not because I'm smarter than Aristotle I just have the, you know, great advantage of coming several thousand years later after the invention of economics, which I much appreciate.
Okay.
I
there's sort of a question, it seems to me that there's sort of a question, I'm not sure how far we want to follow this because I
this these are areas that I'm less clear about myself and so I'm not sure that I can make
But it seems to me that in general in epistemologies, you have a problem of dealing with an infinite regress that you, if you're like, well, if you just trying to induce things all the way down, and you're like, well, how do you know that you can rely on induction.
Well, because of induction, you have a bit of a problem.
Also, it seems to me in what I've understood of paparian epistemology, there is a similar danger of an infinite regress where you're like, well, we generate a conjecture and then we criticize it and you're like well where did the conjecture come from and you're like well there was an unconscious process.
Now, correct me if you don't believe any of this I don't want to put words in your mouth.
I don't think that's an infinite regress.
Okay, when you, when you say where the conjectures come from I mean we.
We know where they come from. It's just that we don't know the implementation details and that they turn out to be crucial in this case.
But, but they come at the, at the lowest level of implementation, they must be random.
Or they must be random.
I mean, not random with a particular probability distribution function, but they are not their random in the sense that mutations are random.
That is, it's not that every genetic changes equally likely. It's that what we mean by random in that case is that the changes are not are not caused by any particular aspect of the problem of the environment in the case of an animal.
So it's not that the giraffe
stretches its neck to get the high hanging fruit or vegetable, and it, and then the mutations happen.
And the mutations happen anyway, whether it's stretching or not that and they come first, and any, any improvement in the giraffe's neck comes before the selection pressure applied is applied.
Yeah, so that so that is absolutely the case in the, in the case of natural selection. Yes, is plausibly the case in human in the human generation of ideas, although it is, I'm not sure that that's the only way that it could work.
But like the thing, the thing that I'm hearing you suggest is that when you're trying to solve a conflict between ideas, you start with basically a random seed, and then you're like, just going to try something random.
Does that solve the problem.
It makes all the difference that where in the process this random supposed random number happens. It's not that you start with the random seed. It's that you start with, with, say, a very high level heuristic, which is, which is then unsatisfactory in some way.
And so you want to modify it. Yeah, okay, by a heuristic modifying heuristic, and so on down to you know what about by time you're 11 stages down.
Then you have somewhere where you don't have a heuristic so that there's some process that says, Well, let's try the first thing that comes to hand.
But it's a random number generator, it's right okay you're starting you're starting with with background knowledge, but then you tweak the background knowledge to see if that works better, and then you continue a process of, of sort of,
yes, in pruning tweaking and pruning the high level to the higher level tweaks are dependent on the problem.
Okay, it's just when eventually after 11 level 11, you get down to a place where you've exhausted all the possibilities of extracting it from the problem so you just take the first thing that comes to hand.
Oh wait I didn't understand that sentence. You get down to so level 11. Is there a specific level 11 or you're just like that.
No, I mean, I'm sure it's not levels either it's because it's it's much more opportunistic than that.
Like, at the highest level, you're, you're thinking.
Somebody says to you.
Do you know that there are actually white criminals as well.
Okay, and that, and you say, No, your first thought is no that can't be. And then you think, Well, actually, I have seen newspaper reports. Okay.
It's part of a conspiracy they're just saying that.
So at this higher level.
The, the nature of the problem is has a large input in into the nature of the conjectures to solve it.
When you say a higher level, you're referring to like at the level of human thoughts as opposed to the level of the underlying mechanisms that are generating the thoughts at the level of explicit thoughts.
Got it, got it, got it.
That of less explicit and so on and there.
Yeah, and then
if the problem isn't solved by the
application specific considerations, like it.
At the highest level you're looking, you know that you're looking for something that contains phrases like white people and black people and crime, and so on.
And then at the next level down.
And, and you quickly scan through sort of various ones of those and see that that kind of thing isn't going to solve your problem.
So all of the solutions that are all of the, yeah, all of the, the conjectures that are made out of those building blocks.
Don't answer the question or all the ones that you've tried all the ones that seem promising to you.
Yep. Okay.
So you have various strategies say, well, let's generalize the problem. Yeah, okay, I'm not, I'm not talking about all the criminals, you know, so you can have a more general thing that tries to hedge your theory.
And then, then if you're rational, you'll think, well, wait a minute, am I using a hedging process that would, that would save any theory.
If it would save any theory, then it's not rational to assume it and you might not think that you might like those theories. You might settle on a theory like Marxism that explains any situation in terms of the same reason.
And you might be satisfied with that for a while you might be satisfied with that for years or you might not.
Yep.
What I was referring to happening at level 11 is that if the thing is still unsatisfactory when you've tried everything, every kind of way of changing things and every kind of way of changing criterion and all that sort of right down to inexplicit levels.
Then what will happen is that the process will just try something.
Maybe people are actually docs.
Maybe people are actually computers. Yeah.
That one is actually on point. Okay.
All right, so, so, so my, here's my story.
When they go about in the world, they have ideas. The, when they execute the ideas, they are in conflict with each other. That causes a problem. Some mechanism in a human mind recognizes there's a problem and initiates a process.
Maybe the process is actually going on in the background all the time, but a process either starts or continues of generating conjecture that attempts to, to resolve the conflict between ideas.
That conjecture process. So first of all, we don't really know how it works, but here's a conjecture about how the conjecture process works.
We, we have a bunch of background. So yes, now we're in the box of this is the conjecture generation procedure.
We have a bunch of background knowledge, and we will start by just applying our background knowledge and seeing if that solves our conflict.
And, you know, we tried that a bunch.
And then, if that doesn't work that doesn't result to come like sometimes it does sometimes you're like, ah, you just forgot about regression to the mean. Right. There it is.
Yes.
But if that doesn't work, then you might sit there and sort of modify your background ideas until you get a version that you're then you're trying the modified versions you're like, well, maybe it's not exactly.
Yeah, we were using example of racism, where we're like, well, okay, maybe maybe it's.
I have some idea that only black people commit crimes. And then I am like, okay, well, maybe it's mostly black people that commit crimes and I'm like, does that solve the yeah, I'm sort of I'm sort of tweaking it a little bit.
And then I'm, I'm continuous. So, so level one is I just try my background ideas level two is I am where again levels is sort of like the order in which we're doing things.
Again, we're all changing your initial theory. Yeah, you're changing it intentionally to meet, you know, to meet this problem. It's not a random change yet.
Yeah, you're thinking that this this kind of thing might solve the problem.
Okay, so, so I do want to flag that in terms of like in the project of designing how an API works, saying we're intentionally doing it to solve this conflict sort of leaves open, like, how exactly does that work.
I can't write code that's like now come up with a solution that yes, like it matches this conflict and ideas.
Let me just say at this point that that conjecture is only step to sort of recognizing a problem is step one conjecture is step two then there's criticism.
But, but at each point, when you notice that tweaking the problem to saying that maybe it's just mostly black people noticing that that is doesn't work is a critical process.
Yeah, and the critical process in general is is is in general also creative.
You're creating usually you're not using stock criticisms, you're usually creating a criticism and sometimes you stock criticism will do like you said, you know, it.
If you if you have, if you have a list in your mind of you sort of biases that you have then you say, well, I'm doing this bias would do it well at this bias.
So, but, but also, in any kind of non trivial thought process, the critical phase is also conjectural create creative.
And, and when you say it's conjectural, you know that means I'm, I have some conjecture, which I'm putting forward that maybe resolves the conflict between ideas.
And then there's another process which is going to generate a conjecture for why our first conjecture might not work. Yes.
And then,
we also need to critique our critique, right, we're going to generate like.
So you, you, you can form the theory that your critique has a flaw, or you cannot form that theory that the number of possibilities increases exponentially as you go along and, and what you actually choose is only a small proportion of those.
So the ones you choose are determined by heuristics of, of how you choose those things, which are themselves theories, conjectures, which can be changed.
I didn't capture that last sentence, which are themselves conjectures which can be changed. Yes, so your, your critiques are themselves conjectures, which can be changed.
So, all of this gives sort of the impression of a very busy mind, there's just like a bunch of pieces that are all both like that there's some conflict and we're going to generate a conjecture and we're generating a counter conjecture that will maybe critique the conjecture.
And, and we ain't scratched the surface yet. Yeah, right.
But just, I was just pointing out that the process I've described is grows exponentially, because at each stage, you've got the choice of whether to whether to reject the conjecture on the basis of the criticism, or reject the criticism on the basis of the conjecture.
Or form a new one of those two. So there's like four possibilities at each level. So at by the, by the time you've got to level, level 11.
It's, it's four to the power of 11.
And there's not room in the whole brain.
So you need a pruning system.
Yes, pruning system is itself.
Conjectural knowledge, which is being changed, which is subject to change.
Okay. So, so on checking that you said there were four cases you can accept to the, the conjecture. You can accept the, the criticism of the conjecture.
You can modify the conjecture or you can modify the criticism of the conjecture.
You can start trying to modify them. Yes. But by the same.
Yeah, right.
Yeah, we're actually we're calling our do epistemology function, what we can, we can sort of double click and be like, all right, now we're going to do the, the, the.
Yes.
It's like chess is it for for a human to play chess, you've got to have some drastic pruning mechanism.
Yeah, the way humans learn chess is creative.
So this, this thing is not just an analogy. That is exactly how we learn to play chess. We learn to prune up pruning algorithms and so on.
Okay, where I'm like, maybe this is a good move. So it seems like when I'm learning chess, I'm largely, I had a conversation with Lily about this on Twitter. In fact, I'm largely learning from feedback where I, I conjecture maybe this is a good move.
And then I get trounced by the person I'm playing against and then I learn turns out that was not a good move. And in that sense, the, the, at least in that situation.
The criticism part is sort of coming from, I guess, okay, it has to turn into an idea in order to operate in my mind, but the idea is well I lost that game by a lot. So something.
Yeah, but then you form a conjecture. And it's not just this was a wrong move. It's a conjecture of about more, more importantly, I think more often than that. It's, it's a question of what was wrong with my way of choosing that move.
Well, what should I have noticed.
Okay, then, you know, at deeper and deeper levels, you build up what chess players call an intuition. Yes.
You, which doesn't take the form of if this happens, then this happens, then this happens, then this happens. It takes the form of this is a position like a good attack. Yeah.
It's a very specific thing and that that that that is how we learn knowledge about chess.
That's how grandmasters could beat computer programs that analyzed orders of magnitude more cases than the grandmaster did. Yeah.
Because there's compressed theories about what makes good.
Yes, there's genuine knowledge there.
All right, and you would say that the chess program is not in the chess program, the chess engine all it does is draw out implications.
No, no, no knowledge creation is happening. Yes.
Although, I mean there's knowledge creation in the discovery of game trees.
I think that what you need to do to build the chess engine is yes, yes, that definitely yes.
Although, I don't know how familiar you are with. So, so it seems to me that I would say that Alpha go does do knowledge creation.
Yes, it may. If so, it's evolutionary knowledge creation. It's, it's, it doesn't know what it's doing.
It doesn't know what it's doing. Yes.
But, but it is doing the same thing of playing out a game tree and then learning from that which sorts of moves seem like good moves overall.
Biology does that too.
The, the, you know, at some point it changed from using RNA to using DNA, because DNA is more robust.
I didn't know what it was doing that there wasn't there was there was no instantiation of that explanation that I just gave. Yeah, in the process that it was just dumb evolution.
Yeah, yeah, knowledge very slowly and Alpha zero creates knowledge very, very, very slowly.
It's just that we don't have the number of games at place. Yes.
Yeah, so I definitely I did.
I once made a, yeah, that there's something you might call sample efficiency, which is how much go skill do you get per game of go that you play. And by this measure, Alpha zero is very, very bad compared to a human.
Because, but Alpha zero makes up for it by playing way more games than a human has a chance to play in their lifetime. In terms of specifically playing chess, it does.
But knowledge that a pro chess player has enables all sorts of other things to happen as well, such as explaining what he's doing.
A chess player can write a book saying how to play attacking chess and Alpha zero, even though it attacks better than he does can't write anything like that.
That seems correct to me whenever you have something that can learn from apparently much fewer cases. It's because the programmer has put in the knowledge that will restrict it to those cases.
Now, now, a little bit of that happens whenever you get an ordinary AI, AI, learning things in that when a human learns those things, they are because they're learning explanatory knowledge, the knowledge has reach, and they have also learned
about, for example, when they learn chess, they've also learned something about games in general, about making certain kinds of decision in general, and not others.
And the, that is because they are not learning when they learn chess they're not just learning how to win, how to win a chess.
Alpha zero is learning how to win at chess but it's not learning, for example, how to make a beautiful game.
Now, because of the way that chess players learn chess, they learning these heuristics which are connected with heuristics about beauty and other things.
So, you often hear chess players saying that okay I won but it was boring.
Alpha zero never says that. And in fact, well, I think it might be possible, and should be done should be tried to make Alpha zero not only win games, but report whether they were boring or not.
And this is a much more difficult problem but I think it's possibly within the scope of dumb AI.
By the way, I'm not convinced that that that Alpha zero is like biological evolution that that's kind of the most I can imagine it being but I would guess that it's dumber than biological evolution.
It seems to me, I have, I have heard it said that you have said although I don't want to put words in your mouth and maybe you'll be like I would never say something like that, that you think that a super intelligence is impossible, because there's
the universality of explanations, or, yeah, university exploratory universality.
And, and so there's sort of like two categories of things there are things that can generate explanatory knowledge at all, and there are things that cannot generate explanatory knowledge at all.
So, so, first, I want to see if that's about right and then I have a response to that.
These things in question being programs.
Yeah, although also we can we can specify pretty much we can think of anything as a program, right, they're all, but yes, well it's just that people say is there something which is to humans as humans are to ants.
Before answering that, I have to rephrase it in the form. Is there something which is to the program running in human brains as the programming in human brains is to the program running in and brains.
Okay, yeah, I'm, I am solid with that.
Yeah, you see that it's just conflating two different kinds of difference. One thing about an ant brain is that it only has a few K of memory and processing space, and humans have have many gigabytes at least.
There could be something that has many exabytes, which is vastly more let's say for and there certainly could be a thing like that.
Yep. In fact, there is a thing like that a human plus the internet is that.
Yeah, although also there's an important difference if it's in your head versus accessible to you on the internet.
If I could modify myself to have exabytes of memory, I think, I think I would be like that would make me quite different as a person than if you just gave me access to the internet, which is also a really big improvement.
I don't want to sound ungrateful for the internet.
I, I mean, in a way you'd be a better person like the one when they invented writing when they invent different person not necessarily better.
You, you, you.
So I agree with Nick Bostrom that in technological improvement will enable ways of being that we don't know about now that we aren't conceiving now, and which are in fact better than now.
Okay, great.
People would be better than us in a certain sense.
But I, but that is not to say that the ideas they have will be some kind of different thing from our ideas. We could have those ideas, just by plugging in some add-ons to our brains.
I think so, so I think I broadly agree with that. I don't think that super intelligences will have some fundamentally different sort of idea than humans and especially enhanced humans would have.
There are some important details about how that enhancement can work that I would want to work through.
It seems to me, though, that we were just talking about a whole zoo of conjecture processes and critique processes and fractal conjecture critique processes and pruning processes that are happening in order to generate even a single conjecture for
a given conflict between ideas in a human mind.
And as we say, we don't know how all of that works in detail.
It seems to me like there is probably a class of algorithms that do, that basically do those functions, and that if you, and that some of those algorithms are better or worse than other algorithms.
And therefore, you could you could write a mind which is much better at doing epistemology at getting better explanations faster and a mind that is much worse at that, based on the algorithms that you're using to do all of these different
conjecture. We already have that. So, so the key concept is subroutines.
We call subroutines and we know that many of the subroutines that we consciously call are executed unconsciously. Yep, wouldn't make any difference to us if they were executed unconsciously in an add on.
Yeah, so I sort of want to hold off on talking about add ons for now, although I do agree that in principle, that that's a thing that we could that humans humans could do that and it is desirable that we do that.
But I would start, I want to start by just clarifying that it is possible to have a thing which is effectively much smarter than modern humans, because the algorithms that it's running to do epistemology are better in some ways than the algorithms that humans run to use epistemology.
I still think you're kind of having the wrong picture of, of what it takes to be better.
We have, you know, I just said, our unconscious mind is an example of an add on pencil and paper is another example of an add on.
We, there's no is our house.
We're not a different person by getting a better add on until we decide to improve as a person by by by learning to choose those unconscious processes or processes in the add on, rather than others.
Okay, once there, once there are a eyes that are have developed the knowledge to use vast amounts of memory for thinking, which I think will not happen that fast by the way I think that's not the.
We are not memory limited or speed limited when the bottleneck in human thinking is overwhelmingly software.
But okay that's a different issue perhaps, but by the time ai's have that humans will also have it that it's just additional hardware that humans could also use.
Okay, so so I want to flag there's a by the time claim like like now now we're not just talking about in principle what things are possible but we're talking about technological trajectories and which ones will will reach fruition at different points in time, which is not fully a crux for
a big chunk of a crux for me if I thought, if I thought that that human augmentation strong forms of human augmentation was going to arrive before a GI, I would.
I don't think this fully solves the problems that I'm concerned about, but it does seem like plausibly we're in a much better situation with regards to these problems.
Well, it's been really fun.
