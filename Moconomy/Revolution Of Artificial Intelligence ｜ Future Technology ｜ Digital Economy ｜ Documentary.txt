Hello, Nel. It's already seven o'clock.
Wake up. It's twenty twenty seven.
Don't wake up. You have a meeting at nine this morning.
In twenty twenty seven, Sarah takes care of everything.
For breakfast, what do I make for you?
A glass of chocolate.
Looking at your last health data, I advise you to use avalanche flakes instead of soy milk.
Sarah is a virtual assistant who knows exactly what's best for you.
For your part of Squash, I selected Emmanuelle.
I crossed your data. This time, you're sure to take it.
Okay Sarah.
For your dinner head-to-head tonight, I reserved this restaurant.
It's new and already very well-noted.
It's perfect. Thank you.
Everywhere you go, artificial intelligence, like Sarah, predicts your needs and does the work for you.
Hello, Nel. We're going to start. I've prepared a contract for our last meeting.
With all of these machines working for you, isn't life wonderful in twenty twenty seven?
But let's not get carried away.
Before Sarah changes your life forever, there's another story to tell.
One with less special effects.
This story takes place behind the scenes of those businesses who are working to invent our future.
For now, it's hardly this wonderful world where machines are working entirely for mankind.
In fact, you could say it's exactly the opposite.
Humans are involved in every step of the process.
When you're using anything online.
But we're sold as this miracle of automation.
Google, Facebook, Amazon, Uber.
These digital giants are using a completely invisible workforce to keep their applications running.
There we are.
With technology, you can actually find them, pay them the tiny amount of money,
and then get rid of them when you don't need them anymore.
A workforce that is disposable.
And underpaid.
On a very good day, I could do five dollars an hour.
On a really bad day, I could do ten cents an hour.
I mean, it's...
Is it possible for you to pay less than the American minimum wage?
I'm not sure we want to go in this direction, yeah.
Whilst millions of men and women are training artificial intelligence for next to nothing,
others are being hired and hidden out of sight to clean up social networks.
You must have been told by the recruiting team that you cannot mention
that you are working for this project, okay?
We went undercover as one of these web cleaners,
working as a content moderator for Facebook.
Oh, Peter.
This is really good technique.
Oh, Peter.
There's a few things that I saw.
Those things are going to stay with me because I remember them as if it was yesterday.
To meet the workers hiding behind your screen,
we're taking you to the factory of the future, the digital economy's best kept secret.
You know, it's just like a sausage factory.
They don't want people to come in to see how the sausage is made.
I mean, I think it's just that simple.
To delve into the mysteries of artificial intelligence,
we're heading to the west coast of the U.S.
Here in San Francisco and the Silicon Valley,
the world of tomorrow is being developed.
We're heading to the West Coast of the U.S.
We're heading to the West Coast of the U.S.
We're heading to the West Coast of the U.S.
We're heading to the West Coast of the U.S.
In the Silicon Valley, the world of tomorrow is being developed.
It's the high-tech hub of giants,
like Apple,
Facebook,
YouTube,
Uber,
Netflix,
and Google.
We have a meeting of Figure 8,
a business specializing in artificial intelligence
that primarily works with Google.
Lucas Beewald agreed to spend the morning with us.
Hello.
Hello, Lucas.
Nice to meet you.
Thank you very much for your time.
I know you have a busy schedule.
Thank you.
At 38 years old, this Stanford graduate
has already worked for the likes of Microsoft and Yahoo!
before founding his own company.
Once his microphone is on,
a quick tour of their startup-style California office space.
This is our best dressed-in-play.
Cool and relaxed.
This is probably our worst dressed-in-play.
Do you play maybe foot?
I think I'm pretty good.
I don't know, maybe.
This is kind of our eating area.
This is actually where I like to work.
My coffee got cold.
And in the reception area, an impressive display.
These are some of our customers
and the different things that they did with our products.
Here's Twitter.
We help them remove a lot of people
that were kind of bullying on their website.
You know, American Express.
Is that in France?
Yeah.
You know, I feel especially proud of,
you know, something like Tesco, right,
is able to use us to improve their online website
to show better search results
so people can find the items that they're looking for.
And I don't see Google.
No, I don't know.
Do you know why some of these get up here?
Frankly, we just stopped.
Because it was getting out of hand.
This is Mr. Brown, head of PR.
This is a good scene.
After our visit, the founder explains the enigmatic name,
Figure 8.
We call our company Figure 8 because we think of it as a loop.
And the loop really has these two parts, right?
There's the humans that do the labeling
and then the machine learning that learns from the humans.
And then it goes back to the humans for more labeling, right?
So we think of this kind of like beautiful loop, right?
Where humans do the best things that humans can do
and the algorithms, the artificial intelligence,
does the best things that the algorithms can do.
And we put that together.
And that's why we call it Figure 8.
To get a better understanding of why AI needs humans to function,
we stopped joking around and get out the computer.
So here's the example.
A lot of people these days are trying to build cars that automatically drive.
Like, for example, Tesla has a system where you can drive around in a car.
But of course, it's incredibly important that these cars don't run into pedestrians.
So the car camera just sees something like this.
So it's really important that they build reliable systems that can identify people.
And the way that they learn to identify people is looking at lots of pictures
of what the car is seeing from the camera,
and then actually literally labeling where the people are.
Here's a real example of how it works.
If you want to teach a self-driving car to recognize a pedestrian,
a human, like you or I,
it first has to identify pedestrians from photos
and then feed this information to the AI.
And this process has to be done over a thousand,
even a million times over,
which can be very time-consuming.
This is where Figure 8 gets involved,
using real people who are paid to do this work.
So the task here is to look at this picture
and then label where the people are.
And so you get paid for this?
You get paid to draw boxes around the people.
How much?
I'm not sure this task,
but maybe it would be like 10 cents per person that you draw a box around.
Who do this job?
Do you have employees doing these jobs and labeling people?
Yes, so it's contractors in our network that log in and do these jobs.
What do you mean by contractors on your network?
So it's like people that log into this and then want to work on these tasks.
How many people work for Figure 8?
In this capacity as labellers.
So again, people can kind of come and go if they want to.
So there's maybe around 100,000 people
that kind of consistently work every day for certain use cases that we have.
But then there's also millions of people that log in from time to time
and work on tasks.
And where do those people live?
They live all over the world actually.
So they live all over America and then they live all over the world.
So who are these millions of people who are being paid to train AI technology?
In order to meet these contractors, as Figure 8 calls them,
we leave Silicon Valley and head 500 miles north of San Francisco in Oregon.
There we are.
Ah, success.
Jared Mansfield signed up to Figure 8 three years ago.
He now spends several hours a week working for them.
Every day, the company offers a list of tasks that he can complete for money.
For example, training search engines.
For this first one, it's showing examples of how to do it.
The query is mac and cheese pierogies.
And the two results are Annie's homegrown organic mac and cheese
and Annie's really cheddar microwavable macaroni and cheese,
which are neither of them are pierogies.
So it's saying that one would be equally bad matches.
What's the use of doing that?
A lot of it, I think, is to train search algorithms.
So like when someone sits at their computer and types a product,
the algorithm will be able to determine with more accuracy
what product it is that that person is looking for.
For every 10 answers, Jared earns less than one cent.
To get an idea of how much money he can make, we leave him to work for 30 minutes.
He's answered 180 questions over the course of half an hour.
How much have you earned?
15 cents.
For how long?
A half hour.
Which would be 30 cents per hour.
Yeah, which are pretty definitely not a livable wage, that's for sure.
Do they have the right to do this?
I mean, they have the right to do whatever they want.
I'm the one coming to them for little tiny bits of coins on this website.
And there's no contract between me and them.
No contract, no salary, no guaranteed minimum wage.
These ghost workers are paid to train software and robots
using only one rule, supply and demand.
It definitely feels like I'm part of this invisible workforce
that is kind of made up of just random people throughout the world.
And together we're kind of training what's going to replace
the workforce as a whole eventually.
Jared is very philosophical about the idea.
Still, he can afford to be.
To earn a real living, he has another job selling chicken in the supermarket
for a little more than $1,500 a month.
Figure eight is just what he does on the side to earn a little extra cash.
After leaving Oregon, we decided to take advantage of what we'd learned in America
and sign ourselves up to figure eight to train artificial intelligence.
On the site's welcome page, small tasks are proposed at one, two or 12 cents.
We chose this as our first task, drawing boxes around objects in images.
Following the instructions, it took us several minutes to draw around 10 objects
and earn two cents.
On the list of tasks, figure eight also offers evaluations of search engine answers,
Jared's task of choice.
We could also listen to conversation between the two.
We could also listen to conversations and confirm if the recording features a man
or a woman's voice and if they are speaking English.
Hi, is James there please?
We work for hours without ever earning more than 30 cents an hour.
It's difficult to imagine that there are people who work on these tasks
on a full-time basis.
We're in Maine, on the east coast of the United States, close to the Canadian border.
We've arranged to meet with one of the NET's ghost workers,
the human side of the figure eight loop.
Her name is Don Carbone. She is 46 years old.
Hello, hello, hello, hello.
Nice to meet you.
Thank you so much for your welcome.
Beautiful.
Yes, I've never seen so much.
We had a blizzard not that long ago, and then we got more.
And it's also, I think, negative seven out there.
Don is a single mother. She lives here with three of her children.
This is what subsidized housing looks like up here.
I mean, it's not bad for public housing.
She lives and works here, working on the figure eight site all day.
I'll turn it on, like I said, right before seven o'clock.
You know, get the initial stuff done.
I'll turn it, I'll turn this off at three o'clock in the afternoon and then turn it back on at nine o'clock at night.
So I'll say eight hours minimum.
So I bust my butt, though.
Like this would be the dashboard.
You could see I've done 6445 tasks since when?
Three years.
See these different badges?
You start off, you have no badge.
And you have to do so many questions and get so many right.
And then you get your first level badge.
And then when you get to level three, you have access to virtually all the tasks that are put up.
What is your level right now?
Right now, oh, I'm on level three.
I've been level three.
I've been level three for quite a while.
Dawn is considered a high-performing worker.
Figure eight, therefore, offers her more work than a beginner.
But it isn't necessarily more interesting.
I have to put bounding boxes around people.
I'm not really keen on this job.
The biggest problem is trying to find jobs that are viable.
And right now, I don't have many.
And it's definitely not better paid.
On a very good day, I could do $5 an hour.
On a really bad day, I could do $0.10 an hour.
I mean, it's not that bad.
I'm not really keen on this job.
I could do $0.10 an hour.
I mean, I have had some really, really good days until February.
Do you think this is a fair payment for what you're doing?
No, no, no, no.
Not at all.
But I live in northern Maine.
We get a lot of snow.
There's a very low job market.
And it helps me as a stay-at-home mom.
It helps with added income.
Dawn prefers to work from home because her youngest daughter,
Jane, has autism.
Here you go.
What happened?
Dawn wants to be there to take care of her
when she gets home from school at 3 p.m.
So how was school?
Good day or bad day?
Really a good day?
With her autism, I always have to be ready to jump in my car
and go get her from school.
I mean, it could happen one day out of the week,
or not at all, or three days out of the week.
And the school is very understanding.
So I mean, I have to take out the whole week
if I was working out of the home.
Dawn receives $750 in government aid every month,
which isn't enough to cover all of her bills.
This is why she signed up to Figure 8.
By working eight hours a day and five days a week,
she says she earns, on average, $250 a month on the site.
On Figure 8, the pay is non-negotiable.
If you refuse the work,
there will always be someone else to take it.
There is an unlimited supply of these ghost workers
coming from all over the world.
It's probably why Lucas B. Wald is so happy.
But he isn't the only one to take advantage of this.
Various other businesses propose these sorts of repetitive
and underpaid online tasks,
the biggest amongst them being ClickWorker,
an Amazon Mechanical Turk,
a platform provided by Amazon and its boss, Jeff Bezos,
who invented the concept in 2005.
Think of it as micro-work.
Micro-work is a platform
that allows you to make your own decisions
and make your own decisions.
Think of it as micro-work.
Micro-working is a growing concern for the ILO,
the International Labor Organization,
a UN agency in charge of protecting workers' rights across the globe.
Hello, German. Thanks for your time.
Janine Berg is the resident expert on this subject at the ILO,
who speaks to us through Skype.
With globalization,
you can see the emergence of kind of a global labor force.
Here, it's the next step.
It's really the service industry that can break up work
into kind of very short little succinct tasks
and then divulge it to workers all over the world
who compete for the jobs, do the jobs.
The price of the wages are turned down
because of this global labor supply
and the technology has facilitated this.
And it's cheap.
That's us, the main advantage.
Janine Berg wrote a report
calculating that micro-workers
earn on average $3.31 an hour
without any rights in return.
Workers' extreme vulnerability
is the key to Lucas B. Wald's business model.
After months of investigations,
we found this video from 2010
that sums up his view of the labor force.
Before the internet, it would be really difficult
to find someone, sit them down for 10 minutes
and get them to work for you
and then fire them after those 10 minutes.
But with technology, you can actually find them,
pay them a tiny amount of money
and then get rid of them
when you don't need them anymore.
While we were interviewing him,
we wanted to ask him if he still shared the same opinion.
But when we start talking about work conditions,
the Figure 8 founder seemed to lose his sense of humor.
Do you have an idea of the average revenue per hour
of your contributor?
I'm not sure.
It's totally dependent on the task that someone puts in
and it's hard to track time on the internet
because people can walk away from their computer and come back.
So I don't know how much people don't really make.
There was a report on ILO saying that
on average the people working on crowdsourcing
were paid $3.31 an hour.
Would that be consistent with what you pay?
Again, I'm not sure.
Is it possible for you to pay less than the American minimum wage?
It could be possible.
So this is legal?
I'm not sure we want to go in this direction.
Can we take this a different direction?
I'd rather this focus on more AI than anything.
Yeah, but this is the whole thing.
This is about crowdsourcing as well.
So I have to ask questions on crowdsourcing.
I prepped them for more of an AI conversation
than a crowdsourcing conversation.
I don't really want to do this.
Yeah, we can find someone else to talk about this stuff.
Okay, so you're not comfortable with this part of the discussion?
No, no, no.
You're right, it is an important part of the conversation
but I think it's just, you know, it's not the AI conversation.
We don't have time to pull up the video.
Lucas B. Wald makes a heasty exit without saying goodbye
and leaves us alone with his head of PR.
One last chance to ask how the business treats these contractors
as they call them here.
When I was working on this,
I found many people complaining, being disconnected.
And I thought I actually have to go now too.
So it's 11 o'clock.
So you don't want to speak about human and the...
No, that's not my role.
All right, I think we're done.
So only artificial intelligence, no human?
Well, that's what we were prepared for, so, sorry.
Okay, it's a pity.
To get some answers to our questions about Lucas B. Wald
and his views on his workers,
we thought we'd try a different tact.
On the day the Figure 8 founder made his statement on disposable workers,
there were other entrepreneurs amongst him,
as well as a researcher, Lily Irani, just on the right.
Ten years after the conference,
we find Lily living south of Los Angeles, California.
Lily Irani teaches at the University of San Diego,
and one of her specialist subjects
is the working culture of high-tech business.
We're lucky she has a good memory.
Do you remember if somebody reacted after this sentence,
which is very brutal in a certain way?
To be honest, I don't remember.
I remember that panel.
Everyone went up to him to talk to him,
and two or three people came up to me
to talk about the ethics of this form of labor.
This is a room full of highly educated people in San Francisco,
and nobody batted an eyelash.
How do you explain that?
You know, the kinds of people who have access to these spaces,
they don't have access to these spaces.
The kinds of people who have access to these spaces
are the kinds of people who never worked in a situation
where they wondered if they could make rent,
or they never worked in a situation where somebody gets sick
and they can't pay someone to go take care of them,
so they have to kind of take a really bad job at home.
They have no connection to the kinds of situations
of the people that are willing to do this work.
It's what happens when you go to schools
like Stanford and Harvard and Princeton
that tell you you're the smartest person
and you're going to be a future leader
and you've been chosen because you're special
and that you have the power to change the world.
A Silicon Valley elite who is out of touch
with the rest of the world,
this is the key to understanding Lucas B. Wald's logic,
although it's not the only part.
These workers are invisible by design.
They can write code and send your work out,
never talk to anyone.
It's designed so you can get the work back on a spreadsheet
if you need to.
You just see these letters and numbers
identifying the worker.
You don't see a name, you don't see where they live,
you don't see what their situation is,
you don't see unless you keep track of it yourself
have they worked for you before or not?
Do these ghost workers really know who they work for?
Have they ever heard of Lucas B. Wald?
We showed them the footage of the figure eight founder
talking about their work.
With technology, you can actually find them,
pay them the tiny amount of money
and then get rid of them when you don't need them anymore.
You're giggling over and paying people pennies and,
yeah, bye-bye.
Okay.
Now I'm going to start arguing what I do about the AIs
when they get me agitated.
It's kind of surprising, I guess, a little bit
to see they're so openly,
openly talking about that view
that they have of the workforce.
I guess it doesn't really surprise me that much,
but, yeah, it definitely kind of sucks,
I guess, when they could be paying them a lot more
or at least showing some appreciation
or maybe even some discretion.
Basically, you're saying in person,
you hide somebody for 10 minutes and fire them.
This way, you don't have to look at the person
and you just, goodbye.
So that's kind of just, it is kind of,
the fact that the head of the company is,
people are that disposable.
That really isn't right.
I don't like that.
So I like what I do when I have something to say
and I will say it.
So I'm not disposable.
Amongst this invisible workforce
hiding behind your screen,
there are those who feed algorithms for next to nothing.
It's the people in charge of tidying up the web,
the social media cleaners
who work on sites like Facebook or Instagram.
These workers are never mentioned
in the slick presentations of the Silicon Valley CEOs.
I started building a service to do that,
to put people first
and at the center of our experience with technology
because our relationships are what matters most to us.
That's how we find meaning
and how we make sense of our place in the world.
Today, with 2 billion users,
Facebook no longer has anything to do
with Mark Zuckerberg's initial vision of the site.
With violent videos, hate speech and pornographic images,
more and more content has to be deleted
and it isn't always robots doing this job.
There are, once again, humans hidden behind the screen.
Determining if something is hate speech
is very linguistically nuanced.
I am optimistic that over a five to ten year period,
we will have AI tools that can get into society
and that can get into some of the nuances,
the linguistic nuances of different types of content
to be more accurate in flagging things for our systems,
but today we're just not there on that.
So a lot of this is still reactive, people flag at us.
We have people look at it.
These people are in charge of sorting
and managing content on the network.
Facebook call them content reviewers.
According to their site,
there is 15,000 workers doing this job across the world,
in Ireland, Portugal, the Philippines and the U.S.
We contacted Facebook,
but the company refused our request for an interview.
So in order to meet these moderators
and understand their role,
we identified Facebook's main subcontractors,
multinationals such as Majoral, Cognizant or Accenture.
We found this job offer for a content reviewer
for the French market in Portugal.
Gregoire is one of the journalists in our team.
He responded to the ad and was offered the job.
Before taking off, he received his contract,
which included his monthly salary, 800 euros,
a little over the minimum wage in Portugal,
with a food allowance of 7 euros 63 cents a day.
Facebook isn't mentioned once in the document.
Even when directly asked, Accenture refused to give the client's name.
This is where Gregoire will be working,
at the Accenture offices in Lisbon.
Before getting started,
our journalist was sent to a welcome meeting.
The footage is a little shaky,
as Gregoire is filming with a hidden camera.
Hello.
Hello.
I have been in the meeting with Accenture in late 30.
I have been in the meeting with Accenture in late 30.
I have been in the meeting with Accenture in late 30.
Gregoire isn't the only new employee.
Twelve other people are starting the role at the same time.
Another French person, along with some Italians and Spaniards.
An HR representative is running the welcome meeting.
After the vacation documents and social security paperwork,
the small group finally find out which company they are working for.
But it's top secret.
You must have been told by the recruiting team
that you cannot mention that you are working for this project.
The client is really very demanding.
You cannot mention anyone that you are working for Facebook.
If someone asks you where you work, you work for Accenture.
We still have this code name that is CO.
So if I'm talking to some colleague from Accenture,
not from this project, and he asks me where do I work,
I cannot tell that I work for Facebook.
This is not allowed.
It's completely confidential that Facebook is working here at this facility.
Codenames, confidentiality clauses, and a complete ban on cell phones.
Facebook gives you the life of a secret agent for $800 a month.
And if you're the chatty type,
the following argument should shut you up pretty quickly.
Cleaning up social media is a bit like doing your family's dirty laundry.
It has to be done, but nobody talks about it.
Why so careful? What does the job involve?
We continue discreetly with Gregoire.
Before becoming a moderator,
Gregoire has to follow a three-week training program.
Moderating Facebook's content doesn't only involve
deleting violent videos or racist jokes.
It's a lot more complicated.
At the moment, the algorithms can't handle everything.
Every decision must be justified using very strict rules.
This is what we learn during the training.
Every day is dedicated to a different theme during the program.
For example, nudity, violent images, or hate speech.
On the agenda today, dark humor and jokes and bad taste.
Here's an example of an inappropriate joke about 9-11.
It may seem over the top,
but there are dozens of rules like this for each category,
which can be difficult to get your head around.
Take nudity, for example.
Depending on what part of the body you see, or their position,
the moderator can't always make the same decision.
Here's an example from the exercises
to better explain.
Gregoire decided to delete this particular photo.
But according to Facebook's rules, he was wrong to do so.
In the feedback session, the trainer offers this explanation.
If we cannot see...
If his head is not here, then it's ignored.
It's in between her boobs.
So if I don't see directly the contact with the nipple, it's nothing.
You know, that's exactly why I am having so much trouble to understand things.
You have an artistic picture of a photograph of a woman
and you show a tiny nipple on it.
And so on one hand, this is a delete because we have 100% uncovered nipple.
On the other hand, you have this almost porn photo.
And you don't delete because it doesn't feed the world.
That's exactly why I...
Yes, but you have a small problem because you're still going
from what you think in your decisions.
And we're in school to learn rules.
Applying Facebook's rules without questioning them is the number one rule.
A principle that will be drilled into you all day, every day.
There has to be a line and they drew it around that.
We just need to respect it and we just need to apply it to do our jobs.
Sometimes we'll find disagreements, but I mean, this is to the job
because this is not my social network experience.
A training program with the end goal of turning you into a machine.
Pedro worked for six months as a content reviewer for Facebook at Accenture.
He agreed to respond to our questions, but only if he remained anonymous.
Two years after leaving the company, he still remembers the numbing side of the rule.
You have to play by their game or else you won't have a job at the end of the month.
And it's got two points where I just felt I was a robot
and just doing as many pictures and videos as much as possible
just because that's the only thing I can do.
You're just there with numbers and clicking enter.
Numbers, enter, numbers, enter.
The hardest thing for Pedro is trying to forget everything that he saw on that screen over six months.
We're not prepared for it. We're not mentally prepared for it.
All these stuff, they don't really give us the input before
and it just comes to you as a shock.
It just comes to you as like a wave.
Here, have this in front of you and you can't really say yes or no to it.
If you give me a million euros, a billion euros, I wouldn't go.
It's not for me.
What Pedro described to us, the wave of shock that washes over you unexpectedly,
is exactly what happened to Grégoire.
It started around the fifth day of training during the practical exercises.
A stream of horrific images
and unbearable videos that must be watched closely in order to make the right decision
according to Facebook's criteria.
The same horrific scenes are unfolding on his neighbor's screen too.
I'm going to open the window.
Excuse me.
May I take a glass of water?
I'm not really feeling well.
I just took a break because I saw the bodies of the members,
but the people who threw themselves from the top of the tower,
they were crushed by the ground.
The nose, the body, the hands that trembled,
it was psychologically very difficult today.
It's like this on a daily basis for Grégoire and his group.
Luckily, they can always rely on the useful advice of the trainers to feel better.
If you feel uncomfortable with the process,
please warn me and we'll do a little pause, a little break,
go outside, do the macarena, okay?
And then we'll come back.
If the macarena isn't quite enough to cheer you up,
the business also has psychologists available for the most traumatized moderators.
On this day, a video lasting several minutes
brought the violence to another level for Grégoire.
Oh, Peter.
During the break, everyone tries to shake off the shock
by discussing the grim video they've just witnessed.
Grégoire was with two guys and they were playing with the gun.
And suddenly, the girl showed the guy,
but it was like, it was like,
it was like closing, closing, yeah.
At the moment, it feels very bad, like, I don't know,
but I think that they're feeling, they don't last a lot of times, you know?
It's like, at the moment, I feel very, very, very sad, I don't know,
but then I can't, like, continue.
Grégoire realizes the extent of the damage this job can cause
when talking with a former moderator who is now a trainer.
I have trouble, like, on the street,
because I just see people being hit.
Like, in my brain, I see so many accidents that, like, I cannot prove it.
I just said, fuck off, everybody is running across the street, like, I cannot anymore.
Oh yeah, you can't take it?
Yeah, it's like a kind of a mini-pity.
We've got that.
I mean, I don't take medication, but I know that, like, I have to be like this.
If I can't watch people running across the street.
Anyone.
You're still doing this while you have PTSD?
There is a purpose.
I do feel every day, like, I'm cleaning the trash.
Right.
Okay, I will watch it, but at least I know that I'm going to watch it.
Even two years after quitting the post,
Pedro still has very vivid memories of certain videos.
There's a few things that I saw.
Those things are going to stay with me because I remember them as if it was yesterday.
It's very emotional sometimes.
I remember sometimes people used to, like, they were working, being productive,
and suddenly they just stand up and run out of the room.
That's okay.
Trauma built up.
And for Pedro, left him feeling helpless.
But if you see someone getting murdered, the only action you take is the lead, for example.
You just erase it out of the platform.
You don't really go into depth of, like, calling the police, for example.
It's like, you never really feel content with what you're doing.
You're just going round and round in circles and just, like, bombard with all this stuff.
It's like a mixture of emotions that you go through in one day.
Eight hours for it.
How many were you when you started?
We were 30 when we started.
From that 30, it started just decreasing month by month.
Until now, there's only, like, three people.
Pedro claims that a lot of people struggle to deal with the role and end up quitting.
To understand what Pedro went through and what Grégoix and his colleagues are currently experiencing,
we met up with a psychiatrist.
Professor Thierry Beaubé is a specialist in post-traumatic stress disorder.
For example, he works with police officers who have been involved in terrorist attacks.
We show him the footage we filmed.
Potentially traumatic images, like those that are described here,
can have several effects.
For some people, it's just anxiety effects.
It can make you anxious for a while, sometimes in an important way, with panic attacks.
But in a number of cases, there can be what we call a traumatic infraction.
That is, one of these images, or some of these images,
will go deeper into us and bring us back to our past.
What's special about post-traumatic stress disorder is that when these images come back to its past,
they produce the same stress every time.
We also talk to him about the famous confidentiality classes imposed by Facebook.
They are used by different movements, such as sector movements,
and it makes them more vulnerable to traumatic impacts.
Anxiety, trauma, stress. Cleaning up social media comes at a great cost.
Grégoire decides to quit only two weeks later, still in his training period.
He received his paycheck just before leaving. His hourly pay, written at the top,
four euros, 62 cents gross. This is a tough pill to swallow for his colleague.
After our experience there, we contacted Accenture.
Their response was a brief email that didn't once reference Facebook.
It did, however, contain this phrase,
the well-being of our employees is our priority.
To finish our tour of the Internet site,
Trash Cleaners, the invisible workforce behind your Facebook or Instagram feed,
we had one last meeting.
Sarah Roberts is the leading researcher specializing in those who work as moderators.
She is a key figure in this field.
We met her at the university where she teaches in California.
She presented us with an analysis of the rise
and development of content moderation over the past year.
We are talking about a scope and a scale of magnitude that has not been seen before.
Billions of things shared per day on Facebook.
Hundreds of hours of video uploaded to YouTube per minute per day, and so on.
The response has continued to be,
we'll put more content moderators on it,
which means that that continues to exponentially grow.
It has gone from a next-to-nothing kind of line item in the budget
to being a massive, massive cost center,
meaning it doesn't actually return revenue.
It's not like a new product.
It's just seen as an economic drain.
And the way we manage that problem is by pushing it onto the internet.
The way we manage that problem is by pushing it onto some low-wage workers
and to do it as cheaply as possible,
because, again, that stacks up when you double your workforce in two years
that it does not come for free.
This is why companies like Facebook use subcontractors.
But according to this researcher, this isn't the only reason.
It's about labor costs, but it's also about creating layers of lessening responsibility
between those who solicit this kind of work and need it
and those who do it and where they do it.
They remove themselves.
They put themselves at a distance from the workers and their conditions.
And it's not just a geographic distance, but sort of a moral distance.
So when that content moderator some years later alleges harm
or is having trouble psychologically or emotionally because of the work that they did,
then it may be possible for that company to disclaim responsibility for that,
even though ultimately they really are responsible
because they asked them to do that work in the first place.
Despite these precautions,
three former moderators filed lawsuits against Facebook and the U.S. a few months ago.
All three were working under subcontractors.
All claimed to be victims of post-traumatic stress disorder.
The American company refused every request we made for an interview.
They did, however, send us an email to explain how Facebook, with its partners,
pays great attention to the well-being of content moderators working on its platform,
which is an absolute priority.
To finish off, here's some of the latest news from the sector.
While these ghost workers are left in the shadows,
it's business as usual for the companies working in this new sector.
A few weeks after filming,
Figure 8's founder sold his company for $300 million.
Well, at least now, he has good reason to be happy.
