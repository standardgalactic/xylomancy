Hello, I'm Gary Burke, a co-chair for this summit 2023 ontology summit, and it's March 8th, 2023.
And we are going to be doing our second phase of our ontology summit, moving into things like ontology design patterns,
wiki data, and things of that nature. First, I should say that the schedule speaker was called
away on a project that he had to attend that has made a video recording. And so we were going to be
playing a 35 minute or so video recording later in the session. But first, I'm going to do a few
introductory slides, overviewing this part of the summit. So with that, let me turn to a slide
share here, screen share, and show you my first slide. So this has a working schedule for the second
part of the summit, starting with modules and patterns with Kogen Shimizu from Wright State.
He'll introduce himself in detail. And it shows that some of the other sessions that we have,
basically things are nailed down now. So next week, we will have a design pad in discussion.
So to follow up to this session, we'd call Hammer, who's now at Google, had been at IBM.
We have invited some of the original people, such as Valentina Presuti to present, but we never heard
back from her. So we had call stepping up to do that. Following that, we're going to have a session
on Wikidata. I'll have a little bit more to say about that probably next week. And you can see
the remaining schedule here leading up to a panel, which we still are filling in, but Pascal Hitzler
will be one of the main speakers on that. So with that, let me turn to today's session. And
I thought I would introduce a little bit of the topic on ontology design patterns
and modular ontologies before we go to the video. So this is an example of a widely used pattern
actually that I was a bit involved with, which is called semantic trajectory, which you see on
the left. And you can get an idea about what ontology design patterns are. So we have a range
of concepts here. What is a semantic trajectory? How do you define it? Well, first we define it in
terms of having segments that go from and to places where we do a fix, that is, we take a sensory
measure. And this segment is traversed by some type of conceptually moving object. Most of
time we're thinking of a real physical object, but it may be a conceptual object. So it may be
something like a disease that is essentially having a course of action over time. And we're
taking measurements on disease over time. And we have a source for the and a sensor type and a
location for the fix. You'll notice that most of the box is a solid line. Yes, Gary, can you go into
presentation mode? Let's see if I can do that. Do you want me to go into slide mode here? Yeah,
make it easier to read. Does that help a little bit? Thank you. No, not so far.
All right. I'm going to go on here. My next slide tries to illustrate the range of things you might
see in ODPs, ontology design patterns. On the left, you see a rather complex pattern. Actually,
this is an early version, dealing with sensors, the sensing things, sensing features of interest.
There's actually several patterns probably composed in this. And this particular pattern,
the semantic sensor network pattern, for example, has evolved over time and improved on. Slides are
changing, Gary. Your slides are not changing. You don't see two ODP examples on the screen?
No. You're on the first slide. Okay. I'm talking about the second slide. No, we don't see. Oh,
second slide. Yeah. You do see it? Yes. Okay. But it would help if you would. Did you still see
the second slide with two ODPs? There's one diagram. Okay. Well, there's two things on it.
On the left side is a complex one. On the right side is a very simple pattern for transitions.
We don't see that. You don't see that. Gary, I think you are sharing the original window of
the thing and not what you are seeing. You want to share your screen, not an individual application.
There we go. There you go. Yes. Okay.
I was asked to change your mode. Do you see the two patterns now?
Yes. Okay. So again, to complete this is the complex one on the left, which is dealing with
sensors, information, and the very simple idea of what is a transition and transition of an event
has a starting time. It's a setting for a thing and it has a final state. So transitions from a
start to an end. Very, very simple design. Okay. Can you see a new slide now? Why ODPs?
Yes. Yes. Okay. Fine. Okay. So I wanted to provide a little rationale for some of the things
that go into using ODPs. The original idea was that it was difficult to understand and get an
overview of very large ontologies as they were growing. It was also difficult to see the effects
of a change or an extension in some concepts of what impact it would have. Also, another thing
that was said is that it's often very hard to get full agreement on all the commitments
on a large ontology. For these reasons and other reasons such as interoperability problems,
and alignment problems, understandability problems, people decided to look at these trade-offs and
maybe it would be better to start with something smaller like some of the patterns that I showed
you before. Here's a little bit more on some of this reasoning about what ontology patterns
might be like. They reflect, of course, the need to capture the reality that is in data,
common to patterns. Often the patterns in data are hard to find, but if we can spend some time
looking at that, we can sort of extract some of those patterns from the data itself as opposed
to a pre-developed top-level ontology. I have a quote here, roughly a quote here from Verna Kuhn
early on in the era when patterns were starting to be used for solving semantic problems that made
me more productive to agree on minimal requirements imposed on small notions like a pattern notion.
The idea was to use small and well-engineered, coherent, minutely constrained schemas as a start
for ontology that later could be combined, as I showed you with the semantic sensor net,
where you might be combining several different patterns. You can use very good documentation
and design rationalities and best-reengineering practice for reuse over time, so you can prove
things like the semantic sensor network over time. For all these reasons, people did try out
going to modular patterns. As they did, roughly about 12 years ago or so, Gangamy and Presuti,
who I invited to a session but haven't heard back, wrote some documentation on modular operations
and just talked about five basic types of operations when reusing them and building them.
So the first is, of course, importing them, and you can use import functionality to do that into
whatever you're trying to do. You can also specialize two types of specialization. You can
take an existing idea and specialize it conceptually and then go from there. Or you can have a
specialization done by creating subclasses and subproperties on existing ODP classes and properties.
You can also generalize an ODP and the concepts in them. And one of the most complex things,
and you saw a little bit in the semantic sensor net, the early version, is composition,
where you use multiple ODPs, small pieces, and try to compose them in a meaningful way,
fitting them together. And the last one, of course, here is the idea of, well, you may not find
an idea in a particular pattern that you want to use, and you might have to develop new patterns
for that. And here is an example of just such a thing of an expansion. I showed you that
semantic trajectory before. Here we have a portion of that trajectory on the right,
but you're sort of extending it and combining it with other things, so that a particular project
that NSF funded called the Geolink Projects used the trajectory for scientific expeditions.
They specialized the idea of what is traversing the segment to a vessel that might be going on a
cruise. And they also added other ideas on that, such as the data was gathered and put it into a
repository, things of that nature. So this is just a small example of how patterns get built and
get reused. And we'll hear more about that from Kogan and also next week from Kahl. My last slide
is just a few sources on that. This is the reference to that semantic trajectory, for example.
This is a tutorial sort of on how you combine patterns, make good patterns. This is something
on how you document patterns and so forth. So with that, let me stop the share and let me turn
the session back over to Ken, who will hopefully start the Kogan's video, which runs about 34
minutes or so, which will leave us with a little bit of time for Q&A, although he's not here this
time. He promised to come back next time. When Kahl presents, he'll be available questions and
answers. So if we have an important one, we haven't addressed here, he may be able to do it then.
So this is the recording. Hopefully you'll be able to hear the sound, but it's quite redundant.
You'll notice that the transcript is on the right and you'll also see the transcript on the screen,
as he's speaking. Hello, everyone. Welcome to my talk. Today, I'm going to be providing a
introduction to patterns and modules. And by this, I really mean patterns and modules as they
exist outside of the traditional sort of formal ontology perspective. So I'm not looking at the
modules and the patterns as they exist inside of say, for example, Dolce or BFO or any of the other
upper fundamental foundational reference ontologies, but instead coming at this from more of the
empirical data-driven side of things. We'll go over briefly the methodology and some of the resources.
So very briefly, my name's Kogen Shimizu. I'm an assistant professor over at Wright State University
in Dayton, Ohio. Some of you have already spoken with me at previous talks and some of you have
just known me for years already, but regardless, I'm happy to be here and talk a little bit about
what I'm interested in and then also the point of the talk. So a little bit more about me is that I'm
broadly interested in knowledge engineering and I mean this from the full perspective or the full
spectrum from just basic knowledge representation from any, from low expressivities of taxonomies,
controlled vocabularies all the way to full-blown owl ontologies, but this also encompasses
some of the deployment aspects and how our knowledge graphs and these knowledge bases
use and that's a lot of where this pattern-based methodology comes from is it's not just about
patterns and the knowledge, but also patterns of usage and how you can really simplify how
knowledge graphs and the constituent knowledge is really utilized and then of course the next
two things are just kind of employing knowledge engineering to do more effective open science
and more effective teaching of this material. So kind of looking at knowledge engineering from
the perspective of knowledge engineering in order to be a more effective teacher, but I digress by
now so without further ado let's take a look at the rest of our talk today. There are four main
pieces that we're going to dig into and I'll give briefly and motivation and then we'll again briefly
kind of go over the modular ontology modeling methodology or MOMO and then I have a few examples
of what patterns look like and kind of some connections to some previous pattern work that
we've seen in previous talks here and then we'll close with some tools and resources.
So the first example that I have is called the nowhere graph. The nowhere graph is a NSF funded
consortium and I don't mean that in a more formal sense it's there is no NSF consortium in this case.
By this I just mean that there's a pretty huge team. I think it's over 50 collaborators at this
point and that spans from all of the student researchers to the investigators, the collaborators
from NGOs and private industry and government agencies. It's pretty quite expansive and with
high coverage. We have a whole bunch of different data sets that come from that are contributed by
the different collaborators or we're pulling them from publicly available websites and we're
integrating them all and trying to provide a geospatial backbone so that way the representation
of spatial integration is pre-done. We're front loading the cost of doing the spatial
integration and this came with some pretty tricky and interesting problems with how to
adequately express these spatial relations and also ensure that we have provenance from all
of the different data sets and all of the different features and do the semantic harmonization and
it turns out that we did wind up using a modular knowledge graph in order to do this.
So this is what the schema looked like back in July of 2021 and into 2022 I believe and each one
of these little tiny boxes that you can see here are a module. We have an expertise module,
we have a hazard module, we have different modules for the different data sets so climate
division, soil types, storm observations, smoke plumes, things that impact the world around us
by some physical phenomena and is also of interest enough that the government at a state or federal
level is tracking them and providing data sets about them and so what we did is we identified a
pattern that exists in this observations and it's drawn from the SOSA SSN, the
sensors, observations, sampling actuators, ontology from the semantic sensor network
and extracting a core piece of that and using that as a template to mint new patterns
which kind of turn into these modules and so on and this strategy I think as both Nick and Chris
have said in previous talks is really effective for rapidly expanding additional coverage for a
domain without really having to know the ontology in and out. There's some clear connection points
to these strategies and so what this results in is this November of 2022 is this much larger
schema and I don't think this is everything either and it's also hardly readable because
it doesn't fit on the screen. It's kind of an interesting sort of catch-22. It's cool that
we've been able to integrate all of these different data sets but now it doesn't fit on the slide so
we can't really show it off but anyway the evolution and maintenance of the graph comes from
these patterns and these modules and being able to rapidly replace a module or add in a new module
based on an older module or the same pattern is really instrumental and we'll kind of go into
this in a few slides. Another example that we have is the enslaved hub ontology so the
enslaved hub is a smaller but no less important knowledge graph. It's really about identifying,
integrating and really making visible the stories of the peoples of the historical slave trade so
trying to find how a particular person might have traveled from place to place largely against
their will and with different names and different personal relationships and trying to identify
what actually is the ground truth because that's one of the hard things here is that integrating
all of these little tiny data sets from historians across the nation and around the world even
you have different interpretations of the events that occur or different interpretations
of the first source, the first-ian sources and this resulted also in a modular knowledge graph
otherwise we wouldn't be presenting it in this particular presentation but the point is that
having a way of modeling the different types of characteristics of the peoples of the historical
slave trade as well as this sort of integration of the data sets is really valuable and really
makes it easy to apply a pattern-based method towards it. This I will not get into so much
with the rest of the presentation but if you have any questions or you want to see the schema
you can go to enslave.org or if you have any questions my email is at the end of the
presentation and you can go ahead and pass on questions and I'll either answer them or send
them on to the team. So anyway let's go ahead and dig a little bit more into modular ontology
modeling so one of the things that I didn't really talk about is what is the difference
between a knowledge graph and an ontology and in this case we don't really mean them to be
too differently except for in this case an ontology is really just the t-box of the ontology
right and then we consider the knowledge graph to be a the a-box coupled with the ontology which
acts as a schema for the knowledge graph really it's just changing the different buzzwords around
in order to make sure that the work is fundable sometimes or a little bit more relatable
to a broader audience and in this case what we mean with pattern-mediated methods
for knowledge engineering and including these patterns is really including and using patterns
as a first order or first class citizen within the modeling paradigm so making sure that the
modular ontology is directly represented using annotations and this is what really drives the
ability to expand the the ontology or the knowledge graph schema based on the existing
patterns within the ontology or to yank out and say we'll we don't want this one anymore let's go
ahead and replace it with this new one and then finding all of the pertinent axioms and
underlying instances for those for those classes is quite valuable and so what we have here is on
this slide is what we call the modularity which is the patterns made out of or sorry the schemas
made out of patterns and then on the right hand side we have the metadata scaffolding and so this
is really the the kits the catchy way of saying well we're just going to annotate the schema with
additional information that indicates what pattern or module particular classes within the ontology
belong to so with this in mind the metadata scaffolding can really be thought of as the
sort of ladder right you have a conceptual component which is an extremely human centric term
which might be implemented in a number of different ways for example space and time are great examples
of this because there's so many different ways of modeling space right that we can each say that
each ways of those modeling spaces is kind of pattern is kind of like a pattern and so a spatial
extent would be the conceptual component it would be represented by some set of patterns
and then you choose a pattern and you turn it into something that's more apt for your use case and
we call that a module and then you have the instances of the modules which are really just the
shapes of the data the actual triples or the materializations of the the data that the model
module models we use a a language called opala or opal which is the better way of of kind of turning
the the acronym into into a human word which is just the odp representation language so op
and then a from pattern and then l what i have here on the right is an in progress draft of the
version two of opal and what we are trying to do here is to include even more information
about what is actually going on inside of the pattern axioms tend to follow patterns especially
within the momo methodology but there's also different ways of thinking about patterns in
terms of their representation so you can have a perspective which is really just an extremely
simplified view of maybe a more expressive version of a pattern you have documentation that's
associated with it so the the pattern will have a schema diagram and all of the different ways
that you want to represent a pattern we're trying to codify into the into this model there is an
additional there's a base opala or opal which was published in 2016 from a number of people from the
the community and we are kind of generating a new specification currently so modular ontology
modeling now let's take a look at the actual methodology it's it's nine steps we want to focus
as i said largely on the empirical data driven reality which means that we're not necessarily
always concerned with the philosophical ramifications as we are with what can we model
and what data is readily available or important to the use case at hand so you start with designing
the use case with however whichever methodology that you want with use case generation and this can
you can draw from any number of knowledge elicitation frameworks what we find to be particularly
important and we call out here is the use of competency questions i don't think this is
particularly new to the ontology modeling community but it really helps you identify
what the key notions are but also the interactions with the data and this is really where the the
empirical or data driven reality aspect comes in because if you can't really in natural language
ask a question about it then what to what extent is it useful to model beyond that
that those there's probably some fighting words in that statement but at this top level sort of
of this address here we can sort of gloss over that for now the the the interesting parts now
are in steps four five and six which are really kind of what differentiate momo from other
methodologies and that's really once you have the key notions for your use case which are extracted
from your data your competency questions your domain experts what have you you want to match those
the conceptual components that patterns model we have resources that i'll display later on in the
presentation about sorry about of all of the different patterns that we have and can be used
to sort of plug and play a schema together the instantiation of the patterns comes what comes
next and that's really replacing the terms and properties of a pattern wholesale kind of like
template starting with maybe like madlib style you're not subclassing a pattern you're just
using the structure of the pattern over and over again in step six we have the systematic
axiomatization which is once you have your patterns and you look at the schema diagram for
your different modules and your different patterns is you go edge by edge within your schema diagram
and you assign the ontological meaning of what that top level intuitive conceptual relationship is
i won't get into that so much within this talk but what we have here is the modular ontology
modeling published in the semantic web journal and you should be able to kind of get a lot more
information on the exact processes within this methodology from there after that you plug all
of the modules together with quite literally like puzzle pieces you review the final product add any
more axioms that you think are useful across the entire assembled schema and then you produce your
our artifact so that was really Momo in a nutshell so what i have here are a few examples three
actually i think and then a brief discussion on the template based instantiation that we utilize
for Momo and how it kind of connects or is quite obviously parallel to the sort of DOSP
strategy employed within the oboe community so this first pattern that we have here is a pattern
for depicting causal relationships between events this is something that came out of the
nowhere graph pro project actually the next two patterns are as well but i kind of want to show
you here how you have a pattern and then you also have a module within the pattern right this
abstract event compared to this events this concrete notion of event event for those of
you who are familiar with the upper ontology sphere this would probably be easily modeled as
your sort of perjure and enduring thing because you have a description in a situation you have
this thing that exists in time and thing that exists out of time but from a pattern perspective
the exact implementation of this doesn't matter and that's kind of the point you can implement
this pattern using an upper ontology or you could call it whatever you want like event
concrete which is maybe not a great name but kind of gets the point across these blue boxes
with the dashed lines are what we call the interfaces i said earlier conceptual components
but you can kind of think of them as interfaces from software engineering because they are an
implementation they are a hook within this pattern that says right here belongs anything
that is a model of what an observation is or anything here can be fulfilled by something that
sort of adheres to the contract of what a spatio temporal extent is
and we just note that with with the blue box and so you can replace that blue box with an entire
new pattern or you can kind of just drop it away and have it something very simplistic like a stub
and so on and so this is how we do that and this is also what allows it to kind of for
people to kind of conceptualize these as puzzle pieces because you take your spatio temporal
extent pattern you plug it in quite literally like a puzzle piece into the spatio temporal
interface within the schema diagram and then you just build out your patterns
and you modify them to your use case and then you're done right that's kind of the strength
of what we're trying to do here is by leveraging these patterns and the fact that all of the
ontological analysis has already been done it's really just the assembly and configuration for
your use case that drives the the usefulness of this
okay I accidentally reordered these sorry for flipping through a few slides there
this is another example here of a pattern we have two interfaces this time but now actually
what we have here is this purple box which is really just a controlled vocabulary it's this
it's just another sort of technicolor idiosyncrasy for our presentation or our schema diagram
presentation and it's really just saying that the the class of organization scheme consists of
strictly a set number of individuals not particularly exciting but it's something
that we can model and is sometimes extremely convenient to to model even at the pattern level
and then doing it explicitly like this instead of having a subsumption hierarchy somewhere in
the background it means that there's really no change to the ontology when you add in a new
instance for example here of the organization scheme in this case you would replace custom
with whatever you want because custom kind of doesn't belong in the in the in the pattern here
keep moving on so this final pattern example that we have here this is a pattern for depicting
features of s2 cells or any cell in a hierarchical grid so let me back up there a little bit what we
have are these cells and a cell is really just a geometry a tessellated geometry across the
surface of the earth or anybody really but in this case let's let's just stick with the earth
and then what you have is these cells are hierarchical so four cells make up the next
tessellated geometry and it just up and up and up and so s2 is one particular version of this
and that's employed by google and it's really just four cells make up the next larger cell and then
four of those make up there and there's also a way to do this using hexagons that's called h3
using it out of uber but really what what's interesting about this are these red arrows
I mentioned earlier that sometimes it's useful to have these shortcuts within a pattern a simplified
view right so when you have a cell and you want to represent it using geosparcle or
using some sort of geo informational science standard way you disconnect the cell as a concept
from its geometry which is the literal that describes the sort of boundary points of the cell
and then the spatial relations actually occur between the geometries not technically between
cells however when you're querying generally you want to know how the things are spatially
related at a human level and not just these arbitrary geometries that exist under the hood
and so having a way to specifically represent these within the schema diagram useful but also
logically under the hood as a sort of roll chain is also is also useful and we use the
opal annotations for the different excuse me for the different shortcuts to say well this is this
one's optional you don't have to actually materialize this it's it's part of the pattern but only in
so far that you may want to simplify this for for other other people so for example going from
cells the attribute of the particular feature that simplifies three hops with an inverse in there
into one simple thing but you lose a lot of the expressiveness and the ontological pitchness
there so there's there are some tradeoffs. Finally as one of our examples this here on the left is
the kwg core ontology and the sosa ssn kernel that we use the core is really just the four main
concepts that we have and some very basic relationships it's obviously much more built
out within the ontology itself but from a schema diagrammatic and also from this nice compact
view it's useful to only include a couple of these pieces but it connects into this kernel
and then this kernel on the sosa ssn kernel this pattern that we've extracted essentially from that
ontology we just essentially mint or not mint we stamp over and over again one per data set
how this connects right so the feature of interest remains the same because it's the super class
but this observation that we have here within the kernel I actually gently drew the arrow to
the wrong thing it should be to the climate observation and the observation and then you
have the climate observable property and the observable property right this is not a particularly
exciting implementation or instantiation of the sosa ssn kernel template but you can see how
um after you've kind of changed the names to be more tailored to your particular sub use case
right represent a us climate division and its climate observations there's all of this additional
stuff that's now hung off of it right we use has simple result instead of has result the observation
has a phenomenon time and then we go out and we say okay at least with this particular diagram
we say that there's hidden or additional complexity which would be implemented by another pattern
or another module elsewhere for spatial object or temporal entity
all right so we're going to go ahead and start wrapping up I have a few things for the tools
and resources and then we'll we'll end with my slide for passing on any questions to me
so the the the cool the the cool one and this is really a self insert here is called model
the modular ontology design library which is a collection of curated patterns so on
the next slide we have the ontology design patterns portal this is a huge collection
of patterns of varying quality because it contains submissions of patterns which were peer reviewed
but were rejected but never removed from the portal or they have wildly different sorts of
constraints on them ontological commitments that make them very tailored to a specific
use case and you would wonder whether or not they can really be called a pattern right
so what we did is we took out the patterns that we thought were maximally useful
and polished them up new schema diagrams made sure that the axioms were consistent gave in
some examples and and kind of organized them by category and then we described all of them
using opal right so model is actually an annotation ontology of all of the different patterns
um this what here on the right is 13 patterns in version one uh i am working on a second version
which contains 32 some of them are redundant in so far that they are alternative patterns
for the same conceptual component or the same interface right a couple of different spatial
extent patterns a couple of different event patterns um a couple of different role patterns
and so on um and then uh model is not just an artifact it is meant to be a template model is
a type of ontological collection which is a collection of patterns um i call mine model
because i suppose that's my prerogative but it could be any um anybody could make a model
uh finally i think i already said this is that the model encodes many inter pattern
relationships so it has what interfaces it provides and then conversely what interface
it implements what conceptual component in implements what are the different specializations
and generalizations between the patterns and what category do they belong to
uh we already talked about the portal so i'll move on what i have here is called commodity
the comprehensive modular ontology integrated development environment quite a mouthful
commodity is a plugin for protoché um i wrote this as part of my phd dissertation so it functions
but it is not like production quality you know it it's something to use and um to
leverage but you might run into a bug here there if you do let me know and i'll try my best to
address it or or help out but essentially what this does is it provides a graphical canvas uh
to do modeling uh with all of the power power of owl uh and the coup de grace so to speak would be
the uh pattern library which is the number two you can actually drag and drop all of the patterns
from model directly onto the graphical canvas and it will connect them based on those uh
interface points that we talked about uh and then you can also uh customize the sort of semantics
that the edges um edges will generate uh what do i have here so here's a quick example of what
this looks like um oh that was wrong let me try that again uh so what you can see here is the
the dragging and the dropping directly onto the thing uh it will draw the module around it um when
you draw drag sorry drag the next one over it'll connect it on the obvious touch points um and
then you can rename stuff and drag and drop and add your own classes and so on um i'm not going to go
back because this seems to be fighting me on this so thank you very much for attending this talk i'm
so sorry that i couldn't be there today uh please forward any questions to me um at my email uh or
go ahead and pass them on to Gary and he could do this i will also be here next week um right after
Carl's talk uh which will have a lot of overlap with this sort of design process and we can talk
there um or i can answer any questions that you might have again thank you so much and have a great day
i guess i'll verbally thank Cogan for this and we'll see him next week uh we now have uh about
the 12 to 15 minutes for discussion including questions and answers of course uh Cogan not
being here there may be limitations on what we're able to say but uh maybe we can have some
discussion among ourselves here so with that i'm looking for hands raised here and uh i know there
was a small amount of chat in our other uh online chat yes james you're commuted but here we go uh
thanks Gary and uh i appreciate that Cogan was able to present even though he wasn't able to present
so much appreciated uh it did have a bit of a hard time connecting this step up to what i do day to
day when i do things that i call design patterns or usually focused on templates and csv files or
tsv files that get expanded into some set of al-axioms to define a class uh and but i guess my question
was uh so i am aware that there's this larger literature about ontology design patterns uh
that i'm not super familiar with uh i guess my my general question is how well this talk lines up
with the kind of the larger literature on these things uh i don't know maybe that's a question
for gary but other people could uh could chime in is there like a single notion of ontology design
pattern and cogan was expressing it or uh is it a more diverse kind of field topic keyword
well it's an interesting question i'm not sure i can be definitive i have opinions of course
and i am not necessarily as up to date on all the literature uh if there's somebody out here
on attending who who feels they are they can certainly speak up uh cogan mentioned setting up
sort of a new uh a new repository uh for uh curated design patterns and this reflects the
fact that that people have been building design patterns and posting them and uh the ideas for
them to have good documentation to reuse practice to make connections to other uh design patterns
and maybe upper levels and a lot of that is is missing you know when we we talk about fairness
for ontology we sometimes find that they lack some of the ingredients of fairness and so
that is has been true for odps uh over time but like the the the foundry uh there's a sub community
here of people like like uh pascal and cogan and uh the people uh involved with the nowhere
where graph we're trying to pull some of this together and and provide more of a community
where there are higher standards existing practices so i'd say again that maybe it isn't it isn't as
large a community and maybe hasn't been uh as well funded uh as things in the biomedical field
but this is an attempt to sort of do something of that level quality and i myself am very much
interested in how these two communities can sort of share and cooperate i mentioned the
semantic trajectory as being able to be applied to a course of disease uh but i'm not sure anybody
has done that i'm not sure that anybody has looked at what's common about these patterns and how to
how to take a a dead simple pattern from oboe and sort of put it in and compose with it along with
odps from the other communities that would be an interesting thing to look at it and might be an
interesting research article uh for us to consider so hopefully i've given people enough time to
know maybe more about this and have things to say i just wanted to laugh at your bit about being
well funded because we don't think of ourselves as well funded and being on the side of tooling
side of things but we think of ourselves as stealing time and money to build these tools but
but maybe you're right a lot a lot could be said about that it's a relative question of course
and the continuity is such is very important where things get started in the question so
the geolink pattern that i sort of identified came out of or built on the semantic trajectory but
they didn't necessarily continue to fund more of that for other types of expeditions and things
like that so some of the concepts can be reused but necessarily the projects have a you know a
three year five year type of extent and one's uncertain about the other side that's true we
often have longer time frames than that you know although but not always thanks
okay
um i see something in chat so i'll just read that in addition to what james asked what ontology
projects do you know and hopefully it's the community rather than just me uh use ontology
design patterns are practical practically during during development um again that that's a much
better question to ask of both kogan and call so let's keep that question i do know that there
have been studies which looked at the relative of quality of ontologies built by reusing patterns
or not and unfortunately at the time of the publication i know of it wasn't great it wasn't
a big help at that time but again things have moved along since some of those earlier studies
ashaya you have your hand up yeah so maybe i just ask a clarification questions in his talk
does he mean that uh the design pattern we can use no matter what top ontology that we are using
and another one is so the my understanding is that the design pattern if as logo so they are not
necessarily that kind of have the same using same block like but they can still connect to each other
is that correct understanding i can i can maybe address part of that which is the interoperability
question with upper level ontologies so you notice that some of them had these stubs with
the dotted lines and has he's he said i i don't remember his exact words your ideas you can plug
in different things at this particular point some of them may be entire patterns some of them
may be a very simple concept and so forth so the idea is that the the core of the pattern below
the dotted line is gets reused and it's in common so that you can you can ask some questions across
it because there's a common element a little bit like what cob is doing right cob is providing
that core that other people can tap into but yes there will be variations depending on whether
you tap into dulce at the top or you tap into oboe so or bfo i should say so it allows sort of
some commonality and some flexibility it's a compromise there maybe somebody else has some
other wisdom to add to that or or real wisdom to add to that well it design pattern each design
pattern will have certain requirements for it to be applicable and that could make it
impossible to use in certain with certain upper ontologies
so it's but i to what extent do these design patterns have those requirements explicitly
stated so this is very much a bottom up effort at times coming from what the data is saying
to reflect the reality of the data as opposed to a more abstract concept above
and so as long as you have comps the questions that can answer with the data can answer real
things of interest to a domain that they feel that's that's viable now there there could be of
course these different philosophical distinctions at the top level the question is whether you have
comps the questions that sort of tap into that at all they may it may not for practical purposes
yeah again this is a question this is a deeper question that people who are like kogan and
call can probably provide a better follow-up there is a there's a workshop on ontology design
and patterns
wop regular wop is an annual event
and you can see that some of the people and they're online the past ones are online and you can
look at the at the press the papers i often do so there are people here who are active in that
community who might have some comments yes we have a few minutes left so let's hear from
people with different experiences on this or different ideas on this
you don't have to be shy because you've heard me talk about it yeah obviously people will know
more than that yeah so hello i'm chris hello chris so i was one of the co-organizers of the
last rendition of the workshop on ontology design patterns so if there's anything in particular
you would like me to comment on now i'm unhappy too
so we may have questions what were some of the patterns about from the last or the issues
uh at that i didn't attend right so there there were patterns from different domains
one of which was particularly interesting to me which was about the design of scientific
taxonomics now i don't know the the test anymore because i haven't reviewed the actual pattern
but each year there are a number of patterns that get published and one interesting point to notice
here is that the patterns that get published are not always following the same structure so
there are different ideas of what what a design pattern should consist of and it's also how a
design pattern is supposed to be reused and this is also one of the key notions in which
i personally think that the notion of a software design patterns differs from the notion of a
ontology design pattern so when we talk about a software design pattern these patterns are often
thought as language agnostic so they provide us with a solution that could be adopted in
different languages whereas these ontology design patterns they are often tailored to a specific
knowledge representation language so that it can be reused in that particular form of listening
and that is one of the key differences that often get confused between these two different notions
thank you that's a good although i do know in in his what 10 points that the less that
is to produce the owl artifacts so up until then there's some degree of conceptualization
more abstraction right right so um there have been different proposals for how a design pattern
is supposed to be reported and one of these proposals includes this 10-step or 12-step
process where you have to list all the requirements for a particular use case
and all the ways in which a pattern can be reused but that is not standardized in any way so there
are different proposals of how this could be achieved and this is just one of them so again
i have tried to actually empirically look at how patterns are reused and so far it doesn't seem to
be the case that there are there's a standard notion of either the reuse of design pattern
or standard design patterns that are reused consistently throughout ontology so this is
still a very open question that's a challenging observation that we want to sort of repeat next
week so i hope you'll be back for that and ask again because i agree that you know this is an
we're empiricists here so we want to know what really works where things are and so forth and
what can be reused really reused so we have a question have you looked at uh modl model
they're they're curated the repository for ontologies for odp's anybody else looked at that
oh the idea is the importance of building up a library we've got a hand raised
oh okay i missed it maybe it's on the other screen
oh unfortunately
disappeared they have to go hopefully they we can continue this next week
yeah
yes indeed and so uh call hammer who's now at google uh has been very involved in these things
continually and uh has done a lot of practical development with them and can speak to that
and can speak to methods used and uh since he's went from IBM to google there's probably
something he's able has been able to do he may be able to speak at a different degree of abstraction
but he has practical experience so with that i think we can adjourn for today and and hopefully
see you all again next week and tell your friends i hope frisk can make it okay i'm glad to be there
thanks everybody i know
