Hi, I'm Ken Stanley. I live in San Francisco, and I just started a new social network
It's actually a serendipity network called Maven. I can tell you a little story about this book, Kenneth
So this is the second physical copy I've got of your book, and you know why?
I lend it out to some of my friends and my friend Kate loved it so much that I never saw it back again
So just so I can have the Bible in my studio
I've got the second copy of it
But yeah, you know, I can't really think of any book that I've read that has changed my thinking as much as this book has
It has massive implications, not only for philosophy, but also for how we as artificial intelligence researchers
Think about building the next generation of AI
To achieve your highest goals, you have to be willing to abandon them. We have a nose for the interesting
That's how we got this far. That's how civilization came out. That's why the history of innovation is so amazing
Everything washes out when we start ruling by committee
Like we have to allow people to follow their passions to their extremes, and yet we run society as if this actually makes any sense at all
I think the gradient of interestingness is probably the best expression of like the ideal divergent search
You get to this problem that like I don't know how to formalize interestingness
Which you get to then are proxies for interestingness
That not everything that's novel is interesting, but just about everything that's interesting is novel
It is in my personality and nature to want to
Overthrow this I guess we could say tyranny of objectives
My particular area of interest and research has been in what's called neuro evolution
Which is a combination of neural networks and evolutionary computation
So I'm saying we got to flip this completely like the smart part is the exploration
The dumb part is the objective part because it's freaking easy the first interview that you had with me
That was like incredible. Yeah, that was early on
I remember I used blender to create this 3d environment for the stepping stones and that was so crazy
I couldn't believe that I was like wow
That's like the coolest thing I've ever seen like for just about anything that I've ever said
Because it's like a music. It's like this 3d thing moving around. It's like wow. This is like seriously professional
Well, I wasn't professional, but yeah, so yeah, I mean that kind of make it be cool when you left open AI you had
An interesting conversation with Sam Altman
This is obviously a huge departure from my career trajectory like that's one reason and I'm nervous because like I I'm known for AI research
Like that's where my reputation is staked and I'm like just leaving it to do a social network
He said that you know the thing that I think you need to do is to think about the theme of your career
Not what you've been doing like you've been doing AI research. That's what you've been doing
But what is the theme the thread that connects everything you've been doing like even maybe since before your career?
Like what are you about as a person?
It's not AI research because he said for example like take my career
And what he said was that I have realized that I am all about scaling. It's scaling
That's what connects all these things you scale a startup, but the beautiful thing is that AI is all about scaling
There's a deep insight there actually
You know like to understand that at the heart of this AI currently is the idea of scaling and there's nobody better
Than Sam whose entire life is about scaling things
To actually like, you know supercharged the scaling now
I personally don't know if scaling is about every everything
Yeah, it's about like I'm not totally bought into the idea. It's all about scaling
I'm not even sure Sam would even claim that I'm not putting I don't mean to put words in his mouth
But it's the thing that ties together his career
So it's what he's about not say all AI is about but what he's about scaling and it's just made things click for me
Oh, not just like about me, but about him like that was the first thing I thought was wow
This is so interesting that I understand him better like in this instant
It was such a short thing to explain
But it just made me understand why is he even here like why is Sam Altman in charge of open AI then?
I just suddenly understood this it's scaling
That's who he is
He's like the best in the world in scaling and then he said you don't seem you know
You're not you the theme that cuts across everything you've done like the book that you wrote the research that you've done
It's this open-ended this stuff. It's divergence
You're interested in you seem interested in like these freedom exploratory type of systems like
Divergence in all kinds of contexts. I'm about scaling. I don't think he said this literally but basically the way I took it is
I'm about scaling you're about divergence that that sounded so neat and nice
So professor Kenneth Stanley has created a new type of social network a serendipity network where all of the popularity
Contest is gone the likes are gone
It's designed to accumulate information to foster creativity
Just like things work in the real world what it is not is a popularity contest and that
Is clearly I think a radical move because basically all social media. I don't think there's an exception is a popularity contest
You've got like buttons. You've got popularity. You've got follows. You've got popularity. It's all driven by that
And so we have actually taken that away
We don't use those mechanisms
And so the question then is what do you actually do in a system like that?
You've taken away our drugs of choice
Of course, it's kind of like a detox
So we're gonna actually make your life more healthy. Hopefully like that's the hope here
But how like how does it stay interesting? Well, the thing that really drives our system is following interests
So like one way that we put it is that you follow interest instead of following inch influencers
And so following interest means that influence it means that interests are kind of first-class citizens
Where like you can follow an interest in our system where you follow a person maybe in another system
Even has its own profile for the interest and these interests arise a whole cloth out of nothing
In the system, so it's not like there's this fixed set like in a lot of systems
There's like fixed sets of things that you can join or follow like this is just
Created as it goes
And so users kind of have an experience where they're discovering and adding new interests often they're through other users
Like you'll see interests that other users follow sometimes you'll even find out if someone falls an interest because of you
because that's kind of a way of
Having a more maybe a healthy form of validation socially so it's like oh
I got someone interested in something rather than you know, somebody likes
My post or somebody's trying to follow me
Like I'm a brand but you got somebody interested in something because it's about the interests and so people are finding interest also through new posts
Like it when you post something on the system and artificial intelligence will extract interests out of it
And it'll suggest those to people who are exposed to that post and so people can find new interests that way too
And so adding interests is kind of the recreational activity instead of liking and follow
Fans of MLST will know that we've carved out a niche in the kind of center point between
philosophy and artificial intelligence and this
Book the episode that we did on on this book was really
emblematic of us starting to cut out that niche a few years ago the main thesis of Kenneth and Joel's book is that
objectives or consensus mechanisms lead to the
Entreatification of society systems and everything. There's nothing really insightful or interesting about just doing objective
Optimization. Yeah, we've got plenty of good algorithms for doing that and it's not counterintuitive at all
It totally makes sense, but it's not going to get us hardly anywhere interesting whatsoever
It's kind of the curse of optimization
And what that means is when you build an optimization system you have to take a metric
You have to take a utility function or a cost function and you have to optimize it
But then it suffers from the shortcut rule and good hearts law
The shortcut rule is that you get what you optimize for exactly what you optimize for and nothing else
Which means if you can't specify all of the richness and complexity that you want to capture in the cost function
Then it's all gone and good hearts law is this very interesting idea that when a target becomes a measure
It ceases to become a good measure which means many of the systems we design
Including current social networks are divorced of all of the richness and creativity which exists in the real world
We need to create systems that capture the creative generative processes
Which exist in our physical and social worlds and with naive objective optimization. It's impossible
In my opinion the reason why chat GPT is the antithesis of creativity is it's designed to reduce entropy
It's designed to make things simple whereas a creative process is about producing new information
So there's a tug of war with things like GPT which are centralized because we have access to creativity
We have access to serendipitous novelty and we can put it into GPT
But GPT is always pushing back on us. It wants to make things simple
This is model bias in order to produce a truly creative process
We need to design platforms which eliminate this centralizing force. Maybe you could call it a self-organizing worldwide group chat
It's got this self-organizing component
Which I think is interesting to think about that, you know, so what's happening, you know
Usually when you go into a forum, you go into Reddit or something like that and you have to choose which silo
Are you going to be addressing?
It's obviously advantageous if you want to talk to people who share your interest because you can choose a place where the interest is reflected
So go to that particular forum
But the thing is like that really is limiting when you think about it because of the fact that like often as
Conversations me and or within something like that you touch on things that other people in other forums would have really found interesting
You know, for example, like if I was
Had an issue with say the architecture in San Francisco
I mean, I could go talk to the San Francisco subreddit and like 10 people about my problem with it
But then it starts to touch on
General urban planning. Let's say well, there is an urban planning subreddit and none of them see this conversations
They won't be part of it. They probably would have had something to say about it might be something interesting
That's where self-organization self-organization could have kicked in
I mean people could have actually come in from there and that is what Maven does like constantly always like every single thing
Anybody says is reanalyzed by the AI to think about what is now who to whom is this now interesting as a conversation?
And then those people are drawn in so you're having because of that basically different communities are getting crossed over constantly and cross-pollinating
Because as the conversation meanders new communities are brought in
And that's what I mean by self-organizing so that's constantly organizing around like who should be interested
And and and so you don't have to think about like which silo do I belong in you just send it out
It gets sent to people who would find it interesting and as the conversation continues. It'll just reorganize
around those people and by adding interest you're expanding your kind of like serendipity surface horizons
Things that might be interesting to you and the system works in such a way that like it's trying to expose things that match your interests
But in doing so it will also sometimes expose things slightly adjacent
And so your interest will gradually expand as you discover
Oh, I actually am interested, you know, like I didn't even think about 3d printing
But now I realize actually that's something I would like to follow like what's going on there when people talk about that
And then that comes like part of your part of your interest set
And so if you think about it in aggregate like the system is a giant interest graph that's growing over time
The more people come in the more we discover new interests because these aren't things like I said, they're not from a stock list
So it's just growing and growing and this interest graph lets us understand things like what interests relate to others
You know because we know people who follow this interest also follow that interest or like we see these interests co-occur a lot in posts
Like when people post like often AI and ethics occur at the same time or something like that
And so we haven't just like really interesting graph that I don't think anywhere else has
Showing how everything is related in an interest graph and rather than in a person graph
Which again, I think is generally arguably more healthy since it doesn't have this popularity
Contest act aspect to it. And so the last thing I just wanted to mention about like how it works as you're kind of expanding interests and
Discovering new things on the system is one thing that made people may wonder is but where's the quality control?
you know because like the the the kind of
Top-line billing for things like likes or follows is quality control
It has all these other implications, you know, it has convergent aspects like when we have consensus we get convergence
Which is an unintended consequence of likes, you know, so if like a million people like something that's definitely consensus
But what happens is that we have these convergent points like throughout the day on these very very high agreement things and that
Filters out diversity, so we're counteracting that and that's a good thing
So you get way more diversity is one effect of a system that's about following interests rather than
Following influencers, but you still may be wondering so you took out this thing
Which is the supposed the purported quality mechanism was left there
Well, we were doing something interesting which is more subtle which is worth a little mention
Which is we're using something called a minimal criterion to understand what is not actually good content
So actually we're not interested in maximization
And I speak a lot like when I speak about like my greatness cannot be planned about like what's bad about maximization
Optimization on everything so we should get rid of the idea of optimizing content
But we do something which is saying there's a minimal threshold below that we do try to
Circulate less if it's below a minimal threshold and we have different ways to measure engagement to like sort of set our minimal threshold
But above that threshold there's no contest everything is treated evenly and agnostic Lee
And so you get this kind of churn of ideas that are all of like minimal at least minimal
Interestingness and it's worth noting that this kind of idea of a minimal criterion has been used in research in the field of open-endedness
And there's also an interpretation of natural evolution based on minimal criterion
So it's not just like a totally ad hoc thing and it does really interesting things like it leads to
Very rapid fast divergence and increasing complexity like in artificial systems
But without convergent properties and it's extremely simple
And so this is a completely different kind of quality mechanism, but there is it is in there
And so you should be one maybe philosophically just make it make some sense is that kind of the philosophy behind a minimal criterion
Is that it's really just pointless after a certain point to argue about is something better than something
It's like once things hit a good enough especially in the world of subjectivity
Like if you're talking about like movies or something or even like intelligence
Like if you're talking about like is this guy more intelligent in that case at some point just stops mattering like at an absolute scale
It's true like below a certain point. It's like it can matter a lot
You know, it's like if you if you're like in like, you know the disability range of IQ or something
But above a certain point
It just gets ridiculous to like split hairs and like is that actually better?
Like this person said this and that person said that which is the better statement. They're both interesting
Um, then we actually try to rate them and then you get rich get your get richer phenomena and all kinds of artificial aspects
Start to come into play which have really nothing to do with any kind of true objective absolute sense of quality
Because there is none in subjective domains. So we can say like above a certain amount
Let's not play that game. It's stupid because it leads to conversion
It filters out all the diversity and let's let diversity reign when you're within that range
Where things are good enough that it's not degenerating to my couple of co-founders. Um, one of them is jimmy sekreton who um,
Some people might know I worked with him many years ago on the pickbreeder
project, um jimmy actually was the lead of that project and um, we've talked for years about maybe
Reuniting at some point. Um, he's had a lot of industry industry experience since then he was a VP at brave recently
Um, and so it was just a good opportunity to get back together and work together again
Um, and my other co-founder is named Bloss Moros and he has some really unique experience building online communities
Uh, he's built some communities like uh, the lattice work which some people may have heard of or
Um, also something called the rabbit hole where people follow
Books and readings together that he's uh, he's been sharing with people
This book changed my life. Kenneth this book changed my life
If there were just a few things you can summarize, you know from this book. What would it be? So the book is um
a result of ai research
and it's a
It's a really strange story because it's very unusual that ai research results lead to something that
Looks a little bit like social critique
In fact, I think I'm unaware of any other example like that and I certainly wasn't trying to do something like that
That wasn't my career goal. Um, but the thing is that we were seeing results that had really
large-scale implications outside of ai
Um, and I mean in hindsight it starts to make sense to me that like if if you're really trying to understand intelligence
Which is like just one of the most salient aspects of being human
Then you should expect to learn something about what it means to be human
I mean that that seems to make some sense in hindsight. So that should be happening
It that should be a side effect of our field like to the extent we don't do that
It might be a sign that we aren't necessarily digging in the right places or learning the things we should be learning
But in any case we what we found was this really strange paradoxical, uh, uh phenomenon
Which is that pursuing an objective can actually get in the way of achieving the objective
But it's more than that. It's also that it gets in the way of achieving anything else even outside of the objective you started with
Um, and this is something that originated from observing results from experiments. So this is not, um, like an opinion
Um, this is just empirical results that we were observing and experiments that we did
Some of those experiments had people in the loop. So we had people searching through spaces
Finding in in our case pictures was the original experiment. It's called pick breeder
And we saw this phenomenon of people only finding things when they're not looking for it
Um, which is really hard to absorb so you can only find things if you're not looking for them
It's like some kind of zen statement or something like that
But if you think about it, it starts to make sense even algorithmically because it also sounds philosophical
But it's really an algorithmic observation but algorithmically it makes sense
Because there's this this phenomenon of deception in complex spaces, which is like a well understood
I mean, sometimes we use other other words for it
Uh, we might call it like getting stuck in a local optimum or something like that or premature convergence
But really what deception means is that it appears that you're going in the right direction when you're going in the wrong direction
Or vice versa, it could appear that you're going in the wrong direction
You're going in the right direction and the thing about that is that it's much more pathological and pervasive
Than the way that we usually think about it because it's not a surprise that that exists in search spaces
But it's so pervasive in spaces that are complex
And that is what we didn't appreciate I think and that the book is really keying in on
Because you see like in complex spaces that should be the rule rather than the exception
Like by complex I just mean things that are hard like things in the world that are hard to solve
So something like creating agi or curing cancer or creating
infinite renewable energy or things we might want to do
Those things the stepping stones that lead to those things don't look like those things
They aren't obvious in other words
Like if they were obvious that we would just do them and they wouldn't be considered hard problems
Obviously, we don't know what the stepping stones are which means that when we do find the right stepping stones
They will be surprising
Which means they won't be things that we would initially guess are the important things you need to do to get to those things
And this was initially observed in these artificial search spaces like pickbreeder
But it was clear that this is a general principle in all complex spaces
Because they will always have this kind of circuitous property or else they're not complex. It's basically like a truism
And so the the the problem
Which the implication for the problem we have in society
Gradually grew in my mind over time after this like looking at the ai results
Especially from also talking to people about the results because people often would ask what does it mean for me because people would say
Like ai conferences. They'd say I have I have objectives
Like is this like applicable to the way I think about things or is this only about algorithms?
But of course, it's not only about algorithms because we all are facing search spaces
Like that's a problem that's generally ubiquitous in life
Not just in algorithms and because of that it it started to emerge in my mind that like this matters to people
This matters to institutions. It matters to governments. It matters to education
Like there's objectives everywhere is completely saturating everything that we do
And if this deceptive principle which I call the objective paradox because it's a paradox that pursuing something can cause you not to achieve it
If it holds with really tough problems
Then like we're all in trouble because like we're all doing everything by setting objectives
And the more I thought about it the more this seemed like a serious social problem
Even though it's not the kind of thing, you know, that is currently debated in society
Like you don't have like protests going on about like anti-objective movements or things like that
But that made it even more seem like this needs to be brought up at least we can have a conversation
Maybe I can't change the way things work in the world, but at least we could have a conversation
Um, and it seemed important to to bring it up because nobody doesn't seem to be on anyone's radar
And I mean just just give one concrete example
Think about like when you apply for science funding since I know a lot of people who watch this show probably do
They want to know what your deliverables are. That's your objectives. Like what are you going to achieve?
Like we're already off to a bad start
Um, because that's not how innovative systems work
Innovative systems work by collecting stepping stones and not knowing where you're going because they're interesting in their own
Right because we don't know which ones will lead to what?
Um, and already the entire science funding system almost across the world works in the opposite objective paradox way
And so that's a mistake and most institutions work that way
And so I we wrote the book Joel emin and I to try to highlight this and start a conversation
In a way a goal or a stepping stone is like knowledge
So I kind of think of your your philosophy as as describing a kind of epistemic roadblock
So the the paradox is that in science we want to accumulate knowledge
And we're shooting ourselves in the foot because you're saying well
You're only allowed to operate inside the space of this known knowledge because the goal
Presumably shrouds out any other knowledge that you don't already know
So it's about this kind of paradox of the unknown unknowns
But I wanted to bring one other thing in because some might say that um, it's you know, there's in reinforcement learning
there's exploration versus exploitation and you have a fixed goal
But people might argue well, yeah, you have a fixed goal, but uh, there's this implicit motivation
You know so so the agent can still learn
Subgoals and do lots of kind of weird and wonderful things that might be somewhat orthogonal to the end goal
And I've always felt that I mean again, this is a teleology question the reason why
There is no teleology in evolution. It's a process that is divergent
It generates entropy and complexity all the time and that is precisely because there is no
End teleology you have these independent agents kind of doing things on their own and not necessarily sharing information
With each other. Uh, yeah, so it's true that um, you know exploration versus exploitation is is very
A well known and well studied. I mean, it's no surprise to anybody that we should do some exploration
Um, but you know, there's there's a couple things about that that I think
fall very short of the the kind of
Observations the book is making about like how what exploration really should be
You know and one of them is basically like related to what you just said that that it's just like just
Having this objective at all in mind can be just too much
Too much of a drag on your ability to explore
That it just doesn't all add up
I mean and we should we should note that like of course in ice we can see it in the book that modest objectives do work
So the book is not saying no objectives ever work. That's important to concede here
Modest objectives can work and a lot of the time reinforcement learning when it works works because it's what I would call a modest objective
So like you keep your eye on the ball
Um and exploration you can think of as a little bit of distraction moving you around
But you need to have that distraction because you need to sometimes get off deceptive paths
And it works that works out. Um, but the problem is when like you're looking at something that's like
Radically ambitious, you know, that's what you know, I talk about something
Like curing cancer like this is like way beyond like where we understand what will lead to what
Then it actually doesn't make sense anymore
It becomes actually like a huge weight on your ability to explore
And that leads to you know, that like it's actually the case that having an objective
Is much more powerful than a force for diversity
Like sometimes, you know what this this field that the original experiments that led to the book led to a field called quality diversity algorithms
And this whole field is sort of about this idea that quality is is is is kind of like a
A huge powerful force and diversity is this very delicate feather
And you you try to combine them together and if you're not careful about it
It's always going to be the quality crushes diversity
Diversity is the hard thing to do and so that leads to kind of the second point I want to make about exploration versus exploitation is that
Exploration is actually a very complicated subject and when we think about it is just making random moves
That's the most trivializing way to think about what exploration means exploration is an intelligent process
It's not random. I mean, of course in an algorithm. It might be defined as something random
But real exploration means following gradients of interestingness, which is highly information rich like understanding what's interesting in the world
People are really good at that. Like that's one of the remaining deficits. I think for models today
artificial models because
understanding interestingness is an extremely difficult problem
But those gradients you can think of them as gradients you can follow
That's what it means to explore
It's not taking a random move in a reinforcement learning algorithm
And so exploration algorithms like forget about having an objective like it's its own topic in its own right like the way to motivate to
Represent where you want to go. What does it mean to be interesting? What is novelty things like that?
They all have to be
Confronted in order to understand what it means to explore an informed way
And what that will do then is it will accumulate things that are interesting
And some of those things will lead to other interesting things and eventually one of those
might turn out to be the stepping stone that leads to something you care about
Or may turn out to be something someone else cared about but what you're doing is collecting stepping stones
And so you're making it more likely something something important will happen in the future
Yeah, and we were talking about this minimum
Criterion earlier, but I suppose what we're trying to do is is create algorithms which are naturally plausible
maybe even biologically plausible because we see these fascinating dynamics in the real world
And we select features of it, you know, so it needs to have diversity preservation that needs to be entropy generating
Agents need to follow their own gradient of interestingness
And the almost all of the algorithms that that you've been associated with our population method
so this kind of population idea seems really interesting and
I guess like one one question is
How far can we go with computers, right? I mean
The the reason why we have an interesting
Concept built into us is because we're physically and socially embedded
So it's not necessarily that we have
Knowledge of what's interesting. It's quite serendipitous
But the I think the key is that the knowledge is actually embedded in the system
Like the reason why a bird knows how to fly where a bird doesn't know how to fly the knowledge of flight
Is actually encoded into its physicality and how it's embedded in the system, right?
So I guess I'm saying like that's how interesting this works in the real world
And we want to write algorithms to do that artificially
Yeah, I mean, I think that the trick in this is that
We really want these algorithms to do things that are interesting to us
So it's it's true like our experience and the things that we find interesting or idiosyncratic in some way
I mean, I guess it's
It gets philosophical because there's a question. Is there any absolute way of thinking about what it means to be interesting?
But it's like if you started a whole new world and things just evolved inside of that world independently of this world
You know to what extent is that interesting to us?
And that's actually like an artificial life kind of view, which I think probably some of it actually is interesting
But like at the cutting edge like that's hard like in other words like the cutting edge of what's cutting edge for us
so like the cutting edge of technology of all aspects of society of art of music of of
Political organization like all of that stuff has a cutting edge
And those things are interesting to us for idiosyncratic reasons
They have to do with how we developed on this earth and our embodiment and all kinds of things
And so like it's just we have to somehow if we want
To incorporate machines into that cutting edge so that they can explore along with us to push it forward
In ways that we would actually care about
Then they have to absorb a lot of the understanding that we have that comes from our legacy
Somehow so that they can draw from that to understand what's interesting
And yeah, the problem is it's non-trivial and information rich. I think it's it's not like just like a couple rules
Um, like it's like your entire lifetime of experience bears on what you find interesting
um, and so to endow them with sufficient representation to capture that
Is very challenging and it doesn't just happen because they absorb all the language on the internet is the problem
Like that would be convenient
But interesting this is another matter than just knowledge
And so it's this is a really tricky thing
But we can um
We can imagine this happening. I mean I I can imagine trying to
You know bring them into the fold of where we are at the cutting edge and helping them to see what's interesting
And they would you know gather some degree pick up some degree of of uh instinct from us
Um, I just want to point out that there's a whole completely different way of thinking about how to get interesting
This which would be which would be like from first principles kind of
Like just starting with single celled things and just thinking like well, would it just become interesting?
Because I mean evolution did that so I guess it's it's a little bit
Um
It's a little bit circular because like we're a product of that process
So it's like well, that's why we think it's interesting
I mean you could argue that like well if we weren't we wouldn't find it as interesting
But I don't totally believe that because like it seems like to me that
It's like not debatable that what happened on this planet is interesting no matter where you come from
Now I mean we could definitely debate that but like to me
It's just like there is some level at which like something happened here that's interesting
Like it's not clear to me that like the tv show you like is interesting in some absolute sense
But just generally the entire process of evolution on earth all the way up to humans is somehow
It just seems intrinsically interesting and I think the reason is because like there's some
built-in
There's some built-in conditions that
Uh that that encourage non triviality of some sort or complexity
Um, which is sufficient to be somewhat interesting at least
Um from from the point of view of anybody who's intelligent, I guess you could say
And so that's obviously very debatable and getting a huge side discussion about this
But I think it's important to still think about even outside of the philosophical part of it
Because we do want to understand if there are relatively simple principles that can help us to get a leg up on this
Like in terms of actually producing interesting this like generatively producing it
Like that are not that don't require
Like knowledge of what it was like to live your entire life and every other person that lived on the planet
Like that's a lot to ask like if there are some basic fundamentals
That can sort of scratch at the surface of interesting this then that can help us
Get our feet foot in the door and start to move forward
I really like this idea that interesting this is just the knowledge that we don't understand so we we have these
And when I say anthropocentric, I mean we have these like kind of human
perspectives on things and
We think of knowledge as the kind of stuff you get on wikipedia
But you know, knowledge is everywhere and and in a sense, I I think of intelligence as being everywhere
Intelligence is distributed far outside the brain
I was reading a book by max pennett earlier arguing that you know language is in the brain
Well, I don't think language is in the brain language is is an organism
If anything language tells us what to do not the other way around
So, um, yeah, it's just a completely different perspective and our anthropocentric priors really kind of guide how we
How we think if that makes sense, but but just just to close the loop though
I was uh watching a presentation by jim fan from invidia and
You know, he's kind of got this these three axes where you have embodiment and you have
Skill and you have realities and he's got these different agents that operate on different parts in that 3d space
and I
Just kind of disagree just based on my last point because I think all of these things are entangled together
Like he's making the point that oh, we could have these foundational agents that could
Generalize between different forms and different realities and have different skills
And they're all the same thing, right? All of these things are just embedded in the world
I guess a reality could be an environment and a form could be
I mean, I kind of think of those two as basically being affordances
So how can I interface with the environment? But if you think about it interface, I mean
You're great to talk about this because you did this poet
Um
Paper which was kind of diversifying doing curriculum learning across different environments
But but in a sense the environment affords an interface you can only interact with it in a certain way
So you can kind of you can kind of think of the embodiment and the environment as being the same thing
But if you were trying to argue that intelligence was abstracted away from physicality that you could build this general agent that you could just
Plomp into any world and it would just automatically be able to do anything
So do you see what I mean? There's this tug of war between I think intelligence just is the physical and social world
And another school of thought is no you have these intelligent agents that just know what to do in any world
I see I see yeah
Yeah, that's um, that's that's that's a uh a hard question to think about um, like these other worlds and how they would relate
Um, or if there is something like truly general beyond
Any world and they could work successfully in any world that's conceivable
Uh, yeah, I I wouldn't be confident in that. Um, I mean it that I agree with I think I agree with that
but I but I also
Not at always sure like when you get down to very specific points
Like it has to have a body then I become less sure of things like that
Um, like is that really essential in our world to have a body in order to be an active participant in the you know
Advance of knowledge or something like I'm not sure that you need a body for that
You need some exposure to our world though. I'm not saying you wouldn't have some exposure
And so, uh, of course we live in a physical environment with like vision and sound and things and that there's
Some of that's gonna have to get in somehow
In order to really participate in a meaningful way
Um, and so but I just don't know exactly what the you know, desiderata are like that
You have to have this or you have to have that I'd be a little more open to
Different variations than you know, some strict like person who's only about embodiment or something like that
Very interesting just before we go on on to the to the other bits we discussed
Maybe we should just describe pickbreeder in in really simple terms
So this this picture on on the front of your book came from pickbreeder, right?
Pickbreeder was an experiment in open-endedness. Um, I was really
Interested in systems that are what I would I call open-ended and now this like kind of recognizes as a sub feel that in machine learning
Basically open-endedness, but open-ended systems
Actually, I should note um for historical reasons that the the term open-endedness where I first encountered is an artificial life
Where there was a sub community there called open-ended evolution or OEE
Um, and so I would I was really interested in it from from that perspective and um, of course evolution is often
cited as like the the the most canonical precedent of open-endedness like it's this process that for
Uh, more than a billion years has been you know diverging into more and more interesting stuff
It doesn't seem to end. It's almost eternal. Um, and so so it started out with these kind of
Open-ended evolution researchers in artificial life. Um, but I always thought that
This is a general issue across like not just artificial life
But AI as well because I think open-endedness is also the big thing that characterizes what it means to be human
It's it's interesting because it's what created humans like evolution created us
So we're a product of an open-ended system
But I also think we produce open-endedness and that's like the most salient thing about us
It's like civilization is basically a giant open-ended system produced on top of human intelligence
So there's like an open-endedness sandwich with us in the middle
You know we come out of evolution and then we produce civilization and both are open-ended on both sides
Um, and so to understand us and intelligence. I have this intuitive feeling
We need to understand open-ended processes because AI will have to be one eventually
And a lot of the time that's like the last thing missing. I feel like like AI can do all these
Impressive analytic things that can like solve a test or something to answer your question
brilliantly
But like it doesn't produce things that move civilization forward
That's like inventions and ideas and you know like things that change the way we think and that just doesn't really happen
Um, and that's like what it means to be human. I think because if you think about like what uh, what is
Um, how how much what do you think?
What is it elicit in you if you hear that somebody can multiply 10 digit numbers in their head?
It's impressive, but I don't wouldn't say oh the humanity
It's not the kind of thing where you're just like clutching your heart like that's just so moving
It's just like that's impressive. That's that's like a computation
The humanity comes out in like when someone invents something, you know, it moves you it changes your life
Like that's humanity. Um, and that's open-ended this and so
So I think that's what we need to capture
And so and also just as a practical matter for AI people the thing the other thing about it
I think is important is that because it produced us like we are a product of an open-ended system
We might need to create an open-ended system to produce another us
Um, and so that that was really motivating me a lot with like the picked reader
Um, I want to understand how these things work because I wanted to understand how brain like things could evolve
artificially
Um, and so because I'm mentioning all this like in detail because like when you hear what this is
It doesn't sound like a really serious experiment. It's like what we're going to do is we're going to have people go on the internet
and breed pictures
So we'll give them an interface where they could see a picture and then they could see as several pictures
And then they could choose one and it becomes a parent and it has children
Just like if you're breeding dogs or breeding horses or something like that
It could be you know, it could be like sexual or asexual. It doesn't really matter
It could be both but a lot of people would just do it asexual meaning one one parent because this is in the computer
So you could do whatever you want
Um, and so so people would choose pictures and make children
And so you hear that you're like, oh, that's that's like a toy like what is the point of all of this?
But you see the point of it for me
It wasn't the toy even though I was hoping people would enjoy it as a toy because that would get people to to use it
But was to see the unfolding divergent process of discovery. That was really what interested me
I wanted to see a new tree of life
Form on the internet a tree of life like, you know, the kind of phylogenetic trees
You see like with the single cell at the bottom and humans in some branch somewhere. Um, I wanted to see a new one happen
Because I wanted to understand the process
It's not the individual images that I care really about like there are images
They were pretty impressive like people found things through random mutations. So this is not like dali or something
It's not like modern image generation. This is like old school stuff through random mutation
They would find things like butterflies and skulls and cars and really impressive discoveries extreme needles in a haystack
Um, but it wasn't the individual images that interested me
I wanted to understand the process because I thought if I could see an actual open-ended process
Then I could understand algorithmically how it works
Um, and this is something we desperately needed to understand and the problem is there's not a lot of reference to C processes like this
You know evolution is a is a reference
But we can't see it because it's buried in the ground like you need to go digging and get fossils out of the ground
And I wanted to see every single little step exactly what happened in a process like that
So I could totally analyze it and understand it. I just thought something interesting will happen
Um, and it's you know, it's notable that I didn't know what would would happen
I didn't know what we would discover. Um, it was totally unclear which made it very hard to get to get funding actually
Because it's not they're like, well, what's the point of all of this? But the point was to see the process
Um, and so we put this out there
and indeed the the the result was we we did discover this very shocking fundamental thing
About objectives like that that people on that site it turned out when they found these amazing things like the butterfly or the car
Uh, it was because they were not looking for them or to be more clear
It's because everybody along that trajectory was not looking for it. Um, like the very last couple steps
Someone might have been thinking because they realized they're getting close, you know, they might have been thinking
Oh, I'm getting close to a car. So I'm going to try and optimize this towards a car
But all the other steps along that trajectory nobody was thinking about cars
um
And so the only way to find things on there is by not looking for them and for people who were looking for things
Which is most people because that's how we've been trained to think
Most of us are acculturated to set an objective and go towards it by the time we're adults
So most people actually don't like pick reader. I found I think that's true because they would
automatically come in with this predisposition towards setting an objective and then it would be frustrating to be extremely
frustrating because a deceptive space like any complex space, but it looks like they're going in the right direction
They're not they they hit a dead end. They experience this intuitively
So they feel stuck and then they're just like this this sucks and then they're like
But why did all these other people succeed in discovering all this stuff?
Like it doesn't make sense
But it's very frustrating to an objective person and so I think this is why a lot of people would just leave
Quickly never come back because it doesn't work like the way you would expect the toy to work
a quick point, but um
There's another amazing book called the language game
And it basically talks about you know, there's this idea that that what if culture and language itself was alive?
It was a living breathing organism and the um
Yeah, so it's this idea that essentially we humans have this proto ability to um
Use improvisation to make sense in the moment and we also have other proto abilities like shed attention
And even babies will look at things. They'll they'll make sure you're looking at it
So there's an interactive shared attention process and there's a whole bunch of things that we do that give rise to this incredible
Kind of social complexification that we have and it's a bit mysterious how it happened in evolution
But the fascinating thing is that I think the real intelligence of humans is
Culture and society if you take an individual human and you put them on mars or put them in a in the wilderness
Then that human it's like going back in time
A long long while so it's almost like our collective intelligence is
The is the culture and then if you contrast that to something like gpt
So they said well gpt isn't learning how to play charades
It's learning to find incredibly complex patterns across billions of words of language
Humans and gpt can write short stories technical manuals and press releases and do simple tasks with language such as answering questions
But gpt is not mimicking the human mind. It has no mind at all
So there's always this kind of interesting tug of war between like, you know, creating the actual
Thing which has the high resolution dynamics, which is alive in the same way versus kind of creating this very simplified version
That appears to be like the thing you want to create but actually isn't
Yeah, that's true
I mean some way when you see like the intelligence is the society and the culture like it is basically saying this is this collection of stepping stones
Are part of the intelligence of the process, you know, because I always speak in terms of stepping stone collection and open-ended processes
And so like that's what makes them really powerful is that like the longer they run the more stepping stones there are
It's like the next generation of inventions are going to be more interesting the last generation because there's more inventions to build on
Um, and so, you know, it's like back in the day when there's only like wheels and fire
There's only so many things you can do but now you've got, you know, you've got computers
You've got the internet so these are stepping stones that we can build on top of
And it's the the whole collection of stepping stones, which is all of our culture and society
Is the the potential we have to do something new
So you could say that's a store of intelligence as part of an intelligence system
I mean, I think it makes it certainly means that any individual is empowered more
To do more to do more interesting things
Yeah, yeah, that's one way to think about it
I mean just just a final point on that
I think though the the real gap between us and machines is this creativity
And I think also autonomy is is part of that
So the reason why we have built this incredible culture this infosphere with all of these stepping stones is is because every time
You and I or any people have interactions they
creatively do things just to just to understand each other just to just to
Make sense in the moment you use this ingenuity of creativity
And then that just gets recursively rinsed and repeated and reapplied and all of these things just bubble up into our culture
and
There's just nothing like that in in ai systems. I mean, obviously the closest we have gotten to that
Is all of the work that that you've done
But I think the autonomy gap and the creativity gap that's that's the elixir that we don't yet have
Yeah, that that is actually interesting because I I've often said that
You know one of the keys to
Getting open-ended systems to work is that you you don't just want to have more solutions
You want more opportunities or more problems is one way to think about it
But I they're not necessarily problems. They're opportunities to do something new
And so that's like where create that's what allows you to have creativity
Like you can't have Shakespeare if you don't have an audience like to actually listen to it
And you can't have giraffes if you don't have trees
What's interesting is that we are both like as as organisms in this world both opportunities
And agents in the world. We're creating opportunities for other people to do things just by existing
And that what you said just made me realize that like it's the creative opportunity that like every single interaction provides
Which is causing things to move forward. It's like me talking to you right now
Like you're presenting an opportunity to me and it's a creative opportunity
Like the way i'm addressing this conversation is actually creative
Because i'm trying to figure out like what is actually something that I can create here with you and also for the audience
That's like not existing in the world yet
Like that's why i'm having to conversate like I've already existed in the world
There'd be no point to have the conversation
And it's kind of interesting that like everything is a creative act
Almost everything is a creative act in that sense like everything you confront
confront you with a new opportunity to do something creatively
And that is that is really interesting how it's starkly different from the perspective of like gpt or something
Like it doesn't look at it wouldn't see things that way at all
Which is really bizarre, you know
Because I think a lot of us do see like each each interaction that we have as a new creative opportunity
Although no one would probably articulate it that way. It just occurred to me now even to think of it like that
But that's just like very deep in human nature that like you want something new to come out of this
Not the same thing you just did yesterday
And that's just not intrinsic at all in the ai it's not trying to do that
So yeah, it's not going to be a participant in the advance
Of things of society of culture and civilization. It's not going to be a participant yet
Until we address that
Yeah, although final point on that
I think the autonomy gap is quite interesting because people anthropomorphize ai
They think of it as an agent or it could be an agent if only you gave it autonomy
Even though they don't have
Agents so they do silly things when you give them autonomy, but um, you know at the end of the day
People confuse
combinatorial creativity with inventive creativity
and
And also people confuse where the locus of the agency is so it's more like a paintbrush if I use a language model
I'm giving it the entropy. So I'm entropy smuggling from my physical and social world
And people kind of get confused and they think oh the language model is is giving you the entropy
No, the entropy came from you. It might be surprising what it what it gave you
So, yeah, you know, it's it's still interesting in the in the sense that they are tools which have become established in in our
Kind of ecosystem, but they're not agents and that they don't they don't do things on their own. Yeah
Yeah, yeah, I agree that they they have what you might call combinatorial creativity like they can combine two things and sometimes
It's it's really entertaining when they do that
Um, often though the things that they combine are because you asked them to combine them
So it's actually that the real creative seed was from you, but then they do a good job with it
So that's actually entertaining
But they can sometimes come up with their own combinations like it does happen
Um, but I also agree that that's not transformational type of creativity that this is like a lower grade of creativity
But like even beyond that, I think the real problems. They don't really understand what's interesting
Um, like regardless what kind of creativity we're identifying like I think this relates to things that Bowden said about creativity
Um, but like the regardless of even that like it's just they don't really understand what's interesting
So they can come up with arbitrary combinations
But it's not because they really have an intuitive sense of this is going to be interesting to somebody
Like often there are things that already were combined by somebody else or otherwise are just like totally arbitrary
And are only interesting because an ai did it but not really interesting in their own
It's not like something you would ever be like, oh, that was great that you came up with this bizarre combination of ideas
Um, you know like like I had uh like for example
Yeah, I mean one thing I had fun doing with gpt was like having it come up with ideas for movies
It's just kind of funny, you know, and they they could be quite entertaining like to hear these ideas
So, you know, it came up with this idea or I was asked to at one point to come with sequels
so it came up with
a sequel to the wizard of Oz
Where um, she comes back and the wizard is a drug addict
And she has to help him recover
um from his addiction
and that's like
It's just like an arbitrary combination of ideas. Like it's like it's actually really funny because it came up with it
But I don't think that's actually a really interesting idea. Um, it's like doesn't make any sense
It doesn't really follow from like the ethos of like this kind of like wizard of Oz like fiction that like he would turn into a
Drug addict and that would be like the next book. Um, but that's what it comes up with
So so it's like that kind of combinatorial creativity it can do but it's not yeah
It just doesn't have a sense of true
Interestingness in novelty and I think that's deep deep in in in like a deep challenge
Uh, for us right now is to overcome that. Um, if we if we wanted to get to agi because that that's really
Like the the star of human nature
Yes, I mean, this is so interesting. I will ask you other question a second
But this is this is such a fascinating topic. I mean, um, I think of creativity as something novel which makes sense
The early versions of information retrieval were kind of content filtering and then it became more
Collaborative filtering and the kind of the the bright line. I think between those two worlds is one is is a social concept
so for me for me creativity is about the
instantiation of a durable social concept, which means it's recognized that the relevancy is is kind of like
social proof
Right, so um everyone thinks it's a good idea. So it stays and you get these weird phenomena where
You know, things go viral only because of the social proof
So it's got nothing whatsoever to do with the content of the thing. It's just because everyone else thinks so so
Yeah, like maybe creativity is is purely just a kind of social ranking function
And nothing whatsoever to do with the entropy or the the embedding this I don't totally agree that because I I don't like consensus
like in in creativity
Um, like I think consensus is is
Anti-creative in some ways. So like if everybody agrees something is really cool. That's consensus
um, and so those things matter like things that we all agree on like those can be actually
valuable creative products
So there's no doubt about that
But the problem is that the the process requires some things that not everybody agrees on to actually get to see the light of day
Also because those are stepping stones to things that everybody agrees on
You know, I mean it's often the case that like some major breakthrough came from somebody who did something that nobody agreed on
So we need room for things that we don't agree on also
Which is why we need a diversity of interestingness detectors. Like we don't want just one
Um, and this is like, yeah, this is why this is such a hard problem
There's not a universal sense of interestingness that we could actually formulate. I think it's it's like a set
That's why I like population based like you mentioned. I like population based things like I
I'm suspicious of everything being point put into one single convergent system
Even though that that gets into really interesting questions about whether there could be such a like matt like a super brain
That just encompasses everything that civilization does in one mind
But I think even if it could theoretically exist, it would be incredibly complex
To actually construct compared to a population
Where there are actually like walls between different parts of it like that makes it a lot easier to have this bubbling up
Without consensus
And so it's not that no one should care
You know, that's not like it's not like the most interesting things or things. No one cares about
It's that there should there are different niches of expertise like in different niches of
You know of aesthetic preference and like they're all somehow good to have around
Because they flow into each other and then build on each other and intersect with each other over time
Could could encourage such another because I agree with you that so collaborative filtering the way it's implemented. It's basically
Convergent, you know, it has a consensus mechanism
But but then we were talking about whether it's about the content or the social validation
And it might it might have sounded like I was saying, oh, it's completely arbitrary if it's social validation
But let's look at carcinization. So like, you know, the the independent
Morphological evolution of crab like forms. Well, the reason why they independently converged in different places in the phylogeny
Is because they were just so
Physically well attuned and there could be a similar thing with
Social validation that it could just be so finally socially attuned that that's the reason why these diverse clouds of memes exist
And then maybe they kind of converge together later on
But it still sort of maintains that diversity preservation that that you that you think it's so important and I agree
Yeah, that that that could be. I mean the the the independent
discovery of similar
motifs
like crustaceans
is
Yeah, it is it there's an interpretation of that where it's because
It's because
Yeah, there's there's a generally well adapted thing and but I actually because I I usually don't like thinking about evolution in terms of adaptations
So that that's why I struggle with that because I I understand that the adaptation arguments for evolution
But I feel like a lot of the adaptation explanations are the explanations for the less interesting parts of it
Like I'm always interested in the divergent aspect of evolution
I want to know why does it diverge and so if you only go with adaptive explanations
You're actually sort of like asking for convergence because it's like those are the things that work whatever that means
So like that's where we should go
So it's we should y'all converge to crustaceans eventually because it's such a well adapted form
Um, and I think that like actually maybe another explanation of why you see all of those things like lots of different
Realizations of a similar theme
It's just because it's easy to make it that could be it's it's actually a priori
Like property of the search space that making stuff like that is just easy
It follows from a lot of different paths
So you'll just hit on it again and again because what we're doing is just illuminating everything that's possible over time
Um, and so we'll just see these things and some things are just more likely than others
Because representationally in dna. They just happen to be
Taking up more of the space not necessarily because they're better or something in that way
You know, because it's like what is is a crustacean better than a than a single cell?
Like I there's no really relative comparison there. They're both successful in their own right
It's not an absolute competition over like the entire world
So Ken actually you just created this serendipity social network
Um, you know, what why did you do it?
Setting objectives can actually be bad for creative achievement
Innovation or even achieving the objective itself that you wanted to achieve
It can get in the way
Because it closes your mind to all the other things that could lead in different directions that would actually be opportunistic for you
In other words, you can be deceptive to set an objective and and we we did a lot of research and ai that showed this
Um algorithmically, but then we wrote this book for general audiences, not ai audiences
Although it was meant to be also interesting to ai audiences
But we were hoping other people could appreciate it because we started to believe joe layman and i my co-author
Who worked on me with a novelty search?
We started to believe that the lessons there
Aren't just algorithmic, but are actually social like in other words
They apply to the way we run institutions the way that people run their individual lives the way we run educational systems
The way we run businesses and investment like everything because everything in this world is saturated in objectives
Including by the way social networks are extremely objectively driven like they're based on maximization principles
You maximize likes or you maximize follows you try to maximize exposure by maximizing attention
And then you get more and it's reinforced. It's very objective
And so it reflects a widespread ubiquitous culture, which is like worldwide, which is really interesting
Um, which is just like we all believe in this idol of of objectives that it should guide everything that you do
And the book is arguing that there are other incentives and other other
Gradients that you should follow like especially interesting this like not knowing where you're going to end up
But knowing that this path looks really interesting for independent reasons because it opens up a whole new playground of possibilities
Even though I don't know what the payoff will be
That that is very important to the advance of civilization
But it is not recognized in the way that we institutionalize everything that we do
And so like the algorithmic insight led to this like kind of social critique view
And that is why we wrote this book because we wanted to we thought this is like a big problem
Like he's granting funding agencies run on objectives
Like that's probably the most salient thing for us because we were like researchers
So it's like when we have to ask for money to do research
We would have to ask we would have to tell them what is our objective and we'd be evaluated based on the objective
Whether it's worth worth funding the research
Which is completely backwards if what i'm saying is actually true, which i'm very confident that it's true
And so I wanted to convey that confidence to the world by writing it down and putting all the arguments in a book
So everybody could see this and then it applies to all kinds of things. It's not science funding
It's like investing. It's the way that we run the the country the way they run education everything I said
So we wrote this book and so this is the beginning of the story is we wrote this book and the book is old now
It's like eight and a half years old, but around when it was about seven years old
That's around where this this this idea started swirling in my head of like that we should do this kind of
New kind of social network. How did that lead to that? Well, the thing was that
over the course of these
Seven years before I started feeling I should do this
I was the thing that the book did which might be an unintended consequence
Was it created a situation where I became the worldwide focal point for people who don't like the fact that everything in the world is objectively driven
It's like I was the the place you go to complain about the system
Um and everybody thinks they're in this system. I mean, I shouldn't say everybody
Of course, there's some people who just like are invested in objectives
But actually you'd be surprised how few that is like I thought at first the book would be very polarizing
And that there'd be like these two sides and be super controversial
But I rarely meet someone who really is willing to stick up for objectives. That's that's actually quite unusual
So it's actually like the book seems to be a relatively popular message that most people agree
But it's very paradoxical because of the fact that
A lot of the people who I talked to are people who are literally perpetuating this objective system
And they actually hate it, you know, and so I started to realize this like but the reason that they perpetuate the system because
Everybody feels like they're locked into it because of the next level up
You know, so you could talk to some somebody who's running like some, you know
So like billion dollar like government federal lab or something and they allocate money very objectively like to projects
But but if I talk to that person, they're like
I hate the way this whole system works
Like we would love to change things like the way that your book describes
But we answer to congress or we answer to an executive or we answer to like our investors or like it depends on what organization is
But everybody feels like they answer to someone and then someone they answer to is objectively oriented
And so there's no way to just do something radical and just like tamp down
uh
Tamp down those objectives
And so of course, um, you know, you what I'm talking about is just tamping down
I'm not talking about eliminating objectives from the face of the earth
We can still we can we can we can split the difference to some extent
It's we need to move the pendulum a little bit in the other direction is all I'm saying
So it's just not like I'm saying to get rid of all objectives. That that would be a kooky thing to say
Um, but like even moving the pendulum seems to be very hard
And so I got to meet people at all the levels like at the top levels and the bottom levels
Everybody affected by this system and they all hate it
They're all sick of it and even in like their personal life
Like they don't they feel like they they can't actually just do things because they want to just do them because they're fun or explore
Like they have to justify everything they do. This is particularly true of adults
You go the the younger you go the less. This is true
Which is one of the sad things like if you're five years old, this is not true
You just go to the playground and you do whatever you want. You don't care what it's going to do for payoff
But this is basically sucked out of us over the course of our education because the education system is extremely objective
Um, and so, you know, I I met people at all levels, you know, I met people from like
I would meet diverse walks of life and also diverse age groups
Um, like I would meet people like artists and doctors and retirement planners and military planners
Like I met such a diversity of people
But I met everything, you know from like the most senior person to like a 14 year old high school student
And like the 14 year old actually I met because his grandmother found me from hearing some of my stuff and
And asked me if I would come talk to her kid because he's too obsessed with objectives to her grandson
Um, and that was just like really surprising, you know, like each one of these things is like a revelation for me as an expert
Because it's like you wouldn't expect an AI researcher to have experiences like this. It's like a therapy session
I mean these people came into my office and we had therapy basically
I you know, I basically snapped him out of the objective fixation
Um, and it was really interesting to me too to to experience that like to see like what it does to somebody because you're
Like changing someone's life in 30 minutes. Um, and that's really fundamentally interesting
And so after experiencing these kinds of things over years like seven years of this
You can imagine this is like messing with my head in a way which is different than like AI research
It's like a parallel life. I was living
um, I was seeing that like
You know, there's a huge demand for a more serendipitous world because like what we're really talking about here is serendipity
Um, you know, because when you talk about good things happening that aren't planned because you don't have the objective when you get to them
That's like the definition of serendipity is unplanned greatness. Basically, which is you know, it's not a surprise
The book is called why greatness cannot be planned. Um, and so like I think what people really wanted was more opportunity for serendipity
You know, a lot of people argue that serendipity is random
So for a lot of people that would be a non-starter from a business perspective
Because you can't package randomness like sell it to people. But the thing is that um, I believe because of my all my research
And all the things I've been doing to me serendipity is not random
Like that's a very important thing serendipity is is something that that is that can be increased in probability
By increasing the number of stepping stones that you collect in your life
Or the number of stepping stones that we collect as a society
This jumping off points that are interesting
The more you have at your disposal that you've been exposed to the more places you can get
Which means you're more likely to experience serendipity. That's why some people seem so much more luckier than others
It's not just an accident. Like they put themselves out there collected more stepping stones
They've basically increased their serendipity surface so that there's more likely something chance will happen. That's interesting
Um, and this is why by the way, like if you go to wikipedia and you look at like the serendipity wikipedia page
Serendipity's invention page. There's a book on uh, sorry
There's a page on this like serendipity's invention. It has like a whole list of like inventions from people that were serendipitous
You know, like the microwave, you know
It was invented because somebody like walked by like a radar device and it like melted a candy bar in his pocket
And and and what's really interesting about it is that if it was true that serendipity was random
Those would all be just totally random people
But they're all really smart really accomplished people like across the board
Like that doesn't make any sense if this is a random process
Smart people have a more of an opportunity to be exposed to something. Um, and by smart, you know, I don't mean conventional smart
I just mean people who actually do things that are interesting
Which isn't necessarily conventional IQ or something like that. Um, those people have just more chance more chance
And so serendipity is not random. And so coming from that perspective
I started thinking there's usually be able to do something about this like everybody is so unhappy with the way that the world works
Um, you know from my experience over years
And I'm like, well, wait a second, you know
For a while I was thinking well, this is all a reaction to social critique
But it's not because it's a reaction to algorithms because the book is not a philosophical book
The book was based in concrete algorithms and empirical results
Which had nothing to do with philosophy
Like they were just things that I was exploring for algorithmic purposes
They're totally concrete things that were actually implemented and led to these conclusions
And so when I started thinking about this, um, like a like a year and a half ago when the book was seven years old
I started to feel like
Because it comes from algorithms. It should be able to to swing this back to algorithms
Like there should be a systematic way to construct a world that works the way it should work because everybody's so unhappy with the way the world works
And so I started trying to think like what could that possibly be? What does that even mean?
But then it was the first thing I thought was well
It's gonna be it's gonna be on the internet because I can't algorithmatize
Like the world itself
So something has to be different about the internet like the internet could work in a different way
So then I was like, oh, it's it's a network is some kind of new new kind of a network
Which exposes people to stepping stones in this more open-ended way, which is like inspired by open-ended algorithms
It's inspired by things like a novelty search or minimal criterion types of algorithms
Poet like it's inspired by these kind of insights we've had over the years
And and then it could be wrapped around people through a network
To make the world work that way. So then I thought oh, that's a serendipity network. That's like a cool idea a serendipity
No, it's like a thing you could imagine
But then the next thing I realized which is is that well obviously like within a second
I realized that's a new kind of social network because as soon as you connect people in a network
And it's information moving back and forth among people like that. That's basically a social network
So a serendipity network is a social network
But what's so fascinating about it at least to me at the time is that the trajectory of thought that leads to this
Has absolutely nothing to do with social networks up to that point
It's a totally independent trajectory of thinking like social networks has this whole history of decades now
Of thinking about mechanisms and stuff to increase engagement and blah blah blah
And that's what we have likes and follows and it's super objective
It reflects the the overriding prevailing objective culture we live in
It's like just that started to seem really interesting to me that this is just another angle of the same culture
That we're seeing that we all accept and assume is normal
Because it's been beaten into us that everything has to be objective that just seems natural
But it doesn't have to be that way
Um, and so I I started to think the serendipity network is a counterpoint
That's like really interesting. Sorry. I see you have something in your mind
People presumably see this differently. So some people have come up to you saying
I really hate the way society is running and you are giving the example of creatives and artists and
A lot of that is because it's it's not possible to quantify what they're doing
But I I like the lens of agency. So what you're basically saying is um, you want to live in a high agency society
And that's because the more agency you have the more serendipity you have the more stepping stones
You collect and then it becomes a political thing, right? So people on the left
they don't think we have any agency and
People on the right they they want a high agency society
The reason they don't want a government is because what does a government do? It erodes your agency
It's it's kind of like a agency eroding. Well, uh, you know, it's that's that's an interesting point that that I have not
I haven't rarely addressed the connection of any of this to politics
It has come up in some rare occasions actually but very rarely like it's come up because
There are specific cases that have happened where somebody very political did come to me
Excited because they thought the book justified their point of view
Um, and in some cases it was people who I totally disagree with their political point of view
But it was really interesting to me that that they they saw the book is sort of empowering to them
And I've seen that on both sides
um, and so
Rarely have I discussed this though
And I want to point out though that like it it is the book is very apolitical because of the fact
That I see this on both sides
But if you really dig into this, you know, I think what you just did by by by putting agency as sort of like the
The abstraction of what I'm saying
You you succeeded in couching this in a way that that would nest potentially bias people one way or another politically
So you've basically just pushed it to the right
Um, but I don't think that that's what people usually do. Um, that's your interpretation of it not not not to the right necessarily
I think it's more of a um
The the words authority and paternalist paternalism and autocracy. So in a in a company
We run companies in a very autocratic paternalistic way
We have, you know, like big corporations have um, lots of ethics boards and you know policy boards and
And I think the justification is it's about control and alignment
And even with facebook, for example, that there's there's power seeking behavior
And the way you gain power is well the way you subjugate people is by taking away their agency to give you more agency
But you see this on the left and right. So on on on the left you you you get kind of like, you know, um, you might be
Like chomsky and a narcosyndicalist and and you want the diffusion of agency or you might be
Like Mao or Stalin or whatever and and want to have like, you know, you don't want anyone to have any agency
So I think you see it on both sides
Yeah, that's that's right. Yeah, I think you see you see agency deprivation on both sides
And so like you can interpret you can interpret
You know the book with respect to agency as sort of an argument against it whatever sides you want
I think, um, you know, because like it's true that, you know, like I've I've heard this
More right-leaning argument like like in that that sort of like the book seems to enable
That like there's a lot of like belief in top-down planning that like it is like sort of leftist kind of belief that
Like you just have the government plan everything and that this book sort of like disabuses all of this
This is really great
But on the other hand, like from from the left side, like you have this idea that like
Exploration is extremely important in life, you know
And you think about like things like youthful exploration and it involves like doing things that you actually want to do
Which could involve things like doing drugs
It could involve things
Like having partners in different forms that aren't necessarily socially sanctioned in the way that people on the right necessarily want them to be
Um, and so you feel this kind of like also attempt to kind of like control autonomy coming from the other side
Um, and so, you know, and it's true
Like if you go to either extreme like obviously like you have dictatorships on the left or the right or autocracy
Um, and then you get a lot of control in a lot of different ways
But it's different kinds of control because there's different different kinds of political inclinations there
That I think I want I would like this book
In this point to be totally a political because I don't think it has to do with any particular political movement
I think all of us can agree on this which is rare
That we all want to be able to explore things that are interesting
Um, and it's true. We have to put limitations on that. That is true. That that's what society needs to do
And I think every side would agree some limitations are necessary
Somewhere but we can we can disagree on what those limitations are and that's left first right
But the general point that we want to maximize our autonomy and ability to explore
Is still important. I think and we can then go on to interpret it politically in terms of what those restrictions should be
Yes, yeah, and I wrote an article recently and I was talking about the strange bedfellows
In in the free energy principle, but that was just that you get people on the right who
Are I don't know they believe in crypto and decentralization and and so on and and you would actually think that these people are arguing for
You know agency maximization
But the interesting thing though is that when you look at the behavioral complexity of the sphere of the left and the right
All of the complexity is actually on the left
The left has this tendency to infinitely fractionate and kind of produce entropy
And there's a famous saying that the left eats itself and that that's kind of like, you know
Almost saying that they're spending more time infinitely kind of slicing and dicing them up and creating complexity
Whereas the right is is very
monolithic and homogeneous
Yeah
Okay, yeah, I mean I could see that I mean, you know and like the concept of a social experiment
Like you know the the left sometimes wants to do a social experiment
This is actually exploration. It might be interesting. Actually might be bad, but it could be interesting
And and the disagreements come with this idea of where to put the constraints, you know, because I think
We should all agree. I mean algorithmically. I totally agree that open-ended systems need to be constrained
Like there's some things you can't actually invest in they're too dangerous to invest in so we just won't go there
Um, and you know even evolution has that like that's why some lineages stop
They basically have run into the constraints of the of the physical world
Um, and so it's a question of what the constraint should be is really the the political debate
I mean obviously and the open-ended goes beyond politics because if you're building an algorithm, it's generally not a political issue
Well, it's becoming one because ai is becoming political
But a lot of the time you just wanted the algorithm to do what you wanted to do and it's nothing to do with politics
But these issues still come up if it's going to be open-ended it's going to explore
It's going to be creative and it's a creative algorithm and you're going to deal with what the restriction should be
It's just not really political in that case. It has something this is more of an algorithmic question
But constraints just come up and then we really fight with each other a lot about them
But I've been I've been extremely happy that the book has remained effectively a political
Because it allows it to make a general point. It doesn't just get everybody
That we don't immediately form sides on like that's only I really would like to avoid because it hasn't done that yet
Um, like we we tend to like can't form camps immediately around every issue
You know, you know, you can't it happens like lightning fast like covid happens like everybody's on one side or another
It's like instantly like we're all mad about one thing
but like here like
It hasn't happened and I feel very happy about that because it's a social point that we could actually rally around here
No matter what side we're on in politics because not really a political point
You know deep in your core deep in your core
Why did you do this thing? Uh, well, I think so, you know deep in my core
the
The the well, there's a number of things
It's even though it looks on the face of it
Like this is not a natural thing for me to do like I remember somebody when I first
Tweeted about me even like somebody said wow, I never would have expected him to do that
Um, and I can see that if I simulate what people would think I would do
But the thing is that it actually really follows very naturally from who I am because I've always been interested in these kinds of
Divergent systems and like the ultimate divergent system is the world itself and the people in it
It's the people in it who do the surprising things who invent the things
Is to facilitate that in the real world is like the sort of ultimate
extreme of like
Investigating open-ended systems even though it isn't just pure AI
Because obviously if there's people in it then the eye is coming from the people and the system
So it's not it's not only people there's a system too that's like connecting those people in intelligently
Which is drawing from insets in AI, but it's not just pure AI research
But for me it's basically an extension to the extreme of like let's do the ultimate open-ended experiment
You could possibly do today
And so in that sense, it's like really invigorating for me like an experimentally
But also the thing that really appealed to me, which is deep. I think is deep in my core
Is that I was um like everybody I was starting to feel the um
That the the social implications of AI more strongly
Um like in the last couple years
Um and like as somebody who's been around a little longer
Um like for a couple decades in this field
I um
I I was used to not that not being part of it, you know
Like so so it might be more shocking for me like someone growing up in AI today might might be less shocked and just this is kind
Of like the way the field is
But for me it was it was more like just like a playground where people were friendly and doing intellectual stuff
Like it wasn't like this huge polarizing political issue like it. Where is AI going to go?
So when that started to hit, you know around the the time of gpt and then jet chat gpt
Just exacerbates it the large language models
And the and then the image generators too and like a very strong political ideologies start to grow up around it
Um and concerns and worries about things like ethics and safety and so forth
It was complicated, you know to square that with the way I thought about it before
And it made me feel uneasy. I would say
Because suddenly things that had just been really for fun. It became like really serious in my mind
And I I hadn't really rappled through like what exactly I think because it's hard to really
Conclude on some of these things like what should we do? It's very complex
So like unlike a lot of people who seem to immediately take like certitude style of views. I just like
Take a long time to decide what I think
On complicated topics like this. So it's like not really in a camp exactly, but just really trying to understand
um, and I just felt like I would just like to do something that's just like
Clearly socially virtuous like that. It isn't ambiguous in this way for a little while
Uh, well, I don't really know what's right or wrong
um, and it just seemed like that like doing something to
Make, you know humans and the way that they interact with each other
More human is just like an obvious virtuous thing to do for the world. It might not work
I mean, I I admit that like I could be wrong about housing and work
It could fail or it could even like succeed in a bad way where it's actually unintended consequences
But at least what I'm trying to achieve to do something to facilitate
Communication that's different that serendipitous rather than popularity and attention driven
I feel very confident that that's a good thing
It's a good thing to be involved in and it uses AI and it's open-ended
So it's just still using the things that I think about
And so it just seemed like such a good fit for the moment like to actually like take AI and just do something that's nice
And um, and then it just puts all the things together that I care about and the only downside to it is that it's
Ridiculously ambitious and likely to fail. But other than that, it's a really really good thing to try
Quick point on that because a way of reframing what you're what you're saying is that
living in a agency amplifying society where people can do what they want to do without being
Stuck in the orbit of other people and that will have the effect as you were saying of
Increasing the behavioral complexity and diversity of knowledge and diversity of everything
Diversitive stepping stones in our society
You're making the the kind of the statement that that is a virtuous thing to do like that that is what we want
But in simple terms, why is that a good thing?
Yeah, right. Thanks for asking that. Um, you want to be more clear about that, you know, because just increasing like serendipity surface
Is a kind of an abstract concept
Um, it's I think it's cool and there's probably some people listening who think it's cool to think about like a more open-ended type of
Network or something like that we have more discovery more diversity more divergence of thought
But like why is that virtuous is the question?
And when it comes to being virtuous, it's because it's a counterpoint to all the other stuff that's going on on the internet and social media
Um, and like all that it's sort of um a coincidence because that wasn't what was motivating me
Um, like when I like thought about this at first, you know, it's more the kind of like oh, why greatness cannot be planned and stuff like that
But but like once the idea came into my head
It was obvious that is a counterpoint to a lot of stuff that is not virtuous right now
Um, and it's because of what is social media doing to us in our heads and doing to our society
Has become um like a rallying cry like again across left and right like everybody sees that there are problems here
They may disagree on the problem some example. We all recognize some of these problems universally
Which are just bad for us like and they span
Like a really wide range from like just mundane things like the fact that you just spent hours of your day
Addicted to something when you couldn't be doing something else to like much more dangerous things
Like disruption of democratic processes and things like that
um
And and you've got things like clickbait and you've got things like flame wars and you've got misinformation and you've got lots of things
But toxicity that like make you feel similar to to me
It's like after if you just like couldn't stop eating a big chocolate cake and just ate the whole thing in one sitting
It's just like you you feel a little sick after you consume that feed like the doom scrolling
Um, and we we all recognize it and describe it in different ways
You know, it's not the same for all of us the way we see the problem
But I think we all know that there's some kind of problem here
And I think I've come to conclude that the reason there is this problem
Is that it is the unintended consequences of the deceptive objective
Like we think that having an objective of maximizing likes and maximizing follows
Is a steady path to the ultimate best thing that you should be exposed to
Like that's the search process is we're going to get consensus
And we're going to show you the thing that's the most important of the day
And that that is actually that is actually
A coherent thing to be doing that that gradient actually makes sense
But it's a complex system and this is deceptive
And so we are seeing all of this stuff that makes us feel pathological
Is because actually that objective does not make any sense
It is a deceptive objective like all other deceptive objectives
And what I could do is help us to
Escape that and have a different alternative way for the world to work
One reading is it's just the wrong objective. It's a deceptive objective
So we're trying to create a system which is a high fidelity representation of how the world works
But facebook have got this deceptive objective that just brings out all the worse than us and
You know, I think I think we intuitively know that it makes us unhappy
But is it because of the erosion of agency?
Is it because of the particular deceptive objective?
I mean, I guess there's a thought experiment where what if it was a different objective which was
More closely aligned to how humans work
So is it the lack of agency or is it that particular deceptive objective which is causing the harm?
Well, it's it's a really complicated topic, obviously because the the implications of the objective are really multifaceted
So it's not like there's just like one thing that this this relates to
um, it's multidimensional and so, um
There there are some good things about it, you know, like I it's not like all
ubiquitous bad news like there's some good things about social media
In fact, like I would not advocate a world where everybody just shifted over to maven and just dropped all the other social media
Like I don't I don't think that's good either
Because it accomplishes some things that actually are good. Like for example, like I think it's useful for getting announcements out
um
Like if you want to reach an audience and you have an important thing to say
And it's the people who care about the things you say then this is very convenient that you have this megaphone
Which is provided by these systems that maximize
follows and attention and things like that
Um, but it doesn't work for most people, you know, because it's very a tiny tiny elite minority
You have the megaphone like those are the people who've attracted all the attention
And then the perverse incentive of it is that getting attention requires you to do things that I think like relates to what you're saying reduces agency
You know, because like if you were really just being yourself, you wouldn't do those things
You wouldn't do those things in public even like you're doing things that are actually embarrassing
And people are doing it every day
Because your agency is reduced because you're responding strongly to these powerful incentives
These incentives are like surprisingly powerful
Like I don't think anybody would have known including the founders of these services. How powerful just a like is
On the human psyche, but it's like it's a truly like, you know, hardcore drug
And it can get you to do crazy things
And so like, you know, at first I think they might have sincerely thought this will actually lead to better content
Like that's like the key here
We need a differentiator to know what's good and this is so easy
Like you just have some press a button and then we can like get consensus and it's it's not like this is some like maniacal plan to control the world
But like it has it turns out it's like a really powerful drug and it's reducing agency
You know, so like it's from everything from the fact that like, you know, you've got people you respect who are just like driveling with clickbait
Which is embarrassing at some level because they they're just responding to the fact that's what they need to do to get a megaphone
Two things that I think are like more on the humorous level
Which is that like something I didn't realize is that like the truly
Pinnacle achievement in the world for like the like the most the most accomplished person you could ever imagine
Would be to just have one little quote in one of those books of like famous sayings
Like that's what people really want. They just want to be like, you know, when you hear a quote of george washing or something
They just want their name as beside that with their little pithy quote
And you see these these like want to be sages every day with their pearls of wisdom like dribbling out onto the internet
It's somehow like even though they're like like the most famous people in the world
They have like a Nobel Prize
But they just got to keep letting you know, like I've got really interesting things to say
That is not normal behavior. Like this is all responding to like this really deceptive to this really deceptive objective
Um, and in some ways a little embarrassing because to me it diminishes the greatness in some way to see people acting like that
Like I would think they're like above it in a way like these are these are the great role models of our time
Um, and and they're acting in this way because it shows we're all just human
Um, or at least I would have thought they were and so I I think you know, like all of this is
Is a reduction and then another thing that reduces our agency
Is this like the mundane fact that I would like to pursue things I'm curious about
But I don't feel like I can that's clearly a lack of agency like it when I tweet or something
You know, I have enough followers that it could be useful to tweet something
Because I can reach a number of people. Um, and so but I because of that I feel like I can't tweet certain things
Um, because I know what their expectations are. It's like I'm a brand. That's why everybody talked about personal branding
I mean, what a disgusting idea to brand your own self
But this is like considered just like normal stuff now like everybody's branding themselves
And you can't avoid it because you're gonna lose if you don't, you know
Like because I might have some interest in washing machines or something
But I'm not gonna I'm not gonna start talking to my followers about that like that's not what they expect from me
It's gonna be total disappointment and I know I don't know what I'm talking about too
So like part of my like, you know, brand is that I know what I'm talking about like everybody else
So if I start saying things that are like way off base and ridiculous
You know, I'm just diminishing my brand and it's like actually the guy's an idiot
And so I'm embarrassed and I don't want to do that
But I actually might be curious about these things like where can I go to just talk about things?
I'm curious about is actually really interesting that can't do it there
Then you've got this huge population
99.9% who don't have enough followers that they even could get their message out
And are like totally disempowered and have no agency at all
You know, they actually have interesting things to say not all of them, but a lot of them do obviously
Because some of them don't even want to play that game
That's why they don't have their megaphone, but they still might have something interesting to say
Where can they go?
So I think all of us have a really diminished agency in this like totally deceptive objective culture
Which I think is is like a really cool opportunity. It would be virtuous to fix that. I'm not saying that I know I can fix it
You know, I'm like this savior like figure like that's not what I think
I'm just saying it's worth trying to do something about this
That is virtuous to just try to try to create a real alternative
Yeah, that was that was beautiful. But yeah, just a comment on what you said, it's so true
I mean, um, what what's even more interesting is how quickly it's become received wisdom and accepted by everyone like, um
LinkedIn for example, they're giving out these top voice badges and people are now, you know
It's their full-time job to be the marketing department for open ai
So every time a new model gets released they'll use gbt and they'll generate a press release and
And then they've become a top voice on linkedin
And I always thought that youtube was quite immune to this because youtube does actually
You know, um, it optimizes for satisfaction and you get some very interesting long form content that
What little did I know the more I learn about youtube the realize that the more I realize how debased and deranged it is because you start learning about
Thumbnail optimization and clickbait titles and how important the first five seconds are and how you're doing this psychological manipulation
And actually just look at all the popular videos on on youtube and it's just garbage. It's just debasement and and also it's it's
It's debasing our behavior. It's lowering our moral standards in in many ways and all sorts of weird stuff like that and nobody notices
Hey, can I add to that because um, there's there's also an interesting thing about that like youtube and you think about that
That intuitively you would think that it would contribute to like in in other places
We've talked about like open-endedness and how it contributes to the continued march of civilization
Like more diversity more divergence of ideas more interesting things going on
So you would think youtube is like going to absolute like poor rocket fuel on that like that's what I would expect
And to a little extent you see pockets of this like you do see
Certain new stepping stones that you wouldn't have seen before
Because there's such a vast amount of like opportunity now to reach an audience with something that hasn't really been tried before
um, but
Somehow something about culture also seems broken at the same time
You know because like where are all the new musical genres that used to happen like they don't seem to be happening anymore
um
Like like things seem to have stopped somewhere around the year 2000 a lot like I was you know
I was saying like that like in rock music used to have like a new
Farm like every like 10 or 20 years like what what happened like the radio sounds exactly the same as it did 25 years ago
um
And like I think part of it is that this is another side effect of these kinds of objective driven algorithms
These are convergent algorithms the the like aggregate effect over decades with millions of people is incredibly hard to understand or digest
But I think we actually seeing the aggregate effect now that like it's actually
Causing a kind of like slowdown of cultural progress
Um and convergence to like already agreed upon standards
That is just like really deleterious to to to cultural and probably other types of progress that otherwise would be happening
That's so true. I mean you can argue that it's a kind of continuation of globalization in general
But we've certainly seen this in in the uk so we used to have quite a distinct culture and since
Even since mtv and cable tv and so on but even more so since youtube there's just this global mono culture now
And I completely agree with you that all of the interesting diversity preservation has gone and everything's just becoming the same
um slave to the algorithms and all that and so yeah, it's um
It's really interesting. The other thing I wanted to comment on is even things like
Our search engine and our info sphere
If you think about it
Where's all the new information coming from so like now we're using things like perplexity or we're using
Retrieval augmented generation on top of the search results
So no one's looking at the search results anymore
No one's looking at the individual pages and they're kind of cannibalizing each other
And now we're producing this thing where there's there's no fresh information to build a search index anymore
Right, so we just kind of like feed, you know
Garbage in garbage out and and we're kind of eating our own poop to a certain extent so
It almost feels like there's going to be a mode collapse of all of the information and the reason for that is as you said
We now have
An entropy and agency minimizing society, which is the complete opposite of what we need
Yeah, yeah, it's like ultimately it's a kind of a permission not to think is what it creates
Like to think for yourself
Because everything's been ranked and everything's been already classified and there's already mass consent
Like how can you disagree with a million people?
It's like it's already consensus like it's just you come in and you're like this must be the best thing
And of course you still have your own brain and you can still feel like add and really like that even though everybody else seems to like it
But the truth is it's having a massive effect on you
Like with the fact that every single thing that like comes out even like a single sentence that somebody tweets out
Like in the middle of a conversation is ranked. It's that's insane
Could you imagine if that was like happening while you're at the dinner table?
And like you're having a conversation like numbers appear above people's heads while they're talking like this
See who says the best thing to say it would totally distort you
I mean you would you would be mentally deranged from something like that, but that is what's happening
Um, that that's the way we experience the world on and every level from like like a like a big new movie to like a single sentence on
On x and it's just a it's just it's a crazy pathological perversion of human nature
Which is being just just totally like like forced upon us
And so so yeah, like the idea like some people can't even imagine there's an alternative world
It's weird because like 25 years ago there was an alternative world like this stuff didn't even exist
Like I used to socialize. I think so I had social I had social uh social experiences
And there were no like buttons and but now it's like well what there is no such thing as a like a social network without a
Like button like what the heck does it even mean? That's that is what social is
But there are alternative worlds and I think um, you know, I I feel like it's possible to
to pursue one um in my case like the problem is it's really dangerous to to pursue them because they seem crazy
It's like if you just said oh the facebook would be better if you got rid of the like button
If you got rid of reactions and you get rid of following your friends and but it's like that's better
Like what what is that? Like that's the whole premise of the whole system
Like I will not be able to sell that to mark zuckerberg. He won't do that
Um, and so like that's not that is so dangerous that that's why I think nobody's trying any alternatives because it sounds crazy
But the reason that I feel like I'm empowered to actually do something radical like that
Is because I came to the conclusion and the framework for it
Not by trying to undo what already exists
But just you're completely independent trajectory of thinking like I have nothing to do with all that stuff
I wasn't trying to get rid of it. I was just thinking about how serendipitous systems work
I was working on opening algorithms for decades
Um, like I just have a trajectory of thought that just totally independent and it just leads me to a point
Which happens to be different and that's a reason that it isn't crazy like it actually comes from thing
It's not just I'm just trying to overturn the status quo because those kind of that kind of radicalism often is just like doomed for failure
But I have like a just a different set of thinking and so like I think that that gives some hope
That like an alternative world could exist
Um, and it's worth a try you know worth to try to to give this alternative and then see what that might actually be like
It feels to me that human beings must be better than chess computers and we just don't know
Yet we haven't proven it yet because human beings have creativity and chess computers don't so presumably there is something a human
Could conceivably do that would break the chess machine. We just haven't found it yet
And what you know my read on what you're saying there is that
There's almost no scale when it comes to creativity if you're doing something creative
One thing which is creative isn't necessarily better than another thing. Yeah. Yeah, that's a good way to put it
It's totally true. You know, it's like when we talk about evolution and we talk about fitness
We think of it as like this absolute measure that like helps us to understand like why something survives why something doesn't
But think about it like when you think about creativity think about it like between like very disparate species
It's like a meaningless thing to talk about
You know like the fitness of a bacteria versus the fitness of a human being
It's like what do we even mean like maybe we can mean that like the bacteria actually reproduces at a much faster rate
And actually any given bacteria has many more offspring than any given human like there's different ways we could talk about
So they're winning. I don't know if you want to put it that way
They have more higher fitness than actually absolute numbers. They also would there's like way more bacteria than humans on the face of the earth
But what's the point of this comparison?
Like it's the creative aspect is actually the interesting
It's like we're missing the forest for the trees
But we're trying to be extremely objective and of course you generally wouldn't talk about bacteria versus humans in that way
Because it would be ridiculous, but we do that with content
Which is ridiculous
Because like the actual interesting thing is the creative component
Not some superficial stuff like how many bacteria can you count in the world?
um
And so it's like these these like more these orthogonal dimensions
Like what humans actually do in their lifetime and stuff like that that makes it worth caring about us
Even though we don't actually have as much biomass on the world in total
And so yeah, it gets silly at some level and create a very creative domains
Or when you care about creativity to try to be extremely objective to make decisions about what we should focus on
Should not focus on
And if you think about it like the entire social media world works that way
I just wondered whether you could bring in the the market system and the profit motive here because
You could argue that even in a corporation where the central goal is to make profits
There is still even though it's a constrained space
There is still an infinite number of
Instrumental sub-goals that would lead to the company making more money
So, you know, the the whole greatness cannot be planned
Idea is that we should be discovering new stepping stones and the and the powers that be in the company shouldn't necessarily be eroding
Your agency and telling you what not to do
But in a purely creative pursuit or even maybe in a serendipity social network, there really is no grounding principle at all
Yeah, I mean it's very true
That corporations also face this issue. I mean because of the effect creativity
Reoccurs and over and over again in many many different situations
And I mean you can go from evolution to social networks to corporations look at just a ubiquitous issue
And so yeah, look even in corporations like you will have a lot of convergence
Obviously if you have a single objective guiding the entire corporation and you'll wipe out things like research labs
I mean, you can't have them
They won't be doing research at least you could call the research lab
But if they're all basically subservient to the bottom line
It's not actually research lab because research means you have to do things that actually are not necessarily guided by the final
Ultimate short-term objective and that's um or even long-term objective
We need to be independent of objectives in order to explore interesting paths and that's a way of preventing disruption
You know, that's why it's strategically important even though it may seem like it's off path, you know
Because it's like what what do we really care about and other than the bottom line if this is about profit
But the thing is that like you won't be having any profits anymore if you're disrupted
And disruption comes from unpredictable areas and it's not just about optimizing along the path that you're on
Um, so to prevent destruction you need some ability to look outside and that means yeah
Not queer caring only about a quality maximization
principle and then of course that crosses over like you say into
Social media really strongly because there isn't even a profit motive to a large extent
I mean there has become a lot of profit motive. I mean there's a lot of people
Who are using their brands to make money on social media?
Um, but like from the point of view of the aggregate system or just an end user who's just trying to experience something interesting
What does profit even matter? It has nothing to do with what you're getting out of this thing
Um, which is partly why Maven is at your risk risky endeavor
um, but this is this is uh, it going to be, um
Arguably better for for like the end user to just be exposed to more interesting things for them based on what they're interested
In um and get away from the maximization principle that sort of guides
Everything in the world and we were saying before
Because you could take a cynical and take on this but but you convinced me before that serendipity is a natural thing
Because you could argue that for example, I can go and set up a youtube channel
And actually serendipity is instrumental to power seeking or me wanting to be famous or whatever
But it comes back to this notion of agency and I want to I want to try one one more time at this because I just think it's so
Powerful as a lens to kind of think about some of some of the things you speak about
and I think of agency as a thing with preferences or or volition which
Successfully shapes the world around it to match its preferences. So that's kind of what I think of as as agency
And I think it's really related to power seeking
So for example, one of the reasons why things want to shape the world around them
Is because they want to kind of commandeer
Or even steal agency away from the things around them
And then there's this notion that um, you know innovation in a sense or in its essence is quite heretical
Right. So, you know, there was this story of uh, I think giordiano bruno
In the sort of uh the 16th century in florence or rome or whatever
He thought that the stars that we see at night are actually quite similar to the sun
And you know, they might have their own planets and even suggested that universe is infinite
And uh, you know, there could be no celestial body at its center
And he was burned at the stake in 1600, right?
So, you know, there's there's a saying that science advances one funeral at a time
But I think the reason he was burned at the stake was because such an idea would diminish the agency of the catholic church
And similarly, you know, when this einsteinian
Relativity was doing the rounds in the 1920s even though newton died hundreds of years ago
There were still people who were kind of like sequestering power and agency just being on the orbit in the orbit of the legacy of newton
So presumably they were writing books and reputations were made and so on and and as soon as you kind of tear down that myth
All of their power dissipates so that there seems to be like a real power dynamic to this as well
Yeah, I would agree with that. Um, and it's
I mean, we become
invested in
Whatever has given us success or where we've staked our career where we built our reputation
I mean, it makes sense that that that would matter a lot to people and people tend to have staked their reputation in
The previous paradigm. I mean, that's basically always the case. I mean the next paradigm hasn't happened yet
Um, and so when somebody comes around with a new paradigm
It's a threat to everybody is a threat to everybody without how they've staked their careers. And so it's it's going to be heretical
Um, intrinsically heretical. Yeah. Um, and you know, you you can see
Uh, like growing consensus around certain paradigms a little like large language models like today
Um, and of course, there's always going to be, you know, some some people some pranks that are you know, snipping at the side and saying like
Uh, we you know that we're going to get rid of lms or something like that
But those aren't really the things that are a threat. I mean, it's more like if somebody really has something creative to say
That's like totally out out there. Then it's a threat. And then we would expect. Um, there's going to be an immune reaction
To protect the status quo. Um, it's a problem. I mean, you see that in I mean that definitely happens in like, you know
The way your grant review happens like that like you're reviewed by your peers
But your peers generally represent the status quo. So, um, of course
It makes it hard to get anything through like a like a grant committee
Um, to get funded if it is truly heretical. How can you fund something heretical? Um, and um, it's just a big problem with
The way that you know, our objective based way of working like like if you we try to imagine
systems that actually can
function around
Assessing heresy in like a productive way. That's like not the way anybody's really thought about the system
I mean, because like obviously some heresies are are actually a waste of time. There's no question about that
Um, but like sorting between which are and which aren't is is not really anything anybody's concerned with officially
Um, and so that that's just like it isn't a really great function that we have right now
And I see the connection to agency and power seeking. Um, yeah, because like it's it gives you power
to be connected to the status quo
And yeah, you can build a career in the status quo
So that's that's going to be that that's that's maybe unfortunate side effect of of actually discovering things
It creates power and then people get invested and then they become entrenched to the last year's heretic is now like, you know, it's a day's dictator
So, um, it's just a cycle that it's hard to get out of because we're humans. Yeah, but um
One interesting take though is that I mean first of all, there are many degrees of freedom when it comes to agency and power seeking
So just uh, the agency to read the kind of books
I want to read is a kind of power or dominion over my
Intellectual life and there are some things we I mean even like murdering someone for example
We we technically have the agency to do that, but we wouldn't because there'd be consequences
So there's all of these kind of conditioning forces and and so on. Okay. Let's see. Is any serendipitous process of form of power seeking? I mean the
Um, that is that sounds cynical, but let's let's see. Does it make any sense? Um, so, you know, because I I do think that
Without without that point without you making that point
I would have said that, you know, serendipity
Is one of the more
Pure types of motivations if if you can call it a motivation that like, you know, so just doing things because you're curious
Um, just exploring the world or something like that
Um, it's not like intrinsically trying to figure out how to gain power in the world because trying to explicitly gain power is
Is an objective type of thing. I mean that would be your objective then is to gain power
Um, and so, you know, if you're just truly just curious, what would happen if I did this?
I mean, it's not clear that you're actually explicitly aiming towards power
Um, but I mean so it seems like if you are getting power through serendipity, it's more implicit
Like it's something like just by virtue of truly falling into something some stumbling into something cool
It creates a little bit of power around you. It's like people might care about it
You might be empowered because you can do more because it's I mean, what does it mean to be cool?
It's like something something that does something that's worth some attention. Um, so there's some there's some like sort of um,
Yeah, maybe tangential power jet power that's acquired through serendipity, but not always and I think some some of it's just pure
Just purely for your own consumption, you know, like if you find a show you like or something
I don't know what level of power
Uh, you know, maybe you can tell your friends so you did get a little bit of you get a little empowered by it
um, but I remember thinking like um early on when I was uh
You know when I was researching neat like the earliest thing that I did was the need algorithm like in grad school
That was my dissertation
Like I didn't have much experience like understanding how people get like known or something something like that in research
Or or famous for that matter. I didn't really understand any of this
And I kind of just assumed that no one would care like I don't I don't think I was really motivated by people can't
Because I was just like the thing that's really
Good about this is that I'm allowed to do it
More it was more of that like I can just do what I want because interesting and I thought that was really
Cool that I could just like explore stuff and and no idea that like a single person would ever care about this at all
But I thought well, it's really I like the fact that no one seems to have done this before that was sort of my motivation
Um, it did maybe create power in the future because other people did end up liking it which really shocked me
Um, you know, like I I didn't actually expect that. Um, but um, but I think like the motivations there were not very objective
I mean, it's just like I just really just curious and just really grateful that I was allowed to pursue my curiosity
Like I remember when I did my proposal
That I felt very very successful that they approved it
But mainly just because it was like well, I'm allowed to look at this for two years or something
I can just think about stuff I want
Um, that's I think that's more serendipitous thinking
Um, then just like how am I gonna influence people and control things and stuff like that?
Um, but this is an issue. I haven't put a huge amount on it. So maybe you have other thoughts about that
Well, I think it's it's fascinating for a couple of reasons. I mean first of all, I guess I'm only arguing that it's the same kind of stuff as power
So I'm not necessarily saying that
um, you know serendipitous exploring will turn you into a
You know into a maniac who wants to take over the world
I think there's a difference with having the volition and the ambition to want to take over the world
But the paradox is as you just said if if the person were to be successful taking over the world
It would be via a serendipitous process
And in a way there is because you because you always make the argument that there's not a monotonic increase if you line up
The objectives but but in a way that there kind of is because the first stepping stone embarking on this serendipitous process
Is as you just said, oh my god, I've now just got dominion over my creative thoughts
I'm no longer in the four in the gravitational pull of these people
I can now explore things that I genuinely find interesting and i'm in a very happy place
So I I now have power over my you know my even
Deciding how to brush your teeth on the left side of the right side is a kind of a kind of power in an agency
And then and then for whatever reason the thought might occur to you. Oh, I want to take over the world
Or it's an externalized process and when you see several pockets of you know independent serendipity
And being executed those pockets become clouds and then the clouds become very powerful
Yeah, I mean there's I would probably more use the word autonomy than than than power when I think about like what I
What I would be excited about when I get the chance to explore on my own like I gained autonomy
Rather than that person telling me that this is your project now. I can just say my own project
But I mean autonomy is a form of power
So but I mean going away from just like semantics. I think that
The problem is that there's some kind of entangling here between
like algorithmic issues and human psychology because I mean
Like power seeking is not just an issue of an algorithmic question. Like is it an objective or not?
It's also like a psychological issue like with us and you know algorithms might not have that psychological component to them
Like if I try to create an open-ended algorithm or something something like the psychological explanation for why it's doing things
But in terms of humans we actually yeah, we do seem to like
Getting dominion over more and more stuff
So it's true that like a stepping stone might be interesting because it gave us more influence over the world
And then we can jump off from there to something else that would also be serendipitous
Which actually as a side effect creates even more influence and in some way
We're following a gradient of power and getting more and more influence
um, and that's that seems to be um
Just something that's psychological like the fact that we like that or care for that and um, but but I guess
Like the point about agency makes sense that like, you know, you're you're actually
gaining agency
Well, if you can do seren I'm not sure serendipity is causing you to have more agency or is it that agency is causing you to have serendipity
Because the agency is sort of like necessary in order to explore
But then you could argue that because you were successful and you found something you'll have more agency on the next iteration
Um of your exploration. I mean
So maybe they they feed into each other in some way
Um, but that's just a side effect of the way that society rewards things. Um, I'm not sure there's like an algorithmic principle
Um, but yeah, there's definitely some some entangling between these two ideas. I can see that
What would your main argument be
for the morality of
people being able to independently shape their world
Well, I guess there is a moral component to it. I mean
If I didn't think so, I wouldn't have
Gone on with Joel to write a whole book. I mean, I I thought that this is actually a wrong that should be corrected in the world
and it it's um, it's partly for
practical or you could even say utilitarian purposes that I actually think that
We will be more effective as a society
by
Allowing more serendipitous exploration like that that actually is important for our survival and continuing progress. So
but but I mean it's also true that for individuals and
the uh
Like the human flourishing like to be to actually be happy. It seems like it does seem to be
An intrinsic aspect of human nature that there's a need for self-expression. I mean, I do believe that too
Um, which is a really interesting thing about you know human nature because
Like when we think about things that are getting better at disseminating content to us that we would like
Um, like that is that sort of implies that human nature is mostly about consumption
Um, you know, it's like the whole thing is to optimize your consumption
So that you're satisfied you feel satisfied and like it's like the the ultimate end point of that seems to me to be like
That there'll be an AI that just basically 24 hours a day generates movies that are just optimized for your brain
Um, so you don't have to do anything. You sit there and consume. It's like all perfect for you
You're like, that's the best show I ever saw and then another best show you ever saw all day long
But the thing is that like that can't possibly work because of the fact that at least my theory is human nature
requires self-expression
um, you have to also
Produce in it in addition to consume to be a satisfied person
um, and that relates to serendipitous exploration like what you cannot produce without exploring
um, and so like people deserve and need this like in order to have
meaningful lives
And that's harder to achieve. Um, but I think it's a moral issue though
um, because to me, yeah, that there's a there's a real
Uh, diminishing of the value of life if everything is consumption
Um, and that seems to be actually where these systems are headed like in terms of social media systems
Um content ranking systems like it's not just social media ranking of movies and ranking of books and everything about ranking
Um is all to optimize consumption so that you're you know, most of your time is taken up consuming with the optimal thing
Which is like the thing that most people want to consume
Um, and that does seem like there's like more and more going towards
Like actually it can consume your day
Um, so it can work. I think like you can actually just sit around consuming things all day is easier to do that than it was 200 years ago
Um, but um, but yeah, you're you're sacrificing something like really important
Which gives meaning to life and existence
Which is way harder to build for like is to enable self expression
That's another maybe angle on I think why I wanted to do the the maven system because it's like
Not trying to optimize for consumption
It is true giving you diversity of things, but the hope is that those trigger you to do something like to do your own self exploration
Um, like it's going to lead you to participating in that discussion or just to doing something else outside in your own life
Because you've been exposed to something different
Than what's like the optimal consumption object, which is just something that we could keep you around for hours
But it doesn't only do anything for you
So yeah, I mean, I think there's a huge moral component to it. Um, and it's like really
Really, uh, sad to me like that like everything is consumption oriented
And when I just don't think I think everyone is ultimately need self expression
We're just like running trajectories in our head and we're kind of think, you know, when I go to that place
I get the coffee. I get the dopamine
But then there's the question of well, where does the volition come from?
Because just from a neuroscience point of view that there is kind of goal optimization because your brain is just doing this
Clever search problem. We don't know how it solves the search problem
So it's somehow cutting down the exponential trajectories and it's doing all of these like little paths
And you know, we eat the cookie and we get the dopamine
And and then the volition arises from that prediction process
But then aren't you just isn't that just a form of of goal seeking in a way?
And the the serendipity and the stepping stone collection is kind of instrumental to that
Well, it to me it highlights that any grand theory, which it sounds like
This is one attempt at one
uh, needs to account for
um, our intrinsic drive to explore for its own sake
Um, and if it doesn't account for it in a satisfying way, it wouldn't be a satisfying theory to me
So if it really like it it turns out like it's like a mystery within the you know framework of the theory
Why would anybody care about just exploring like why wouldn't you just try to maximize dopamine immediately?
And go to the coffee shop or something like that
Well, then there's I feel like the theory is missing something. It's not that theory is completely wrong throw it out has no value
But this is the thing we need to figure out like it's really um
It's it comes up everywhere because it always seems to be the last afterthought
Um of like every theory every algorithm like an ai
It's like all of them are very good at dealing with goals and how we figure out how to get rewards and things like that
But it's this huge afterthought of like where is intrinsic motivation coming from and I you know, obviously they're they're even intrinsic motivation algorithms
It's not that no one thinks about this
But even that often is thought of as an afterthought
It's like there's like the main branch of reinforcement and then there's this little weird section of intrinsic motivation people thinking about
But to me it's like that's not the side show. That's the real show
Um, you know, it's like it's amazing to me like how insanely creative people are
Um that like, you know, because like even like mundane conversations are actually creative
Um, and like that's something that really like hits me when I talk to like chat gpt or something like that
It's like I wonder why I can't I don't want to it's not that I can't but I don't feel very motivated to just like, you know
Just talk about like random stuff with it
Just like, you know shoot the breeze and just enjoy it like a conversation like it's just like pointless
There's no it doesn't because seems like even like just talking to some random
Like let's say someone who's not impressive in any other way whatever that might mean
Like you can still have a conversation with them where it's unpredictable and interesting
But people are just really good at doing that on like a moment by moment basis
And just like that is not part of current ai at all like at at the granular level or at the macro level just not there
Um, and then these theories don't account for it either like the and yet it seems to me
But this is all just um, you know speculative that this is not like some kind of formal theory
But it's just my intuitive strong belief that um, this is central to what it means to be human and intelligent as a human
Is that like the the fundamental drive is towards exploration?
You see it from childhood all the way out
And it's just like I think it's and if you want to know why like where does the drive come from
It probably relates to some extent to our success. Um, you know, like as a species like we're
Um, it's useful to be this way
Um, it doesn't have to be that useful because like remember evolution is not itself only about optimization
Um, but it has to be useful enough to keep us alive
Um, and so it's it's it's it's useful enough. It may be that like it's you know, it's related to
Highly efficient algorithms to can create things like us
You know, for example, like early on in life when you're learning things like how do you walk or something or how do you how do you talk?
Um
I think it may be helpful that it's not an optimization process that we actually be less efficient
It was an optimization process like we optimize walkers, you know
This was a classic experiment in novelty searchers. He took like a biped robot and tried to
Evolve it to be the optimal walker and we also did a novelty search and the knowledge which produces better walkers
Um, because it's just like the stepping stones like starting from scratch or just like not what you would expect
So actually optimization like the ones that lead to walking so optimization turns out actually fairly relatively inefficient
And it's maybe better to just have this baby just like interested in trying stuff
Like what can I do with my arm and I just like swinging around what can I do with my leg?
And maybe this is a good way to build up
Um, like a repertoire of skills
Which is why repertoires keep coming up in like quality diversity and stuff like that
Um, it's just better for building up a repertoire
Then like you have to learn how to do this you have to learn how to do this
You know, this is like it's all a big set of objectives. Each one is a separate optimization process
Um, like that's just like really inefficient and awkward. Um, and so maybe it emerges from the fact that's actually a good way
Of like, you know encompassing a huge bundle of skills and abilities or a repertoire
Um, and then emerges from that that that just like remains a driving force throughout life
Although it's squelched because of social types of pressures
Um, but it's still part of our nature. I think
Um, and so, um, I don't actually want to claim to have a all-encompassing theory here about this
Um, but I I do think I can, uh, criticize any theory that doesn't have it
Um, yeah, because like it seems to be always missing and always just like, well, you know, I don't
Why should I have to defend myself by how I'm going to fit it into Friston's theory? I mean, it's his problem
Like if he can't like just show that strongly it's predicted by his theory, you know that that we should have this huge drive
I think the theory needs to be
Get some scrutiny and again, I don't mean to criticize it like holistically. There's probably lots of good ideas in there
Um, but something there it really needs to be addressed
Yeah, I mean, there's also this spectrum of, um,
An activism
Which is to say on the extreme an activism side of things you could just argue that there is no volition
There is no planning. There is no kind of sophisticated exploration
And so you could just argue in some sense that you know, I just happen to be here and what what we think is creativity is pure serendipity
It's just my local physical and social embedding the reality
I'm sure is somewhere in the middle that it's a combination of serendipity, but also some sophisticated planning and volition
Yeah, yeah, I mean I I accept that planning happens. I believe so
there's planning volition
And it's a mix like you said that that's my my my guess about things. Um, so
Um, yeah, we we should we should try to understand
I just don't get interested in it because I feel like it's the easy thing to explain
You know, it's like you have all these grandiose theories about how we plan it. Yeah, I mean, I agree that it's something we should figure out
Um, and by easy, I don't mean is actually truly easy, but it's the easier part of the problem
I mean reminds me of charmer's hard problem and stuff. You know, I'm not talking about consciousness
That's a really really hard problem
But you know, charmer splits up consciousness into the easy part and the hard part is it's a hard problem of consciousness
Um, I think that's really conceptually useful like to think about like the easy part in the hard part
So that we understand there's still something missing here that like even with all these grand theories like this still over here
Is not being addressed. I think it's sort of similar in the world of intelligence even are like human intelligence and AI
Um, that like there's this like tendency to like spend all this time grinding away at the easy problem
Um of like, you know, this like just cognition and planning and following objectives and optimizations
Like how does all this happen and prediction prediction is another one of those like easy things?
I think the hard thing is creativity
Like that's much more complicated actually and difficult to explain because it requires computing things like interestingness
Which are far harder to formalize than something like, you know, how well am I walking right now compared to five minutes ago?
Like you can you can pretty much formalize that kind of thing. Um, so there's the easy problem and the hard problem
And I just find the easy problem like somewhat less interesting
Um, we really want to get to the heart of what is like going to be agi
Like it's going to have to somehow account for the creativity side. Thanks. Yeah, and I would argue there can be no creativity without agency
So there there seems to be a very close relationship between those two concepts
Is there an interesting point there though that on
On most social media now
99 of people are consumers
And they're perfectly okay with that
Maybe that's not the right way to
To frame it because every everyone's a publisher in the sense that they have their photos and they have their status and stuff like that
But but most of their activity is is consumption
Yes, um
That's true, uh, that will be still the case here. So, um,
You know, I don't think we're going to fundamentally change the fact that the majority the vast majority of users are just consumers and
Larking
and and and but remember that like, you know, one thing people have been telling us is that like the
Emotional experience of like scrolling through this feed is very different. So for those people
who just want to consume
um, you know, you're not going to have this feeling of
uh, constant conflict and um, like constant emergencies like this feeling I remember when the pandemic started like Twitter was
Absolute or even core. I was just like sickening to scroll through. I mean, it's just like a cause mass panic in my mind
um, like that kind of
Feeling of like everything is in your face as it possibly can be to grab your attention to freak you out as much as possible
Like that's not like that at all. Um, people are just pursuing curiosity
Um, and so it's it's it's also I think a beneficial to to those who don't care about um, actually producing content
But it's worth emphasizing that for those who want to actually be part of a conversation
It's it's definitely presents an opportunity because you don't need followers like you come into the system
And you know, there's there's no concept of following in the usual sense
You can actually like another person's profile. Um, which just means you'll remember their profile
But it won't affect your feed in any way
So it's not like you'll see more of their stuff if you do that
So it's not following just a way of remembering people that you thought were interesting. Um, and so
because of that, um,
You know, like the one percent of people or the point one percent of people who have like 10,000 followers
Or something like out in the other parts of social media
Uh, they have a huge huge advantage over you
In terms of you've got something interesting to say today, but nobody's going to hear it
So you got to build up that following
But on maven you could just day one look it doesn't matter everybody's equal in this sense
Like it's just going to be sent to people who share the interest that you have
So you have a shot, uh, regardless of following
Um, that's equal to everybody else
And so for the 99 percent of people in that boat, it's worth a try, you know
Because if you want to actually discuss like 99 percent people want to post we're in that boat
If you want to discuss something you have a chance here to actually find like-minded people who will actually respond to you
But even the people who are in that small elite
I still think they get a benefit because of that whole point we discussed about, um, the fact that they're not
They're not obligated to continue to perpetuate the persona
That they feel they're obligated to perpetuate like in all the other social media
Because that's why people are following them is because they are who they are
Um, and so like if they want to inquire about some random concept that they don't really have authority in
Um, they should feel totally comfortable because you know the thing about maven is they can do it
And the people who follow them for other reasons will probably won't see it. It doesn't matter
They're in a different community. It's just sent to people who do have those interests
So I think everybody could get a potential, um, productive benefit
from just
The different the different way that participation works in this case
Some people say that on facebook you get echo chambers. So in a way your your desire to be heard is met
through this
Fractionation into many many small interest groups in a way no matter who you are your voice can be heard
But of course heard in a weird echo chamber that nobody cares about
But you could say the same about maven in a sense that your voice is heard but only by john in maryland
And you know like if i'm if i'm trying to get my voice heard by the right people to seek power or to get a job
Or something you could argue that that doesn't help me much more than facebook does
Yeah, no, I I do agree that like if your point is to actually
uh to
Amplify your voice like to make an announcement. This is probably the wrong service for that. Yeah, because it's it's not like a
Medium for virality. So it doesn't offer that
What you get here is the opportunity to pursue your curiosity
And so like john and maryland it's probably not enough to start a social movement
But if you're interested in whether it's even viable to start your social movement or like what are the pros and cons or the arguments about
What you want to say?
Well, john and maryland might actually be an interesting foil to have a discussion with
Because john and maryland is interested in talking to you about this
Which is a good thing because like how are you going to find someone who is interested in talking about this thing?
And so you can have a conversation there and it doesn't have to be
This inflammatory style of conversation where john needs to beat you because he needs to get followers for his cause
Even if he disagrees with you because he can't get followers for his cause through this
It's just it's just an intellectual exploration. And so for that purpose
This is really good
Like you can talk to people about things you're interested in and if you want to go through
Amplification and like have a newsletter or something you would do that somewhere else
Um, but we offer this opportunity to actually have a conversation
Yeah, no, you're absolutely right. So this is about this general theme of following your own gradient of interestingness
And you can talk to john in maryland because he has the same gradient as you
Yeah, yeah, and you're certainly not an echo chamber in terms of agreement because I mean, I mean you both you both may be interested in
AI ethics, but you both may have the opposite opinion
Um, so that's different than following a person, you know, because you follow the person because you agree with them
So that's why I like that person. So you tend to have a lot of people who agree with you
Um, and so this is not like that at all
Do you feel social media is broken and are you seeing how it affects people around you?
Yeah, I mean, you know, I was feeling there's something I was feeling in
AI around the time that I decided to do this
Like a year and a half ago when I started thinking about this seriously
and I was
Just like getting this feeling probably from social media
Of just negativity lingering around AI like increasing which is like really new to me
Um, because you know, I I was an AI for decades and and it was like a really, um
Like just like a nice fun club of people pursuing their intellectual interests for a long time
Like there was no ethical consideration. I mean it would come up like, uh
You know like in in very abstract terms like like decades ago
Like whether, you know, there might be danger in AI or something. It's like that's so far off
Like they really need to worry about this
Um, but like suddenly it just hit like a couple years ago
You know, like everybody not just me, but it's just like suddenly hit that like this is not like a political issue a social issue
It's a polarizing issue
And I was starting to try to understand like where do I fit into all those issues that that are like complicated?
Answers and arguments about them like in terms of like the ethics and the safety and all these different things
um
And then also this idea that like just like our lives are going to be
pervaded by like chatbots and stuff which hadn't really occurred to me like
concretely, um for a long time
um, and I
Yes, it just kind of hit me all at once like all this stuff
and I just started feeling like
I would just like to do something that's just like definitively clearly nice
Like just really nice like I was starting to feel like I'm not sure what I'm doing is nice anymore
It's not that I advocate that we all stop AI research. I'm not one of those people. I'm not saying stop AI research
But it was just for me personally as I'm sorting out all these issues
um
I was just like what could be just like clearly definitively socially positive at least to try
So I can just feel good like I'm just doing something without having to think about all this other complicated stuff
It just makes my mental burden easier
And that's something that emotionally contributed also to going in this direction
Because I just thought, you know, there's obviously
There's obviously a problem
socially with social media
Um, it's having a lot of bad effects on us and there's not a lot of disagreement about that from like all sides
Like everybody seems to agree with that. It's got a lot of negative effects on discourse on emotions
On how people feel about themselves like and and so I I was like, you know, if AI could help with that
Like that actually is like a win-win probably on all sides
So I could just do something I feel proud of basically for a while
And then in the meantime I can think about what I really think about all these issues that are very complicated
Because I wasn't really sure what I think about all of it. Um, it's hard to adjust when you just think of it as a game
basically for 20 years
And it's just like a fun game that you're playing and then suddenly like it has all these social implications
You didn't really think about like it's just like I need time to absorb this and understand it
So I'm just going to do something. I feel like maven would be a social positive. I'm not a hundred percent sure it's going to succeed
Um, but I feel like it's pretty clear
It's trying to do something nice because if I try to give up likes and follows
I'm going against the grain in a way that's extremely risky. It's not like I'm trying to exploit people and extract money from them
I'm like going the opposite direction. So how can I make that into a business? It's going to be complicated
But I can feel good about myself. So that's kind of like another thing that led me in this
Direction the thing that was nice about it is that it it is dovetailing on my AI research, right?
It's not like I just like, oh, let's just forget about AI and do social media
It's like all the insights from quality diversity from open-endedness. They all come to bear on this
So I didn't feel like I was just like giving up like all of the intellectual effort of the last 20 years
I felt like this just naturally builds on top of it
Like it doesn't have to be explicitly an autonomous AI system
Just like pick breeder itself wasn't you know
Like you can make a system that wraps open-endedness principles around people
And still use a lot of the ideas like the minimal criteria and stuff that I've been thinking about
And so it wasn't like just like I'm just dropping out. It's just like an extension
But like an interaction that allows me to sidestep a lot of these
sticky issues right now
You know, I interviewed your student and co-author Joel Lemon and you know, he obviously we he grew up on this idea of
Of greatness cannot be planned and now he's very concerned with AI risk
And you were saying about ethics and actually a lot of this a lot of your concern with Facebook with ethics with risk and so
Is because it's um serendipity eroding
So I said to Joel, how do you kind of juxtapose?
This kind of thing that you wrote about with Kenneth, which is that we should be serendipitous and now you're being quite paternalistic and consequentialist
Which is the complete diametric opposite of serendipity
How do you juxtapose those two ideas? And he said I don't know
Like when it comes to those AI risk issues safety issues ethics issues
um
I just
Feel comfortable saying I don't know about a lot of like I don't know what I should conclude exactly about a lot of things
I do have opinions about it, of course, but I mean that'll be a whole other show
um, but like yeah, I don't have firm conclusions to come to yet
um, and um
I think we need some time um to understand, uh, like like open-endedness, um
It's still like it's super fascinating from just like an autonomous AI perspective. It may be essential to achieving AI
Uh, but what are the implications of it in terms of safety and things like that? Uh, it's like a very complicated issue
um
So yeah, I mean I agree with Joel. It's a it's a little bit tricky to
Uh, um to try to reconcile all these different things now with
everything we've been doing, um
and uh
Yeah, why not just drop some people into a nice open-ended system and do something else for a while?
um, while i'm trying to figure this out, um
And um, you know, I think there are things open-endedness can contribute
Well, one thing I think is you can't get out of
You can't get out of the problems
of
AGI
Without confronting open-endedness. Like I think open-endedness is part of this
Like it has to be confronted like the whole problem is that it is open-ended in my view
Like that is actually the most fundamental aspect of the problem
Like if it wasn't open-ended it wouldn't be as much of a problem, but also wouldn't be very interesting
Um, and so I wouldn't be AGI in my view
Um, but then on the other hand like the open-endedness is helpful then for understanding what the risks are at some level
Because like controlling an open-ended system, which is like a paradoxical thing to try to do
Is the problem of safety?
Like how do you actually get an open-ended system to not go over certain lines that are like really like
Unacceptable, but still have it be open-ended. Like that's a challenge. Well, that's what open-endedness research is about
So in some sense open-endedness could be very important to continue to research because we need to understand this now from a safety point of view
um, but anyway for now
I'm yet going to be uh, just building this network. Uh, and uh, but yeah, on the side I think about these things a lot
Yeah, and I agree. I don't know that I'm a little bit skeptical about AI safety
but just as a thought experiment AI could be the technology that
If if you democratize it it could just have catastrophic and you know, um
Unforeseen consequences and then as you are just alluding to if you place constraints in the system
Then you have all of the problems that you've spent your career talking about
So it seems like it's almost it's almost like um pandora's box
That this is the one technology that kind of breaks everything and now we need to have a paternalistic society
Yeah, yeah, except I mean the the thing that I think about is just that you know humans are also very dangerous and open-ended
We are open-ended and we're we have agi sort of like we are general
And and we're really dangerous and we can like kill each other and kill many of each other and so forth
And we can destroy society if we want if we if we put our minds to we could do it
And um, but so we've been confronting this issue. It's not like a new issue actually
The issue of how to control an open-ended system is the issue of society itself
Or I would say the issue of civilization
Because civilization also confronts the problem that like it needs to be open-ended enough to continue to progress
Like if you put the brakes on too much then progress stops and like you have extremely authoritarian systems then
Like if people again have any freedom at all
Um, but you know, then there's the problem is there's too much freedom and too much freedom is too much open-ended
Is also extremely dangerous like there have to be brakes on something
Um, but it's interesting that this is this is a problem we have been dealing with like that's how I think about it
So it's it's not like a new problem. Actually, it's new what it's applying to but the problem itself has existed
And so I think that like, you know, all the institutions of government and society and culture
Have grown up around trying to control an open-ended system from going out of control, but still be open-ended
We actually have a lot to draw on there like how we've done this in the past
Um, but it's different than let's make a benevolent dictator that like loves us all like that actually is not what society has done
And when it tried to do that it didn't work very well
Um, and so like this is much more complex at like a cultural and sociological level
You know controlling open-ended systems, but it's I think it's interesting that we've seen it
Um, and it involves people
You can think of um, it is being an agency problem. So we're we're a society that
Values individual agency and the technologies that have a large blast radius at the moment are controllable in the sense
That it needs significant resources to get access to them
but
If you did believe that ai posed an existential risk and it's democratized then given a high agency society
It would presumably be impossible to control it
Yeah, um
Yeah, it's true ai is a
a very special uh
Case that isn't like things that have come before. I mean I agree with that
and
but you can
something like institutions
Are relevant like because institutions prevent certain things from happening
I mean like a bunch of people could get together and build a nuclear bomb if there weren't institutions
Um, like if you say anybody could just do whatever they want they can go mine uranium and do whatever they want
Um, like like there are restrictions on what can go where and how it can go because there are institutional restrictions
And I think ai needs to be embedded in some kind of institutional framework
But it's probably some of the institutional framework or ai's
Um, which would bound what ai's can do. So it's probably a multi-agent thing
um, but in the end that's just like
You know really speculative like what am I even talking about like in reality right now what you're saying?
I think it's true like we're looking at um unprecedented possibilities that they can't be fully understood
And therefore it makes sense to to move cautiously
Um and think about it. Um, but but I think also it's you can't just not move also. You have to move
um, and so, um, it's just a needle-threading exercise for for society
I kind of think of a lot of this gold directedness stuff that you're talking about as being a story of agency
and how
There's a very complex natural way of things in the world and we all have spheres of agency and there are physical agents and social agents
and you could think of um agency your autonomy is just being a kind of force
Of yourself around the world around you a bit like a gravitational force of the sun, you know
things orbit around the sun
And having autonomy is about having things orbit around you rather than you orbiting around other things
So it's about the you know
There's almost you can kind of imagine a solar system of of orbits and and where the
The kind of the generating sources of agency are coming from and then of course it gets much more complicated when when you think about that in
The world of intelligence because then agency isn't just about this very simple gravitational force
It's about active sense making and planning and being able to kind of you know
Develop sophisticated behaviors to change the world around you. Well, that's that's interesting. Um, so
Yeah, I mean the agency point is interesting. I can see the connection between agency and objectives
You are sort of like
objectives reflect the
set of rules that
Already can find you and so you're operating within those set of rules
Um, but you could create your own rules and that would be to actually
Express some agency in the world
So if if goals are an instrumental fiction and I guess what I mean by that if planning and goals are an instrumental fiction
There are a way of post hoc rationalizing complex behavior
So we we kind of project this cognitive map if you like to understand physical phenomena
And it's not to say it doesn't exist in the real world. Of course it does but it's um
It's very diffused
And the what we think of as planning is actually a very complex low level information sharing
Between all the particles in the system and and so on but but then the question is well
Obviously if we if we simulated the system as a sufficiently high resolution
Um, obviously we would capture those dynamics, but I think what you're saying is well, why don't we come up with an abstract model?
and
Still capture as many of the dynamics as possible
And I guess that's that's the gap that I'm trying to understand
Yeah, so
Maybe it's like instead of because that's this pretty high level abstract to to think about like how
You know at what how many dynamics can be captured through some abstract algorithm?
I mean, I think maybe it's better to think like what exactly more concretely am I saying? I mean like algorithmically capture something
Like what exactly am I talking about like basically what I'm talking about is the fact that
For individuals
In order to have serendipity you need to be exposed to the right stepping stones
Like this is what leads to serendipity
And like the assumption I have is that the right stepping stones for you are not the same as the right stepping stones for me
It's very idiosyncratic like what is actually going to be transformative for you
It also makes it hard to predict for you what's transformative for you. So there's nobody really can say for sure
But it has something to do with exposure
Like you need to be exposed to things that would be transformative or else they just won't lead to the transformation
You're the one who can make the transformation if you were exposed because someone else won't do it
But if you're not exposed, you won't do it
Um, so it's important for people to be exposed to things and it goes all the way back to pickbreeder
That we saw things like, you know, the the the woman there who really loved the bugs
Um, and so being exposed to bugs or bug precursors
Was like a triggering event for her although she didn't know it
Um, and then she was like really uh crazy inside a bug space
Um, and so that was important for her to get exposed and and like the pickbreeder system was
Good at like large scale exposure of stepping stones partly because it's images
So it's a little bit of a it's a little bit of a cheap because like it's really easy to scan huge numbers of images very quickly
It's not so much true of like just content in general or sort of especially written content
Um, but so people were were getting a diversity of exposure which meant that they can go in many directions
Which is like in aggregate very divergent as a system
um, and so this this is
It was interesting is that it's conflicts with
Social media which is actually consensus driven and convergent because of that
Which is basically like it's basically based on a model that says like if more people agree
That something would be interesting to you then will you have a higher probability of being exposed to that thing?
Um, which is like antithetical to your idiosyncrasies
But it's still going to be true that like if most people like it then there is a high chance that you'll like it because you are
one of most people usually
Um, but what it doesn't do is expose you to the things that are idiosyncratic to you because consensus can't do that
So you're missing all those things
and so
there and then what we should be doing
In a system that's geared towards serendipity is not allowing consensus to decide what you're exposed to
um, and so that's clearly radical
I think that's quite radical because like all of social media rests on this assumption
It's almost like a natural law in social media like people don't even question that like that is
Like it's like the way in the notes use the word social
It's like you call them social features like as if that like there's a synonymous synonymous with being social
It's like you have to have these things. These are consensus mechanisms
um, but I think like what I'm saying and like these kinds of
I want to see algorithms like the insights from the algorithm. I don't see the algorithms themselves because I'm not saying like run
Novel research on top of a person
um, but the the insights from the algorithms they
Suggest that that won't work for serendipitous exposure
um
And so what we can do is basically try to expose you to things that match your interests and then from there
You'll be able to see lots more of that like opportunity surface
You could say of what might actually be triggering to you and the assumption is like look
There's like a lot of stuff bubbling around under the surface of all of this consensus
Um, which is very like spiky in terms of convergence, you know
Because like if you think about it like a lot of a lot of the conversation of the day
Even if it doesn't involve somebody with a big megaphone like it goes back to the person with the big megaphone
You just don't realize it
You know if yan lakoon says something about ai today because he has I don't know 300 000 followers or something
On x then like a lot of people are going to be talking about that thing unwittingly or not
And so there's a lot of convergence day by day on like what are the topics
And yet there are lots of people who have something interesting to say in ai
And I I wouldn't say that like yan lakoon isn't interesting because he's obviously earned his place and his megaphone
But the thing is he's redundant because he says similar things constantly and he they keep on dominating
And of course, it's not just him. There's like maybe a hundred people that like are like this
But those people basically are dominating and consenting conversations
They and then there's the 100 000 people who aren't those people
Because after all like, you know, I think I read the statistics that like on x like it's about 0.1 percent of the population
It has 10 000 followers or more
So 99.9 percent of them are at a level where you're likely never to hear anything they have to say unless they're replying to yan lakoon
And so those people have lots of interesting things to say but not interesting in a consensus sense
But interesting to you
In a sort of idiosyncratic sense some more than others, but they have idiosyncratic things to say
Some of our would probably be consensus interesting
But like they just have trouble getting consensus because they don't have enough followers yet
But the thing is that like all of that churning stuff
You're not getting exposed to a generally in a consistent level
And so it would make sense to
Intentionally design something
To work like an open-ended system because an open-ended system would have these mechanisms that actually that kind of exposure would be routine
Rather than like require enormous effort and a megaphone and very rare
Um, and so that would be that is possible actually to create a system like that
We understand how systems like that work
They're actually not that hard to understand the problem with the reason that they can be built
The reason they're hard to build like artificially is because they're missing human intelligence
Um, I mean because human intelligence is part of what makes these kinds of systems run and that hasn't quite been conquered yet
But the thing is like if humans are in the loop the outer structure of such a system is understood
Like we do understand this now. We have humans in the loop if the social network
So we just have to fold this thing around them that has this kind of exposure
and we can
Fix that but I just want to point out that like the side effect of that. It's not just about
increasing serendipity
It's that it the incentive change being so dramatic changes like a number of things that really change dramatically
You know, like where's the incentive for clickbait? It's not there anymore because there is no such thing as virality
Um, and like you why would you promote yourself in a situation like that?
Like if you actually want to cause a scene say something offensive
Maybe that gets you attention here. What's the point of getting you won't get more attention because it won't be amplified
um, and so like
in a large sense like
Human behavior is vastly changed
The incentive system has vastly changed on top of it. And so this should be it should be actually
A good form of like detox from like all of the bad things that you see that are happening as unintended consequences
You said something interesting about yam, lakuna. I noticed this as a podcast interviewer myself people only really
Talk about three things at a time three themes people are incapable of thinking about too many things because of this convergence
I feel sorry for yam lakuna because he he always practices saying the same things over and over again
So obviously for me as a podcaster, there's a trade-off between
Clout and actual real sources of entropy and i'm trying not to influence
The the interview with my own views and sources of entropy because again that creates these convergent
Measures, but anyway on to the most important thing you you were just saying that
Some people argue that certain things are just the way they are
So there's this book called
The status game by will store and he says that we all um, you know, we play the success game
We play the virtue game. We play the dominance game
And you could argue that this is the real reason why social networks have
Verality because people are playing the social games
And if you create an a social network, then there's no game to be played. So maybe people won't be interested anymore
Mm-hmm. Well
so
So first, I mean I that the fact that the word social get gets like, you know kind kind of
Entangled with this issue of like popularity is just like crazy to me
Like I can't the the word should be separated in my view
Um, you might argue that the network would fail because everybody is too motivated by popularity driven mechanisms
So there's no way we're gonna have a network like commercially successful network or even successful enough to have a community
But that that's different to me than saying it's not social like that's a strange point to me
Like like socializing didn't used to have to do with these things like these are all
Ridiculous new ways of describing what it means to be social
I mean, there was no like button in my life before like 20 years ago
I mean, I did plenty of socializing. It was not a problem not only that
But I mean maybe more relevant to that because that that's that's more of just an emotional reaction
Like it's basically um, it's there is precedent for having networks that are successful without these mechanisms
Um, and you know bolton board services are really interesting great precedent
You know because obviously I spent of course a lot of time thinking about this
I understood that like this is a very radical proposition including risky proposition
Like will people be able to stick around in a place that's lacking things that they instinctually expect at this point
Um, which are not only like instinctual, but like actually you're literally addictive
Um, and so it's like, you know, it really is like a detox
So you take people out of that like cannot even work and of course I was thinking about that
I mean, I think one thing that creates an opportunity
for that is like
It the counterpoint to the fact that it is so pervasive and people are so disgruntled
Gives a little bit of a boost to the opportunity to have an alternative
Like it may not have been in an earlier like 10 years ago
Um as potentially obviously appealing like why this like it's not as fun as that
But but now people know that like this actually makes me feel ill like when I do this all day
Maybe not everybody but enough people um that there's an opportunity there
But going back to precedent like precedent is interesting here because like whether or not people would just do it as some reactionary thing
um
Like these bolton board services I started studying because because I was trying to understand is there any example
Of successful social networking like without these popularity mechanisms
um
And I was you know surprised like looking at phpbb, which is like 1990s technology
You know, it's just a really boring thing that nobody in the industry talks about. I mean, I like I'm not an expert
Actually, I should be on the industry not my industry
But you know, I I listen to some um, you know
Some of the pundits and the pundits and the critics and things in the industry you like never hear them talk about
Oh, wow phpbb a really interesting, you know cutting edge thing
But it is actually cutting edge like they still exist and at huge scale
You know, like that probably the biggest I think is city data
Which has like on its form two million people
None of these mechanisms like completely absent from it
And I was trying to understand, you know, why why is that and there's lots of those by the way
It's not just city data. They may be the biggest but there's lots of just local websites with very thriving communities of people
Who have none of these mechanisms. They just use primitive bulletin boards a lot of time phpbb
Um, and why is that?
Well, it's like obviously they're like different one reason is because like everybody there is interested in the same thing
So they they've shared interests
And they know that people are interested in what they have to say
And they also are motivated because you don't have to be famous in order to actually be part of the conversation
Like nobody has a particular megaphone over anybody else
And I was you know, I'm shocked when I look at phpbb
Individual contributors
Like you can see for people you can see how many times they put their posts have been read in aggregate
And there are tens of millions tens of millions of reads on complete. Nobody's like like, you know,
Mr. Poodle 24, you know, he's got like 20 million views
Um, like he would be a celebrity in twitter with that kind of thing
But this isn't like this world where is this doesn't even get noticed?
Um, and so people are getting they are getting attention
Um, but it's through completely different mechanisms and they feel part of that community
Um, and so like some of that guided some of the design choices that that I went to because I was trying to understand
You know, they're very different kind of way of presenting conversations and things like like it's very more simplistic than most of these
Networks like networks use these kind of hierarchical structures to like have conversations break down into trees and things like that
Like phpbb is like totally linear. It's more like a dinner conversation
It's just the topic is set by the first poster and then post post post post post everything's just in order
The only thing you see is the latest like there's no attempt to rank anything at all. Um, it's just time. That's all
Um, it's ridiculously simplistic and that I wasn't necessarily taking the lesson that we're just going to recreate phpbb
Because I want to apply some of what I understand about open-endedness
But I thought in some ways it's like taking phpbb into the future
This is like the futuristic version of phpbb. You don't need to go to one website
You just automatically get sent to the people who find what you say interesting
Um, and we will actually have one thing that that we that is maybe not clear that comes up in
They're sort of implicit in some of what you're seeing is we will have some quality mechanisms
I'm not totally against like you made an interesting point, which I thought was really insightful and they know it's about
Why would you in pickbreeder have things like star ratings?
Um, you know, you did do things like that like you let people have individual autonomy in their individual paths
But you still gave some ability to express quality directly and explicitly like why wouldn't that also be true here?
I think that's thought provoking to think about that
And but you know what may not be obvious
Even even like having visited maven is that there actually is a quality mechanism in there
Um, but what I took was the minimal criterion idea, which is like obscure probably
Um, like I wrote a bunch of papers with minimal criteria. Maybe well not a bunch me like five
They had minimal criteria like there was not novelty search with minimal or minimal criterion novelty search
There was minimal criterion co-evolution
Poet had a minimal criterion inside of it. It's this like obscure idea
Which I've like always I've loved for the whole time that I've thought about it
Which nobody else well, maybe a few but it never caught on like the way something like novelty search did
um, it's it's more obscure, but I but I've always really loved it and um
because it's
It's a way of interpreting evolution. Um, that I really liked
Um, where it's like you don't necessarily think about it as on a continuum of quality where it's like fitness is often presented that way
Rather you think of it either you succeeded or you didn't
Like if you get over the threshold, it doesn't matter
There's no need to rank and the thing about this is this is about interpretation
It's not like a right or wrong type of thing because it's not really saying any specific explicit thing you should do
But it's just like interpretations of evolution
I really like this minimal criterion view because it suggests it puts an emphasis on a different aspect when you think about evolution
Um, rather than the aspect of competition, which like I said like I think leads to convergence
So I'm trying to understand what leads to divergence
Well, the minimal criterion is very effective at having some kind of quality standard like there's a minimal quality standard
You can't go below so you can't degenerate, but other than that you have total divergence
Um, and I think that's really appropriate for very subjective domains where it's very hard to say this is better than that
And it really is that way with text and and speaking, you know, because if you think about like, um
Stuff that's set on twitter that's very subjective like pearls of wisdom or something
Um, like those really don't belong in a ranking. It's quite odd actually to have a like a
Unstrict continuum like it and this I was thought of this because like someone on maven said like a like a few weeks ago
Like list could you just everybody reply with some really succinct pearl of wisdom that's meant a lot to you throughout your life
So you get this big list of like little pearls of wisdom from everybody
And I read through all of them and I just absorbed them in my own way because like they mean specific things to me
Some of them resonate more than others and I was just thinking like what would I have done if one was ranked at the top
Because it would be the rich get richer. So this would be this extremely like top level piece of wisdom
So I wouldn't be thinking about anything. I would just be like, I don't want to waste my time on the crap ones
This is the good one and then I can just leave and there would be no thinking involved
And I wouldn't get to absorb each one for its own right like how it interacts with me in my idiosyncratic way
And so of course there is total crap in the world and we don't want that
Um, you know, like I wouldn't want like the reply that said like everybody should just eat bananas or something
Um, but but there is something above that threshold. It starts to be much less clear like how we should rank things
So I've always been interested in this minimal criterion
But what you said and and we have that so basically we have a minimal criterion standard
So you're going to see this kind of evolutionary divergence where like the stuff below that you won't see circulate as much
So there is a quality standard, but it's not a maximization algorithm. That's what's so interesting about it
It's just a minimal algorithm. Um, so above that you just get churn like total churn round robin the way you put it
Um, but your point made me think because I was thinking why didn't I just go to uh,
You know the the pickbreeder view of the world like I could have done that too in this kind of context
Um and tried to intermingle like ratings in some level
But I think like I thought about this a lot just since I've read your your notes and I think I concluded that
Um, it's not that it's like there's a strict principle that would like
That suggest you shouldn't do that
It's more that like I think the medium is it's the interaction of the medium with the quality standard is very subtle
Um, so I obviously made a decision, but it was intuitive and implicit
Like I hadn't really thought about it a lot until you pointed this out to me
But I think that um after thinking about it
Like there's there's a mismatch between the pick reader way of showing things
And like this kind of text based social media content because I think the pick reader stuff worked
Because I could really quickly show you all kinds of perspectives simultaneously
Like there was only one section of the pick reader site that showed top ranked like all-time top ranked
It was in like but but then there was a newest top ranked like new top ranked or the highest quality new stuff
There was random. There was most branched
And so there was like a whole set of different categories plus you could like go into individual like you could go to like faces or something
Like individual categories and I and I think that that works there because there are pictures
You can see all of it at once, but I can't present all of content that way to you
And I think that if I gave you top ranked
As an option like if I gave you a bunch of different panels
You would spend your whole life there like in the consensus driven world
And it wouldn't be pick reader at all like we need to get divergence
We need to expose you to diversity
And so like if I have this very narrow window like the screen of a phone
And I also it's much harder for people to consume the content because it's not pictured to read it
I think that a minimal criterion works a lot better
Um because it doesn't require you to prevent present all these different views simultaneously
And have people like like equitably you look at all of these different options
Like it's just like totally intuitive. It's just like every other social media from their perspective
But under the hood we're taking care of things to make sure that this is divergent and has like a bottom where you can't go below it
Um, so I think that's why we get to that point
Yeah, because when I when I started using it and we'll introduce it properly, you know, for folks to understand but
I was met with a little bit of mild confusion because I didn't understand what was going on
Because we all have a mental kind of reference frame to understand the world
And we were talking about goals and planning are quite a common one. So the thing about pick breeder is
I mean
The clues in the name with the neat algorithm
There is a topology there and in my mind and in the user experience you can actually see the topology
You can understand the structure and on maven my my read of it was that it was quite flat
So there's this minimal criterion
But we don't know what that is and then so it's a bit like the bias variance tradeoff
There's some structure and then like you you allow for complete variation
Above the minimal criterion and then all of those posts are kind of round robin
allocated to to folks who use the system and then
Um, I guess I'm naturally looking for the next level of structure now based on your answer
I I agree with you. You convinced me that the the kind of the will store status game thing
Um, it might be a component of the reason why facebook is viral
But I agree with you. Look at my discord server. Look at, you know, these php websites
People love recognition. They they're interested in things. They love this serendipitous process
So yeah, absolutely that that completely works
But I think what facebook did though is is they chose a proxy for interestingness
Which perhaps is quite deeply ingrained with us because it's this social status thing that we all care about very much
And what you're desperately trying to do I assume in maven is to not choose any one topology
But to allow the topologies to emerge naturally
But I guess my point is is that without the user experience kind of guiding what the topology is
Then it's almost like you don't get this reflexive feedback loop that you need for the system to work
Yeah, there's such a complicated thing. I mean there's a lot of points to that. So like facebook
in its genius, um
Is you know that I don't know if it's genius as much as obvious
Like I feel like these were the first things I would try to like it's like I would put a like button
It's just such an obvious thing to think of
um
I think what wasn't necessarily obvious was how addictive that is like that is such uh
Such a like a worm into some human psychology. Like it wouldn't be obvious at the first
I mean, I notice it like getting likes on a post in x or something. It's like very
distracting and
Consuming like is when your post is getting a lot of likes and that is weird because it's just a number going up
Like there's nothing actually happening. Um, like it's not like I'm learning anything or something, but I can't look away from it
Anyway, um, and so you could say that's genius because it hit on something really really powerful
um, and I don't think we can
Create anything as powerful as that like that is it's just like, you know, it's it's like, um, you know
Um, you know green beans can't compete with heroin or something like it's like heroin is going to win
Like on the addiction scale
um, but like so
We're gonna that is an uphill climb. I think at some level
Um that we have to deal with
But there is but in terms of structure there is still structure like it's it's still not as powerful as that in terms of an addiction mechanism
Um, but we certainly have structure. I mean, it's it's not just like you kind of sort of
presented it as kind of like a flat like thing where it's like it's like you totally have to just
Um derive your own structure from reality. You can't get any from the system itself
But you have to the thing is what we tried to do there's two things we try the first thing is we tried to replace
You know the the kind of addiction mechanism. What which is this like, um,
this kind of uh
Self-affirmation that you get like when you get these kinds of signals like a like signal or a follow signal
With something else to do because you need something to do to occupy your time
Um, something that feels like an activity and that was to follow interests
Um, so that's why we said you do follow interests and not influencers. That was like our first slogan
It's current slogan. Maybe we'll change the slogan
Um, but so like yeah, we see that so like by following interests, of course, like your world will not look like my world
They're all customized around interests
Um, and you know the system is using ai to generate interests
So those interests it's not like you just decide what your interests you can if you want just type them in
Um, but you're seeing them surface constantly and we've definitely seen people
Have been using that the way that it's intended which is to constantly expand that like surface of serendipity
Um, because they see something pop up, you know, it's like you see something lately like ai for
Um, uh for architecture and it's like, you know, I hadn't thought about that
So it's okay. I'll click that one and then I'll follow that now that comes something that they're interested in and they didn't know
And you definitely see people growing their interest graph
Um, and so that's that's a new activity that we've introduced
I don't think it's as compelling as getting likes or follows, but it's something that's
It's it's a recreational activity
And the other thing is though that you you you mentioned like the reinforcement signal like that that's something that
Obviously it's really it's like directly is the likes and follows too, but it's it's important um for for keeping people
Engaged and there is a subtle thing going on like that. Um, I mean in addition to the minimal criterion
We should weak reinforcement signal, but there's the um the fact that replies get resurfaced in our system
Like our system is very respectful of replies like in a way that like um x isn't for example
Like x sometimes you see replies in your main feed, but it's not systematic
Like generally that's not that common. Um, I'm not sure what the algorithm is to decide
But you don't see them that much
But in ours every single reply goes back to the top and this is like respecting php bb style
You know because they're like the the top thread you'll see when you go there's always the one with the most recent reply
Um, and so we kind of show like the last few replies always like whenever we like pop something back up to the top of the feed
Um, and this is basically causing that thing to get more exposure. It's just implicit
And so like the most engaged posts you see more and you're going to see like what's most recent on them
So there is a mechanism and it's even arguably objective
Which is you could say it's bad in the big picture
But like you point out like the real truth is it's not that you don't want any objective mechanisms that you want to balance
Um, like we can have people say something as high quality and pick breed and still get an overall divergent process
But you can't have it dominate. That's a big problem
So i'm just trying to reduce the domination of the objective component because I've always thought like when it comes to quality and diversity
The real problem is that quality kills diversity when you make it like the primary thing
Like all the quality diversity algorithms are about trying to put quality in a box
So it won't destroy diversity because if you're not careful, that's what will happen
Um, and so we still have some we still have some structure because of that. It's just like through the
Yeah, through the actual exchange between person and person
And you would start to notice that hopefully implicitly like as a user
That like the big conversations keep coming back over and over again
And that's what phpbb users experience. So that's been shown to be uh enough to keep people around
From an engineering perspective, do you have a cold start problem?
And do you have any thoughts on how the dynamics of the system will change at different levels of scale?
Yeah, there's definitely a cold start problem. Obviously, of course
We we face a stark horrendous version of the cold start problem because I mean
you have uh
Just the general cold start problem for any company
Then you have the cold start problem for a social network, which I think is like generally really bad
Um, and then you have a cold start problem for a social network in the world today
Which is worse than it used to be
Because there already are all these socials established social networks, you know when when x started or twitter started
Uh, it was a lot easier and in fact, um
One of our investors a leader investor is of williams. Um, who was one of the founders of x or of twitter when he founded it
Um, so we've had a lot of conversations about like how did he start twitter and stuff like that and the story there is just, uh
Um, of course, it's just impossible to reproduce today. You couldn't do it that way
Um, it was a different world where things like this could catch on um, organically just independently
But now you're fighting against the fact that people already have homes
Or more compelling places to go because we're saying come here and talk to a few dozen people or he could go over there
Talk to a million people like what what should you rather do? That's a horrible cold start problem
Then it's even more exacerbated by the fact that we don't use addiction mechanisms
So we're not exploiting human psychology in the in the usual way that can get you like, you know off the ground with something like this
Um, so we obviously have an enormous cold start problem
Um, and so but the thing about cold start problems is I know much has been written and said about cold start problems
Um, but I think like one important insight about cold start problems and by the way, I'm not an authority because I haven't succeeded yet
so don't take my word for this like I could be wrong, but what I think is that
um
You know every cold start problem has to be solved in a way that is different from the past
Um, like there's not like a formula for how to win in the cold start race
So there's all this conventional wisdom, but it's from the past
It's like this is how it was won before the next thing that cold starts successfully
It'll be totally counterintuitive
It will be something nobody thought of as a way of handling the cold start problem
And so this is a unique situation that has never been confronted before like how can maven actually solve the cold start problem
And it will be solved in a way that doesn't reflect conventional wisdom. Um, and so I think you know, what gives us the opportunity
So there we're obviously working on this from many angles because that is our problem. It's the cold start problem
Um, like we have but we have some opportunity some inroads into the cold start problem
One of the is just like we do have the the goodwill of people
Because of the fact many people resonate immediately with the idea of getting some way out of all of the mess
Um, like it's now in the air and you know, some of our investors like say and like they keep pounding on us too
They're like, look, this is the time to act like like look everybody's upset like there's a new article comes out
But it's in the air that like everybody's disgruntled social media for numerous reasons
And it's not it's like public is at a general public level or pundits are saying but also individual level like individual people
People say, you know, I just feel I feel slimy and yucky and anxious and tired after I go through my feet
Are there's like terms like doom scrolling and it's like that creates a huge opportunity
You know, it's like an opportunity to actually go through a feat and not feel that way
Um, that's only people have been telling you so I think if enough people can latch on to that
That's something something else that I think is going to help which is I wanted to preview a little is that we are adding other features too
Like obviously you're just seeing like version one here
We're going to add some other cool features. I think like there's some of them are like just gestating right now, but
They're going to be some more pickbreeder-ish things you can do in the service
These are, you know, some people say, you know, there has to be a single player mode
Like that's one way out of the cold start problem. That's one thing you hear sometimes
Something fun to do if there aren't other people around which makes sense because if you're starting cold, there's no other people
Okay, we're taking that to heart. There'll be there could be some fun things to do like that
um, so we're going to
You know approach this and not just at the high-minded level but also at the practical level too
But hopefully coming at from these all these different angles
Um and exploiting the fact that like we actually are saying something virtuous, which is very unusual
You know, we're taking away all of these nasty things that exploit human nature
And just letting people just be themselves
Like you can just pursue something for curiosity's sake. You don't have an incentive to get attention anymore because you can't get any followers
Um, and so like what would be the point?
So you also don't have a reason to be embarrassed because like you don't have followers. They don't care
um
If you want to go ask something about something you don't know about because I feel I have enough followers on x that I feel like
I don't want to say certain things because I know what they expect and I'm going to sound like an idiot
You know because I actually only know about the things I know about
But there are some things I'd like to talk about but like I don't really know well about them very uncertain
But I just basically don't feel comfortable doing that because I have all these followers
Well, you don't have that problem here. Um, and so you can do all these things and I think that that can be powerful because you know people
Would would like to have some relief
Um from this kind of pervasive nastiness which like just like surrounds everything
I just like wonder what it's doing to us that every single thing you do is launched into the most cynical Darwinian competition
You could possibly imagine it's like it's not even like the big thing
It's like every single statement like just one little reply for like one sentence
It's immediately launched into a Darwinian competition for the top comment and it's just crazy like what is that doing to our psychology?
You can go here. You can relax. Just be yourself pursue your curiosity
I think we have a chance because of that
The reason why I asked you the question about the scaling though is it was a bit of a trick question
Facebook they went through this kind of I mean you can think of it as a revolution that facebook and google
Um invented this relevance ranking
Which is this idea that we've got a whole bunch of data in our system
And and we do some collaborative filtering and machine learning and we do some objective optimization
And and we create these convergence things and and in a way that's very good because you know
There's lots of complicated information and it's a way of discarding what's not relevant and giving you what what is relevant
But on your system, it's almost like going back in time to the 1990s where you just you just have a php bulletin board
And you just do rand robin and you just give people what they want
And so my observation was that it works brilliantly now at the very beginning
You almost don't have a cold start problem. It works great
But but but the question is more like well what will happen when you have a million users
Yeah, yeah, I missed that part of the question that that is a really interesting part of the question
Um, you know, probably my mind doesn't go there first because I'm I'm I'm like that's like the best problem to have
So that that's like what I think about less. I think you know, I really got to worry about the problem of are we going to have a even like, you know
like 10 000 users
Um, but like yeah, that's really interesting to think about so what happens at scale and many people have commented this like the very earliest users on maven
You know loved the nice community everybody they can trust like it's just like everybody is really interesting thinks about what they're saying
Obviously you pour in a million people. That's not true of everybody anymore
I mean people have I've heard people say like about usenet if anybody's old enough to know remember usenet
I know some people old enough to remember news that they say that was the golden age of social media
Like everybody was interesting and polite to each other and just said said things sincerely. They weren't looking for attention
like that that kind of
You know that that kind of uh using that era stuff
That's going to be um, you know people people talk about or people remember that from social media
And and and that is
That that is going to change at scale and people say like why did usenet fail or like not fail
But why did it sort of go out of style?
Well, because it's millions people portances that it was the it was the smart people
I heard somebody say this recently like it was like the top
10% or something of IQ was there and as soon as everybody else came in it went downhill
Um, I'm not endorsing that I don't necessarily think IQ is what tells us whether somebody's good at social media
But but it's it's somehow there's like the best people of some kind of theory and but I do agree
I don't just agree with that but I agree that like obviously the more people you pour in the more people you're going to get
That aren't doing what we wish they would do. They're gonna make the experience worse for other people
Um, how does that scale?
um, but I think that
First it's just super interesting to think of the minimal criterion at scale
That is that is that is going to kick in more like right now minimal criterion is almost irrelevant
And that's why I don't know I probably no one would notice it one way or another
It's it's not necessary at the moment because the people who have come in generally have some connection to me or my co-founders
And so there's a level of trust that they're just generally people of similar interests
Everybody's sort of on the same page. There's a few there's a few people who came in who who probably weren't great
But like it's not really a problem at this point
um, and so
So there it's yeah, you got this kind of a community. We almost curated. They're nice
And so it doesn't really matter you you might not even I don't even know if you knew there was a minimal criterion
I'm assuming you didn't know that uh when you visited there. You probably I would assume you wouldn't know that
Is that you it looked like there wasn't but I assumed that there had to be
You because um, you're you're building a system that because we can think of it topologically so on on facebook
It's quite homogenous and in your system you can think of this landscape where you have peaks going out to the horizon
And it's it's much more even and balanced and then you might argue
Well, there's a real risk that you might have something very important which doesn't really get mixed together
Because you so many people are independently thinking of very important things
And they're not being raised up because we don't have this kind of homogenizing force
But but then you can bring in well you do because we're in a globalized world and everyone's everyone lives in the same world
Everyone watches the news everyone uses facebook and so on so there's this weird kind of like convergence from other platforms that will leak into your system
That's so our other systems leading to convergence in general like of outside those systems that that's the implication of what you're saying
Um, so actually I would just
So I don't lose that train. I thought about the middle criteria. I do think it's really interesting to scale
I'll just put that like to hold that point in the conversation too because like that's um
You know, we see really interesting dynamics in these mineral criterion algorithms
Like when we run them in like without people and they they they're very good at diverging and filling up a space of possibilities
Um, and so I think at scale you would start to see that true filling
Um, like filling up because the space of possibilities that like we play within these toy domains like a robot in a maze
It's not so interesting, but the space of possibilities of human thought is super interesting
Um, and so I think that's one benefit at scale that like never ever seen an experiment like that at scale with people
That will be interesting
But you're saying that nevertheless like the world is inside of this kind of convergent loop like it's it's most systems
And it's not just like conventional what you might call social media, but things like youtube
It's like they're they're all working on this like based kind of convergent stuff
And I mean I see commentary in the news every day even today like about
Um, why things like pitchfork are closing down and stuff like it's like these these ranking algorithms are turning into the
controlling force of culture
um, and I I do wonder how how much that's affecting
Uh, everything because you know like like things that seem weird to me culturally
That I don't understand like for example
It seemed like until around the year 2000 that like rock music was evolving in some way
Like you could be pretty sure that like the music of today is really different than 20 years ago
um
And like I was enjoying that until around that and then it seemed to stop like now
It's like almost 25 years later
Like it doesn't sound much different from what it was 25 years ago
And I'm like sorely disappointed. I expect it to be in shock by now
And I wonder if it's because like there's this major convergent mechanisms like a cross culture. Are you worried about?
objective measures creeping into
Maven in the future the ultimate like version of drifting towards quality over diversity is is a sellout
Like if I did that
But it's you know, I would be a little worried because yeah, like commercial pressures exist
But uh, I don't imagine myself doing that at the moment. That seems unlikely
I mean, that's our differentiating factor too. It's kind of interesting. Some people have said like, you know, you you're gonna have to
Introduce like these things in like people just like somebody said to me like, um
The only reason anybody going to go to another social network is going to take their followers with them
Like you're gonna have to have followers
And so I'm just like well, but that's our differentiating factor also
So it cuts both ways
Like if we just have followers and likes like why would why would you go to us?
You already have that and your other network like it's just absolutely makes no sense
I mean, I understand that's like the argument in things like
Threads or blue sky or mastodon. Oh, like they are basically just twitter run by different management
Um, and then like, you know, you kind of try to import your followers
Um, they all have a uh, like some other kind of you know motivation like why why should you just go play the same game somewhere else?
Um, some of them try to say like we have a more kind of like fun field culture
We're not about arguing but but I mean who's to say that you can't control culture
And so, you know, I I think
It's like creating another one of those is just not not going to do anything
It's going to be an absolute failure from business perspective
So it some is it sense it sense it's an advantage that we are so different like it allows us to differentiate in this market
Um, and uh, I'm not sure what we would gain by becoming more objective other than just like having no differentiation
Yeah, and I've been reading this book broken code talking all about the evolution of of um, you know, facebook and
zuck had this methodology of
Just copying everyone else's ideas as quickly as possible
But your one is so paradigmatically different even more so now that I've understood it more deeply speaking with you that there's no risk whatsoever of him copying it
Um, which is actually a bit of a moat, right?
Yeah, exactly. So I can't get rid of likes
That would be or file our friends. I mean that'd be crazy. That's not going to happen
I mean they could try to start a separate service, but I I think it's way outside their philosophy to do something so crazy
Um, and so nobody else can get rid of it either. It's an excess and gonna get rid of likes
It's not gonna happen. So and I by the way, I think those services still serve a purpose, you know, I think of it not a social
I think it was an announcement service
You know, like I feel it's really weird that we think that social means having popularity metrics
But like to me it does help you to get a megaphone
And it's useful if if you want a megaphone or if you want to listen to the people who like have maybe you think use megaphone
You want to hear like I don't feel like we should get rid of all of that
It's just very convergent because there's only so many megaphones to go around
Um, but there's nothing necessarily like there's a lot of bad side effects to it
But I don't think we should just completely get rid of it or that it's necessarily the case that maven has to replace all of that
Like we can have something good for having megaphones and making announcements to our followers
And we can have something for exploring and curiosity
Um, and they can coexist and but yeah, I don't see
Zuck or anybody else in this field like going going in our direction. Um, it's just impossible
Yeah, there was this really interesting thought experiment about a
Panopticon which is this hypothetical building where I think it's a prison and
Everything you do can be observed through a kind of series of mirrors
And the whole idea is that when you know
When you're in front of the judgmental eyes of others you don't explore
Any new interesting behaviors you don't discover yourself and so on and we're talking about yanlacoon earlier and in a way
You might feel sorry for him because it's not necessarily that he's incapable or doesn't want to talk about other things
It's almost like because his personal identity and because people's
Understanding and expectations of what he says are so kind of diffused and solidified in the system
He has no free will he can talk about nothing else because that's what he's supposed to say
And the only way to break out of that pattern is to kind of step away from your social personal identity
Yeah, and which is really hard and risky and frightening to do that. Um, so it's it's true
I do think he like almost everyone else in his position is trapped. Um, that's what I want. It was very interesting to me to, uh
Experience just dropping out of my field. Um, which effectively did, you know, because I was like machine learning research
and then just like nothing
and um
my mind
Like just outside of maven even like it just completely started going in new directions like in machine learning
You know, because it's like it no longer mattered. Like I have no incentives anymore
Like like I don't I'm not trying to satisfy anybody's expectation professionally
Um, I don't have to publish a paper. So I just um, I just noticed immediately like a liberation in my thinking
Which yeah made me think a lot about this issue why people start to get stagnating when they get older
Um, like is is it just aging or is there like more to it? You know, because it's just like the the social effects being so powerful
Um, so I've kind of been enjoying just like my mind being completely free
Um, not not having any I mean, I still have social media expectations. So that's still true
Like if I talk about AI online, I know what people expect
But like in terms of just like thinking about AI or what I need to do
I don't need to do anything. Just think about whatever I want to think about. It's kind of interesting
Yeah, I've often thought about this. Um, you know yoga teachers talk about the tyranny of your social embedding
and of course, they don't use that technical language that they'll talk about it in terms of
um, not thinking about your social world and just being present and
Experiencing things as they are and just being but basically what they're talking about is
Escaping the the tyranny of the social world which erodes your agency and forces you to do things and makes you worry
And um, yeah, I agree with you. It's not about aging
Um, I think as you as you get more and more sclerotically ensconced in the social world you kind of like
You don't even your your your optionality just just disappears
Yeah, yeah, it's it's very true
It learns this epic tag cloud and it's not hard coded in any way. It just grows over time
It's it's a bit like a huge cloud, you know, a new interest arises
Um
And it might be a side effect of old interests, you know
That this is sort of like the idea of this like diverging kind of like going into new areas from where you've been
You know, because if you're talking about computers, then you might start talking about ai is it as a side effect of that now?
ai is introduced to the system
It's a new interest at that point computer computers was an it was an original interest now. We have ai as an interest
It's implicit that like ai is related to computers like that's what you think in a graph. There would be related in some way
But we don't actually
Have like this massive data structure that shows all those implicit relationships. They just exist implicitly
We extract them at certain points. So like when you go to
The profile of an interest because like I said, you can follow interests as if they're almost like people and has a profile
like one section of that profile are
Related interests and those related interests are known for reasons like that they co-occur
And so it's it it understands that these have co-occurred before and it figures that out at that point
But the whole graph is not stored in any one place at least not now
So it's an implicit graph that's growing and it has different aspects to you know, it's not like one graph either because there's also
The interest graphs to go through people
You know because you can say that I have these interests and then I overlap
That overlaps a lot with you and then we can see what it whatever the other interests you have
And so those are interests that are likely interesting to me too
Um, you know because like we share a lot of interest anyway
Um, and so we could actually say, you know, what is the graph that goes from interest to person interested in it to other interests to another person interested
So there's a there's a there's a graph like that too
And all those exist implicitly inside of the system
And I think eventually we would if if the system is successful
We would analyze those like we would try to extract some parts and let you see it more explicitly because that would be fun
You know, it would be fun to see the graph to navigate the graph explicitly along its edges and just see what this thing looks like
Um, it's a little bit like like visualizing like the the family tree and evolution or something's like what's related to what?
Um, and uh, that tool does not exist yet
But I imagine we would eventually build it. Um, just because it would be fun for people to see and probably also useful scientifically for
For uh, for researchers. Professor Kenneth Stanley. It's been an absolute honor as always. Thank you so much for joining us today
Thank you again. Uh, this was a great opportunity. I always love being on this show. Be happy to be here any day
Amazing amazing
