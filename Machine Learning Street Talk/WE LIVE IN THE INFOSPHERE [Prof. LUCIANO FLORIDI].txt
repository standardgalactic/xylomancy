Professor Luciano Floridi is the Oxford Internet Institute Professor of Philosophy and Ethics of
Information at the University of Oxford, where he's also the Director of the Digital Ethics Lab
of the Oxford Internet Institute. Still in Oxford, he's a distinguished research fellow of the
Yuhiro Centre for Practical Ethics of the Faculty of Philosophy and Research Associate and Fellow
in Information Policy in the Department of Computer Science. Outside Oxford, he's the Faculty Fellow
of the Alan Turing Institute and Chair of its Data Ethics Group and the Distinguished Scholar
in Residence of the Department of Economics at the American University in Washington DC.
His research concerns primarily digital ethics, the philosophy of information, which is a discipline
he founded and the philosophy of technology itself. I will introduce AI as a divorce between
the ability to perform a task successfully in view of a goal, shall we say play chess,
chess to be trivial, and any need to be intelligent in doing so. Replace that with
parking a car, landing an aircraft, delivering something to your house. You don't have to be
intelligent to do that if you are a piece of AI, that's why it works. If you had to wait to be
intelligent, it would. My iPhone there turned off properly, would not play better chess than
anyone else in this room if we had to wait for their iPhone to be as intelligent as a rat.
It is because it isn't, and we gave up on trying to make it intelligent as a rat.
We're in the midst of an information revolution, as well as a computing revolution.
Floridi said in his introductory book that all members of the G7 qualify as information
societies, because in each country at least 70% of their GDP depends on intangible goods,
which are information related, not on material goods. Their functioning and growth requires
and generates immense amounts of data, more data than humanity has ever seen in its entire history.
It was estimated in 2003 that humanity had accumulated approximately 12 exabytes of data,
and we're fast approaching the age of the zettabyte, which is 1000 exabytes.
Sometimes people think in terms of, oh, can we regulate AI, which is a bit like,
can we regulate electricity? Well, it's a bit vague. What do you mean? It's not
true, false, correct, incorrect. It just doesn't yet make any friction with the real world.
Floridi thinks that the material world is becoming redundant. Our agency as humans is being
perniciously eroded, and that the increasing dominance of the information landscape, or the
infosphere, as Floridi calls it, is becoming the primary basis for our reality.
Now, about 95% of all of the data that we have today has been created by the current generation.
We're not talking about Shakespeare or Dante. We're talking about lots and lots of dogs and cats.
Floridi thinks that the infosphere is becoming so polluted with every passing day that the
manifold of the infosphere is increasingly determined by technology and artificial intelligence.
People are consumers. Consumers become followers. Followers become barcodes.
Increasingly, the data is stored in a representation, which is primarily machine-readable,
designed for consumption by other machines. Our very existence is being squeezed as a result.
It wouldn't be great to have something instead of us doing it for us, better than us.
Yeah, absolutely. I mean, if you read the description of that something that does it
instead of us, better than us, in Aristotle, it's a slave. That's what we could do in the past.
It was horrible. Luckily, it's not happening around us. But we were using humans as means to an end.
Now, we can use technology. Why this divorce? Why sort of pulling apart and saying, look,
I want to develop something that is successful. I don't care whether it does it in the same way
as I do it. As long as it's successful, it's fine. As opposed to, no, no, I want to implement human
cognition. And if it's not human cognition, I don't care whether it's successful or not,
but it has to have a little spark. Now, remember, AI, is it an engineering branch?
Or is it a branch of colony science? Well, as a branch of colony science, we are at year zero.
No step forward. We do not have the intelligence, as I said, of a rat.
When it comes to engineering, that looks like magic. That looks like what has happened to humanity.
Who has given us so much brain to do what we're doing today? And the old phrase like,
is it worth asking whether a submarine can swim? Really, can a computer think,
ah, that's the wrong question. That's not the framework within which we should understand
what a computer does. A submarine does what it does, an airplane does what it does,
and it doesn't do it like a bird, doesn't do it like a fish. But it does it successfully.
And that's the whole engineering point here. Success in delivering the output,
given that particular input. But how do you know it's not the same process?
Well, imagine you have two, two, four, and I tell you one is plus, the other one is multiplication.
Which one did I use to get four from two and two? I don't know. Two plus two is equal to four.
Two by two is four. You see, you can't say. So it's the same thing. No, it isn't.
The way I do the dishes, the way my dishwashers do dishes, two different things.
Floridi said something very significant and profound has recently happened to human
self-understanding. He said that in many respects, we're not standalone entities,
but rather interconnected informational organisms or info orgs, sharing with biological agents
and engineered artifacts, a global environment ultimately made of information, what Floridi calls
the infosphere. This is the informational environment constituted by all the informational
processes, services and entities, thus including the informational agents, as well as their properties
and interactions and mutual relations. Now, if there was a representative scientist for the
Fourth Revolution, this would definitely be allenturing. It's now critical that we equip ourselves
with a viable philosophy of information.
Gazillions of data, yeah, of any kind, of any sort, and they're all digital, readable, machine
readable. When I mean machine readable, they're barcodes, not meant for our eyes, they're meant
for the machines. If you hear anything about the natives, the natives in this space are the robots,
not us, we scuba die. But these machines, they are digital elements in the digital environment,
reading digital stuff and digital processing, etc. And of course, I show you better machine
learning, better algorithms, but also more and more internal things, things connected to other
things. And when you go home and you see all those green and blue lights, they're not for us,
they're talking to each other. And a lot of the data we have are generated by those machines.
Information and communication technologies have been changing the world profoundly
and irreversibly for more than half a century now, with breathtaking scope and at neck breaking pace.
On the one hand, they've brought concrete and imminent opportunities of enormous benefit to
people's education, welfare and prosperity, as well as great economic and scientific advantages.
This merging of our existence, both analog and digital, both online and offline,
we really ever offline? Of course not. So I'm reminded normally that if you have ever heard
the whale singing, if you don't even know what I'm talking about, then you're very, very young.
But if you know what I'm talking about, then you have used something called a modem.
That is called whale singing. And if you have heard the whale singing,
well, you're more like on my side of the divide. So we don't hear the whale singing anymore.
Floridi thinks that the risks are the nature of reality and our knowledge of it. The organization
of a fair society, considering the digital divide, our responsibilities and obligations to present
and future generations, our understanding of a global world, and the scope of our potential
interactions with the environment. And finally, conceptual implications and complexity of an
information and communication technology landscape. So we don't hear the whale singing anymore.
There is no terminator coming. There is no gods in the sky deciding for us. There's nobody but
humanity responsibility for what we're going to do with this technology. And anyone disagrees,
I hope is just naive and doesn't have an agenda.
Floridi said that the information society has grown quickly and chaotically,
leading to a lack of balance between technological growth and a lack of understanding
of the implications of this growth. It also highlights the need to dig deeper into the
nature and implications of the information age in order to better anticipate and identify and
resolve problems. We started understanding ourselves in roughly in two ways, who I am
and what I can do. I am, no humanity speaking, different exceptional, special because of my
nature and because and or what I can do compared to anything else. So one is called personal identity.
It's going to come close to privacy and the gazillions of data out there are eroding or
transforming, exercising pressure on that particular who I am, my nature, my data subject,
as we are defined by the European legislation, we all data subjects here. GDPR, General Data Protection
Regulation says so. So if you have data subject and there's a gazillion of data about you somewhere
being manipulated, well certainly your identity is not sure we say in question. The other half
is remember not who I am but what I can do as opposed to anyone else but I say I and we define
ourselves at least since Kant onwards in manner of the German philosophy in terms of autonomy.
We are special because we are in control of our actions, we can decide, we can plan, we can choose.
Well now we have autonomous agents out there and if you are trying to identify yourself as
we can only be not the ones who play chess well then we are really in trouble. You can devalue
human skills, you can remove human responsibility, you can reduce human control, erode human self-determination
is the other side of the coin. It's not super dangerous but the rock who thought that their
little drop of water was nothing, 18 years later has a big hole in it because drop after drop after
drop. The drop will shape the stone will shape the rock.
Surely we want to have a technology that makes us more capable of deciding what we want
or prefer what we really have in front of us and I'm a bit worried that here human nature,
no we philosophers we know something about human nature, we'll kick in, we're lazy,
we're also very malleable and we are easily convinced to do this or that so we need to be
a little bit more careful exposing this very fragile malleable entity to a very robust,
quite silly, very efficient, very successful technology that will probably tend to inadvertently
change the nature of that fragile entity. This is something that I would like to be a little
bit more concerned about not terminate. So until recently you would go to know this wonderful
techie conference and it was all about technology innovation. The average politician
salivates immediately as soon as you talk about innovation because innovation is growth,
growth is money, money is jobs and people happy. So innovation, innovation, absolutely
and it's crucial but it's not real challenge. I don't think that that's the most difficult
challenge we are facing now. Not because it's easy but because something more difficult to do
behind innovation. The challenge therefore is how you govern all this but governance is a
matter of design, designing the right policies so that incentives and disincentives are in the
right place. There are no loopholes, people tend to do more the right thing than bad thing. So
all of a sudden we are shifting all this into socio-political issues. It's a matter of design,
design the kind of society we want. Remember what's the human project here that we want to implement?
So anyway, I had a very fun trip up to Oxford the other day and had a chat with Luciano himself.
I hope you find this episode valuable. Remember to subscribe and if you're listening,
give us a rating on Apple podcasts or whatever you listen to the podcast on. Enjoy.
So to start proceedings off with misinformation, the internet has put the world in our pocket,
knowledge at our fingertips but the business of the internet is about ads and exploitation,
debasement and derangement of human attention and some have argued that social media is a bit
like the climate change of our society. Are you concerned that the current state of internet
economics will create a layer of plausible yet false abstraction between us and reality?
There is a risk of more and more content being worthless, unreliable, false, misleading,
fake news, propaganda. It is not a new problem but the size, the immensity, the impact is new.
It's one thing if you publish a few pamphlets with several lies and another thing if you have
hundreds or millions of followers believing at once that something was not the case and
something that was the case wasn't. And I'm talking about elections and very public figures.
I wouldn't however put the whole emphasis on the negative side. The social media are also,
if we want, the solution to the problem. Today are part of the problem, I agree,
but they could easily become part of the solution. Precisely because if you remember,
and I close here, good old days when we were online and there was no web, only the internet,
we thought that we were going to create a more informed, more civilized, more reasonable
environment. We can still do that. It's the kind of business models and lack of political, legal
framework that has generated this tsunami of, shall we say, rubbish, which is polluting our
infosphere, the space of our information. So yes, it is a problem. No, it doesn't have to be a
problem. It could be easily a big solution. Once we're just in for all and as close here,
imagine if we were to ban, and it's a bit of a joke, advertisement online would have to pay,
we would pay for the product. That means that there will be competition for quality,
we'll be probably in a different kind of game.
Interesting. And we'll get into a minute, we'll get into the subject of how the structures of,
let's say, markets and economic models affect us as human beings and as a society,
but also affects our perception of reality, essentially. But before we get there, you wrote
a paper called GPT-3, It's Nature, Scopes, Limits and Consequences, and you said that
reversible and irreversible questions are based on mathematical logic,
libanate law and another field such as computing and physics.
Can you explain what you meant by that?
It's a simple idea. So if I fail, it's my fault.
A question that I define there as reversible means that from the answer, you can reverse to
the actual identity of the source of the answer. An irreversible one is one that doesn't allow
you to do that. Let me give you an irreversible answer today. Come to my house, you find clean
dishes on the table. Who has cleaned the dishes? It's irreversible. You can't tell. It could be me
or it could be the dishwasher. So you cannot tell, by looking at the dishes, the output,
whether those dishes have gone through a process of hand washing or machine washing,
and whether the source is one or the other. A reversible one would be the sort of question
that today, and I'm talking today, we can ask to chat GPT. Use anything like Mary's mother has
three children, tell me the name of one of them, and GPT says I don't know. It does, I have no
enough information. It's Mary's mother, so surely. So that becomes immediately reversible. You know
exactly that the answer is coming from a computer, from a large language model, and not from a human
being who gets that immediately. Imagine the other way around. You ask for a super complex
calculation, and boom, you get the answer in a fraction of a second. The other one is make a
mistake and maybe takes longer. So who was the other side? So increasingly in the paper, I've
read that, and it was before chat GPT coming out, but it's obvious. It's been our progress since then.
Increasingly, the sort of output that we are dealing with will become irreversible. We will be
unable to tell whether the source is, for example, a human being, a group of human being,
a human being with a computer, or chat GPT, or whatever is going to come, GPT4, etc. Imagine
GPT10, not many years from now. I think that it will be completely irreversible. It does not mean,
however, let me close here, that I'm like the dishwasher. If you can't tell who did the dishes,
what difference does he make? I've done them in one way, which is completely different.
The machine does it in a sort of mechanical, etc. So we should be clear about what we infer from
the reversibility, any reversibility of the output. And that seems to me where a lot of confusion is
generated. Interesting. So there's the provenance of the information. So where it originated from,
we could go down the line as saying, because it is human aligned with this reinforcement
learning for human feedback, it's remarkably human aligned, actually, much more than the
original GPT3. And then you spoke to this somatic divergence, and we can talk about the pragmatic
divergence as well. And actually, that's getting into a little bit about what John Sowell talked
about, you know, the difference between ontology and epistemology. Is that something that you're
seriously concerned about? I mean, could you expand on that?
I am concerned about it. And I'm one of the few people, or I hope many more than a Sims,
who agree with the Chinese room, and the the philosophy behind it, of course, you can always,
not among philosophers, you can always argue for details and sophisticated counter-arguments,
but the bottom line, I mean, John got it right a long time ago, we're dealing with syntactic engines,
there is no understanding, there is no insight, there is no emotional involvement, etc. Anything
that would go into qualifying, characterizing human intelligence, which is also a rather fuzzy
concept, by the way. So on that front, I think we're going to see more and more of successful
machines of the kind that we were just discussing. You mentioned the source, because that is the
real difference. Let me give you a small example.
Suppose you take from the shelf an amazing novel, a novel that has John won the Nobel, for example.
I would be surprised if you were to confuse that for something that's been generated by GPTX.
The other thing is not true. Suppose you take a normal text, like an encyclopedia entry,
or a good summary of that novel. Would you be able to tell me whether it's a human being or GPTX?
You wouldn't. So there's also a symmetry between the sort of product that we get and the sort of
inferences that we can run. Final point, you know, technique is not everything,
and we always fall into the same trap. You see someone reproducing on the pavement
in a street, the Sistine Chapel. That's amazing. I mean, I wish I could do that,
but it's not Michelangelo. Why? Well, because there is a different history, a different intention,
there's a different aesthetics. So the mere ability of reproducing or doing like
fails to get the semantic capital behind all that, the intention, the interpretation,
the historical context, the continuity, the why did it happen and did not happen something else.
All that is the richness of our understanding and semantics. We lose that if we think that
all the difference that there is between Michelangelo and the artist in the street
is just technique. It's not the case, and we should not be confused on that.
I completely agree with you that there is a rich semantic context which is embedded,
and this is something I'm conflicted on. So I agree with Sirle in the sense that he said there
was this rich and nagal actually, this impenetrable realm of the subject of experience, and that
informs the meaning. There's a nontological difference in understanding,
which is what Sirle said. But what's been so remarkable with chat GPT is it does seem to
confer some semantic sort of inference, if you like. And I think the reason for that is
going back to Pierce's triad, the symbolic version, the semantic content is embedded in our language,
and that's why GPT3, even though it's mimicry, it often appears to, I mean,
for example, it knows what the concept of Christmas is. So now it's becoming
such a close reflection of us, it's becoming more difficult to distinguish.
And at some point it would be impossible, if not already. But we should be careful not to confuse
this with what you mentioned before, the intentionality, the realm of meaning,
of existential experience of all this. Christmas is something that reverberates and provides meaning,
for example, in each of us for a reason that is utterly cultural. It would have meant nothing to
play to, obviously, for historical reasons and so on. Let me give you an example. This would be
like saying that when you cut the tree and you find the rings of the tree, telling the age of the
tree, the tree somehow told us its age. Well, it takes a little bit of imagination. No, it did not.
And yet the symbolic, the representational, it is true that the tree has provided that information
to begin with. But it's also because we can interpret that way. So I would like to see more
work done on the hermeneutical side of all this, so that we get clear on what we are consuming.
Content, which is sometimes impeccable, sometimes irreversible, cannot be distinguished from
content that could have been produced by a human being. But also the understanding, the interpretation,
the context, the why it matters of their content. Now, boilerplates are exactly what they are.
And if there's something in a, for example, encyclopedia entry or in a bigopedia entry,
that matters is exactly, is objectivity, is luck, insofar as we can do that, of interpretation,
of an angle, almost like as if the author had to disappear. But that is exactly where tools like
GPT number will excel. It will be different if we were talking about the way in which
an artist, a writer, or anyone simply putting notes in her own diaries, is going through the
process of verbalizing, conceptualizing the experience, etc. So ultimately, allow me another
analogy. There's a reason why, although we could have the best director and the best orchestra
performing that particular concert, in the hall, a just a recording that you had to play,
we don't. And we can't get a few, a bunch of kids in a choir and a few people who are rather
amateurish here in Oxford, and do a good job, but certainly not as good as it could have been done
by professionals. Is the human experience that matters? It doesn't matter whether you could
do that, better by having a tool. Given the pollution of the infosphere with data generated
from large language models, what are the ethical implications on society?
They are quite enormous. I mean, the responsibility on so many fronts, this responsibility, of course,
of the source of this pollution. And by the way, we know that the actual sources are not many.
It's not that each of us is constantly pouring, sort of providing extra bits of
misleading information in life. We do inadvertently repeat and reverberate that. But
the actual sources of, say, for example, Russian propaganda are very few and well known.
And likewise, you know, on many other contexts. So first of all, a huge responsibility on those
who are polluting the environment. They are few, they are powerful, and they should be
curtailed, shall we say, if not entirely stopped. Huge responsibility on people who could legislate
much better and more firmly. Look at the current debate. People listening to this and watching
this should look at the date, but look at what's happening these days to Twitter. I mean, the
debate is open about whether it's going to be a source of information or misinformation and who
should be there or shouldn't, etc. How much do we want to control? How much we want to not filter?
But also our responsibility as a society, we should demand more and we should be more careful.
So if you put together all these responsibilities between the producers, those who take advantage of
it, the consumers, we are all in on this. No wonder, it's a mess. But as I said at the beginning,
we could rectify it with a bit of goodwill. No, you wrote an article in Aion a few years back
called Should We Be Afraid of AI? And the risk debate has been ongoing since the 1960s when
Irvin John Goode prophesied a potential intelligence explosion that could leave humanity behind.
And on one side of those who believe in true AI, the Church of the Singularitarians, as you
wonderfully described them. And on the other side, you have those who do not believe in true
AI, known as the Church of the Atheists, but spell AI, which is absolutely delicious. And
you said we should remain tolerant of both views. But the real challenge is to ensure that AI is
used in a way that does not undermine human dignity. And you said the dogma of the Singularitarians
consists of three beliefs. The creation of some form of AI is likely and humanity will be dominated
by it. And it's the responsibility of the current generation to ensure it's benign.
So you said that Singularitarianism is implausible. It relies on weak senses of the possibility
and Moore's law. And it distracts from the real evils. It's almost an indulgent of the
Western elite. So what can be done to ensure that Singularitarianism is not a distraction?
I'm afraid that the only cure there will be history, meaning that as we move on,
we will see that AI in its variety of forms, natural language processing, robots,
even little gadgets that can help us to do this and that in our mobile phone. I mean,
that they improve, say communication or enable us to take a better picture. The recommended
systems that you find on Netflix, etc. And all these things we will see as we move on and
grow up that what has really happened is absolutely extraordinary, but not extraordinary as the
Singularitarian thing it is. We're actually separating and increasingly so the ability to
do these things, to solve problems, take care of tasks successfully in view of some goal,
some end, from any need to be intelligent in doing so. That is extraordinary. This
divorce between agency and intelligence. That is amazing. And if anyone doesn't want to speculate,
just think about chess playing. I mean, chess playing today is done at zero intelligence,
at least I hope people will admit that my iPhone doesn't think any beats anyone I can encounter.
So extraordinary ability that would require intelligence if I were to play that way,
I wish I could, but that it can be done as zero intelligence. Now, as we learn more and more,
that there is the delta, the gap that we are building. And these two things will go further
and further, not away as we move on things in terms of what we just said in terms of
large language models, the GPT and the other ones that are quick following from other companies
without advertising for anyone. We will find any Singularity narrative science fiction,
I mean, entertaining at some point, frustrating at others, because as you said, it is also
distracting. We have plenty of problems generated by this divorce. If you have an enormous new
force or source of agency in the world at zero intelligence that requires intelligence hours,
governance, law, ethics, a sense of what is the human project you want to build.
And meanwhile, you're worried that your car would run away with your credit card to have
a holiday on a beach. Well, then certainly frustration starts building up because we're
not taking care of the real issues. Now, the discrimination, the digital divide,
the amount of things that we're not doing, sort of opportunity cost,
wherever we are lacking a clear framework and so on. So Singularity, I mean, like all churches,
I think they will become increasingly old and they will not die. I mean, they will always have
a few faithful ones, but hopefully will not be in the headlines, which is one of the reasons why
people like to not push forward the Singularity so that they get the headlines. In terms of the end
game though, you might argue that they have a point. I suppose you're arguing that, I don't want to
put words in your mouth, but you just spoke about the industrialized attenuation of our agency and
maybe that's analogous to saying we're becoming increasingly enslaved by technology
and our children's generation much more so than we are. So in some sense,
that really is what you argue. Oh, no, it would like saying, well, I mean,
you could read that in terms of the engine and wonder whether the engine and the whole
industrial revolution and urbanization coming from model engine and so on has been
liberating, has been enslaving, has been a good thing, a bad thing.
As all real historical and real philosophical issues, it's a mix back and you can't simply say,
oh no, I wish the car had never been invented. Really, like I'm not quite sure, but on the
other hand, the damage that we have caused to this environment, so same with the AI. No,
one could say, oh, I wish people had never taken this journey out of the particular bottle.
Really, like the kind of things that we can do thanks to this. Now,
things of one case for just a simple case like cold fusion. I mean, today, if there's even a
remote chance to get there is because of machine learning. We will never get there without the
enormous abilities of computational problem-solving provided by AI and so forth. So this case too
requires more commitment, more sort of human intelligence, more governance, not less. So
sometimes I find that debate becomes a little bit of a deterministic kind of debate between things
that not people who think they were doomed and things, you know, with no rosy glasses think, oh,
it's going to be a wonderful world. Well, honestly, it just up to us that the crude,
painful sort of truth is that unless we do something about it, it will be a mess. But if we do
something about it and we do it rightly, well, then we can do an enormous amount of good things
for this. Now, at last point, just to have some references, just look at, no, the impact of AI
in a variety of forms again, on the sustainable development goals has been already significant,
could do so much more at the same time. How much energy goes into development these sort of large
language models? Huge. Are we really doing the best with this sort of consumption and impact
when then, if we were to use this, for example, for entertainment, for advertisement, when every bit
of electricity out there should be carefully considered, even impact on the environment,
these are real issues, but they are philosophical issues for human beings.
Is there a way that we can embrace this technology in a way that preserves human dignity?
I think so. The question is not, however, to simplify in terms of human-centric,
because, what reason maybe we can explore later, but we have done too much of that, precisely
because we have been so human-centric, we have destroyed this world, we have killed the environment,
we should be more sort of at the service of both the natural and the sort of man-made
artificial environments as well. So to me the best way of using technology is by
respecting, as we said before, human dignity, but also using technology to the benefit of
quote-unquote the other, which could be future generations, it could be the environment,
it could also be us taking it as humanity, but not just us. If we use technology just for us
and our own benefit, we will ignore future generations, we will ignore the environment,
and we will not have done a full decent job. So yes, there is, but it takes a little bit more
of a commitment that we have at the moment. What form of governance do you advocate for?
To me the governance that we could develop would inevitably leverage this digital revolution by
offering, not imposing, not expecting, offering more participation at the beginning of the
decision or process. So these are two distinctions that go against the right democracy. I'm not
advocating for the right democracy, I'm saying offering so cannot be expected or compulsory,
but plenty of offer at the beginning, not at the end. Take a referendum, a painful memory here,
we are in the UK, a referendum is not the right democracy. Why? Because you can't choose between
A and B, if you dislike both A and B, someone has prepared the alternative for you. The real
democracy that is co-designing of the choices, not the options at the end, but the initial choices,
is the one that says, should we consider a referendum? So the point here is that the earlier
the involvement, the better is to live in that kind of society. So the governance that I'm advocating
is a governance that has as early as possible involvement of people in a co-design of the
choices that we face. Now that was here, sorry, but it's a huge topic. That means that
behind this particular sort of mechanism, there is a separation between those who have
power, the people, and can delegate power, and those who exercise power but don't have it.
This structural separation between having power without exercising, and exercising power without
having it, that to me is the ABC of any decent governance. Governance fails, especially political
governance, no, in the democratic sense of governance, fails the moment you have those
who have power exercise it and those who exercise it have it. It doesn't matter whether it's a
majority, it's a minority, it's an oligarchy, it's three people, it's one person, it's a family,
it's a tyranny of a few people, maybe only one. As soon as you separate this, then we start having
the right governance, then we can talk about involvement in the decisional process as early
as possible, then co-design, and therefore for all this, the kind of technology that we have,
this is doable if we want to implement it. One thing that concerns me is that when we talk about
the architectural design of governance, the structure can sometimes exclude other parts of
the complex world that we live in, and also there's this compatibility with the Demos,
which is to say it needs to be intelligible, and then you have this problem of people voting in
their own self-interest, even if they did understand the purpose of the governance.
True, and we know that self-interest can go only there far. We learned that from the past century,
no, no, the 20th century. The 20th century has been the century, especially the second half,
so stuff has been a disaster. The second half, much more successful, has been the century of
the citizen consumer, and therefore the self-interest as a citizen voting for the best options,
making a difference, and therefore, no, competition between different parties, etc.,
and the consumer having the same kind of choices, voting quote-unquote with his no,
that what they feed, so to speak, choosing their restaurant or another, their shop,
rather than another, their product or another, but this figure that was the selfish interest
consumer slash citizen has become not the user and the follower. So today, instead of having
citizens, we have followers, instead of having consumers, we have users, and therefore there has
been sort of an impoverishment of precisely their selfish interest, the caring for my
individual project, which is one of the two legs for democracy. So their leg has become weak.
The other leg is absent, which is the social side. So at some point, society should also
invite, facilitate, support, so nudge gently towards more not social solutions, for the simple
fact that if we need to be more ambitious in our goals, we need to get together. It's not enough to
not pursue our own self-interest, we have to pursue interests that are shared. So imagine the following
picture out of this quick analysis, two legs, one has become weaker, the selfish interest for my
individual project, the other one, which is a social project, is not there for obvious reasons.
When we tried in the first half of the last century, it was the most horrible episode in human
history, the Nazi, the Soviet Union, no democracy going out of the window. I mean,
Auschwitz, I mean, we have created the most horrific possible nightmares that humanity has ever seen.
So on this not so well so established body of democracy, which has one leg missing, and the
other one, we, there's a lot of work to be done, we can do a better job reinforcing a sense of
individual projects, what we call not more selfish interest, yes. And no, instead of, no, either or
instead of weakening it, reinforcing it and balancing it with a social project. The idea that, no, if
you get together, you can do so much more and so much better than just by yourself. Finally, example,
if that car, and I've used that more than once, forgive me, but if that car doesn't start,
it's totally pointless for you to go and push and come back home and say, I've done my duty.
It has to be the five of us, and it has to be the five of us, one, two, three, push, coordinated.
So we need to have a society that increases the support for individual projects and has a good
liberal democracy and counterbalances that with social common projects. So there we have both.
Now, normally, you find this a little bit more sort of developed in, no, western social democracies
of a Scandinavian kind. No wonder everybody wants to get there. I think you would agree,
I mean, Chomsky spoke to this, but that market forces as well as technological forces re-ontologize
us. I want to pick up on this word re-ontologize. I think it's an amazing word. I'm just going to
scroll down to this. But yeah, you said that once digital immigrants like us are replaced
by digital natives like our children, the immigration will become complete and future
generations will increasingly feel deprived, excluded, handicapped or poor whenever they're
disconnected from the infosphere like fish out of the water. You said that information and
communication technologies are re-ontologizing, which is an even more extreme form of re-engineering
us in our society, which is to say its intrinsic nature is being transformed. You said that we're
modifying our everyday perspectives on the ultimate nature of reality, that is our metaphysics,
from a materialistic one, you know, in which physical objects and processes play a key role to
an informational one. Explain your rationale, but I love this word re-ontologizing.
Well, this comes from a very Kantian anti-metaphysical perspective. I find any metaphysics of the
bed kind that Kant was talking about beyond my comprehension. It's not something that I just
don't quite get. I mean, how people can possibly believe that they have a direct line with being
capital B and being told by being what it's like to be being is beyond me. So, I'm afraid on that
front I am rather deaf and I understand that it might be my limitation. I rather speak, sorry,
when I use the word metaphysics, that's what I mean, the Kantian kind of thing that you don't do
because it's meaningless to do it. There's also a lot of no kind of Vienna circle kind of an
analytic philosophy in all this, but ontology, on the other hand, is how we structure the world
in the sense that we think that that's the way it is. So, with the kind of eyes we have and the
kind of light around the world, those are the colors we perceive. To me, the colors in the world
are part of the ontology of the world. They're nothing to do with metaphysics. It's not the
way things are in themselves, no woman and etc. I have no sense of what we're talking about,
but certainly a world full of colors is the world which I take it to be, the world. That's my ontology.
Now, reontologizing means changing some of that particular nature, allowing me a distinction,
so I hope it's not too confusing. Reality in itself, call it system. Description of reality
as we perceive it, enjoy it, conceptualize it, live through. Model of the system.
Ontology to me is the ontology of the model, it's not the metaphysics of the system. I hope I haven't
made a complete mess here, okay? So, metaphysics, no man and system, whatever the source of the data
that we get, fantastic, the data don't speak about the source, the music of the radio is not about
the radio, but there is a radio. Of course, the music is what we perceive. The music has its own
ontology, structure, etc. The model. The model is, at that point, what we enjoy. Why did the
digital revolution has changed the nature of the world around us? Not metaphysically,
but ontologically, so the reontologizing. Because some of the things that we have inherited from
modernity, and I really mean modernity in the ordinary sense, no, three or four centuries
depending on whether you have a large, short, medium modernity from Columbus onwards or
bit shorter, first world world, your size, your preference, but modernity, we have been
inherited from modernity a sense of the world that is now being restructured and a certain
understanding of the world, so re-epistologizing as well, of that world. Two simple examples.
Modernity onwards, which I know I've used in the past, we have grown up with the idea that
law and territoriality are two sides of the same coin. You can't simply separate them.
My place, my rules, your place, your rules. If from Westphalia onwards, that's the ABC
of any legal system for a long, long time. The law ends where the territory of that particular state
that issues the law ends, no, at the border. So, law and territoriality, two sides of the same coin,
or two sides of the same piece of paper, you can't cut one without cutting the other. Of course,
that's the ontology of the world in which I live. Welcome to cyberspace, right to be forgotten,
our whole debate, and today we know that actually law and territoriality are no longer
two sides of the same coin. They've been completely decoupled and you cannot have rules that, for
example, are passed in Europe that apply to a search engine that is based in the United States,
and yet is only one click away. So, the right to be forgotten was not the moment when this became
obvious. We were legislating about Google and Google not complied in Europe. The complaint was like,
well, but it's not changing the way Google.com is working. Well, the law doesn't apply there.
And of course, there was a debate in terms of, oh, but it has to apply everywhere,
in the physical space, etc. So, the decoupling of the law and the territoriality is a reontologization
of that particular space. We live in a different world. We perceive the world differently.
Conceptually, we also start thinking differently. Now, let me give you a small example, and I close
here, of a reontologizing of something we took absolutely for granted. If you have a taxi,
you have a license. If you have a license, you can be a taxi driver. The two things go hand in hand,
and it's illegal, etc. Then Uber comes, and having a car being allowed to give a lift to someone
is decoupled from having to have the license as a taxi driver, a cab driver. This decoupling has
generated an enormous amount of profit, problems, issues, a change in game, and all of a sudden,
we realize, yeah, those two things were not completely on one side of the other. So, obviously,
this uberization of the world means decoupling things that we have taken for granted as a single
unit from modernity, or gluing together things that we thought were completely independent.
In the past, last example, personal identity. For a long, long time, we discuss personal
identity, I mean, philosophically speaking, as you like substance, soul, body, what the
incarnations are. Today, if you look at anything, our identity is our data. That's the European
legislation describes as data subjects. I am my information, privacy, the whole privacy debate
is discussed in terms of what constitutes me as that body of information. Privacy is a matter of
getting my body almost, so why is this important? Because if you look, and I close here, at the
European legislation, how did they cope with the decoupling of space, territoriality and law, by
coupling personal identity and data, personal data, so that today the legislation does not say
you do as you are told because it's my space, but it says you do as you're told because this data
are the data of the individual who is my citizen, wherever you are. So the coupling,
re-coupling new legislation, this is incomprehensible unless you have this cut and paste in mind,
which is the reontologizing, re-epistemologizing of modernity through the digital revolution.
It's a big deal. The Uber example is absolutely beautiful, and I can place myself in a startup,
and these folks think they're being incredibly disruptive, and what you said is interesting,
we used to talk about the mind-body dualism, but now there's almost a kind of identity dualism,
you know, there's my digital identity, and that is becoming increasingly, as you say,
the only thing which matters. But to close off this re-ontologizing thing, I'm not sure this
might be a little bit tangential, but Heidegger conceived of technology as an intermediation
between us and our environment, I think in a similar way, and you know, it shapes the environment
as much as it shapes us back, and in a sense, reliance on technology can make us less human,
which is kind of what you're relating to. So is there an instructive contrast to Heidegger's
analysis of the relationship between humans and technology, and you're right?
I think Heidegger was onto something when obviously, technologies between us and the environment,
but allow me to be critical. He didn't see this, seems to me, clearly enough, because that description,
a description of a first order, what I like to call first order technology, is essentially the very
idea that between me and the tree, there might be, say, a sewing mechanism, or between, say,
me and that particular sort of garden, there might be a spade, but increasingly,
unless the industrial revolution, instead of having humanity and nature and technology in the middle,
you have humanity, technology, and technology, and that's a second order technology. So we increasingly
use more and more technology to deal with other technology, and that's not in Heidegger, it's
a second order technology. But what AI does is to generate a third order technology where, no,
between A and B and C is technology throughout, so it's a computer controlling a robot building a car.
At that point, we are outside that relationship, and we can just control,
check that everything goes in the right way, we are on the loop or after the loop.
At that point, we can reinterpret the Heideggerian negative view of technology and say,
that is exactly where you want to be. You want to be outside the me, technology, nature, or me,
technology, technology, I want to be on top of technology, technology, technology,
and see whether that goes in the right direction. Now, it's even more powerful, even riskier,
but with higher risks, higher rewards, it could also mean how humanity can actually take care of
the world, nature, and itself properly. Now, we would not be able to save this planet and ourselves,
from ourselves, on this planet without technology. It's inconceivable that we can see at the end of
the 21st century as a success by abandoning technology, like seriously, no, more embedded
technology, but then we need to understand this third order idea if we're still stuck in a sort of
19th century, 19th century idea that it's between me and the world, we're not going to get out this.
Final point, obviously being on the loop or after the loop, the designer of the whole loop,
comes with enormous responsibilities. That's why ultimately, to me, it's not digital innovation,
but it's the governance of the digital that makes the whole difference. Digital innovation, it's
not easy, but it's not difficult, especially if you have deep pockets. You buy the next startup,
and the next three kids will come up with a fantastic idea. Knowing what to do with that,
that takes a genius. So, you said in your information book that John Wheeler coined the
notion of it from bit and some physicists entertain an information-based description of
reality. And you said that this informational metaphysics may, but does not have to endorse
a more controversial view of the physical universe as a gigantic digital computer,
according to which dynamic processes are some kind of transitions in computational states
in a style described similarly by Putnam or maybe I call it Turing machine functionalism.
So, you pointed out the ontological difference between imagining a stomach as if it were a
computer versus holding that the stomach is actually a computer. You said that there's a
clear philosophical distinction between whether the physical universe might be modelled computationally
is a different question to whether the ultimate nature of the physical universe might actually
be digital and computational in itself. So, what's your take? I think the whole problem is ultimate.
We go back to this temptation of talking about reality as if we were something that we need to
grasp, catch, portray, hook, spears, when in fact the way I prefer to understand it is as
mullible, understandable in a variety of ways, something that provides constraints. It doesn't
mean that you can interpret in any possible way, but leaves room for different kind of interpretations.
So, if the flow of data that come from whatever is out there, and again I'd rather be sort of
agnostic about it, can be modelled in a variety of ways, one way is to especially 21st century,
given the technology we have, etc., to interpret that as an enormous computational kind of environment.
It's perfectly fine as long as we don't think that there is our right metaphysics, is the correct
ontology for the 21st century. Now, this is not relativism, because on the other hand,
different models of the same system are comparable depending on why you're developing that particular
model, and let me give you a completely trivial example. Suppose you ask me whether that building
is the same building. That question has no real answer, because it depends on why you're asking
that question. If your question is asked because you want to have directions, I'm going to say,
oh yeah, it's the same building. The same building, yeah, absolutely no. Go there, turn left, no,
traffic lights up. But if your question is like same function, as I know it's a completely
different building, it was a school, now it's a hospital. Next question, so is it or is it not the
same? That question is the mistake. An absolute question that provides no interface, or computer
scientists call level of abstraction, chosen for one particular purpose so that I can compare
whether an answer is better than another. Let me crack a joke for the philosophers who might be
listening to this. Does he or shep? Is it the same or is it not the same? Who is asking? Why? Because
if it is the tax man, the tax man. You're doomed, man. I mean, there is no way you can play any
or I change every plan that you're going to pay that tax. It's the same ship, I don't care. But
if it is a collector, that ship is worth zero. You change all the plans, you must be joking.
It's worthless. So is it or is it not the same? Depends on why you're asking that particular
question. Tell me why and I can give you the answer. Now why, in other words, no frame within which we
have chosen the interface that provides the model of the system, no potential answer. So the question
is like, is the universe a computational gigantic, yes or no, meaningless? Is it worth
modeling the universe as a gigantic for the purpose of making sense of our digital life? Oh yes,
definitely, because we are informational organisms. Aha, so metaphysics. No, I meant,
in the 21st century, the best way of understanding human beings today is as information organisms.
Last century, we thought that biologically, not made much more sense, a lot of water and
sprinkle all the extra and so on, mechanism, decar time, etc. So not absolute answers, not
relativistic answers, but relational answers, the relation between the question, the purpose
and the actual answer. But it takes three, not two. Any absolute question? Absol mess.
This is so interesting. I mean, I spoke with David Chalmers recently about the hard problem,
and there was a thought experiment about maybe David lives in the matrix and one of the architects
came down to him and he said, David, you don't have the consciousness model installed. We've
installed it on other people, but we didn't bother installing on you, but you're a philosophical
zombie or whatever. And what would we need to do to convince you that you're in a simulation?
And David said, well, I'm outside the Empire State Building, maybe if you turned it upside
down, I believe you, but to be clear, you're actually saying, because I'm interested in
this kind of ontological distinction, you're saying that even if we did exist in a computer
simulation, it wouldn't make any difference? It wouldn't. For the same reason that it doesn't matter
whether we are in God's mind as Berkeley's subjects, it makes no difference because
what you have lost there is any traction by asking that particular question,
with anything that would provide any answer. In other words, these are only sophisticated ways of
playing. As you lose tails, I win. Find me a solution. You should stop engaging with this kind
of questions. It's the trolley problem. You should stop engaging in that particular question,
because there is, but philosophers love those disposals. They imagine the possible world in
which, well, as soon as anyone starts talking about, imagine a possible world, whatever that I
reach for Michael Ashnikov or something else, I think we should really not indulge in these
kind of things. Not because they have wronged, but because they are misused. Any real philosopher,
and I'm talking about this, no, 20, 25, 30 classics, have been using thought experiments,
logical possibilities. For a purpose, not in themselves. You will not catch their cut,
trying to solve the demon, no, malicious demon problem. That is a tool to get somewhere. It's
not something worth in itself. Same reason why the trolley problem was developed to test a
particular theory, not as a puzzle in itself. Same reason why people are not in a matrix,
etc., etc. Once again, ask yourself, what is the purpose for this particular question?
Because the purpose is a lot of mental enjoyment, chess is much better.
Beautiful. Well, we've got about two minutes left. So I guess we'll have a closing statement,
but maybe also you could bring in, I mean, I've got a machine learning audience, so they would be
interested in digital ethics, for example, and what they could do to learn more. But
also, many folks are interested in getting into digital ethics and philosophy. So what would
you say to those people? To the machine learning people. Well, first of all, I would say, congratulations,
you are in the right business. But secondly, I would say, please don't forget where all this is
going. Have a sense that these are not just toys. These are not just a matter of competition between
one company and another to have a larger model, a faster sort of computer, a slightly improved
quantum something, and on and on. We can go in a variety of directions. Machine learning is one
of the problems. But think about the impact that they will have on society, on the environment,
and on individual lives. It could be a fantastic impact. It could really make a difference in
suffering, in not saving the environment, or it could be a total disaster. So please
mind your machine learning and be a little bit more aware of the importance of your job.
Don't underestimate how crucial it is, what you're doing. You are providing the foundations for the
21st century information society. That is not a small task. We do that right. We're going to not be
thanked by future generations. We do that wrongly. Future generations may not be even there, but if
they are there, they will not be grateful. So please not be careful. What can be done? Well,
one of the things that, no, this will end up with self-advertisement a little bit, but one of the
things that we are going to do with the new center Yale is precisely opening the doors to all disciplines
and all practitioners. Because research and development today is done especially in AI,
especially machine learning, especially in digital contexts, enormously more within
industry than sometimes in even the top universities. So opening up, having this translational, no,
from blue sky to product and multidisciplinary open idea that it's a big table out there. We
need everybody around the table, the politician, the lawyer, the engineer, the machine learning
expert, the philosopher, the ethicist, the social scientist, etc. Everybody around the table,
then that point that I made at the beginning will become a little bit more reasonable doing it
together to improve the world, improve the chances of saving the environment on ourselves.
It can be done. And I'm not sticking some of my actual neck out, so to speak, on this.
But it's something that I truly believe. It's entirely up to us. And we can do this properly
if we put ourselves into it. Professor Luciano Floridi, it's been an absolute honor.
Thank you so much. Thanks a lot. Thank you so much.
