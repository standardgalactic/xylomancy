Nick, mae wedyn yn lle牙io sequence.
Ble bydd ynですねconnid rom ddiwedd fel?
Rwy'n cael bell am fy sefyllion chi'n cael ti adeilad Carrina,
yng Nghymru wrth iddyn nhw'n ei nhw'n ei deรc solidiflu.
Yn
I don't want to do too many spoilers for people who haven't read the book, but yes, so the climax of Anna Karenina is her leap under a train in a Russian station, probably helps on the outskirts of Moscow, so I can't remember the details, and the question is why, what is it that leads her to this terrible, terrible end, and the natural answer is to think, well, I must be an answer to that in context of her,
her beliefs and her expectations about the future, her sense that my relationship with Vronsky has failed, the whole thing is a mistake, and my marriage is broken down with my husband, and what am I going to do with my child, and just the whole, how everything is falling apart and she's becoming a pariah in Russian society, so there must be some sort of story, we could tell that story, and if we could look inside her head closely enough, we'd be able to work out exactly what was it, what were the key triggers that made her jump then.
And I want to suggest in the book that that's really wrong. Of course, there are mostly forces driving her to a desperate act, but if you were to imagine asking her, just as she's about to make the fatal leap, can you just quickly run through what the issues are here.
She'd really struggled to tell you, she'd say, well, I'm desperate, I'm very unhappy, I feel there's no hope, why exactly, well, you get some salad of stuff, but it wouldn't be a particularly coherent one, if you asked her several times you'd get different answers, and the thought would be that, sort of the intuitive thought, the sort of starting point for lots of thinking in psychology and deed economics where actually there's a kind of very strong sense that people are very rational in their actions driven by that,
that values and their beliefs, there's a sense that there ought to be some true answer, if she may give you a rather incoherent answer, but there really is underneath everything there's a true answer.
So the idea would be that supposing she survives miraculously, she doesn't actually get moaned down by the train, and she's convalescing, and you say, well actually now, now we can really get to the bottom of it, we've got the time, we can talk you through it, we can give you questionnaires, we can scan your brain, would there be any way to reconstruct the
true answer, and I think the chance of what motives were, and I think the answer again is, I want at least to give you the intuition, or give the reader the intuition that maybe not actually, it's not really the case that the true story, as we're going through our lives, we're continually inventing stories about why we're feeding as we're feeding and why we're doing what we're doing,
but the stories are sort of coming rather late in the day, even at the trivial level of sort of doing something like going to the fridge, if you had to explain why we're doing that, I know what it is, I want some coffee and I need the milks in the fridge, so that's the explanation, but it's sort of a bit bogus to think, I'd thought all that through, I'd worked out a plan and part of my plan was going to the fridge, I just found myself setting off, or setting off to turn on the coffee pot, or turn on the fridge, or turn on the fridge, or turn on the fridge, or turn on the fridge, or turn on the fridge, or turn on the fridge, or turn on the fridge, or turn on the fridge, or turn on the fridge, or turn on the fridge, or turn on the fridge, or turn on the fridge, or turn on the fridge, or turn on the fridge, or turn on the fridge, or turn on the fridge, or turn on the fridge, or
or turn on the fridge, Whatever it is. So the stories come after, and I want to say that's true, it's sort of everywhere I mean right now, our behaviours are generally too quick for us to tell the story beforehand is it were if we're playing tennis I'd say, you're charging about
the court reactions to all sorts of you know subtleties of the what's happening to the opponent, opponents play, you can tell a story about, oh, I thought they are quite weak on the backhand, and if I tried to crossquarter definitely know, I'd definitely, not been going to execute a shot, you can accept that story retrospectively, but yeah you can tell us at the basket.
doesn't much about aer inertia.
geworden, but you just kind of knew it to me for them.
Write on them, but you kinda
of Curtis Point.
you kinda know it's retrospect
ish that.
And that's, sort of.
How to we give ourselves about why we do what we do.
It's always rational.
Is always retrospective
i lag.
There is most desperate and extreme
of status in about that kind of six.
Now I think.
Aut diesemy will have in this rights
in its emotional stateist exactly the kind
of situation where you might be something drastic
I brother and instant.
So I suppose there is an insight,
that I am pushing here which is not by any means unique to me,
it is very much as standard in social psychology
and aspects philosophy.
Daniel Dennett has been talking about that a
yoK Pelfer ond, many decades very lucidly.
If the idea is you do not have deep insight into your
own mind, creating stories about your own behaviour as you are going along.
werth i gael fyrando a phobio, fel yna gyson mache ener' ti yn meddwl i'w gweithio ac mae draweratem.
Ond roedd ad скорu rymwn bod bod penderfyniad, mae werth yn ei adwysig yn gawis pa mŵ 뭐야 gyda
eithaf sydd, i ydym yn grathu eu fod yn mhugi'r cyfle gŵr yn ei hench formae ar gyfendrachoddau ateb.
Rheif iawn.
yn ny definitions hayllai, rydyn ni'n iawn yn ei cyfwyn conversations yw cancer Dr Carl Friston.
A rwy'n wedi digw i'r holl reddaksbyn letter hefyd perthyn y teimlo logol Cym wires
tyfnLuc Thomas Plarrau, yn y bywyd, ac r04d o bwyl â'r mhoridau ff Character Mm- nies была reu
2 rhywgsm ddim yn dipyn i amddangos yr ystyfyriau sicrhau beg nesaf, os gweith broadfyrdd
cais ei busodai ddysgu. Goffi spainnau a hyn mae'n roedd y fferrrwyr ddycied threaded
i chi wnaeth ystod o hyd, metallau o 好en ei ganddoedd mawr i gael eu gwrando i heb
Ref odd y vein funct o blau
y gyfrannareth er synth o gwneud.
A cyfsig 눈kenu rhywbeth ffamil ydych yn yws pwyr oxyddiad o ly genocide edrych y gallod hyfrif daytime.
Mae o b отдyn nhic Prophet Draniol a chafethau horau
o hyd y saethro fанияr o dysgu mor hollenei a hannog ar diagnosis hon hefyd o wipwyr yn cyflwr.
Mae hynny yn hun owe cute am ei s Histor f kidaud, ac mae hyn y rhaid o radd o Ger�f yn gochio bedd
dy unaidd vaen ein cynhyrchu cael heb mwyrio sy'n gyffredinol wages grad bod agpersio aboard hon my poder.
os y brawnau poured bobl yn cael pergyfu.
Ond dog spam Mu tyw.
Baso底 eich bod yn gwir eich cet innid br crochets yn Mystiriau
ond byddwn yn hyn sy'n cael bod mysnerio ni.
Gynnwys mewn brawnol erau caelうr brawn tradyrwyddiad.
A hynnyny, bod y f vergessen yma ym ddu
a'r roektorau rydym siersonhau
m factorynd o gyflwynig hynny
yr ysrüyd i newid yr ysgrun wedi MININ
ac yn dasgwyd rydym yn ysgrun
ac roed gen i advancing mysnerio,
Rwy'n cael ei wneud bydd yn eich gwneud
of the deep learning system inside your head and how would that even work? I mean the complexity
and this gigantic co-operative parallel computation, the idea that you could somehow capture that
by saying actually that complex pattern of activity, that's the belief that things have
become too desperate to go on and there is the desire for oblivion or the desire to go on with
life or it's completely crazy really. Obviously you could say well as the levels of explanation
thing, maybe at some high level or some sort of pattern of neural activity could have this
high level interpretation. But when people actually build complicated learning models like
large language models, there's certainly no sign that you can read off in some direct way
how they're operating. And of course another nice thing about the world of large language models
which came a bit after the mind is flat. So I missed a trick there because there are a
wonderful illustration exactly of this kind of point. So you ask a large language model a
question, it will give you an answer. You can say well why did you say that? And it will give you
an answer to that too. But you'll be kidding yourself if you think that the large language model
is quickly having a quick look inside its own processing history and saying oh why did I say
let them be look inside. No it's just another improvisation. So the key concept I think which
comes up in the mind is flat and also of course in the language game which we'll be talking
about later is that humans are spectacular improvisers and we're so good at improvising.
We often have the sense that we must just be reading off the truth. So we're sort of novelist
thinking we're doing journalism. So we're sort of making up stories and thinking well I just came
to me that story. That must be how I really do feel. I must have been feeling that all along.
That sort of sense of revelation. I said suddenly you blurt something out and you think that's what
you've been feeling all this time isn't it? I think well not really I just made it up
and tomorrow I'll make the opposite thing happen. We are inchoate sort of mushes and our rationalisations
are attempt to try and put sense and organisation on to what is really a very mysterious underlying
system which our brains are far too complex for us to understand. Yes I mean I've spoken with many
people who try to come up with some kind of a clear difference between us and machines and a lot
of the language model people say oh you know you're just the same. We're the same. I spoke with
Max Bennett he's got a book about intelligence and he said that you know the brain is a simulation
machine and we do self-modelling because we have this agranular prefrontal cortex which you know
can actually model ourselves and then we can change the pointer and we can have a theory of
mind and model other people in this Daniel Dennett-esque sense but as you are sketching out in I
think it's around chapter six of the book there was this thing about well imagine there was a wire frame
cube and imagine what would happen if you kind of put a plane against three of the coordinates of
the cube and imagine what kind of shadow it would cast on the floor and when we do these kind
of experiments we realise just how incoherent and inconsistent our simulations of the world are
but the trick is that's what it is. It is a simulation. All we're doing is we're just running
these trajectories in the moment and when we articulate them and we actually just stand back
and just think what did I just say it just doesn't make any sense. No no no I think these
quick cases of imagery are really interesting because as you say if you take a sort of simple
piece of a simple geometric thing like a cube and you imagine well I must be able to imagine
how that works because after all I can imagine you know whole elephants and whole roomfuls of
people so surely try to imagine the shape and structure of a cube will be easy but actually
as you say if you try to do simple thought experiments you find you can't do them. In
fact Jeffrey Hinton obviously one of the key pioneers of deep learning and he did a very
earlier and very interesting paper on exactly this he has a paper I think 1979 in the Journal
of Cognitive Science I think that's roughly the right reference where he talks about
essentially the incredible shallowness and weakness of human inference with examples of
things like cubes being viewed from odd positions. So for example there's an angle you can look at
a cube from so it suddenly looks like a hexagonal pinwheel so it's a hexagon made up of little
triangles and in fact if you look at a hexagonal pinwheel you can find if you look at it enough
it suddenly looks like a cube it's like oh my goodness there's a 3d object I've suddenly seen
how that could be a cube so your brain is kind of able to spot that this is a possible interpretation
but I would you know invite everybody to try to imagine moving a wireframe cube around in your
mind and try and turn it into that pinwheel and you know I think you'll never do it. So the thing
is our stimulations of the world are very momentary and fragmentary and they are local so we've
got lots and lots of you know bits of experience of the world and we've got lots of ways of extrapolating
from it if you then say how do how do all those extrapolations tie together into one uber model
of everything the answer is well they don't they don't they they are ignorant. Yeah I mean this is
one of the themes and we'll get on to the language model the language game book it in in a minute
as well but the world is gnarly it's just more complicated than we could ever possibly understand
and in my opinion intelligence is about building models to explain as much of that cone around us
with as much consistency as possible but it's a bit like the no free lunch theorem you know you
need to have lots and lots of models because no one model is going to going to work in in all
different cases. You're coming at this I think from the direction of connectionism I think in the
mind is flat and you're of course citing Hinton and this is in contrast to let's say psychology
where we try to build these abstract consistent models of how the mind works and and the key is
is the word consistency I think there are many folks in AI and even mathematics who you know
dared to believe that the world was a consistent place and could be defined using mathematical
structures and I think one of the the kind of lessons of the last 50 years or so is that's
just not the case. Yeah I think that's right I mean you can only I only describe very local bits
of the world in a consistent way so it's a kind of tremendous miracle when any consistent piece
of mathematics turns out to describe some tiny sliver of reality so one that I'm very fond of
because I've been doing a bit of work with it recently is in an indirect kind of way is thermodynamics
so thermodynamics wonderful it's amazing that it's possible to to think about heat and work and
and there's a concept of entropy which is always increasing or at least not decreasing and and
yeah it's it's just astonishing that this this way of seeing the world turns out to predict a lot
of stuff very accurately um but it doesn't explain everything it just sees the world through a
particular prism and miraculously it turns out there's a very clean way of understanding what's
going on when you look through that prism um and that's generally the way I think science is so
we we try to find any squinting way you can look at the world so that patterns emerge and when they
do that's you know massive progress and it's very important but we mustn't forget that almost
everything is not like that I mean the the amount of things we things where we there is a consistent
tractable theory of universal application is is vanishingly small and the gnarly sort of in
fractally complicated nature of the world is is the default and of course in some sense it's bound
to be the case that we can't we can't we can't model the world in any decent way in our own
heads partly because obviously the world is much larger than we are so that would be very strange
and also other people are in it so um so obviously I can't be modeling you if you're modeling me
and we're off in some kind of horrible infinite regress straight away so it's always going you
know inevitably going to be a matter of extreme approximation and almost everything but what's
miraculous I suppose about human intelligence or intelligence in general is the ability to cope
pretty well with a world that's way too complex to really understand um so it's kind and we have
to be doing that by you know working up to a large extent by analogy from experiences and
things we've already already seen and learned about we can't be trying to drive all the way back to
a sort of axiomatic consistent framework because that's going to be only possibly a tiny number
of cases but even if it were possible we're never going to you're never going to get there
you know some sort of finite amounts of time you know each each child has to learn to understand
physical world each child is not going to infer Newtonian dynamics or thermodynamics from scratch
in the first two years of life yes I mean I suppose it's interesting that we were capable of
producing a model which is reasonably consistent let's say the Newtonian model but no I really
agree with what you're saying that I've spoken with many physicists recently who are trying to
conceive of life and intelligence using thermodynamic descriptions and there seems to be a hierarchy
of resolution so of course there's like dynamics and then there's behavior which is roughly where
machine learning people operate and then there's function which is where psychology operates and
there seems to be various trade-offs when you go to all of these different levels and of course
there are some folks who say oh no you know things like consciousness are outside of those three
that there's something a little bit extra but when you do go to the highest resolution and talk
about dynamics um it almost becomes a useless theory because when you look at dynamical systems
there's no such thing as causality physics equations don't have the notion of causality
you can reverse time and it wouldn't make any any difference and also it no longer
um brightly divides the phenomena that you're interested in so if you say well all life is
just dynamics then well what's the difference between living things and non-living things
can't tell you yes I mean it's true I think there's just a general point which you're absolutely
right to to highlight here which is that we're all attracted and I certainly am by abstract
frameworks but the danger with excess enthusiasm for abstract frameworks is you then abstract away
from the things that actually matter so as you say you suddenly and really abstract framework
for understanding life might it might very it may absolutely be something where you want to say
using simple physical principles which are that you know so there's no magic there's no
ilan vitale there's no sort of magical life force um under it with simple physical principles we
want to explain you know how cells work or how you know how bodies work that's sort of right um
but it's very unlikely you're going to do that without any um with the conclusion that well you
know life's pretty much like rocks it really really isn't like rocks and what you're going to have
to do is understand that what deep new principles have arisen um which allow yourself organisation
or whatever whatever it is which allow you know life to be possible and say I suspect the same
is true with you know complicated thoughts and consciousness obviously is a completely mysterious
thing um but it would be yes it'd be wrong to think that just by abstracting away one's kind
of solved the problem one's got to then with him with that one down to track framework have a sense
of oh right so um you know life what's special about life is this or what's special about conscious
things that we're conscious of is this thing over here and and of course as you do that you might
then blur the distinction you have started with you might say oh consciousness isn't quite what
we thought or some things are alive that we thought weren't alive or you know we might start to
wonder about you know our viruses are alive and all that kind of thing those but those boundary
cases start to get re renegotiated um but but yes the idea that you can just abstract abstract enough
and all the problems go away so it's terribly appealing I've thought I've fallen to that trap
all the time but I try to extract myself yes indeed indeed I mean it's quite interesting
in parallel I mean I interviewed David Chalmers and he's got a book called Reality Plus and he's
talking about virtual worlds and whether they can be real we've you know seen as real and
whether they could be seen as having um moral value and to me it often comes back to the agency
question which is that I see technology as being a kind of extension of our existing ontology but
you know the there is a bright line I think that is crossed when the machines become the the agency
producing nexus rather than just being part of our nexus because you can talk about transhumanism
and plugging ourselves into machines or even as um Andy Clark does the the extended mind and you
know just thinking of of there being this this nexus of cognition but um yeah it's um it's really
interesting I mean on that moral question actually aliens could come and land on the planet and they
could be deciding whether or not to blow us up and they've just read your book the mind is flat
and they were um you know struck by the fact that we can only pay attention to one colour at a time
one word at a time that we're not really looking at them you know because we're just deluded by our
confabulatory predictive models and you know we're very very similar to mini chat gpt's and they
might just reasonably think well let's just blow them up yes I think I'd be very harsh of them to do
that but but I think um I mean they certainly would I mean an alien sort of super intelligent alien
looking from space at our intuitive understanding of ourselves would say these people have got it
completely wrong I mean I think one of the things that's quite interesting about psychology as a
discipline is that when you start doing it um there's a there's a part it depends on which
bit you're studying so bits of it you think oh this is kind of common sense I mean maybe common sense
with evidence so you know common sense is you know especially like everything else very inconsistent
and some bits stand up better than others to analysis and there are you there are nice elegant
experiments and theories which allow you to um guide your common sense but a lot of it sounds
like common sense common sense plus um but on the other hand um when you start to look at the the
machinery it takes a of the brain and look at the things we do without having a sense that they're
psychological at all so things like seeing the world or understanding language or I mean moving
our bodies around I mean intuitively most of us don't of course in the in the world of machine
learning and AI and so on we don't see it this way but intuitively as everyday people we don't
think of these as psychological at all we think well these are these are just these sort of happen
I mean just my arms move about and my eyes just see um so we don't but of course most of our most
of our mental activity at the most of the brain activity is actually dealing with all of this
stuff and when you think about that way that works you realise oh hang on almost everything
psychological is is almost all my ideas about my own psychology were completely wrong so rather
than um psychology playing back um your intuition's at you and say yeah you're basically right but
here are a few adjustments I think in even you look more deeply um it's the psychology our sense
of our own psychology is almost 100% wrong so as you say I mean we I look around the world I think
everything's in full detail and colour um if you say to me oh but hang on your phobia is only very
very narrow you've only got good vision in about one year one degree of angle and that's where most
of your colour vision is I think yeah I kind of know that but but on the other hand the world's
full of colour and full of and full of precise definition and that's an illusion um and and
my sense that I have you know a deep understanding of my own motivations I'm not sure I do have that
really but if I if many people do that's an illusion too um you look at a page of text as you
were suggesting um I think I see all those words actually if you black them all out and put
make no x's except the word I'm looking at pretty with a few letters either side I won't notice
anything different um all these you know basically the world of sort of psychophysical
psychological demonstrations is just absolutely stacked full of things that make you think oh
my goodness my mind works totally differently from what I thought um so so I think the thing
is that we've got this sort of rationalising perspective on how how our minds work um and
that's what some bits of the psychology textbook are telling you they're saying oh yeah well you
want to if you want to do that rationalising we'll help you rationalise better but the other
part of the book is saying actually all the rationalising it's rationalising it's not really
how you work don't fool yourself yes yes and even in the language game when you spoke about
philosophers who really study concepts deeply um these are concepts that have still arbitrarily
emerged from the language game yes but you know there there is this interesting kind of tendency
to to think of objective reality as we experience it as being the real thing yeah and um I mean you
don't you know you were just talking about the the the phobia so we only see colour you know just in
our in our foveal cone and we hallucinate the colour everywhere else and then the temptation
is to kind of think well you know um I guess we're talking about phenomenology and you could
read your book and you could say okay so there is maybe only a tenuous relationship between
our percepts and our phenomenal experience of the world um but a lot of philosophers really
don't like that idea I mean what why is that yeah um I mean I I think there's a there's a strand
in philosophy uh and this may not go to the heart of the problem but for me it's my best shot
there's a strand in philosophy which is starts from the point of view that that common sense
can't be far wrong so you essentially say look the common sense view of the world is the thing
we're trying to explicate we're trying to clarify it and so for example if you talk about
beliefs um you want to understand well what is a belief then they must be such things we talk
about them so let's try and establish you know what they are and how we know we've got one
similarly with desires similarly when you talk about perceiving a colour I think well there must be
there must be a blue to be perceiving that's what I that's the way we talk so we're trying to
to make sense of the way we talk um and assuming that that is a kind of ground truth and and that
from that perspective annoying um sort of physicists and physiologists and psychologists
coming along and saying what do you know if you look at how colour vision works and how colour
actually works it's all rather complicated and very different from what you imagine that's that
sort of common sense ground is sort of approached philosophy wants to say well that's all very well
but it doesn't really doesn't really change anything um so yeah I think there's a there's a
kind of um a desire to hold on to the intuitive position even though I think that's not worth
defensible yeah I uh I spoke with Dennett about you know he's got some wonderful ideas about
colour perception and this is a great one of those things about you know whether colour is a
an ontological thing that you know whether whether it exists in the physical world or whether it's
only like a mentalistic property and this kind of you know um intentional you know I guess if
we call that the physical stance wouldn't it but what what's your take on that yeah so I think
I would be sceptical of thinking of of colours as part of the fabric of the universe um essentially
for the same reason I'd be sceptical about almost any commonsensical notion um I mean the whole
history of science is a history of commonsense ideas that either break up um completely or get
modified to a point of looking here almost unrecognisable so we have a sort of intuitive notions
of temperature say um and you might think well our temperature is part of reality well I mean
people have gone about forever saying they're hot and they're cold but then if you think about the
trying to understand the difference between you know the hot the coldness of ice versus the coldness
of I know equally cold metal or various other you know equally cold air um you know some things
feel a lot colder than others so we'd be saying to ourselves well I do understand the concept of
hot and cold hot and cold is definitely part of reality and I can tell you this cold metal thing
is a jolly lot colder than the cold air say or cold water but you'd be totally wrong um at least
if you try to understand temperature from a modern physics point of view um so as soon as you start
to break up um the intuitive way of seeing the world and make it rigorous then your concepts
like temperature just blow up because you haven't really properly distinguished your heat flows and
you know temperature as thermodynamics would talk about it and so on they're just not you know
they're not they're not they're just different parts of the physical realm which get bundled together
which when that and that bundling is going to be discerning our you know our sensory um our
sensory perception of temperature so you know whether I feel hot or cold is going to be
disturbed by all kinds of funny things you think about the wind chill factor in which weather
forecasts are so keen on um how cold it feels but of course once upon a time there was just the
feeling of cold and hot um now we realise there's an enormous plethora of factors determining
how hot or cold we feel only one of which is this actual temperature thing and so saying well I
have this sense of a category that is sort of available to me perceptually or from a sensory
point of view that must map onto the world absolutely not and I mean colours are another
extreme example of that really the forces that drive colour perception are you know really
complicated and very contextual and so yeah I mean I think um I would be um I'd be with
Dennis on this one I think yeah um colours are a great example I mean and temperature as well
because I guess they're they're actually very vague complex concepts but um I've got a good friend
Walid Sabah and he's a rationalist just like Chomsky and a go-fi guy so you know say someone who's
trying to use these um you know psychology rationalisations to build AI from first principles
and in a way the the world of go-fi has shrunk because I think over time people are starting
to sign on to the fact that it's very gnarly and it's very complex but but Walid is one of the
last hangars on and he's making a similar argument to what you do in the language game which is
that there's a kind of information hierarchy so you speak about in learning and see learning so
you know like nature and culture and culture of course is very complex and fractionated
and arbitrary and um I guess he might be speaking even one level above in learning which is like
the platonic realm so he says there are certain templates cognitive templates that would exist
if the universe didn't exist so transitivity is a great example or the located in or contains
templates so you know um I put a thing in the bucket I put the bucket over there the the bucket
is now located over there so you know he's quite reasonable it mean Gary Marcus makes the same
argument he calls it reasoning quite reasonably arguing that this does not exist in current
AI systems and possibly should be but it does seem to be quite a small set of models that um
because rationalism of course is reasoning in the domain of certainty yes yes well I think this
point about certainty is really crucial so um there aren't many aspects of the world where we can
really reason with certainty because of this sort of um unkempt and gnarly nature that the world has
so in reality sort of axiomastic approaches are only helpful in very small numbers of cases
and we have retrospectively managed to axiomatise a few things so it is possible source of to
axiomatise thermodynamics um and that that happened quite recently um so you have you working away
with people are working away with thermodynamics forever even formally and mathematically and
I still haven't got the axiomatisation straight and that comes later and probability theory of
course was only axiomatised at the beginning of the 20th century and you know in general you know
even the things which were that certainty is possible like mathematics even there the
axiomatisation usually comes sort of late um think about calculus I mean just trying to understand
you know Newton and Leibniz were sort of setting off doing differentiation and integration but
they hadn't really got any axiomatic foundation for that and it took ages and took 19th century
real analysis to figure out how on earth how do you make sense for this this stuff um so I
think always the axiomatisation for me always comes last um and anyway um yeah almost everything
we're thinking about is never going to be axiomatisable so um now I don't I don't deny and I think
it's a very interesting thought that there may be certain abstract patterns of thinking things
about like basic patterns of logical influence thoughts about the geometry and so on um which
may be things that you know it's not impossible that those things are important and maybe maybe
they're even built into us that's not not not not a crazy idea at all um but I do think yes
that's that's going to be a small aspect of you know the total chaotic complexity of the world
I understand the world around us yeah so and final question on that I mean you know there's
there's this strand of mathematical realism um or there are folks who think that it's
basically something we've invented I mean where do you place yourself on? Ah yes I mean that's
that is very difficult because um I want to take a line I'm not quite sure what the philosophical
sort of right label philosophical label is for this but I want to take a line in which
one thinks of mathematics is a bit like one thinks about chess so you know we could have
had different rules for chess uh any number of different rules I mean and it would play
differently but given the rules we've got you're kind of you know these these is you know mating
for is kind of mating for or it isn't um so you don't have limitless choice it's once you've sort
of pinned pinned down the the the details you've you know that you've got a formal system then
what that formal system does is kind of pinned down so it's but it's not the case it won't so for
example if we take um numbers um one could say well you know what's the what's the right
actualisation for numbers and the answer would be well there's no answer to that because um
once upon a time people didn't even know about negative numbers or um fractions or um or um
the difference between real and um we remember the idea of irrational numbers and the whole number
that says the real line and all of this stuff so continually as we as people study uh mathematics
more new things start to appear in complex numbers after all and on it on it goes and so you know
sort of thinking to oneself um oh well this kind of pre-existed before we came to it is a bit
misleading but on the other hand it's not the case that we have sort of free power of creation at
every step and once we've sort of set the rules of chess once we've set the rules of
your piano arithmetic or something well then you're locked in but you could change the rules
you could do something different if you wanted yeah and then I asked the same question to Thomas
Pard um on Wednesday because um a lot of people argue that you know the free energy principle
for example is is ontological you know that it basically is a statement about how how the world
works or even with the you know the Bayesian brain hypothesis you could ask the question well
is the brain actually doing a Bayesian update and the response is usually I don't know what you mean
by is it real and does it matter because frankly it kind of doesn't I think that yeah I think
I mean I'd take a slightly different view of that I suppose because I think it's certainly if
it's a good approximation I mean the kind of classic um I think it was the statistician box
with this famous phrase but we all talk all here all the time that you know some models are
all models are wrong but some are useful and I think that's that's basically deeply right
with the possible exception there's an extreme extremely basic physics everything else is clearly
approximation and essentially wrong out of out of some tiny little domain and so I think saying
is it useful the question really is is it theoretically useful to think of the brain
from a Bayesian point of view having said that there is still the question if you looked inside
the system can you see something that looks like Bayesian calculation or not and I think
you know people would differ about that um the overall uh sort of the input output behaviour
that's one thing can you reconstruct that from a Bayesian point of view I think often the answer
will be more or less yes roughly at least a qualitative level even if you can't actually
see the the update calculations going on but on the other hand if it turned out that you know some
kind of um you know so Bayesian propagation was going on in the mind I don't believe it is but I'd
be delighted I think it's absolutely marvellous discovery however I think it's very unlikely because
that requires that one has a model of the world which one can update in a consistent way
and that's the whole thing I think is wrong I think we don't we only have models of teeny slivers
of the world so within your tiny sliver maybe there's something you know Bayesian going on
I'm glad we explored that actually because I was trying to wrestle with the apparent contradiction
of obviously like I'm making the connectionist argument but also talking about perception as
as inference yes because you actually stopped short then of saying it's a kind of Bayesian
inference but but you do think it's some kind of well you know the interesting thing is that
it's the same argument before whether or not it's doing Bayesian inference it's as if it is yes
that's right yes and I'm I am conflicted on this I mean I am a very great believer in the
utility of the Bayesian approach and indeed Tom Griffiths and Josh Tenderbub and I have a
book with many co-authors coming out only in a year or two on the Bayesian reverse engineering
to mind which is going to be a big sort of synopsis of Bayesian approaches to cognition
and that's coming out in a year well we're doing a copy editing at the moment so maybe it's a
yeah something like a year or 18 months can you send me an advanced copy yeah yeah yeah yeah yeah
I'm a huge fan of Josh anyway his work at at MIT is brilliant okay so I think he's doing some
of the most exciting frontier work in AI at the moment yeah I'm thinking back to not only dream
coded but I mean in the sort of Bayesian world he's incredible yeah no no Josh is absolutely
fantastic and Tom Griffiths is an amazing guy so there it's a great and this is with many many
other co-authors on individual chapters but it's going to be yeah I think it's going to be really
really nice really nice book but as I say I'm conflicted on these issues because on one hand
I'm very very taken with the the Bayesian approach to understanding specific bits of the cognitive
system but I sure will you extrapolate that up to thinking oh well really the brain is just doing
a sort of Bayesian model of reality and all the people in it I think that's that's hopeless
the best way very locally Bayesian and very approximately yeah it's I'm torn as well it's
such a wonderful way to to think about it even then things like model selection you know because
a lot of intelligence or even abduction is about selecting models or intelligence about
creating models and doing so efficiently is is how we understand the world it's how we communicate
we this improvisation process on the language game is the mutual creation of models and sharing
model yeah yeah yeah and from a Bayesian perspective I guess that is quite a nice framework to understand
yes I think that's right yeah but it's as you say it's um it's it's difficult to to think of
that as the sort of total model because of the the fact that's hopelessly computationally intractable
and anyway we don't we clearly have a very partial understanding of the little bits of the
world we encounter whereas the world's complexity as it vastly exceeds our compass so it can't be
the case that this is the the right way to to think about cognition at an aggregate level but
little pieces of the system I think look quite Bayesian yes yes I think it's um it's unlikely
that we are solving that intractable I mean it seems mathematically or just you know statistically
impossible but perhaps um there is some um you know smaller version of the problem that we are
solving which could be thought of in in analogous terms yeah nothing that's right yeah yeah in a
way um you seem like strange bedfellas because um he's really close with um you know intellectually
some of the active inference people because he talks a lot about like core knowledge for example
and it's this like Elizabeth spellkey type um you know core knowledge and presumably that is
not what you know I mean that's not I'm deeply hostile to but I know that's not my not my starting
point at all no no I think that's right we are um we have lots of things in common but um
yeah I think and I think I think of the mind as flatter than he does I think for example he's
very keen and I must say it's very charming and interesting I'd set off ideas the kind of idea
of the vision as an inverse graphics engine yeah um that's yeah that's fine if you but then we'll
inverse graphics engines you know have a lot of physics built into them so you have to assume
a kind quite idealised model of the physical world um anyway yeah I mean we are yeah we're we're
very agreed on some things and very distant on others we do we do do all the stuff together we
have a you know we have you know we have um one or two papers over the years we've got one coming
out at the moment so it's though we're coming from different places we're um yeah there are some
connections because in a way Bayesianism in general is about solving lots of inverse problems yeah and
I guess that that's an a cognitive interface for us to reason about problems but you're almost
kind of like um you know you're you're just moving the complexity somewhere else yeah because at
some point you still need to actually like you know solve this problem yeah yeah these I already
said this to you last time Nick but um I was reading this book when I was jetting or cruising
around the Norwegian fjords and it was a serene setting I had you know mountains all around me I
was in the spa on the boat and um I was reading your book and taking notes on every single page
and I even had some stickers as well so when it was particularly interesting I put a gold star on
there um but no the the reason why I love this book so much is it's one of the you know like every
few years or so you read a book that really changes how you think about things and this is definitely
one of those books um especially because after speaking with Chomsky um I was kind of stuck
between two worlds and I always had leanings towards this direction of thought but I think
your your book really really pushed me um you know completely into that um school of thought
so maybe we should just kind of start off um talking about um you spoke about was it Captain
Cook and yes yes yes um talking about you know how they they use the game of charades to um you
know get some mutual understanding yes yes yes so so one of and this is apparently quite a common
phenomenon in um the days of uh of Cook's voyages that the voyages would just trundle along the
coastline in some remote spot and they'd put in and on the assumption that some some some native
people would appear and they'd be a bit of trade and interaction um and they like this would be
mutually beneficial um but of course they'd be doing this with no common language so Cook does
this on a particular occasion and they talk about how um the uh the the the the people that are on
the beach uh what wait on one side then Cook Cook and team waiting on the other side um I think
the what the two of the the the the the the people I think this is Tiret Ciaro del Fuego so
that people have probably the house community in Tiret Ciaro del Fuego and are now pretty much
extinct I think sadly due to brutal um you know brutal effects of colonialism um so a couple of
people come come out um with with weapons and they throw down the weapons and Cook's team think
okay so they're obviously saying you know we don't want to fight you we're we're throwing aside
our weapons um and this is they've never they have no common language never interacted before
this is completely de novo contact um but that turns out to be dead right so they they do a bit
more of this kind of of dance and before you know it there the uh the native people are on ship
they're eating and drinking and hating most of what they eat I think um but then exchanging
exchanging goods for mutual benefit so the ability to to forge a communicative relationship
where you can actually do practical useful things and avoid disaster such as as conflict which does
that does happen and indeed Cook himself was in fact killed in a uh a later incident I think in in
uh in somewhere in Hawaiian islands um but the the stakes are really high but it's possible
for people to actually invent communicative signals which are mutually interpretable and I
think this is incredibly interesting because I mean you don't see any any side of this in any other
species I mean this is an amazing thing that that the human beings can figure out if I go through
this set of actions this sort of charade like acting pretends someone else will look at that and think
now you're trying to communicate with me here and the message you're trying to convey is this
in fact we have to have the same understanding you're you're sending a signal out into the world
and saying what do we think what do we think this means I have the sticks I throw the sticks
down what's a lot about and I have to think as if I'm doing that that action I have to think
well I think it means this and I have to think you're you're going to think the same things we've
got to converge on the same mutual understanding even though we have no um you know no no very
little common cultural background and no language and this is something that we you know it's an
amazing feat and I think it's something that's uniquely human but I think that's the uniquely
human that that pragmatic communicative drive endability that's the thing that really makes
humans distinctive perhaps unique but I mean whether it's a precise whether it's a categorical
distinction or a gradation it makes us very special and that's the thing that's going to drive the
ability to create communicative systems so the point of the language game is saying start with
that kind of example or think about playing charades as a parlor game where you're not allowed to
speak you just do funny actions to indicate godzilla or kinkong whatever you're trying to do
then you realise that you create these momentary signals which mean something
also you can reuse them so once you've done for example the stick throwing aside you can you
can do that again to mean something you know something similar or if I've done a chest beating
for kinkong I might think well now I want to do a chimpanzee but I'll try chest beating that
seemed to work pretty well before and I'm going to somehow you know do a gesture for smallness to
say oh it's not kinkong anymore it's now it's a chimpanzee or whatever but we'll create these
simple actions which will start to have more and more specific meanings and we can chain them
together like you know kinkong but smaller oh but smaller could be a kind of you know changing the
you might go going from a well part partied hands to you know to to to partied fingers say
and that might then become a generic way of making things smaller whatever they happen to be
so you can quickly quickly generate something which is a little bit language-like in the sense
it has a set of standardized conventions and they become sequenced and so on and and those
conventions will become quicker and quicker and more crude so you don't go to the whole sort of full
kinkong sort of pantomide you just do a few clues and you think oh yeah I know what that is
so the signal becomes stylized it becomes sequenced and so on and so on and the thought is
that this is this is really what's underlying the foundations of human communicative systems
so we know through the amazing observation in Nicaragua and orphanages for deaf children
in the 70s and 80s that you can get the spontaneous creation among groups of people
children who have no other means of communication they start to spontaneously create
sign language or sign systems which turn pretty quickly into full blown sign languages as complicated
as any prior sign language or nearly or any other human language at all I mean these are
these are just as complex as languages and they're created in a few generations of kids over a
you know decade or two through spontaneous interaction so that's I mean if you're for
some people someone with a more nativist perspective that the measures of that story is
ah language is pretty much built in it just needs to be triggered look it's just emerging
spontaneously um for my friend and collaborator Morton Christianson and I we'd say no that's
not completely the wrong story the right story is um we're amazingly good at creating communicative
conventions in the moment we're good at reusing them and give us a bit of a chance and we'll
create you a system these things these systems sort of sort of spontaneously arise um through
reuse and and repurposing um and of course anything from that point of view um it changes
everything really so the first thing it changes is one's answer to the question oh why are languages
so well adapted to us um you know why is it that we find them so easy to learn in the sense that
you know every child exposed to any language can learn it quite quickly and then the answer
is going to be oh yeah of course because we we just we created them didn't we they're the things
that are natural ways of for us to communicate because that we we created them over a you know
over a period of incremental shavar playing so the things that seem natural to us and the
categories that seem natural to us and the ways of you know doing syntax that seem natural to us
those those are the ones that languages embody because the languages have evolved to be culturally
over through cultural evolution to be natural um and if you ask yourself why is it that languages
have um uh similar structures to each other which is a fairly arguable question actually
because they're they're much more diverse than i mean i'm no expert but the people who look at the
full panoply of the six or seven thousand human languages on the planet would say my goodness
they are pretty diverse but it to the extent that there are commonalities then the answer would be
well that's going to be in the same way that shavar playing is going to have commonalities
there's going to be you know at the beginning there might be bits of iconicity you're trying to
do king kong you do a king kong like action yeah that that's like phase away kind of
rather marginal pretty quickly in most languages um and that you're going to have
compositionality you're going to have to create complex messages from simple components well
that's that's something that's going to be sort of wired into the basic system we're probably
going to have to have a small number of meaningful units um we can't have a an inventory of meaningful
units which is only as tiny as five or six because there's more things in the world we want to talk
about but if we make too big we can't learn them all and blah blah blah so there's going to be
same communicative pressures the same challenges that we're facing when creating
these these cultural forms so they're going to have some common properties so that you don't have
to explain those common properties by by focusing on the um the properties of the brain you're more
thinking of course brain to do have properties that are relevant but the languages basically the
the languages are adapting to us rather than there being a a surprising degree to which the
the brain is kind of built to do language yes yeah i mean i guess we'll get on to the
the kind of the memetic properties of language in a bit but but also um as well as having the
same brain we we we share the same physical environment we have the same physical in in
bodiness um you know which would presumably create certain guardrails in how this language
game could be played but just to go back a tiny bit so the interesting thing about humans is that
because of our evolutionary history we don't necessarily need to have language so you you
can raise um humans without language but they will be very very different to humans with language
and you were talking about you know so we do this incredible mental gymnastics we play the
language game you know with ingenuity and and inventivity and and and we create language and
and then there's a kind of maturity curve so it starts off as pigeon and then it becomes creole
and then over time we see this conventionalisation and and and we see that you know sort of concepts
becoming formed and further embedded and shared especially if they have value so i mean could
you could you talk to that evolution a little bit yes um so just to say a little bit about the
pigeon creole story so when groups of people have contact where they have no common language
this would be like the the howshand and cook um when that happens for an extended period of time
pretty quickly some convention system of conventions emerges so although it's true that people can
live without language and there are these horrendous cases where children are raised with in very bizarre
circumstances where their caregivers inverted commas are not actually speaking to them at all
and they don't don't learn language because they're not exposed to one and that has pretty
pretty cataclysmic social and cognitive consequences um but it's that's incredibly unusual
and you put two people together they start communicating as best they can and um so when
you have people with with with different languages they will start to create a system
which has very very simple syntax which at least will allow them to talk about specific objects
that they need to move around or trade or whatever um but as as the children of people who speak
who've learned this pigeon um which is the name for this this kind of very simplified language for
working across the divide the children of those people will take that pigeon and elaborate it
and turn it into something which is essentially its own language so there there will be a you know
there will be structures and patterns in that language which didn't exist and the the pigeons
pigeons speakers won't really understand and you know before you know it you've said you've
got a full blown language and your creoles are full blown languages so you end up with something
which is a little mixture of of the two two base languages or maybe sometimes more than more than
two so the tendency to create rich systems is is very basic to us you give people a chance
to communicate they're driven not by the desire to create a language no one's ever bothered no one's
interested in doing this unless you're you know unless you're sort of inventing Esperanto or
you're you know Tolkien trying to create an elvish language or something I mean most of the time
people aren't interested in creating languages they just want to communicate but they want to get
their message across to another person they've got to do it somehow and they'll try and use
some signals using based on signals that we've already got to hand and the person will respond
in kind and that process of incremental struggle to just to get our messages across and get these
little works successfully together that will drive us to create you know create a system
to a piece by piece so it's so it's a very interesting phenomenon that this is it goes back
to Adam Ferguson the Scottish Enlightenment philosopher of the 18th century has this wonderful
phrase that that many aspects of society are created by human action not a human design
and I think that the deep insight in that is that most of the time when we're creating almost
any aspect of culture it's not that we're blindly just randomly sort of thrashing we're trying to
solve a particular we're acting you know in a purposeful way trying to solve a particular problem
trying to make some communication trying to build a house that stands up or trying to solve some
problem but by trying to do solve the problem in front of us we're incrementally creating new
tools and new methods that can be used in you know unexpected ways so we're contributing rather
like a termite contributing to the the creation of its its mound we're contributing to this this
this collective construction of which we no particular interest we're not we don't care about
that we just want to solve the problem in front of us but but nonetheless we are creating this
this collective um collectively we're creating something that should be complicated and human
language is a you know they are one of our most perhaps our most astonishing achievement as a
species really yeah and I'm fascinated by this idea of collective intelligence um so the extreme
view is that we are just like ants that we discussed this last time um but that can't be true
because we are capable of solving problems and planning and and doing some form of sophisticated
cognition so so then there's this notion of okay so I I learn how to use a tool and then I share
that simulation with others and it becomes memetically embedded in in our culture and then
the interesting thing though is it becomes a form of collective intelligence because other people
in the in the environment they might learn to use the tool differently or they might improve on
it and then that will be propagated back to me and the fascinating kind of progression from my
point of view is is when almost the locus of intelligence becomes more um kind of focused on
the um the meme sphere than than the individual agents like when does that transition happen
yeah um I think I think it does happen quite early actually in in human development so
I mean if every if we all had to solve all our sort of cultural and technological problems
from scratch we'd we'd be struggling yeah so I know Michael Tomasello is always keen on pointing
out the the developmental psychologist and primatologist he's always keen on pointing out
the the thing about humans is that um we're always improving on past solutions by other people
and if we weren't um and often blindly I mean we we can't be thinking I want to validate and
fully understand why this is the right solution think through all the alternatives you know take
nothing for granted that would be a mad approach um because we'd all be trying to understand words
you know from from scratch and human progress would be impossible um whereas in practice
we largely take everything around us on faith we think oh well this is seems to be how we
hunt and this is how we make a boat and um I guess I'll I'll go with that and you might make
a incremental change or improvement but largely you're taking the the the way of life of the people
around you and the way the way it works including your systems of communication including language
you're taking them for granted and working with them and and and and creating um small variations
and perhaps improvements um and but but because you're doing that um it's not really right to think
that the the location of uh sort of cultural and intellectual progress is in any particular
head and we have this sort of great person theory of of uh of progress as we do when thinking about
history generally so we tend to think well these particular individuals have brilliant insights
and of course there are undoubtedly particular individuals with brilliant insights no doubt
that's true but really um and if you took Einstein out of the 19th century uh physics background
where are you going to be nowhere right you've got no chance of making spectacular um breakthroughs
in 1905 if he's got hasn't got this enormous intellectual milieu of people probably less
smart than Einstein most most of us are a bit wildly but um but you know these people have created
this enormous infrastructure of mathematics and and experimentation and physical understanding
in which and indeed philosophy in which it's language and all of this stuff
so Einstein can make an incremental contributions it's a it's a small step of course it turns
out to be a spectacularly productive step um but the productive it's it's it's productive um
because there are all these other people around and all the other infrastructure around so that
but the further incremental changes can be built on top of the of that individual so I think
you know in a way we should we really should be thinking of human progress
much more than we do and I don't quite know how to think about this correctly but we should be
thinking of human progress um and of course it's not always forwards um as as a kind of collective
computation so we should think about the computational system as not it's not the only
competition the the brain isn't the only computational system in town probably the more
interesting one is the you know the collective computations that we're doing think about thinking
about this to say as a scientific or a mathematical community or inventing new technologies or
creation of artistic forms these are things that are really a collective computation and we
don't really have a good ways to understand that but we do know that um you know parallel
computation with large numbers of agents is you often a very powerful thing um and I think
you know that we should be trying to understand ourselves as small components in a big parallel
computation a lot of the time yeah I've been reading a book about creativity and it's um
it's something that wasn't even a concept that we spoke about or could conceive of
again and we used to speak about that in the language game that many concepts even things like
money for example are just cultural inventions but um yeah and we started studying it I think
only in the 20th century and through the ages it was thought of first of all is um you know like
when when we had the Greek gods it was not seen as possible for anyone to be creative and if it was
it was something expressed through through god and um and then we've gone into the sort of renaissance
period and and then we did have you know folks like Leonardo da Vinci and and they they were
deified as being very creative and in more recent centuries we're moving towards this kind of
wee concept of of creativity that we see it as a social thing and you were just describing like
Einstein and there's this information graph and you know perhaps a creative act is some um you
know big gradient on that graph where we introduce something of novelty and value and then
there's a social proof component as well which is to say that it needs to be recognised by other
people but creativity is one of these concepts just like we were talking about earlier with
things like intelligence that you can describe it in many many ways and you never seem to capture
the whole phenomenon yeah yeah I think that's right it probably isn't a well-defined thing really
oh another example I really like is the will which I think in the sort of
early philosophy of mine going back I suppose to the 18th century was usually important everyone
was going on about the will and everything's driven by the will and tried to understand the
will was really crucial and we've all sort of forgotten about it now and we feel occasionally
talked about will power and so on but we just don't go about thinking what really explained
the will and similarly it's very interesting and I hadn't wasn't really aware of it the idea that
creativity is seems in retrospect quite natural to think well why would we yes why why would we
think of that as a as a as a category rather than just people doing things well or badly just
doing paintings doing bits of you know anatomy why did we suddenly say oh hang on this is this
is a creative activity we're in here and this is a particularly large creative moment that's
you know so it's very it's a very particular way of thinking and speaking we shouldn't um yes we
shouldn't shouldn't take that as take that for granted that's a a game we've yes a game we've
just invented yeah because it's quite quite a western thing as well to think in this way
and I suppose the irony is that your book is telling the story of everyday moments are
extremely creative and in fact um there is a drive to um to to do this language game even
gratuitously so you know I'm traveling with my girlfriend and we are just creating words for
things you know like it's not a glacier it's an enrique and glaciers and then it's an enrique and
it's just a private language and there there's it's rapport building there's there seems to be a
very natural drive to do that yeah no absolutely no we I think to the extent that one should think
about creative as a useful concept at all we should absolutely be thinking of ourselves as in
daily life unbelievably creative yes it's completely wrong I think to be to be thinking
that there are some creative people and other creative people or the creative people have been
creative when they're doing their special creative thing we're all being amazingly creative all the
time and just understanding things like these simple charades I'm doing charades is an astonishing
astonishing feat from a sort of computational point of view I mean there's so many possible
actions you could carry out and you have to think well what knowledge do I have what does the
knowledge that the other person have which means that if I do these actions they're going to draw
this influence it's like really a really hard thing to do and yet we do it you know it can be
absolutely you know with no effort at all without thinking anything about it and you know some
people are better at these things these particular things and others but it's either it's creativity
through and through or picturing is another one either people can think oh I can't really draw
I'm absolutely hopeless but they will still manage to convey a movie title or a book or
something through some sort of bizarre drawing and that is an astonishingly creative thing to do
in fact in some ways the more hopeless you're drawing the more creative it is because you're
forced to rather try to produce a convincing likeness of Mel Gibson or something you have to do
something much more indirect but we can do that and it's an incredible yeah it's an incredible
feat but the other thing about this process that's worth stressing is it's incredibly ad hoc and momentary
so the thing about this viewing language as a sort of charade-like process is that we only have to
solve the problem for the moment we're in so with your your your fun names for glaciers
there only has to work in the context of you and your girlfriend and this particular place
and if you were to come across some other icy formation perhaps in Antarctica to think
is this a glacier or not I'm not really sure it's a lot of ice but is there a mountain behind it
and what exactly is the definition it doesn't matter it doesn't matter at the point you're
having the interaction you have a clear sense a clear enough sense that that's one of those
glacier things and that's another one and we might ask all kinds of abstract questions about
what cat you know what would be one of these you know could you have such a thing on Mars for
example or would it be a glacier if it was made of something other than water it's just irrelevant
now it's because it becomes relevant if you start to think of this as a scientific project of
universal application but the thing about communication is it never is it's about getting
our message across right now saying look at that fun thing oh it's moving or oh it's retreating or
you know you're just trying to convey a specific um specific message in a particular moment
and the ability to talk generally about the world is is that's the thing that comes last
so the language is specific specific first and general later and I think that's a just a
gigantically it's a little in some ways very obvious but it's possible to make a gigantic
mistake by thinking no the right starting point for thinking about language is to think of it
as sort of like a formal logical language which makes universal statements about reality
because then as soon as you mention glaciers you think oh well what is the set of all glaciers
in the universe and that must there must be well to find otherwise what are we talking about
then you're immediately into you know sort of rabbit holes of which you need in practice be
even contemplating you're you're solving a problem right in front of you yes and so this bottom up
approach is quite interesting so you're talking about the moving from the specific to the general
and I think that is how a lot of our cognition works even though like a lot of you know psychologists
might argue otherwise and you give this beautiful example you call it the lightness of meaning yes
and because this is one thing I wanted to get to which is that when we play the language game
we're physically situated in the same space this is very high resolution I can point to
any objects like you know we can do multimodal gestures sounds and so on and of course we do
all the time with that again in this very creative way without thinking anything about it we gesture
a nod and you know do you see shrugs and all these things without without batting an eyelid
exactly so so the language game starts off high resolution and then there's this kind of cone
where things become overloaded compressed conventionalised there's you know euphemisation
of language is another one and part of that is because of the carrying capacity you know so it's
quite it's quite efficient for words to be transmitted because we can't really you know
transmit a pointer to a flower anymore and so how does how does that process work and maybe
speak to the overloading of lightness I think is a great example yes yes so I think the so
I think the starting point we often have when we think about words is that we think well every
word must have a meaning and okay they're ambiguous words but let's put them to one side
if they're just they're just like other words but they just happen to have several several meanings
until it's frowning onto the same word so it's a bit like still thinking that there are river banks
and financial banks yes but basically one word one meaning but when we think about a bit more
and this has kind of been very much explored in the later part of the 20th century especially
since Wittgenstein's analysis of language games so Wittgenstein obviously used the seven language
game in a slightly different way to us but you know he's clearly a a major inspiration for what
we've been thinking about as he has been of course for many many people thinking about language for
past 60 or 70 years so Wittgenstein would have said well hey look look closely at the the way
words are used and you'll notice that there are all kinds of usages which are not actually
particularly distinct but they're not quite the same either so if you take something like
so he used the term family resemblance for them so that the different usages can
resemble each other in a variety of ways and there's maybe no common feature
so if you take something like light you can talk about light objects so you think oh that's
pretty much what light means it's about weight but then you can talk about light cavalry
and you think oh well I suppose that sort of cavalry with a lot very heavy stuff on
light music ah now we're getting into trouble so what what is this it's um or indeed heavy music
is a bit strange but it's entirely you know entirely entirely comprehensible and we can have we can
think about um uh light opera or a light um light cruiser or a light almost anything and when we
think about these different meanings that they're not unrelated it's not it's not that they're um
completely disconnected um but they are it's not it's not completely clear what the what the
connection is so talk about a light blue it somehow would be weird if a light blue was extremely
extremely dark it seems sensible that if a light thing is something feather like
then a light blue ought to be sort of pale um and this is because of you know the way you know
different modes um different perceptual modes so we interact it seems natural to think of
you know uh pale things as connected to sort of delicate things in but this is all coming out
of our you know sort of perceptual systems um and those connections make sense when you think
we're doing something charade like so if i want to talk to you about um a light blue or a um a light
load or whatever it may be if you realise that i'm playing charades the whole time and i'm thinking
well i haven't got a word handy for that pale blue oh well it's sort of you know sort of ethereal
and sort of weightless ah light i'll call it light and then off i go and call it light blue and you
think i see what you mean yes i guess um and then before we know what we've established this now of
course this is actually established in the language but this doesn't come from nowhere it's come
from a sort of analogical kind of extrapolation of a charade like type and that's going to be true
wherever you look the number of number of ways light is used is gigantic but they have this
common sort of analogical pattern so they're emerging from this from our perspective they're
emerging from this sort of charade like um improvisation where the same conceptual tools
are being continually reused and reused and reused so it's not one word well meaning it's one
word many money possible meanings put words together in different contexts they will mean
completely different things that's okay because we can track this because we are these words are
that flexibility is is is being shaped by what our natural communicative instinct so we don't
have to think well light blue i'm starting from scratch here that could be absolutely anything
that could be blue mixed with lots of red or it could be um very very deep or no it's not really
true it's sort of the the natural analogy that for some reason we have is you know feathery ethereal
things pale things kind of go together okay for whatever reason that's the way we are um so that's
the natural a natural transition to make so this is really interesting because we're getting into
analogical reasoning and you could look at all of the usages of light and that is a beautiful
example saying you know go in the dictionary and look at you know a light to carry might be another
example yeah and you might look at those and and think well they're really divergent and it seems
arbitrary and it might be even more so if the language evolution has progressed and and the
kind of the cognitive distance has has progressed and and so on but weirdly in many cases we can
look at them and and we can see the analogy between them and it's it's difficult to understand
why that is it might be because we're like a neural network and and because we we've seen it used in
all of those cases that's the only reason for the analogical link it might be because they were
conceived in the shared physical and cognitive space which means even though it seemed quite random
at the time there was some grounding because with creativity there seems to be like a degree of
randomness a degree of grounding a degree of interestingness maybe some kind of intuition
it's very mysterious isn't it yeah yeah yeah and I think you're right that these are when you think
about the the the origin of the vocabulary we speak with now it's I think for our for more than
an eye we'd like to think of that as a as the outcome along a long game of charades but of course
as you say that in the latter stages of that game we may well have completely forgotten quite why
what was the analogy between x and y well who knows we've forgotten that but now it's become
established off we go so we might be using the same the same a term in ways which you know where we've
completely forgotten the connection so that the history is always going to be sort of difficult
to to disentangle but but I think the crucial point is to try and put aside the idea that oh but
there must be some common core there must be some real meaning what's light deep down I think that's
almost invariably an error it's a bit like going back to your point about you know creativity I think
thinking well what what's creativity what's the what's the underlying real thing the fact
that we can talk fluidly about a concept light or creativity or anything else in a huge variety
of context context is telling you something about the clever analogical ability of the mind so
for example I mean a creative idea in mathematics versus a a creative recipe versus a a creative
charade I mean it's really very hard to understand what it what is the the the connection between
but there's some sort of analogical thing it's like oh that's when you think about it you think
well that's wasn't obvious but it seemed really cool or something but all you need is that crude
crude analogy because all you're trying to do is communicate in the moment you're you're trying
to say oh that idea seems like a really boring idea but this is you know a bit more you know
productive or you know well maybe we'll call it creative you're only trying to to to solve the
problem in the moment which will be to say steer away from this boring thing and steer
towards this more exciting thing or whatever it may be so thinking of thinking of the purpose of
languages always contextual and always just trying to coordinate our interactions in in the moment
they're happening that makes it puts a lot less load on the the the idea of meaning and it doesn't
it sort of abstracts or pushes one away from thinking there must be some abstract core there must
be an underlying meaning I mean the whole search for the underlying essences is a
is almost a very doomed to fail I think yes I know but but many do try to essentialize language
and they would be forgiven for thinking that there is an essence because there is an apparent
consistency yes and but but if you think about it we could contrive mutations to the language where
there was no analogical link it's it but it is surprising though just how consistent it is
given how arbitrary it was yeah yeah and I think if languages were not deeply patterned and
analogically even though there will be some of that patterning will be lost I mean in the midst of
time there weren't deeply patterned we wouldn't be able to learn them so that's the thing all the
all the cases which just don't really fit the pattern they're going to go we're going to lose
them because we don't quite remember why they've worked away they should and so they'll be they'll
be the things that get dropped pretty quickly yes because I think another reason we think this
way is in school we're taught you know about grammar for example and my mother used to say
Timothy we'll speak the queen's English in this house and you know when when text message
abbreviations came along there's a chorus of people you know just talking about the decline
of of our language yes and apparently that happens almost every generation yes yes it's lovely
there's just this incredibly long history going back to I think Roman times and certainly through
the history of the English language of a continual sense of despair that the language is falling into
total ruin and of course it does go back to this kind of failure to to really believe in the
improvisational power of human communication because if you if you change people's constraints so you
force them to type awkwardly on a on a keypad on their phone then they will they will improvise
differently they'll start to use little symbols they'll start using emojis they'll they'll use
all kinds of shortings they didn't use before but if you take those constraints away they're not
it's not that they've got this fixed structure they're now stuck with and all they can do is
sort of do emojis that send emojis to each other and they will simply jump back to using the full
repertoire of communicative possibilities so there's always this sense that the language is going
to the dogs but it but it never factfully does and of course the other aspect of it is that
when languages change there's always this terrible fear the distinctions that were really very
important to getting lost and how will we ever be able to communicate about this you know this
particular idea or concept or this distinction which is being blurred and the answer is we'll
invent a new one if it matters there will be a new distinction before you know it so you know one
need worry the the human ability to to creatively solve communicative problems that need to be solved
is not um is not going to get go away and the fact that we have distinctions that we think
they're important is is telling us that there's a drive to make those distinctions in certain
circumstances so they're going to get they're going to get made and the languages around the world
are all very different they all allow us to communicate about just everything we want to
communicate about and they're flexible we can add new words as you do as you do it's a casual
conversation with your girlfriend you add you make up new words and play with language and you
make distinctions that haven't been made before we all do that and that's um you know that that
capacity the open-ended nature of language is you know is is our salvation really and I think that
should make make us much less worried about the idea that um that language is this kind of fixed
system continuing danger erosion which you know is a rather like this the Greeks had the sense
that um their own civilization was was a sort of a a collapse from the golden age and the um that
that um you know sort of uh human progress was already sliding disastrously um and I think
that's just a natural a natural a natural tendency and I think we should uh yeah fight against
it we should have a more optimistic perspective we are actually astoundingly creative creatures and
we'll um find our way to to to communicate and think intelligently about almost anything
given half a chance yeah I mean I think a lot of this is because we feel that it's the personification
of an objective reality and it's converged and and any deviation is a kind of derangement of
that but of course that's just not the case at all but it's interesting though that that you're
using the word you know communication expedient and there is an interesting juxtaposition with
communication and thinking because I I think you're communicating a model and a model is knowledge
and the the process of language evolution is epistemic foraging so it's it's the search for new
knowledge and knowledge which becomes memetically ensconced um is knowledge that works because it
has intrinsic value by other people I mean we could argue whether it has intrinsic value or it just
has memetic value because everyone's using it but over time we you know the knowledge is being
shaped we're taking parts of the models away that we don't need anymore and we're adding in new
models when we do need them but some of that knowledge is grounded to objective reality but
probably that the bulk of it as you argue in the book is is really quite relativistic yeah I think
the degree to which languages are shaped around the physical world is is pretty loose
I mean again the the thing that we're mostly worried about in in communicating successfully is
is really local stuff so it's not that if you look for example at the taxes of the biological
taxonomies that different languages have it's not the case that they all just map on neatly onto
either each other or what sort of modern biology would tell us if you looked at as it were the
the evolutionary history and we're not reconstructing that and we're solving practical problems like
these are edible things these are edible things these are things that need to be cooked these are
things that don't need to be cooked these are things you can that run about and have to be
chased and these are things that sit on their own trees and just can be foraged the it's
these are the you know the things that the the practical challenges we face are going to shape the
way we we use words and those will be flexible from one culture to an ex but but also from one
situation to the next and as ever we shouldn't be thinking that asking thinking we should ask the
question and for this language you know what are its concepts you know what are the key concepts
in this language that's a mistake because the the as we were talking about with light there's no
answer to the question you know what does light mean or what does creativity mean what does anything
mean in the abstract there's simply the sort of network of particular um in particular examples
of how this can be used effectively so yeah in page 101 you said that Noam Chomsky's entry into
the study of language in the mid 1950s sparked a revolution both in terms of ideas and you know
more literally as an academic coup de tat the young Chomsky was an iconoclast and a brilliant
scholar you say deeply immersed in philosophy and logic and what would now be called theoretical
computer science and he had a radically new agenda aiming to wrestle linguistics from the study
of culture which is what we've been talking about and reconstruct it on abstract mathematical and
scientific foundations so i mean what's your take on Chomsky yeah well i think i think there's no
doubt that the Chomsky revolution in linguistics is an astonishing achievement i mean it's an amazing
thing to take the the the intellectual ideas that have been developed for understanding formal
languages um in logic and what became the foundation of computer science and to realise that that
could be used as a basis for understanding grammar so it's an amazing and amazing insight
but i think the breaking away breaking language away from culture is a kind of fundamental
mistake from from more than in my perspective so we want to see we want to say that let's see the
kind of chaotic and um ill disciplined nature of languages inevitable and the patterns that arise
within it are coming about by periods of entrenched usages and repeated analogies and so on
so we want to see the ordering language is coming up coming about spontaneously through
process of cultural evolution and so it's going to always be inherently messy and inconsistent
and it's not going to be governed by general principles that the the relationships and patterns
within it are going to be ad hoc um arising bottom up and therefore conflicting like any other bottom
up principles of order different principles will be governing different parts of the language
and they will clash and there will be differences between them now if we're coming from Chomsky's
perspective you don't want to see language as a cultural product at all you want to see it as
essentially an abstract mathematical object and then the messiness and awkwardness of language
gets shuffled off to be either performance or just to be in the periphery of the language so you
say there's this kind of there's this core essence the essential part of the language which in fact
for Chomsky he wants to view that as that essence is the same for all languages aside from
parametric variations and but for us we want to see the patterns in languages as a secondary
so rather than saying there's this kind of core and then it kind of for some mysterious reason is
varied and sort of messed up by actual linguistic use and the evolution of actual languages
but the core is kind of solid we would like to see the patterns and commonalities and sort of
regularities in language other things that are emerging over time so then you start playing
charades without any of these but after a bit of charade playing suddenly patterns start to emerge
so of course that from that perspective you don't want to have you shouldn't be looking for
a kind of mathematical abstraction which is going to perfectly capture language it's just a
mistake to think that's such a thing and the only way you can maintain that viewpoint is by an awful
loss of violent cojoling of language to fit the pattern so my feeling would be that it's much
better to see languages are soft flexible culturally created and ever mutating construction
rather than having a fixed mathematical basis so I think the Chops give the insight is
the program is a fascinating one but I think ultimately it hasn't proved to be the right
tack yeah I mean as a computer scientist I can really understand where he's coming from and
you know he developed to this formal language hierarchy yeah I mean he was thinking about
you know touring machines for example as being able to recognise recursively
innumerable languages and it's mathematically beautiful but it does point to this tendency
that I think we've seen particularly in the 20th century to develop theories of everything
and what I would call universalism which is his idea to try and describe the world in just some
very simple abstract model I mean we spoke with Steven Wolfram he's another great example of this
even Carl Friston had you know people have argued that the free energy principle is a form of
universalism and why do you think there is such a tendency to try and reduce the world in this
way well I think it's it's a great trick if you can pull it off I suppose so it's not obvious to
start with that Newtonian mechanics or something close to it is a pretty pretty good description
of large amounts of reality but my goodness it is so miraculously it says that your planets and
apples obey the same laws fantastic and so I think it's natural it's a natural ambition to have
but I think it's also in most cases a hopelessly unrealistic one because the world is actually
just a very chaotic and complex place and and it's essentially historical so I suppose the
universalist perspective is saying it started with the assumption that there are sort of deep
templates which are not forged by sort of random historical contingency and the deep templates
have got to be got to be found but but the more you think of the aspects of reality you're
interested in as historically contingent and you know like these are the shards we play this is the
way that the our thinking took us these are the environments we're in this is how our bodies
are constructed these are the challenges we face this is you know this is the stuff that this
particular group of people um wanted to talk about here's their language here's another one if they
had even the same problems face them again they'd have come up without something else it's just not
you know it's just not going to be something that's that yields to that to that strategy
so I think but but of course our most successful and sort of striking theories in in science have
that character so it's very natural to want to emulate them if I could think of a universal
theory of language which works I'd go for it I just don't think it's possible yes I mean what I
like about Chomsky's theory is that it's intelligible it's high level and it kind of you know
harves up the world in in an interesting way whereas you know Stephen Wolfram's theory
the the content of the universe is still in the emergent complexity even if it can be constructed
from simple building blocks which I guess would distinguish it but um we should we should move
on a tiny bit so um my very good friend professor Mark J Bishop um we both read your book at the
same time and we were messaging each other on LinkedIn remarking on on your book and he says
he started the book and a couple of things cropped up for him was that um he thought you
were focusing on an anthropomorphic aspect of language and he cited Ferdinand Cersa so he defined
language as an internalised system of symbolic units defined by their interest systemic relations
following Roy Harris um he's he's a fan of of Roy Harris by the way as a linguist who invented
a theory of communication called integrationism which emphasizes innovative partition participation
by communicators but he said he thinks to he prefers to think about language or languaging
as a mode of exercising influence about an entity's future intent and he actually gave the
example of imagine the embodied language of an operating theatre where even the bodily positions
of the nurses and the doctors and the technicians convey the meaning of a game you know in a kind
of operation so would you entertain that kind of expanded view of the game? Yeah yeah no absolutely
indeed um I think that goes back to the Vicensteinian notion of course of a language game where
Vicenstein has a an example of of two people doing some building together so you know one person
says slab and it means something like no I need a slab over here to put put put in position or
it might mean um yeah that slab's the wrong slab or it might mean you know break a slab
into pieces for me or it could mean all sorts of things and it'll be clear from the context just as
in the operating theatre obviously it's a similar kind of setup so sort of a a shout of you know
forceps or scissors or whatever it's probably going to be have different meanings if you're
you know doing the operating versus um if you're you know cleaning up the instruments or something
yes um so so yes I think we should always be thinking of the game as very much embedded and we
don't you know we don't particularly emphasize this but embedded in the sort of momentary interactions
that you're engaged in so and then it becomes even more clear that the the the the work that language
is doing is is is is always scaffolded by all of the other stuff I mean we're trying to we're trying
to successfully do stuff together we're trying to cope me I have coherent coherent um interactions
where we you know collectively operate successfully build something you know how take turns and whatever
it is share things cook meals and that that's that that's the the the purpose of having communication
at all um so so yes in some ways the load that language is bearing is quite a light one
and the more we have this other rich stuff then the the lighter it is and I suppose the illusion
is thinking yes but if you took all that away and just dealt with the null context some sort of
you know for free floaty rounded space then if you just you know what would language mean then
to which the answer is well sort of nothing really you take take all the context away and
we've just got you know sort of empty empty symbols but on on this anthropocentrism point
though I think Mark feels that there isn't such a bright line between humans and animals and in
the language game and the thing is I was on board with your argument because you you are I think
pointing out matter of factly that we have this social memetic plasticity and complexification
and animals don't so it's not that they don't have a social world but they don't have the plasticity
that we have I think that's that's right so certainly animals have communication systems
but they don't have communication systems that differ from one species to another so you know
the the waggled answer the b from a particular system of species of b will always be the same
now you people sometimes say aha but wait a minute what about birdsong bird there are birds
which have variable songs but of course they don't actually have a communicative function
so it's not that the bird is singing something it's like ah now you know over there there's some
you know some food or you know there's no there's no there's no there's no sort of
confluence of flexibility and communicative function that's the thing that that's amazing
about people so I do yes on that aspect about anthropocentrism I think I'm
I'm with it so there's no analogue of the operating theatre for animals where they're
they're engaged in some collective activity and sort of grunting and nodding to each other and
those grunts and nods are being systematically interpreted or at least if there is such a
a thing we you know that would be very interesting to discover but I think I think that's
that would be a non-standard perspective to think that there's no other animals other than us
who can do that yeah it's weird because I was reading that Max Bennett book and and he talks
about Machiavellian apes and so they they do develop sort of like plastic behaviours but then
but the the templates are not shared memetically I think that's the difference GPT3 can write short
stories technical manuals and press releases and do other simple tasks such as answering questions
but GPT3 is not mimicking the human mind it has no mind at all and you said to put it metaphorically
human language is to GPT as the horse is to the motor car horses have indeed been replaced by motor
cars and buses and trains as the most efficient means of human transport but they're scarcely
artificial horses yes yes well I think that I think that is right really so I'm I'm not as
worried about the singularity as many people so I'll give you my look at my positive perspective
which is don't worry about the singularity we're okay but also I'll just add a note of caution
because I feel a bit more cautious these days so the positive perspective is I think yes the idea
that the ability to to answer questions in natural language is somehow the sum total of human
intelligence I guess is a fundamental mistake and an interesting question to ask oneself is if
we allow large language models purely to talk to each other for that for forever more how far
are they going to get right well they what new things are going to do or invent nothing is my
suspicion yeah so they're just pumping out they're going to taking our language they're pumping it
back out and then just pumping back in and about and in and round it will go and we're going to get
absolutely nothing new whereas humans are creating new culture and new invention new ways of doing
things all the time of course the obviously models aren't engaging in in acting in the world as well
and then perceive but irrespective of that they're just not you know they're in a kind of echo
chain but so we can create a culture which they can reflect back at us but that's that's just
reflection and you might say well we aren't we doing that well I think there's something
that not we are of course we are hoofring up information and we are able to reflect it back
at each other but we're also able to you know we're sophisticated reasoning beings who are
actually able to generate new ideas and thoughts and I think I don't think we should be too worried
I think this is a very narrow though impressive achievement though that's my positive sense
that the the the thing is that these systems cannot in particular place your rods in the way
that we can so the thing about human communication is it's not just all about firing back reflecting
back things that have been said before it's about following problems in particular situations
in creative clever ways and this is not yet what these systems can do and maybe maybe it's very
very far from what they can do so the sort of the thing that makes humans remarkable is that
with practical objectives and goals in front of us and languages I suppose we can
say intelligent things and work together in a creative flexible way which is not
yeah it's not not just a generation of abstract text a quick point of that though so these models
are now embedded in our cognitive nexus and they are they are referred to as generative AI and
people even think of them as being a creative thing and I can understand why people think that
you can put any input into GPT and people think that you can kind of explore the space of any
possible output but of course that space is constrained perniciously by data and model bias
and various weird motifs that are baked into the model and so I think in in many ways having
these things embedded in our cognitive nexus will kind of constrain our creativity in a very kind
of pernicious way I think we have to worry about that for sure yes I mean if we're all it's a bit
like it's a kind of more extreme version of if everyone uses the same search engine we all
find the same things when we're interested in the same topic yes and all the other stuff gets kind
of lost and if it becomes even more dangerous if we have the same essentially the same summary
paragraph keeps coming out and saying are they the way to look at this is this and these are the
crucial issues so I think we should be very cautious I think people doing research very rarely
get insensible answers out of large language models so if you actually have something tricky
that you don't understand then asking asking a large language model is almost invariably just
give you a pile of stuff which is exactly the stuff you didn't understand in a slightly random
order it's not that the large language model has you sort of solved the puzzle that you were
struggling with it's not said oh yes I was wondering about this too and in fact the answer is this
it's never does that it just gives you the the salad of various odds and ends that you don't quite
you know what to do with so it's not I mean you know it'd be an awful lot to ask for it to
to sort of solve all our problems for us but it but it isn't doing that um so so I am yes I'm
optimistic that if you if you think I mean if to build a uh a system that's really going to
contribute to you you know a human society at the level of a fellow human being then it's going
to have to be engaging in this charade-like behaviour it's going to have to be able to
have conversations with us in in the world we're in helping us do the things we're
doing having struggling with the problems we're thinking about and wrestling with
and the context we're in as well as just firing back sort of disembodied streams of um of text
so that's why it's on my positive view is like you know machines don't large language models
don't play charades then nothing like as smart as we are I doing something very different
just quickly or not on that but do you need agency to play charade well well I mean I don't know
how we tie it to agency I'm not sure
isn't that isn't that a fascinating thought yeah it is it is very interesting I mean
I've sort of moved my instinct would be to play charades well in a sort of consistent way you need
to have a sense of your joint understanding with the other person because you have to have a sense
of these are the things we know in common if I do these actions that will remind you of the same
thing that will remind me of if I were in your shoes and that's going to be that and that's going
to trigger the thoughts that it could trigger in me so we've got to have some sort of sense of
common understanding of the world so it's an interesting question whether you could actually
do this without essentially being yourself something awfully like a human intelligence agent
yes and then and I use the word agency but a deflationary word would be to use divergence
there's something about a divergent search process accumulating these epistemic you know
nuggets of information putting them back into our information ecosystem it feels like if we had
a like a monolithic centralising algorithm it wouldn't have the same characteristics well I
think any monolithic centralising algorithm is going to lead um yes to sort of a centralized
and standardized way of seeing the world which will be very different will not not lead us forward
as a as a society so I and this is this is a sort of general point about distributed computation
I suppose you need um to have large numbers of agents thinking in divergent in different ways
and the evolutionary process generated by those divergent thoughts and perspectives will and for
some of which will be abandoned most of which will be abandoned others of which will catch on
that's actually the process to to search a large that's the way to search a large space of
an open-ended space of interesting possible things to think about and do
once you've centralised this in in one giant echo chamber then then you're in trouble
yeah but but just to bring it home I mean so would ex-risk people worry about the singularity
and I think the I think recently they've cannibalised AI ethics and governance and they're
they're moving away from the previous mono and maniacal AGI that's going to kill everyone
and now they're talking about memetic intelligence which is the same thing we're talking about but
I mean I don't know whether whether you think that the monomaniacal superintelligence is even
possible but if we are talking about the memetic collective superintelligence that we already are
a part of presumably you don't think we need to worry about that killing everyone no no I think
I don't so the the monomaniacal um in superintelligence I I'm basically not that worried about
but the staggering effectiveness of large language models has slightly shaken my confidence
so I suppose one thing is we should always be suspicious of any any confident feelings you
have about anything you know obviously we we're all we're always making errors all the time about
these things we're always thinking no one will need more the world won't need more than three computers
and all sorts of the Beatles with you know guitar groups are on the way out we don't need the Beatles
and all of these you know pronouncements that have been made throughout history with great confidence
by people with great expertise and turned out to very rapidly to be total nonsense that we should
always be doubtful about those thoughts and in particular if you'd if you'd asked me 20 years
ago say or probably 10 um would it be possible in the 20 uh 2024 to create models which can
chat about any topic can write write a poem about any topic can decide to um can be instructed
to respond without using the letter b and and so on and so on I didn't know way no way there's
never a possible you must be totally joking I did to go to the 22nd century what are you thinking
and and I was completely wrong now I'm not sure that the people who developed large language
models had a particularly different intuition either um or if they did yeah maybe just a
personality trait more they're just more of optimistic characters but no one really could
see the path I think no one could see oh yeah we're kind of here and if we just move a bit
further along suddenly um these problems are going to be solvable it's a it's a sort of
miraculous I think it's an amazing thing that they've proved to be solvable so I suppose I've
slightly been shaken in my intuitions about you know where what's near and what's far my net
my suppose having lived through the sort of good old fashioned ai um period the the story for such
a long time was oh massive changes around around around the corner amazing things are about to
happen oh no they didn't oh no they haven't they haven't no still that's all that happening they're
just about to happen we'll give them a bit more time and neural networks of course look like they're
part of this coming in in in you know even in 50s 60s 70s um it's very interesting um I remember
seeing Jeff Hinton give a talk at 1985 and being astounded by it I'm just amazed I just thought
this is this is most wonderful wonderful stuff but um the idea that we get to a point where suddenly
all sorts of applications and all kinds of capacities are emerging no one really saw coming
uh that's amazing so so I'm I'm just a little bit less gung ho and relaxed than I might have
been in the past but but ironically it's apparently intelligent but not intelligent
and you know it but you know you could argue it's just the McCorduck effect you know you're
just moving the goalposts and everything but it feels to me that while it's a miraculous
achievement and what open ai are doing with the generative vision models it's fantastic but
I still don't see a path to it dramatically changing the job market because you still
need agents doing things they can you these things are tools right they don't do anything on
their own no no I mean of course tools can change things very drastically over time I mean language
itself of course from the language is like a language charades perspective and indeed from
lots of perspectives is a in a way the most spectacular tool of all and that has changed
what's possible for humans to do over long periods of time and I suppose you might say well when
mathematics first started up it seemed pretty pretty impractical did need to do very much very
use and so probably in the long term and maybe it's not we're not talking about centuries here we
may be talking about shorter term some than that then the the systems will will radically change
what we can do but like you I am sceptical of the immediate totally revolutionary impact
these models are going to have on our lives I think that's going to be it's a bit like sort of
google search with with bells on from a practical point of view as a piece of technology it's
miraculous and I think it's actually giving us probably deep insights into the way brains and
intelligent systems can work if we didn't have a force it's incredibly exciting it's very exciting
to be alive at this time it's a moment really is a massive you know it's a massive intellectual
shift and I'm sure I hope I very much hope there are people around in many centuries to come
and if there are I think they will look back at this as an absolutely seminal moment and they
won't they won't be forgotten and lost in the midst of time this will be you know massively
I'm a view of massively significant um but it isn't I think it's not the emergence of
it's not the emergence of a new species of intelligent being it's going to be living alongside
us anytime soon Nick Chaito has been an absolute honno to have you on the show thank you so much
it's been a great pleasure thank you so much Tim wonderful right great stuff that's brilliant
